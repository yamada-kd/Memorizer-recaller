Epoch    10: Training cost= 2.3087, Training acc= 0.1001, Validation cost= 2.3076, Validation acc= 0.0969
Epoch    20: Training cost= 2.2866, Training acc= 0.1118, Validation cost= 2.2856, Validation acc= 0.1100
Epoch    30: Training cost= 2.2579, Training acc= 0.1224, Validation cost= 2.2544, Validation acc= 0.1245
Epoch    40: Training cost= 2.2133, Training acc= 0.1408, Validation cost= 2.2116, Validation acc= 0.1433
Epoch    50: Training cost= 2.1503, Training acc= 0.1562, Validation cost= 2.1443, Validation acc= 0.1577
Epoch    60: Training cost= 2.0559, Training acc= 0.1689, Validation cost= 2.0437, Validation acc= 0.1705
Epoch    70: Training cost= 1.9542, Training acc= 0.1812, Validation cost= 1.9545, Validation acc= 0.1824
Epoch    80: Training cost= 1.8900, Training acc= 0.1919, Validation cost= 1.8600, Validation acc= 0.1936
Epoch    90: Training cost= 1.7734, Training acc= 0.2033, Validation cost= 1.7828, Validation acc= 0.2050
Epoch   100: Training cost= 1.7084, Training acc= 0.2150, Validation cost= 1.7175, Validation acc= 0.2166
tm  [-0.3 -0.4  0.3 -0.1 -0.4 -0.4 -0.9 -0.9  0.9 -1.2  5.8  0.1  1.3  4.   0.1  4.6 -0.  -0.4  0.4  3.7 -0.6 -0.4 -0.5 -1.1 -0.  -0.5 -1.  -0.4 -0.2 -0.2  3.9 -0.7 -0.3  1.1 -0.1  1.5 -0.5  8.1  1.1 -1.6 -0.8 -0.3 -0.8  3.7 -0.5  3.7  0.1 -0.6  2.2  1.2 -0.9 -1.   3.3  0.8 -1.   1.7  1.2  5.3  2.7  0.7  4.2 -0.3 -0.   5.4 -0.3  0.3 -0.   3.7 -0.1  2.   2.5 -0.4 -0.9 -0.5 -0.3 -1.  -0.7 -0.2 -0.   4.2  0.5 -1.1  1.6 -1.4 -1.5  2.2  4.  -1.1  4.5  0.6 -1.1 -1.1  1.   3.3 -0.1  3.2  2.2 -0.7 -0.4  1.8  3.4  0.3  2.4 -0.8  0.2 -1.4 -0.4  1.2  1.3  1.7  0.6  1.2 -1.  -1.5  3.7  0.3 -0.2  3.2 -0.3  2.8 -0.5 -0.6 -0.9  2.8 -0.5  0.5 -0.1 -1.2  5.5  3.   1.5 -0.6  3.   3.5  0.6  1.8 -1.8  1.6 -0.7 -0.4  3.3 -0.1 -0.2 -0.9  0.6  0.2 -0.5  3.7  3.7 -1.2  3.1  1.4  2.4 -0.6 -1.6 -0.9  0.9 -0.   2.5 -0.6  2.  -0.8 -0.6 -1.2  1.1  0.4  2.6  0.4  0.4  2.5  0.4  1.6 -0.1 -1.1 -0.4  1.2  0.2 -1.   4.   0.3 -0.4 -0.5 -0.8  0.7  2.  -0.9 -0.1  0.1 -0.4  7.  -0.2  3.1 -0.4 -0.9  0.9 -1.  -0.9 -1.1 -0.9  2.2  0.6  5.2 -0.4 -1.6 -0.8 -1.   1.9  0.2 -0.4 -0.6 -0.2 -0.9 -1.1  3.8  0.5  0.1  0.3 -0.4 -0.7 -0.5  2.   0.8  1.  -0.1  1.7  0.4  1.7  1.7  2.7  4.8 -0.4  0.7 -1.2 -0.3  6.8  3.7 -0.1 -1.1  1.8 -0.5  0.3 -0.   0.2 -0.3  3.5 -1.3 -0.9  1.6 -0.7  0.5 -0.6  1.5  2.9 -0.1  2.3 -0.6]
ty_50sample [[5 5 5 2 2 7 7 7 7 9]
 [3 8 3 7 7 7 5 5 5 5]
 [9 9 8 8 6 7 7 7 7 2]
 [7 7 4 4 8 9 5 5 5 6]
 [4 9 9 9 5 5 5 5 7 7]
 [4 4 5 5 5 9 7 7 7 7]
 [2 2 2 2 8 7 7 7 6 6]
 [9 9 7 7 7 7 7 6 6 6]
 [6 6 9 8 8 5 5 7 7 7]
 [7 7 8 8 4 6 6 9 9 1]]
tt_50sample [[3 5 2 4 8 0 6 7 1 9]
 [3 8 2 6 7 0 1 9 4 5]
 [9 5 8 0 6 4 7 2 3 1]
 [7 4 3 0 8 2 1 9 5 6]
 [4 3 9 0 2 6 5 8 7 1]
 [4 3 5 8 0 2 9 7 6 1]
 [4 9 2 8 3 1 7 5 0 6]
 [9 0 8 7 1 4 3 2 6 5]
 [2 4 9 6 0 8 5 3 7 1]
 [7 3 8 2 5 6 0 4 1 9]]
vm  [-0.  -0.3  1.8  0.1 -0.5 -0.5 -0.2 -0.4 -0.4  0.9 -0.   1.5 -0.6 -0.6  2.  -0.5 -0.4  0.1  1.1  3.5  0.6 -0.2 -0.1 -0.5 -0.8 -0.2 -0.5  0.5 -0.4 -0.1  1.5 -0.4 -0.3  1.7 -0.1 -0.  -0.   1.7  0.7 -0.7 -0.2  3.1  3.   2.3 -1.1  1.8 -0.7  1.7  2.2  3.  -0.9 -0.3 -0.3 -0.1 -0.3 -0.3 -0.2  3.  -0.2  1.5  0.8 -0.1  0.5  2.7 -0.3 -0.4 -0.1 -0.2  0.4  0.6  2.2  1.1  0.1  0.4  1.  -0.1 -0.4  2.   2.9  2.2  1.2 -0.3  3.  -0.1 -0.1  2.7  2.1 -0.8  1.9  1.3 -0.4 -0.3 -0.2 -0.3 -0.8  1.5  4.4 -0.5  0.7 -0.2  2.3  3.8 -0.  -0.6  1.3 -0.5 -1.3  3.8 -0.1  3.4  0.9 -0.1 -1.  -0.2  2.4 -0.2  0.5  2.  -0.4  1.  -0.3 -0.3 -0.2  3.  -0.8  4.   1.3  0.7  1.6 -0.1  2.7 -0.6  1.3  2.6  0.8  0.6 -0.3  1.1 -1.1 -0.5  2.3  0.7  3.5  0.9 -0.9  0.7 -0.6  0.   1.1  0.4  3.8 -0.1 -0.5  0.7 -0.8 -0.5 -0.1 -0.2  1.5 -0.6 -0.1  1.5  1.4 -0.6  2.2 -0.3 -0.8  0.1 -0.4 -0.5  1.5  3.2 -0.5 -1.  -0.5  3.3 -0.1  0.2  2.4  5.3 -0.2 -0.2  0.8  0.1  0.8 -0.4  1.6  0.2 -0.4  0.9 -0.5 -0.1 -0.1 -0.8  0.5 -0.6 -0.3  0.1 -0.3 -0.1 -0.5  1.6 -0.1 -0.5  3.  -0.3  1.1 -0.2 -0.8 -0.6 -0.1 -0.3 -0.8  4.6 -0.8 -0.1  2.4  0.1  1.7  1.  -0.6  1.3  2.1  0.1  2.8 -0.1 -0.4 -0.6  1.3  1.8 -0.   0.7 -0.7 -0.3  4.   1.1  1.3 -0.2  3.  -0.7 -1.  -0.6  1.3 -0.6  0.7  0.5 -0.5  2.5 -0.1  2.  -0.2 -0.3  1.7  0.4  4.4  2. ]
vy_50sample [[7 7 5 4 4 4 2 2 2 2]
 [5 5 5 5 9 9 6 7 7 7]
 [4 4 2 5 5 5 7 7 7 7]
 [9 7 7 7 2 2 5 5 5 5]
 [4 4 4 4 6 6 6 9 9 5]
 [6 6 9 9 7 2 5 5 5 2]
 [7 9 9 6 6 6 8 8 5 5]
 [3 6 6 7 7 2 2 4 9 9]
 [2 2 2 2 5 7 7 7 7 1]
 [5 6 6 6 8 2 7 7 7 7]]
vt_50sample [[7 5 0 6 8 4 1 3 9 2]
 [8 1 5 2 0 9 4 6 7 3]
 [0 2 4 6 5 1 3 8 7 9]
 [9 1 7 2 4 3 6 8 5 0]
 [4 8 7 3 6 2 1 0 9 5]
 [6 3 9 7 4 0 5 1 8 2]
 [9 7 2 1 6 4 8 3 0 5]
 [0 6 3 7 5 8 1 2 4 9]
 [2 6 5 4 3 9 7 8 1 0]
 [3 5 6 9 8 0 4 2 7 1]]
Epoch   110: Training cost= 1.6281, Training acc= 0.2262, Validation cost= 1.6417, Validation acc= 0.2277
Epoch   120: Training cost= 1.5616, Training acc= 0.2374, Validation cost= 1.5595, Validation acc= 0.2391
Epoch   130: Training cost= 1.5123, Training acc= 0.2484, Validation cost= 1.5175, Validation acc= 0.2490
Epoch   140: Training cost= 1.4668, Training acc= 0.2583, Validation cost= 1.4526, Validation acc= 0.2594
Epoch   150: Training cost= 1.4165, Training acc= 0.2678, Validation cost= 1.4200, Validation acc= 0.2691
Epoch   160: Training cost= 1.3774, Training acc= 0.2772, Validation cost= 1.3648, Validation acc= 0.2787
Epoch   170: Training cost= 1.3677, Training acc= 0.2867, Validation cost= 1.3454, Validation acc= 0.2881
Epoch   180: Training cost= 1.3474, Training acc= 0.2946, Validation cost= 1.3364, Validation acc= 0.2959
Epoch   190: Training cost= 1.3099, Training acc= 0.3014, Validation cost= 1.3187, Validation acc= 0.3035
Epoch   200: Training cost= 1.2304, Training acc= 0.3091, Validation cost= 1.2663, Validation acc= 0.3110
tm  [ 1.2  1.8 -0.2 -0.4 -1.1 -1.  -1.2 -2.  -0.8 -0.7  2.7  2.6 -0.4 -0.7  3.6  1.4 -1.   3.8  0.3  1.5  0.6 -0.6  2.1 -0.8 -0.4 -0.  -0.9 -1.4 -0.1 -0.2  6.1  2.2 -0.4  4.5  2.8  2.1  0.4 -0.3 -0.5 -1.1 -0.1 -0.5 -0.5  7.2 -1.4  5.5 -0.3  3.5  3.6  1.1 -1.9 -1.3 -0.1  2.2 -0.9 -0.6 -0.7  0.2  0.9 -0.3  1.8  5.6 -0.3  5.3  1.4 -0.8 -0.7 -0.   3.9  3.   1.   0.4  0.9 -0.5 -0.2 -0.4 -0.  -0.4  7.1  1.4 -0.8 -0.1  6.4 -0.1 -0.4 -0.1  4.  -0.7  1.9 -0.5 -0.5 -1.3 -0.4 -0.9 -0.4  1.1 -0.6 -0.6 -0.9 -0.3  2.8  3.7 -0.   1.2  6.7 -0.8 -0.6  7.5  2.4  3.1 -0.2 -0.5 -0.4 -0.2  2.  -0.7  0.8  5.8 -0.4  0.3 -0.9 -0.1 -0.7 -0.4 -1.3  6.1  3.2  2.   1.6  2.5  5.8 -0.3  4.4  1.1 -0.4  0.6 -0.2  5.1 -1.  -1.6  1.1  0.6  0.8  1.1 -1.1  1.2 -1.7  2.3 -0.8 -1.2  3.8  0.2 -0.2 -0.3 -1.6 -0.6 -0.4 -0.5  1.7 -1.3  0.3 -0.5  2.  -1.7  0.9 -0.9  1.5  5.1 -0.4  0.7 -0.4 -0.  -0.1 -0.6 -0.   6.4  1.6  0.2 -0.4  4.1  4.  -0.6 -0.2 -1.5  2.3 -1.   2.8 -0.7  0.4 -0.8 -0.1  0.5 -0.6 -1.9  2.1 -0.6 -0.6 -0.2 -0.7 -0.  -1.3  0.9 -1.2 -0.6  0.2 -1.9 -1.1 -0.   1.  -0.5 -0.4 -0.9 -2.4  5.9  0.9 -0.6  0.4 -0.5  0.2  1.4 -0.9  0.8  1.  -0.4  1.4 -0.1  0.7 -0.5  3.1  1.7 -0.2  1.7 -0.8  0.7  4.2  3.3  4.  -0.7  5.6  2.1 -1.1  3.5 -0.1 -0.5  0.6 -0.1 -0.8  0.1 -0.2  1.7 -0.8  3.   5.6 -0.9  2.5 -0.2]
ty_50sample [[7 7 3 3 3 8 2 9 5 5]
 [7 7 9 6 6 2 2 5 5 3]
 [9 5 5 3 3 6 6 7 4 8]
 [1 4 6 9 7 7 8 5 5 5]
 [5 7 8 8 4 9 6 3 3 0]
 [9 5 5 5 7 7 6 0 4 4]
 [2 3 3 5 5 9 9 6 1 7]
 [4 3 3 7 7 6 5 5 5 5]
 [4 4 0 3 3 8 8 8 9 7]
 [9 6 6 8 8 5 3 3 4 4]]
tt_50sample [[4 7 3 0 8 6 2 9 1 5]
 [7 8 9 0 6 2 1 5 4 3]
 [9 5 2 3 1 6 7 4 0 8]
 [1 4 6 9 7 8 3 2 0 5]
 [7 5 8 4 1 9 6 3 0 2]
 [9 3 5 2 7 1 6 8 4 0]
 [2 4 0 3 5 9 6 8 1 7]
 [4 9 0 3 7 6 1 5 2 8]
 [4 1 0 3 5 2 8 9 6 7]
 [9 6 7 8 2 5 1 3 0 4]]
vm  [ 2.2  0.3  2.4  1.8 -0.6 -1.6 -1.2 -1.   1.6 -0.4  4.2  2.2 -0.6 -0.2  2.1 -0.4 -0.3 -0.3  5.2  3.   0.3  0.8  1.4 -0.8 -0.5 -0.2 -0.9  1.3 -0.7 -0.1  1.5  1.2 -1.1  3.  -0.2 -0.5 -0.   1.6  2.1 -1.5 -0.5  1.9  1.3  3.9 -1.4  1.5 -0.5  3.5  4.8  1.  -1.6 -0.4  2.6 -0.4  0.1 -0.6 -0.1  5.2  1.4  1.  -0.3  0.   0.2  6.4 -0.3  0.6 -0.8  0.6  2.2  1.4  2.7  3.3 -0.7 -0.6  1.9 -0.3 -0.8 -0.2 -0.   3.5  3.6 -0.6  1.2 -0.5 -0.6  2.1  2.3 -1.6  3.2  2.5 -0.7 -0.8  0.4  0.4 -0.3  1.5  6.3 -0.3 -0.1  0.8  4.4  4.6  1.4 -0.9  3.4 -1.1 -0.2  4.5 -0.   1.4  4.1  0.2 -1.6 -0.2  3.5 -0.   0.5  4.1 -0.1  2.4 -1.2  1.1 -0.8  0.7 -1.   4.   2.4  1.7  3.8  0.2  1.7 -1.2  2.   3.4 -0.6  1.6 -0.8  1.4 -1.3 -1.   3.5  0.   2.5  0.1 -0.9  0.2 -1.4 -0.7  0.9 -0.1  1.1 -0.4  2.   2.1 -1.4 -1.3  2.8 -0.4  5.4 -0.9 -0.4 -0.4  1.6 -1.   3.1 -0.5 -0.5  0.  -0.6  2.   1.   2.5 -0.6 -1.3 -0.3  3.4  2.1 -0.3 -0.5  2.7  0.5 -0.5 -0.6 -0.4  0.8 -0.6  3.  -0.4  0.7  4.3 -1.   0.4 -0.4 -1.2  1.8 -1.2 -0.1 -0.2 -1.  -0.1 -0.8 -0.5 -0.5 -1.3  1.2 -0.5  1.5  0.5 -0.2 -0.7 -0.5 -0.3 -1.1  3.  -0.7  0.2 -0.3 -0.8  2.1  0.7 -0.8 -0.3  3.5  0.6  0.1 -0.4 -0.4 -0.3  1.9  3.4 -0.1  1.1 -0.8 -0.3  5.  -0.2  1.2  0.5  2.2 -0.1 -0.4 -0.6  0.6 -0.7 -0.4 -0.3 -1.2  0.8 -0.3  1.2 -0.7 -0.9  8.  -0.1  5.   2.5]
vy_50sample [[5 5 3 3 9 8 8 6 6 1]
 [6 4 4 3 3 5 9 8 7 7]
 [7 7 6 8 8 5 3 4 2 2]
 [6 6 9 9 2 8 8 5 5 3]
 [2 8 8 5 5 9 9 7 1 1]
 [7 6 2 2 3 3 5 5 8 8]
 [3 3 1 4 8 8 9 5 5 5]
 [1 9 8 3 6 5 2 2 2 4]
 [6 3 3 7 8 8 1 9 9 2]
 [3 5 5 2 2 6 6 6 8 1]]
vt_50sample [[7 5 0 3 9 8 4 2 6 1]
 [6 4 2 3 1 5 9 0 8 7]
 [7 1 6 0 8 5 3 9 4 2]
 [4 6 0 9 2 8 1 7 5 3]
 [2 0 8 3 5 9 4 7 6 1]
 [1 7 6 2 3 0 9 5 8 4]
 [3 1 4 8 7 0 9 2 6 5]
 [1 9 8 3 7 5 6 0 2 4]
 [5 6 3 7 8 4 0 9 1 2]
 [9 3 5 2 0 7 6 4 1 8]]
Epoch   210: Training cost= 1.2445, Training acc= 0.3168, Validation cost= 1.2216, Validation acc= 0.3187
Epoch   220: Training cost= 1.1905, Training acc= 0.3241, Validation cost= 1.1968, Validation acc= 0.3261
Epoch   230: Training cost= 1.1936, Training acc= 0.3315, Validation cost= 1.2054, Validation acc= 0.3329
Epoch   240: Training cost= 1.1480, Training acc= 0.3381, Validation cost= 1.1406, Validation acc= 0.3399
Epoch   250: Training cost= 1.1518, Training acc= 0.3446, Validation cost= 1.1473, Validation acc= 0.3465
Epoch   260: Training cost= 1.1367, Training acc= 0.3508, Validation cost= 1.1466, Validation acc= 0.3524
Epoch   270: Training cost= 1.1229, Training acc= 0.3569, Validation cost= 1.1748, Validation acc= 0.3582
Epoch   280: Training cost= 1.0457, Training acc= 0.3624, Validation cost= 1.0572, Validation acc= 0.3639
Epoch   290: Training cost= 1.0981, Training acc= 0.3678, Validation cost= 1.1409, Validation acc= 0.3691
Epoch   300: Training cost= 1.0671, Training acc= 0.3726, Validation cost= 1.1047, Validation acc= 0.3741
tm  [-0.2 -0.5  4.8  3.5 -1.4 -0.8 -0.3 -1.5 -0.   4.5  1.9  3.  -0.  -0.4  5.3  0.2 -2.1  1.8  2.9 -0.2  0.4 -0.3  6.4 -1.5 -0.   1.2 -0.9  1.2 -0.1 -0.5 -0.3  1.6 -1.1  4.6  1.7 -0.9 -0.4  2.5  3.2 -0.2 -0.5  4.2 -0.7  0.1 -2.5 -0.2 -0.5  1.9  2.3  3.6 -1.1 -0.4 -0.1  0.3 -0.7 -0.7 -1.2 -0.2  3.4  3.1  1.7  5.2 -0.6  5.4  2.  -0.3 -0.1  0.1  3.4 -0.   4.8  2.3  3.7  3.  -0.6 -0.2 -0.  -0.2  7.4  0.7  4.9 -0.1  3.5  1.6  0.1  2.5 -0.6 -2.3 -1.1  0.7 -0.4 -0.5 -1.6 -1.3  1.8 -0.1  2.9 -0.9 -0.6 -0.3 -0.2  5.7  5.1 -0.6  3.4 -0.8 -1.1  3.6 -0.3  0.2  4.8 -0.2 -0.8  0.2  6.  -0.7  0.1  2.7 -1.1  2.4 -1.2 -0.1 -0.4  1.8 -0.9  5.8  3.   2.   2.5 -0.5 -0.3 -1.  -0.6  3.3 -1.8 -0.1  0.5  3.6 -1.4 -1.1 -0.   5.5 -0.1 -0.8 -1.9  2.2 -1.1 -0.8 -0.4 -0.2  2.3 -0.5 -0.1  0.6 -0.8 -0.8 -0.5 -0.1  7.  -1.3  0.  -0.   2.7 -0.8  1.8 -1.5 -1.3  3.6 -1.1  2.3  3.4  1.7 -0.6 -1.2 -0.2  7.8 -0.   2.  -0.8  4.6  3.  -1.   1.2 -1.   1.7 -0.9  0.  -0.4  3.   0.6 -1.1 -0.3 -0.7 -0.6 -0.2 -0.9  0.8  0.9 -1.8 -0.1 -1.  -0.2 -2.  -0.6  5.2 -1.4  0.5  1.5  2.4 -0.  -0.5 -0.2 -0.9  9.6 -1.2 -0.6  3.4 -0.7  4.3  0.5 -1.5 -0.8  1.2 -0.1  0.2 -0.7 -0.8  2.7  3.9 -0.9 -0.5  1.6 -0.  -0.   2.4 -0.8  5.8 -0.2  4.4  2.2 -1.4  1.1  2.  -2.1  1.2  0.9 -1.   0.7 -0.1  2.9 -0.9  0.6  4.7  2.   1.6  8.2]
ty_50sample [[7 1 0 9 9 8 5 2 6 3]
 [6 6 2 4 0 9 9 5 3 8]
 [2 2 7 5 5 9 8 8 6 4]
 [9 6 5 5 3 0 8 8 4 4]
 [3 9 9 6 6 1 8 5 5 5]
 [0 6 6 2 9 8 1 4 5 5]
 [7 4 4 6 3 9 2 2 1 5]
 [2 6 6 1 0 0 3 8 8 5]
 [5 4 3 0 9 7 7 8 6 6]
 [4 4 1 6 6 9 2 7 5 3]]
tt_50sample [[7 1 0 9 8 5 4 2 6 3]
 [6 7 2 4 0 9 5 3 8 1]
 [2 7 3 5 0 1 9 8 6 4]
 [9 6 5 2 3 1 0 8 4 7]
 [3 9 6 7 0 1 8 2 5 4]
 [0 6 3 2 9 8 4 1 7 5]
 [7 8 4 6 3 9 2 1 0 5]
 [2 6 9 1 0 3 4 7 8 5]
 [5 4 3 0 9 7 8 6 2 1]
 [4 8 1 6 9 0 2 7 5 3]]
vm  [ 0.8 -0.6 -0.7 -0.6 -0.8  0.6 -0.5 -1.4 -0.5  3.5 -1.1  1.  -1.1 -0.1  2.7 -1.1 -0.9 -0.  -1.1  1.2 -0.1 -0.1  2.1 -0.6 -0.2  0.6  0.3 -0.   1.1 -0.6  5.2 -0.4  1.3  1.9  0.5 -0.2  0.1  2.7 -0.1 -1.1 -0.2  4.1  1.6  2.6 -1.3  4.1 -0.6  2.4 -0.1  3.9 -0.8 -1.2 -0.9 -0.4 -1.3 -0.3  0.6 -0.1  2.6 -0.3  5.5 -0.4  0.9  3.3  0.1  0.8  1.6  2.5  2.7  1.8  2.9 -0.1  0.9  2.1 -1.4 -0.5  0.2  1.9  8.8  1.2  0.7 -0.7  3.3 -0.6 -0.   5.3  3.5 -1.1 -0.  -0.  -0.6 -0.9 -1.3 -1.1 -0.8  2.8  0.4 -1.1 -0.5 -0.8 -0.3  4.5  1.3 -0.1 -0.5 -1.1 -2.   6.7 -0.3  3.7 -0.3  0.5 -0.7 -0.1  5.3 -0.8 -0.   2.7 -1.1  1.8 -0.3 -1.2 -0.1  3.  -1.   3.5  1.8  2.1  5.8 -0.2  1.2 -0.5  1.8  0.4  3.1  0.2 -0.2  0.3 -1.  -0.9  3.2  4.   4.6  2.3 -1.3  1.1 -0.4 -0.3  3.1 -0.   6.4  1.2 -0.4  1.4 -1.  -0.2 -0.8  0.3  0.2 -0.7  1.7  0.1  1.9 -0.8  0.1  0.9 -1.2  0.5 -0.1 -0.4  4.7  6.1 -0.2 -1.3 -0.6 -0.  -0.6  1.1  6.   7.3 -0.7 -0.4  1.9  0.5  3.7 -0.5 -0.8  4.1 -0.1  3.7 -0.6 -0.3 -0.4 -1.1 -0.9 -0.5 -1.  -0.6 -0.8 -0.1 -0.4  6.5 -0.6 -1.1  4.1 -1.2  1.   0.1 -0.4 -0.6 -0.4 -0.1 -0.8 10.  -0.2 -0.4  2.6  0.4  0.1  1.4 -0.6  2.3 -0.6  1.7  6.6  0.8 -0.5 -0.1  0.4  0.4 -0.4  0.3 -0.7  0.4  5.1  6.4  3.5 -1.3  5.1 -0.7 -1.  -1.2  1.7 -1.3  5.2 -0.4 -0.4  1.9 -0.2  2.8 -0.6  2.  -0.1 -0.3  4.5  5.5]
vy_50sample [[4 5 5 8 0 0 0 2 9 9]
 [7 2 2 8 6 4 5 1 1 3]
 [3 4 6 5 5 7 0 9 2 1]
 [4 3 9 7 6 5 5 5 2 8]
 [9 9 7 7 3 3 6 5 2 2]
 [1 4 0 5 3 2 2 9 8 6]
 [7 6 4 3 3 5 5 9 9 9]
 [5 5 0 3 2 6 4 4 8 9]
 [3 1 5 5 4 4 2 7 6 6]
 [5 5 5 9 4 8 6 6 3 3]]
vt_50sample [[4 1 5 8 6 0 7 2 9 3]
 [7 2 8 6 4 0 9 5 1 3]
 [3 8 4 6 5 7 9 0 2 1]
 [4 3 7 9 6 0 1 5 2 8]
 [9 0 7 4 3 8 1 5 2 6]
 [1 4 0 5 3 2 7 9 6 8]
 [7 6 4 3 1 0 5 2 9 8]
 [5 1 0 3 2 6 4 7 8 9]
 [3 1 9 5 8 4 2 7 0 6]
 [2 7 0 5 4 9 8 6 3 1]]
Epoch   310: Training cost= 1.0909, Training acc= 0.3774, Validation cost= 1.0638, Validation acc= 0.3789
Epoch   320: Training cost= 1.0684, Training acc= 0.3821, Validation cost= 1.0772, Validation acc= 0.3834
Epoch   330: Training cost= 1.0735, Training acc= 0.3862, Validation cost= 1.0777, Validation acc= 0.3874
Epoch   340: Training cost= 1.0524, Training acc= 0.3902, Validation cost= 1.0108, Validation acc= 0.3915
Epoch   350: Training cost= 1.0077, Training acc= 0.3944, Validation cost= 1.0538, Validation acc= 0.3954
Epoch   360: Training cost= 1.0117, Training acc= 0.3986, Validation cost= 1.0427, Validation acc= 0.3995
Epoch   370: Training cost= 1.0299, Training acc= 0.4028, Validation cost= 1.0016, Validation acc= 0.4035
Epoch   380: Training cost= 0.9678, Training acc= 0.4068, Validation cost= 1.0101, Validation acc= 0.4074
Epoch   390: Training cost= 1.0174, Training acc= 0.4107, Validation cost= 0.9671, Validation acc= 0.4114
Epoch   400: Training cost= 0.9980, Training acc= 0.4142, Validation cost= 0.9744, Validation acc= 0.4152
tm  [-0.8  0.8  2.9  4.3 -0.9 -0.2 -0.4 -1.6  1.6 -0.6  2.6  1.7  3.1  0.9  1.9  2.9 -1.2  2.2  1.   0.3 -0.2 -0.8  5.6 -1.4 -0.7  1.6 -0.7 -0.4  1.3 -0.6 -0.   0.8 -1.1 -0.6 -0.5 -0.1 -0.   5.2  1.1 -0.7 -0.5 -1.1 -0.8 -0.2 -1.1  1.7  0.3 -0.6 -0.8  0.6 -0.9 -0.3  2.9  0.7 -0.8  2.8 -0.3  1.9  0.5  5.7  4.1  4.4 -0.5  2.  -0.1  1.  -0.6  0.1 -0.   5.   4.   1.1  2.9  3.   1.6 -0.5  2.3 -1.7  5.6  2.3  2.1 -0.9  2.1 -0.8  0.5  1.1 -0.2 -1.1  0.6  0.2 -0.3 -0.9  0.1  1.3  1.  -0.3  3.6 -0.5 -1.3  0.9  1.6 -0.3  4.8 -0.2  1.7 -0.1 -0.6 -0.4 -0.2 -0.2  0.7  1.  -0.2  0.6  4.   1.2  0.8 -0.7 -1.2  1.5 -1.1 -0.4  0.5  1.2 -0.6  1.4  2.7 -0.2  1.8  3.1  1.8 -1.1 -0.5  0.7  1.2 -0.6 -0.9  2.6  2.1 -0.6  1.5  0.  -1.1 -0.4 -0.8  1.3 -1.2  3.6  0.  -0.3  2.1 -0.7  3.4 -0.5 -0.8 -0.7 -0.2 -0.8  5.2 -0.1  1.8  0.3 -0.2 -0.6 -0.9 -1.1  3.8  3.9 -0.6  5.7 -0.3 -0.2 -0.1 -1.4  0.8  4.1 -0.9  1.   3.8 -0.7  2.5 -0.3  1.6 -1.3  1.9 -0.4 -0.4  2.2  1.9  3.8 -0.9  1.1 -0.4 -0.8 -0.2 -0.2  0.7 -0.3 -1.3  1.8 -1.   0.7 -2.2 -1.5  2.8 -1.1 -1.1  2.6  6.1 -0.7 -0.   1.1 -0.8  8.2 -0.9 -1.1  5.2 -0.9 -0.1  0.6 -1.  -0.6 -1.2 -1.   4.3  0.5  1.4  7.1  2.3 -1.  -0.3  0.5 -0.9  1.8  4.3 -0.2  2.1  0.1  3.6  4.  -1.1  5.6 -0.2 -1.7  4.6 -0.4 -0.3  3.9 -0.2 -0.8 -0.5 -0.2  2.5  2.4  0.6  4.6]
ty_50sample [[1 1 8 9 9 3 6 4 5 5]
 [1 5 5 7 7 3 8 6 9 9]
 [6 6 1 5 2 3 3 4 4 7]
 [8 3 3 5 4 7 9 2 2 1]
 [8 7 4 4 6 5 9 2 3 3]
 [8 2 4 9 1 5 5 3 3 7]
 [0 9 2 2 4 4 1 3 6 6]
 [7 2 2 0 0 8 4 9 3 3]
 [6 6 5 1 7 7 3 4 9 9]
 [5 4 6 3 3 7 7 7 9 2]]
tt_50sample [[1 8 9 2 7 3 6 4 0 5]
 [2 1 5 7 3 0 4 8 6 9]
 [6 0 1 2 5 9 3 8 4 7]
 [8 3 5 4 6 7 9 2 1 0]
 [8 7 4 6 5 0 9 2 1 3]
 [8 4 2 9 1 5 6 3 0 7]
 [0 5 9 2 4 1 3 7 8 6]
 [7 1 2 0 5 4 3 8 6 9]
 [6 2 5 1 7 3 0 4 8 9]
 [5 4 6 1 3 0 7 9 8 2]]
vm  [-0.1  0.7  3.  -0.7 -1.1 -0.8 -0.4 -2.1 -1.3  0.2 -1.8  2.1 -1.4 -0.8  3.6  0.7 -0.5  1.5 -0.6  1.4  0.8 -0.1  2.7 -0.4 -1.7 -0.2 -0.2 -0.1  1.9  0.1  2.5 -0.6  0.5  3.8 -1.4 -0.1 -0.1  1.1 -0.8 -1.3 -0.   0.7  4.6  1.3 -1.2  3.4 -1.7  3.   1.   4.2 -1.1 -0.2 -0.4  0.2 -0.6 -0.7 -0.1  3.7 -0.5  3.   2.6  0.7  0.7  0.6 -0.5 -0.5 -0.1 -0.8 -0.1  2.   4.5 -0.6  3.   0.1 -1.1  1.5  0.3  0.8  6.7  1.9 -0.6 -0.9  5.6 -0.   0.8  7.3  3.3 -1.1  2.7  1.5 -0.2 -1.  -0.6 -0.4 -1.4  3.1  4.  -0.9 -0.5 -1.4  3.   5.2  0.2  1.1  0.2 -0.  -2.1  3.8 -0.8  5.7 -0.2 -0.9 -0.4 -0.1 -0.9  2.7  2.8  0.3 -0.7 -0.4 -0.6 -1.4  2.2  1.4 -1.   6.8  4.1  2.4  2.6 -0.1  4.6 -0.8  1.3  1.4 -0.   2.2 -0.1  1.2 -0.9 -1.   2.8  3.   4.9  4.6 -1.5  2.9 -0.7 -0.8  0.3  2.7  6.3 -0.1 -0.6 -0.2 -0.9 -0.2 -1.4 -0.2  0.5 -0.8  0.1  3.5  4.6 -0.8  2.6  0.1 -0.1  0.7  0.7 -0.5  2.3  5.5 -0.5 -1.8 -0.3  1.4 -1.2 -0.6  6.9  4.   0.9  0.4  2.1 -1.   0.7 -0.  -0.5  2.1 -1.1 -0.6 -0.7 -0.7  1.  -1.6 -0.5 -0.4 -0.9  0.9 -0.6 -0.8 -0.2  2.9 -0.8 -1.1  5.6 -1.3 -0.1  1.  -0.1 -0.4 -0.3  0.9 -1.   8.5 -0.6 -0.1  4.2 -0.3  3.6  3.4 -1.9  4.5 -0.4  1.5  5.5  3.  -0.3 -0.7  0.4  1.6  0.1 -0.1 -0.8  1.   3.4  2.3  0.8 -0.7  3.3 -1.2 -1.5 -0.5  1.2 -1.   6.4  0.1 -0.7  3.1  1.   0.2 -0.6 -0.  -0.5 -0.5  4.6  2.7]
vy_50sample [[7 7 4 4 1 1 3 3 9 9]
 [6 6 5 0 0 1 4 2 9 9]
 [4 0 9 9 8 8 6 6 2 2]
 [7 5 5 4 4 8 2 2 6 6]
 [5 3 9 9 1 7 6 4 2 2]
 [3 0 0 9 7 6 6 4 8 5]
 [8 2 9 9 3 4 7 7 6 6]
 [6 1 7 9 9 8 0 2 2 4]
 [3 5 5 7 7 7 4 6 6 8]
 [4 9 8 1 0 2 6 6 3 5]]
vt_50sample [[7 4 5 6 8 1 3 9 2 0]
 [3 6 5 0 1 8 4 2 7 9]
 [4 0 9 7 5 8 6 3 2 1]
 [7 5 9 4 3 8 0 1 2 6]
 [5 3 9 0 1 7 6 8 4 2]
 [3 0 1 7 9 2 6 4 8 5]
 [8 9 2 5 4 3 0 7 1 6]
 [6 1 7 5 9 8 3 0 2 4]
 [3 5 0 2 7 1 4 6 9 8]
 [4 9 8 1 0 2 7 6 3 5]]
Epoch   410: Training cost= 0.9730, Training acc= 0.4178, Validation cost= 1.0054, Validation acc= 0.4187
Epoch   420: Training cost= 1.0091, Training acc= 0.4212, Validation cost= 1.0246, Validation acc= 0.4221
Epoch   430: Training cost= 0.9858, Training acc= 0.4246, Validation cost= 0.9510, Validation acc= 0.4255
Epoch   440: Training cost= 1.0323, Training acc= 0.4277, Validation cost= 0.9857, Validation acc= 0.4286
Epoch   450: Training cost= 0.9911, Training acc= 0.4306, Validation cost= 1.0107, Validation acc= 0.4316
Epoch   460: Training cost= 0.9404, Training acc= 0.4336, Validation cost= 0.9260, Validation acc= 0.4347
Epoch   470: Training cost= 0.9557, Training acc= 0.4367, Validation cost= 0.9208, Validation acc= 0.4376
Epoch   480: Training cost= 0.9401, Training acc= 0.4398, Validation cost= 0.9586, Validation acc= 0.4407
Epoch   490: Training cost= 0.9614, Training acc= 0.4426, Validation cost= 0.9177, Validation acc= 0.4436
Epoch   500: Training cost= 0.9072, Training acc= 0.4455, Validation cost= 0.9367, Validation acc= 0.4464
tm  [-0.9 -1.   6.4  3.9 -1.3 -0.3 -0.4 -1.3  1.   4.1  0.6  0.8  2.1 -0.5  4.3  3.6 -2.5  0.8  2.7 -0.1  0.  -0.4  4.6 -1.4 -0.7  0.1 -0.7 -0.   3.4 -1.2 -0.6  0.9 -0.3  4.9  1.  -0.3 -0.6  1.5  0.9  0.7 -0.5  0.7 -0.8 -0.7 -1.3 -0.1 -0.4 -0.4 -0.7  3.4 -1.  -0.1  0.4  2.8 -0.6 -0.4 -0.7  0.4  1.5  3.8  2.7  6.3 -0.2  3.1  3.3 -0.5 -0.5  0.5 -0.  -0.1  4.3  0.2  4.3  2.7 -1.1 -0.1 -0.1 -0.3  7.3 -0.1  3.1 -0.4  4.8  0.8  1.4  2.6 -1.  -1.1 -1.3  0.3 -0.2 -0.6 -0.6 -1.6  0.4 -0.3  1.8 -1.2 -0.4 -0.4 -0.3  3.7  5.5 -0.1  0.3  0.4 -1.1 -0.3 -0.2 -0.2  1.8 -0.3 -0.2 -0.4  3.1  0.4  1.   0.7 -1.3  0.5 -0.6 -0.4  2.   1.  -0.5  4.1  0.1  1.   0.6 -0.3  3.4 -1.8 -0.9  0.1 -0.3  3.4 -0.1  3.5  0.2 -0.8 -0.5  4.2 -0.4 -0.5 -1.7  2.7 -0.9  0.8 -0.8  1.6  3.  -0.4  0.4 -0.4 -0.8 -0.1 -1.  -0.2  1.  -0.7  1.6  2.7  4.2 -0.6  2.9 -1.5 -0.1  3.9 -1.3  2.9  2.1 -0.1 -0.2 -1.1  1.7  6.2 -1.5  2.6  3.3  1.2  2.8 -0.1  0.6 -1.   1.  -1.3 -0.5 -0.4  1.4  0.7 -1.2 -0.  -0.7 -0.6 -0.1 -0.4  1.6 -0.4 -1.5 -0.1 -0.8  0.6 -1.8 -0.9  4.9 -1.1 -0.3  0.7  4.8 -0.3  0.4  1.1 -1.3  9.3 -1.4 -0.4  7.2 -0.7  2.7  1.  -1.3 -0.6 -0.8 -0.3  3.  -0.2  0.3  5.7  2.3 -0.9 -0.2 -0.  -0.1  0.3 -0.5 -1.2  4.4 -1.1  3.9  3.4 -1.4  2.5  3.1 -1.3  3.3  0.7 -0.8  3.4 -0.6  0.2 -0.5 -0.7 -0.2  2.9  1.3  5.9]
ty_50sample [[1 7 6 6 9 9 0 4 3 3]
 [0 0 2 1 3 6 9 8 8 7]
 [9 4 0 1 1 5 7 3 8 8]
 [1 9 2 2 2 0 0 8 6 7]
 [6 0 3 3 1 1 4 9 9 9]
 [4 3 3 8 2 6 7 7 7 5]
 [2 8 6 6 9 1 5 5 3 4]
 [4 9 8 6 6 1 7 3 3 2]
 [4 0 3 1 6 2 8 8 7 9]
 [8 4 2 9 7 0 3 3 6 6]]
tt_50sample [[1 7 6 2 8 9 4 0 5 3]
 [0 2 1 3 4 5 6 9 8 7]
 [9 4 0 1 5 7 6 8 2 3]
 [5 1 3 2 9 0 4 8 6 7]
 [6 0 5 3 1 7 4 8 9 2]
 [4 3 1 8 9 2 6 7 0 5]
 [2 8 6 7 9 0 1 5 3 4]
 [4 9 8 6 1 0 7 5 3 2]
 [4 0 3 1 6 2 8 9 7 5]
 [8 4 2 9 5 0 7 3 1 6]]
vm  [ 0.7 -1.3 -0.1 -0.3 -1.2 -0.  -0.8 -1.9 -0.6  0.4  6.6 -0.5  0.1  2.1  1.9  6.6 -0.5 -0.4  0.8 -0.4  0.  -0.2  0.4 -1.  -0.9  1.  -0.8  1.7  0.4 -0.2  4.8  1.4 -0.9  8.3  1.5  2.6 -0.2  4.7  5.  -0.9 -0.9  3.  -0.5  3.8 -2.1 -0.1  0.8 -0.5  1.   3.  -2.1 -0.7  0.3  2.2 -0.8  0.1 -0.8  0.7  3.7 -0.   3.7  3.  -0.2  9.1  0.8  0.9  0.3  5.1  0.1 -0.2  1.8 -0.8 -0.2  2.1 -0.8 -0.6  0.6  2.2  6.9  1.4  5.6 -0.5  1.9 -0.6 -0.1  6.5  0.3 -1.2 -0.6 -0.4 -0.7 -0.2 -1.2 -0.9  2.4  4.2  1.3 -0.5 -0.5 -0.5 -0.1  5.1  1.1 -0.5  1.2 -1.6 -1.   5.   1.9  1.7 -0.6 -0.1 -0.3 -0.   1.9  0.9 -0.2  2.8 -1.1 -0.1 -0.5 -0.1 -0.8  4.2 -0.8  3.2  1.2 -0.   5.6 -1.3 -0.7 -0.7 -0.4  3.1 -1.8 -0.  -0.5  0.2 -1.3 -1.5  1.1  3.8 -0.1 -0.2 -0.9  4.  -0.2  0.3 -0.1  2.7  4.2 -0.3 -0.7 -0.7 -0.3 -0.5 -0.4 -1.   6.9 -0.7  5.6 -0.6 -0.9 -1.3 -0.3 -0.8 -0.3 -0.1 -0.5 -0.2  3.5  1.8 -0.8 -0.9 -1.2  3.1  2.   1.2 -0.8 -0.3  0.3 -0.2 -1.1 -0.5  2.2 -1.3  2.   0.8 -0.2  0.1 -0.8 -0.4 -0.8 -0.6 -0.5 -0.7  0.5  0.6 -1.3  1.4 -0.8  1.2 -1.8 -0.6  2.5 -0.9  2.3  1.8 -0.4 -0.7 -0.4  0.3 -1.2  8.2  0.8 -0.9 -1.  -0.8  0.6 -0.5 -0.5  0.5 -0.  -0.1  1.1 -0.2  1.7  1.3  2.3  0.8 -0.5 -0.3 -0.1 -0.7  4.9  5.9  5.8 -0.4  2.8  1.  -0.9  0.6 -0.2 -1.3  0.3 -0.6 -1.2  2.5 -0.3  2.1 -1.3  5.7  6.2  2.3  0.3  5. ]
vy_50sample [[4 2 7 5 9 0 8 8 3 3]
 [8 6 6 3 2 2 1 7 7 5]
 [1 4 3 3 6 6 7 5 2 2]
 [8 8 3 4 5 2 2 1 9 6]
 [7 7 5 0 4 9 9 1 6 6]
 [2 9 9 1 1 7 6 8 4 4]
 [0 1 1 7 6 6 3 9 4 4]
 [6 6 4 4 4 1 3 5 9 9]
 [2 9 5 0 6 7 3 3 4 1]
 [0 0 1 1 3 8 7 2 6 9]]
vt_50sample [[4 2 5 7 1 9 0 8 6 3]
 [8 6 3 9 0 2 1 4 7 5]
 [1 4 3 0 6 9 8 7 5 2]
 [8 7 4 3 5 0 2 1 6 9]
 [7 0 8 5 4 3 9 1 6 2]
 [2 5 9 1 7 3 6 0 8 4]
 [0 2 1 7 6 3 8 5 9 4]
 [6 2 8 7 4 1 3 5 0 9]
 [2 9 5 6 0 7 8 3 4 1]
 [5 0 4 1 3 8 7 2 6 9]]
Epoch   510: Training cost= 0.9451, Training acc= 0.4481, Validation cost= 0.9346, Validation acc= 0.4493
Epoch   520: Training cost= 0.9280, Training acc= 0.4508, Validation cost= 0.9172, Validation acc= 0.4520
Epoch   530: Training cost= 0.9469, Training acc= 0.4536, Validation cost= 0.8674, Validation acc= 0.4547
Epoch   540: Training cost= 0.8612, Training acc= 0.4562, Validation cost= 0.8691, Validation acc= 0.4570
Epoch   550: Training cost= 0.9033, Training acc= 0.4587, Validation cost= 0.9097, Validation acc= 0.4597
Epoch   560: Training cost= 0.8898, Training acc= 0.4611, Validation cost= 0.9310, Validation acc= 0.4620
Epoch   570: Training cost= 0.8927, Training acc= 0.4635, Validation cost= 0.9708, Validation acc= 0.4642
Epoch   580: Training cost= 0.9060, Training acc= 0.4657, Validation cost= 0.8542, Validation acc= 0.4665
Epoch   590: Training cost= 0.8965, Training acc= 0.4678, Validation cost= 0.8509, Validation acc= 0.4689
Epoch   600: Training cost= 0.9228, Training acc= 0.4698, Validation cost= 0.9072, Validation acc= 0.4707
tm  [ 1.4  2.2 -0.8  0.6 -0.1 -1.2 -0.4 -1.6 -0.1 -0.6 -0.7  0.5  1.1  0.1 -0.4  3.3 -0.1  2.3 -1.2  0.1 -0.7 -0.1  4.6 -0.4 -0.   0.8 -0.5 -1.2  0.9 -1.3  2.8  0.7 -0.8 -1.1  5.3  0.2  2.4  3.6  2.1 -1.3 -0.3 -0.6 -0.4  4.8 -0.6  6.3 -0.   2.1  2.3  3.3 -0.4 -1.6 -0.2  0.7 -1.5  2.7  1.8 -0.1  4.   3.7  3.1  2.4  2.   1.2 -0.2 -0.9 -0.7  1.8  3.9  2.7  2.5  0.7  3.2 -0.  -0.7 -0.3  1.6 -0.8  3.4 -0.  -1.1 -0.5  1.5 -1.  -1.  -0.4  3.5 -0.7  0.3 -0.4 -0.3 -2.   0.8  0.7  1.9 -0.7 -0.2 -0.5 -1.7  3.  -0.8 -0.7 -0.3  2.   2.9 -0.4 -0.7 -0.2 -0.1  0.8 -0.3  4.8 -0.5 -0.7  3.8 -1.   1.2  1.9 -0.1  3.8 -1.6  0.4 -0.5 -1.2 -0.6 -0.1  1.4 -0.   3.3  3.4  5.1  1.8  3.3 -1.2  4.1 -2.4 -0.3 -0.5 -0.4 -0.5  2.9 -0.9  0.8  0.6 -0.6  4.3 -1.6  2.9  1.1 -0.2  2.   2.   7.6 -0.4 -1.6 -0.7 -0.3 -0.8 -0.3 -0.4  2.5 -1.3 -0.2 -1.7 -1.8 -0.6  2.   2.9 -0.2  3.   2.  -0.3  1.8 -0.3  1.6  2.  -0.3  0.7  1.8  2.2  2.6 -0.1 -0.6 -1.1  5.5  2.2  0.1  1.3  1.6  5.2  0.5  0.8  0.2 -2.1  3.6 -1.2 -0.8 -2.  -0.   2.4 -0.8  4.3 -0.9 -1.7 -1.2 -1.  -1.5  2.2  8.7 -0.4  0.4  0.9 -2.4  2.6 -0.2 -0.2  1.7  0.5 -1.   1.  -0.3 -1.7 -0.7 -0.8  2.   3.5  0.5  2.1 -0.1  5.1 -0.7 -0.9 -2.2  5.5  5.3  7.6  3.9 -0.7  5.8  5.1 -0.5  3.3  1.  -0.2  5.1 -0.4 -0.  -0.   0.4 -0.1  2.2  2.2  5.1 -0.6 -0.6  1.1]
ty_50sample [[8 4 4 0 3 2 6 1 7 5]
 [6 6 4 7 1 1 0 2 5 8]
 [5 5 8 3 2 4 0 0 7 9]
 [4 7 6 1 1 9 5 2 3 3]
 [2 4 6 5 9 1 0 8 7 3]
 [4 8 8 0 0 6 2 7 9 9]
 [5 6 7 0 0 3 9 4 4 2]
 [0 9 9 8 1 2 5 5 7 7]
 [2 1 6 4 4 5 7 8 9 9]
 [6 4 1 3 8 5 9 9 0 0]]
tt_50sample [[8 4 0 3 9 2 6 1 7 5]
 [6 3 9 4 7 1 0 2 5 8]
 [5 1 8 3 2 6 4 0 7 9]
 [4 7 6 1 0 8 9 5 2 3]
 [2 4 6 5 9 1 0 8 7 3]
 [5 4 8 0 1 6 2 7 3 9]
 [5 6 7 0 3 1 9 8 4 2]
 [0 4 9 8 1 2 6 5 7 3]
 [2 1 6 4 5 3 7 0 8 9]
 [6 4 1 3 8 5 7 9 2 0]]
vm  [ 0.1 -0.8  3.5  0.9 -0.6 -0.6 -0.9 -1.   2.9  3.1 -0.   1.4  0.8 -0.3  3.5 -0.3 -1.8  1.8 -0.5  2.2 -0.6 -0.5  3.1 -1.   1.9  0.2 -0.9 -0.3  0.7 -2.2  0.5  0.7 -0.8 -0.2  5.7 -1.  -0.3  2.4 -0.2 -0.5 -0.7  1.8 -0.8 -0.3 -1.5  3.2 -0.5 -0.6  0.6  2.2 -1.  -1.  -0.2  3.5 -0.8  0.7  0.8  1.3  6.3  5.1  4.4  2.4  0.8  6.5  1.  -0.5 -0.2  1.5  2.2  0.2  2.7  3.5  2.7  0.7 -2.2 -0.2 -0.1 -0.5  6.1  1.3 -0.5 -0.2  4.5 -0.8 -0.5 -0.1 -0.4 -0.9 -1.1 -0.3 -0.3 -2.  -0.8 -0.7  0.8 -0.8  0.5 -1.4 -0.8  1.6 -0.9  1.2  5.5 -0.5  0.2 -0.5 -1.7 -0.1  0.7  2.4  2.5  3.5 -0.9 -0.7  9.4 -1.3  0.6  3.8 -0.8  5.1 -1.2 -0.4  0.3  0.2 -0.9  3.4 -0.5  0.2  2.7  1.4  1.5 -1.1 -0.7 -0.5  3.9 -0.1 -0.7  1.5 -0.2 -0.5  0.5  0.8 -0.8 -0.6 -0.9 -0.2 -1.3  1.8  0.4 -0.8  3.6  0.1  4.6  0.5 -1.5 -0.3 -0.3 -0.4 -0.1 -0.5  2.3 -0.6  3.2 -0.6 -0.1 -1.3 -0.8  2.4 -1.   2.8  2.9 -0.1  3.3 -1.   2.1  4.  -1.   2.4  4.8  6.1  1.  -0.5 -0.1 -0.6  6.3 -1.  -0.4 -0.4  3.7  7.  -0.8  2.8 -0.8 -1.2 -0.  -1.  -0.7 -2.3 -1.4  4.  -0.7  5.3 -1.2 -1.1 -0.1 -1.4 -0.5 -0.4  6.4 -0.5 -0.4 -0.3 -1.4  5.8 -1.3 -0.4  7.3 -0.4 -0.5  0.3 -0.3 -1.1 -0.3 -0.7  3.2  0.5 -0.4  5.2  2.8  1.8 -0.6  0.2 -0.9  3.   3.6 -0.   4.4 -1.7  5.6  2.4 -1.3  1.4  3.2 -1.3  4.9  1.3 -0.5  1.3 -0.7  1.4  0.1 -0.1  1.1  0.4 -0.1  2.8]
vy_50sample [[0 8 8 2 2 7 7 4 9 9]
 [6 5 2 2 4 7 7 1 0 0]
 [4 4 6 5 2 0 8 1 9 9]
 [4 9 7 0 1 2 3 5 5 6]
 [8 9 1 5 5 3 4 7 6 2]
 [7 9 3 3 8 2 6 4 1 0]
 [2 2 8 4 5 5 6 0 7 1]
 [0 0 2 5 1 1 6 3 4 7]
 [3 9 7 7 6 4 1 0 0 5]
 [6 6 4 4 9 5 5 1 1 2]]
vt_50sample [[0 1 8 2 6 3 7 4 5 9]
 [6 5 3 4 2 7 8 1 0 9]
 [4 3 6 5 2 0 1 8 9 7]
 [4 9 7 0 1 2 8 3 5 6]
 [8 9 1 5 0 3 4 7 2 6]
 [9 7 3 8 2 5 6 4 1 0]
 [2 8 3 9 4 5 6 0 7 1]
 [0 2 8 9 5 1 6 3 7 4]
 [9 3 7 6 2 4 1 8 0 5]
 [6 0 7 4 3 9 5 1 8 2]]
Epoch   610: Training cost= 0.8767, Training acc= 0.4719, Validation cost= 0.9834, Validation acc= 0.4727
Epoch   620: Training cost= 0.9273, Training acc= 0.4740, Validation cost= 0.8510, Validation acc= 0.4747
Epoch   630: Training cost= 0.8818, Training acc= 0.4761, Validation cost= 0.8610, Validation acc= 0.4767
Epoch   640: Training cost= 0.8537, Training acc= 0.4784, Validation cost= 0.8431, Validation acc= 0.4789
Epoch   650: Training cost= 0.8577, Training acc= 0.4807, Validation cost= 0.9003, Validation acc= 0.4811
Epoch   660: Training cost= 0.8687, Training acc= 0.4825, Validation cost= 0.8567, Validation acc= 0.4829
Epoch   670: Training cost= 0.8644, Training acc= 0.4843, Validation cost= 0.8721, Validation acc= 0.4846
Epoch   680: Training cost= 0.8045, Training acc= 0.4862, Validation cost= 0.8610, Validation acc= 0.4865
Epoch   690: Training cost= 0.8188, Training acc= 0.4882, Validation cost= 0.8264, Validation acc= 0.4885
Epoch   700: Training cost= 0.8520, Training acc= 0.4903, Validation cost= 0.8200, Validation acc= 0.4906
tm  [-1.3 -2.5  4.3  6.4 -0.8 -0.2 -0.5 -0.7  5.9 -0.1  7.6  2.   0.   2.   0.5 -0.9 -1.3 -0.2  2.5  0.2  1.8 -0.5 -0.6 -1.5 -0.9  1.2 -0.6 -0.1  1.1 -1.3  4.1 -0.1  0.7  5.6 -1.4 -0.7 -0.9  1.   1.8 -1.2 -1.  -0.3 -0.2 -0.7 -1.1 -0.6  0.4 -0.  -0.7 -0.8 -1.2 -0.4  3.1 -0.5 -0.   2.5  1.   3.6 -0.4 -0.3  2.2  0.6 -0.6  3.7 -0.3  5.  -0.7  4.1  0.   3.5  0.1  0.5 -1.1 -0.   0.1 -0.5 -0.2 -1.1  4.9 -0.   9.1 -1.   0.4 -0.4  1.3  2.6 -1.  -1.2  2.6  1.8 -0.8 -0.4  1.4 -0.9 -0.1 -0.3  5.4 -0.2 -0.1 -0.3  4.3  0.5  5.7 -0.3 -1.  -0.1 -1.3  2.2 -0.2 -0.4  2.2 -0.3 -0.9  1.1  3.7  2.4 -0.4  1.1 -1.5  1.2 -0.1  0.2  2.5  6.2 -1.   0.1  5.   2.   1.3  1.9  2.  -2.9 -1.   0.3  4.3 10.5 -0.4  5.3  1.1 -1.6  1.5  4.7 -0.4 -0.4 -1.2 -0.8 -0.4 -0.4  2.8  2.   2.  -0.7 -1.4  3.  -1.  -0.4 -0.3 -0.3  2.5  1.4  0.5  2.6 -0.  -0.1  2.5 -0.3  1.1  3.4 -0.8  3.  -0.8  0.  -1.  -1.8  1.9 -0.1 -1.3  0.9  5.   2.2 -0.8 -0.   0.3 -0.1 -0.4 -2.2 -0.6  0.1  1.4  6.  -1.4  0.8 -0.5 -0.9 -0.3 -0.   2.4 -0.3 -1.2 -1.  -1.2  1.  -1.1 -0.7  5.9 -0.1  4.2 -0.6 -1.3 -1.4 -0.9  2.1 -0.7  6.4 -0.9  0.7  5.5 -0.5  1.8 -0.2  0.3  4.1 -0.3 -0.2  3.4 -1.  -0.2  4.   2.4 -0.4 -0.4  3.1 -0.8 -1.   0.8 -0.8 -0.3  1.2  2.6  1.6 -1.3  1.8 -0.5 -2.2 -0.6 -0.4 -1.3  1.3 -0.6 -0.8 -1.3 -2.1  1.2  2.8  7.3  3.9]
ty_50sample [[1 6 6 3 7 7 0 2 4 8]
 [3 3 8 2 4 7 1 1 9 0]
 [8 9 6 3 7 7 0 2 4 4]
 [0 6 3 3 7 7 9 9 2 5]
 [8 2 5 4 0 6 1 7 9 9]
 [8 9 9 2 7 7 3 0 4 1]
 [0 3 7 7 1 4 2 2 5 5]
 [4 5 9 9 6 6 8 1 7 2]
 [0 0 9 1 3 3 5 5 2 7]
 [9 2 7 7 6 4 5 5 8 3]]
tt_50sample [[1 6 5 3 9 7 2 0 4 8]
 [3 5 8 2 4 7 6 1 9 0]
 [8 9 6 3 0 7 1 2 5 4]
 [0 4 6 3 7 1 8 9 2 5]
 [8 2 5 0 4 6 7 1 9 3]
 [8 5 9 2 7 3 6 0 1 4]
 [0 3 9 7 1 4 2 6 5 8]
 [4 5 3 9 6 8 0 1 2 7]
 [0 8 1 9 6 3 5 2 4 7]
 [9 2 7 1 6 4 5 3 0 8]]
vm  [-0.1 -0.2 -0.3 -1.1 -1.   2.3 -1.  -2.  -0.5  0.1  4.7  0.5  0.2  0.7  3.8  2.2  0.2  1.3 -0.5  1.6  0.9 -1.1  1.7 -0.4 -1.5  4.8 -0.3  0.4  0.5 -0.6  3.5 -0.7 -0.8  2.   0.8  1.9  0.9  5.1 -0.3 -0.9 -0.6  1.   0.9  2.6 -1.6  2.9 -0.9 -1.2 -0.3  1.5 -1.5 -1.2 -0.2  3.9 -0.7  0.5 -0.1  1.3  1.9  1.1  6.8  0.4  1.5  7.8  0.4  2.   2.2  2.1 -0.5  1.7  0.7 -0.3  0.2  3.5 -0.5 -0.8  2.  -0.   8.   3.3  0.5 -0.3  4.4 -0.8 -0.1  5.3  1.6 -0.8  0.1 -0.4 -0.4 -1.2 -0.9 -0.5 -0.4  3.3  1.  -0.9 -0.8 -0.7 -0.1  2.3  2.8 -0.4  1.  -0.4 -1.6  3.5  1.8  4.8 -1.5  0.8 -0.3  0.9  3.6  0.2 -0.3 -0.  -1.  -0.3 -0.6 -1.1  1.2  4.7 -1.   3.5 -0.1 -0.4  4.2 -0.2 -0.2 -1.2 -0.7  1.   1.9  1.  -0.8 -0.  -0.3 -1.   0.3  0.5 -0.5  0.3 -0.5  2.  -0.3  3.9  2.5  1.   6.1  0.2 -0.6 -0.3 -0.4 -0.6 -0.3 -0.9  3.8  0.1  6.8 -0.  -0.5 -1.  -0.9 -0.7 -0.1 -0.4  0.3 -0.2  3.1  1.3 -0.1 -1.3 -1.   1.2 -0.4 -0.1  4.6  1.4 -0.3 -0.  -0.3 -0.9  3.6 -1.5 -0.1  2.7 -0.2  2.  -0.7  1.9 -0.1 -0.8 -0.9  0.6 -0.6 -0.3 -0.9  4.4 -0.5  4.1 -1.8 -1.5  3.9 -0.9 -0.1  2.1 -0.  -0.8 -0.4  0.8 -0.7  8.2 -0.1 -1.2  1.6 -0.5 -0.5 -0.2 -0.4  1.8 -1.1 -0.7  4.4  0.6  2.7  3.8  1.6  0.  -0.2 -0.4 -0.5 -0.1  7.3  5.9  2.9 -0.6  2.6 -0.6 -1.4  0.3  0.  -1.6  6.1 -0.4 -0.5  5.  -0.1 -0.3 -1.1  4.2 -0.1  2.1  0.8  2.2]
vy_50sample [[1 1 2 5 5 8 7 9 9 9]
 [2 2 0 9 1 1 7 4 4 8]
 [0 9 8 2 5 6 3 4 7 7]
 [1 1 8 2 9 9 3 3 6 0]
 [4 6 0 8 1 1 2 2 5 5]
 [6 6 1 7 5 8 4 0 0 0]
 [4 4 7 6 1 1 1 3 2 5]
 [7 6 3 3 8 4 2 2 1 5]
 [5 9 8 1 6 7 7 4 4 3]
 [7 8 9 2 5 5 1 1 6 4]]
vt_50sample [[4 1 2 0 5 6 8 7 3 9]
 [2 5 0 3 9 1 7 4 6 8]
 [0 9 8 2 5 6 4 3 7 1]
 [1 8 2 5 7 4 3 9 6 0]
 [6 4 0 8 1 3 7 2 5 9]
 [6 1 2 7 5 9 4 8 0 3]
 [4 9 8 7 6 1 0 3 2 5]
 [7 6 9 3 8 4 0 2 1 5]
 [5 9 8 1 6 7 0 4 2 3]
 [7 8 9 0 2 5 1 3 4 6]]
Epoch   710: Training cost= 0.8695, Training acc= 0.4923, Validation cost= 0.8353, Validation acc= 0.4926
Epoch   720: Training cost= 0.8701, Training acc= 0.4940, Validation cost= 0.8973, Validation acc= 0.4943
Epoch   730: Training cost= 0.8352, Training acc= 0.4958, Validation cost= 0.8614, Validation acc= 0.4962
Epoch   740: Training cost= 0.8380, Training acc= 0.4976, Validation cost= 0.8191, Validation acc= 0.4981
Epoch   750: Training cost= 0.8344, Training acc= 0.4994, Validation cost= 0.7992, Validation acc= 0.4999
Epoch   760: Training cost= 0.8283, Training acc= 0.5011, Validation cost= 0.8155, Validation acc= 0.5018
Epoch   770: Training cost= 0.9096, Training acc= 0.5028, Validation cost= 0.8359, Validation acc= 0.5034
Epoch   780: Training cost= 0.8122, Training acc= 0.5042, Validation cost= 0.8953, Validation acc= 0.5050
Epoch   790: Training cost= 0.8037, Training acc= 0.5060, Validation cost= 0.8590, Validation acc= 0.5066
Epoch   800: Training cost= 0.8512, Training acc= 0.5074, Validation cost= 0.8503, Validation acc= 0.5080
tm  [ 0.2 -0.9 -1.   1.9  0.  -0.8 -0.7 -0.8  1.1 -0.6  0.6  0.6 -0.1 -0.3 -1.4 -1.2 -0.5  0.6 -0.8 -0.5 -0.4 -0.3  2.6  0.2 -0.2  3.2 -0.7 -0.9 -0.5 -0.8  6.4  2.2  2.  -0.8  2.2  0.7  0.3 -0.7  1.6 -1.7 -1.   0.9  0.5  2.5 -0.6  2.6  2.1  2.7  1.2  2.  -0.2 -0.9 -0.  -0.7 -0.6  4.8  0.8 -0.4 -0.2 -0.2  0.5 -0.2 -0.  -0.1 -0.3  0.4 -0.4  5.3  4.4  3.9 -0.7 -0.2 -0.2 -0.3  2.5 -0.   1.3 -0.3  6.7 -0.4  6.  -0.4 -0.4 -1.2 -0.3  0.9  1.9 -0.5  0.4 -0.3 -0.3 -0.4  1.9 -0.2  1.8 -0.1  2.  -0.5 -0.9 -0.  -0.2 -0.1 -0.3  2.3 -0.1 -0.2 -0.2  5.3 -0.6 -0.3 -0.4  6.3 -1.2  1.1  4.2 -1.  -0.5  1.5 -1.1  2.2 -0.4  0.1  0.1  1.4 -0.5 -1.2  2.5  5.5  0.1  0.2  5.7 -1.4  2.1 -1.7 10.6  7.8 -0.2 -0.  -0.1 -1.5  5.5 -0.8  3.4  3.2 -0.7  1.8 -0.5  0.7  2.1  2.6  0.5  1.1  1.1  3.1 -1.  -0.5 -0.4 -0.8 -1.  -0.3  3.3  1.3 -0.2 -0.9 -1.1 -0.2 -0.2  2.1 -0.   2.1  0.1  0.4  0.6 -0.3  2.6 -0.4 -1.1  4.5  3.5  5.   0.2  0.5  1.4 -0.3  0.3 -1.1  2.1  3.   3.5  4.7 -0.2 -0.  -0.1 -1.6  2.6 -0.3  0.8 -1.5 -0.4  1.6 -0.9  3.8 -0.2 -1.   3.2  1.2 -0.3 -0.1  2.8 -0.9 -0.4  0.5 -1.6  3.6 -0.4 -0.5  2.5  0.  -0.9  0.3  2.6 -0.5 -0.8 -0.8  5.9 -0.2 -0.8  2.2 -0.1  2.5 -0.2 -0.1 -1.9  1.9  5.5  7.8  3.9  0.5  5.9  6.9 -1.2  2.6 -0.6 -1.2  0.2 -0.9 -0.5  0.3 -0.5 -0.3 -0.7 -0.5  2.9  0.7  2.   3.7]
ty_50sample [[9 9 0 0 8 8 5 5 2 7]
 [2 7 4 4 3 9 6 1 8 8]
 [9 9 0 0 6 4 7 7 2 8]
 [4 4 3 9 9 0 5 6 8 1]
 [0 0 9 4 2 2 1 8 5 5]
 [3 3 6 2 0 9 9 5 4 1]
 [0 2 5 8 9 9 4 3 3 7]
 [5 6 9 9 1 3 3 0 2 4]
 [3 7 2 5 5 9 6 0 4 4]
 [7 6 9 1 4 2 8 8 5 0]]
tt_50sample [[6 9 0 4 8 3 5 1 2 7]
 [2 7 4 3 5 6 9 1 8 0]
 [5 9 3 0 6 1 4 7 2 8]
 [4 2 3 7 9 0 5 6 8 1]
 [0 6 9 4 3 2 1 8 5 7]
 [3 8 6 2 7 0 9 5 4 1]
 [0 2 5 8 9 1 6 4 3 7]
 [5 6 8 9 1 7 3 0 2 4]
 [3 7 2 5 9 1 6 0 4 8]
 [7 6 9 1 4 2 3 8 5 0]]
vm  [ 2.3 -1.5  4.1  2.1 -0.5 -1.3 -1.5 -0.7  5.9 -0.2  8.1  0.7 -0.3 -0.5  2.3 -0.5 -1.7 -0.2  1.2  3.4 -0.9 -0.3 -0.8 -0.8  0.3  0.4 -1.3  0.1 -0.5 -2.2  1.6 -0.4 -0.3  2.4  4.9 -0.8 -0.6 -0.1 -0.7 -1.5 -1.1  2.  -0.7 -0.4 -0.9  2.6 -0.7 -0.4  3.4 -0.5 -1.4 -1.1  1.5  4.6 -0.1  1.6  1.   6.6  4.8  3.7  1.5 -0.4  0.8  8.4  1.2  0.8 -0.5  5.3  1.   0.   0.5  2.7 -0.7 -0.5 -2.2 -0.2 -1.4 -0.2  2.2  2.6  2.3 -0.7  3.9 -1.1 -1.1 -0.3 -0.3 -1.  -0.3 -0.1 -0.6 -1.6 -0.1  1.6  0.2  0.7  2.4 -1.3 -0.3  1.   0.9 -0.1  3.  -1.3 -0.3 -0.4 -1.9  1.7  3.   1.6  3.5  3.8 -0.8 -0.6  7.9 -1.2  0.4  6.7 -0.7  6.1 -0.8  0.6 -0.   3.2 -1.5  2.6 -1.   0.4  3.4  2.1  3.7 -2.2 -0.6 -0.3  5.3  7.1 -0.9  3.  -0.1 -0.9  0.9 -0.5 -0.8 -0.6 -0.3 -0.7 -1.4 -0.2  2.8 -0.8  1.6  0.   4.2  2.  -1.5 -0.4 -0.  -0.2 -0.3 -0.5  2.3 -0.2  1.8 -0.1  3.8 -0.8 -0.6  0.2 -0.7  1.6 -0.  -0.2  3.8 -1.2  0.7  0.4 -1.4  1.5  5.8  5.9 -0.6 -0.5 -0.9 -0.1  4.7 -2.   2.2 -1.1  1.9 10.3 -0.8  4.7 -0.8 -1.   0.8 -0.9 -1.  -2.2 -1.3  5.5 -0.7  4.8 -0.5 -0.9 -0.9 -1.1  2.7 -1.2 -0.  -1.2 -0.6 -0.7 -1.3  0.2 -1.1  0.2  6.5 -0.4 -0.7 -0.2  2.8 -0.4  0.3 -0.4  2.  -0.6 -0.3  3.2  2.6  8.2 -0.5  1.5 -1.  -0.2  3.9 -0.3  2.5 -1.4  2.9 -0.4 -0.8 -0.1  2.1 -1.   1.2 -0.3 -0.8  0.8 -1.1  0.6 -0.4 -1.1 -0.2  0.7  1.8 -0.3]
vy_50sample [[0 3 3 6 5 7 7 1 4 4]
 [7 7 2 2 6 8 8 0 0 4]
 [7 0 8 8 4 1 5 3 2 2]
 [9 9 8 0 3 5 7 2 6 1]
 [9 9 5 2 4 8 0 0 0 6]
 [7 0 0 6 9 9 9 2 1 1]
 [3 7 2 2 1 0 9 9 4 5]
 [8 2 6 4 1 9 9 0 7 5]
 [8 8 5 3 9 1 1 4 6 2]
 [7 7 2 9 5 8 8 4 4 0]]
vt_50sample [[0 3 6 2 5 7 8 9 1 4]
 [7 1 9 2 6 3 8 0 5 4]
 [0 7 8 9 4 1 5 3 2 6]
 [9 4 8 0 5 3 7 2 6 1]
 [9 3 5 2 4 8 0 7 6 1]
 [7 8 6 5 0 9 3 2 4 1]
 [3 7 2 1 0 8 9 6 4 5]
 [8 2 6 4 1 3 9 0 7 5]
 [8 0 5 3 7 9 1 4 6 2]
 [7 1 2 9 5 3 8 4 0 6]]
Epoch   810: Training cost= 0.8275, Training acc= 0.5089, Validation cost= 0.8330, Validation acc= 0.5096
Epoch   820: Training cost= 0.7670, Training acc= 0.5108, Validation cost= 0.7744, Validation acc= 0.5112
Epoch   830: Training cost= 0.8093, Training acc= 0.5125, Validation cost= 0.7747, Validation acc= 0.5129
Epoch   840: Training cost= 0.8740, Training acc= 0.5140, Validation cost= 0.7685, Validation acc= 0.5146
Epoch   850: Training cost= 0.8405, Training acc= 0.5154, Validation cost= 0.8160, Validation acc= 0.5160
Epoch   860: Training cost= 0.7900, Training acc= 0.5169, Validation cost= 0.8127, Validation acc= 0.5176
Epoch   870: Training cost= 0.8299, Training acc= 0.5184, Validation cost= 0.8233, Validation acc= 0.5190
Epoch   880: Training cost= 0.7507, Training acc= 0.5199, Validation cost= 0.7884, Validation acc= 0.5205
Epoch   890: Training cost= 0.7927, Training acc= 0.5215, Validation cost= 0.8069, Validation acc= 0.5220
Epoch   900: Training cost= 0.7490, Training acc= 0.5229, Validation cost= 0.7858, Validation acc= 0.5235
tm  [-0.4  4.9  2.9  6.2 -0.8 -0.8 -0.6 -1.  -0.  -0.8  1.1  1.9 -0.   1.6 -0.2  2.7  1.6  0.2  1.2 -0.   0.5 -0.9  5.3 -0.7 -1.3  4.1 -0.8 -0.1  0.7 -0.2 -1.1 -0.5 -1.7 -1.2 -1.1 -0.3  2.6  7.7  6.2 -1.1 -0.4 -0.9  0.3  1.7 -1.6  1.3 -0.1 -0.3  0.1  1.5 -0.6 -0.6  2.2 -0.1 -0.5  3.4  0.8  3.6  0.9  7.2  1.5  0.2  1.4  3.6 -1.2  1.1 -0.6 -0.6 -0.1  4.6  3.7  2.3  1.5  2.6  4.7 -0.5  1.8 -2.   0.5  3.2  0.2 -0.6 -0.2 -0.8 -0.1  0.7  1.5 -1.3  3.8  0.  -0.4 -0.9 -0.2  3.5  2.1 -0.1  5.7  0.3 -1.5  1.5  1.9 -0.4  3.6 -0.4  2.  -0.7 -0.1 -1.6 -0.2 -0.6  1.8  0.7 -0.7  1.3  2.5  1.2  1.4 -0.6 -0.6  1.5 -0.9  1.1 -1.1 -0.2 -0.5 -0.4  4.5  0.   3.6  2.2 -1.2 -0.2 -0.3  1.3 -1.4 -3.6 -0.5 -0.8  0.2  0.4  0.9 -0.8 -1.4 -0.7 -0.2  1.4 -1.2  1.7  1.7 -0.1 -0.3 -0.7  5.4 -0.4 -1.  -1.2  2.6 -0.7  8.3 -0.3  1.9 -1.5 -1.  -0.2 -1.7 -0.4  2.5  0.8 -0.1  5.5  1.7  0.6 -0.2 -0.6 -0.6  0.4  0.7  0.7 -1.2 -1.2  1.  -0.6 -0.7 -0.9  2.9  2.   0.4  2.2  1.1  6.9 -0.9 -0.1 -0.4 -0.8  0.5 -0.8  2.2 -0.3 -0.8  2.2 -1.  -0.4 -1.4 -2.5  0.8  1.1 -0.8  4.   3.7 -0.9 -0.5  1.4 -0.8  3.9 -0.7 -0.6 -0.  -0.3 -0.2 -0.  -1.4 -0.5 -0.4 -0.8  0.3  1.8  0.1  4.4  0.4 -0.1 -0.8 -0.4 -1.   2.6  7.5 -0.3  0.8  3.5 -0.1  3.  -0.5  3.3 -0.5 -1.3  3.2 -0.4 -0.1  3.2  0.9 -1.2 -0.4 -0.4  8.7  2.1  0.9  3.5]
ty_50sample [[8 8 1 3 5 5 7 7 4 6]
 [3 8 8 7 1 6 9 5 0 2]
 [1 6 0 3 5 4 7 8 2 2]
 [0 9 5 5 3 1 8 6 7 4]
 [5 7 1 4 8 8 9 0 2 3]
 [3 1 1 6 8 2 9 5 0 7]
 [4 3 5 7 7 8 1 1 0 0]
 [7 1 4 5 5 2 2 8 8 3]
 [4 6 6 8 0 2 5 3 3 7]
 [4 2 6 1 1 5 9 9 7 3]]
tt_50sample [[8 9 1 3 2 5 0 7 4 6]
 [3 8 7 4 1 6 5 9 0 2]
 [6 1 0 5 3 4 7 8 9 2]
 [0 2 9 5 3 8 1 6 7 4]
 [5 7 1 4 6 8 9 2 0 3]
 [3 1 4 6 8 9 2 5 0 7]
 [4 3 5 7 2 6 8 1 0 9]
 [7 1 0 4 5 2 9 6 8 3]
 [4 6 9 8 0 2 5 3 1 7]
 [4 2 6 1 5 8 0 9 7 3]]
vm  [-0.4 -1.4 -1.1 -1.8 -0.9  0.1 -0.2 -1.5  0.7 -1.3  6.2  2.7 -0.9 -0.3  3.1 -0.8  0.3 -0.3 -0.6  4.   0.9 -1.  -1.3 -0.3 -1.   4.4 -0.3 -0.5  0.4 -0.8 10.7 -0.6  0.3  3.4 -0.6  1.6 -0.2  3.  -0.6 -1.5 -0.7 -0.6  1.2  7.1 -1.1  2.5 -1.1  1.1  0.1 -1.6 -1.6 -1.8  0.3  1.7 -1.1 -0.3 -0.3  3.5  0.9 -2.   6.5 -0.7  1.3  7.2 -0.8  2.9 -0.1  6.   0.3  4.6 -0.1 -0.5 -1.5 -0.1 -0.8 -0.7  0.3 -1.1  8.2  2.4  3.  -0.7  2.6 -0.8 -0.3  2.1  3.6 -0.7  4.9 -0.4 -0.6 -1.3 -0.4 -0.4 -0.9  3.8  0.5 -0.9 -0.1 -1.4  3.8 -0.3  1.6 -0.1 -0.1 -0.8 -1.9  8.3  2.5  5.5 -1.  -0.4 -0.5 -0.4  5.5 -0.1 -0.3  5.4 -1.  -0.6  0.4 -1.2  0.3  5.6 -1.5  2.9  2.   0.9  3.4  4.8  0.1 -2.   2.3  0.4  2.8  6.7  0.3  3.4  0.6 -2.1  2.4  1.3 -0.1  0.8 -0.2 -0.4 -0.3  1.5  3.5 -0.6  6.   0.5 -1.9  1.7 -1.  -0.6 -0.3 -0.8  3.4  0.3  3.   0.6 -0.8 -1.1 -0.1 -0.1  1.2  4.3  2.7 -1.1 -0.4  2.6 -0.3 -1.3 -0.8 -0.4 -0.3 -0.9  4.   3.5 -0.5  0.5 -1.  -0.8  2.6 -1.9 -0.5  2.1 -0.2  2.8 -0.4  3.3  0.4 -1.3 -0.6  1.5 -0.7 -0.5 -1.1  0.3 -0.4  7.  -1.2 -1.1  1.6 -1.1  2.1 -0.8 -1.7 -1.2 -0.7  0.  -0.9  6.7  3.4 -0.5 -0.9 -0.2 -0.9 -0.1  0.1  7.6 -0.7 -0.3  1.3 -0.4 -0.3 -0.5  0.2  3.4 -0.3  3.6 -1.  -0.7  8.7  7.4 -0.3 -1.   2.5 -1.1 -1.  -0.3 -0.8 -1.3  0.8 -0.6 -1.4 -0.  -0.2 -0.5 -1.1  0.1 -0.2 -0.9  5.6 -0.7]
vy_50sample [[4 3 1 5 0 6 7 2 9 8]
 [0 6 5 8 1 3 4 2 7 9]
 [5 5 0 4 4 2 3 3 9 8]
 [0 2 8 7 7 6 3 3 1 5]
 [7 2 5 8 8 6 3 3 9 1]
 [4 6 3 3 2 2 7 7 8 8]
 [1 7 7 4 2 2 8 8 3 0]
 [2 5 5 8 6 3 4 9 1 7]
 [8 5 3 3 6 9 9 0 7 7]
 [7 8 8 5 0 0 6 3 3 9]]
vt_50sample [[4 3 5 1 0 6 7 2 9 8]
 [0 6 5 8 1 3 4 2 7 9]
 [5 0 1 4 2 6 7 3 9 8]
 [8 0 2 4 7 6 9 3 1 5]
 [2 7 8 5 6 0 3 4 9 1]
 [4 6 0 3 2 5 7 9 1 8]
 [1 7 6 4 2 5 8 9 3 0]
 [2 5 0 6 8 3 4 9 1 7]
 [8 5 3 4 6 9 0 7 1 2]
 [7 8 5 1 2 0 6 3 4 9]]
Epoch   910: Training cost= 0.8729, Training acc= 0.5241, Validation cost= 0.8022, Validation acc= 0.5247
Epoch   920: Training cost= 0.7900, Training acc= 0.5253, Validation cost= 0.8398, Validation acc= 0.5260
Epoch   930: Training cost= 0.7825, Training acc= 0.5266, Validation cost= 0.8669, Validation acc= 0.5273
Epoch   940: Training cost= 0.8356, Training acc= 0.5279, Validation cost= 0.7434, Validation acc= 0.5287
Epoch   950: Training cost= 0.7686, Training acc= 0.5293, Validation cost= 0.7509, Validation acc= 0.5301
Epoch   960: Training cost= 0.7402, Training acc= 0.5307, Validation cost= 0.7541, Validation acc= 0.5316
Epoch   970: Training cost= 0.9192, Training acc= 0.5320, Validation cost= 0.8028, Validation acc= 0.5328
Epoch   980: Training cost= 0.8234, Training acc= 0.5331, Validation cost= 0.7391, Validation acc= 0.5340
Epoch   990: Training cost= 0.7587, Training acc= 0.5344, Validation cost= 0.7728, Validation acc= 0.5354
Epoch  1000: Training cost= 0.7741, Training acc= 0.5358, Validation cost= 0.7077, Validation acc= 0.5367
tm  [ 3.   0.4  0.9 -0.1 -0.3 -1.5 -1.3 -1.   1.6  0.   0.3 -0.1 -1.  -0.   1.5  0.4  0.5 -0.2 -0.6  3.4 -0.8  0.4  0.2 -0.6 -0.2 -0.4 -0.6 -0.5 -0.3 -1.5 -0.3 -1.  -0.8 -1.6  3.4 -1.   1.6  3.5  0.7 -2.2 -0.7  3.   1.5  3.3 -0.7  4.8 -1.  -0.   3.9  1.3 -0.8 -1.6 -0.4  3.1 -1.   1.8  0.8  5.7  4.9  5.2  2.4 -1.   0.5  6.1 -0.6 -0.2 -0.7  2.1  0.5 -0.1  2.4  2.9  0.4 -0.8 -2.1 -0.2 -0.4 -1.  -0.2  3.1 -1.8 -0.8  0.9 -0.7 -1.7  1.2  2.3 -0.9  3.8 -0.2 -0.8 -1.4 -0.5  4.1 -0.3 -0.   3.  -1.1 -0.3  1.2 -0.1 -0.3  0.4 -1.1  0.6 -0.7 -1.4 -0.7  0.7  1.9 -0.   2.3 -0.9 -1.   4.6 -0.9  0.3  2.6  0.2  5.2 -0.9  0.7 -0.6 -0.4 -1.1  0.5 -0.7 -0.3  5.8  3.   0.6 -0.4  1.1 -0.4  3.9 -1.8 -1.  -0.7 -0.7 -0.3  1.1 -1.5 -0.5 -0.5 -0.  -0.4 -1.4  0.4  4.2 -0.3  2.2 -0.   5.9 -0.2 -1.2 -1.1  0.8 -0.3  1.8 -0.6  1.9 -1.1 -0.6 -0.8 -1.1 -0.3 -0.2 -0.5 -0.2  0.5  3.   2.   1.5 -0.4 -0.5 -1.1  0.4 -0.5  2.2  0.9 -0.9 -0.5 -1.1 -0.5  7.1  0.1  0.4 -0.1  0.5  9.9 -0.6  0.7 -0.3 -1.3  1.9 -1.2 -1.8 -1.6 -0.5  3.6 -0.3  4.  -0.2 -1.6 -1.3 -1.3  1.4  0.5  0.9 -0.9 -0.6 -0.8 -1.2 -0.4 -0.3  0.2  0.7 -0.5 -1.  -0.7 -0.2 -0.8  0.5 -0.5  1.   0.9  0.1  0.5 -0.4  9.6 -1.2  1.2 -0.8  0.9  7.2  4.7  2.4 -1.5  1.8 -1.7 -0.6 -1.3  2.3 -0.3  5.6 -0.1 -0.2  0.3 -0.7 -0.4  1.5 -0.9  2.3 -0.5  1.1 -0.6]
ty_50sample [[0 5 3 2 2 4 4 6 1 7]
 [7 7 3 1 9 9 8 6 4 2]
 [7 0 3 3 8 8 5 4 9 9]
 [6 9 3 8 7 2 2 4 0 1]
 [9 1 5 7 4 4 3 2 2 6]
 [4 6 5 0 0 1 1 3 9 8]
 [7 0 9 3 8 2 4 1 5 5]
 [4 3 7 6 8 9 9 0 5 1]
 [5 3 3 7 1 1 9 2 2 0]
 [1 3 0 4 7 7 9 6 2 2]]
tt_50sample [[0 5 8 3 2 4 6 9 1 7]
 [7 5 3 1 9 8 0 6 4 2]
 [7 2 0 3 8 5 4 1 6 9]
 [9 6 3 8 7 5 2 4 0 1]
 [9 1 5 7 4 8 3 2 0 6]
 [4 6 5 0 7 1 2 3 9 8]
 [7 0 9 3 8 2 4 6 1 5]
 [4 3 7 6 2 8 9 0 5 1]
 [5 3 8 4 7 1 9 6 2 0]
 [1 3 0 4 7 9 8 5 6 2]]
vm  [ 0.7  2.4 -1.1  0.5 -0.2  1.4 -0.7 -1.2 -1.5 -0.1  0.7 -0.7  6.7  0.5 -1.5  6.   0.2 -0.1 -1.4 -1.8 -0.4 -1.3  4.6 -0.1 -1.3  0.4 -0.2 -1.2  2.7 -0.6 -0.  -0.4  1.6 -2.   1.3  4.8  4.5  2.6  1.4 -0.9 -0.6 -0.1  1.5  2.5 -0.3  1.1  1.2 -0.6 -0.9  6.1  0.3 -0.8 -0.8  1.8 -1.4  4.  -0.6 -0.9 -0.7  3.8  2.4  4.6 -0.8 -0.8  1.2  1.3 -0.7  4.5 -0.6  1.   1.8 -0.8  1.   1.5  1.3 -0.3  6.4 -0.6  7.1 -0.2  0.3 -0.1 -0.8 -1.2 -0.1  3.1  2.  -0.4  1.7 -1.  -0.7 -0.2  0.  -0.2  0.9 -0.2 -0.5  0.1 -0.5 -0.6 -0.1 -0.2 -0.3 -0.1  0.7  0.8  0.9 -0.2  0.3 -0.8 -1.9  1.8  0.2  0.5 -0.1 -0.4 -0.6 -1.  -0.1 -0.3 -0.3 -0.2  3.3 -0.6 -0.1 -1.4  1.4 -0.1 -0.5 -0.3  3.4 -0.3 -0.2 -0.8  8.6  0.1 -0.8 -0.5 -0.6 -1.3  0.3 -0.4 -0.3  1.3 -0.5  3.5 -0.1  5.4  1.2  5.2  0.7 -0.1 -0.2 -1.3 -0.2 -0.2  0.3 -0.8 -0.5 -0.8  4.4  2.  -1.1 -1.2 -2.3  0.1  3.8  1.6 -0.1  1.4  2.4 -0.3 -0.2 -0.   1.5 -0.  -0.5 -0.1  1.9 -1.1  0.3  2.4  2.4 -0.9  0.5  2.5 -0.1  4.9  1.4  0.8  0.7 -0.7  3.8 -1.   2.7  0.2  0.   0.1 -0.3  0.8 -0.5 -0.1 -1.2 -1.2  1.  -0.2 -1.2  3.4  5.2 -0.3  1.7 -0.  -1.2  6.6  2.9 -1.   2.9 -0.4 -0.8 -1.1  1.5 -1.4 -1.7 -1.7  5.3  2.2  3.8  4.1 -0.7 -0.2 -0.5 -0.6 -1.4  4.4  4.7  8.1  3.   0.4  3.3  7.5 -0.9  6.4 -0.1 -0.6  3.3 -1.   2.1  2.8  0.4 -0.3  0.2  2.1 -0.3  1.6 -0.2  1.6]
vy_50sample [[2 2 6 9 9 0 0 0 7 7]
 [9 2 3 0 7 5 1 6 4 4]
 [4 4 5 0 0 7 7 3 6 2]
 [1 2 2 4 8 6 0 5 5 7]
 [9 1 2 3 7 0 5 8 4 6]
 [7 4 6 1 0 0 2 9 8 8]
 [6 9 1 0 7 7 3 5 2 4]
 [8 6 2 4 9 9 1 1 3 5]
 [4 8 8 2 0 1 6 6 3 5]
 [6 7 0 0 3 3 4 9 9 1]]
vt_50sample [[4 2 6 8 1 9 0 3 5 7]
 [9 2 3 7 0 5 1 6 4 8]
 [4 9 8 5 0 7 3 1 6 2]
 [1 2 4 9 3 6 8 0 5 7]
 [9 1 2 3 7 0 5 8 4 6]
 [7 4 6 1 0 2 9 5 3 8]
 [6 9 1 0 8 7 3 5 2 4]
 [8 6 2 4 9 0 7 1 3 5]
 [4 8 9 2 0 1 6 7 3 5]
 [6 5 7 0 3 2 8 4 9 1]]
Epoch  1010: Training cost= 0.7420, Training acc= 0.5371, Validation cost= 0.7397, Validation acc= 0.5380
Epoch  1020: Training cost= 0.8241, Training acc= 0.5383, Validation cost= 0.7100, Validation acc= 0.5392
Epoch  1030: Training cost= 0.8223, Training acc= 0.5395, Validation cost= 0.7569, Validation acc= 0.5403
Epoch  1040: Training cost= 0.7696, Training acc= 0.5408, Validation cost= 0.8061, Validation acc= 0.5416
Epoch  1050: Training cost= 0.8134, Training acc= 0.5419, Validation cost= 0.8116, Validation acc= 0.5427
Epoch  1060: Training cost= 0.8589, Training acc= 0.5429, Validation cost= 0.7755, Validation acc= 0.5437
Epoch  1070: Training cost= 0.7708, Training acc= 0.5440, Validation cost= 0.7845, Validation acc= 0.5448
Epoch  1080: Training cost= 0.7553, Training acc= 0.5451, Validation cost= 0.7647, Validation acc= 0.5459
Epoch  1090: Training cost= 0.7282, Training acc= 0.5462, Validation cost= 0.7223, Validation acc= 0.5471
Epoch  1100: Training cost= 0.7060, Training acc= 0.5474, Validation cost= 0.7262, Validation acc= 0.5483
tm  [ 2.8 -1.  -0.2  1.4 -0.4 -1.1 -0.8 -0.9  1.4 -0.6  2.8 -0.3 -0.7 -0.4 -0.1  0.8 -0.4 -0.2  0.6  2.2 -0.6  2.1  0.4 -0.  -0.9  2.8 -0.4 -0.2 -0.  -1.   4.3 -0.8  0.7  0.4  3.4 -0.  -0.1 -0.5 -0.2 -1.7 -0.8  4.1  1.8  1.2 -0.4  2.9 -0.3  1.6  4.1  1.1 -0.9 -1.3  0.6  0.6 -0.2  2.8  0.8  5.   0.6  0.4 -0.2 -0.8  1.7  4.8 -0.   0.9 -0.3  3.2  2.6  0.3 -0.2  0.7  0.2 -0.2 -0.4  0.9 -1.1  2.7  1.7  0.3  3.9 -0.6  3.1 -0.5 -1.3  3.2  1.3 -0.6  1.   0.8 -0.6 -0.8  1.8 -0.2  0.4  0.9  5.2 -1.  -0.  -0.3 -0.   0.6 -0.8 -0.4 -0.1 -0.1 -1.3  2.9 -0.1  1.5 -0.5  4.1 -0.8 -0.   0.9 -0.4  0.3  1.8 -0.3  3.8 -0.7 -0.4  0.6  1.3 -1.1  0.2 -0.3  3.2  2.9 -0.1  7.7 -1.3  0.5 -1.2  7.6  7.6 -0.4 -0.2 -0.1 -0.6  3.1 -0.8  2.6  3.6 -0.8  4.6 -0.8 -0.4  3.9  3.1  1.2  1.1  4.5  2.4 -0.8 -0.8 -1.  -0.7 -1.  -0.2  4.1  1.7  0.3 -1.1  0.4 -0.3 -0.5 -0.4  0.4  1.2  1.8  0.9  1.6 -0.8  0.5 -0.6 -1.2  1.9  5.5  4.8 -0.7 -0.1 -0.7 -0.4  0.6 -1.4  5.2  0.1  0.1  4.2 -0.4 -0.  -0.3 -1.5  2.8 -0.4 -0.1 -1.6 -0.5  2.3 -0.7  4.5 -0.3 -1.  -0.2 -0.2  2.7  1.  -0.6 -1.1 -0.3  0.5 -1.2 -0.5 -1.1 -0.3  3.5 -0.2 -0.1 -0.1  0.6 -0.3 -0.  -0.4  4.2  0.8 -0.4 -0.1 -0.   7.9 -0.2 -0.8 -1.4 -0.3  2.9  4.6  2.3 -0.2  3.3  0.3 -1.2 -0.3  1.9 -0.6  0.8 -0.6 -0.5  1.2 -0.5  0.7 -0.7 -0.9  0.6  1.2  1.7  3.4]
ty_50sample [[6 5 0 4 4 2 3 7 7 1]
 [1 9 6 6 6 0 4 8 3 2]
 [0 7 8 8 1 3 4 2 2 5]
 [4 3 5 2 2 8 6 6 0 0]
 [3 6 5 5 9 8 1 1 0 2]
 [2 6 7 4 9 0 1 8 5 3]
 [8 2 2 0 3 5 7 7 6 4]
 [1 5 3 2 6 6 4 7 9 9]
 [8 8 0 7 7 6 4 5 2 3]
 [8 7 5 3 3 6 1 4 9 2]]
tt_50sample [[6 5 0 9 4 2 3 8 7 1]
 [1 9 6 7 5 0 4 8 3 2]
 [0 7 8 1 9 3 6 4 2 5]
 [4 3 5 2 8 7 1 6 0 9]
 [3 6 5 7 9 8 4 1 0 2]
 [2 6 7 4 9 0 1 8 5 3]
 [8 2 0 3 9 1 5 7 6 4]
 [1 5 3 2 6 8 4 0 7 9]
 [8 9 0 1 7 6 4 2 5 3]
 [8 7 5 0 3 6 1 4 9 2]]
vm  [ 1.3  3.   3.2  2.3 -1.  -0.3 -1.4 -1.  -0.5 -0.6  2.1 -0.2  2.6 -0.5  1.6  6.1  0.6  1.2 -0.4  2.8 -0.  -0.6  3.7 -0.4 -1.3  1.4 -0.6 -0.4  2.2 -0.6 -1.  -0.8  0.4 -1.2  0.2  1.5  2.   3.  -1.1 -1.1 -0.3 -0.1  1.5 -1.1 -0.7  2.1 -1.3 -0.9 -0.   2.3 -0.5 -1.  -0.1  5.  -0.9  1.4  0.5  5.7 -0.2  7.1  0.9  2.3 -0.2  2.5 -0.1 -0.1 -0.5 -0.4 -0.8  1.2  3.1  0.   3.5  0.6 -0.4  0.2  0.4 -0.5  0.6  1.9 -1.1 -0.7  4.3 -0.8 -0.2  1.4 -0.1 -0.8  1.  -0.1 -0.7 -0.7  2.   1.2 -0.3 -0.2  3.6 -0.9 -0.7 -0.1  0.8 -0.2  1.6 -0.2  0.6  2.9 -1.3 -1.4  1.4  1.7 -0.9  1.7 -0.7  1.  -0.6  1.4  2.1 -0.8 -0.4  0.2 -1.1 -0.6  3.1 -0.  -0.8  1.1 -0.1 -0.7  0.1  2.5  6.5 -0.9  0.3 -0.6  7.7  3.3 -0.9  0.4 -0.1 -0.2 -0.5 -1.  -1.1 -0.1 -0.1  2.  -1.1  2.6  1.8  4.   1.9  1.1  3.9 -0.9 -0.8 -0.5 -0.4 -0.4 -0.5 -0.3  2.9  4.3 -0.1 -0.6 -1.2 -0.7  3.2  0.1 -0.   3.3 -0.1  0.6  1.2 -0.8 -0.1 -0.1 -1.7 -0.6  8.6  0.4  0.2  0.7  1.  -1.   2.4  0.3  0.7  1.1 -0.5  3.2 -0.3  1.1  2.5 -1.3 -0.  -0.4 -0.4 -0.7 -0.6  1.9 -0.2  1.9 -0.7 -1.6  1.6 -1.1 -0.8  3.5  5.3 -0.9 -0.3  1.9 -1.4  2.3 -0.5 -0.5  8.1 -0.2 -0.1 -0.5 -0.4 -0.4 -1.3 -1.2  5.2  3.1  2.   4.5 -0.2  1.8  0.  -0.6 -1.2  3.5  3.6  0.3  0.6 -0.3  0.8  1.  -1.6  1.4  2.5 -0.7  6.4  0.1 -0.2  4.9 -0.2 -0.8  0.3 -0.8 -1.4  2.3  0.1  0.4]
vy_50sample [[6 8 8 8 1 3 5 0 4 4]
 [0 0 4 8 3 2 9 9 7 6]
 [2 3 8 1 5 7 4 9 6 6]
 [5 0 0 1 3 3 8 7 4 4]
 [3 5 5 0 1 1 8 6 4 2]
 [1 8 9 5 4 4 2 0 3 6]
 [3 6 9 1 4 4 8 2 0 5]
 [8 1 6 4 7 0 2 2 3 5]
 [8 1 2 2 4 7 7 0 6 6]
 [5 1 0 6 6 3 3 8 7 2]]
vt_50sample [[6 2 8 1 3 5 7 0 9 4]
 [0 1 8 4 2 3 5 9 7 6]
 [2 3 8 1 5 7 4 9 0 6]
 [5 6 0 1 3 9 8 7 4 2]
 [3 5 7 0 9 1 8 6 4 2]
 [8 1 9 7 5 4 2 0 3 6]
 [3 6 9 7 1 4 8 2 0 5]
 [8 6 1 4 7 9 0 2 3 5]
 [8 2 1 3 4 9 7 5 6 0]
 [5 1 0 4 6 9 3 8 7 2]]
Epoch  1110: Training cost= 0.7631, Training acc= 0.5487, Validation cost= 0.7712, Validation acc= 0.5494
Epoch  1120: Training cost= 0.7370, Training acc= 0.5497, Validation cost= 0.7053, Validation acc= 0.5505
Epoch  1130: Training cost= 0.7959, Training acc= 0.5507, Validation cost= 0.7569, Validation acc= 0.5516
Epoch  1140: Training cost= 0.7222, Training acc= 0.5517, Validation cost= 0.7759, Validation acc= 0.5526
Epoch  1150: Training cost= 0.7918, Training acc= 0.5528, Validation cost= 0.7900, Validation acc= 0.5535
Epoch  1160: Training cost= 0.7980, Training acc= 0.5536, Validation cost= 0.7462, Validation acc= 0.5545
Epoch  1170: Training cost= 0.7884, Training acc= 0.5545, Validation cost= 0.7309, Validation acc= 0.5554
Epoch  1180: Training cost= 0.7323, Training acc= 0.5556, Validation cost= 0.7033, Validation acc= 0.5564
Epoch  1190: Training cost= 0.7014, Training acc= 0.5566, Validation cost= 0.6797, Validation acc= 0.5575
Epoch  1200: Training cost= 0.7517, Training acc= 0.5576, Validation cost= 0.6888, Validation acc= 0.5586
tm  [ 0.4 -2.2  4.3  6.7 -1.3 -0.9 -0.  -1.  -0.1  2.   5.6 -0.5 -0.  -0.   1.4 -0.2 -0.7 -0.6  5.  -1.2 -0.3 -0.2  1.4 -0.6 -0.6  1.  -0.5  2.1 -0.5 -0.5  4.2  2.  -0.6  9.8  1.9  0.7 -0.   0.1  7.9 -0.7 -1.2  6.4 -0.   2.2 -1.6 -1.4  3.8  2.6  3.1  1.6 -1.7 -0.3  0.6 -0.7  0.3  1.2 -0.8 -0.1  0.5 -0.5 -0.4  1.1 -0.1  6.3  1.1  0.5 -0.1  2.1  3.1 -0.2 -0.1  0.5 -0.6 -0.1  2.8 -0.1 -0.   4.2  4.2 -0.4 13.8  0.6 -0.6 -0.  -0.7  4.9  0.5 -1.4 -0.7  0.  -0.7 -0.1 -0.3 -1.5  3.   0.6  4.1  0.5 -0.  -0.6  0.2  7.5 -0.2 -0.9 -0.1 -0.6 -0.1  5.1  1.6 -1.   2.8  0.5 -0.6  0.8  3.2 -0.7 -0.7  3.1 -0.9 -0.3  0.1  4.  -0.7  4.8 -0.1  1.5  1.3  5.5  2.5 -1.5 -0.2 -1.4 -0.5 -0.2 -2.5  5.6 -0.2  1.  -1.7 -1.2  2.5  2.2  0.4  1.2 -1.   2.4 -0.4 -1.2 -0.2  3.1 -0.5 -0.5 -0.6  0.3 -0.4 -0.6 -0.5 -0.9  3.4 -0.4  3.9 -0.5 -0.1 -1.3  3.5 -0.4 -2.  -0.3 -0.8  2.7  2.4  0.2 -0.6 -0.6 -0.2  4.8  1.3  4.7 -1.5  1.5 -0.5 -0.3 -0.6 -0.7 -1.  -1.8  4.3 -1.1  2.6  0.5 -0.8 -1.1 -1.1 -0.7  3.2 -0.6  3.9 -0.1 -1.1  1.2 -1.1 -0.8 -1.1 -0.   2.5  1.8  3.6  1.3 -1.5 -0.5 -0.2 -0.5 -0.9  4.2 -0.8 -0.8 -0.6 -0.1  2.8 -0.2 -0.2 -0.2  1.  -0.3 -0.2 -1.  -0.1 -0.2 -0.1 -0.2 -0.5 -0.9 -0.3 -0.9  1.7 -1.   5.6  1.5  2.5  6.1 -0.7  3.  -0.4 -1.5 -2.1 -0.5 -0.7  2.  -0.1  2.2 -1.6  0.8  9.2  3.   1.6  7.2]
ty_50sample [[9 7 0 5 4 2 1 6 8 8]
 [1 2 0 7 4 6 9 8 5 3]
 [3 5 8 4 4 1 1 9 9 6]
 [7 6 3 2 2 5 0 4 8 9]
 [4 4 7 5 1 1 3 3 8 8]
 [3 9 1 6 6 0 4 4 2 5]
 [5 4 9 9 9 8 1 6 6 7]
 [8 1 5 5 3 3 6 4 2 9]
 [5 9 2 3 8 8 4 7 0 6]
 [5 1 1 2 9 6 3 0 4 7]]
tt_50sample [[9 7 0 5 4 2 1 6 8 3]
 [1 2 0 7 4 6 9 8 5 3]
 [3 5 0 4 8 1 7 9 2 6]
 [7 6 3 2 1 5 0 4 8 9]
 [4 7 6 0 1 5 9 3 8 2]
 [3 1 9 8 6 0 4 2 5 7]
 [5 4 9 8 3 0 1 2 6 7]
 [8 7 1 5 3 6 4 0 9 2]
 [5 9 2 3 1 8 4 7 0 6]
 [5 2 1 8 9 6 3 0 4 7]]
vm  [-1.2 -1.3  6.7  4.9 -1.5 -0.1  0.  -1.2  2.1  1.1  4.4  2.5  0.  -0.3  5.8 -0.5 -1.1 -0.   2.2  1.5  0.5 -1.  -0.  -1.1 -0.8  3.  -0.6  0.1 -0.  -0.9  1.2  1.2 -0.6  7.1 -1.  -0.4 -0.2  2.2  0.2 -0.9 -0.9 -0.4 -0.4 -0.7 -1.7 -0.5 -0.8 -0.1 -0.7 -0.8 -1.7 -0.4  0.2  1.  -0.1 -0.2 -0.3  2.3  0.   0.9  4.3  2.8 -0.3  4.7 -0.3  2.8 -0.6 -0.1  0.2  4.2  2.3  1.5 -0.5  2.  -0.5 -0.6  1.2 -1.2  5.7  0.5  4.2 -0.7  2.5 -0.3  1.5  0.5 -0.7 -1.4  0.3  0.6 -0.2 -0.9 -0.2 -1.  -0.6 -0.2  4.  -0.6 -0.3 -0.6  2.7  2.2  7.1  0.3 -0.5 -0.3 -1.3  1.3  0.8  0.7  1.2 -0.6 -0.5  0.3  4.8  0.7  0.4  1.9 -1.4  0.1 -0.2 -0.4  1.7  4.7 -1.1  4.8  3.3  1.2 -0.1  3.1  0.7 -2.2 -0.7  1.2 -0.2  6.9 -0.6  3.   1.5 -1.   0.8  2.2 -0.8 -0.3 -0.9 -0.9 -0.5  0.1 -0.3 -0.3  0.4 -0.5 -1.1  1.2 -0.8 -0.5 -0.4 -0.6  4.   0.5  0.9  1.6  0.9 -0.2  0.9 -0.7  0.3  4.5 -0.8  2.3 -1.   0.8 -0.4 -1.3  0.6  4.3 -1.1 -0.   4.4  2.6  0.3 -0.4  0.6 -0.9  1.2 -1.7 -0.5 -0.6  0.9  4.4 -1.   1.5 -0.5 -0.7 -1.   0.3 -0.1 -0.3 -1.6  0.3 -1.1  1.1 -1.4 -1.2  4.7 -0.9  0.7 -0.1 -0.2 -1.1 -0.7  1.  -0.6  7.4 -1.1 -0.4  5.6 -0.6  1.9  0.4 -1.3  3.7 -0.6 -0.5  2.2 -0.8 -0.   4.4  2.4 -0.8 -0.   3.7 -0.6 -0.4  2.7 -2.  -0.1 -0.4  2.2  1.4 -1.2  1.9 -0.2 -1.9 -0.2  0.  -1.   2.5 -0.7 -0.5 -0.9 -1.6  0.4  1.3  4.3  2.7]
vy_50sample [[1 7 7 0 0 5 2 2 8 4]
 [1 3 0 7 7 4 9 2 8 8]
 [5 2 2 6 9 9 9 3 7 4]
 [8 6 7 2 4 0 0 5 5 5]
 [6 4 5 2 3 3 1 9 7 7]
 [5 7 7 6 0 8 1 4 9 2]
 [0 2 1 1 4 5 6 3 9 9]
 [6 4 4 5 1 7 2 2 9 9]
 [5 2 7 4 4 1 3 3 8 8]
 [2 6 9 7 4 1 3 8 0 5]]
vt_50sample [[1 7 6 0 3 5 9 2 8 4]
 [1 3 0 7 5 4 9 2 6 8]
 [5 2 6 8 1 9 0 3 4 7]
 [8 6 7 2 4 0 1 3 9 5]
 [6 4 5 2 3 8 1 9 0 7]
 [5 7 3 6 0 8 1 4 2 9]
 [0 2 8 1 4 5 6 3 9 7]
 [6 3 4 5 1 7 2 0 8 9]
 [5 2 7 4 0 1 9 3 8 6]
 [2 6 9 7 4 1 3 0 8 5]]
Epoch  1210: Training cost= 0.7357, Training acc= 0.5586, Validation cost= 0.7249, Validation acc= 0.5596
Epoch  1220: Training cost= 0.7654, Training acc= 0.5596, Validation cost= 0.7169, Validation acc= 0.5607
Epoch  1230: Training cost= 0.7293, Training acc= 0.5607, Validation cost= 0.6986, Validation acc= 0.5618
Epoch  1240: Training cost= 0.7060, Training acc= 0.5617, Validation cost= 0.6647, Validation acc= 0.5628
Epoch  1250: Training cost= 0.7009, Training acc= 0.5628, Validation cost= 0.7465, Validation acc= 0.5638
Epoch  1260: Training cost= 0.7361, Training acc= 0.5637, Validation cost= 0.7310, Validation acc= 0.5647
Epoch  1270: Training cost= 0.7023, Training acc= 0.5646, Validation cost= 0.6640, Validation acc= 0.5656
Epoch  1280: Training cost= 0.7082, Training acc= 0.5655, Validation cost= 0.7486, Validation acc= 0.5664
Epoch  1290: Training cost= 0.7148, Training acc= 0.5665, Validation cost= 0.7130, Validation acc= 0.5673
Epoch  1300: Training cost= 0.6677, Training acc= 0.5674, Validation cost= 0.7550, Validation acc= 0.5683
tm  [ 2.3  1.1  5.5  3.9 -1.7 -2.2 -0.4 -1.2 -0.8 -0.8 -1.3  2.  -1.3 -0.6  4.4  0.5  1.3  0.8  3.9 -0.4  0.9 -0.2  3.4 -0.5 -0.8 -0.4 -0.6 -0.  -0.2 -0.3 -0.5  0.4 -0.7  2.3  0.5 -0.6  3.4  0.2  6.2 -1.5 -0.8 -0.1  1.4  3.3 -1.1  2.2 -0.4  6.   5.7  0.8 -0.8 -0.6  0.7 -0.7 -0.5 -0.5 -0.6  2.3  0.3  5.6 -1.1  0.8 -0.4  2.  -0.5 -1.  -1.1 -0.9  2.4  2.8  3.1  3.2  1.6 -0.6 -0.1 -0.  -0.4 -0.9 -0.4  1.4 -0.3 -0.7 -0.6  1.5 -1.2 -0.2  2.3 -1.2  6.2  0.5 -0.6 -1.  -0.2  3.9  0.2 -0.5  3.9 -0.2 -0.4  0.8  4.4  3.1 -0.2 -0.4  2.4 -0.4 -0.5 -0.5 -0.6 -1.   3.1 -0.4 -0.7 -0.1 -0.2  1.1  0.8  2.1  0.  -0.1 -0.5  2.9 -1.2 -1.  -0.4  4.4  3.9  3.1  0.8  2.9  0.2 -0.1  3.6  1.1 -2.8 -2.7 -0.1 -0.  -0.6 -0.5  3.  -1.   2.2 -0.1 -0.9  2.1 -1.8 -1.6 -0.6  0.5 -0.5 -0.2  4.7  0.8 -1.3 -1.2 -0.6 -0.1  2.6 -1.1 -0.5 -1.4 -0.1 -0.7  0.7  0.1 -0.2  1.4 -0.1  1.7  0.2  1.1 -0.7 -0.2 -0.1  4.1  2.9 -0.5 -1.1  0.4  1.5 -0.6 -0.7 -1.   2.1 -0.3  1.2 -1.1 -0.   2.8 -0.5 -0.9 -0.3 -1.7  3.4 -1.  -0.3 -0.2 -0.6 -0.2 -0.4 -0.7 -0.  -1.3 -0.8 -0.3 -0.4  1.5  2.9 -0.3 -0.8 -0.4 -1.  -0.5 -0.2  1.1 -0.5 -0.2  1.9  0.8 -1.6 -0.3  1.7 -0.6 -0.7  2.3 -1.  -1.1 -0.8  6.6 -1.   1.3 -0.8  2.8  4.1 -1.3  2.9 -0.1  1.1  1.5 -0.5  1.5  0.  -0.2  2.8 -0.2 -0.8 -0.4  0.5 -0.5  0.  -1.   6.9 -0.9  2.6 -0.2]
ty_50sample [[7 7 3 0 5 9 4 2 6 1]
 [3 8 7 0 5 4 2 2 9 6]
 [1 8 3 0 0 6 9 4 5 7]
 [5 2 9 0 0 4 1 7 3 6]
 [5 7 9 9 0 8 3 1 6 6]
 [6 9 8 1 3 2 0 7 4 5]
 [9 9 1 0 0 4 3 6 6 2]
 [5 6 9 1 2 4 0 7 7 3]
 [8 2 2 3 3 6 5 9 1 1]
 [7 4 5 5 1 1 6 8 2 9]]
tt_50sample [[7 3 8 0 5 9 4 2 6 1]
 [3 8 7 0 5 4 1 2 9 6]
 [1 8 3 0 2 6 9 4 5 7]
 [5 2 9 8 0 4 1 7 3 6]
 [5 7 9 0 2 8 3 1 4 6]
 [6 9 8 1 3 2 0 4 7 5]
 [9 5 1 7 0 4 3 6 8 2]
 [5 6 9 1 4 2 0 8 7 3]
 [8 4 2 0 3 6 5 9 7 1]
 [7 4 3 5 0 1 6 8 9 2]]
vm  [ 0.9 -1.5  2.8 -1.1 -1.  -1.4 -0.9 -1.1  1.7 -0.7  2.6  0.2  1.  -2.   6.8  1.4 -1.6 -0.3 -0.2  4.1 -0.2  0.5 -1.3 -0.2  0.1 -0.5 -0.9 -0.9  2.8 -1.4  4.7  0.   4.4  6.2  3.7  1.4 -0.4 -1.  -2.4 -0.5 -0.9 -1.5 -0.7  0.1 -0.8  1.5 -1.6  0.8  2.3 -1.2 -1.8 -1.5 -0.8  4.8 -0.5 -1.3 -0.6  3.3  1.2 -0.9 -0.2  3.  -0.5  1.7  0.1 -0.7 -1.3  3.   0.1  0.6  0.8 -0.2 -0.6 -1.2 -3.3 -0.1 -1.3 -1.   4.9  0.5 -0.3 -0.7  4.5 -0.5 -0.3 -1.7  0.5 -0.3  1.4 -0.7 -1.1 -1.3  2.4 -0.7 -1.1  0.2 -0.6 -1.4 -0.5 -0.6  3.9  0.6 -0.1  1.1 -0.   0.1 -2.   4.3  3.   2.1  1.1 -0.6 -0.5 -1.   2.6 -0.5  4.3  6.9 -0.7  1.2 -0.1 -0.7  2.5 -0.1 -1.6  8.2 -0.4 -0.3 -0.3  5.5  8.7 -2.   4.3 -0.9  5.3 14.  -0.5  8.1 -0.2 -1.3 -0.1 -0.2  1.   0.8 -0.3 -0.7 -1.4 -0.3 -1.3 -0.6  4.   1.5  0.5  0.1 -1.4 -0.4 -1.  -0.6 -1.8 -0.3 -0.6  3.7  3.1 -1.1  4.2 -1.   2.8  7.  -0.2 -0.3 -1.5  0.7  0.8 -0.4  0.1  5.5 -1.8 -1.2  9.4  4.8  2.2  0.7 -0.8 -1.   1.  -1.  -0.1 -1.6 -0.9  1.5 -0.1  3.2  0.9 -1.4  1.5 -0.2 -1.3 -1.2 -0.8  0.5  0.4  4.1 -0.3 -0.3 -1.1 -1.7 -0.1 -1.3  3.7 -0.9  0.8 -0.5 -2.2  1.5 -0.   0.4  5.1 -0.2  1.5 -0.4 -0.2  1.9 -0.2 -0.6  1.8 -0.1 -0.4 -0.1  0.1  7.6 -0.1  3.1 -0.7  2.  -0.   0.2 -0.2 -2.5  3.9  1.3 -1.4  1.6  0.8 -0.4  2.1  2.9 -1.1 -0.6 -0.7  0.4 -0.1 -1.3 -2.1 -1.4  2.6 -1.8]
vy_50sample [[6 3 7 4 2 0 8 8 5 5]
 [0 0 2 5 9 9 3 3 3 4]
 [2 6 6 0 8 9 5 5 3 3]
 [9 5 6 2 1 1 8 4 0 7]
 [1 9 4 4 6 6 3 8 5 7]
 [4 3 0 0 2 8 5 6 9 9]
 [9 9 1 2 0 0 6 6 5 3]
 [7 3 8 9 0 6 6 1 1 5]
 [8 7 5 5 4 1 3 0 9 2]
 [3 4 9 6 7 7 8 5 5 0]]
vt_50sample [[6 3 7 4 2 0 8 1 9 5]
 [0 2 7 1 6 5 9 3 4 8]
 [2 6 0 1 8 9 4 5 3 7]
 [9 5 3 6 2 1 8 4 0 7]
 [1 9 0 4 6 2 3 8 5 7]
 [3 4 0 1 2 8 5 6 9 7]
 [9 1 7 8 2 0 6 4 5 3]
 [7 3 8 9 0 4 6 1 2 5]
 [8 7 5 4 1 0 6 3 9 2]
 [3 4 9 6 2 7 8 5 1 0]]
Epoch  1310: Training cost= 0.7249, Training acc= 0.5682, Validation cost= 0.6957, Validation acc= 0.5691
Epoch  1320: Training cost= 0.7244, Training acc= 0.5692, Validation cost= 0.7061, Validation acc= 0.5700
Epoch  1330: Training cost= 0.7265, Training acc= 0.5701, Validation cost= 0.7637, Validation acc= 0.5709
Epoch  1340: Training cost= 0.7220, Training acc= 0.5711, Validation cost= 0.6717, Validation acc= 0.5718
Epoch  1350: Training cost= 0.7167, Training acc= 0.5719, Validation cost= 0.7033, Validation acc= 0.5728
Epoch  1360: Training cost= 0.6787, Training acc= 0.5728, Validation cost= 0.7356, Validation acc= 0.5736
Epoch  1370: Training cost= 0.7364, Training acc= 0.5736, Validation cost= 0.7125, Validation acc= 0.5745
Epoch  1380: Training cost= 0.6885, Training acc= 0.5744, Validation cost= 0.6536, Validation acc= 0.5754
Epoch  1390: Training cost= 0.7259, Training acc= 0.5753, Validation cost= 0.6899, Validation acc= 0.5762
Epoch  1400: Training cost= 0.6782, Training acc= 0.5762, Validation cost= 0.6855, Validation acc= 0.5771
tm  [ 4.   0.1  6.2  6.  -1.4 -1.3 -0.7 -1.1 -0.7 -0.3  3.9  0.4 -0.5 -0.7  3.6  1.3 -0.1 -0.1  5.1  1.5 -0.2 -0.3  2.2 -0.  -1.3  2.6 -0.5  0.  -0.4 -0.7 -0.1  0.1 -0.6  4.9  2.3  1.8  0.9 -0.1  1.4 -1.2 -0.9  2.9  1.  -0.5 -1.   0.9 -0.7  1.2  4.5  1.9 -1.8 -0.1  2.   1.4  2.  -0.  -0.1  4.  -0.1  3.4 -0.6  0.9  0.7  6.4  0.6  0.5 -0.2 -0.5  0.9  1.5 -0.1  4.   1.6 -0.1  2.1 -0.  -0.9  0.9  0.2  1.1  4.  -0.2  4.2 -0.2 -1.4  2.   0.3 -0.9 -0.1  0.7 -0.2 -0.7  0.7  0.3  0.9  0.7  6.9 -0.3 -0.2  0.2  1.4  5.  -0.5 -0.6  2.1  0.9 -0.3 -0.1  0.6  0.5 -0.2  1.6 -0.7  2.7 -0.1 -0.1  1.   1.6 -0.3  1.6 -0.5  0.5 -0.   1.4 -0.9  3.7 -0.2  1.6 -0.1 -0.   5.8 -1.3 -0.5 -0.1 -0.2  4.4 -0.5 -0.2 -0.3 -0.3  0.5 -1.1 -0.1  2.1 -0.4  3.4 -0.9 -0.9 -0.3  2.1 -0.2 -0.1  5.2  0.6 -0.8 -0.8 -0.5 -0.4 -0.1 -0.1  3.9  1.3  0.7 -0.8  0.7 -0.9 -0.5 -0.7 -0.2  3.2  0.1 -0.1  0.3 -0.8 -0.1  4.3 -0.6  2.1  1.6  2.1  1.2 -0.6 -0.3 -1.1  0.4 -1.3  4.8 -0.9  1.   2.5 -0.4  0.3 -0.4 -1.1  3.3 -0.2  2.2 -0.5 -0.5  3.6 -0.8 -0.1 -0.5 -0.9  0.1 -0.   0.3  2.3  1.3 -0.7 -0.6 -0.  -0.9 -0.8 -1.4 -0.6  4.  -0.2  2.8  0.5 -0.8 -0.5 -0.3 -1.   1.9  0.1 -0.2  0.2  1.6  3.3  0.4 -0.6 -0.9  0.6  3.4 -1.4  3.3  1.9  1.8  3.5 -1.2  1.4  1.9 -0.6  0.1 -0.1 -0.7  4.1 -0.4  0.3 -0.8 -0.8  2.7  2.2  0.7  3. ]
ty_50sample [[7 7 9 6 5 5 8 3 4 1]
 [3 4 6 1 8 8 9 9 2 2]
 [1 3 9 5 5 6 2 4 7 0]
 [2 0 3 9 6 6 7 4 5 8]
 [3 9 2 8 6 6 1 0 4 7]
 [2 4 0 0 6 7 9 3 5 1]
 [6 5 9 2 1 3 3 0 4 4]
 [3 6 8 4 2 9 1 0 5 7]
 [7 7 4 4 0 1 6 8 3 3]
 [2 0 5 4 9 1 7 6 3 8]]
tt_50sample [[7 9 0 2 6 5 8 3 4 1]
 [3 4 6 1 8 7 9 5 0 2]
 [1 3 9 5 8 6 2 4 7 0]
 [2 0 3 9 1 6 7 4 5 8]
 [3 9 2 8 5 6 1 0 4 7]
 [2 4 0 8 6 9 7 3 5 1]
 [6 5 9 2 1 7 3 0 8 4]
 [3 6 8 4 2 9 1 5 0 7]
 [5 7 4 0 1 2 6 9 8 3]
 [2 0 5 4 9 1 7 6 3 8]]
vm  [ 0.9 -0.9  1.5  6.1 -0.2 -1.2 -0.7 -0.4  3.1  1.8  1.8 -0.4 -0.6  1.4 -0.7 -0.3 -0.7 -0.8  0.1  0.4 -0.5  0.8  2.5 -0.6 -0.8  0.9 -0.2  1.  -0.4 -1.5 -0.  -0.6 -0.2 -0.4  1.9 -0.9 -0.3  1.4  1.2 -1.5 -0.6  7.7  2.4 -0.5 -0.6  0.4  0.9  1.   2.4  2.9 -0.8 -0.7  0.2 -0.  -0.1  4.7  2.4  4.9  1.8  3.2  0.  -1.5  2.6  5.1  0.7  2.  -0.   2.7  2.  -0.3  0.9  1.6  0.4  0.1 -0.9  1.1 -0.7  2.6  0.   0.4  4.  -0.3  1.  -0.4 -0.9  6.6 -0.2 -0.8 -0.2  1.2 -0.3 -0.7 -0.3 -0.4  1.4 -0.1  6.5 -0.8 -0.2 -0.  -0.7  1.8 -0.  -1.  -0.7 -0.1 -0.9 -0.2 -0.2 -0.1  0.9  4.4 -0.9 -0.   4.  -0.4 -0.5  0.5 -0.2  5.3 -0.5  0.2 -0.   1.6 -0.8 -0.6 -0.3  3.   4.9 -0.5  3.4 -1.5 -0.9 -0.7  6.5  4.3 -0.4 -0.8 -0.7  0.2  1.4 -0.2 -0.   1.5 -1.1  3.8 -0.5 -1.   6.2  2.3 -0.1 -0.2  4.3  3.2 -0.8 -0.3 -0.5 -0.2 -0.4 -0.2  4.   0.5  0.1 -0.9 -0.1  0.5 -1.2 -1.  -0.4  4.   4.5  1.6  0.2 -1.1  1.3 -1.5 -0.8  2.6  2.6  2.1 -1.3 -0.5 -0.3 -0.2  1.  -0.9  3.4  1.   1.7  7.7 -0.6 -0.3 -0.9 -1.1  2.4 -0.9 -0.1 -1.5 -0.8  3.  -0.9  2.9 -0.6 -1.2  0.7  0.3  4.3  1.7 -1.2 -1.1 -0.5  0.4 -0.7  0.3 -1.7 -0.2  4.  -0.3  0.2 -0.1  0.2 -0.8 -0.1 -0.1  3.3 -0.  -0.4  3.   0.   5.7 -0.3 -1.  -1.3 -0.9  2.   1.4  3.1 -0.3  1.9 -0.6 -0.7 -0.4  2.3 -1.2  0.2 -0.6  0.1  1.5 -0.6  1.1 -0.8 -0.9  2.6  2.3  3.4  5.6]
vy_50sample [[5 0 0 6 8 2 1 3 4 7]
 [6 1 2 4 0 5 9 7 8 3]
 [2 2 0 9 8 8 4 6 5 7]
 [8 9 5 2 2 4 4 1 3 3]
 [7 2 8 8 9 9 5 4 4 1]
 [6 1 4 9 9 2 8 3 5 7]
 [3 1 1 4 0 8 2 7 9 5]
 [1 1 7 5 0 8 3 3 2 4]
 [5 1 6 6 9 7 3 0 2 4]
 [1 7 3 5 2 6 8 0 4 9]]
vt_50sample [[5 9 0 6 8 2 1 7 3 4]
 [6 1 2 0 4 5 9 7 8 3]
 [3 2 0 9 1 8 4 6 5 7]
 [8 9 5 7 2 4 6 1 0 3]
 [7 2 8 0 9 3 5 6 4 1]
 [6 0 1 4 9 2 8 3 5 7]
 [3 1 6 4 8 0 2 7 9 5]
 [1 9 7 5 0 8 6 3 2 4]
 [5 1 6 8 9 7 3 0 2 4]
 [1 7 3 5 2 6 8 4 0 9]]
Epoch  1410: Training cost= 0.7077, Training acc= 0.5770, Validation cost= 0.6535, Validation acc= 0.5780
Epoch  1420: Training cost= 0.7282, Training acc= 0.5779, Validation cost= 0.7005, Validation acc= 0.5788
Epoch  1430: Training cost= 0.6770, Training acc= 0.5788, Validation cost= 0.6391, Validation acc= 0.5797
Epoch  1440: Training cost= 0.7032, Training acc= 0.5796, Validation cost= 0.6611, Validation acc= 0.5806
Epoch  1450: Training cost= 0.6646, Training acc= 0.5805, Validation cost= 0.6896, Validation acc= 0.5814
Epoch  1460: Training cost= 0.7211, Training acc= 0.5814, Validation cost= 0.6673, Validation acc= 0.5823
Epoch  1470: Training cost= 0.7047, Training acc= 0.5821, Validation cost= 0.6789, Validation acc= 0.5831
Epoch  1480: Training cost= 0.7291, Training acc= 0.5829, Validation cost= 0.6942, Validation acc= 0.5838
Epoch  1490: Training cost= 0.6515, Training acc= 0.5838, Validation cost= 0.6358, Validation acc= 0.5847
Epoch  1500: Training cost= 0.6383, Training acc= 0.5846, Validation cost= 0.6683, Validation acc= 0.5855
tm  [-1.  -1.5  2.7  6.9 -1.2 -1.  -0.1 -0.9  4.4 -1.4  3.8  1.8 -0.3  1.1 -0.4 -0.1 -0.6 -0.8  2.3 -0.9  0.1 -0.4 -1.1 -0.9 -0.7  2.9 -0.5 -0.1  0.1 -0.7  5.4  0.4 -0.5  7.8 -1.5 -0.5 -0.5  3.8  7.6 -1.4 -1.  -1.1 -0.3  2.  -1.4 -0.9  3.9  3.7  0.7 -2.  -1.7 -0.6  4.4 -1.4 -0.8  2.4 -0.1  2.8 -0.2 -1.2 -0.1 -0.2 -0.3  2.7 -0.7  1.9 -1.5  3.3  1.6  4.6  0.1 -0.3 -1.3  0.9  3.3 -0.2 -0.2 -1.4  2.8 -0.2 14.  -0.9 -0.8 -0.6  1.   0.2  0.3 -0.9  3.9 -0.1 -0.9 -0.6  2.7 -0.8  1.8  0.9  2.7  0.3 -0.6 -0.4  6.3 -0.3  1.5  0.7 -0.6 -0.3  0.1  4.6  0.8 -1.   3.1 -0.6 -0.8 -0.1  2.   2.4 -0.3  3.7 -0.9  0.  -0.1  4.  -0.4  3.3 -0.3 -0.4  6.6  6.2  2.3  2.8 -0.3 -1.9  0.4 -0.6 -1.5  6.2  1.3  3.6  0.7 -1.6  2.8  2.8  0.8 -0.4 -0.9 -0.4 -0.6 -1.   0.9 -0.4 -0.6 -0.6 -0.9  2.2 -1.5 -0.6 -0.3 -0.8  3.8  0.5 -0.7 -0.7 -0.4 -0.5  2.9 -0.5  2.8  5.4 -0.4  4.4 -1.5  0.4 -1.1 -0.7 -0.1  1.9  0.3  0.8 -1.4 -0.   0.3 -0.2 -1.3 -0.6 -0.6 -1.7  1.3 -0.3  0.8  4.8 -0.6  0.6 -1.1 -1.1  2.  -0.7  3.8 -0.6 -1.1 -1.2 -0.9 -0.  -0.8 -1.1  0.5  1.2  3.1 -0.4 -1.7 -1.  -0.7  2.7 -1.   4.5 -0.7  0.  -0.2 -0.2  0.7  0.8 -0.2  3.1 -0.1 -0.2 -0.5 -0.3 -0.5  0.5  0.2  0.9 -0.9  1.5 -1.1 -0.9  2.  -0.1 -0.1  2.6  2.9  6.3 -0.   4.  -1.3 -1.8 -2.2 -0.7 -1.  -0.9 -0.3 -1.2 -1.7 -1.3  7.9 -0.2  6.6  2. ]
ty_50sample [[3 9 7 7 5 4 6 0 2 8]
 [5 4 7 6 3 0 0 8 1 1]
 [4 6 0 5 2 7 9 9 3 8]
 [2 3 9 9 5 8 7 4 4 6]
 [9 6 5 4 2 2 3 8 8 7]
 [5 1 7 7 9 4 6 8 3 3]
 [0 0 6 6 5 7 1 2 8 9]
 [3 1 6 2 2 5 4 7 0 9]
 [5 2 1 3 7 6 8 0 9 9]
 [9 9 3 3 6 6 8 0 2 7]]
tt_50sample [[3 9 1 7 5 4 6 0 2 8]
 [5 4 7 6 3 0 9 2 8 1]
 [4 6 5 0 2 7 1 9 3 8]
 [2 3 9 1 8 5 7 4 0 6]
 [9 6 5 4 1 2 3 8 7 0]
 [5 1 7 9 0 4 6 2 8 3]
 [4 0 6 3 5 7 2 1 8 9]
 [3 1 6 8 2 5 4 7 0 9]
 [5 2 1 3 7 6 8 0 9 4]
 [9 1 4 3 5 6 8 0 2 7]]
vm  [-1.  -1.1  1.  -2.2 -1.5 -0.1 -0.4 -1.9  1.1 -0.2  0.9  1.2 -0.8 -1.   9.1  0.6 -0.6  0.1 -0.2  4.4 -0.1 -0.3 -0.2 -0.5 -1.   0.3 -0.1 -0.   2.4 -0.7  7.1 -0.3  0.3  7.7 -0.6 -0.9 -0.9  0.7 -1.4 -0.9 -0.5 -0.1  0.4  3.2 -1.4  1.1 -2.2  1.3 -0.6 -0.3 -1.7 -1.4 -0.5  2.5 -1.  -1.3 -0.1  1.9  1.6 -1.5  5.3 -0.2  0.7  4.5 -0.3  1.1 -0.6  1.3  0.7  0.9  1.2 -1.  -0.6  0.3 -2.8 -0.2 -0.3 -0.2  8.2 -0.3 -0.2 -0.8  5.6 -0.3 -0.   4.2  2.  -0.8  0.8 -0.1 -0.4 -0.9 -0.7 -1.6 -1.3  1.6  0.1 -1.7 -0.2 -1.1  2.1  4.3  2.4  0.6 -0.5 -0.5 -2.6  7.3  0.   5.9 -0.1 -1.1 -0.3 -0.6  1.6  2.5  2.   3.3 -1.  -0.4 -0.4 -1.5  2.   3.  -1.2  9.7  2.2  1.   3.5  2.4  2.8 -1.9  1.   0.2 -0.7  9.2 -0.2  3.4 -0.4 -1.6  2.2  3.4  3.5  2.  -1.1 -0.3 -0.1 -0.5 -0.2  0.4  6.2  0.3 -1.2  1.8 -0.7 -0.8 -1.5 -0.5  0.5 -0.4  1.1  1.9  2.6 -0.7  3.1 -0.4  0.   4.1  0.4 -0.9 -0.2  3.4 -0.8 -1.3 -0.8  2.7 -1.3 -0.7  8.2  6.1 -0.   1.1 -0.6 -1.   1.5 -1.4 -0.5 -0.5 -0.9 -0.3 -0.4 -0.1  1.3 -1.3 -1.2 -0.1 -1.6 -0.4 -1.  -0.8  0.3  4.3 -0.6 -0.8  2.5 -2.2  2.9 -1.  -1.2 -0.7 -0.3  1.8 -1.3  8.1  0.5 -0.4  0.1  0.1  1.6  1.1 -1.3  5.5 -0.5  0.8  2.   0.7 -0.3 -0.1  0.8  2.1 -0.3  2.3 -0.7 -0.6  1.4  2.   0.5 -1.8  3.5 -1.6 -0.8 -1.   0.4 -0.9  2.9  1.  -1.  -0.  -0.1 -0.2 -0.2 -0.1 -1.5 -0.7  4.7  0. ]
vy_50sample [[4 7 1 6 3 3 8 8 2 9]
 [6 6 0 7 2 8 4 3 5 9]
 [7 0 9 4 6 8 8 8 5 1]
 [6 4 9 9 3 7 8 8 2 1]
 [0 3 9 9 6 5 4 2 7 8]
 [5 9 9 2 2 3 6 8 4 0]
 [8 9 7 1 4 4 3 6 2 2]
 [1 8 3 3 7 6 0 5 4 9]
 [6 7 5 3 2 8 8 4 1 9]
 [2 3 0 0 8 5 7 9 6 6]]
vt_50sample [[4 7 1 6 5 3 8 2 0 9]
 [6 1 0 7 2 8 4 3 5 9]
 [7 9 0 4 6 3 8 5 2 1]
 [6 4 9 5 3 7 8 0 2 1]
 [0 3 9 6 1 5 4 2 7 8]
 [5 9 7 2 1 3 6 8 4 0]
 [8 9 1 7 4 5 3 6 2 0]
 [1 8 2 3 7 6 0 5 4 9]
 [6 7 5 3 0 2 8 4 1 9]
 [2 3 0 1 8 5 4 7 9 6]]
Epoch  1510: Training cost= 0.6545, Training acc= 0.5855, Validation cost= 0.6807, Validation acc= 0.5863
Epoch  1520: Training cost= 0.6580, Training acc= 0.5862, Validation cost= 0.6989, Validation acc= 0.5870
Epoch  1530: Training cost= 0.6595, Training acc= 0.5870, Validation cost= 0.6868, Validation acc= 0.5878
Epoch  1540: Training cost= 0.6634, Training acc= 0.5877, Validation cost= 0.6448, Validation acc= 0.5886
Epoch  1550: Training cost= 0.7233, Training acc= 0.5885, Validation cost= 0.6582, Validation acc= 0.5893
Epoch  1560: Training cost= 0.7475, Training acc= 0.5892, Validation cost= 0.6907, Validation acc= 0.5900
Epoch  1570: Training cost= 0.6007, Training acc= 0.5899, Validation cost= 0.7565, Validation acc= 0.5907
Epoch  1580: Training cost= 0.6334, Training acc= 0.5907, Validation cost= 0.6999, Validation acc= 0.5914
Epoch  1590: Training cost= 0.7054, Training acc= 0.5914, Validation cost= 0.7218, Validation acc= 0.5922
Epoch  1600: Training cost= 0.6646, Training acc= 0.5921, Validation cost= 0.7222, Validation acc= 0.5928
tm  [ 3.8 -0.2  4.3  4.6 -1.5 -1.7 -0.5 -1.2 -0.9 -0.7 -0.3 -0.  -0.5 -1.4  1.6 -0.1 -0.6  0.8  2.4 -1.  -0.1  1.3  1.8  0.7 -0.7  0.7 -0.5 -0.5 -0.  -0.4  1.9  2.3  1.9  5.7  3.3  1.6  2.  -1.2  2.  -1.1 -1.2  0.1 -0.4  0.9 -1.   0.3  3.1  4.7  5.3  2.  -1.2 -0.6  0.5 -0.8 -0.   0.3 -0.7 -0.  -0.6  0.4 -1.4  2.1 -0.5  0.7 -0.1 -0.7 -0.6 -0.2  3.1  2.3 -0.2  1.4  0.9 -0.9  3.  -0.2 -0.2  0.4  2.6 -0.3  5.8 -0.1  0.4  0.2 -1.  -0.6  2.5 -0.8  1.  -0.1 -0.3 -0.6  1.1 -0.3  1.3  0.4  3.1 -0.1 -0.5 -0.1  1.8  4.7 -1.1  0.6  2.6  0.4  1.1  2.5 -0.2 -0.8  0.5  0.6 -0.7  1.5 -0.3 -0.6  0.1  2.3 -0.5  1.1 -0.4  3.2 -0.3 -0.2 -0.5  2.1  1.6  5.3 -1.  -0.4  6.9 -0.8  1.8 -0.7 -0.6  6.  -0.5  0.5 -0.7 -0.9  2.6 -0.8  3.9  3.5 -0.9  3.1 -1.2 -1.3 -1.2  2.2 -0.4  0.6  3.9  0.5 -0.9 -0.7 -0.9 -0.6 -1.  -0.6  1.2  1.3  1.4 -1.2  1.6 -0.7 -0.4  1.5 -0.1  1.6 -0.2 -0.5 -0.3 -0.2  0.3  6.6 -0.4  3.1  0.3  3.3  2.4 -0.2 -0.  -1.2 -0.7 -1.1  5.  -1.   1.3 -0.2 -0.2 -0.5 -0.4 -1.3  6.3 -0.4  3.2 -0.2 -0.3  0.6 -0.8 -0.1 -0.2 -0.3 -0.2  0.1 -0.6  1.2  4.7 -0.4 -0.3  0.  -1.5 -0.4 -0.7 -0.3  2.7 -0.1  2.7  0.9 -0.8 -0.5  0.3 -0.9  1.8  0.7 -0.6 -0.8 -0.2  3.6 -0.2 -0.4 -1.3  2.3  1.3 -0.7  4.7  2.4  4.   9.4 -1.3  5.5 -0.2 -0.4 -0.6 -0.3 -0.3  0.2 -0.1  0.5 -0.8 -0.6  3.6 -0.4 -0.1  3. ]
ty_50sample [[7 9 6 0 4 8 3 2 5 1]
 [6 3 2 2 4 0 7 9 1 1]
 [6 2 2 5 9 4 3 7 1 1]
 [0 1 7 2 4 9 6 5 8 3]
 [4 7 7 1 1 6 2 5 0 0]
 [1 5 0 0 2 2 3 6 8 8]
 [1 8 2 2 7 6 3 0 5 9]
 [9 6 6 4 4 5 8 3 1 0]
 [8 7 4 5 5 2 3 0 6 1]
 [2 5 5 0 8 1 1 3 4 9]]
tt_50sample [[7 9 6 0 4 8 3 2 5 1]
 [6 3 2 8 4 0 7 9 5 1]
 [6 0 2 5 9 4 3 7 1 8]
 [0 1 7 2 4 9 6 5 3 8]
 [4 9 7 1 6 2 3 8 5 0]
 [1 5 0 7 2 9 4 3 6 8]
 [1 8 4 2 7 6 3 0 5 9]
 [6 9 2 7 4 5 8 3 1 0]
 [8 7 4 5 9 2 3 0 6 1]
 [2 5 0 7 8 1 6 3 4 9]]
vm  [-1.1 -0.8 -0.7 -0.6 -0.2  1.4 -1.2 -1.   3.7  0.4  3.  -0.4  1.9 -0.5  0.9  5.3 -1.2 -0.6 -1.3  3.9 -0.5  1.2  2.9 -0.5 -0.9  1.3 -0.4 -0.1  4.2 -1.6  2.4 -1.1  1.9 -1.2  2.2 -0.9 -0.8  3.  -1.5 -1.  -0.2  1.3 -0.8 -0.2 -0.4  2.1 -1.5 -1.3 -0.7  2.1 -0.2 -1.4 -0.4  5.  -1.2  2.6  0.8  2.5  5.5  0.5  4.8 -0.6  1.9  4.9  1.3  0.3 -0.9  4.  -0.2 -0.7  1.  -1.1  1.6  1.3 -3.1 -0.4 -0.7 -0.   4.5  1.2 -0.9 -0.7  4.3 -0.8 -0.1  2.6 -0.5 -0.4 -0.6 -0.1 -0.5 -1.4 -0.8 -1.5 -0.5 -0.4 -0.3 -1.9 -0.7 -0.2 -0.8 -0.3  2.9  1.  -0.8 -0.  -1.9  1.6  1.3  3.4 -0.6  1.6 -0.2 -0.8  1.7  1.6  2.  -0.1 -0.7  2.5 -0.7 -1.4  3.5  0.3 -1.   0.8 -0.8 -0.8  5.9  1.8  4.8 -1.5 -0.3 -0.7  9.8  6.2 -0.4 -0.  -0.  -0.5 -0.3  1.4 -0.3 -0.1 -1.   1.6 -0.1  3.8  3.   1.6  4.2  1.7  1.5 -0.1 -0.2 -0.4 -0.9 -0.4 -0.8  0.7  4.1  1.6  1.2 -0.7 -0.5 -0.5  3.1  2.8 -0.4  1.   3.   1.3  0.6 -1.1 -0.3 -0.7 -1.9 -0.2 10.4  2.6 -0.4 -0.1 -0.6 -0.8  2.5 -0.7 -0.7  0.2 -0.9  3.9 -0.5  0.4 -0.1 -1.1 -0.6 -0.4 -1.2 -1.4 -1.2  0.4 -0.4  7.1 -0.6 -1.5  0.9 -1.8  0.4 -0.1  2.5 -1.1 -0.1  3.2 -1.6  6.5 -0.4 -0.1  4.9 -0.5 -0.4 -0.5 -0.4 -0.4 -1.3 -0.1  5.2  3.   1.   6.9  0.1  3.4  0.1 -0.9 -0.8  1.5 -0.1  5.7  2.5 -2.   3.  -0.4 -1.2 -0.4  1.7 -0.5  7.  -0.2 -0.4  2.9 -0.8 -0.7 -0.1 -0.  -1.9  2.   0.9  1.8]
vy_50sample [[6 2 1 8 5 5 3 9 0 7]
 [3 3 4 0 9 8 8 1 2 2]
 [2 3 5 5 6 1 1 4 9 7]
 [5 2 8 7 4 1 9 9 0 3]
 [0 2 1 1 7 7 4 5 3 3]
 [8 3 9 9 7 1 1 5 6 4]
 [2 1 1 7 4 0 0 0 6 5]
 [6 8 1 5 7 2 9 3 4 0]
 [1 7 5 9 8 0 4 2 3 6]
 [0 2 5 8 3 1 1 7 9 6]]
vt_50sample [[6 2 1 8 4 5 3 9 7 0]
 [6 3 4 0 9 7 8 5 1 2]
 [2 3 5 6 8 1 0 4 9 7]
 [5 8 2 7 4 1 9 6 0 3]
 [6 0 2 1 7 4 8 5 9 3]
 [8 3 9 2 7 0 1 5 6 4]
 [2 1 9 7 4 3 0 8 5 6]
 [6 8 1 5 7 9 2 3 0 4]
 [7 1 9 5 8 0 2 4 3 6]
 [0 2 5 8 3 4 1 7 9 6]]
Epoch  1610: Training cost= 0.6234, Training acc= 0.5927, Validation cost= 0.6568, Validation acc= 0.5935
Epoch  1620: Training cost= 0.6184, Training acc= 0.5935, Validation cost= 0.7000, Validation acc= 0.5942
Epoch  1630: Training cost= 0.6435, Training acc= 0.5942, Validation cost= 0.6179, Validation acc= 0.5950
Epoch  1640: Training cost= 0.6337, Training acc= 0.5950, Validation cost= 0.6259, Validation acc= 0.5957
Epoch  1650: Training cost= 0.6206, Training acc= 0.5958, Validation cost= 0.6813, Validation acc= 0.5964
Epoch  1660: Training cost= 0.6595, Training acc= 0.5965, Validation cost= 0.6145, Validation acc= 0.5972
Epoch  1670: Training cost= 0.7827, Training acc= 0.5972, Validation cost= 0.7270, Validation acc= 0.5978
Epoch  1680: Training cost= 0.6459, Training acc= 0.5979, Validation cost= 0.6102, Validation acc= 0.5985
Epoch  1690: Training cost= 0.6357, Training acc= 0.5986, Validation cost= 0.6653, Validation acc= 0.5992
Epoch  1700: Training cost= 0.7368, Training acc= 0.5992, Validation cost= 0.6884, Validation acc= 0.5998
tm  [ 2.3  0.5 -0.2 -0.1 -0.8 -0.9 -1.2 -0.9  1.2 -0.8  0.8  0.3 -0.4 -0.4  1.1  1.5 -0.2 -0.1 -0.8  2.4 -0.8 -0.3  0.3 -0.3 -0.3  0.5 -0.9 -0.5 -0.4 -1.6 -0.2 -0.8 -1.1 -1.5  3.9 -0.6  1.6  4.2  2.2 -1.9 -0.8 -0.7 -0.6  4.2 -0.9  5.  -1.3 -0.3  3.8 -0.1 -0.5 -1.5 -0.2  4.  -0.7  1.6 -0.4  3.3  5.4  3.6  1.8 -0.4  0.7  6.2 -0.9 -0.7 -0.7  2.6  0.1  3.3  0.9  2.7 -0.  -0.4 -2.5 -0.1 -0.4 -1.6  0.   1.8 -1.9 -0.7  1.8 -0.4 -1.2 -1.3  1.  -0.6  3.2 -0.3 -0.6 -1.8  0.5  4.1 -0.2  0.1  0.3 -0.9 -0.8  0.5  0.9 -1.3  1.2 -0.4  1.6 -0.5 -1.2 -0.3  1.2  1.3  0.4  1.3 -0.7 -0.9  4.6 -0.9  1.6  4.1 -0.1  3.6 -0.8 -0.3 -1.  -0.8 -1.   0.8 -0.3 -0.5  4.2  6.2  0.4 -0.4  2.1 -0.6  0.5 -2.8 -0.4 -0.2  1.6 -0.2  0.5 -1.1 -0.6 -1.  -0.  -0.5 -1.4  1.3  1.4 -1.4  1.9  0.7  4.7 -0.2 -1.1 -1.1  0.2 -0.4  2.2 -0.5  0.4 -1.7 -0.5 -0.8 -0.8 -0.9  1.9  2.7 -0.3  0.2  0.2  0.5  1.6 -0.  -0.7 -0.1  0.7 -0.6  0.2 -0.  -0.  -0.7 -1.  -0.7  7.6 -0.4  1.5 -0.2  0.5  8.6 -0.3  1.4 -0.1 -1.5  1.5 -1.1 -1.4 -1.5 -0.7  3.  -0.1  3.8 -0.5 -1.8 -1.7 -1.7 -0.4 -0.1  4.6 -0.4 -0.7 -0.7 -1.5 -0.6  0.1  0.8 -0.6 -0.5 -1.1 -0.7 -0.2 -0.5 -0.4 -0.9 -0.6 -0.1  0.3  1.7 -0.7  8.8 -1.4  2.3 -0.8  3.6  6.1  4.5  2.  -1.5  2.6 -0.3 -0.3 -0.2 -0.3 -0.5  6.1 -0.1 -0.9 -0.3 -0.5 -0.6  2.3 -0.2  3.1 -0.7  1.1 -1.2]
ty_50sample [[3 0 8 2 4 5 9 7 6 6]
 [7 5 1 4 3 6 6 8 2 9]
 [5 3 0 4 2 9 6 8 1 1]
 [7 6 3 3 5 2 2 9 4 9]
 [9 1 2 6 6 7 0 5 3 8]
 [2 6 9 0 5 7 8 3 1 4]
 [7 3 9 1 4 8 2 6 5 0]
 [8 5 4 9 7 7 3 0 1 6]
 [0 7 3 4 8 5 9 2 6 1]
 [8 9 5 2 6 0 4 7 1 1]]
tt_50sample [[3 0 8 2 4 5 9 7 1 6]
 [7 5 1 4 3 0 6 8 2 9]
 [5 3 0 4 9 2 6 7 8 1]
 [7 6 8 3 5 2 1 9 4 0]
 [9 1 2 4 6 0 7 5 3 8]
 [2 6 9 5 0 7 8 1 3 4]
 [7 3 9 1 8 4 2 6 5 0]
 [8 4 5 9 7 2 3 0 1 6]
 [0 7 3 4 8 5 9 2 6 1]
 [8 9 5 2 6 0 4 7 1 3]]
vm  [ 3.4 -0.6  6.6  3.6 -1.8 -1.  -0.7 -1.4 -1.6  1.3  6.1 -0.2  1.  -0.6  5.6  3.2 -0.2  0.6  4.  -0.6 -0.2 -0.2  2.1  1.  -1.4  1.3 -0.3  0.3 -0.2 -0.6  0.3  1.4 -0.2  7.8  3.6  3.2  2.3 -0.3  0.8 -0.5 -1.1  4.6  0.8 -0.3 -1.1 -0.4 -0.6  0.5  3.7  3.7 -1.9 -0.4 -0.1  3.8  0.3 -0.7 -0.8  1.8 -0.3  2.3 -0.4  2.8 -0.6  5.9  0.9 -0.2  0.2 -0.5 -0.  -0.1 -0.2  2.9 -0.  -0.3 -0.3 -0.1 -0.3  1.8  2.4 -0.   4.2  0.3  2.5  0.1 -1.1  3.6  0.1 -0.9 -0.3 -0.2 -0.2 -0.4 -0.4 -0.6 -0.   0.8  4.6 -0.3 -0.2 -0.5  0.6  7.8 -0.3 -0.7  1.6  1.1 -0.7  1.   2.3  0.1 -0.2 -0.4 -0.2  1.3  0.2 -0.2 -0.1  0.7 -0.6 -0.3 -0.3  1.5  0.   1.7 -0.4  5.5 -0.4 -0.  -0.3 -0.4  3.9 -1.2 -0.6  0.1 -1.   6.1 -0.6 -0.2 -1.  -0.4 -0.1 -0.3 -0.2  2.4 -0.4  2.2 -0.5 -0.8 -0.8  2.6  0.2  0.4  1.8 -0.4 -0.5 -0.7 -0.6 -0.6 -0.1 -0.3  4.9  1.8  0.1 -1.   1.8 -0.9 -1.  -0.5 -0.2  0.9  1.5  0.  -0.1 -0.5 -0.5  5.9 -0.6  1.3  2.6  0.6  0.4 -0.2 -0.5 -1.5 -0.2 -1.4  3.8 -1.1 -0.   0.1 -0.4 -0.3 -0.1 -0.8  3.3 -0.4  0.6  0.6 -0.6  2.8 -0.7 -0.6 -0.7 -0.2  1.1 -0.8  0.7  2.7  0.7 -0.3 -0.1 -0.2 -1.2  0.6 -0.8 -0.6  3.3 -0.1  3.5  0.3 -0.9 -0.4 -0.2 -0.7  1.8 -0.2  1.   0.2  1.5  1.1 -0.2 -0.6 -0.5  0.3  2.6 -1.6  4.8  0.5  1.3  3.2 -1.3  2.   0.9 -0.7 -0.   0.2 -0.3  4.8 -0.4  1.4 -0.7  0.6  0.6  1.7 -0.3  3.6]
vy_50sample [[7 2 0 6 9 5 4 8 1 3]
 [4 9 6 6 3 3 5 8 2 2]
 [3 3 7 5 2 2 6 6 9 4]
 [8 8 3 6 6 0 0 9 2 2]
 [7 5 4 9 6 6 8 1 2 2]
 [2 1 9 7 0 5 8 4 6 3]
 [2 4 7 0 3 5 8 8 6 9]
 [8 1 7 2 5 3 0 0 6 9]
 [7 0 0 0 1 1 9 9 5 3]
 [4 8 6 3 2 0 0 9 1 9]]
vt_50sample [[7 2 0 6 9 5 8 4 1 3]
 [4 1 9 6 3 0 5 8 2 7]
 [3 7 8 0 5 2 6 1 9 4]
 [8 5 1 3 6 0 7 9 4 2]
 [7 5 9 4 6 0 8 3 1 2]
 [1 2 9 7 0 5 8 4 6 3]
 [2 4 7 3 0 5 1 8 6 9]
 [8 1 7 2 5 3 0 4 6 9]
 [7 6 0 8 1 2 9 4 5 3]
 [4 8 3 6 2 7 0 1 5 9]]
Epoch  1710: Training cost= 0.7418, Training acc= 0.5997, Validation cost= 0.6951, Validation acc= 0.6003
Epoch  1720: Training cost= 0.6711, Training acc= 0.6003, Validation cost= 0.6691, Validation acc= 0.6009
Epoch  1730: Training cost= 0.6953, Training acc= 0.6009, Validation cost= 0.6460, Validation acc= 0.6015
Epoch  1740: Training cost= 0.6239, Training acc= 0.6016, Validation cost= 0.6137, Validation acc= 0.6022
Epoch  1750: Training cost= 0.6026, Training acc= 0.6024, Validation cost= 0.6328, Validation acc= 0.6030
Epoch  1760: Training cost= 0.6887, Training acc= 0.6030, Validation cost= 0.6401, Validation acc= 0.6037
Epoch  1770: Training cost= 0.6381, Training acc= 0.6037, Validation cost= 0.6182, Validation acc= 0.6043
Epoch  1780: Training cost= 0.6570, Training acc= 0.6043, Validation cost= 0.6509, Validation acc= 0.6049
Epoch  1790: Training cost= 0.6438, Training acc= 0.6050, Validation cost= 0.6415, Validation acc= 0.6056
Epoch  1800: Training cost= 0.6551, Training acc= 0.6055, Validation cost= 0.6531, Validation acc= 0.6062
tm  [-0.9 -0.8 -1.3 -0.  -0.5  1.2 -1.3 -0.7  3.1 -1.   8.5 -0.5  3.1  1.5 -1.3  4.8 -0.2 -0.4 -1.  -0.8 -0.7 -0.8 -0.5 -0.5 -1.   2.6 -1.  -0.3  1.1 -1.3  4.3 -1.2 -0.3 -0.4  2.7  1.6 -0.1  8.1  7.  -1.1 -1.2 -0.7 -1.4  5.6 -1.3 -0.   0.4 -1.5 -0.3 -0.4 -0.7 -1.2  1.7  4.1 -1.   4.7 -0.8  0.5  4.8 -0.6  2.5 -0.1 -0.4  5.2  0.1  1.3 -0.5  7.3 -0.3  1.5 -0.6 -0.6 -1.   1.5 -1.  -0.4  1.4 -1.1  4.6  2.5  6.7 -0.4 -0.4 -0.8  0.9 -0.4 -0.2 -0.3  0.7 -1.  -0.7 -1.2 -0.3 -0.4  0.7 -0.  -0.7 -0.3 -1.  -0.3  2.6 -1.1  3.5 -0.3 -0.6 -0.2 -0.3  4.9  4.  -0.6 -0.6  1.3 -0.4 -0.2  4.6 -0.  -0.2  1.4 -1.1  0.9 -0.6  1.5 -0.3  2.  -0.4 -1.3 -0.2 -0.4  5.2  1.6 -1.  -1.  -0.4 -0.2  1.4 -0.3 -0.7  0.2  1.8 -0.9 -0.4  1.2 -1.3 -1.  -0.3 -0.2 -0.6  4.   2.8 -0.8  2.3 -0.4 -0.2 -0.7 -0.8 -0.5  0.7 -0.8  3.5 -0.2  3.2 -1.4 -1.  -0.5 -0.6 -0.7  3.3  2.7 -0.3  1.3 -0.  -0.4 -0.2  0.5 -0.8 -0.3  1.5  0.2 -1.2 -0.9  0.4 -0.1 -1.1 -0.6  3.1 -1.2  0.3  0.7  0.5  6.6 -0.4  1.4 -0.7 -0.5  0.2 -0.5 -0.1 -0.5 -1.   2.5 -0.7  2.6 -1.9 -1.6 -0.2 -0.6  0.9  0.1  0.7 -0.7 -0.9  0.8 -0.9  6.8  2.4 -0.6 -0.8 -0.9 -1.  -0.7  3.  -0.6 -0.7 -0.8  0.1 -0.   4.3  5.7  0.   2.  -1.3 -0.2 -0.5  1.2  5.3  7.   2.6 -0.3  2.5  5.4 -0.7  3.8 -1.1 -1.4 -0.2 -0.9 -0.6  1.7 -0.6 -1.1 -1.   3.3  5.2  1.5  0.2 -0. ]
ty_50sample [[2 1 4 3 9 0 5 8 6 7]
 [7 7 1 1 8 8 2 0 0 0]
 [6 2 0 0 7 3 1 8 9 4]
 [1 8 3 3 4 4 0 6 7 7]
 [5 4 0 8 2 9 1 6 3 7]
 [3 5 5 8 8 8 6 4 0 0]
 [7 5 3 4 4 8 2 2 6 0]
 [0 2 2 7 8 5 9 6 6 4]
 [9 9 1 1 4 0 7 2 3 3]
 [4 9 3 7 6 1 5 8 2 2]]
tt_50sample [[2 1 4 3 9 0 8 5 6 7]
 [7 4 1 3 8 2 5 9 0 6]
 [6 5 2 0 7 3 1 8 9 4]
 [1 8 5 3 4 0 2 6 9 7]
 [5 4 0 8 9 2 1 6 3 7]
 [3 7 5 8 2 9 1 6 4 0]
 [7 5 3 4 9 8 1 2 6 0]
 [0 3 2 7 5 8 9 1 6 4]
 [9 6 5 1 4 0 7 2 8 3]
 [4 9 3 7 6 1 5 8 2 0]]
vm  [ 3.1  4.9  2.8  5.2 -1.1 -1.6 -0.9 -0.9 -0.7 -1.5 -0.3 -0.  -0.5 -0.   0.3  5.5  3.9 -0.2  2.  -0.1 -0.1 -0.1  3.7 -0.1 -1.5  1.  -0.2 -0.2  1.1 -0.4 -0.5 -1.2 -0.5 -1.1 -0.1  1.7  2.   3.   3.9 -1.9 -0.5 -0.4  2.1  1.7 -0.7  2.6 -0.7  0.4  3.7  2.1 -0.6 -0.8  1.6  1.1 -0.5  2.  -0.   4.9 -0.   5.4 -1.  -0.1  0.3  2.7 -0.5 -0.2 -0.7 -0.9  0.3  3.4  1.7  1.5  3.  -0.1  3.1  0.8 -0.5 -0.5 -0.8  1.2 -0.6 -0.6  0.8 -0.2 -1.3  0.2  1.5 -0.5  5.4  1.2 -0.6 -0.6  2.3  2.8  1.7  0.4  5.2  0.3 -0.7  0.3  3.4 -0.2 -0.6 -0.3  2.   1.3 -0.1 -1.  -0.  -0.5 -0.   0.7 -1.   1.2 -1.3  2.3  1.2 -0.1  0.6  0.2 -0.8  0.9 -0.8 -1.  -0.3  0.3  1.1  0.4  2.6  3.3  2.7 -0.2  2.6 -0.4 -0.5 -2.5 -0.1 -0.5  0.6  0.6 -0.  -1.5 -0.3 -0.1 -0.2  4.3 -1.4 -0.7  1.8  2.6 -0.3 -0.   7.6 -0.4 -1.2 -0.9 -0.5 -0.1  1.3 -0.7  0.2 -1.  -0.4 -0.5 -1.2 -0.3  2.  -0.3  1.   3.8  1.1  0.9 -0.6 -0.4 -0.6  0.2  0.3 -0.1 -0.5 -0.7  0.9 -0.1 -0.9 -1.   2.1  0.3  3.6 -0.1 -0.4  4.  -0.4 -0.2 -0.4 -1.7  4.  -0.5  2.4 -0.6 -0.2  0.3 -0.2 -0.  -0.4 -1.9 -1.4 -0.3 -0.4  3.7  4.4 -0.8 -0.5  1.9 -1.5 -0.9 -0.4 -0.3 -0.1 -0.1  1.4 -0.3 -1.1 -0.2 -0.5 -0.6  0.2  4.2  0.5  0.5 -0.9  6.4 -0.8 -0.6 -1.   4.   2.7  1.   0.8  1.9  0.8  3.4 -0.6  1.1 -0.3 -0.   4.1 -0.1 -0.4  1.8  0.8 -1.  -0.  -0.5  5.1  0.8  1.1  0. ]
vy_50sample [[8 3 3 2 5 7 6 0 0 1]
 [2 4 9 9 0 0 8 8 7 6]
 [4 0 0 8 8 3 5 7 7 1]
 [0 2 2 6 4 1 5 7 8 9]
 [6 6 7 4 0 0 8 2 3 1]
 [4 5 0 7 9 2 6 6 3 3]
 [6 3 4 7 2 1 8 0 0 0]
 [6 6 0 9 3 8 8 4 4 5]
 [1 1 4 3 5 2 9 6 6 8]
 [9 2 2 0 8 3 6 1 5 7]]
vt_50sample [[8 3 2 9 5 7 4 6 0 1]
 [2 4 9 0 3 5 8 7 1 6]
 [4 2 0 6 8 3 5 9 7 1]
 [0 2 3 6 1 4 5 7 8 9]
 [6 5 7 4 9 0 8 2 3 1]
 [4 5 0 7 9 2 6 8 3 1]
 [6 3 4 2 7 1 8 0 9 5]
 [6 1 0 9 2 3 8 4 5 7]
 [1 7 4 3 5 2 9 6 8 0]
 [9 2 4 0 8 3 6 1 5 7]]
Epoch  1810: Training cost= 0.5974, Training acc= 0.6062, Validation cost= 0.6617, Validation acc= 0.6068
Epoch  1820: Training cost= 0.6418, Training acc= 0.6068, Validation cost= 0.6963, Validation acc= 0.6074
Epoch  1830: Training cost= 0.6052, Training acc= 0.6074, Validation cost= 0.6818, Validation acc= 0.6080
Epoch  1840: Training cost= 0.6622, Training acc= 0.6080, Validation cost= 0.6365, Validation acc= 0.6085
Epoch  1850: Training cost= 0.6121, Training acc= 0.6085, Validation cost= 0.6572, Validation acc= 0.6091
Epoch  1860: Training cost= 0.6685, Training acc= 0.6091, Validation cost= 0.6384, Validation acc= 0.6097
Epoch  1870: Training cost= 0.6075, Training acc= 0.6097, Validation cost= 0.6219, Validation acc= 0.6103
Epoch  1880: Training cost= 0.5815, Training acc= 0.6103, Validation cost= 0.6540, Validation acc= 0.6109
Epoch  1890: Training cost= 0.6423, Training acc= 0.6109, Validation cost= 0.5914, Validation acc= 0.6115
Epoch  1900: Training cost= 0.6179, Training acc= 0.6116, Validation cost= 0.7214, Validation acc= 0.6121
tm  [-1.2 -1.  -1.7 -0.  -0.3  0.9 -0.5 -0.8  3.9 -0.2  0.6  0.1 -0.2 -0.  -1.6 -0.6 -1.  -0.2 -1.4 -0.7 -0.5 -0.5  2.5 -0.5 -0.1  3.4 -0.3 -0.2  1.3 -1.2  5.6  0.3  0.4 -1.   1.3 -0.8 -0.6  1.5  2.5 -1.4 -0.9 -0.5 -1.   3.  -1.1  0.8  1.2 -0.1 -0.7  0.7 -0.4 -1.2  0.6 -0.5 -1.1  5.8  0.3 -0.6  3.7 -0.9  3.7 -0.1  1.   1.4  1.2  1.3 -0.4  5.1  2.4  2.8 -0.7 -0.5 -0.4  1.9 -1.2 -0.6  1.9 -0.6  7.9 -0.5  5.8 -0.5 -0.2 -0.6  1.1 -0.2  0.3 -0.3 -0.2 -0.4 -0.3 -1.4 -0.6 -1.4  0.4 -0.3 -0.7 -0.7 -0.9 -0.4 -0.4 -0.7  3.6  3.  -0.7 -0.3 -0.3  6.3  0.2 -0.3 -0.5  3.3 -0.4 -0.3  6.  -0.3 -0.5  1.6 -1.2  2.2 -0.5 -0.4  0.4  1.  -0.5 -1.6  1.1  4.2  3.2  1.   1.9 -1.7 -0.3 -0.8  8.1  5.9  0.3 -0.1  1.5 -1.1  2.5  1.6  0.8 -0.2 -1.   0.5 -0.3  2.6  2.  -0.1  1.3 -0.2 -0.2  1.7 -0.4 -0.  -0.1 -0.6 -0.3  0.5  2.9 -0.1  0.1 -0.7 -0.9 -0.4  0.9  5.1 -0.1  1.5  0.2 -0.4 -0.2 -0.4  0.6 -0.1 -0.6  3.7  1.4  2.3  1.3 -0.3 -0.3 -0.7  1.1 -0.9 -0.2  1.7  2.2  5.  -0.2  0.2 -1.2 -0.9  0.6 -0.2  0.2 -1.2 -1.   0.6 -0.9  4.7 -1.2 -1.3  2.3 -0.5 -0.2 -0.3  3.8 -0.9 -0.4  2.3 -1.3  7.2 -0.4 -0.4 -0.1 -0.6 -0.9 -0.1  1.3 -0.2 -1.  -0.7  3.4  0.5 -0.3  4.1 -0.2  0.7 -0.2 -0.7 -1.   2.9  3.1  9.   4.  -0.5  6.3  8.6 -0.5  4.9 -0.5 -1.2 -0.4 -1.2 -0.2  0.8 -1.1 -1.  -1.1  1.   2.1 -0.1  2.8  3.9]
ty_50sample [[1 4 9 6 0 3 8 2 5 7]
 [4 2 6 7 9 8 1 0 3 5]
 [2 0 1 1 6 3 3 5 9 4]
 [7 7 6 6 0 2 5 4 9 9]
 [2 9 5 3 7 1 1 0 8 4]
 [7 9 9 2 5 8 1 1 6 3]
 [9 3 5 4 7 0 1 6 6 8]
 [1 8 9 9 0 5 5 6 7 4]
 [5 4 8 9 6 2 7 1 3 0]
 [6 9 9 1 1 5 5 7 3 8]]
tt_50sample [[1 4 9 6 0 3 8 2 5 7]
 [4 2 6 7 9 8 1 0 3 5]
 [2 0 7 8 1 6 3 5 9 4]
 [7 1 6 3 0 2 5 9 4 8]
 [2 9 5 3 7 6 1 0 8 4]
 [7 0 9 2 8 5 4 1 6 3]
 [9 3 5 4 7 0 1 6 2 8]
 [1 8 0 9 3 5 2 7 6 4]
 [5 4 8 9 2 6 7 1 0 3]
 [6 9 4 0 1 2 5 7 3 8]]
vm  [-0.5 -0.9 -1.  -1.1 -1.2  0.7 -0.  -1.3 -0.7 -0.4  4.1 -0.1 -0.7  0.1  1.2 -0.3  1.4 -0.5 -0.  -0.6  0.6 -0.8  0.1  0.8 -1.4  3.   0.6  0.2 -0.4 -0.7  7.3 -0.1 -0.   4.7 -0.3  2.   0.5  2.   1.1 -1.  -0.7  4.3  3.6  3.7 -1.3 -0.5 -0.7  0.9 -0.2  1.6 -1.5 -1.3 -0.3  0.1 -0.6  1.  -0.3 -0.  -0.3 -1.5  3.1 -0.6  0.3  3.8 -0.3  2.5  0.4  1.7  0.4  2.1 -0.8  0.1 -0.9 -0.  -0.2 -0.   3.3 -0.   6.6 -0.3  6.4 -0.2  0.8 -0.2 -0.1  6.7  2.4 -0.4  1.8 -0.  -0.2 -0.3 -1.  -0.4 -0.3  1.9  2.7 -0.4 -0.  -1.   1.7  3.3  1.9 -0.5 -0.2 -0.  -1.2  7.8  1.4  1.6 -1.1  0.4 -0.3 -0.   3.3  0.5 -0.7  0.7 -0.9 -0.6  0.  -0.5  1.1  5.2 -0.6  1.8  1.9  2.8  2.2 -0.1 -0.1 -1.2 -0.4 -0.   2.4  7.9 -0.  -0.2 -0.3 -1.2  2.2  0.9  1.4  2.7 -0.8  0.2  1.1 -0.4  3.4  3.3  3.8 -0.4 -1.2  1.2 -0.6 -0.6 -0.5 -0.6  1.7 -0.2  4.   2.3 -0.8 -0.8 -0.4 -0.2 -0.5  0.3  2.3 -0.6  1.7  2.6 -0.8 -0.9 -1.1 -0.3 -0.1  0.5  2.1  1.5 -0.7  0.8 -0.1 -0.8 -0.1 -1.2 -0.1  0.8  0.1  0.7 -0.4 -0.7  0.3 -0.9 -0.3  2.2 -0.3  0.5 -0.6  0.1 -0.2  2.8 -1.1 -0.9  3.8 -0.8  2.8  1.1 -1.9 -0.5 -0.4  0.3 -0.6  6.7  1.3 -1.  -0.8 -0.2  0.4 -0.  -0.2  3.8 -0.7 -0.3  3.6 -0.2  0.2 -0.2 -0.  -0.1 -0.3  0.1 -0.5 -1.2  6.8  5.8  2.8 -0.3  3.1 -0.6 -0.8 -0.6 -0.4 -1.1 -0.5 -0.4 -0.4  2.1 -0.1 -0.2 -1.   1.4  0.1 -0.   3.5  3.4]
vy_50sample [[4 5 1 0 0 9 9 2 8 8]
 [9 9 6 3 7 8 4 1 2 5]
 [7 2 0 0 6 1 1 9 4 5]
 [0 0 9 2 8 8 6 6 3 5]
 [8 0 2 4 1 1 5 9 3 3]
 [2 1 3 0 9 9 4 8 8 5]
 [7 7 1 2 2 8 6 5 3 4]
 [3 2 7 7 0 8 9 6 1 4]
 [6 9 4 3 8 8 7 0 2 1]
 [6 2 4 8 1 3 9 9 5 7]]
vt_50sample [[4 5 1 0 6 7 9 2 8 3]
 [0 9 6 7 3 8 4 1 2 5]
 [7 2 0 3 8 6 1 9 4 5]
 [0 7 1 9 2 8 6 4 3 5]
 [0 8 2 4 1 6 5 7 9 3]
 [2 1 3 0 7 9 4 8 6 5]
 [7 0 9 1 2 8 6 5 3 4]
 [3 2 7 0 5 8 6 9 1 4]
 [6 9 4 3 8 7 5 0 2 1]
 [6 2 4 8 1 3 0 9 5 7]]
Epoch  1910: Training cost= 0.5884, Training acc= 0.6122, Validation cost= 0.6135, Validation acc= 0.6127
Epoch  1920: Training cost= 0.6776, Training acc= 0.6127, Validation cost= 0.6845, Validation acc= 0.6132
Epoch  1930: Training cost= 0.6686, Training acc= 0.6133, Validation cost= 0.6207, Validation acc= 0.6138
Epoch  1940: Training cost= 0.6670, Training acc= 0.6139, Validation cost= 0.6181, Validation acc= 0.6144
Epoch  1950: Training cost= 0.6188, Training acc= 0.6144, Validation cost= 0.6370, Validation acc= 0.6150
Epoch  1960: Training cost= 0.6518, Training acc= 0.6150, Validation cost= 0.6323, Validation acc= 0.6155
Epoch  1970: Training cost= 0.6502, Training acc= 0.6155, Validation cost= 0.6462, Validation acc= 0.6161
Epoch  1980: Training cost= 0.6581, Training acc= 0.6161, Validation cost= 0.6719, Validation acc= 0.6166
Epoch  1990: Training cost= 0.6798, Training acc= 0.6166, Validation cost= 0.6457, Validation acc= 0.6171
Epoch  2000: Training cost= 0.6437, Training acc= 0.6171, Validation cost= 0.6071, Validation acc= 0.6177
tm  [-1.4 -0.2  7.2 13.2 -1.1 -0.6 -0.2 -0.6  2.4  2.8 -0.8  1.2 -0.3 -0.  -0.3 -0.6 -1.6 -0.3  1.2 -1.3 -0.3 -0.1  4.  -0.9 -0.9  1.7 -0.4 -0.4  0.8 -0.9 -0.9  1.1 -0.5  2.2 -0.6 -1.2 -0.   0.7  6.2 -0.7 -0.8  2.  -0.7 -1.2 -1.2 -0.5  4.8  2.9 -0.5  3.9 -0.6  1.6  2.3 -1.4 -0.2  3.8  0.8  1.3 -0.1  4.8  1.1  0.6  0.2  1.3  0.6  0.3 -0.5 -0.7  2.3  1.9  0.7  0.7  1.9  2.5  2.1 -0.3  1.5 -0.6  3.8 -0.1  8.  -0.4 -0.7 -0.1  2.   3.3 -0.9 -1.6 -0.3  1.2 -0.1  0.1 -0.6 -1.4  2.4 -0.6  5.1 -0.3 -0.7 -0.2 -0.3  5.1  4.3  0.1 -0.6 -0.3  1.  -1.1 -0.9 -1.6  2.6  0.3 -0.6  1.3  3.1  0.6 -0.4 -0.4 -1.   2.7 -0.2  2.9 -0.1  0.6  0.9 -0.5  2.7  6.6 -0.  -0.9  1.  -1.6 -1.4 -0.3  0.   2.  -0.1 -0.6 -0.1 -0.1  1.   0.8  0.8 -0.2 -1.5  2.1 -0.7 -0.6 -0.2  1.5 -1.6 -0.9  0.3  2.1 -0.6  0.2 -0.3 -0.4  0.6 -0.2  0.2 -0.2  1.3 -0.2 -0.1 -0.2 -0.7  2.5 -1.1  7.5  0.2 -0.6 -0.6 -1.2  2.1  2.6 -0.5  5.  -0.9  1.5  0.2 -0.5  0.3 -1.  -0.7 -1.1  0.7 -0.   3.4  5.3 -1.1 -0.7 -1.6 -0.9  1.4 -0.5  3.9 -0.2 -1.1 -0.5 -1.8 -0.3 -0.9 -1.2  5.4  1.6 -0.   1.1  3.1 -1.2 -0.3  2.4 -0.4  6.6 -2.1 -0.1  6.  -0.4  1.7  1.5 -1.2 -0.7 -0.7 -0.2  3.1  1.  -0.7  4.7  1.3 -1.  -0.3 -0.8 -1.2  1.6  0.4 -1.8  3.   3.5  2.4  9.  -0.9  5.2 -0.  -1.3 -0.8 -1.1  0.7  2.2 -0.7 -0.6 -1.2 -1.2  6.5  1.8  4.2  7.8]
ty_50sample [[9 1 7 7 6 0 5 3 2 4]
 [7 0 4 5 8 1 3 2 9 9]
 [1 2 4 3 0 8 9 6 7 7]
 [1 7 2 2 3 4 8 5 6 6]
 [5 4 9 8 6 1 0 7 3 2]
 [6 5 4 8 3 3 1 2 0 0]
 [9 8 5 7 6 3 3 0 4 1]
 [4 7 3 3 0 8 8 1 5 5]
 [6 7 8 5 3 4 0 2 1 9]
 [7 2 2 1 5 6 0 8 4 9]]
tt_50sample [[9 1 7 8 6 5 0 3 2 4]
 [7 0 4 8 5 1 3 2 9 6]
 [1 2 4 3 0 8 9 6 7 5]
 [1 7 2 0 3 4 8 9 5 6]
 [5 4 9 8 6 1 0 7 3 2]
 [6 5 4 8 9 3 1 2 7 0]
 [9 8 5 7 2 6 3 4 0 1]
 [4 7 3 6 0 9 8 1 5 2]
 [6 7 8 5 3 4 0 2 1 9]
 [7 3 2 1 5 6 0 8 4 9]]
vm  [-1.7 -1.   7.7  2.9 -1.5 -0.3 -0.4 -1.4  2.9  3.6 -0.7  2.1 -0.5 -0.5  8.8 -0.7 -1.8 -0.4 -0.   1.1 -0.3  0.1  1.4 -1.  -0.5 -0.6 -0.3 -0.4  2.4 -1.2 -0.2 -0.  -0.1  6.5 -0.7 -1.6 -0.5  0.3 -1.  -0.7 -0.5  0.6 -0.8 -1.1 -1.4 -0.2 -1.1  3.  -0.9  0.5 -1.2 -0.6 -0.5  0.1 -0.9 -1.2 -0.2  2.4  1.4  2.2  5.6  0.4 -0.5  1.7  0.9  0.2 -0.9 -0.3  1.2  0.9  3.2 -0.2 -0.2 -0.1 -3.1 -0.4  0.  -0.9  5.7 -0.3 -0.2 -0.9  1.3  0.2  0.8  2.4 -0.8 -1.5  0.5  1.4 -0.5 -0.5 -1.  -1.8 -1.  -0.5  2.5 -1.4 -0.3 -0.6  0.   5.   6.1  1.3 -1.  -0.3 -2.2 -0.1 -0.6  0.4  4.  -1.  -0.4 -0.8  3.2  2.   2.   1.2 -1.1  1.  -0.4 -0.7  0.8  0.9 -0.5  8.6  2.9  1.7  1.3  2.1  1.  -1.9 -0.9  0.8 -0.7  8.  -0.4  2.2 -0.3 -1.   0.8  3.3  0.9 -0.4 -1.5 -0.6 -0.6 -0.8 -0.5 -0.2 -0.1 -0.3 -0.9  1.7 -0.5 -0.1 -0.7 -0.1 -0.2 -0.4 -0.4  1.4  3.9 -0.1  2.9 -0.1 -0.4  5.9 -1.2  2.2 -0.5  2.  -0.9 -1.2  0.9  3.7 -1.4 -0.4  7.   4.6 -0.2 -0.1 -0.1 -1.   0.9 -1.3 -0.8 -0.8 -0.2  4.9 -0.9 -0.6 -0.1 -1.  -1.3 -0.4 -1.6 -0.5 -1.4 -1.2 -0.6  1.5 -0.7 -0.7  4.3 -2.2  2.  -0.7 -0.  -0.7 -0.4  0.9 -0.6  8.7 -1.   0.9  5.7 -0.3  2.4  0.9 -1.8  1.9 -0.   0.9  1.6  0.5 -0.8  2.8  1.5 -0.1 -0.2  3.1 -0.7 -0.1 -0.5 -2.2  0.  -1.9  2.1 -0.8 -1.  -0.4  1.1 -0.9  2.7  1.1 -0.6 -0.  -0.7 -0.3 -0.2 -1.5 -1.  -0.7  6.   0.7]
vy_50sample [[1 7 6 5 3 8 0 9 4 4]
 [9 8 8 5 5 0 4 4 1 6]
 [8 9 6 7 7 5 5 2 4 1]
 [6 3 9 0 0 8 2 7 1 1]
 [1 8 0 2 9 5 6 4 7 3]
 [4 9 1 3 5 2 2 6 0 7]
 [8 5 5 9 1 7 3 2 0 0]
 [4 2 9 8 8 3 3 5 0 0]
 [5 1 0 7 7 4 8 3 2 2]
 [4 2 3 7 9 8 1 5 6 0]]
vt_50sample [[1 7 6 5 3 8 0 9 4 2]
 [9 7 8 5 3 0 4 2 1 6]
 [9 8 6 7 3 5 0 2 4 1]
 [6 3 9 4 0 8 2 5 7 1]
 [1 8 0 2 9 5 6 4 7 3]
 [4 9 1 3 5 2 8 6 0 7]
 [8 4 5 9 1 7 3 2 0 6]
 [4 9 2 8 6 3 5 1 7 0]
 [5 1 0 7 9 4 8 3 6 2]
 [4 2 3 7 9 8 1 5 6 0]]
Epoch  2010: Training cost= 0.6192, Training acc= 0.6177, Validation cost= 0.5728, Validation acc= 0.6183
Epoch  2020: Training cost= 0.5422, Training acc= 0.6183, Validation cost= 0.5965, Validation acc= 0.6189
Epoch  2030: Training cost= 0.6053, Training acc= 0.6189, Validation cost= 0.5656, Validation acc= 0.6194
Epoch  2040: Training cost= 0.5593, Training acc= 0.6195, Validation cost= 0.6281, Validation acc= 0.6201
Epoch  2050: Training cost= 0.6000, Training acc= 0.6200, Validation cost= 0.5899, Validation acc= 0.6206
Epoch  2060: Training cost= 0.6450, Training acc= 0.6206, Validation cost= 0.6145, Validation acc= 0.6211
Epoch  2070: Training cost= 0.6745, Training acc= 0.6211, Validation cost= 0.5929, Validation acc= 0.6216
Epoch  2080: Training cost= 0.6637, Training acc= 0.6215, Validation cost= 0.6073, Validation acc= 0.6220
Epoch  2090: Training cost= 0.6195, Training acc= 0.6220, Validation cost= 0.6554, Validation acc= 0.6226
Epoch  2100: Training cost= 0.6155, Training acc= 0.6225, Validation cost= 0.6340, Validation acc= 0.6231
tm  [-0.8 -1.  -1.4 -1.5 -0.2  1.2 -0.9 -1.   2.6  0.9  1.2 -0.2 -0.  -0.6 -0.1 -0.6 -0.8 -0.1 -1.4  2.6 -0.4 -0.2  1.2 -0.2 -0.4  1.8 -0.1 -0.3  0.2 -1.5  4.5 -0.4  1.6 -1.2  2.2 -0.9 -0.4 -0.2 -2.1 -1.4 -0.9  2.2 -0.3 -0.1 -0.7  1.5 -1.6 -0.4 -0.6  1.4 -0.4 -1.5 -0.8  2.3 -1.   2.   0.4 -0.1  3.5 -0.6  5.1 -0.4  1.   2.7  0.   0.7 -0.3  4.2  1.1  0.1 -0.7 -0.2 -0.2 -0.3 -3.2 -0.5  0.6 -0.3  7.4 -0.2 -0.4 -0.7  2.7 -0.7 -0.1  1.8  0.8 -0.5 -0.4 -0.5 -0.4 -1.1 -0.8 -1.  -0.8 -0.1 -0.4 -1.6 -0.4 -0.7 -0.8 -0.5  4.   0.3 -0.8 -0.1 -2.   5.1 -0.1  2.8 -0.9  3.  -0.6 -0.8  5.6 -0.5 -0.1  1.1 -0.9  2.3 -0.4 -1.3  2.7  2.1 -1.  -0.1 -0.2  0.6  3.5  1.7  3.6 -1.8 -0.3 -0.7 12.4 12.  -0.4 -0.1 -0.3 -1.1  1.7  0.4  1.3  1.5 -1.  -0.3  0.5  1.8  3.7  0.   4.8  0.5 -0.5  2.2 -0.1 -0.4 -0.5 -0.3 -0.9 -0.1  2.9  3.2  1.2 -0.9 -0.8 -0.1 -0.2  3.1 -0.1 -0.4  1.8  2.1 -0.2 -0.3 -0.  -0.9 -1.8 -0.1 11.   4.7 -0.4 -0.2  0.1 -0.5  2.6 -0.8 -0.7  1.7 -0.2  4.9 -0.5 -0.2  0.2 -1.3 -0.7  0.1 -1.2 -1.7 -0.8 -0.  -0.4  6.7 -0.8 -1.   2.8 -1.9  0.9 -0.8 -0.  -0.8 -0.3  0.  -1.3  6.6  0.1 -0.3  4.  -0.3 -0.9 -0.6  0.1 -0.1 -0.8 -0.4  5.5 -0.3 -0.5  3.2 -0.1  2.8  1.5  0.6 -0.8  0.1  3.6  7.8  2.5 -1.8  3.7 -0.7 -1.1 -0.4 -0.1 -1.1  3.9 -0.5 -0.5  0.6 -0.6 -0.4 -0.  -0.3 -2.3  0.1  2.2  1.3]
ty_50sample [[6 1 4 0 5 8 2 9 9 7]
 [0 7 4 8 3 1 2 6 5 9]
 [8 4 9 9 6 1 3 2 5 5]
 [4 4 7 9 6 1 0 2 8 5]
 [2 1 9 6 5 5 7 4 8 0]
 [0 4 1 6 7 5 2 2 3 9]
 [6 3 3 1 1 5 4 2 2 2]
 [0 2 6 7 7 3 8 5 4 4]
 [2 6 4 4 0 9 3 5 8 7]
 [9 2 3 0 4 5 7 1 6 8]]
tt_50sample [[6 1 4 0 5 8 3 2 9 7]
 [0 7 4 8 3 1 2 6 9 5]
 [8 7 4 9 6 1 3 0 2 5]
 [3 4 7 9 6 1 0 2 8 5]
 [2 1 9 6 3 5 7 4 8 0]
 [0 4 1 6 7 5 8 2 3 9]
 [9 6 3 1 5 0 4 7 8 2]
 [0 2 6 7 3 8 9 1 5 4]
 [2 6 4 1 0 9 3 5 8 7]
 [9 2 3 0 4 7 5 1 6 8]]
vm  [-0.8 -1.9  6.6  0.1 -1.5 -0.3 -0.  -1.4  0.9  1.1  5.6  0.2  1.5 -0.2  9.   4.7 -1.1 -0.2  1.4  0.8 -0.3  0.5 -0.5 -0.6 -1.4 -0.8 -0.1 -0.3  2.7 -0.7  4.1 -0.6  1.9 11.  -0.5 -0.4 -0.5  0.7 -1.4 -0.4 -0.6  1.8 -0.2 -0.9 -1.  -0.8 -1.2  0.  -0.8 -0.4 -1.8 -0.8 -0.5  2.3 -1.2 -1.2 -0.3  3.5  0.  -0.7  3.1 -0.1 -0.5  4.   1.2  0.8 -0.8  1.2 -0.3 -0.8  0.7 -0.9 -0.9 -0.4 -2.6 -0.5 -0.1  0.5  4.3 -0.3  4.8 -0.5  1.3 -0.3 -0.1  5.1 -0.4 -1.   1.2  0.3 -0.9  0.1 -0.7 -1.8 -0.7 -0.1  1.6 -1.1  1.3 -0.7  1.8  6.5  2.6  0.  -1.  -0.1 -2.3  3.5  2.6  1.4  1.7 -1.6 -0.1 -0.7 -0.1  4.8  1.5  1.3 -0.9 -0.4 -0.3 -0.3  3.   2.4 -0.8  9.5  1.4 -0.3  2.5  1.5  5.  -2.2 -0.5  1.3 -0.2 15.4 -0.6  2.6 -0.7 -1.7 -0.4  4.3  1.3  0.8 -1.  -0.3 -0.3 -0.9 -0.4  2.8  2.2 -0.3 -1.3 -0.2 -0.7 -0.5 -1.2 -0.3 -0.8 -0.1  0.9  4.4  1.2 -0.4  4.5 -0.5 -0.1  3.  -0.7  0.4 -0.7  2.1 -1.2 -1.1 -0.5  3.7 -1.9 -0.6  9.2  1.4 -0.6  1.9 -0.7 -0.8 -0.6 -1.8 -0.6 -1.4 -1.4  0.8 -0.5 -0.7  0.2 -0.8 -0.6 -0.2 -1.3 -0.1 -1.2 -0.7 -0.1  1.4 -0.5 -0.1  2.6 -1.7  2.6 -0.6 -2.  -0.5 -0.1  2.5 -0.9  7.2 -0.2  0.3  4.9  0.4  3.5 -0.2 -1.3  2.  -0.3  1.   3.   1.   0.1  1.6  0.7  0.9 -0.1  0.5 -0.  -1.4 -0.7 -1.4 -0.1 -1.5  1.3 -1.  -1.1 -0.6 -0.  -0.5 -0.5  1.4 -0.8  1.5 -0.5  0.2 -0.7 -0.6 -1.6  0.8  3.8  0.6]
vy_50sample [[7 6 1 1 2 4 3 9 8 8]
 [7 8 3 2 1 5 4 9 0 6]
 [2 3 6 7 7 9 1 4 5 8]
 [4 4 6 6 1 1 2 2 7 7]
 [3 8 0 9 2 7 6 4 1 5]
 [4 1 2 5 5 9 3 0 0 7]
 [7 6 2 5 4 4 0 1 9 9]
 [8 9 4 7 6 2 5 3 0 1]
 [1 1 0 9 5 5 3 8 4 2]
 [0 9 3 2 2 2 8 8 5 5]]
vt_50sample [[7 6 1 5 2 4 3 9 8 0]
 [7 8 3 2 1 5 9 4 0 6]
 [2 3 6 7 0 9 1 4 5 8]
 [9 4 8 6 3 1 2 0 7 5]
 [3 8 0 2 9 7 6 4 1 5]
 [4 1 2 5 6 8 9 3 0 7]
 [7 6 2 5 4 0 3 1 9 8]
 [8 9 4 7 6 2 5 3 0 1]
 [1 0 6 9 7 5 3 8 4 2]
 [0 9 3 6 2 4 1 8 7 5]]
Epoch  2110: Training cost= 0.6277, Training acc= 0.6231, Validation cost= 0.6514, Validation acc= 0.6236
Epoch  2120: Training cost= 0.6224, Training acc= 0.6236, Validation cost= 0.6518, Validation acc= 0.6241
Epoch  2130: Training cost= 0.6726, Training acc= 0.6240, Validation cost= 0.6874, Validation acc= 0.6245
Epoch  2140: Training cost= 0.6787, Training acc= 0.6244, Validation cost= 0.6361, Validation acc= 0.6250
Epoch  2150: Training cost= 0.6272, Training acc= 0.6249, Validation cost= 0.6311, Validation acc= 0.6255
Epoch  2160: Training cost= 0.6571, Training acc= 0.6254, Validation cost= 0.6525, Validation acc= 0.6258
Epoch  2170: Training cost= 0.6462, Training acc= 0.6258, Validation cost= 0.6243, Validation acc= 0.6264
Epoch  2180: Training cost= 0.6958, Training acc= 0.6264, Validation cost= 0.5877, Validation acc= 0.6269
Epoch  2190: Training cost= 0.5827, Training acc= 0.6268, Validation cost= 0.6321, Validation acc= 0.6273
Epoch  2200: Training cost= 0.6345, Training acc= 0.6274, Validation cost= 0.6097, Validation acc= 0.6278
tm  [ 1.8  0.1 -0.3  7.5 -0.3 -0.3 -0.8 -0.4  0.4 -0.4  2.2 -0.4  1.8 -0.  -1.9  1.3 -0.5 -0.3 -0.6 -0.9 -0.6 -0.5  2.9 -0.7 -0.5  2.4 -0.6 -0.6 -0.2 -1.2 -0.4  0.8 -0.1 -2.3  5.3  0.1  1.3  0.3  2.5 -1.5 -0.9 -0.2 -0.7 -0.3 -0.6  0.8  3.  -0.7  2.7  4.  -0.7 -0.5  0.2  1.   0.1  6.4 -0.   0.1  2.8  3.9 -0.6  2.5  0.5  4.6 -0.2 -0.5 -0.2  2.6  0.3  1.9 -0.4  3.2  1.7 -0.1 -0.2 -0.3  0.1 -0.4  2.7 -0.2  2.3 -0.2 -0.1 -0.7 -0.8 -0.8 -0.  -0.5 -0.5 -0.3  0.1 -1.2 -0.  -0.2  3.4 -0.4  0.9 -0.3 -1.   0.3 -0.7 -0.4 -0.3 -0.1  1.6  0.6  1.  -0.5  1.1 -0.9 -0.6  4.2 -0.7 -0.   3.7 -0.8 -0.8  0.7 -0.4  3.2 -0.5  2.1 -0.1 -0.6 -0.3 -2.1 -0.5  1.3  0.6 -0.5  5.  -0.7 -0.6 -1.2  8.4 -0.  -0.4 -0.6 -0.6 -0.4 -0.3 -0.8 -0.7 -0.4 -0.2  1.9 -0.9  1.5  0.6  0.6 -0.4 -0.1  4.4 -0.5 -0.7 -0.3 -0.2 -0.6 -0.6 -0.3  2.8 -0.3 -0.5 -1.2 -1.6 -0.8  0.2  1.  -0.5  3.9  1.2 -1.   1.8 -0.4  1.2  2.  -0.7  4.1  0.2 -0.   1.5 -0.4 -0.4 -0.7  1.9 -0.3  4.2  0.2  3.1  6.2 -0.2  0.5 -1.  -0.9  4.6 -0.4  2.4 -1.2 -0.3  3.4 -1.   2.7 -0.9 -1.1 -0.6 -0.4 -1.3  2.9  7.9 -0.6 -0.2  0.1 -1.8 -0.1 -1.1 -0.7  3.5 -0.4 -1.  -0.6  2.1 -1.5 -0.7 -1.   2.9 -0.1  0.9  4.1 -0.2  3.8 -0.1 -1.2 -1.3  4.9  3.8  5.3  5.4  1.8  3.6 11.8 -1.2  7.   0.1 -0.7  0.7 -1.  -0.   1.8 -0.9 -0.4 -0.5  0.1  3.   2.2 -0.5  4.8]
ty_50sample [[0 9 2 6 6 4 4 1 7 5]
 [3 4 9 5 5 0 0 8 2 1]
 [5 8 4 4 9 9 1 7 2 3]
 [1 9 3 6 4 7 0 2 5 8]
 [2 2 9 9 3 6 6 4 8 8]
 [2 2 1 8 8 0 0 6 4 3]
 [8 8 5 5 2 0 3 7 1 6]
 [7 9 2 2 5 0 8 1 3 4]
 [9 4 4 5 1 3 8 0 7 6]
 [4 8 0 1 1 6 9 5 7 3]]
tt_50sample [[0 9 2 8 6 3 4 1 5 7]
 [3 9 4 6 5 0 7 8 2 1]
 [5 8 4 0 9 6 1 7 2 3]
 [1 9 3 6 4 7 0 2 5 8]
 [2 7 0 9 3 5 6 4 8 1]
 [2 1 7 5 8 0 9 6 4 3]
 [8 9 4 5 2 0 3 7 6 1]
 [7 9 2 6 0 5 8 1 3 4]
 [9 4 2 5 1 3 8 0 7 6]
 [4 8 2 0 1 6 9 5 7 3]]
vm  [-0.4 -1.4  1.5 -0.3 -0.8 -0.2 -0.8 -1.4  2.9 -0.2  7.8 -0.3  0.4 -1.1  5.6  5.3 -1.5 -0.1  0.5  3.3 -1.   1.2 -0.1 -0.5 -0.7  1.8 -0.5 -0.3  2.3 -1.1  5.5 -0.7  1.3  7.4  4.  -0.3 -1.1  0.9 -0.6 -0.6 -0.5 -0.3 -1.3  1.1 -1.2  0.4 -1.1 -0.8  1.2 -0.4 -1.8 -1.4  0.8  4.7 -0.4 -0.2 -0.1  2.7  4.3 -0.8  1.6  1.   1.5  7.8  3.1 -0.1 -0.2  2.5  1.5 -0.2 -0.7 -0.4  0.4  0.8 -2.8 -0.7 -1.6  0.9  4.9  0.4  4.  -0.4  4.7 -0.2 -0.6 -0.3 -0.2 -0.5 -0.9 -0.4 -0.5 -1.4 -0.2 -2.   0.7  0.3 -0.5 -1.9 -0.6 -0.4 -0.6  3.4  0.4  1.  -0.3 -0.1 -1.3  5.2  3.6  2.9 -0.   0.2 -0.1 -0.6  0.8 -0.1  1.2  4.  -0.5  2.2 -0.4 -0.9  1.2  2.7 -0.9  5.  -1.3 -0.4  3.7  1.7  7.4 -1.8 -0.1 -1.   2.9  8.9 -0.   2.4 -0.1 -0.8 -0.8  1.2  0.3  1.5 -1.   3.3 -0.9  0.3 -0.8 -0.1  3.1  0.2  2.9  0.5 -0.2 -0.2 -1.4 -0.8 -0.6  1.1  3.  -0.   2.7 -1.1  2.9 -0.7  2.6  3.7 -0.3  1.  -0.4 -0.5  0.4 -0.8 -0.2  5.2 -1.1  0.9  7.   2.4  2.  -0.  -1.6 -1.1  0.1 -1.6  2.4 -1.  -0.8  0.9 -0.5  1.2 -1.  -1.1  1.5 -0.5 -0.1 -1.4 -0.8  1.1 -0.7  4.1 -0.8 -0.9 -0.4 -1.3  0.2 -0.1  3.1 -1.2 -0.3  2.9 -1.9  2.9 -0.8 -0.3  2.4 -0.6  2.1  1.4 -1.  -0.2 -0.9 -0.4  3.   0.7  1.4  3.4  2.5  4.5  0.9 -1.2 -0.8  1.7 -0.4  2.   2.5 -0.7  5.2  4.5 -1.5  3.3  0.9 -0.8  0.7 -0.3 -0.8  1.9 -1.1 -0.5 -1.   0.5 -0.6  1.3 -0.   2.1]
vy_50sample [[2 6 4 4 3 3 9 1 8 5]
 [5 7 0 2 8 8 3 6 6 4]
 [8 7 0 5 9 4 3 6 2 1]
 [3 4 9 9 0 5 2 7 6 8]
 [6 1 1 0 3 2 5 7 9 8]
 [6 1 7 5 9 3 2 0 8 4]
 [8 1 1 7 3 3 2 5 6 6]
 [4 4 1 9 2 5 8 8 7 7]
 [3 2 2 7 7 0 8 4 9 1]
 [0 1 1 2 9 3 3 4 7 8]]
vt_50sample [[2 6 7 4 3 0 1 9 8 5]
 [5 7 0 2 8 9 3 1 6 4]
 [8 7 0 5 9 4 3 2 6 1]
 [3 4 9 1 0 5 2 7 6 8]
 [6 1 4 0 3 2 5 7 9 8]
 [6 1 7 9 5 3 2 0 8 4]
 [0 8 1 7 3 2 4 5 9 6]
 [4 1 6 0 2 9 5 8 7 3]
 [5 3 2 0 7 6 8 9 4 1]
 [0 1 2 5 9 6 3 4 7 8]]
Epoch  2210: Training cost= 0.6248, Training acc= 0.6278, Validation cost= 0.5771, Validation acc= 0.6283
Epoch  2220: Training cost= 0.6407, Training acc= 0.6283, Validation cost= 0.6712, Validation acc= 0.6288
Epoch  2230: Training cost= 0.6200, Training acc= 0.6288, Validation cost= 0.6001, Validation acc= 0.6293
Epoch  2240: Training cost= 0.5508, Training acc= 0.6293, Validation cost= 0.5927, Validation acc= 0.6298
Epoch  2250: Training cost= 0.7006, Training acc= 0.6298, Validation cost= 0.6322, Validation acc= 0.6302
Epoch  2260: Training cost= 0.6152, Training acc= 0.6303, Validation cost= 0.6284, Validation acc= 0.6307
Epoch  2270: Training cost= 0.6300, Training acc= 0.6308, Validation cost= 0.6284, Validation acc= 0.6312
Epoch  2280: Training cost= 0.5967, Training acc= 0.6312, Validation cost= 0.5809, Validation acc= 0.6317
Epoch  2290: Training cost= 0.5865, Training acc= 0.6317, Validation cost= 0.6769, Validation acc= 0.6321
Epoch  2300: Training cost= 0.6597, Training acc= 0.6322, Validation cost= 0.6255, Validation acc= 0.6326
tm  [ 0.   4.8 -0.5  5.2 -0.1 -0.6 -0.7 -0.5 -0.6 -0.4 -1.9  0.4 -0.  -0.5 -1.6 -0.9  0.5  0.8 -0.8 -0.7 -0.3 -0.9  3.2 -0.2 -0.4  0.6 -0.4 -0.7 -0.6 -1.2 -1.1  0.8 -0.2 -3.8  2.  -0.2  2.8 -0.3 -0.2 -1.6 -0.7 -0.6  0.5 -0.6 -0.6  2.3 -0.1  0.3  2.5  5.   1.  -0.9 -0.5 -0.5 -0.2  4.8  0.5  0.4 -0.   6.2  1.   0.7  0.6 -0.1 -1.  -0.6 -0.5 -0.1  0.6  4.1 -0.2  3.9  4.5 -0.5 -0.1 -0.2  3.2 -1.1  2.3 -0.3 -1.2 -0.7 -0.4 -0.5 -0.2 -0.8  1.3 -0.7  1.2 -0.4 -0.3 -1.  -0.1  2.   0.8 -0.5  2.  -0.4 -0.9 -0.1 -0.4 -1.   0.7 -0.2  0.6  0.5 -0.2 -1.6 -0.8 -0.7 -0.5  3.  -0.9 -0.   3.8 -0.9 -0.9  0.2 -0.2  2.9 -0.7  1.1  0.8 -0.3 -0.2 -1.9  0.9  3.7 -0.2  0.6  3.  -0.4  0.2 -1.1 10.9 -0.8 -0.5 -0.7 -0.8 -0.2  2.2 -1.3 -0.2  0.2 -0.6  0.  -1.   0.9  2.1 -0.2 -0.2 -0.3  3.5  0.1 -0.9 -0.7  1.2 -0.4 -0.8 -0.5  0.3  1.3 -0.7 -0.9 -2.8 -0.5 -0.   2.2 -0.2  3.4  1.  -0.3  0.7 -0.2  1.8 -0.2 -0.9  1.5  3.7  1.   0.  -0.2  2.1 -1.   2.4  3.7  1.8  2.3  3.   6.4 -0.3  0.2 -0.5 -1.2  1.8 -0.2  0.9 -1.1 -0.1  1.4 -0.8  2.8 -0.1 -1.3  0.8 -0.7 -1.7  2.5  9.9 -0.6 -0.1 -0.2 -1.8  1.3 -0.8 -0.7  4.7 -0.  -1.1 -0.8  1.  -0.6 -0.7 -1.1  4.   1.  -0.9  2.2 -0.8  2.  -0.2 -0.3 -1.5  5.5  7.3  4.1  3.1  1.1  1.7  7.6 -1.1  4.1 -0.2 -0.6  4.6 -0.4  0.8  0.3 -0.3 -0.8  0.8 -1.2  0.  -0.1  0.   1.5]
ty_50sample [[8 6 6 9 9 3 4 2 5 7]
 [4 5 5 9 2 7 7 6 6 0]
 [7 0 8 1 6 4 4 2 3 3]
 [2 0 7 8 3 6 9 9 4 5]
 [9 9 4 8 6 0 0 2 5 1]
 [6 1 1 3 9 0 4 5 5 2]
 [3 3 9 7 0 1 6 6 2 4]
 [8 4 6 3 0 9 5 7 2 1]
 [9 5 1 4 3 0 7 7 2 6]
 [6 5 5 9 4 9 3 3 1 2]]
tt_50sample [[8 0 6 9 1 3 4 2 5 7]
 [4 5 9 3 8 2 7 6 0 1]
 [7 0 8 6 1 9 4 5 2 3]
 [2 7 0 3 8 1 6 9 4 5]
 [9 4 7 8 6 3 0 2 5 1]
 [6 8 1 3 9 0 4 5 2 7]
 [5 3 9 7 8 0 1 6 2 4]
 [8 4 6 3 0 9 5 7 2 1]
 [9 5 1 4 3 0 7 8 2 6]
 [6 7 5 0 9 4 3 8 1 2]]
vm  [ 0.6  1.5 -0.9  0.7 -1.2  1.  -0.7 -1.  -1.3 -0.1  4.5 -0.9  2.9 -0.  -0.7  3.4 -0.2 -0.1 -0.4 -1.5 -0.2 -0.7  3.8  0.3 -1.3  2.5 -0.3 -0.5 -0.  -0.6  2.7  0.4  0.2 -0.5  3.5  3.3  2.9  1.8  3.  -0.8 -0.6  0.5 -0.   2.7 -1.1 -0.3  1.7 -0.5 -0.   5.2 -0.9 -0.9 -0.3  1.8 -0.4  3.7 -0.6 -0.8 -0.2 -0.2  0.5  3.8 -0.3  2.3  0.8 -0.2 -0.2  1.1 -0.3  1.3 -0.6  0.4  1.3  0.9  3.  -0.4  3.8  0.1  6.8 -0.4  4.2  0.  -0.2 -0.6 -0.2  0.8  1.5 -0.3 -0.5 -0.7 -0.2 -0.6 -0.5 -0.5  1.5  0.5 -0.1  0.3 -0.6 -0.6 -0.2  3.6  0.1 -0.2  2.   0.8  0.8  2.9  1.9 -0.9 -1.8  1.7 -0.2  0.9  1.1 -0.2 -1.1 -0.4 -0.6 -0.2 -0.4  1.7  0.8  0.  -0.3 -0.9 -0.5 -0.  -0.2 -0.8  2.9 -0.7 -0.5 -0.6  4.3  0.1 -0.2 -0.6 -0.3 -0.7 -0.3 -0.5 -0.5  1.1 -0.5  2.8 -0.2  2.  -0.3  3.8  1.5 -0.4  0.7 -0.7 -0.5 -0.6 -0.2 -0.7 -0.2 -0.4  4.4  0.8 -0.8 -1.2 -1.4 -0.6  1.1  0.6  1.4  0.8  2.1 -0.8 -0.  -0.3 -0.3  3.1  0.   3.  -0.1 -0.8  1.7  1.5  0.9 -1.1 -0.  -0.3  2.6  0.8  0.9 -0.2 -0.4 -0.5 -0.4 -0.8  2.3  1.   1.5  1.1 -0.3  1.9 -0.8  1.1 -1.4 -1.   0.8 -0.5 -1.   4.2  5.7 -0.4  0.2  0.7 -1.4  4.5  1.  -1.1 -0.2 -0.5 -0.5 -0.5  0.6 -0.4 -1.2 -1.1  3.4  0.9  3.   2.7 -0.4 -0.1 -0.4 -1.  -0.9  4.1  4.8  6.5  5.5  1.9  3.7 10.6 -1.1  7.1 -0.3 -0.8  0.3 -0.7  0.3  3.6 -0.3 -0.5 -0.7  2.6  2.9  1.9 -0.6  5.9]
vy_50sample [[4 4 9 8 8 1 7 7 3 5]
 [5 2 4 1 0 7 8 9 9 6]
 [4 2 7 9 6 8 0 3 3 5]
 [1 3 8 0 9 4 7 5 2 6]
 [3 9 8 4 0 2 6 1 5 7]
 [1 4 6 9 9 7 2 3 8 5]
 [8 8 9 2 4 5 3 7 0 6]
 [2 2 5 1 0 3 3 6 4 4]
 [5 2 4 8 1 3 7 9 9 6]
 [2 8 9 3 7 1 5 0 6 6]]
vt_50sample [[4 9 2 0 1 8 6 7 3 5]
 [5 2 4 1 0 7 8 3 9 6]
 [4 2 7 9 6 8 0 1 3 5]
 [1 3 8 0 9 4 7 5 2 6]
 [3 9 8 4 0 2 6 1 5 7]
 [1 4 6 0 9 7 2 3 8 5]
 [1 8 9 2 5 4 7 3 0 6]
 [7 2 5 1 9 0 3 6 4 8]
 [5 2 4 8 1 3 7 0 9 6]
 [2 8 9 3 7 5 1 0 4 6]]
Epoch  2310: Training cost= 0.6776, Training acc= 0.6326, Validation cost= 0.5994, Validation acc= 0.6330
Epoch  2320: Training cost= 0.6530, Training acc= 0.6330, Validation cost= 0.5992, Validation acc= 0.6334
Epoch  2330: Training cost= 0.6585, Training acc= 0.6335, Validation cost= 0.5918, Validation acc= 0.6338
Epoch  2340: Training cost= 0.6193, Training acc= 0.6339, Validation cost= 0.5907, Validation acc= 0.6343
Epoch  2350: Training cost= 0.5863, Training acc= 0.6344, Validation cost= 0.6162, Validation acc= 0.6347
Epoch  2360: Training cost= 0.5800, Training acc= 0.6349, Validation cost= 0.5238, Validation acc= 0.6352
Epoch  2370: Training cost= 0.5707, Training acc= 0.6354, Validation cost= 0.6082, Validation acc= 0.6357
Epoch  2380: Training cost= 0.5847, Training acc= 0.6358, Validation cost= 0.5791, Validation acc= 0.6361
Epoch  2390: Training cost= 0.5603, Training acc= 0.6363, Validation cost= 0.5636, Validation acc= 0.6366
Epoch  2400: Training cost= 0.6196, Training acc= 0.6367, Validation cost= 0.6204, Validation acc= 0.6370
tm  [ 3.1  0.3  6.4  6.9 -1.7 -1.3 -0.5 -1.1 -1.6  1.3  0.7 -0.4 -0.1 -0.   2.7  5.2 -0.4 -0.3  2.6 -1.9 -0.2  0.4  3.8  0.8 -1.6 -0.5 -0.3 -0.4  2.8 -0.  -0.5  0.1  0.9  5.1 -0.1  1.7  3.4 -0.4  3.2 -0.6 -0.3  2.8  2.9 -0.6 -0.9 -0.9  2.6  1.9  2.3  6.1 -0.7 -0.   0.9 -0.2 -0.6 -0.1 -0.5  0.8 -1.   3.4 -1.4  1.3 -0.9 -0.1  1.2 -0.3 -0.6 -0.7  0.4 -0.5  0.7 -0.2  1.2 -0.5  2.   0.4  0.4  2.6  1.  -0.5  4.4  0.2 -0.5 -0.1 -0.9  5.2  0.6 -0.5  1.3 -0.2 -0.4  1.5  0.  -0.6  1.8  0.2  3.4  1.6 -0.1 -0.2  1.1  8.  -0.7 -0.4  1.3  0.8  1.1 -0.4  0.8 -1.5 -0.1 -0.8 -0.3  1.  -1.7  3.5 -0.2 -0.7  0.  -0.4 -0.4  3.5  0.3 -1.   0.   3.   0.4  2.3 -0.4 -1.   5.1 -0.7 -0.1  0.1 -0.8  3.2 -0.1 -0.7 -1.2 -0.7 -0.1 -0.3  2.   2.4 -0.7  4.6 -0.4 -1.4 -0.9  6.5 -0.6 -0.   3.7 -0.6 -0.6 -0.5 -1.1 -0.3 -1.  -0.7  1.7  2.4  0.4 -0.7  1.5 -0.4  0.3 -0.4 -0.2  3.7  2.7 -0.5 -0.9 -0.2 -0.4  4.3 -0.6  1.2 -0.  -0.7 -0.1  1.7  0.  -0.9 -1.1 -0.6  4.4 -0.9 -0.6 -0.6 -0.4 -1.  -0.3 -1.   6.6 -0.1  1.9  3.4 -0.4 -0.6 -0.6 -1.  -0.2 -0.3 -0.1 -0.1 -0.1  3.8  2.7  0.4  0.9  2.6 -1.1  0.3 -1.  -0.1  3.4 -0.1  3.4  0.6 -1.2 -0.6 -0.1 -0.3  2.9  3.3 -0.   0.2 -0.4  1.5 -0.4 -1.  -0.5  1.6 -0.2 -1.3  2.7  2.5  0.7  6.7 -1.   4.2  1.  -0.  -0.1 -0.3 -0.1  2.9 -0.2  0.2 -0.6  0.4  2.   0.4  0.4  5.9]
ty_50sample [[7 9 6 8 2 5 4 0 1 3]
 [8 6 2 9 4 4 7 0 3 1]
 [5 6 9 4 8 8 1 3 7 7]
 [9 6 0 7 4 3 8 5 1 1]
 [8 8 6 5 3 4 0 1 9 2]
 [8 1 4 7 6 5 0 9 3 2]
 [4 5 5 2 3 3 8 9 0 7]
 [4 1 7 5 2 2 6 0 9 9]
 [1 8 2 6 0 0 3 7 7 9]
 [3 1 4 0 5 5 6 2 9 8]]
tt_50sample [[7 9 6 8 2 5 4 0 1 3]
 [8 6 2 9 4 5 7 0 3 1]
 [5 6 9 4 8 2 1 3 7 0]
 [9 0 6 4 7 3 8 5 2 1]
 [8 7 6 5 3 4 0 1 9 2]
 [8 1 4 7 6 5 0 9 3 2]
 [4 5 1 2 6 3 8 9 7 0]
 [4 1 5 7 2 3 6 0 8 9]
 [1 8 2 6 0 3 4 5 7 9]
 [3 1 4 7 0 5 6 2 9 8]]
vm  [ 0.2  1.7  3.8  0.6 -1.4 -1.6 -0.6 -1.1 -0.4 -1.  -1.3  3.2 -1.3 -1.1  6.1 -1.3 -0.4  0.2  2.   2.1 -0.1 -0.5 -0.1 -0.2 -0.6  2.7 -0.7 -0.7 -0.6 -0.6  1.3  0.8 -0.5  3.9 -0.3 -0.5  0.3 -0.3 -0.5 -1.6 -0.8 -1.2 -0.   0.  -1.3  2.9 -1.7  4.   3.9 -0.9 -1.1 -0.9  0.5 -0.4 -0.2 -0.4 -0.1  2.6 -0.2  1.9  1.9 -0.1 -0.2  1.4 -0.7 -0.1 -0.6 -0.9  2.7  7.  -0.   3.   0.7 -0.4 -1.   0.4 -0.6 -1.4  2.3  1.7 -0.1 -0.6  1.9 -0.1 -0.5 -0.9  1.3 -0.9  3.  -0.1 -0.2 -1.   1.5  0.3 -0.3  1.1  3.6 -1.  -0.6 -0.4  2.9  0.5  2.1  1.4  1.6  0.2 -1.2  1.  -1.   1.1  0.8 -0.  -0.8  0.9  2.1 -0.2  0.9  3.8 -0.4  1.5 -0.7 -0.5 -0.2  1.7 -0.8  6.   3.7  4.4 -0.2  6.3  2.2 -1.   1.8 -0.7 -0.5  1.8 -0.1  0.8  2.8 -0.5  3.9 -0.7  2.2  1.  -1.   0.8 -1.1 -0.9 -0.5 -0.7  1.8 -0.1  2.5  4.1 -1.2 -0.5 -0.6 -0.4  1.  -0.7 -0.3  0.1  2.  -0.4 -0.  -0.6  1.1  4.7  0.6  1.2 -0.7 -0.  -0.4 -0.3 -0.   4.2 -0.3 -0.5  3.6  4.7  1.8 -0.6 -0.5 -1.2  2.  -0.8  1.8 -0.2  0.6  3.8 -0.3  1.9  0.2 -1.6  0.5 -0.3 -0.2 -0.8 -0.5 -0.4 -0.5  1.2 -0.4 -1.4 -0.1 -1.2 -0.2 -0.3  3.7 -0.8 -0.8  0.6 -1.1  0.4 -0.7 -0.3  2.6 -0.3  2.2  2.5 -1.7  2.3  0.8 -0.6 -0.2  0.  -1.4 -0.2  0.2  4.  -0.5  2.1 -1.4  2.5  5.1 -0.7 -0.1 -0.   3.6  1.2 -1.3  1.8 -0.3 -1.1  3.7 -0.1 -0.8 -0.4 -0.4 -0.6 -0.3 -1.8  0.2 -1.2  5.3 -0.8]
vy_50sample [[3 7 0 6 6 1 5 9 9 9]
 [2 6 7 7 5 4 8 3 3 1]
 [3 6 8 8 0 7 9 2 1 1]
 [0 4 9 1 5 7 3 6 6 8]
 [7 5 1 4 4 0 6 2 9 9]
 [1 3 6 5 2 0 9 4 7 8]
 [2 9 0 6 7 1 3 4 8 5]
 [2 7 6 0 5 4 9 9 3 1]
 [7 6 2 0 3 8 4 9 5 1]
 [6 3 3 5 8 1 4 4 9 9]]
vt_50sample [[3 7 0 6 8 4 1 5 9 2]
 [2 6 7 5 4 9 0 8 3 1]
 [3 6 8 4 7 0 2 9 1 5]
 [0 4 9 1 5 7 3 6 2 8]
 [7 5 1 8 4 0 6 2 9 3]
 [1 3 6 5 2 0 9 7 4 8]
 [2 9 6 0 7 1 3 4 8 5]
 [2 7 6 0 5 4 8 9 3 1]
 [7 6 2 0 3 8 4 9 5 1]
 [6 3 2 5 0 1 8 4 9 7]]
Epoch  2410: Training cost= 0.5778, Training acc= 0.6372, Validation cost= 0.5594, Validation acc= 0.6375
Epoch  2420: Training cost= 0.6719, Training acc= 0.6376, Validation cost= 0.6033, Validation acc= 0.6379
Epoch  2430: Training cost= 0.6208, Training acc= 0.6380, Validation cost= 0.6255, Validation acc= 0.6383
Epoch  2440: Training cost= 0.6213, Training acc= 0.6384, Validation cost= 0.5658, Validation acc= 0.6388
Epoch  2450: Training cost= 0.6527, Training acc= 0.6389, Validation cost= 0.5849, Validation acc= 0.6392
Epoch  2460: Training cost= 0.5950, Training acc= 0.6393, Validation cost= 0.6669, Validation acc= 0.6397
Epoch  2470: Training cost= 0.5927, Training acc= 0.6397, Validation cost= 0.5336, Validation acc= 0.6401
Epoch  2480: Training cost= 0.5920, Training acc= 0.6401, Validation cost= 0.6541, Validation acc= 0.6405
Epoch  2490: Training cost= 0.6747, Training acc= 0.6405, Validation cost= 0.5769, Validation acc= 0.6409
Epoch  2500: Training cost= 0.6213, Training acc= 0.6409, Validation cost= 0.5587, Validation acc= 0.6413
tm  [-1.1 -1.4  1.5 -2.  -1.3  0.1  0.  -1.4  0.3 -0.1  5.3  0.3  0.6 -0.4  8.7  3.4 -0.2 -0.2 -0.1  5.5 -0.1 -0.4 -0.5 -0.1 -1.5 -0.1  1.1 -0.3  0.1 -1.   6.2 -0.9  0.6  6.8 -0.7 -0.3 -1.   2.4 -2.6 -0.8 -0.3  2.5  1.7 -0.6 -0.8 -0.1 -3.  -0.6 -0.8 -0.6 -1.6 -1.3 -0.8  6.3 -1.1 -1.2  0.4  3.6  0.7 -1.2  7.5 -0.7  0.6  4.8 -0.4  2.1 -0.7  0.4 -0.5 -0.3 -0.1 -0.5 -0.7 -0.4 -3.4 -0.3  0.2 -0.3  4.7 -0.1 -0.2 -0.6  4.4 -0.6  0.5  6.1  0.1 -0.5 -0.1  0.2 -0.6 -0.6 -0.6 -1.1 -1.1  0.6  2.2 -1.8  0.5 -0.9  1.   3.4  4.5 -0.1 -0.9  0.5 -3.3  4.1  1.2  6.7 -0.5 -0.5 -0.3 -0.4  0.6  2.7  1.2  0.5 -0.9 -0.6 -0.6 -1.4  3.6  5.3 -0.8  9.4  0.8 -1.   3.7  3.5  4.3 -1.5 -0.5 -0.2  5.4 14.2 -0.5  1.7 -0.3 -1.5 -0.3  2.4  0.9  1.8 -0.6 -0.5  0.6  0.5  2.1  2.1  6.2 -0.4 -1.5 -0.2 -0.8 -0.6 -1.  -0.3 -0.4  0.4  2.8  5.1 -0.1 -0.5 -0.  -0.6  0.5  1.7  0.1 -0.9 -0.4  4.1 -0.7 -0.8 -0.8 -0.1 -1.9 -0.9 14.2  2.3 -0.6  0.9 -0.4 -0.9  0.9 -1.3 -1.1 -0.6 -1.4  1.  -0.3 -0.3  2.2 -1.3 -1.8  1.  -1.7 -0.2 -0.7 -0.5  2.1  3.9 -0.7 -0.8  3.  -2.5  2.6 -0.5 -2.5 -0.6 -0.2  1.2 -0.9  7.2  0.6 -0.2  4.2 -0.1  1.2 -0.4 -0.8  3.9 -0.8  0.1  5.   1.   0.8  1.6  1.2  0.8  0.5  0.8 -0.  -1.6  2.   0.5 -0.2 -1.9  2.  -2.9 -1.1 -2.1 -0.1 -0.7  2.1  2.2 -0.9  1.6 -0.3 -0.1  0.1 -0.4 -2.9 -0.1  3.3 -0.5]
ty_50sample [[6 1 5 4 2 2 3 0 8 8]
 [8 2 7 6 5 4 0 9 3 3]
 [3 3 1 4 8 2 2 5 0 0]
 [0 7 8 9 3 3 1 5 4 2]
 [4 5 6 0 7 9 8 3 2 1]
 [2 5 0 4 3 1 6 9 8 7]
 [2 1 5 5 6 6 0 4 3 9]
 [2 0 5 1 1 8 9 6 4 4]
 [8 9 1 1 5 2 6 0 4 3]
 [2 2 6 8 3 4 1 1 7 0]]
tt_50sample [[6 1 5 4 7 2 3 0 8 9]
 [8 2 7 6 5 4 0 9 1 3]
 [3 9 1 4 8 7 2 5 0 6]
 [0 7 8 9 6 3 1 5 4 2]
 [4 5 0 6 7 9 8 3 2 1]
 [2 5 0 4 3 1 6 9 8 7]
 [2 1 7 5 6 0 8 4 3 9]
 [2 3 0 5 1 8 9 6 4 7]
 [8 9 1 7 5 2 6 0 4 3]
 [9 5 2 6 8 3 4 1 7 0]]
vm  [-1.2 -0.2  0.7 -0.6 -1.1  1.3 -0.8 -0.8  2.4  0.5  4.4  0.9  1.8 -0.8  4.9 -0.  -0.9 -0.1 -0.3  5.9 -0.5 -0.6  0.8 -0.4 -0.6  3.2 -0.4 -0.3 -0.3 -1.6  0.8 -0.1 -0.5 -0.3  1.8 -0.6 -0.5  2.3 -2.2 -1.1 -0.6 -0.5 -0.8 -0.9 -1.   2.6 -3.  -1.1 -0.6 -0.3 -0.8 -1.5 -0.6  7.3 -0.2 -0.1  0.7  2.6  3.8  1.7  8.   0.9  1.5  6.7 -0.1  1.1 -0.2  0.9 -0.3  2.6  0.2  2.8  0.6  1.  -3.4 -0.6  0.2 -1.5  4.6  2.3 -1.4 -0.7  5.4 -0.6  1.1 -0.6 -0.6 -1.1 -0.5 -0.1 -0.1 -1.5 -0.5 -0.8 -0.8 -0.1  1.  -1.8 -0.7 -0.3 -0.6 -0.5  6.9  0.6 -0.5  0.2 -2.6  0.4  0.7  5.1 -0.6  2.5 -0.5 -0.6  5.4 -0.8 -0.1  1.5 -0.9  2.  -0.7 -1.7  2.   4.  -1.   4.4 -0.5 -1.3  2.7  5.1  2.2 -1.5 -1.  -0.6  8.1  7.1 -0.7  1.3  1.5 -0.4 -0.4 -0.2 -1.1 -0.4 -0.4 -0.7 -0.5  3.4  1.  -0.7  3.8 -0.2 -0.4 -0.  -0.5 -0.6 -0.1 -0.3 -0.  -0.1  2.9  1.3  0.5 -0.5 -0.9 -0.7  0.6  3.3 -0.4  0.6 -0.2  1.4  1.6 -0.8 -0.   0.7 -1.5 -0.3 11.2  3.   0.5 -0.6 -0.2 -1.   5.1 -1.  -1.  -0.3 -0.   6.2 -0.7  1.4  0.6 -0.7 -1.8  0.3 -1.4 -1.3 -0.9  2.3  0.1  5.4 -1.  -1.4  2.6 -2.5 -0.5 -0.2  4.1 -0.9 -0.6 -0.2 -1.2  5.6 -0.7 -0.5  5.9 -0.8 -0.5 -0.3 -0.4  0.9 -0.7 -0.8  3.3 -0.3  1.1  6.2  1.1  0.6  0.7  0.5 -0.6  2.3  4.9  1.4  1.1 -1.5  3.3 -0.5 -1.4 -0.3  0.7 -0.9  6.3  0.9 -0.9  2.8 -1.1 -0.8  0.7 -1.1 -1.8  1.1  0.3 -0.5]
vy_50sample [[1 6 0 2 3 8 4 5 7 9]
 [9 2 1 7 7 8 6 3 4 0]
 [4 1 3 0 5 7 2 8 6 9]
 [8 5 5 1 1 4 0 7 2 6]
 [2 4 0 9 5 7 6 8 3 1]
 [5 2 9 9 8 8 7 0 1 6]
 [7 0 0 3 9 6 8 2 5 4]
 [4 5 3 1 0 7 6 9 8 2]
 [8 9 0 1 1 4 3 6 2 5]
 [4 8 0 1 1 2 2 6 3 9]]
vt_50sample [[1 6 0 2 3 8 4 5 7 9]
 [9 2 5 1 7 8 6 3 4 0]
 [4 1 3 0 5 7 2 8 6 9]
 [8 3 5 1 9 4 0 7 2 6]
 [2 4 0 9 5 7 6 3 8 1]
 [5 3 2 9 8 4 7 0 1 6]
 [7 0 9 1 3 6 8 2 5 4]
 [4 5 3 1 0 7 6 9 8 2]
 [8 9 0 7 1 4 3 6 2 5]
 [4 8 0 5 1 2 6 7 3 9]]
Epoch  2510: Training cost= 0.6095, Training acc= 0.6413, Validation cost= 0.6517, Validation acc= 0.6417
Epoch  2520: Training cost= 0.5431, Training acc= 0.6417, Validation cost= 0.5973, Validation acc= 0.6421
Epoch  2530: Training cost= 0.5499, Training acc= 0.6421, Validation cost= 0.5707, Validation acc= 0.6425
Epoch  2540: Training cost= 0.6276, Training acc= 0.6425, Validation cost= 0.6867, Validation acc= 0.6429
Epoch  2550: Training cost= 0.5706, Training acc= 0.6429, Validation cost= 0.6198, Validation acc= 0.6433
Epoch  2560: Training cost= 0.5581, Training acc= 0.6433, Validation cost= 0.5497, Validation acc= 0.6437
Epoch  2570: Training cost= 0.6459, Training acc= 0.6437, Validation cost= 0.5967, Validation acc= 0.6441
Epoch  2580: Training cost= 0.5885, Training acc= 0.6441, Validation cost= 0.6162, Validation acc= 0.6445
Epoch  2590: Training cost= 0.5985, Training acc= 0.6445, Validation cost= 0.6005, Validation acc= 0.6449
Epoch  2600: Training cost= 0.5752, Training acc= 0.6448, Validation cost= 0.5599, Validation acc= 0.6453
tm  [ 1.8  0.3  2.3 -1.3 -1.6 -1.3 -0.7 -1.7 -1.3 -0.9 -0.2  0.1 -0.7 -0.6  6.8  5.1  0.6 -0.   1.1 -0.2  1.3  0.1  2.   0.  -1.5  0.1 -0.3 -0.6  3.9 -0.   3.8 -0.4  1.2  5.  -0.6  0.7  1.2 -0.  -0.5 -1.1 -0.1 -0.1  1.7  2.9 -1.2  0.7 -1.3  1.7  1.1  1.3 -0.9 -1.  -0.5  1.2 -1.2 -0.8 -0.6  1.7 -0.6 -0.4 -0.2  0.2 -0.9  0.1 -0.1 -0.1 -0.5 -0.4  1.7  1.5  1.1 -1.   1.  -0.2 -1.3  1.1 -0.5  0.3  4.  -0.1 -0.3 -0.5  1.6  0.7 -0.9  2.   3.3 -0.4  3.9 -0.6 -0.4 -0.5  0.4 -0.5 -0.2  1.7  0.4 -0.4 -0.1 -0.5  3.1  5.  -0.5  0.9  2.   0.9 -1.3  3.7 -0.1  0.4 -0.5 -0.9 -0.2  1.7 -1.3  5.2  1.3  0.6 -0.2 -0.4 -0.9 -0.3  0.2 -0.8 -0.5  7.7  1.8  1.3  0.2  2.4  6.  -0.5  2.4  0.6 -1.2  3.  -0.  -0.1 -0.3 -1.2  2.  -0.4  4.1  2.1 -0.7  3.8 -0.4 -1.2 -0.8  4.   4.6 -0.   3.   0.5 -0.8 -0.7 -1.5 -0.4 -0.6 -1.   0.6  1.6  1.2 -0.5  1.6 -0.4  3.1  1.4  2.4 -0.5  1.4  0.6 -1.2 -0.3 -0.7  4.  -0.7 -0.3  3.8  0.3  0.9  1.7 -0.6 -1.2 -0.6 -0.6  2.2 -0.7 -1.2 -1.1 -0.5 -0.9  0.7 -1.8  1.7 -0.1 -0.5  1.6 -0.6 -1.2 -0.3  0.9 -0.4 -1.  -0.3 -1.4 -0.1  0.4  1.8 -0.2 -0.5  2.9 -1.3  1.8  0.9 -0.  -0.2  0.   4.2  1.3 -1.7  1.7 -0.4 -0.3  1.7  5.2 -0.1 -0.5 -0.4  3.7 -0.7 -0.7 -0.7  1.6 -0.1  1.7  0.4 -0.4  3.8  0.2 -0.9  0.7 -0.  -0.2  3.6  0.3 -0.3  0.8 -0.  -0.4 -0.   0.4 -0.5 -0.7  2.   0.1]
ty_50sample [[7 4 6 6 3 5 2 9 1 1]
 [4 2 8 1 3 7 9 5 0 0]
 [4 9 5 5 7 2 0 8 3 3]
 [7 6 9 4 3 2 0 1 1 5]
 [4 8 0 9 1 1 6 5 3 7]
 [2 4 6 3 8 5 9 0 1 7]
 [8 6 3 3 1 4 4 2 2 5]
 [8 4 5 5 0 0 6 2 3 9]
 [3 5 4 0 2 9 6 6 1 8]
 [8 5 7 6 0 4 9 3 1 2]]
tt_50sample [[7 4 6 8 3 5 2 9 1 0]
 [4 2 8 1 3 7 9 6 5 0]
 [4 9 5 7 1 2 0 8 3 6]
 [7 6 9 4 3 2 0 1 8 5]
 [4 8 0 9 2 1 6 5 3 7]
 [2 4 6 8 3 5 9 0 1 7]
 [8 6 3 0 1 7 4 2 9 5]
 [8 4 1 5 0 7 6 2 3 9]
 [3 5 4 2 0 9 7 6 1 8]
 [8 5 7 6 0 4 3 9 1 2]]
vm  [ 0.6 -0.4  3.4 -0.7 -1.5 -1.6 -0.5 -1.3 -0.5 -0.7 -0.7  2.2 -1.4 -1.   7.8 -0.5  0.3  0.1  1.2  2.2  0.1 -0.1 -0.1  0.1 -1.1  0.1 -0.2 -0.4 -0.1 -0.4  3.7 -0.3  0.1  6.7 -0.4 -0.4 -0.2 -0.7 -1.3 -1.4 -0.5  1.6  2.4 -0.1 -0.8  1.8 -1.9  3.3  3.  -0.5 -1.4 -1.  -0.4 -0.3 -0.4 -1.  -0.2  4.3 -0.5 -0.3  1.1 -0.6 -0.2  2.1 -0.6  0.4 -0.3 -0.4  2.7  2.9 -0.1  0.7 -0.1 -0.5 -1.7 -0.  -1.  -0.1  2.8  0.3  0.7 -0.4  2.  -0.  -0.8  2.5  2.3 -0.6  2.9 -0.2 -0.4 -0.7  0.5 -0.4 -0.5  1.7  3.7 -1.2 -0.1 -0.5  2.2  4.1 -0.  -0.  -0.1  0.5 -1.8  3.6 -0.6  2.2  0.1 -0.1 -0.8  0.9 -0.1  1.2  0.7  2.1 -0.1  0.1 -0.7 -0.8  1.2  1.9 -0.8  7.7  3.2  3.4  1.2  3.3  5.7 -1.   1.1 -0.4  0.   9.2 -0.4  1.  -0.2 -1.   4.3 -0.3  4.3  2.6 -1.1  1.6 -0.8 -1.4  0.2  1.3  3.2 -0.   1.2  3.4 -0.8 -0.5 -1.1 -0.3 -0.5 -0.3  0.3  3.   2.2 -0.7  1.4 -0.3 -0.2  1.3  1.2 -0.3 -0.3  2.1 -0.9 -0.7 -0.1  3.1 -0.9 -0.3  7.8  5.3 -0.2  0.2 -0.6 -1.  -0.1 -1.1  2.1 -0.5 -0.9  0.3 -0.4 -0.3  0.6 -1.8  0.7 -0.  -0.4 -0.7 -0.4 -0.8 -0.3  1.9 -0.  -1.   0.6 -1.4  2.1 -0.3 -1.  -0.5 -0.8  1.4 -1.   1.3 -0.5 -0.5  3.5  0.7  3.8  0.8 -1.4  2.1 -0.  -0.2  2.2  1.3 -1.1 -0.7  0.6  4.5 -0.2 -0.2 -1.  -0.5  2.7 -0.7 -0.  -0.3  2.6 -1.1 -1.3 -0.6 -0.  -0.8  2.5  0.2 -0.5 -0.1 -0.1 -0.2 -0.3 -1.1 -1.  -0.7  4.7 -0.1]
vy_50sample [[7 6 5 3 3 0 0 9 9 2]
 [8 5 3 2 9 1 0 0 6 4]
 [8 5 9 3 1 1 2 0 7 4]
 [3 3 9 5 1 1 2 6 7 7]
 [9 4 6 1 8 0 3 7 5 2]
 [9 3 3 6 1 1 5 4 4 8]
 [4 7 3 3 5 9 6 6 2 0]
 [0 5 5 4 2 7 3 9 1 9]
 [7 1 5 6 2 2 9 3 0 4]
 [6 9 2 2 7 4 4 0 8 1]]
vt_50sample [[7 6 5 3 4 0 1 8 9 2]
 [8 5 3 9 2 1 0 7 6 4]
 [8 5 9 3 1 6 2 0 7 4]
 [3 8 9 0 5 1 6 2 4 7]
 [9 4 1 6 8 0 3 7 5 2]
 [9 3 2 1 6 7 5 4 0 8]
 [4 7 3 1 9 5 8 6 2 0]
 [0 6 5 4 2 7 3 9 1 8]
 [7 5 1 6 2 8 9 3 0 4]
 [6 9 3 2 7 4 5 8 0 1]]
Epoch  2610: Training cost= 0.5850, Training acc= 0.6453, Validation cost= 0.5917, Validation acc= 0.6457
Epoch  2620: Training cost= 0.6959, Training acc= 0.6456, Validation cost= 0.7998, Validation acc= 0.6460
Epoch  2630: Training cost= 0.6058, Training acc= 0.6459, Validation cost= 0.5983, Validation acc= 0.6463
Epoch  2640: Training cost= 0.5902, Training acc= 0.6463, Validation cost= 0.6337, Validation acc= 0.6467
Epoch  2650: Training cost= 0.5528, Training acc= 0.6466, Validation cost= 0.6159, Validation acc= 0.6471
Epoch  2660: Training cost= 0.5750, Training acc= 0.6470, Validation cost= 0.5873, Validation acc= 0.6475
Epoch  2670: Training cost= 0.5902, Training acc= 0.6474, Validation cost= 0.5618, Validation acc= 0.6478
Epoch  2680: Training cost= 0.5612, Training acc= 0.6478, Validation cost= 0.5844, Validation acc= 0.6482
Epoch  2690: Training cost= 0.6257, Training acc= 0.6481, Validation cost= 0.6143, Validation acc= 0.6486
Epoch  2700: Training cost= 0.5460, Training acc= 0.6485, Validation cost= 0.6327, Validation acc= 0.6489
tm  [-1.4 -0.2 -0.3 -0.6 -0.3 -0.4 -0.6 -0.6  4.3  1.1 -2.   2.2 -1.5 -0.5  2.  -1.1 -0.8 -0.5 -0.7  4.4 -0.6 -0.2  2.3 -0.7 -0.1  0.  -0.3 -0.5 -0.2 -1.6  0.3 -0.7 -0.8 -1.7 -0.2 -2.2 -1.1  2.4 -0.2 -1.4 -0.3  2.6  0.8  1.8 -0.9  3.  -2.1  1.2  0.2  2.7 -0.5 -1.2 -0.8 -0.  -0.7  0.8  2.2  4.2  5.   2.9  5.6 -1.7  2.8  3.2 -0.6  0.1 -0.4  0.1  1.8  1.6  1.1  0.3  1.1 -0.1 -3.9 -0.1 -0.4 -1.   3.1  1.6 -1.9 -0.5  2.7 -0.4  0.1  4.4 -0.2 -0.9  1.8  0.  -0.1 -1.4 -0.9 -0.6 -0.8 -0.3  2.1 -1.8 -0.3  0.8 -0.7 -0.6  5.3 -0.2 -0.8 -0.6 -2.6 -0.3 -1.2  2.9  2.2  1.1 -0.3 -1.   5.6 -0.2  0.4  3.  -0.3  4.4 -0.5 -1.5 -0.3  0.3 -0.6  2.9  0.6  2.   7.1  3.7 -0.2 -0.8 -0.5 -0.6  3.5 -1.4 -0.2 -0.7 -0.2 -0.5  3.3  0.2  2.1 -0.5 -1.5 -0.  -0.4 -0.5  5.4 -0.7  3.9 -0.3  1.5  3.8 -0.7 -0.1 -0.5 -0.4  2.8 -0.2  0.5 -0.8  1.3 -0.5 -1.1  0.5 -0.2  2.6 -0.4  0.1  2.5  3.4 -0.5 -0.8 -0.3 -1.3 -0.6 -0.5  4.   4.1 -1.  -0.6 -0.8 -0.7  4.  -0.5 -0.7  0.9 -0.1  8.6 -0.6 -0.2 -0.7 -1.6 -1.1 -0.9 -1.2 -1.7 -0.5 -0.7 -0.2  5.8 -0.3 -1.6  1.5 -2.   1.7 -0.5  0.2 -0.8 -0.5  0.8 -0.8  4.5 -0.9  0.4  0.6 -0.3 -0.2 -0.  -1.3  0.6  0.   0.4  0.6  1.4 -1.5  2.2 -0.4  4.8 -1.1  0.5 -0.7 -0.2  3.8  3.8  1.4 -1.7  2.6 -2.4 -0.5 -1.6  1.4 -1.1  7.9 -0.1 -0.8 -0.5 -0.9 -0.6  1.6 -1.1 -0.1 -0.7  6.5 -0.4]
ty_50sample [[5 8 8 3 3 4 6 7 9 2]
 [2 4 5 8 1 7 7 9 3 0]
 [4 0 1 6 3 5 7 2 9 8]
 [3 2 9 9 6 5 7 7 4 0]
 [4 4 1 9 7 7 8 0 0 5]
 [1 1 9 4 3 3 7 5 2 0]
 [2 0 9 3 5 4 6 7 1 8]
 [7 6 4 4 1 9 2 5 0 3]
 [6 8 3 4 1 5 2 0 9 7]
 [3 5 1 1 2 8 7 7 4 4]]
tt_50sample [[5 1 8 3 0 4 6 7 9 2]
 [2 4 5 8 1 7 6 9 0 3]
 [4 0 1 6 3 5 7 2 9 8]
 [3 2 9 6 8 5 1 7 4 0]
 [6 4 1 9 2 7 8 0 3 5]
 [1 6 4 9 8 3 7 5 2 0]
 [2 0 9 3 5 4 6 7 1 8]
 [7 6 4 1 8 9 2 0 5 3]
 [6 8 3 4 1 5 2 0 9 7]
 [5 3 1 0 2 8 7 6 4 9]]
vm  [ 4.3  0.6  8.1  8.3 -1.9 -2.1 -0.5 -1.3 -1.  -0.9 -0.5  0.6 -0.3 -0.   5.   3.7  1.5 -0.5  2.9 -1.4 -0.1 -0.3 -0.2  0.  -1.4 -1.1 -0.3 -0.5  0.6 -0.3 -1.1 -0.6 -0.3  4.4 -1.   0.5  3.4  0.5  3.1 -1.2 -0.  -0.4  3.  -0.4 -0.6 -0.3  0.2  2.7  3.4 -0.6 -0.6 -0.1  0.5  0.4 -0.9 -0.3 -0.8  5.9 -1.2  6.2 -1.  -0.4 -1.2 -0.  -0.7 -0.2 -1.5 -0.9  0.7  1.6  2.  -0.4 -0.  -0.8 -0.3  1.7 -0.6 -0.7 -1.  -0.   0.5 -0.4 -1.1  0.7 -1.4  0.2  1.2 -0.3  7.5  0.5 -1.   1.9  1.3  3.6 -0.  -0.4  4.7  0.3  1.1 -0.1  6.   1.9 -0.4 -0.7  1.   0.8 -0.6 -1.1 -0.  -1.6  2.6 -1.1 -0.8 -0.4 -1.3  3.   1.8  0.6  0.8 -0.7 -0.   2.8 -0.7 -1.5 -0.3  5.6  2.   1.2 -0.2  4.1  2.1 -0.3  0.9  2.3 -1.4 -0.3 -0.4 -0.   0.6 -0.5 -0.4 -0.7 -0.2 -0.4 -0.4  1.  -1.3 -2.1 -0.   1.8 -1.1 -0.   4.1 -0.4 -1.3 -1.1 -0.6  0.9 -0.5 -1.1 -0.9 -0.  -0.3 -0.1  1.5 -0.4  2.2  0.3 -0.5  3.7 -0.2  1.2 -1.2  0.4 -0.4  3.2 -0.1 -1.1 -0.1 -1.  -0.6 -0.1 -0.3 -1.   0.6 -0.4  2.5 -1.  -0.5  3.2 -0.3  0.1 -0.3 -1.4  5.6 -0.5 -0.4  1.5 -0.8 -0.7 -0.3 -1.  -0.2 -0.7 -1.3 -1.1  0.3  1.  -0.3  0.2 -1.   1.3 -0.9 -0.7 -0.8  1.3  3.1 -0.3  2.7 -0.3 -1.2 -0.   2.1 -0.1 -0.4  4.3 -0.6 -1.  -0.6  5.7 -1.   0.7 -0.6  1.   0.2 -2.  -0.4 -0.5 -0.2 -0.1 -0.5 -0.1 -0.2  0.1  1.7 -0.  -0.5  0.2 -0.1 -0.3  0.2 -1.3  2.6 -0.6  5.1 -0.9]
vy_50sample [[3 7 5 8 9 2 2 0 4 1]
 [4 8 6 6 5 5 3 7 0 1]
 [3 2 7 6 1 1 5 8 0 4]
 [1 6 5 3 9 9 2 7 4 4]
 [1 4 2 6 6 0 7 3 9 9]
 [4 8 0 3 2 2 6 6 1 7]
 [6 9 2 5 5 4 4 1 0 0]
 [7 8 9 9 3 2 2 0 5 4]
 [3 8 2 6 0 9 4 4 5 7]
 [2 9 5 0 0 3 7 4 6 6]]
vt_50sample [[3 7 5 8 9 6 2 0 4 1]
 [4 8 2 6 5 9 7 3 0 1]
 [3 2 7 6 9 1 5 8 0 4]
 [6 1 5 3 9 0 2 7 8 4]
 [1 4 2 6 5 0 7 3 8 9]
 [4 8 0 5 3 2 6 9 1 7]
 [6 9 2 3 5 4 8 7 1 0]
 [8 7 9 6 1 3 2 0 5 4]
 [3 8 2 6 9 0 4 1 5 7]
 [2 9 5 0 7 8 3 1 4 6]]
Epoch  2710: Training cost= 0.5772, Training acc= 0.6489, Validation cost= 0.5439, Validation acc= 0.6494
Epoch  2720: Training cost= 0.5991, Training acc= 0.6493, Validation cost= 0.5886, Validation acc= 0.6498
Epoch  2730: Training cost= 0.5915, Training acc= 0.6496, Validation cost= 0.6124, Validation acc= 0.6501
Epoch  2740: Training cost= 0.5622, Training acc= 0.6500, Validation cost= 0.6220, Validation acc= 0.6505
Epoch  2750: Training cost= 0.6063, Training acc= 0.6503, Validation cost= 0.5606, Validation acc= 0.6508
Epoch  2760: Training cost= 0.5364, Training acc= 0.6507, Validation cost= 0.5614, Validation acc= 0.6512
Epoch  2770: Training cost= 0.5283, Training acc= 0.6512, Validation cost= 0.5852, Validation acc= 0.6517
Epoch  2780: Training cost= 0.5798, Training acc= 0.6516, Validation cost= 0.6170, Validation acc= 0.6521
Epoch  2790: Training cost= 0.4777, Training acc= 0.6520, Validation cost= 0.5816, Validation acc= 0.6525
Epoch  2800: Training cost= 0.5887, Training acc= 0.6524, Validation cost= 0.6119, Validation acc= 0.6528
tm  [-0.4 -1.  -0.8 -1.  -0.6  0.7 -1.1 -0.5  0.1  0.7  6.3 -0.5  2.5 -0.7 -0.1 -0.2 -0.1 -0.5 -0.5  2.  -0.2 -0.4  0.6 -0.3 -1.1  0.8 -0.4 -0.3 -0.7 -1.6  3.1 -0.6  1.4 -0.5  4.2 -0.4  1.   1.3 -2.4 -1.4 -0.6  5.1  0.6 -0.8 -0.7 -0.  -2.  -1.  -0.   1.2 -0.7 -1.4 -1.2  7.  -0.2  1.3 -0.3  1.4  3.5 -0.1  4.  -0.4  0.8  6.5 -0.3 -0.1  0.5  4.  -0.2 -0.3 -1.   3.  -0.7 -0.5 -3.5 -0.2 -0.2 -0.3  4.4  0.7 -0.3 -0.3  1.2 -0.6 -0.4  3.9 -0.1 -0.6 -0.5 -0.6 -0.4 -1.  -0.9 -0.2 -0.8 -0.1  1.5 -1.5 -0.3 -0.6 -0.8 -0.   3.1 -0.9 -0.3  0.4 -2.5  3.1  3.1  3.1 -1.   3.8 -0.5 -0.5  6.1 -0.8 -0.5  0.2 -0.8  1.3 -0.3 -0.7  3.   3.8 -0.8 -0.2 -0.6 -1.3  3.5  1.1  2.8 -1.4 -1.  -0.3 12.  12.2 -1.1 -0.1 -0.7 -0.6 -0.4 -0.2 -0.6  0.6 -0.5 -0.8  0.6  1.3  4.9 -0.2  4.6  0.1 -0.7 -0.  -0.4 -0.6 -0.1 -0.2 -0.9 -0.3  4.1  2.7 -0.4 -1.  -0.8 -0.6 -0.7 -0.4 -0.2 -0.5  1.3  2.8  0.1 -0.3 -0.3 -1.5 -1.7 -0.5 11.8  1.7 -1.1 -0.3  0.7 -0.5  3.9 -0.8 -0.4  0.6 -0.1  5.8 -0.4 -0.1  1.5 -0.8 -0.7 -0.2 -1.4 -1.1 -0.4  2.5 -0.1  4.4 -0.7 -0.9  1.8 -2.2  1.4  0.  -1.4 -0.5 -0.3 -0.8 -1.1  4.   0.7 -0.7  5.1 -0.5 -1.1 -1.1  2.1 -0.1 -0.5 -0.7  5.1 -1.1  0.5  3.9  1.   2.2  0.6  0.5 -0.4 -1.   6.4  4.6  3.5 -1.6  1.2 -1.9 -1.4 -1.  -0.1 -1.1  2.5  0.2 -0.5  1.8 -0.6 -0.1 -0.  -0.3 -2.2  2.  -0.2  1. ]
ty_50sample [[6 0 2 1 4 4 8 8 9 7]
 [6 6 4 9 8 8 7 1 1 3]
 [3 0 5 7 2 1 4 6 9 8]
 [0 8 4 3 6 9 9 5 2 1]
 [7 4 0 5 5 1 8 6 2 9]
 [5 0 6 8 9 9 4 3 7 1]
 [6 7 0 1 8 2 5 9 9 4]
 [0 9 4 4 1 8 3 5 6 7]
 [8 2 5 5 7 7 1 1 4 0]
 [7 9 6 4 4 1 1 5 0 2]]
tt_50sample [[0 6 2 5 1 4 8 3 9 7]
 [6 2 0 4 9 8 7 5 1 3]
 [3 0 5 7 2 1 6 4 9 8]
 [0 8 4 3 6 7 9 5 2 1]
 [7 0 4 3 5 1 8 6 2 9]
 [5 0 6 2 8 9 4 3 7 1]
 [6 7 0 1 8 2 5 3 9 4]
 [0 9 2 4 1 3 8 5 6 7]
 [2 8 5 9 7 6 1 4 3 0]
 [7 8 6 9 4 1 3 5 0 2]]
vm  [-0.3 -0.6  4.2 -0.3 -1.8 -0.5 -0.3 -1.3 -0.9  0.5  0.1  1.7 -0.8 -1.1  8.4 -1.4 -0.4 -0.1  2.3  1.5 -0.  -0.9  0.1  0.7 -0.9  2.8 -0.3 -0.2 -1.  -0.9  3.5  2.2 -0.3  8.1  0.7 -0.3  0.9 -0.6 -1.3 -1.  -0.7  2.7  1.1 -0.4 -1.5  0.5 -2.   1.9  1.2 -0.1 -1.5 -1.  -0.6  0.1  0.5 -1.  -0.6  1.1 -0.3 -0.1  4.2  0.2 -0.1  4.2 -0.4  0.7  0.3 -0.6  2.4  3.2 -0.6  4.5 -0.2 -0.3 -1.8 -0.4  0.5 -0.6  5.1 -0.   1.8 -0.2  1.7 -0.1 -0.3  2.7  0.8 -0.9 -0.  -0.1  0.3 -0.5 -0.6 -0.5 -0.5  1.   3.8 -1.  -0.3 -0.6 -0.1  5.6  3.  -0.2  0.3  0.7 -1.9  3.6 -0.1  2.5 -0.2  0.3 -0.4  0.4  4.2 -0.9 -0.3  2.3 -0.8 -0.1 -0.3 -0.4  0.9  3.9 -0.9  7.4  2.3  2.5 -0.2  1.7  2.1 -1.2 -0.7 -0.1 -0.1  9.5 -0.4  0.1 -0.1 -1.1  3.1 -0.6  1.5  1.7 -0.9 -0.5 -0.3 -0.8 -0.5 -0.1  2.6 -0.3 -0.5  2.6 -0.7 -0.7 -0.5 -0.5 -0.2 -0.2  1.8  2.4  0.6 -0.9  0.2 -0.7 -0.8  1.5 -0.  -0.4 -0.3  1.3 -0.4 -0.5 -0.2  4.6 -0.8 -0.3  7.3  4.3 -0.3 -0.3 -0.2 -1.2  1.6 -1.3  0.5 -0.6  1.3  2.3 -0.6 -0.4  0.7 -1.3 -0.6  1.2 -0.6 -0.5 -0.7  0.3 -0.5  1.6 -0.6 -0.7  2.7 -1.7  1.  -0.3 -0.6 -0.4 -0.6 -0.5 -0.8  3.5 -0.4 -1.   3.5 -0.1  1.7  0.1 -1.   1.9 -0.2 -0.6  3.2 -0.9 -0.9  0.4  1.7 -0.   0.   0.9 -0.8 -0.5  6.7 -1.1  2.4 -0.5  2.6 -0.5 -1.5 -0.3 -0.4 -0.9  1.3  1.2 -0.6  1.6 -0.2 -0.2 -0.5 -0.9 -1.1 -0.4  2.6  1.3]
vy_50sample [[0 7 6 1 4 4 3 9 8 2]
 [7 4 2 2 3 3 9 9 5 1]
 [0 2 7 7 9 9 1 4 8 6]
 [0 7 1 5 2 6 3 8 4 9]
 [1 1 8 4 3 0 0 7 6 9]
 [3 1 5 2 2 4 6 0 7 7]
 [6 9 2 2 1 1 8 5 3 4]
 [7 5 3 0 2 9 9 4 8 1]
 [1 9 5 5 3 6 4 7 0 2]
 [3 6 6 9 9 4 7 7 5 2]]
vt_50sample [[0 7 6 1 5 4 3 8 9 2]
 [7 4 6 2 3 0 8 9 5 1]
 [0 3 2 7 9 5 1 4 8 6]
 [0 7 1 5 6 2 3 8 9 4]
 [1 2 8 5 4 3 0 7 6 9]
 [3 1 5 2 9 4 6 0 8 7]
 [6 9 2 7 1 0 8 5 3 4]
 [7 5 3 0 2 6 9 4 8 1]
 [1 9 8 5 3 6 4 7 0 2]
 [3 8 6 9 0 4 7 5 1 2]]
Epoch  2810: Training cost= 0.5339, Training acc= 0.6528, Validation cost= 0.5531, Validation acc= 0.6532
Epoch  2820: Training cost= 0.6092, Training acc= 0.6532, Validation cost= 0.5025, Validation acc= 0.6536
Epoch  2830: Training cost= 0.5678, Training acc= 0.6535, Validation cost= 0.5440, Validation acc= 0.6540
Epoch  2840: Training cost= 0.5937, Training acc= 0.6539, Validation cost= 0.5488, Validation acc= 0.6544
Epoch  2850: Training cost= 0.5438, Training acc= 0.6543, Validation cost= 0.5562, Validation acc= 0.6548
Epoch  2860: Training cost= 0.5374, Training acc= 0.6547, Validation cost= 0.5875, Validation acc= 0.6551
Epoch  2870: Training cost= 0.5094, Training acc= 0.6550, Validation cost= 0.5164, Validation acc= 0.6555
Epoch  2880: Training cost= 0.5308, Training acc= 0.6554, Validation cost= 0.5984, Validation acc= 0.6559
Epoch  2890: Training cost= 0.5413, Training acc= 0.6558, Validation cost= 0.5091, Validation acc= 0.6563
Epoch  2900: Training cost= 0.5968, Training acc= 0.6561, Validation cost= 0.5718, Validation acc= 0.6566
tm  [-0.5  1.4  4.  12.9 -0.5 -1.2 -0.3 -0.5  1.5 -0.6 -1.7  0.9 -0.4  0.  -1.1  4.2 -0.7 -0.   0.5 -0.6 -0.7  0.6  3.3 -0.7 -0.8 -0.4 -0.5 -0.4  2.9 -0.8 -1.6 -0.5 -0.9 -1.8 -0.5 -1.1 -0.8  5.8  9.4 -0.8  0.8 -0.7 -1.3  1.3 -0.8 -0.2  5.8  0.7  1.5  2.9 -0.7 -0.2  4.2 -1.3 -0.7  5.2  1.4  4.2  2.   6.5 -0.8 -0.4  2.4  2.4 -0.9 -0.9 -0.7 -0.6  0.4  2.1  1.5 -0.7  4.4  2.2  1.  -0.1 -0.4 -0.7 -0.4 -0.2  1.9 -0.2 -0.7 -0.6 -0.5 -0.2 -0.4 -0.6  2.6  0.1  0.6 -0.7  0.4 -0.4  3.5 -1.   2.2 -0.4 -1.3  0.3  0.6 -0.6 -0.2 -0.  -0.2 -0.6  1.7 -2.1 -1.  -1.   2.5 -0.5 -0.6  0.6 -0.5  3.6 -0.2  1.2  0.2  3.  -0.5  2.8 -1.  -1.   1.2 -1.3  0.6  6.   3.6  0.4  0.  -0.4  0.  -0.7 -1.  -4.2  1.4 -0.8 -0.4  2.1 -0.3 -0.5  0.2 -0.7 -0.6  3.3 -0.7 -0.9 -0.  -0.2 -1.5 -0.4  4.9  0.5 -0.6 -0.3 -1.  -0.6  3.2  0.2 -0.3 -1.6 -0.  -0.3 -1.1 -0.5  3.   3.2 -0.3  6.5  0.5 -0.8 -0.6 -0.8 -0.3  2.7 -0.   3.8 -2.1 -0.3  1.6 -0.6 -0.8 -0.8 -0.2 -0.   2.7 -0.2 -0.3  5.4 -0.2 -0.2 -1.7 -1.5  5.3 -1.2  6.  -0.9 -0.7 -0.6 -0.8  0.9 -0.6 -1.6 -0.8  3.8 -1.5  1.   7.8 -1.  -0.3  4.2 -1.3  1.2 -1.7 -0.3  1.4 -0.3  0.5  0.7 -1.5 -0.5 -0.7 -0.2 -0.3  4.8 -1.   3.7 -0.6  3.7 -1.2 -1.3 -1.2  5.  -0.4 -0.7  1.3  3.6  2.  11.5 -0.3  5.9 -0.5 -0.4  1.3 -1.8 -0.  -0.  -0.6 -1.6 -0.4 -0.7  9.7  1.3  3.2  2.5]
ty_50sample [[9 9 3 3 2 1 5 0 4 4]
 [4 6 7 0 0 8 9 9 3 5]
 [4 8 7 9 0 3 5 1 2 2]
 [2 6 0 0 4 5 8 3 9 1]
 [6 8 2 9 1 1 0 7 4 5]
 [9 4 7 0 0 3 6 1 1 5]
 [7 8 8 4 6 1 3 5 0 9]
 [0 9 4 4 3 2 2 5 5 8]
 [7 9 1 8 9 5 0 3 2 4]
 [8 6 6 3 2 1 4 0 5 7]]
tt_50sample [[8 9 3 7 2 1 5 4 6 0]
 [4 6 7 1 0 2 8 9 3 5]
 [4 8 7 9 0 3 5 1 6 2]
 [2 6 0 7 5 4 8 3 9 1]
 [6 8 2 9 1 3 7 0 4 5]
 [9 4 7 0 3 8 6 2 1 5]
 [7 2 8 4 6 3 1 5 9 0]
 [0 9 4 7 3 6 2 5 1 8]
 [7 1 9 6 8 5 0 3 2 4]
 [9 8 6 3 2 1 4 0 5 7]]
vm  [ 2.   0.7  6.7  4.7 -1.5 -1.8 -0.6 -1.2 -0.7  0.  -2.7  2.1 -1.5 -1.1  5.6 -0.6 -0.2  1.2  1.6 -0.  -0.3  0.2  3.1 -0.3 -0.6 -0.6 -0.6 -0.2  0.3 -0.4 -0.9  0.8 -0.5  1.7  1.5 -1.1  0.2 -0.2  3.2 -1.   0.2  1.5 -0.4  1.2 -1.3  0.9 -0.2  3.3  5.4  3.9 -0.9 -0.8 -0.2 -1.1 -0.1 -0.6 -0.4  1.8  0.5  5.9 -0.6 -0.6 -0.1  1.7 -0.7 -1.  -0.4 -1.4  3.   2.3  1.8  1.   3.5 -0.2 -1.7  0.1 -0.5  0.7  0.2 -0.3 -1.   0.  -0.1  0.  -1.2  0.6  1.7 -0.7  2.4 -0.1 -0.1 -0.9 -0.8 -0.1 -0.  -0.5  1.9 -0.8 -0.3 -0.  -0.3  4.8 -0.3 -0.2  0.7 -0.4 -0.8 -1.1 -1.6 -0.3  2.5 -0.4 -0.7 -0.3 -0.  -0.2  0.4  3.4  0.6  1.8 -0.3 -0.  -0.9 -1.1 -0.2  5.7  0.6  5.3  1.1  1.4  2.4 -0.4  1.  -0.2 -2.4 -2.6  0.4 -0.8 -0.8  0.   2.6 -1.   3.9  0.6 -1.2  3.7 -1.2 -2.  -0.7 -0.2 -0.3 -0.1  6.8  3.2 -0.6 -0.2 -1.  -0.3  0.5 -0.7 -0.  -0.9  2.3 -0.7  1.2 -0.1 -0.3  1.1 -0.1  2.   1.1 -0.2 -0.7 -0.3 -0.3  5.5 -0.1 -0.1 -0.1  3.9  1.3 -0.5 -0.3 -0.8  1.4 -0.3  3.1 -0.9 -0.2  2.4  0.1 -0.5 -0.6 -1.6  4.9 -0.9  0.3 -1.  -0.4 -0.4 -0.9  0.7 -0.  -0.7 -0.7 -0.6 -1.   0.1  6.1 -0.5 -0.5  0.8 -1.1 -0.3 -0.9 -0.2  1.7 -0.   3.1  0.9 -2.1 -0.4  0.3 -0.4 -0.2  2.2 -1.7 -0.5 -0.6  5.3 -0.9 -0.3 -1.   4.6  1.8 -1.8  2.9 -0.4  2.2  3.8 -0.8  2.1  0.1 -0.2  5.6 -0.7 -0.6 -0.2 -0.4 -0.4  2.3 -0.8  3.6 -1.   3.8  1.1]
vy_50sample [[7 8 9 0 3 5 6 4 1 2]
 [3 1 2 7 4 9 8 6 0 5]
 [9 8 7 5 1 2 2 3 4 6]
 [8 8 3 5 5 1 0 0 6 2]
 [4 9 5 6 7 2 1 3 0 8]
 [0 0 9 6 1 4 3 2 8 5]
 [2 2 5 4 4 7 3 8 6 0]
 [0 3 5 5 6 8 8 1 4 2]
 [3 7 2 4 8 5 0 1 6 9]
 [4 8 2 7 5 1 3 9 9 0]]
vt_50sample [[7 8 9 0 3 5 6 4 2 1]
 [3 1 2 7 4 9 8 6 0 5]
 [9 8 7 5 1 2 0 3 4 6]
 [8 3 4 7 5 1 9 0 6 2]
 [4 9 5 6 7 2 1 3 0 8]
 [0 9 7 1 6 4 3 2 5 8]
 [2 9 1 5 4 3 7 6 8 0]
 [0 7 3 5 6 8 1 9 4 2]
 [3 2 7 4 8 5 0 1 6 9]
 [4 8 2 7 5 3 6 1 9 0]]
Epoch  2910: Training cost= 0.5640, Training acc= 0.6565, Validation cost= 0.6808, Validation acc= 0.6569
Epoch  2920: Training cost= 0.5490, Training acc= 0.6568, Validation cost= 0.5542, Validation acc= 0.6573
Epoch  2930: Training cost= 0.6125, Training acc= 0.6571, Validation cost= 0.5364, Validation acc= 0.6576
Epoch  2940: Training cost= 0.5895, Training acc= 0.6575, Validation cost= 0.5561, Validation acc= 0.6580
Epoch  2950: Training cost= 0.5516, Training acc= 0.6578, Validation cost= 0.6092, Validation acc= 0.6583
Epoch  2960: Training cost= 0.6295, Training acc= 0.6581, Validation cost= 0.6347, Validation acc= 0.6586
Epoch  2970: Training cost= 0.5810, Training acc= 0.6584, Validation cost= 0.5802, Validation acc= 0.6589
Epoch  2980: Training cost= 0.5301, Training acc= 0.6588, Validation cost= 0.5619, Validation acc= 0.6592
Epoch  2990: Training cost= 0.5492, Training acc= 0.6591, Validation cost= 0.5450, Validation acc= 0.6596
Epoch  3000: Training cost= 0.5810, Training acc= 0.6595, Validation cost= 0.6616, Validation acc= 0.6599
tm  [ 0.2 -0.1 -1.9 -1.2 -0.5 -0.3 -0.7 -0.5 -0.8 -0.1  1.2 -0.2  0.9 -0.7 -0.9  3.  -0.1 -0.1 -1.1  0.1 -0.5 -0.4  3.7  0.5 -1.   2.4 -0.3 -0.4  0.2 -0.6  3.7 -0.2  1.7 -2.   3.   0.3  1.3  0.3 -1.2 -1.4 -0.5  2.1  0.   1.6 -0.6  1.3 -0.5 -0.4  1.4  4.9 -0.3 -1.5 -0.8  2.5 -0.8  3.3  0.4 -0.   1.5 -0.3  0.8  1.1  0.8  2.  -0.2 -0.  -0.1  2.4  0.4  0.9 -0.7 -0.1  1.6 -0.2 -1.8 -0.2  0.7  0.3  5.2 -0.5 -0.4 -0.6  1.  -0.3 -0.6  1.4  1.8 -0.2 -0.5 -0.4 -0.5 -1.  -0.5 -0.6 -0.2  0.5 -0.5 -1.1 -0.6 -0.4 -0.9  0.  -0.2  0.4  0.9  0.5 -1.   3.5  0.5 -0.2 -1.4  2.9 -0.1 -0.2  1.5  0.1 -0.3  0.2 -0.2  0.6 -0.4 -0.3  1.4 -0.2 -0.6 -0.9 -0.4 -0.   2.  -0.1  5.7 -1.1  0.2 -0.9 11.6  6.4 -0.4 -0.6 -0.3 -0.6 -0.1 -0.5  1.5  2.2 -0.7  3.7 -0.2  1.2  2.2  2.5  4.3  1.4  2.2 -0.3 -0.2 -0.3 -0.5 -0.7 -1.  -0.1  4.   2.9 -0.3 -1.4 -1.5 -0.3  0.8  1.4  1.9 -0.4  2.5 -0.1 -0.1  0.4  0.2 -0.4 -1.1  0.6  7.4  0.7  0.4  0.1 -0.2 -0.9  1.3 -0.1  1.4  1.  -0.3  1.1 -0.2 -0.6 -0.4 -1.5  1.7 -0.  -0.1 -0.6 -0.4 -0.1 -0.3  4.4 -0.6 -1.1  0.5 -1.3 -0.6  2.2  4.9 -0.4  0.2  1.3 -1.9  2.8  1.7 -0.6  1.5 -0.2 -0.7 -0.4 -0.1 -0.6 -0.8 -0.8  4.9  1.1  0.   1.9 -0.5  4.   1.1 -0.8 -0.9  3.3  3.2  8.8  4.1 -0.3  4.3  4.3 -1.1  2.2 -0.1 -0.6  3.5 -0.6 -0.1  2.4 -0.7 -0.3 -0.2  1.1 -1.1  0.9 -0.1  3.5]
ty_50sample [[4 4 8 2 0 9 1 5 3 7]
 [0 9 9 1 7 3 5 4 8 2]
 [7 8 3 6 2 2 5 0 0 9]
 [7 2 9 4 5 6 3 1 0 0]
 [6 2 1 1 5 8 9 7 0 3]
 [7 9 2 3 8 0 4 6 5 1]
 [2 0 9 6 3 8 4 5 5 7]
 [8 8 0 7 5 5 4 3 1 6]
 [4 8 8 6 9 3 0 7 2 1]
 [2 4 8 5 7 3 6 1 0 0]]
tt_50sample [[4 6 8 2 9 0 1 5 3 7]
 [0 9 6 1 3 7 5 4 8 2]
 [7 8 3 6 4 2 5 1 0 9]
 [7 2 9 4 5 6 3 1 0 8]
 [6 2 1 4 5 8 9 7 0 3]
 [7 9 2 3 8 0 4 6 5 1]
 [2 0 9 6 3 8 4 5 7 1]
 [2 8 0 9 7 5 4 3 1 6]
 [5 4 8 6 9 3 0 2 7 1]
 [2 4 8 5 7 3 6 1 9 0]]
vm  [ 0.7 -1.  -0.7 -2.9 -1.3 -1.  -0.1 -1.2  0.  -1.   2.7  1.3 -0.9 -1.   8.   2.8 -0.1 -0.4 -0.1  5.1 -0.2  0.8 -0.7 -0.2 -1.  -0.1 -0.  -0.2  2.  -0.7  7.1 -1.2 -0.1  6.7  0.1 -0.3 -0.8  0.6 -1.2 -1.3  0.2  1.5  1.3  4.7 -0.8  0.6 -2.2  0.3  1.5 -1.  -1.7 -1.7 -0.6  3.4 -0.7 -1.  -0.1  3.8  1.1 -1.9  2.1 -1.2  1.1  3.9 -0.1  0.6 -0.3  2.8  2.   0.9 -0.2 -0.8 -0.6 -0.2 -3.6  0.2 -1.2  0.9  3.3 -0.  -0.1 -0.6  3.7  0.5 -0.7  3.2  3.2 -0.2  2.5 -0.1 -0.9 -1.  -0.5 -0.8 -0.7  2.   0.1 -1.7 -0.  -0.5  0.4  2.5 -0.2 -0.4 -0.  -0.5 -2.8  7.7  1.3  3.9 -0.1 -0.2 -0.3 -1.   0.7  1.6  1.   4.6 -0.1  0.6 -0.2 -1.3 -0.1  0.1 -1.   8.8 -0.3 -0.1  4.4  4.2  4.3 -0.8  1.6 -0.3 -0.4  6.4 -0.2  1.3 -0.  -0.9  0.4  0.5  4.   1.6 -0.9  2.1 -0.8 -1.   1.   0.3  7.3  0.2  2.   1.  -0.5 -0.6 -1.4 -0.6 -0.1 -0.   1.6 -0.1  1.3 -0.8  2.1 -0.3  0.6  1.2  1.8 -1.4 -0.2  3.1 -0.7 -0.3 -1.   0.  -0.5 -0.9  7.1  2.2 -0.6 -0.  -1.3 -1.   1.8 -1.   1.3 -0.8 -1.2  0.3 -0.6 -0.4  0.2 -1.7  0.3 -0.4 -1.1 -0.8 -0.9 -0.8  0.2  4.4 -0.5 -1.  -0.8 -2.2  2.8 -0.3 -1.7 -0.4 -0.3  1.3 -1.1  1.5  1.5 -0.2 -0.8 -0.3  1.5  1.6 -1.1  1.3 -0.3 -0.2  1.   2.4 -0.5 -0.6  0.2  7.1 -0.7 -0.1 -0.5 -1.1 -0.   3.9  1.1 -1.8  4.6 -2.4 -0.5 -1.4  0.  -0.2  3.2  0.6 -0.8 -0.2 -0.3 -0.  -0.2 -0.1 -0.6 -0.4  5.3 -0.8]
vy_50sample [[4 5 7 3 6 2 2 0 1 9]
 [3 4 0 6 5 5 9 7 8 2]
 [7 5 5 9 2 8 6 3 1 1]
 [3 0 5 9 4 6 2 7 1 8]
 [6 4 4 5 5 7 8 2 0 1]
 [5 9 4 1 8 6 2 3 7 0]
 [5 7 6 4 8 3 0 0 2 1]
 [7 2 2 0 3 8 1 6 5 4]
 [5 5 3 6 9 9 1 2 7 4]
 [9 2 2 4 4 3 0 7 1 6]]
vt_50sample [[4 5 3 7 6 2 0 8 1 9]
 [3 4 0 6 5 1 9 7 8 2]
 [7 4 5 2 9 8 6 3 0 1]
 [0 3 5 9 4 6 2 7 1 8]
 [3 6 4 5 7 8 9 2 0 1]
 [9 5 4 1 8 6 2 7 3 0]
 [5 7 6 4 3 8 0 9 2 1]
 [7 2 3 0 9 1 8 6 5 4]
 [0 5 3 6 8 9 1 2 7 4]
 [2 9 8 4 5 3 0 7 1 6]]
Epoch  3010: Training cost= 0.5667, Training acc= 0.6598, Validation cost= 0.5915, Validation acc= 0.6602
Epoch  3020: Training cost= 0.6167, Training acc= 0.6601, Validation cost= 0.5713, Validation acc= 0.6605
Epoch  3030: Training cost= 0.5571, Training acc= 0.6605, Validation cost= 0.5866, Validation acc= 0.6609
Epoch  3040: Training cost= 0.5626, Training acc= 0.6608, Validation cost= 0.5498, Validation acc= 0.6612
Epoch  3050: Training cost= 0.5612, Training acc= 0.6611, Validation cost= 0.4961, Validation acc= 0.6615
Epoch  3060: Training cost= 0.5344, Training acc= 0.6615, Validation cost= 0.4810, Validation acc= 0.6619
Epoch  3070: Training cost= 0.5775, Training acc= 0.6618, Validation cost= 0.5954, Validation acc= 0.6622
Epoch  3080: Training cost= 0.5622, Training acc= 0.6621, Validation cost= 0.5271, Validation acc= 0.6626
Epoch  3090: Training cost= 0.5376, Training acc= 0.6625, Validation cost= 0.5676, Validation acc= 0.6629
Epoch  3100: Training cost= 0.5343, Training acc= 0.6628, Validation cost= 0.5592, Validation acc= 0.6633
tm  [ 3.2  2.  -0.7  1.4 -0.4 -1.1 -0.9 -0.5 -0.2 -1.  -1.3 -0.1 -0.7 -0.3 -0.8  1.5  1.3  0.6 -0.5 -0.2 -0.7 -0.3  1.9 -0.3 -0.4 -0.4 -0.5 -0.4 -0.2 -1.1 -0.5 -0.6 -1.  -3.   3.2 -0.4  0.3  4.2  6.8 -1.8 -0.5 -0.9 -0.6  5.3 -0.6  2.  -0.  -0.1  4.3  2.1 -0.4 -1.2 -0.5  1.  -0.6  3.3 -0.3  2.1  3.9  4.5 -0.8 -0.2  0.4  3.6 -1.  -0.9 -0.6  0.5  1.   3.5 -0.2  1.9  2.5 -0.4 -1.5 -0.1 -0.1 -0.7 -0.1 -0.2 -1.9 -0.3 -0.3 -0.3 -1.  -1.2  1.7 -0.3  3.9 -0.2 -0.2 -1.3  0.2  1.2  0.8 -0.4 -0.2 -0.6 -0.5 -0.   0.9 -1.7 -0.6 -0.2  1.4 -0.5 -0.7 -0.8 -0.7 -0.6  1.   0.6 -0.4 -0.5  1.6 -0.5 -0.3  3.4  0.8  2.4 -0.7  1.8 -1.1 -1.2 -0.4 -0.9 -0.3  1.8  4.   4.1  2.   0.5  2.7 -1.  -0.1 -5.1 -0.1 -0.5 -0.1  0.6 -0.1 -1.2  1.  -0.7 -0.2  1.9 -1.1 -0.1  2.1 -0.9  1.1  0.5  7.2 -0.5 -1.1 -0.4 -0.5 -0.4  2.6 -0.6  0.4 -1.8 -0.6 -0.9 -1.5 -0.4  2.2  2.4  0.1  0.3  0.7 -0.1  0.2 -0.1 -0.7  0.1  1.4 -0.  -1.4 -0.4  0.6 -0.5 -1.  -0.5  5.1  0.7  4.4 -0.2 -0.   6.3  0.2  0.5 -0.8 -1.6  5.5 -1.1  0.1 -1.2 -0.2  1.  -0.1  2.6 -0.2 -1.4 -1.8 -0.9 -1.1  1.8  7.7 -0.3 -0.4  0.2 -1.9 -0.9  0.2 -0.1 -1.   0.1 -0.7 -0.6 -0.4 -0.9 -0.3 -0.8 -1.   1.2 -0.3 -0.2 -1.1  8.6 -1.5 -0.2 -1.   5.4  2.4  4.7  3.1 -0.6  2.5  4.7 -0.2  2.3 -0.3  1.   5.8 -0.8 -0.3 -0.6 -0.6 -0.5  3.  -0.1  6.  -0.5  1.4 -0.4]
ty_50sample [[8 3 0 4 2 2 5 7 6 1]
 [4 6 7 2 0 3 9 1 5 5]
 [7 9 1 2 8 8 4 6 3 5]
 [4 7 9 0 2 5 1 3 6 6]
 [0 7 6 6 5 4 8 3 1 2]
 [0 4 9 1 5 8 2 6 7 3]
 [4 7 7 0 3 5 1 6 2 9]
 [5 1 6 8 0 0 4 7 2 3]
 [4 9 8 6 7 5 0 3 1 2]
 [3 3 4 7 0 5 8 1 2 9]]
tt_50sample [[8 3 0 4 2 9 5 7 6 1]
 [4 6 7 2 0 9 3 1 8 5]
 [7 9 1 0 2 8 4 6 3 5]
 [4 7 0 9 2 5 1 3 8 6]
 [0 7 9 6 5 4 8 3 1 2]
 [0 4 9 1 5 8 2 6 7 3]
 [4 8 7 0 3 5 1 2 6 9]
 [5 1 6 8 9 0 4 7 2 3]
 [4 9 8 6 7 5 0 3 1 2]
 [3 6 4 7 0 5 8 1 2 9]]
vm  [ 2.   0.3 -0.7 -1.5 -0.6 -0.3 -1.  -0.9 -0.  -0.9  5.7 -0.8  1.1 -0.6  2.5  6.3 -0.2 -0.2 -0.6  2.7 -0.5  0.9  0.5 -0.4 -0.8  0.8 -0.7 -0.6  1.9 -0.9  2.  -0.9  0.1 -0.8  6.   0.7 -0.3  3.8 -0.3 -1.3 -0.5 -1.  -1.2  3.4 -0.9  0.9 -1.2 -1.   2.4  1.7 -1.1 -1.9 -0.6  9.1 -0.6 -0.1 -0.7  1.   5.3  0.3 -0.1  1.6 -0.2  5.4  0.7 -0.6 -0.3  3.1 -0.1  0.8 -0.2 -0.1  0.4 -0.3 -3.2 -0.2 -0.5  0.2  3.3  0.6 -1.5 -0.2  3.  -0.3 -1.2 -1.2  1.2 -0.5  0.3 -0.6 -0.7 -1.5 -0.4 -0.6 -0.2 -0.2 -0.9 -1.3 -0.7 -0.3 -0.  -0.4 -0.1 -0.1  2.1 -0.  -1.8  2.5  2.7  1.4 -0.7  1.8 -0.2 -0.7  1.3 -0.4  1.3  3.1 -0.1  2.1 -0.6 -0.5 -0.4 -0.7 -1.   3.  -1.3 -1.9  2.9  3.6  6.1 -0.5 -0.1 -0.6  3.3 -0.7 -0.5  0.8  0.9 -0.3 -1.3 -0.7 -0.3 -0.3 -0.3  2.9 -0.9  1.4 -0.4 -0.5  4.8  1.5  5.8 -1.3 -0.6 -0.2 -0.9 -0.3 -0.4 -0.6  3.  -0.7 -0.1 -1.3 -0.4 -0.5  2.9  2.6  0.4 -0.9 -0.2 -0.3  0.4 -0.2 -0.8  3.3 -0.9 -0.4  4.9 -0.3  2.1  0.  -1.  -0.8  3.9 -0.6  2.7 -0.5 -0.4  3.5 -0.2  0.3  0.4 -1.2  2.4 -0.4 -0.8 -1.2 -0.4  2.3  0.4  3.2 -0.9 -0.8 -1.6 -2.3 -1.   1.5  7.3 -0.4 -0.2  0.3 -2.  -0.3  1.7 -0.4 -0.3 -0.6 -0.5 -0.5 -0.3 -0.8 -0.5 -0.8 -0.1  1.3  3.7  2.3 -0.2  7.5 -0.6 -0.3 -0.9  4.9  0.2  5.5  3.4 -1.5  3.4  4.2 -0.9  3.5  0.1 -0.1  6.1 -0.2 -0.5  0.3 -0.8 -0.3  2.1  2.5 -0.4 -0.1 -0.3 -0.4]
vy_50sample [[2 4 8 3 6 7 7 9 1 5]
 [6 8 2 7 4 4 9 5 0 3]
 [0 8 2 6 4 4 3 3 5 7]
 [8 2 2 7 4 1 1 5 5 0]
 [7 1 5 2 0 9 3 3 6 6]
 [0 5 4 6 8 7 9 2 1 3]
 [8 9 9 6 1 4 5 0 3 7]
 [9 7 0 0 5 5 2 6 6 1]
 [0 7 3 1 4 2 5 6 8 8]
 [5 1 1 4 0 6 3 8 7 2]]
vt_50sample [[2 4 8 3 6 0 7 9 5 1]
 [6 8 2 7 1 4 9 5 0 3]
 [0 8 2 6 1 4 3 9 7 5]
 [8 2 3 7 4 9 1 6 5 0]
 [7 1 5 0 2 9 4 3 6 8]
 [0 5 4 6 8 7 9 2 1 3]
 [2 8 9 6 1 4 5 3 0 7]
 [9 7 8 0 4 5 2 6 3 1]
 [0 7 3 1 4 2 5 6 9 8]
 [5 9 1 0 4 3 6 8 7 2]]
Epoch  3110: Training cost= 0.5904, Training acc= 0.6631, Validation cost= 0.5411, Validation acc= 0.6636
Epoch  3120: Training cost= 0.6662, Training acc= 0.6634, Validation cost= 0.5129, Validation acc= 0.6638
Epoch  3130: Training cost= 0.4955, Training acc= 0.6637, Validation cost= 0.5577, Validation acc= 0.6642
Epoch  3140: Training cost= 0.5037, Training acc= 0.6640, Validation cost= 0.6100, Validation acc= 0.6645
Epoch  3150: Training cost= 0.5895, Training acc= 0.6644, Validation cost= 0.5581, Validation acc= 0.6648
Epoch  3160: Training cost= 0.5822, Training acc= 0.6647, Validation cost= 0.5355, Validation acc= 0.6651
Epoch  3170: Training cost= 0.5100, Training acc= 0.6650, Validation cost= 0.5240, Validation acc= 0.6655
Epoch  3180: Training cost= 0.5767, Training acc= 0.6654, Validation cost= 0.5370, Validation acc= 0.6658
Epoch  3190: Training cost= 0.5803, Training acc= 0.6657, Validation cost= 0.5195, Validation acc= 0.6662
Epoch  3200: Training cost= 0.5298, Training acc= 0.6660, Validation cost= 0.5413, Validation acc= 0.6665
tm  [-1.1 -1.  -1.1 -1.4 -0.9  0.5 -0.4 -0.7  3.7 -1.   5.9  0.9  0.5 -0.3  1.4  2.3 -0.5 -0.4 -0.6  1.6 -0.6 -0.5 -1.3 -0.4 -0.7  2.2 -0.6 -0.5  0.2 -1.5  5.2 -0.8 -0.7  2.7 -0.  -0.5 -0.7  7.1  2.9 -1.  -0.4 -1.5 -1.1  5.6 -1.5  0.8 -1.3 -0.5 -0.5 -2.  -1.1 -1.5  0.7  4.6 -1.1  1.1 -0.2  0.8  4.5 -1.1  5.1 -0.3  0.6  5.  -0.2 -0.  -0.6  4.8 -0.2  3.3 -0.4 -0.4 -0.8  1.9 -2.8  0.1  0.2 -1.6  4.6  1.7  2.8 -0.7  0.8 -0.5  1.1 -1.1 -0.1 -0.4  1.7 -0.3 -0.6 -1.4 -0.1 -0.5 -0.5 -0.  -0.8 -1.3 -0.7 -0.4  2.7 -1.7  4.7  0.9 -0.4 -0.5 -1.8  6.2  2.5  1.3 -0.  -0.2 -0.3 -0.9  4.4  0.4  0.3  3.8 -0.8  1.1 -0.5 -0.3 -0.3  2.  -0.8  1.8  0.  -0.4  4.8  6.5 -0.8 -1.3  0.3 -0.4 -0.6  0.3 -0.1  1.7  4.5 -0.6 -0.4  1.8 -0.3 -0.8 -0.6 -0.7 -0.3  1.4  0.6 -1.3  4.2 -0.4 -0.9 -0.1 -0.7 -0.4 -0.4 -0.6  4.  -0.1  0.4 -1.3 -0.1 -0.5  0.3 -0.3  3.9  6.2  0.8 -0.5 -1.   0.4 -0.5 -0.3 -1.2  0.4  0.5 -0.6 -0.  -0.1  1.6 -0.4 -1.2 -0.6  3.1 -1.3 -0.7 -0.2 -0.3  6.4 -0.3  1.2 -0.4 -0.8 -0.9 -0.4 -0.8 -1.  -1.1  0.4  0.2  3.8 -1.1 -1.2 -0.3 -1.8  0.9 -0.3 -0.1 -0.7 -0.6  1.  -1.   5.7  0.8  0.4 -1.  -0.8 -0.6  0.4 -0.   1.3 -0.4 -0.7 -0.7 -0.1  1.1  3.6  0.1  3.3 -1.1  1.4 -0.5  0.6  3.9  5.3  0.6 -1.5  3.7  1.2 -0.4  1.  -0.9 -0.8  0.3 -0.2 -0.8 -0.5 -0.9 -1.1 -0.8 -0.2  2.6 -0.3  3.8 -1.4]
ty_50sample [[3 1 4 2 2 0 5 8 6 6]
 [7 8 9 4 4 1 6 2 3 0]
 [0 4 1 3 3 2 9 8 7 5]
 [3 8 0 5 2 4 7 9 1 6]
 [1 5 2 2 3 8 9 6 0 0]
 [5 7 8 4 2 1 3 6 9 0]
 [1 0 2 4 8 7 3 6 9 5]
 [9 1 7 6 4 2 2 8 0 3]
 [1 9 8 8 3 2 7 6 0 5]
 [1 8 8 4 9 7 7 0 6 3]]
tt_50sample [[3 1 4 2 0 7 9 5 8 6]
 [7 8 9 4 5 1 2 6 3 0]
 [0 4 1 3 6 2 9 8 7 5]
 [3 8 0 5 2 4 7 9 1 6]
 [1 5 2 3 7 8 9 6 0 4]
 [5 7 8 4 2 1 3 6 9 0]
 [1 0 2 4 8 7 3 6 9 5]
 [9 7 1 6 4 2 5 8 0 3]
 [1 9 8 4 3 2 7 6 0 5]
 [1 8 5 4 9 7 2 0 6 3]]
vm  [ 0.3 -0.2  4.7 11.1 -1.3 -0.8 -0.7 -0.3 -0.2 -0.3  7.3 -0.7  0.7  0.4 -0.5  3.5  0.  -0.7  1.9 -1.1 -0.1 -0.4  0.6 -0.3 -1.6  2.  -0.2 -0.1 -0.6 -0.9 -0.6 -0.8  0.1  2.6  0.5  0.7  1.9  4.2  3.  -1.1 -0.6  5.7  3.3 -1.4 -0.6 -0.7  1.7 -0.3  1.5  1.4 -0.8 -0.   1.2  3.  -0.5  3.1 -0.2  6.1 -0.4  3.9 -0.4 -0.8  0.1  5.5 -0.4  2.1  0.2  0.1 -0.4 -0.1 -0.5  1.9 -0.5 -0.2  1.3  0.4 -0.5 -0.  -0.2  1.1  8.1 -0.2 -0.5 -0.5 -0.4  6.2 -0.3 -1.  -0.1  0.2 -0.3  1.1 -0.4 -0.   1.1 -0.1  5.9 -0.1 -0.3 -0.1  1.8  2.5  0.  -1.2 -0.3  2.4 -0.3 -0.6  3.7 -1.2  0.   1.6 -0.6  1.3  0.8  0.4 -0.3 -0.6 -0.2  0.7 -0.1  3.2  0.9  2.7 -0.1 -0.7 -0.1 -0.   2.2 -0.5  1.5 -0.8 -1.2  0.2  4.2  6.  -0.6 -0.4 -0.2 -0.2 -0.5 -0.4 -0.9  0.1 -0.5 -0.  -0.3 -0.7  5.5  1.  -1.2 -0.6  0.6 -0.3 -0.7 -0.5 -0.2 -0.1  0.2 -0.4  1.8  1.3 -0.9 -0.4 -0.2 -0.6 -0.2 -1.1 -0.6  5.3  0.8  1.9 -0.5 -0.9 -0.5 -1.4 -0.4  1.   0.6 -0.3 -1.2 -0.2 -0.  -0.9  0.1 -0.8  3.  -0.2  0.5  5.6 -0.3 -0.3 -0.7 -0.7  3.8 -0.4  1.9  0.1 -0.2  1.7 -0.5 -0.4 -1.1 -1.   1.5 -0.3  2.9  3.3 -2.3 -0.8 -0.4  0.1 -0.7  1.2 -1.3 -0.5  5.3 -0.7  0.3 -0.7 -0.1 -0.4  0.  -0.3  2.4 -0.3  2.   3.7  1.3  1.8 -0.4 -0.9 -0.6 -1.6  3.3 -1.2  1.   2.9 -0.6 -0.6 -1.  -0.3 -0.  -0.9 -0.9 -0.7  0.9  3.1 -0.5 -0.1 -1.6 -1.1  3.   3.   2.2  4.7]
vy_50sample [[5 2 9 6 6 1 7 3 8 4]
 [3 6 7 1 0 5 9 4 8 2]
 [0 9 8 1 7 2 5 6 4 3]
 [1 4 2 8 8 0 3 7 6 9]
 [7 3 5 5 1 0 0 4 8 2]
 [4 1 1 7 8 8 3 6 2 0]
 [3 5 7 1 6 2 0 4 8 9]
 [5 9 9 6 7 0 8 4 2 3]
 [6 7 0 8 3 3 4 5 1 9]
 [2 4 8 7 7 0 1 5 5 3]]
vt_50sample [[5 2 9 6 0 1 7 3 8 4]
 [3 6 7 0 1 5 4 9 8 2]
 [0 9 8 7 1 2 5 6 4 3]
 [1 4 2 8 5 0 3 7 6 9]
 [7 3 5 9 1 6 0 4 8 2]
 [4 5 1 7 8 9 3 6 2 0]
 [3 5 7 1 6 2 0 4 8 9]
 [5 9 1 6 7 0 4 8 2 3]
 [6 7 0 2 8 3 4 5 1 9]
 [2 4 8 7 6 0 1 5 9 3]]
Epoch  3210: Training cost= 0.5700, Training acc= 0.6664, Validation cost= 0.5360, Validation acc= 0.6668
Epoch  3220: Training cost= 0.5777, Training acc= 0.6667, Validation cost= 0.5716, Validation acc= 0.6671
Epoch  3230: Training cost= 0.5882, Training acc= 0.6670, Validation cost= 0.5179, Validation acc= 0.6674
Epoch  3240: Training cost= 0.5323, Training acc= 0.6673, Validation cost= 0.5704, Validation acc= 0.6677
Epoch  3250: Training cost= 0.6176, Training acc= 0.6675, Validation cost= 0.5468, Validation acc= 0.6680
Epoch  3260: Training cost= 0.5623, Training acc= 0.6678, Validation cost= 0.5565, Validation acc= 0.6683
Epoch  3270: Training cost= 0.5634, Training acc= 0.6681, Validation cost= 0.6419, Validation acc= 0.6686
Epoch  3280: Training cost= 0.5056, Training acc= 0.6684, Validation cost= 0.5523, Validation acc= 0.6689
Epoch  3290: Training cost= 0.5166, Training acc= 0.6687, Validation cost= 0.5105, Validation acc= 0.6692
Epoch  3300: Training cost= 0.5397, Training acc= 0.6691, Validation cost= 0.5261, Validation acc= 0.6695
tm  [ 2.3  2.  -0.3  3.9 -0.4 -1.6 -0.9 -0.4  0.8 -0.5 -1.6  0.2 -0.6 -0.2 -1.1  2.4  1.4 -0.3 -0.8 -0.1 -0.4 -0.3  2.4 -0.4 -0.4 -1.2 -0.3 -0.3  0.7 -1.1 -1.4 -1.1  0.4 -4.  -0.2 -0.8  0.5  1.6 -0.7 -1.8  0.1 -0.6  0.1 -0.7  0.2  1.5 -0.6 -0.2  3.   2.1 -0.  -1.  -0.5  2.  -1.   3.9  0.3  4.5  1.4  6.6 -0.6 -0.8 -0.1  0.6 -0.8 -0.6 -1.1  0.7  0.4  1.8  0.4 -0.1  2.4 -0.7 -2.3  0.9 -0.2 -0.8 -0.7 -0.3 -2.5 -0.5 -0.4 -0.  -1.  -0.5  0.3 -0.3  4.6 -0.  -0.6 -0.6  0.7  2.  -0.3 -0.3  1.3 -1.2 -0.5  0.7  1.9 -2.4 -0.  -0.3 -0.1 -0.2 -1.6 -1.7 -0.7 -0.7  1.1 -0.  -0.4 -0.5  0.5  0.4  0.4  1.7  0.8  3.  -0.3  0.8 -0.3 -1.2 -0.6 -0.9  0.1  0.7  2.7  5.9  4.4 -0.1  3.1 -0.8 10.7 -0.9 -0.5 -0.2 -0.1  0.3 -0.1 -1.3  0.  -0.6 -0.5  0.7 -1.4 -0.4  4.9 -0.3 -0.1  0.9  6.  -0.6 -0.9 -0.5 -0.4  0.1 -1.2 -1.  -0.4  1.  -0.4 -0.6 -2.   0.1  2.3  1.7 -0.4  1.4 -0.1  1.4 -0.7  0.4 -0.4 -1.3 -1.2 -0.9  5.8 -0.2 -0.6 -0.  -0.2 -0.7  2.8  3.   2.4  1.6 -0.7  7.3 -0.1  0.5 -0.6 -1.7  3.6 -1.1 -0.9 -1.3 -0.3 -0.6  0.5  2.1  0.5 -1.3 -1.2 -1.7 -0.6 -0.1  5.4 -0.5 -0.4  0.3 -2.  -0.9 -0.6  1.   4.3  0.4 -0.6 -0.6 -0.3 -0.4 -0.  -0.7  0.6  3.1 -0.6 -0.  -1.4  8.1 -0.5  0.7 -1.   4.   0.5  3.9  1.  -1.1 -0.1 -0.4 -0.5 -0.2  0.7  0.7  7.5 -0.4 -0.2 -0.4 -0.3 -0.5  3.3 -1.3 -0.9 -0.8  3.4 -0.9]
ty_50sample [[8 3 6 5 2 9 0 4 1 7]
 [5 7 0 2 4 9 1 3 8 6]
 [0 8 6 1 7 5 3 9 9 4]
 [0 6 3 1 2 2 7 8 5 4]
 [0 1 6 5 3 4 4 7 9 2]
 [4 5 1 6 7 3 8 2 9 0]
 [4 8 9 5 6 0 1 1 3 3]
 [7 8 9 9 0 5 1 3 2 4]
 [7 8 1 1 3 4 4 2 5 6]
 [3 6 1 1 2 2 0 9 9 5]]
tt_50sample [[8 3 6 5 2 9 0 4 7 1]
 [5 7 0 2 4 9 1 3 8 6]
 [0 8 1 6 7 5 3 2 9 4]
 [0 6 3 1 9 2 7 8 5 4]
 [0 1 6 5 3 8 4 7 9 2]
 [4 5 1 6 3 7 8 2 9 0]
 [4 8 9 5 6 0 2 1 3 7]
 [7 8 9 6 0 5 3 1 2 4]
 [7 8 1 9 0 3 4 2 6 5]
 [3 6 1 8 4 2 0 7 9 5]]
vm  [-0.2 -0.9  3.3 -0.8 -1.6 -0.6 -0.4 -0.9  1.7 -0.9  9.3  0.2  0.7  0.6  7.3  6.7  1.8 -0.7  2.5  4.9 -0.2 -0.4 -1.2 -0.6 -1.5  0.9 -0.1 -0.4 -0.1 -1.   2.8 -1.4 -0.5  6.5 -0.5 -0.5 -0.5  7.6 -0.1 -1.3  0.1  2.4  2.1  1.8 -1.2 -0.1 -2.3 -1.   0.1 -1.6 -1.5 -1.1 -0.4  8.5 -1.  -0.9 -0.2  6.3  1.9 -0.6  4.5 -1.2  0.   6.1 -0.4  1.1 -0.5  0.6 -0.7  0.7  1.4 -0.6 -0.8 -0.1 -3.2 -0.1 -0.5 -0.4  0.3  2.1  0.4 -0.6  2.4 -0.5 -0.2  4.1 -0.2 -0.8  1.5  1.  -0.9 -0.5 -0.5 -0.2 -0.8  1.   2.6 -1.4 -0.2 -0.2  4.   0.5  2.3 -0.8 -0.2  0.3 -2.7  3.7  4.6  3.1  1.  -0.5 -0.6 -0.5  0.1  2.   1.3  1.5 -0.4  0.2 -0.5 -0.8 -0.2  1.9 -0.5  8.3 -0.3 -1.6  6.1  5.8 -0.3 -0.9 -0.2  0.4 -1.7  2.6 -0.4  0.8  1.9 -0.7 -0.7  0.5 -0.4 -0.6 -0.1 -0.4 -0.2 -0.8  4.2 -0.3  3.6 -0.4 -0.4 -0.4 -0.9 -0.7 -0.5 -0.3  3.6 -0.4  0.9 -0.5 -0.4 -0.2  1.8 -0.5  2.2 -0.1 -0.2 -0.4 -0.7  4.8 -0.9 -0.5 -1.5 -0.6 -0.4 -1.1  4.  -0.4 -0.8 -0.  -1.1 -1.1  2.6 -1.2 -0.3 -0.8 -1.2  5.7 -0.4  1.1  0.6 -1.  -0.7 -0.7 -1.3 -0.5 -1.  -0.1  1.6  1.  -0.8 -1.3 -0.3 -2.4  3.8  0.7 -2.9 -0.9 -0.4  0.9 -0.9  3.  -0.  -0.3 -0.3 -0.3  1.7 -0.5 -0.5  1.4 -0.1 -0.1 -0.4  0.7  2.8  2.6  0.7  4.4 -0.9  2.1 -0.3 -2.   2.5 -0.4 -0.3 -1.6  0.1 -3.4 -0.4 -2.  -0.5 -0.7  2.   1.  -0.7 -0.  -0.5 -0.3 -0.2 -0.6 -0.   1.3  4.4 -1.4]
vy_50sample [[5 2 3 7 1 4 4 6 8 9]
 [1 9 9 2 6 5 5 0 7 8]
 [1 3 9 5 4 4 8 8 2 0]
 [2 7 3 5 9 4 6 0 1 1]
 [5 6 2 9 9 0 1 8 4 3]
 [9 2 5 8 8 1 1 1 6 0]
 [4 9 5 2 2 6 0 3 1 1]
 [5 2 1 4 0 6 6 8 9 3]
 [9 8 3 3 6 5 2 0 7 4]
 [5 4 7 3 9 6 1 0 8 2]]
vt_50sample [[5 2 3 7 1 4 0 6 8 9]
 [1 9 4 2 6 5 3 0 7 8]
 [3 1 9 6 5 4 8 7 2 0]
 [2 7 3 9 5 6 4 8 0 1]
 [5 6 2 9 7 0 1 8 4 3]
 [9 2 5 8 3 1 4 7 6 0]
 [4 9 8 5 2 0 6 3 1 7]
 [5 2 1 4 0 6 7 8 9 3]
 [9 8 1 3 6 5 2 0 7 4]
 [5 4 7 3 9 6 1 8 0 2]]
Epoch  3310: Training cost= 0.5509, Training acc= 0.6694, Validation cost= 0.5619, Validation acc= 0.6698
Epoch  3320: Training cost= 0.5457, Training acc= 0.6697, Validation cost= 0.5051, Validation acc= 0.6701
Epoch  3330: Training cost= 0.5923, Training acc= 0.6700, Validation cost= 0.5475, Validation acc= 0.6704
Epoch  3340: Training cost= 0.5141, Training acc= 0.6702, Validation cost= 0.5464, Validation acc= 0.6707
Epoch  3350: Training cost= 0.5097, Training acc= 0.6705, Validation cost= 0.5710, Validation acc= 0.6710
Epoch  3360: Training cost= 0.4975, Training acc= 0.6708, Validation cost= 0.5799, Validation acc= 0.6713
Epoch  3370: Training cost= 0.5249, Training acc= 0.6711, Validation cost= 0.5250, Validation acc= 0.6716
Epoch  3380: Training cost= 0.5025, Training acc= 0.6715, Validation cost= 0.5277, Validation acc= 0.6719
Epoch  3390: Training cost= 0.5095, Training acc= 0.6718, Validation cost= 0.5243, Validation acc= 0.6722
Epoch  3400: Training cost= 0.5589, Training acc= 0.6721, Validation cost= 0.5500, Validation acc= 0.6725
tm  [ 1.8 -0.3 -0.8 -1.9 -0.8 -1.1 -0.8 -1.   1.8  0.6 -0.5  0.8 -1.5 -1.4  4.1 -0.7 -0.9 -0.  -0.4  4.4 -0.6  1.7  2.9 -0.2 -0.4  1.7 -0.4 -0.3  0.  -1.1  3.7 -0.4 -0.1 -0.1  5.2 -1.2 -0.7 -0.5 -1.3 -1.3 -0.3  3.  -0.5  2.  -0.7  3.1 -1.8  0.5  2.9  2.7 -1.1 -1.6 -0.3  1.5 -0.1 -0.   0.6  2.1  4.6 -0.4  0.6 -0.9  2.8  5.8  0.4 -0.2 -0.1  1.1  4.4  0.  -0.2  1.3  0.3 -0.  -4.6 -0.1 -1.4  1.2  3.9  0.5 -1.2 -0.2  4.6  0.8 -1.2  2.6  2.4 -0.2 -0.7 -0.1 -0.2 -1.6 -1.3 -1.5 -0.5  0.7 -0.3 -2.2 -0.2  0.5 -1.6  2.1 -0.1 -0.  -0.1 -0.2 -2.6  4.1 -0.5  3.1 -0.2  2.9 -0.2 -0.9  4.5 -0.8  0.7  4.4 -0.1  3.7 -0.6 -1.4 -0.4 -0.2 -0.7  4.8 -1.1  0.9  4.5  1.5  7.5 -1.  -0.1 -1.   6.1  4.5 -0.2 -0.3 -0.1 -0.3  1.6 -0.5  4.8  1.3 -1.1  4.3 -0.6 -0.6  1.5  0.4  5.9  1.9  5.5  2.2 -0.3  0.1 -1.2 -0.5 -0.8 -0.2  3.8 -0.3  2.9 -1.1  0.  -0.2 -0.7  0.9 -0.1 -0.7  2.1  0.7 -0.2 -0.7 -0.   0.5 -1.1  0.2  8.3  5.1 -0.2 -0.7 -0.8 -0.7  3.4 -1.4  1.5 -0.3 -0.2  3.8 -0.3 -0.4 -0.5 -1.4  1.6 -0.8 -1.  -1.6 -0.5 -0.  -0.6  5.4 -0.1 -0.9 -0.6 -1.9  0.1 -0.5  2.4 -0.5 -0.2  0.2 -1.7  0.  -0.4 -0.5  1.  -0.2 -0.3  1.6 -1.1 -0.6 -0.3 -0.5  2.7  0.3 -0.9 -0.1 -0.2  7.8 -0.4 -0.6 -0.9  1.1  1.   5.1  5.2 -1.7  5.9 -0.7 -1.  -0.7  1.6  0.5  6.  -0.6 -0.6  0.3 -1.1  0.1  0.3 -0.2 -1.1 -0.6  2.9  1.4]
ty_50sample [[4 0 0 8 5 7 3 2 9 1]
 [7 7 1 4 5 6 8 2 0 9]
 [9 1 8 7 0 6 3 2 5 4]
 [7 9 1 1 6 0 8 2 4 3]
 [8 4 6 1 9 3 7 2 5 0]
 [7 2 9 4 0 3 6 6 8 1]
 [4 8 2 6 5 5 9 1 0 3]
 [5 3 1 7 9 6 2 8 4 4]
 [0 9 7 1 2 4 5 6 3 3]
 [4 9 6 0 5 2 1 7 8 3]]
tt_50sample [[4 0 6 8 5 3 7 2 9 1]
 [3 7 1 4 5 6 8 2 0 9]
 [9 1 8 7 6 0 3 2 5 4]
 [7 9 1 5 6 0 2 8 4 3]
 [8 4 6 1 3 9 7 2 5 0]
 [2 7 9 4 0 3 5 6 8 1]
 [4 8 2 6 5 7 1 9 0 3]
 [5 3 1 7 9 6 2 8 4 0]
 [0 9 7 1 2 4 5 6 3 8]
 [4 9 6 0 5 2 1 7 8 3]]
vm  [-1.1 -0.9 -1.3 -2.4 -1.4 -0.4 -0.3 -0.9 -0.2 -0.9 -0.2  1.8 -1.  -0.2  2.5 -0.9  1.3 -0.5 -0.6 -0.2 -0.1 -0.6 -1.  -0.3 -0.7  1.3 -0.1 -0.4 -0.2 -1.   6.5 -0.6 -0.5  3.5 -0.4 -0.5  1.3  3.2  5.5 -1.3 -0.4 -0.   1.3  8.3 -1.2  0.4 -0.8  2.3 -0.3 -1.2 -1.1 -1.2 -0.7 -0.1 -0.9 -0.1 -0.6 -0.3  1.4 -1.6  4.2 -0.7  0.1  1.8 -0.8 -0.  -0.3  2.3  0.4  3.5 -0.4  0.1 -1.1 -0.5 -2.  -0.1  2.  -0.9  5.4  0.3  2.1 -0.7 -0.5 -0.1  0.9  1.3  2.4 -0.6  4.3 -0.4 -0.7 -0.9 -0.6  0.2 -0.8  0.9 -0.4 -0.8 -0.3 -0.8  2.7 -0.5  3.1 -0.3 -0.2 -0.3 -1.9  7.4 -0.1 -0.4 -0.  -0.4 -0.4 -0.9  4.5  0.6 -0.2  3.  -0.8 -0.3 -0.3  1.7 -0.5  0.8 -0.7  2.8  3.1  3.4  3.4  4.2 -1.6 -0.9  2.  -0.1 -2.2 -1.2 -0.   0.2  2.8 -1.3  3.   1.4  1.9 -0.2 -0.8 -0.6 -0.1 -0.6  1.7 -0.6  5.3 -0.4 -0.9  1.5 -0.6 -0.3 -0.4 -0.3  5.1 -0.6 -0.3 -1.3 -0.5 -0.5  0.6 -0.   0.6  3.6  1.8 -1.2 -0.2  3.  -1.2 -0.1 -1.1 -0.5  2.3 -0.7 -0.9  1.1 -0.6 -0.3 -0.7 -0.6  2.2 -0.7 -0.6 -0.  -0.2  3.7 -0.6 -0.3 -0.2 -1.2 -0.7  0.3 -1.  -0.4 -0.9 -0.7 -0.   3.2 -0.8 -1.   0.5 -1.8  3.  -0.2 -1.5 -0.7 -0.8  0.1 -0.6  6.   3.7 -0.1 -2.1 -0.5 -0.4 -0.2 -0.3  2.7  0.6 -0.4 -1.1 -0.4 -0.6 -0.4 -0.1  3.1 -1.6  3.8 -0.4 -0.7  4.9  5.8  1.2 -1.3  2.5 -1.  -0.  -0.6 -1.3 -0.8  0.5 -0.2 -0.5 -0.8 -0.2 -0.4 -0.4 -0.2  4.3 -0.7  5.9 -0.6]
vy_50sample [[4 1 3 5 0 7 9 8 2 6]
 [1 0 6 9 7 7 5 8 4 2]
 [9 3 6 5 2 0 8 7 4 1]
 [6 1 4 5 7 8 3 0 2 9]
 [6 8 9 5 7 0 3 1 2 4]
 [0 0 6 1 3 5 8 8 7 7]
 [5 0 8 4 4 7 2 3 9 1]
 [0 7 7 1 6 5 5 2 3 4]
 [3 6 1 4 2 0 8 7 5 9]
 [3 9 2 0 0 4 4 5 6 8]]
vt_50sample [[4 1 3 5 0 7 9 8 2 6]
 [1 0 6 9 7 3 5 4 8 2]
 [9 3 6 5 2 0 8 7 4 1]
 [6 4 1 5 7 8 3 0 2 9]
 [6 8 9 5 7 0 3 1 4 2]
 [0 6 4 1 3 5 9 8 7 2]
 [5 6 0 8 4 7 2 3 9 1]
 [0 7 8 6 1 9 5 3 2 4]
 [3 6 1 4 2 8 0 7 5 9]
 [9 3 1 2 0 4 7 5 6 8]]
Epoch  3410: Training cost= 0.5406, Training acc= 0.6724, Validation cost= 0.5037, Validation acc= 0.6728
Epoch  3420: Training cost= 0.5695, Training acc= 0.6727, Validation cost= 0.5045, Validation acc= 0.6731
Epoch  3430: Training cost= 0.5967, Training acc= 0.6730, Validation cost= 0.6189, Validation acc= 0.6734
Epoch  3440: Training cost= 0.5332, Training acc= 0.6733, Validation cost= 0.4756, Validation acc= 0.6737
Epoch  3450: Training cost= 0.4531, Training acc= 0.6736, Validation cost= 0.4977, Validation acc= 0.6741
Epoch  3460: Training cost= 0.4843, Training acc= 0.6739, Validation cost= 0.4909, Validation acc= 0.6744
Epoch  3470: Training cost= 0.5876, Training acc= 0.6742, Validation cost= 0.5239, Validation acc= 0.6747
Epoch  3480: Training cost= 0.5432, Training acc= 0.6745, Validation cost= 0.5537, Validation acc= 0.6750
Epoch  3490: Training cost= 0.5142, Training acc= 0.6748, Validation cost= 0.5975, Validation acc= 0.6753
Epoch  3500: Training cost= 0.5023, Training acc= 0.6751, Validation cost= 0.5369, Validation acc= 0.6756
tm  [-0.8 -1.3  1.7  5.6 -0.8 -0.3 -0.6 -0.4  4.5  2.4  5.5 -0.8 -0.4  0.4 -0.5  5.8 -1.4 -0.9 -0.  -0.6 -0.3  1.6  2.9 -1.2 -1.  -0.2  0.8 -0.   3.  -1.7  1.3 -1.5 -0.4  2.9  1.1 -1.4 -0.9  6.8  6.9 -0.6 -0.2  7.  -0.3  2.2 -0.7 -0.9  3.2 -0.8 -0.5  4.4 -0.8 -0.3  1.   1.4 -1.3  2.2 -0.6  4.   5.8  0.1  0.4 -1.5  1.7  5.5  2.9 -0.2 -0.4  4.9  0.8 -1.3  1.4 -1.2 -0.6  1.1 -3.1 -0.1 -0.8  2.2  2.4 -0.1  6.2 -0.3 -0.1 -0.1 -0.3  8.3 -0.5 -0.7 -0.5 -0.1 -0.6 -1.  -1.5 -1.9 -0.3 -0.4  1.4 -1.1 -0.6 -0.3 -1.2  3.7  2.  -0.7 -1.2 -0.2 -1.   1.8  2.8 -0.7  2.5 -0.2 -0.5 -0.6  1.7  3.6 -0.1  0.6 -0.6  4.7 -0.3  0.9 -0.2 -0.   0.2 -0.4 -0.7  0.8  9.3 -1.1 -0.3 -0.9 -1.4  0.2 -1.1 -0.4  0.2 -0.7 -1.  -0.6 -1.   4.   0.5 -0.3 -1.5  2.5  0.4 -1.1  4.   1.8 -0.3 -0.2  0.4  0.5 -0.3  0.4 -0.8 -0.1  1.8  0.4  3.1 -1.5  0.4 -0.6  1.5 -0.4 -0.1 -0.2 -0.9  3.3  3.3  1.4 -0.6 -1.2 -0.6 -1.3 -0.6  1.1 -1.2 -0.5 -1.4 -0.3 -0.8 -0.8 -0.2 -0.8  1.4 -0.5 -0.5  5.5 -0.6 -0.9 -1.6 -0.6  1.8 -1.3 -0.2 -0.4 -1.1 -0.3 -0.7  1.2 -1.4 -1.1 -0.  -0.3  3.7  0.3 -2.2 -0.6 -0.1  2.9 -0.6  6.4 -0.7  0.4 -0.2 -0.6  0.3 -0.4 -0.4 -1.3 -0.2  0.9  1.8  1.6  0.2  6.2  0.3  3.5 -1.1 -1.4 -0.5 -1.6 -0.9  1.   3.9 -0.9  0.4 -0.9 -0.2 -0.5 -0.1 -0.7 -0.5 -1.5  0.5 -0.  -0.6  0.3 -1.5  0.5  6.5  1.8  1.9  6.9]
ty_50sample [[5 2 2 1 7 4 4 0 3 0]
 [9 8 1 3 2 0 4 7 7 5]
 [2 2 8 5 4 1 7 9 0 6]
 [2 4 4 1 1 7 0 5 5 8]
 [9 0 7 3 3 1 5 6 2 4]
 [0 1 3 7 7 9 9 2 6 4]
 [5 7 2 1 0 9 3 3 6 4]
 [7 5 0 4 2 2 9 3 8 1]
 [0 2 7 7 3 8 1 5 9 6]
 [4 2 7 7 5 6 1 3 0 8]]
tt_50sample [[5 2 9 1 7 8 4 6 3 0]
 [9 8 3 1 2 0 4 6 7 5]
 [2 3 8 5 4 1 7 9 0 6]
 [2 9 4 1 3 7 0 6 5 8]
 [9 0 7 8 3 1 5 6 2 4]
 [0 1 3 5 7 9 8 2 6 4]
 [5 7 2 1 8 0 9 3 6 4]
 [7 5 0 4 2 6 9 3 1 8]
 [0 2 4 3 7 8 1 5 9 6]
 [4 2 7 9 5 6 1 3 0 8]]
vm  [ 0.2  2.7 -0.6  1.5 -0.9 -0.9 -0.4 -0.5 -0.7 -0.8 -2.4  3.  -1.5 -0.2 -0.5 -1.5  2.4 -0.1 -0.3 -0.8 -0.7 -0.7  0.8 -0.1 -0.4  1.5 -0.3 -0.7 -0.8 -0.9 -0.1 -0.1 -0.7 -2.1 -0.3 -0.6  3.1  2.8  6.1 -1.6 -0.4 -0.4  2.4  4.2 -0.9  1.3 -0.3  3.   1.9  0.  -0.3 -0.9 -0.  -1.1 -0.3  3.2 -0.3  1.4 -0.2  3.7  1.5 -0.8 -0.1 -0.1 -1.1 -0.3 -0.4 -0.4  1.8  5.5 -0.2  2.   0.3 -0.9 -0.7 -0.   2.1 -1.5  0.3  0.9 -0.7 -0.5 -0.8 -0.1 -0.4 -0.1  1.1 -0.6  4.9 -0.4 -0.1 -0.7 -0.   3.3 -0.3 -0.1  1.9 -0.3 -0.4 -0.1  2.8 -1.4  1.6 -0.7  0.2 -0.4 -1.1 -0.2 -1.3 -0.9  1.3 -0.3 -0.4 -0.3  3.2 -0.4 -0.3  1.4 -0.3  1.5 -0.4  3.4 -0.7 -0.5 -0.4 -0.5  3.1  5.9  0.9  4.9 -0.8 -0.   1.5 -0.4 -0.1 -3.7 -0.2 -0.5  2.7 -0.4  3.6 -1.   1.  -0.5 -0.6 -0.4 -0.7 -0.5  3.4 -0.5  0.1 -0.5  2.8  2.2 -1.  -0.4  0.7 -0.   3.6 -0.7 -0.7 -0.8 -0.8 -0.  -1.4 -0.2  0.8  2.5 -0.   1.3 -0.3  1.9 -0.4  0.5 -0.5 -0.6  2.3 -0.5 -1.   0.3 -0.8 -0.1 -0.3 -1.1  3.   1.3  1.8  0.8  1.7  6.7 -0.6  0.8 -0.3 -1.7  1.1 -0.2 -0.5 -0.1 -0.4 -0.7 -0.1  1.6 -0.2 -1.1 -0.3 -1.1 -0.2  0.8  3.2 -0.5 -0.4 -0.1 -0.9  1.1  0.3 -0.1 -0.9 -0.2 -0.6 -0.4 -0.8  1.3  0.9 -0.8 -0.8  0.2 -1.5 -0.6 -0.6  3.3 -1.2  1.8 -0.7  2.3  6.4  4.4  1.6 -0.4  1.  -0.  -0.6  0.2 -0.7 -0.3  3.4 -0.3 -0.2 -0.6 -0.5 -0.8  1.  -1.2  6.1 -1.1  5.7 -0.6]
vy_50sample [[3 8 8 5 1 9 9 7 6 2]
 [1 3 2 9 7 6 6 4 5 0]
 [3 6 4 0 5 7 1 9 2 8]
 [4 0 9 3 1 7 5 8 2 6]
 [1 4 3 2 9 8 5 0 6 7]
 [1 1 2 4 4 8 8 6 0 3]
 [2 3 7 1 6 6 0 0 9 9]
 [4 3 3 0 2 2 5 1 7 8]
 [6 8 2 2 3 5 4 0 0 7]
 [8 5 4 0 3 9 9 9 1 2]]
vt_50sample [[3 0 8 5 4 1 9 7 6 2]
 [1 3 2 9 7 8 6 4 5 0]
 [3 6 4 0 5 7 1 9 8 2]
 [4 0 9 1 3 7 5 8 2 6]
 [4 1 3 2 9 8 5 0 6 7]
 [9 1 2 7 4 5 8 6 0 3]
 [2 3 1 7 6 5 0 4 8 9]
 [4 3 9 0 6 2 5 7 1 8]
 [6 8 2 9 3 5 4 0 1 7]
 [8 5 4 0 3 9 6 7 1 2]]
Epoch  3510: Training cost= 0.5292, Training acc= 0.6754, Validation cost= 0.5029, Validation acc= 0.6759
Epoch  3520: Training cost= 0.4936, Training acc= 0.6757, Validation cost= 0.4904, Validation acc= 0.6761
Epoch  3530: Training cost= 0.5562, Training acc= 0.6760, Validation cost= 0.4979, Validation acc= 0.6765
Epoch  3540: Training cost= 0.5555, Training acc= 0.6763, Validation cost= 0.5115, Validation acc= 0.6768
Epoch  3550: Training cost= 0.5761, Training acc= 0.6766, Validation cost= 0.5611, Validation acc= 0.6770
Epoch  3560: Training cost= 0.4956, Training acc= 0.6768, Validation cost= 0.6802, Validation acc= 0.6773
Epoch  3570: Training cost= 0.5337, Training acc= 0.6771, Validation cost= 0.5566, Validation acc= 0.6776
Epoch  3580: Training cost= 0.5538, Training acc= 0.6773, Validation cost= 0.5579, Validation acc= 0.6778
Epoch  3590: Training cost= 0.4860, Training acc= 0.6776, Validation cost= 0.4837, Validation acc= 0.6781
Epoch  3600: Training cost= 0.4901, Training acc= 0.6779, Validation cost= 0.5894, Validation acc= 0.6784
tm  [-1.4  0.5 -1.3 -0.4 -1.   1.4 -0.3 -0.7 -0.5 -0.4 -0.6  0.1  0.2  1.  -0.6  2.8 -0.1 -0.1 -0.7 -0.7 -0.6 -0.7  2.1 -0.5 -0.8  2.3 -0.1 -0.3  1.4 -0.8  1.4 -0.2 -0.9 -1.9 -0.3 -0.1  1.3  7.   7.7 -1.  -0.2 -1.4 -0.9  7.3 -1.2  0.1  0.4 -0.2 -0.8  1.5 -0.5 -1.2 -0.4  0.8 -1.3  3.  -0.5 -0.7  2.9  0.8  5.   0.9  0.1  1.7 -0.6 -0.  -0.6  1.2 -0.4  3.7 -0.1 -0.4  1.2  1.4 -1.  -0.2  4.  -1.5  5.   0.4 -0.5 -0.6 -0.4 -0.4  1.7 -1.1  0.2 -0.6  2.6 -0.6 -0.2 -1.4 -0.2 -0.4 -0.3 -0.3 -1.  -0.4 -0.9 -0.4  1.6 -1.2  4.2  1.3 -0.3 -0.3 -0.8  1.5 -0.3 -0.9 -0.5 -0.5 -0.  -0.5  3.1  1.5 -0.5  0.1 -0.7 -0.4 -0.3  2.4 -0.5 -0.3 -0.5 -0.9  2.2  2.1  3.3  3.6 -1.3 -0.6 -0.2 -0.1 -1.2 -4.2  0.4 -0.2  2.2 -0.5  0.1  0.8 -0.7 -0.6 -0.7 -0.2  0.6  1.8 -0.1 -0.6  2.4 -0.6 -0.1 -0.6 -0.5 -0.6 -0.2 -0.5  4.8 -0.2  0.2 -1.5 -0.7 -0.9 -1.3 -0.1  3.3  5.6  1.4 -0.1  0.  -0.3 -0.3 -0.2 -0.7  1.7  2.  -0.1 -1.7 -0.5  1.2 -0.2 -0.7 -0.8  2.2  0.1 -0.6  0.8 -0.3  3.9 -0.6 -0.3 -0.7 -1.3 -0.6 -0.1 -0.2  0.8 -0.5 -0.5 -0.2  2.3 -1.2 -1.4  0.9 -0.9 -1.1  1.7  6.4 -0.5 -0.6  1.5 -1.3  6.3  1.1 -0.2 -1.6 -0.5 -0.5 -0.3 -0.4  0.6 -0.4 -0.8 -0.8  1.7  0.1  2.8 -0.5  1.6 -1.4 -0.1 -0.6  5.2  4.1  5.6  1.1 -0.2  1.9  7.7 -0.1  5.1 -1.1 -0.8  3.4 -0.8 -0.3 -0.  -0.5 -1.   0.2  0.3  6.8 -0.   2.   0.2]
ty_50sample [[1 4 3 3 9 2 0 7 5 6]
 [4 7 1 9 8 2 5 6 3 0]
 [6 4 9 1 7 7 2 3 3 5]
 [6 0 0 7 3 8 5 5 1 4]
 [7 1 1 6 6 2 3 0 0 5]
 [2 6 7 7 1 8 0 5 4 3]
 [3 1 6 5 2 4 7 7 0 9]
 [5 5 0 2 9 9 8 8 6 3]
 [4 7 8 6 5 3 2 9 0 1]
 [1 7 7 5 5 2 4 0 0 3]]
tt_50sample [[1 4 3 8 9 2 0 7 5 6]
 [4 7 1 9 8 2 5 6 3 0]
 [6 4 9 1 0 7 2 8 3 5]
 [6 9 0 7 8 3 5 1 4 2]
 [9 7 1 6 4 2 3 8 0 5]
 [2 6 1 7 9 8 0 5 4 3]
 [3 1 6 5 2 4 8 7 0 9]
 [5 7 0 4 2 9 8 6 1 3]
 [4 7 8 6 3 5 2 9 0 1]
 [1 7 8 5 6 2 4 0 9 3]]
vm  [-1.7 -0.6  5.1  3.2 -1.3  0.3 -0.5 -0.8  4.4 -0.   0.1  2.4 -0.4  0.   4.7  2.  -0.9 -0.4 -0.3  2.8 -0.4 -0.4 -0.4 -0.9 -0.5 -0.2  0.  -0.3  1.2 -1.8 -0.8 -0.9 -1.1  1.2 -0.9 -1.7 -0.5  7.3  3.  -0.9  0.2 -0.7 -1.   1.2 -1.4  0.9 -1.1 -0.4 -1.  -1.  -0.9 -0.6  0.2  3.1 -1.1 -0.4 -0.3  4.3  4.6  4.8  7.4 -0.6  1.7  4.2 -0.4 -0.  -1.   1.2 -0.1  1.1  2.8 -0.4 -0.2  0.7 -4.2 -0.3 -0.1 -1.6  1.   1.1 -1.  -0.8  1.5 -0.1  1.1 -0.3 -1.  -0.9  1.9  0.4 -0.5 -0.9 -0.4 -0.5 -1.1 -0.5  0.9 -1.5 -0.7 -0.1  1.  -0.9  6.6 -0.2 -0.9 -0.4 -2.5 -0.7 -0.1  1.   3.5 -0.8 -0.2 -0.9  3.7  1.4  0.6  2.6 -0.7  2.2 -0.3 -0.6 -0.7 -0.3 -0.6  4.9  1.2 -0.1  6.3  5.9 -1.4 -1.2 -0.7 -0.1 -1.9 -2.2  0.6  0.1  3.  -0.3 -0.4  2.4 -0.7 -1.4 -1.  -0.7 -0.1 -0.6  1.8 -1.  -0.3 -0.8 -0.5  0.5 -0.6 -0.4 -0.4 -0.1  4.3 -0.  -0.6 -1.5  1.7 -0.  -0.2  0.2  2.3  5.3 -1.   1.7 -0.6  2.5 -0.6 -0.5 -0.8 -0.1 -0.1 -1.1 -0.1  0.3 -0.2 -0.8 -0.8 -0.8  3.4 -0.8 -1.4 -0.6 -0.6  9.5 -0.7  0.7 -0.7 -1.1 -1.5 -1.2 -1.3 -0.6 -1.4 -0.9 -0.2  2.1 -1.  -1.3  0.8 -1.9  1.3 -0.6 -0.3 -0.7 -1.   1.5 -0.5  5.7 -1.2  1.5  1.1 -0.6 -0.2 -0.2 -0.9  0.2  0.  -0.1 -0.8  1.6 -0.6  4.8 -0.   3.3 -1.3  2.5 -0.6  0.2  0.1 -1.  -0.4 -1.9  0.3 -1.2 -0.  -0.8 -0.6 -1.   4.3 -0.2 -0.7 -0.5 -0.5 -0.8  1.5 -1.3  2.9  0.3  5.9 -1.3]
vy_50sample [[1 3 5 5 7 2 0 9 4 6]
 [2 8 4 1 1 9 3 5 6 0]
 [3 3 5 5 1 9 6 6 6 2]
 [8 6 3 2 4 5 1 7 0 9]
 [0 2 9 1 4 4 3 8 5 7]
 [3 5 1 0 2 2 9 6 6 7]
 [7 2 3 0 0 8 9 6 1 1]
 [2 5 0 7 8 4 3 6 9 1]
 [6 3 9 1 0 4 8 2 5 7]
 [9 7 5 6 3 3 2 0 0 4]]
vt_50sample [[3 1 5 7 8 2 0 9 4 6]
 [2 8 4 7 1 9 3 5 6 0]
 [0 3 5 7 4 1 9 6 8 2]
 [8 6 3 2 4 5 1 7 0 9]
 [0 2 9 1 6 4 3 8 5 7]
 [3 5 0 1 2 4 9 8 6 7]
 [7 2 3 0 4 8 9 6 5 1]
 [5 2 0 7 8 4 3 6 1 9]
 [6 3 9 1 0 8 4 2 5 7]
 [9 7 5 6 3 2 1 0 8 4]]
Epoch  3610: Training cost= 0.5685, Training acc= 0.6782, Validation cost= 0.5437, Validation acc= 0.6787
Epoch  3620: Training cost= 0.5028, Training acc= 0.6785, Validation cost= 0.5715, Validation acc= 0.6790
Epoch  3630: Training cost= 0.4768, Training acc= 0.6787, Validation cost= 0.5462, Validation acc= 0.6792
Epoch  3640: Training cost= 0.5062, Training acc= 0.6790, Validation cost= 0.5679, Validation acc= 0.6795
Epoch  3650: Training cost= 0.5188, Training acc= 0.6793, Validation cost= 0.5116, Validation acc= 0.6798
Epoch  3660: Training cost= 0.5287, Training acc= 0.6796, Validation cost= 0.5139, Validation acc= 0.6801
Epoch  3670: Training cost= 0.4973, Training acc= 0.6799, Validation cost= 0.5262, Validation acc= 0.6804
Epoch  3680: Training cost= 0.5679, Training acc= 0.6802, Validation cost= 0.4707, Validation acc= 0.6807
Epoch  3690: Training cost= 0.5172, Training acc= 0.6805, Validation cost= 0.4937, Validation acc= 0.6810
Epoch  3700: Training cost= 0.5149, Training acc= 0.6808, Validation cost= 0.5136, Validation acc= 0.6812
tm  [-1.2 -0.6  5.5 10.2 -1.3 -0.  -0.7 -0.5  3.9  1.3 -0.2  2.1 -0.8 -0.4 -0.3 -1.3 -0.9 -0.3 -0.3 -0.5 -0.6 -0.5 -0.1 -0.7 -0.4  2.4 -0.2 -0.5 -0.9 -1.9 -0.9 -0.  -1.   0.2 -0.2 -1.4 -0.   4.1  6.3 -0.8 -0.5  1.5 -0.5 -0.2 -1.3  0.6  2.   0.1 -0.5 -0.2 -0.6  0.   1.1 -0.6 -0.1  3.5 -0.4  3.7  3.4  5.3  3.5 -0.6  1.9  5.4 -0.4 -0.1 -0.3  0.6  1.   1.5  0.8  3.1 -0.5 -0.  -2.1 -0.2  0.2 -1.3  0.6  0.7  3.9 -0.3 -0.2 -0.1  0.2  1.4 -1.  -0.9  0.3  0.2  0.1 -0.6 -0.7 -0.4 -0.2 -0.6  3.3 -1.  -0.4 -0.1 -0.4 -0.   5.3 -0.6 -0.7 -0.4 -1.2 -0.8 -0.2 -0.9  2.6 -0.  -0.4 -0.5  6.8 -1.  -0.3  1.6 -0.5  4.2 -0.   2.1 -0.5  0.  -0.4 -0.1  0.3  4.9  3.9  1.  -1.  -1.1 -1.7 -0.1 -0.9 -1.4 -0.1 -0.5  2.3 -0.5  0.4 -0.1 -0.5 -1.  -0.7 -0.8 -0.4 -0.5  2.5 -1.  -1.5 -0.8 -0.3  2.5 -0.6 -0.3  0.8  0.1  4.1  0.2 -0.1 -1.4 -0.1 -0.1 -0.5 -0.4 -0.5  2.4 -1.3  5.2 -0.1  0.4 -0.  -0.6 -0.1 -0.2  0.7  1.  -1.1  1.  -0.8 -1.1 -0.5 -0.8  3.1 -0.8 -0.3 -0.2  2.9 10.4 -0.9 -0.2 -1.2 -1.  -0.3 -0.6 -0.3 -0.8 -0.8 -0.1 -0.9  1.3 -0.8 -1.2  1.9 -0.5  1.3 -0.3 -0.4 -0.7 -0.6 -0.1 -0.3  4.4 -1.8 -0.1  2.4 -0.9 -0.4 -0.3 -0.5 -0.5  0.2 -0.6 -0.4 -0.5 -0.9  4.8  0.5  0.3 -1.   1.1 -0.6 -0.3  3.5 -0.9  2.  -0.6  1.4  1.6 -0.6  0.5 -0.7 -0.9 -0.1 -0.9 -0.1 -0.  -0.7 -0.6 -0.8 -1.4  6.7  0.4  4.   1.7]
ty_50sample [[1 0 9 5 8 8 7 2 6 4]
 [7 0 1 6 2 8 3 9 5 4]
 [1 2 8 6 4 5 3 3 7 0]
 [3 6 8 4 4 0 5 9 2 7]
 [8 4 4 6 3 5 1 9 7 0]
 [1 1 9 6 0 3 3 2 7 7]
 [7 5 9 9 4 4 2 2 3 8]
 [3 9 1 5 7 2 4 0 8 6]
 [7 6 0 5 8 9 4 4 3 2]
 [3 5 7 8 6 6 1 9 9 0]]
tt_50sample [[1 0 9 5 3 8 7 2 6 4]
 [7 0 6 1 2 8 9 3 5 4]
 [1 2 8 6 4 9 5 3 7 0]
 [3 6 8 1 4 0 5 9 2 7]
 [8 2 4 6 3 5 1 9 7 0]
 [8 1 9 6 5 0 2 3 4 7]
 [1 5 7 9 4 6 0 2 3 8]
 [3 9 1 5 7 2 4 0 8 6]
 [7 6 0 8 5 9 1 4 3 2]
 [3 5 7 8 4 6 1 9 2 0]]
vm  [ 2.3 -0.2 -0.8 -0.9 -1.1 -1.2 -0.4 -1.3 -1.4  0.8 -1.2 -0.3 -0.9 -1.   1.3  1.2 -0.2 -0.2 -0.3 -0.9 -0.4 -0.1  3.8 -0.3 -0.5 -0.3 -0.4 -0.3  2.5  0.1  2.6  0.9  0.5 -0.2  3.7 -0.3  1.8 -0.   4.6 -0.6 -0.1 -0.1 -1.   5.  -1.2 -0.2  4.3  1.1  2.7  7.2 -0.9 -1.1 -0.5 -0.3 -0.6  1.  -0.5 -1.1  2.3 -0.5 -1.2  0.8 -0.5  0.5 -0.3 -0.8 -0.   0.   1.5  0.4 -0.  -0.3  1.6 -0.2 -1.4  0.8 -0.3  1.7  4.9 -0.9 -0.6 -0.1 -0.2 -0.3 -1.3 -0.2  3.3 -0.2 -0.3 -0.6 -0.2 -1.1 -1.  -1.2  0.1 -0.3 -1.1 -0.6 -0.4 -0.7 -1.1  5.1 -0.7  0.5  0.6 -0.5 -0.8  2.7 -0.8 -1.  -0.2 -0.2 -0.2 -0.3  0.3 -0.   0.4  2.7  0.   0.4 -0.4  2.4 -0.7 -1.5 -0.3  1.9 -0.5  3.7  0.5 -0.9  6.  -0.5 -0.2 -0.6 -1.2 -2.5 -0.  -0.8 -1.1 -0.1 -0.  -0.6  3.8  1.7 -0.9  5.6 -0.7 -0.9 -1.2  1.5  2.7  0.7  5.9 -0.4 -0.4 -0.1 -1.  -0.4 -0.4 -1.   2.  -0.8  1.  -1.1 -0.1  0.3 -0.2  1.7  1.4 -0.6  2.8 -0.8 -0.3 -0.5 -0.6  5.7 -0.5  2.1 -0.5  1.1  1.7 -0.3 -0.1 -0.6  0.2 -0.1  4.7 -0.5 -0.4 -0.4 -0.  -0.8 -0.7 -1.7  7.1  0.1 -0.  -0.4 -0.6 -0.7 -0.9  2.6 -0.6 -0.2 -0.9 -0.4 -1.3  1.3  8.2 -0.   1.   0.8 -1.8  0.7  1.5 -0.5 -1.  -0.2  1.1 -0.1 -1.2 -0.9 -0.5 -0.8  1.3  2.5 -0.8 -0.2 -0.5  5.1 -0.9 -0.5 -1.1  5.7 -0.2  3.9  4.8 -0.5  4.7 12.6 -0.8  7.1  0.5  0.7  3.6 -1.4 -0.1 -0.3 -0.6  0.6  1.2  2.7  4.4 -0.8  0.2  5.5]
vy_50sample [[4 8 7 9 0 6 6 3 1 5]
 [9 6 3 7 0 5 2 1 4 8]
 [9 2 4 3 5 6 7 7 8 1]
 [2 8 6 5 3 7 0 4 9 1]
 [4 4 9 3 6 6 0 5 7 1]
 [1 0 4 8 6 6 3 5 9 7]
 [1 0 3 9 4 2 5 6 7 7]
 [4 8 5 6 6 2 7 9 9 3]
 [3 6 9 7 1 5 0 2 2 4]
 [8 4 0 6 1 7 5 5 3 9]]
vt_50sample [[4 8 7 9 0 6 2 3 5 1]
 [9 6 7 3 0 5 2 1 4 8]
 [9 2 4 3 5 6 0 7 8 1]
 [2 8 6 5 3 7 0 4 9 1]
 [2 4 9 3 6 8 0 5 7 1]
 [1 0 4 8 2 6 3 5 9 7]
 [1 0 3 9 4 2 6 5 8 7]
 [4 8 5 6 1 2 7 9 0 3]
 [3 6 9 7 1 5 0 2 8 4]
 [8 4 0 6 1 7 5 2 3 9]]
Epoch  3710: Training cost= 0.5323, Training acc= 0.6810, Validation cost= 0.5305, Validation acc= 0.6815
Epoch  3720: Training cost= 0.5039, Training acc= 0.6813, Validation cost= 0.4965, Validation acc= 0.6817
Epoch  3730: Training cost= 0.5838, Training acc= 0.6815, Validation cost= 0.4823, Validation acc= 0.6820
Epoch  3740: Training cost= 0.5592, Training acc= 0.6818, Validation cost= 0.5262, Validation acc= 0.6823
Epoch  3750: Training cost= 0.5174, Training acc= 0.6820, Validation cost= 0.5499, Validation acc= 0.6826
Epoch  3760: Training cost= 0.4939, Training acc= 0.6823, Validation cost= 0.5258, Validation acc= 0.6828
Epoch  3770: Training cost= 0.5226, Training acc= 0.6826, Validation cost= 0.4560, Validation acc= 0.6831
Epoch  3780: Training cost= 0.5079, Training acc= 0.6828, Validation cost= 0.5233, Validation acc= 0.6834
Epoch  3790: Training cost= 0.5061, Training acc= 0.6831, Validation cost= 0.5674, Validation acc= 0.6836
Epoch  3800: Training cost= 0.4872, Training acc= 0.6834, Validation cost= 0.5424, Validation acc= 0.6839
tm  [ 0.9  4.7 -0.2  7.5 -1.  -0.9 -0.7 -0.3 -0.3 -1.4 -0.9  1.2 -0.5  0.6 -1.6  1.6  1.4 -0.1  0.6 -0.7 -0.5 -0.3  2.3  0.8 -0.9  2.6 -0.4 -0.3 -0.5 -0.5 -0.7 -0.5 -1.2 -2.3 -0.4  0.4  2.3  5.8 10.6 -1.5 -0.4 -0.7  0.9  4.6 -0.6  1.5  2.6  1.3  3.2  1.  -0.4 -0.7  2.8 -0.8 -0.4  5.5 -0.2  2.7 -0.2  4.2 -1.2 -0.4  1.8  2.8 -1.1 -0.5 -0.5 -0.7 -0.2  5.  -0.5  1.8  2.9 -0.1  6.4 -0.1  0.  -1.3 -0.7  0.6  2.9 -0.2 -0.8 -0.3 -0.7 -0.4  1.6 -0.4  4.2 -0.1 -0.1 -0.5  2.3  2.6  2.2  0.1  2.7  0.5 -0.6  1.2  3.  -1.6 -0.5 -0.4  1.5 -0.3  2.7 -1.  -0.4 -1.4  0.4  1.1 -0.5  0.4 -0.2  0.3 -0.4  0.2  0.5  0.7 -0.1  4.7 -1.1 -0.6 -0.2 -1.7  1.7  4.6  2.6  1.9 -0.5 -0.3  1.3 -0.7 -0.9 -4.3  1.  -0.6  1.9  0.2  0.8 -1.3 -0.4 -0.8 -0.   0.9 -0.7 -0.3  3.4 -0.4 -0.9 -0.2  5.1 -0.3 -0.7 -0.5 -0.  -0.5  5.3 -0.6  0.  -1.1 -1.  -0.3 -1.4 -0.6  2.5  0.6  1.5  4.4  0.7  0.  -0.3 -0.1 -0.6 -0.3  3.4  2.7 -2.6 -0.4 -0.2 -0.3 -0.8 -1.   0.9 -0.1  4.8  0.6  0.2  5.5 -0.2  0.9 -1.  -1.3  6.3 -0.5  5.3 -0.2 -0.2  0.1  0.3  0.4 -0.4 -1.4 -0.9  2.8 -0.4  2.8  5.  -0.5 -0.5  1.6 -1.3 -0.5 -0.6 -0.7 -1.   0.  -0.3 -0.2 -0.7  0.  -0.1 -0.8 -1.1  1.6 -0.4  0.9 -0.7  4.7 -1.3 -0.7 -0.8  3.2  4.7  3.1  1.1  5.3  0.5  7.1 -0.3  3.7 -0.8 -0.2  0.8 -1.2 -0.2  0.4 -0.5 -1.2 -0.5 -0.9 10.4  1.   2.9  1.3]
ty_50sample [[9 8 3 0 0 2 4 7 1 6]
 [7 8 1 1 9 6 3 2 4 5]
 [8 5 0 9 7 1 2 6 3 3]
 [8 2 5 1 3 3 4 9 9 6]
 [8 3 2 6 5 1 1 7 9 4]
 [0 5 7 1 1 3 3 2 9 4]
 [0 9 6 7 8 3 5 4 2 1]
 [2 9 9 8 8 7 7 5 0 4]
 [5 6 3 0 9 4 8 2 1 7]
 [5 3 6 1 4 7 9 9 8 2]]
tt_50sample [[9 8 3 0 5 2 4 1 7 6]
 [8 7 1 9 0 6 3 2 4 5]
 [8 5 0 9 7 1 2 6 3 4]
 [8 2 5 1 7 3 4 9 0 6]
 [8 3 2 5 6 0 1 7 9 4]
 [0 5 7 1 3 8 6 2 9 4]
 [0 9 6 7 8 5 3 4 2 1]
 [2 9 3 8 1 6 7 5 0 4]
 [5 3 6 0 9 8 4 2 1 7]
 [5 3 6 1 4 7 9 0 8 2]]
vm  [-0.2  4.4 -1.8 -0.4 -0.3 -0.5 -0.6 -0.4 -2.   1.7 -1.8 -0.6 -0.2 -0.3 -1.3 -0.3  3.  -0.5 -0.8 -1.6 -0.4 -1.   5.7  0.8 -1.2 -0.3  0.1 -0.4  0.  -0.3 -0.3 -0.4 -0.  -3.9 -0.5  0.7  4.3 -0.3 -1.  -1.1 -0.6  3.5  4.1  0.1 -0.6 -0.3 -0.5  0.6 -0.1  8.4  1.  -0.9 -1.2 -0.2 -1.   1.6 -0.8 -0.3 -1.   4.2  2.3 -0.3 -0.7 -1.2 -0.6  1.3 -0.4 -0.   0.1  0.5 -0.6 -0.   3.2 -0.9 -0.2 -0.1  4.  -0.4  4.9 -0.3 -1.5 -0.4 -1.4 -0.3 -0.1  5.   2.1 -0.3  1.9 -0.6 -0.4 -0.4 -0.6  2.  -0.3  0.5  0.2 -0.2 -0.3 -0.6 -0.  -0.   1.1 -0.3  1.4  1.1 -0.9 -0.5 -1.  -1.5 -0.7  0.  -0.  -0.   0.3  1.3 -0.7 -1.  -0.2 -0.2 -0.3  2.8  2.7 -0.3 -0.4 -1.5  3.   2.8 -0.1 -0.6  1.9 -0.3  0.2 -0.  10.9  1.5 -0.3 -0.8 -1.2 -0.8  2.2 -0.7  0.2  1.4 -1.1  0.1  0.6  0.3  4.7  2.6  1.7  0.2  1.5 -0.7 -0.1 -0.5  0.9 -0.2 -0.9 -1.2  0.6  5.  -0.8 -0.8 -2.4  0.  -0.  -0.   2.3  0.4  3.2  1.8 -0.5  0.2 -0.3 -1.5 -0.9 -0.5  6.5 -0.2 -0.9  2.6  2.  -1.2  0.2  5.7  0.8  2.7 -0.1  1.7 -0.3 -0.7  1.4 -1.4  0.4  1.  -0.3  1.8 -0.3 -0.9 -0.2 -0.2 -0.4 -1.2  3.  -1.4 -0.2  3.1  4.4 -0.1 -0.2  0.2 -1.4  4.1  1.7 -0.4  2.8  0.  -0.6 -1.  -0.3 -0.1 -0.8 -0.2  4.7  1.5 -0.7 -0.1 -0.4  0.5 -0.  -0.1 -0.7  3.4  5.5  6.4  1.3 -0.2 -0.3 -0.5 -0.9 -0.2 -0.1 -0.5  5.6  0.4  1.3  1.2  0.2 -0.3  0.8 -0.3 -1.1 -0.3  1.   3.3]
vy_50sample [[8 6 1 1 0 0 9 2 3 3]
 [9 4 0 6 7 1 3 5 2 2]
 [4 9 9 6 6 3 8 2 2 5]
 [1 3 4 7 5 0 6 9 2 8]
 [4 2 8 1 3 0 7 6 5 9]
 [8 3 1 5 6 6 4 9 0 0]
 [2 3 7 7 6 6 9 8 8 1]
 [6 2 1 1 5 8 0 3 7 9]
 [1 4 0 5 9 3 7 8 2 6]
 [6 0 4 3 3 7 8 8 5 2]]
vt_50sample [[8 6 5 4 1 0 9 2 7 3]
 [4 9 0 6 7 3 1 5 8 2]
 [4 0 9 6 8 3 1 7 2 5]
 [1 3 4 7 5 6 0 9 2 8]
 [4 2 8 1 3 0 7 5 6 9]
 [8 3 1 5 6 2 4 9 7 0]
 [2 3 0 7 6 5 4 9 8 1]
 [6 2 4 1 5 8 0 3 7 9]
 [1 4 0 5 9 3 7 8 2 6]
 [6 0 4 3 7 9 1 8 5 2]]
Epoch  3810: Training cost= 0.5753, Training acc= 0.6836, Validation cost= 0.5389, Validation acc= 0.6842
Epoch  3820: Training cost= 0.5765, Training acc= 0.6838, Validation cost= 0.4775, Validation acc= 0.6844
Epoch  3830: Training cost= 0.5356, Training acc= 0.6841, Validation cost= 0.4976, Validation acc= 0.6847
Epoch  3840: Training cost= 0.5261, Training acc= 0.6844, Validation cost= 0.4608, Validation acc= 0.6849
Epoch  3850: Training cost= 0.5609, Training acc= 0.6846, Validation cost= 0.5365, Validation acc= 0.6852
Epoch  3860: Training cost= 0.5123, Training acc= 0.6849, Validation cost= 0.4803, Validation acc= 0.6855
Epoch  3870: Training cost= 0.5272, Training acc= 0.6851, Validation cost= 0.5568, Validation acc= 0.6857
Epoch  3880: Training cost= 0.4961, Training acc= 0.6854, Validation cost= 0.5179, Validation acc= 0.6859
Epoch  3890: Training cost= 0.5314, Training acc= 0.6856, Validation cost= 0.5018, Validation acc= 0.6862
Epoch  3900: Training cost= 0.4578, Training acc= 0.6859, Validation cost= 0.4888, Validation acc= 0.6865
tm  [-0.7  0.8  3.2 11.  -1.1  0.  -0.2 -0.5 -0.8 -0.2 -0.1  0.3 -0.9  0.1 -1.2 -0.6  0.2 -0.  -0.1 -1.5 -0.1 -0.3  2.4  2.  -1.4  3.5 -0.  -0.4 -0.6 -0.6 -0.9 -0.2 -0.1 -0.7 -0.8  0.4  3.7  3.   3.5 -0.4 -0.3  4.   3.2 -0.7 -0.9 -0.8  3.1  1.3 -0.7  4.5 -0.5  0.3  2.6 -0.8 -0.2  4.2 -0.3  2.8 -1.1  4.2  3.  -0.8  0.1  0.  -0.5  0.1 -0.3 -0.5  0.1  0.5 -0.3  2.5  0.6 -0.5  3.6 -0.   4.3 -0.6  0.9 -0.1  6.   0.7 -0.6 -0.4  0.3  6.3 -0.4 -1.   1.2  0.1  0.3  0.3 -0.3  2.8 -0.1 -0.2  6.1  1.  -0.4 -0.4  1.   0.6  1.7 -0.9 -0.3  1.2 -0.2 -0.8 -0.1 -1.3 -0.3  0.6 -0.2  1.6  2.  -0.3 -0.5 -0.9 -0.4  0.8  0.4  3.3  0.1  0.7 -0.3 -1.4  2.5  4.7 -0.3 -0.8 -0.7 -0.2 -1.6  0.6  5.6  1.3  0.1 -1.   1.2 -0.4  0.6 -0.9 -0.8 -0.  -0.5 -0.6  2.2 -0.4  5.2  1.2 -2.2 -0.6 -0.1  0.8 -0.4  0.3  1.  -0.1  1.3 -0.7 -0.   2.6 -0.8 -0.2 -1.2 -0.4 -0.7 -0.3 -0.4  5.3  0.5  1.2 -0.5 -0.3 -0.2 -1.  -0.6  2.  -0.2 -0.1 -1.2 -0.   2.5 -1.7 -0.4 -0.1 -0.2  1.4  4.   5.4 -0.8 -0.7 -0.5 -1.   0.1  2.1  1.5  2.3 -0.4 -0.4 -0.3 -0.6 -0.7 -1.1  2.7  0.6  0.6  2.2 -1.  -0.5 -0.4 -0.   0.7  4.6 -1.3 -0.5  3.7 -0.5 -0.2 -0.1 -0.6  0.5  0.6 -0.5  2.3 -0.1 -0.5  3.   0.  -1.1 -0.1  0.1 -0.7 -0.7  4.1 -0.5  0.9  2.3 -0.5  1.  -0.9  0.6 -0.9 -0.6 -0.6 -1.2  2.4  2.   0.1 -0.3 -0.9 -0.8  4.5  1.8  2.8  5.3]
ty_50sample [[1 1 0 0 6 8 2 2 3 4]
 [1 6 8 0 4 2 5 7 3 9]
 [1 6 8 3 2 0 9 5 7 4]
 [0 2 4 6 1 8 3 9 5 7]
 [2 0 7 7 5 1 8 9 3 4]
 [8 1 5 3 3 2 0 4 4 9]
 [7 8 1 2 5 9 9 4 6 3]
 [2 9 7 0 3 6 5 8 8 1]
 [6 4 5 3 3 8 2 8 1 0]
 [6 7 9 2 1 5 4 0 3 8]]
tt_50sample [[1 5 9 0 6 8 2 3 7 4]
 [1 6 8 0 4 2 5 7 3 9]
 [1 6 8 3 2 0 9 5 7 4]
 [0 2 4 6 1 3 8 9 5 7]
 [2 6 0 7 5 1 8 9 3 4]
 [8 1 5 3 2 0 6 7 4 9]
 [7 8 2 1 5 9 0 4 6 3]
 [2 9 7 0 3 6 5 4 8 1]
 [6 4 5 3 9 7 2 8 1 0]
 [7 6 2 9 1 5 4 0 3 8]]
vm  [-0.6  0.4 -1.4  1.  -0.2 -1.  -0.1 -0.5 -0.2 -0.4 -2.8  0.8 -1.  -0.3 -1.2  2.5 -0.6 -0.  -0.7 -0.2 -0.5  0.4  3.3 -0.4 -0.7 -0.3 -0.5 -0.5  4.3 -0.7 -0.1 -0.6 -0.1 -2.9 -0.2 -1.2 -0.7  3.1  3.9 -0.8  0.  -0.6 -0.8  3.9 -0.4  0.3  1.5  1.5 -0.1  4.5 -0.3 -1.   0.  -1.  -1.4  4.3  0.7  0.   2.7  1.6 -0.3 -0.5  1.7  0.3 -0.7 -0.7 -0.4  0.6  0.9  1.6  0.  -1.   2.7  1.3 -1.5  0.  -0.2 -0.4  2.9 -0.2 -1.3 -0.2 -0.2 -0.3 -0.7 -0.2  1.4 -0.2  2.7 -0.3  1.  -1.3 -0.1 -0.9  0.4 -0.4 -0.6 -0.8 -0.8 -0.5 -0.4 -1.  -0.1  1.9 -0.4 -0.4 -0.8 -0.6 -1.8 -0.6 -0.  -0.2 -0.2 -0.4  0.2  4.8 -0.3  1.1  0.4  2.6 -0.5  1.5 -0.3 -1.  -0.1 -1.2  1.5  6.3  3.9  1.5  4.  -0.3  0.3 -1.   4.7 -3.3  1.7 -0.8 -0.4  0.7  2.5 -0.3  4.1 -0.  -1.1  4.3 -0.4 -0.   2.4 -0.1  1.6 -0.1  4.1  0.8 -0.5 -0.  -0.9 -0.7  0.5 -0.3 -0.  -0.9  0.5 -0.6 -1.4 -0.3  3.6  4.1  1.1  0.4  0.3 -0.5 -0.8 -1.  -0.2  0.2 -0.5  2.4 -0.4  1.  -0.  -0.2 -0.9 -0.7 -0.2  1.6  1.3  0.7 -1.   2.6 -0.4 -0.5 -1.2 -1.6  3.4 -0.4  1.6 -0.3 -0.4 -1.3 -0.8  4.3 -0.5 -1.2 -0.5 -0.1 -1.4  0.3  7.7 -0.6  0.   5.1 -1.7  3.1 -0.6 -0.2 -0.4 -0.1 -0.1  0.8 -1.4 -0.3 -0.6 -0.6  0.   5.4 -1.3  1.8 -0.6  4.6 -1.  -0.7 -1.4  5.  -0.4  6.3  1.6 -0.3  2.7  7.1 -0.3  3.8 -0.2  0.1  5.1 -1.8  0.9 -0.4 -0.6 -0.9  1.5 -0.2  3.8 -0.6  3.8  1.8]
vy_50sample [[8 4 9 3 1 1 5 2 7 0]
 [3 0 8 9 4 5 1 2 2 7]
 [7 2 3 9 1 5 5 8 8 6]
 [3 0 0 5 9 2 2 6 8 4]
 [5 8 3 9 6 1 2 7 4 4]
 [6 0 7 2 9 8 4 5 1 3]
 [2 7 3 3 8 1 0 9 6 5]
 [9 2 3 7 4 8 6 1 5 0]
 [4 6 3 3 7 8 2 1 5 0]
 [4 5 6 9 2 2 1 3 8 7]]
vt_50sample [[8 4 9 3 1 6 5 2 7 0]
 [3 0 8 9 4 5 1 2 6 7]
 [7 2 3 9 4 1 5 0 8 6]
 [3 1 0 5 9 7 2 6 8 4]
 [5 8 3 9 6 1 2 7 0 4]
 [6 0 7 2 9 8 5 4 1 3]
 [2 7 3 4 8 1 0 9 6 5]
 [9 2 3 7 4 8 6 1 5 0]
 [4 6 3 7 9 8 2 1 5 0]
 [4 5 6 9 2 0 1 3 8 7]]
Epoch  3910: Training cost= 0.4830, Training acc= 0.6861, Validation cost= 0.5322, Validation acc= 0.6868
Epoch  3920: Training cost= 0.5514, Training acc= 0.6864, Validation cost= 0.5070, Validation acc= 0.6870
Epoch  3930: Training cost= 0.5043, Training acc= 0.6866, Validation cost= 0.5416, Validation acc= 0.6872
Epoch  3940: Training cost= 0.5297, Training acc= 0.6869, Validation cost= 0.4992, Validation acc= 0.6875
Epoch  3950: Training cost= 0.5293, Training acc= 0.6871, Validation cost= 0.5269, Validation acc= 0.6878
Epoch  3960: Training cost= 0.5529, Training acc= 0.6873, Validation cost= 0.5176, Validation acc= 0.6880
Epoch  3970: Training cost= 0.5020, Training acc= 0.6876, Validation cost= 0.4849, Validation acc= 0.6883
Epoch  3980: Training cost= 0.4915, Training acc= 0.6879, Validation cost= 0.5170, Validation acc= 0.6885
Epoch  3990: Training cost= 0.5185, Training acc= 0.6881, Validation cost= 0.4605, Validation acc= 0.6888
Epoch  4000: Training cost= 0.5057, Training acc= 0.6884, Validation cost= 0.5439, Validation acc= 0.6890
tm  [-1.5 -1.   7.5  4.4 -1.5 -0.  -1.  -0.6  3.6  4.7 -0.1  0.9 -0.8 -0.6  6.8 -1.5 -1.5 -0.4 -0.3  2.8 -0.5 -0.4  2.6 -0.9 -0.1  1.4 -0.1 -0.3 -0.5 -2.3 -0.9  0.2 -0.9  3.2  1.9 -1.8 -0.9  2.1  0.7 -0.3 -0.5  3.6 -1.3 -0.3 -1.5 -0.  -1.2 -0.5 -0.7  3.4 -0.9 -0.4 -0.6  2.5  0.8 -0.5 -0.5  2.4  6.3  4.5  7.1 -0.7  2.5  7.1  0.6 -0.3 -0.3  0.5  1.1 -0.4  1.5  2.  -0.1  1.  -5.2 -0.3 -0.2 -0.6  3.   0.5 -0.9 -0.1  2.3  0.   0.5  3.  -0.9 -0.9 -0.9  0.1  0.3 -1.3 -1.8 -1.5 -0.8 -0.6  1.7 -1.6 -0.5 -0.3 -1.5  5.4  6.6 -0.4 -0.5 -0.5 -2.8 -0.6 -0.1  1.3  2.9  0.6 -0.3 -0.8  8.7 -1.4  0.5  3.5 -0.8  4.  -0.2 -0.8 -0.4  0.5 -0.2  7.  -0.6 -0.   4.7  0.9 -1.  -1.1 -2.2 -0.1 -2.  -1.2 -0.3 -0.4 -0.3 -0.2  0.   0.5 -0.4 -0.8 -0.8 -0.7 -0.5 -0.8 -0.3 -1.  -0.1 -0.6 -0.4  2.3 -0.2 -0.1 -0.2 -0.1  3.3  0.2  2.  -1.4  2.5 -0.5  0.4 -0.2 -1.2  2.6 -1.3  2.3  1.6  0.5 -0.1 -0.8 -0.3  2.7 -0.6 -0.1  2.2  2.9 -0.4 -1.2 -0.6 -0.6  4.3 -0.8 -1.1 -0.7  2.3  8.8 -0.8 -0.7 -0.8 -1.  -1.5 -0.9 -1.6 -1.4 -0.9  0.7 -0.9  1.7 -0.8 -0.7  2.2 -1.7  0.5 -0.8  1.4 -0.6 -0.1 -0.8 -0.4  5.6 -1.7 -0.2  2.7 -0.8 -0.2 -0.1 -1.3 -0.7 -0.3 -0.5  0.1 -0.7 -1.   5.3  1.1 -0.2 -0.6  0.6 -0.4  0.7  1.8 -1.7  3.8 -2.2  2.5 -0.8 -0.9 -0.4 -0.1 -0.9  4.7 -0.4 -0.5 -0.  -0.6 -0.2  0.8 -0.7  1.8  0.3  2.   1.3]
ty_50sample [[1 0 7 8 5 2 3 6 9 4]
 [3 2 0 1 8 9 6 4 7 5]
 [4 1 3 2 5 7 0 8 9 6]
 [9 1 0 5 2 8 7 4 3 6]
 [1 4 0 8 3 2 7 7 5 6]
 [9 9 4 4 2 6 1 0 3 3]
 [8 2 4 9 3 1 5 5 6 0]
 [5 0 8 2 7 6 6 3 4 4]
 [4 6 6 5 5 3 2 8 7 0]
 [7 2 5 1 8 3 6 4 9 0]]
tt_50sample [[1 0 7 8 5 2 3 6 9 4]
 [3 2 0 1 8 9 6 4 7 5]
 [4 1 3 2 5 0 7 8 9 6]
 [9 1 0 5 2 8 7 4 3 6]
 [1 4 0 3 8 9 2 7 5 6]
 [5 9 4 7 2 6 1 0 3 8]
 [8 2 4 3 9 1 7 5 6 0]
 [5 0 8 2 7 6 9 1 3 4]
 [4 1 6 9 5 3 2 8 7 0]
 [7 2 1 5 8 3 6 4 9 0]]
vm  [ 1.1 -1.2  4.9  6.2 -1.2 -1.  -0.6 -0.8  3.5 -0.8 10.3 -0.4  0.5 -0.5  2.   7.1 -0.6 -0.5  1.9 -0.4 -0.6  0.6 -1.1 -0.5 -1.  -0.1 -0.4 -0.3  1.6 -0.8  2.9 -1.  -0.1  8.4  2.4  0.2 -0.6  4.3  3.9 -1.1 -0.  -0.2 -0.8  0.  -0.8 -0.6  2.  -0.9  3.3 -1.5 -1.7 -0.4  1.8  3.9 -0.6  0.1 -0.5  5.   3.  -0.3 -0.8 -0.5  0.1  6.8  1.6 -0.1 -0.6  3.1  0.4 -0.3  0.  -0.4 -0.7  0.5 -1.9  0.2 -1.4  0.1 -0.2 -0.   9.7 -0.5 -0.2 -0.2 -1.1 -0.2 -0.4 -0.4  1.  -0.3 -0.7 -0.8  0.1 -1.2  0.4 -0.  -0.2 -1.  -0.3 -0.1  0.5  1.2 -0.2 -0.3 -0.3 -0.1 -0.6  3.1  5.1 -0.7  1.6 -0.3 -0.5 -0.6 -0.1  2.7  0.3  3.1  0.3  2.  -0.5  1.9 -0.2  0.6 -0.1  2.3 -0.7 -0.6  4.1  1.3  4.7 -1.1 -0.4 -0.3 -1.   7.3 -0.3  0.6  0.5 -0.4 -1.3  0.7 -0.1 -0.3 -0.6  2.3 -1.1 -0.9 -0.2 -0.6 -0.3 -0.3  2.1 -0.7 -0.3 -0.4 -0.7 -0.5 -0.1 -0.1  1.9 -0.9 -0.  -0.4  4.4 -0.7  2.6  1.  -0.4  3.5 -1.  -0.  -0.4 -0.6 -0.6  3.1 -0.8  1.1 -0.1 -0.4 -0.2 -0.5 -1.2 -1.  -0.3 -1.3  5.2 -1.1 -0.5  4.8 -0.5 -0.  -1.3 -0.9  5.9 -0.9  0.3 -0.7 -0.8  1.2 -0.8 -0.2 -0.6 -0.4 -0.9 -0.3  1.8  0.6 -1.2 -0.8 -0.2  2.9 -1.2 -0.2 -1.   0.1  1.7 -0.8  0.9 -0.1 -0.4 -0.8 -0.1 -0.4  0.3  1.   1.8  2.9  0.6  7.1 -0.8 -0.8 -0.7 -0.9 -0.5 -1.1  0.6 -0.4  2.5  4.  -0.7  2.8 -0.2 -0.1 -1.5 -1.1 -0.4  0.1 -0.9 -0.4 -1.9 -0.1  3.7  1.7  0.9  1.5]
vy_50sample [[2 7 3 9 5 6 4 0 1 8]
 [6 1 3 5 4 9 2 0 7 8]
 [6 4 3 0 1 8 7 9 9 5]
 [9 8 1 4 3 3 6 2 0 5]
 [8 2 9 0 6 1 5 7 4 3]
 [3 7 0 8 5 1 6 4 2 9]
 [1 4 9 3 3 0 2 2 8 5]
 [3 4 0 2 8 7 6 6 1 5]
 [4 0 9 6 7 5 5 3 3 2]
 [1 7 6 6 9 9 4 3 2 0]]
vt_50sample [[2 7 9 3 5 6 4 0 1 8]
 [6 1 3 5 4 9 2 0 7 8]
 [6 4 3 0 1 8 7 2 9 5]
 [9 8 1 4 3 7 6 2 0 5]
 [8 9 2 6 0 1 5 7 4 3]
 [3 7 0 8 5 1 6 4 2 9]
 [1 9 4 3 0 7 6 2 8 5]
 [3 4 0 2 8 7 9 6 1 5]
 [0 4 9 6 7 8 5 1 3 2]
 [1 7 5 6 9 8 4 3 2 0]]
Epoch  4010: Training cost= 0.4459, Training acc= 0.6886, Validation cost= 0.5091, Validation acc= 0.6892
Epoch  4020: Training cost= 0.5517, Training acc= 0.6888, Validation cost= 0.5358, Validation acc= 0.6895
Epoch  4030: Training cost= 0.4591, Training acc= 0.6891, Validation cost= 0.4315, Validation acc= 0.6897
Epoch  4040: Training cost= 0.4743, Training acc= 0.6893, Validation cost= 0.5245, Validation acc= 0.6900
Epoch  4050: Training cost= 0.4703, Training acc= 0.6896, Validation cost= 0.4633, Validation acc= 0.6902
Epoch  4060: Training cost= 0.4994, Training acc= 0.6899, Validation cost= 0.4798, Validation acc= 0.6905
Epoch  4070: Training cost= 0.5301, Training acc= 0.6901, Validation cost= 0.5133, Validation acc= 0.6907
Epoch  4080: Training cost= 0.5065, Training acc= 0.6904, Validation cost= 0.4827, Validation acc= 0.6910
Epoch  4090: Training cost= 0.5011, Training acc= 0.6906, Validation cost= 0.5951, Validation acc= 0.6912
Epoch  4100: Training cost= 0.5645, Training acc= 0.6908, Validation cost= 0.4947, Validation acc= 0.6914
tm  [-1.6 -0.4 -1.2 -2.6 -0.9 -0.1 -0.4 -0.9 -0.2  3.6 -2.   0.6 -1.2 -0.5  3.7 -0.9 -1.  -0.1 -1.   1.3 -0.3 -0.4  4.5 -0.2 -0.2 -0.1 -0.2 -0.4  0.9 -1.   2.7 -0.   0.1 -0.9  1.  -1.4 -0.7  0.2 -0.6 -0.5 -0.4  2.7 -0.9  2.9 -1.2  0.3 -1.6  1.  -1.1  6.6 -0.6 -1.2 -1.   0.1 -1.  -0.2 -0.3 -0.7  4.4 -0.4  8.3 -0.5  1.2  0.3  0.3 -0.5 -0.3  0.8  1.8 -0.1 -0.1 -0.4  0.3  0.2 -4.5 -0.5  2.2 -0.3  8.2 -0.1 -2.1 -0.5  2.7 -0.3  0.3  3.2  0.4 -0.5 -0.6 -0.4 -0.3 -1.5 -1.8 -1.6 -1.4 -0.1 -0.9 -1.6 -0.5 -1.  -1.3  3.8  5.4 -0.  -0.6 -0.2 -2.7  3.3 -1.4  2.  -0.3  0.5 -0.1 -0.8  5.9 -0.1 -0.   1.3 -0.9  1.7 -0.8 -0.9  0.2 -0.2 -0.3  3.9 -0.3  2.3  3.4  0.6  0.1 -0.9 -0.9 -0.5  4.4 -0.5 -0.3 -0.6 -0.1 -0.4  3.   1.4  3.6  0.8 -1.5  0.3  0.1 -0.1  0.2  0.3  4.9 -0.3 -0.2  1.3 -0.3  0.9 -0.2 -0.3 -0.  -0.4  1.7 -0.5  2.5 -0.7 -0.9  0.3 -0.8  3.7  0.  -1.1  1.5  0.6 -0.5 -0.8 -0.4  1.3 -0.9 -0.1  6.3  3.3 -0.  -0.3  0.4 -1.2  2.  -0.5 -1.4 -0.  -0.1  2.6 -0.5 -1.  -0.5 -1.5 -1.7 -0.1 -1.5 -0.4 -0.8 -1.  -0.8  4.  -0.7 -1.   2.7 -2.  -0.4 -0.7  4.5 -0.6 -0.1 -0.  -0.8  8.6  0.6 -0.1 -0.4 -0.4 -0.1  1.5 -1.3 -0.3 -0.6 -0.5  3.3  2.3 -1.5  2.6 -0.3  0.2 -0.5  0.9 -0.7  3.1  1.6  5.7  4.2 -2.1  3.9 -0.3 -0.8 -0.3 -0.1 -0.4  7.4 -0.4  0.1 -0.2 -0.6 -0.2  3.1  0.6 -0.7 -0.8  3.5  2.7]
ty_50sample [[1 4 8 6 0 7 5 9 3 2]
 [9 1 1 7 6 3 3 8 0 4]
 [5 3 4 4 8 8 6 2 7 7]
 [6 1 8 2 7 9 4 0 3 5]
 [5 9 6 3 2 8 0 0 4 4]
 [9 4 4 3 3 8 1 7 2 5]
 [0 0 4 1 1 2 7 8 5 3]
 [9 5 8 8 2 6 7 7 0 1]
 [7 0 8 8 3 4 9 1 2 6]
 [4 5 6 0 2 2 7 7 3 9]]
tt_50sample [[1 4 8 6 0 7 5 9 3 2]
 [9 1 2 7 5 6 3 8 0 4]
 [5 3 1 4 9 8 6 2 7 0]
 [6 1 8 2 9 7 4 0 3 5]
 [5 9 6 2 3 7 8 0 4 1]
 [9 6 4 3 8 0 1 7 2 5]
 [9 0 6 1 4 8 2 7 5 3]
 [9 5 3 8 6 2 7 4 1 0]
 [7 5 0 8 3 4 9 1 2 6]
 [4 5 0 6 2 8 7 1 3 9]]
vm  [-0.4 -1.3 -0.5  2.  -0.6 -0.8 -0.4 -0.6  2.1 -0.6  1.4  2.1 -0.9 -0.8 -0.6 -1.9 -0.4 -0.4 -0.3 -0.6 -0.1  0.3 -1.6 -0.3 -0.3  1.  -0.2 -0.3 -0.9 -1.3  4.4  0.9  1.4  4.2  1.2 -0.7  0.4 -0.9 -1.1 -1.6 -0.5 -0.2 -0.2 -0.7 -0.3 -0.1 -0.1  2.2  2.7 -2.1 -1.1 -0.8 -0.2 -1.1 -0.1  3.1  0.1  0.9  1.1 -0.9  0.7 -0.7  0.   3.7 -0.9 -0.2 -0.3  2.4  2.5  3.1 -0.7  2.8 -1.1 -1.  -2.  -0.2 -0.5 -1.1  2.9  0.   8.1 -0.5 -0.6 -0.4 -0.5 -0.5  0.7 -0.2  1.6 -0.3 -0.3 -0.5 -0.1 -0.3 -0.2 -0.1  0.4 -1.2 -0.2 -0.3 -0.1 -1.2  1.2 -0.2 -0.3 -0.2 -1.4  4.8  0.3 -0.5 -0.1  2.7 -0.6 -0.5  6.4 -0.7 -0.8  3.4 -0.5  2.8 -0.   2.3  0.6  1.8 -1.1 -0.6  1.4  6.8  1.4  2.6  4.9 -1.5 -0.4 -0.8 10.2 16.2 -0.6  1.2  0.5 -0.8  2.6 -0.1  2.1  0.5 -1.3 -0.6 -0.6 -0.7  1.8 -0.9  1.3 -0.2 -0.9  2.4 -0.7 -0.3  0.7 -0.2 -1.1 -0.  -0.2  1.4  0.6 -0.7  0.3 -0.3 -0.   3.7 -0.4  0.6 -1.  -0.  -0.5 -0.6  0.1 -0.3 -1.1  0.5  6.9  3.2 -0.4 -0.6 -0.4 -0.6  1.3 -1.5  1.  -0.2  0.3  5.8 -0.5 -0.2 -0.8 -0.9  1.7 -0.  -0.2 -0.9 -0.5 -0.3 -0.8  3.7 -0.1 -0.7  0.7 -0.9  2.1 -0.6 -1.7 -0.4 -0.3 -0.5 -1.3  1.2 -0.9 -0.3  4.7 -0.6 -0.5 -0.   0.6 -0.1 -0.1 -0.6  1.7 -1.1 -1.5 -0.   0.5  5.3  1.3  1.1 -0.6 -1.1  4.8  3.1  2.  -0.6  3.4  1.8 -1.3  0.5 -0.5 -0.5 -1.1 -0.7 -0.3 -0.7 -0.7 -0.3 -1.5 -1.7 -1.  -0.6  4.3 -0.2]
vy_50sample [[6 0 3 9 4 1 7 7 8 2]
 [9 4 5 5 6 2 3 0 8 7]
 [9 1 5 5 7 0 4 3 6 6]
 [5 4 8 3 7 6 2 2 0 0]
 [4 0 5 9 6 1 3 2 2 8]
 [9 8 8 3 1 2 7 0 5 6]
 [8 8 4 4 9 9 2 6 1 1]
 [0 8 2 2 7 3 4 4 5 6]
 [2 1 9 4 6 3 7 0 8 5]
 [4 3 9 5 7 7 0 1 2 8]]
vt_50sample [[6 0 3 9 5 4 1 7 8 2]
 [9 4 1 5 6 2 3 0 8 7]
 [9 1 5 7 2 0 4 3 8 6]
 [5 4 8 7 3 1 6 2 0 9]
 [4 0 5 9 6 1 3 2 7 8]
 [9 8 4 3 1 2 7 0 5 6]
 [8 5 3 4 9 7 6 2 0 1]
 [0 1 8 2 7 3 9 4 5 6]
 [2 1 9 4 6 3 7 0 8 5]
 [4 3 9 5 6 7 0 1 2 8]]
Epoch  4110: Training cost= 0.5704, Training acc= 0.6910, Validation cost= 0.4896, Validation acc= 0.6917
Epoch  4120: Training cost= 0.5024, Training acc= 0.6913, Validation cost= 0.4680, Validation acc= 0.6919
Epoch  4130: Training cost= 0.4860, Training acc= 0.6915, Validation cost= 0.4574, Validation acc= 0.6921
Epoch  4140: Training cost= 0.4801, Training acc= 0.6918, Validation cost= 0.5218, Validation acc= 0.6924
Epoch  4150: Training cost= 0.4719, Training acc= 0.6920, Validation cost= 0.5225, Validation acc= 0.6927
Epoch  4160: Training cost= 0.5047, Training acc= 0.6923, Validation cost= 0.4655, Validation acc= 0.6929
Epoch  4170: Training cost= 0.4477, Training acc= 0.6925, Validation cost= 0.5307, Validation acc= 0.6932
Epoch  4180: Training cost= 0.4978, Training acc= 0.6928, Validation cost= 0.5415, Validation acc= 0.6934
Epoch  4190: Training cost= 0.4450, Training acc= 0.6930, Validation cost= 0.5358, Validation acc= 0.6937
Epoch  4200: Training cost= 0.5012, Training acc= 0.6933, Validation cost= 0.4716, Validation acc= 0.6939
tm  [ 0.1 -0.9  0.3 -0.8 -0.9 -0.9 -0.1 -1.   3.4 -0.8  2.5  1.3 -0.5 -0.9  4.2  3.5 -1.3 -0.4  0.1  2.3 -0.6  1.1 -0.9 -0.6 -0.5  0.6 -0.4 -0.3  3.5 -1.   4.3 -0.8 -0.2  5.3  1.2 -0.8 -1.3  2.7 -0.3 -1.   0.6 -1.8 -1.5  3.1 -0.9  0.1 -0.8 -0.1  0.8 -1.5 -1.4 -1.2  1.4  1.6 -1.  -0.2  0.3  1.   4.6 -0.6  0.2 -0.3  1.3  4.3  1.8 -0.1 -0.7  3.1  2.5  1.6  0.8 -1.  -0.3  0.7 -3.5  0.2 -1.5 -0.5  2.8  0.1  1.8 -0.6  2.4 -0.1 -0.7 -1.6 -0.  -0.3  1.2 -0.2 -0.1 -1.3  0.4 -1.5 -0.2 -0.  -0.7 -1.9 -0.5  0.2 -0.1 -0.4 -0.1  2.7 -0.1 -0.1 -1.6  4.2  1.3  0.8  0.9 -0.5 -0.1 -0.9  1.4  2.8  0.2  4.9 -0.3  2.5 -0.5 -0.4 -0.3 -0.2 -0.4  5.  -0.6  1.5  3.7  5.5  5.2 -1.4  1.3 -0.6 -0.4  4.2  1.6  2.3  1.3 -0.3 -0.2  0.1  2.2 -0.3 -1.1  2.8 -0.9 -0.4 -1.  -0.6  3.9 -0.2  3.1  0.6 -0.4  0.1 -1.2 -0.5 -0.3 -0.3 -0.1 -0.9  3.1 -0.6  2.9 -0.5  4.9  6.4  0.4  0.4 -1.  -0.7 -0.6 -0.6 -0.6  5.1 -0.9 -0.3  3.3  1.8  2.  -0.4 -1.5 -0.8  0.3 -1.   2.3 -0.9 -0.8  3.9 -0.3 -0.1 -1.1 -1.3  1.7 -0.7 -0.6 -1.1 -0.9 -0.7 -0.5  3.  -0.8 -0.7 -1.  -1.2 -0.5 -0.3  5.1 -0.6 -0.1  5.1 -1.8  1.  -0.5  0.3 -0.2 -0.5  0.5  3.1 -1.  -0.2 -0.5 -0.6 -0.4  2.9 -0.5  2.5  0.3  7.3 -0.7 -0.3 -0.8  2.6 -0.7  1.9  1.  -1.3  5.9  5.8 -0.6  4.   0.1  0.1  1.  -0.6 -0.7 -0.5 -1.  -0.7 -0.7 -0.6  0.4 -0.3  3.6 -1. ]
ty_50sample [[3 4 7 6 6 2 1 1 5 0]
 [4 2 1 8 0 6 5 5 9 7]
 [5 9 6 1 4 0 8 3 2 7]
 [3 6 6 0 4 7 8 2 1 5]
 [6 1 4 7 0 9 8 3 2 5]
 [9 2 8 5 6 0 0 3 4 4]
 [7 7 4 6 6 3 2 5 8 8]
 [1 5 5 6 0 7 9 3 8 4]
 [6 6 8 7 9 9 3 5 0 2]
 [0 6 1 2 2 5 9 3 3 4]]
tt_50sample [[3 7 4 6 9 8 2 1 0 5]
 [4 2 1 8 0 6 3 5 9 7]
 [5 9 6 1 4 0 8 3 2 7]
 [3 6 9 0 4 7 8 2 1 5]
 [6 1 4 7 0 9 8 3 2 5]
 [9 8 2 5 6 0 7 3 1 4]
 [7 1 4 9 6 3 2 5 0 8]
 [1 5 2 6 0 7 3 9 8 4]
 [6 1 8 7 4 9 3 5 0 2]
 [0 6 1 8 2 5 9 3 7 4]]
vm  [ 0.5  0.7  4.6  3.2 -1.1 -1.7 -0.7 -0.9 -0.6  0.4 -3.5  2.3 -2.1 -0.7  4.3 -0.5  0.3  1.4 -0.   2.4 -0.1 -0.   4.6  0.9 -0.8 -0.6 -0.4  0.   1.7 -0.7 -1.  -0.7 -0.4 -0.8 -0.2 -1.3 -0.4  0.5 -0.1 -0.8 -0.1  4.6  1.6 -0.2 -0.9 -0.1 -1.1  1.7  2.7  6.6 -0.8 -0.5 -0.2 -0.8 -0.6 -0.1  0.2  3.9  0.8  5.3 -0.  -1.5  0.7  1.2 -0.5 -0.9 -0.2 -1.1  2.7 -0.2  1.3  0.2  3.1  0.3 -2.7  0.7 -0.6  0.9 -0.2 -0.3 -1.9  0.6  0.5 -0.2 -1.2  6.3  0.7 -0.3  1.4  0.9  1.5 -0.8 -1.  -0.6 -0.6 -0.3  3.5 -1.4 -0.2  0.  -0.5  5.1 -0.3 -0.4 -0.5 -0.4 -2.  -1.4 -1.9  1.1  1.5 -0.3 -0.5 -0.2 -0.3  2.4  0.2  0.8  1.3  2.  -0.7 -0.6 -0.3 -0.9  1.   3.6  0.1  5.2  3.5  0.4  3.6 -0.5 -0.2 -0.6 -0.3 -2.  -0.2 -1.  -1.   1.1  3.1 -0.7  4.4  0.6 -1.2  3.1 -0.7 -1.7  1.9  1.2 -0.1 -0.3  6.3  3.3 -0.4  0.3 -0.8 -0.4 -0.2 -0.6  0.4 -0.2  2.3 -0.3 -0.7 -0.2 -0.2 -0.1 -0.2  1.2  2.   2.3 -0.9 -0.7 -0.  -0.2 -1.1 -0.1  3.2  4.  -0.9 -0.6 -0.2 -1.   0.5 -0.   1.1 -0.4 -0.8  2.2 -0.1 -0.7 -0.7 -1.8  2.7 -0.4 -0.3 -0.6 -0.4 -1.2 -1.   2.1  0.9 -0.8  0.  -0.4 -0.1 -0.2  2.  -0.4 -0.3  2.3 -0.7  1.2 -1.1 -0.3  3.1  1.   3.   1.  -2.1 -0.4 -0.3 -0.3  1.9  3.6 -2.1  0.1 -0.4  4.1 -0.6 -0.4 -1.   1.6  0.4 -0.8  2.4 -1.   1.5 -1.3 -0.9 -0.9  0.9 -0.3  7.6 -1.  -0.   0.  -0.2 -0.2  3.9 -0.8  0.7 -0.4  5.   1.8]
vy_50sample [[8 7 7 6 9 9 3 1 2 2]
 [5 9 6 7 2 0 8 8 1 3]
 [2 1 3 9 6 0 7 8 5 4]
 [6 0 7 8 1 2 5 3 9 4]
 [8 0 5 1 2 6 9 4 3 3]
 [7 0 9 2 1 5 8 3 6 4]
 [4 3 1 8 5 7 2 2 6 0]
 [8 8 3 5 0 6 2 9 4 4]
 [5 1 8 8 9 0 4 3 6 6]
 [6 2 5 8 8 3 3 0 0 4]]
vt_50sample [[8 5 7 6 9 0 3 1 4 2]
 [5 9 6 2 7 0 8 4 1 3]
 [2 1 3 9 6 0 7 8 4 5]
 [6 0 7 8 1 2 5 3 9 4]
 [8 0 5 1 2 6 9 4 7 3]
 [7 0 9 2 1 5 8 3 4 6]
 [4 3 1 8 5 7 2 6 0 9]
 [8 3 7 0 5 6 2 9 4 1]
 [5 1 7 8 9 0 4 3 2 6]
 [6 2 5 8 7 1 3 9 0 4]]
Epoch  4210: Training cost= 0.4674, Training acc= 0.6935, Validation cost= 0.5350, Validation acc= 0.6942
Epoch  4220: Training cost= 0.4911, Training acc= 0.6938, Validation cost= 0.5265, Validation acc= 0.6944
Epoch  4230: Training cost= 0.5098, Training acc= 0.6940, Validation cost= 0.5632, Validation acc= 0.6946
Epoch  4240: Training cost= 0.5326, Training acc= 0.6942, Validation cost= 0.4614, Validation acc= 0.6948
Epoch  4250: Training cost= 0.4767, Training acc= 0.6944, Validation cost= 0.4906, Validation acc= 0.6950
Epoch  4260: Training cost= 0.5891, Training acc= 0.6946, Validation cost= 0.5470, Validation acc= 0.6952
Epoch  4270: Training cost= 0.5507, Training acc= 0.6949, Validation cost= 0.4886, Validation acc= 0.6954
Epoch  4280: Training cost= 0.5116, Training acc= 0.6951, Validation cost= 0.4871, Validation acc= 0.6957
Epoch  4290: Training cost= 0.5068, Training acc= 0.6953, Validation cost= 0.4863, Validation acc= 0.6959
Epoch  4300: Training cost= 0.4821, Training acc= 0.6955, Validation cost= 0.5765, Validation acc= 0.6961
tm  [ 2.1 -0.6 -1.  -0.9 -1.2 -1.1 -0.4 -1.1 -0.9  0.3 -1.4 -0.2 -1.1 -0.9  1.8  2.6 -0.1 -0.3 -0.5 -1.1 -0.   0.8  3.5 -0.1 -1.  -1.  -0.5 -0.1  5.   0.1  2.8 -0.7  0.  -0.1  1.4 -0.5  0.8  0.5  4.8 -0.9  0.9  2.7 -0.3  4.9 -0.9 -0.4  4.   1.6  2.4  6.3 -0.7 -0.8 -0.6 -0.8 -1.2  0.4 -0.4 -0.3  1.8 -0.5 -1.1 -0.6 -0.6 -0.1 -0.3 -0.7 -0.4  0.4  2.6 -0.4  0.6 -1.   0.8 -0.1 -1.9  0.2 -0.5  2.   3.2 -0.6 -0.4 -0.2 -0.5 -0.1 -1.3  4.3  3.  -0.2  1.  -0.5 -0.5 -0.9 -0.9 -1.2 -0.3 -0.3 -0.7 -0.4 -0.2 -0.6 -0.9  4.8 -0.9 -0.  -0.1 -0.7 -1.3  3.  -1.1 -1.1  0.1 -0.6 -0.3 -0.5 -0.5  4.4  0.4  0.5  0.   0.2 -0.5  2.3 -0.6 -1.8 -0.2  2.  -0.2  4.6  2.4 -1.   4.6 -0.6 -0.1 -0.4 -1.1 -2.  -0.1 -1.  -0.9 -0.1  0.6 -0.2  4.7  1.2 -1.3  4.7 -0.5 -1.2 -0.2  2.7  2.3  0.4  5.3  0.2 -0.5 -0.1 -1.2 -0.5 -0.4 -0.8  1.8 -1.1  0.8 -0.9  0.6 -0.1 -0.   0.8 -0.  -0.6  3.1  0.4 -0.8 -0.7 -0.6  1.7 -0.9  1.  -0.5  0.  -0.4 -0.  -0.2 -0.8 -0.4 -0.3  4.5 -0.6 -0.9 -0.3 -0.4 -1.2 -0.9 -1.8  7.4 -0.4 -0.2  1.3 -0.7 -1.5 -1.3  1.4 -0.4 -0.4 -1.  -0.2 -0.3  0.2  3.3 -0.1  0.4  3.5 -1.2  0.9  0.7 -0.1 -1.1 -0.1  1.2 -0.  -1.4 -0.7 -0.4 -0.4  1.7  4.3 -0.8 -0.6 -0.6  6.  -1.2 -0.5 -1.2  2.8 -0.9  4.   3.3 -0.9  3.1  5.  -0.4  2.8  0.4  1.9  2.9 -1.5  1.1 -0.4 -0.4  0.8  0.3  1.8  4.4 -0.7  2.1  5.7]
ty_50sample [[4 8 7 9 5 6 2 3 0 1]
 [5 7 3 4 8 2 0 6 1 1]
 [6 3 2 4 4 8 9 9 5 7]
 [4 5 2 3 7 0 6 6 1 8]
 [9 0 6 1 1 3 3 2 7 4]
 [9 4 4 5 8 3 1 2 6 7]
 [0 6 2 1 1 8 5 4 7 3]
 [6 8 1 4 7 3 5 2 0 9]
 [4 7 5 3 6 2 9 0 8 1]
 [5 8 0 4 2 3 7 9 1 6]]
tt_50sample [[4 8 7 9 5 6 2 3 0 1]
 [5 7 3 4 8 2 0 6 9 1]
 [6 3 2 4 8 0 1 9 5 7]
 [4 5 2 3 7 0 9 6 1 8]
 [9 0 8 6 1 3 5 2 7 4]
 [9 0 4 5 8 3 1 2 6 7]
 [0 6 2 9 1 8 5 4 7 3]
 [6 8 1 4 7 3 5 2 0 9]
 [4 7 5 6 3 9 2 0 8 1]
 [5 8 0 4 2 3 7 9 1 6]]
vm  [-1.1 -1.1 -1.4 -1.1 -0.8 -0.   0.5 -0.9 -0.1 -1.6  6.3  0.6 -0.1  0.  -0.5  3.   1.  -0.5 -0.2 -0.4 -0.1 -0.5 -1.7 -0.1 -1.5  2.4 -0.2 -0.4 -0.2 -0.7  7.2 -0.9 -0.   4.5 -1.   0.9  0.2  4.2  2.2 -1.  -0.  -0.8  0.6  4.  -0.8 -0.4 -0.3  0.2 -0.4 -2.6 -1.1 -1.   1.4  0.7 -1.2  2.5 -0.   0.3 -0.2 -2.1  3.2 -0.9 -0.1  1.9 -0.4 -0.1 -0.7  3.  -0.2  3.3 -0.5 -0.4 -0.9 -0.  -1.2  0.3  1.6 -1.1  2.4 -0.2  8.7 -0.5 -0.4 -0.4  0.2  0.5  1.6 -0.2  4.1  0.2 -0.4 -0.1  1.6  0.3 -0.1  1.1  0.6 -0.6 -0.2 -0.6  4.2 -1.5  1.2 -0.2 -0.4 -0.1 -1.3  7.1  2.8 -0.2 -0.6 -0.2 -0.4 -0.1  1.6  3.8 -0.4  0.8 -0.4 -0.3 -0.2  2.2  0.   2.1 -0.6 -0.2  2.4  2.1  1.6  4.9 -0.2 -0.9  0.8 -0.3  3.8  7.6  0.2  0.7  5.1 -0.7 -0.2  0.6  0.4 -0.2 -0.5 -0.3  0.3  0.1  3.1 -0.3  2.4 -0.4 -1.5  0.1 -0.8 -0.2 -0.4 -0.4  1.2 -0.1 -0.2 -0.1 -0.6 -0.3 -0.  -0.3  3.1  3.9  2.6 -0.6 -1.3  1.2 -1.2 -0.5 -0.9 -0.7 -0.2 -0.3  1.  -0.4 -0.5  0.4 -0.4 -1.2 -0.2 -1.1 -0.3  0.2 -0.3  3.4 -0.5 -0.1 -0.2 -1.2 -0.3  0.9 -0.4  0.9 -0.9 -0.5  0.2  2.  -0.8 -1.4  0.3 -1.   1.4 -0.1 -2.5 -0.5 -0.6  2.6 -0.6  4.3  0.5 -0.1 -0.9 -0.5 -0.3  0.9 -0.   3.1 -0.2 -0.6 -0.3  0.5 -0.1  0.9  0.6  2.  -0.9  0.3 -0.4 -1.6  2.8  6.3 -0.1 -0.8  2.4 -0.2 -0.4 -0.1 -1.2 -0.3 -1.4 -0.5 -0.  -0.4 -0.4 -0.9 -1.5 -0.3  1.4 -0.2  5.3 -0.8]
vy_50sample [[3 4 1 5 6 6 2 7 0 8]
 [9 6 0 8 7 3 3 4 1 2]
 [8 1 9 0 5 2 7 4 6 3]
 [8 7 0 6 6 4 3 3 5 5]
 [2 6 7 1 5 3 8 0 9 4]
 [9 7 3 8 0 1 5 6 2 4]
 [3 8 6 6 9 1 4 7 5 0]
 [2 3 0 0 4 7 8 6 1 5]
 [6 0 2 8 9 4 1 5 3 3]
 [4 2 5 1 3 0 6 7 8 9]]
vt_50sample [[3 4 1 5 6 9 2 7 0 8]
 [9 0 6 8 3 5 7 4 1 2]
 [8 1 9 0 5 2 4 7 6 3]
 [8 7 0 6 4 9 1 3 5 2]
 [2 6 1 7 5 3 8 0 9 4]
 [9 7 3 8 0 1 5 6 2 4]
 [3 8 6 2 9 1 4 7 5 0]
 [2 3 9 0 4 7 8 1 6 5]
 [6 0 2 8 9 4 1 5 7 3]
 [2 4 5 1 3 0 6 7 8 9]]
Epoch  4310: Training cost= 0.4745, Training acc= 0.6957, Validation cost= 0.5362, Validation acc= 0.6963
Epoch  4320: Training cost= 0.4995, Training acc= 0.6959, Validation cost= 0.5330, Validation acc= 0.6965
Epoch  4330: Training cost= 0.5964, Training acc= 0.6961, Validation cost= 0.4941, Validation acc= 0.6967
Epoch  4340: Training cost= 0.5157, Training acc= 0.6963, Validation cost= 0.5254, Validation acc= 0.6969
Epoch  4350: Training cost= 0.5005, Training acc= 0.6965, Validation cost= 0.4702, Validation acc= 0.6972
Epoch  4360: Training cost= 0.5001, Training acc= 0.6968, Validation cost= 0.4899, Validation acc= 0.6974
Epoch  4370: Training cost= 0.4440, Training acc= 0.6970, Validation cost= 0.4490, Validation acc= 0.6977
Epoch  4380: Training cost= 0.4829, Training acc= 0.6973, Validation cost= 0.5424, Validation acc= 0.6979
Epoch  4390: Training cost= 0.5495, Training acc= 0.6975, Validation cost= 0.4869, Validation acc= 0.6981
Epoch  4400: Training cost= 0.4432, Training acc= 0.6977, Validation cost= 0.4999, Validation acc= 0.6983
tm  [ 2.6  1.4 -1.2  2.9 -0.8 -1.1 -0.1 -0.7 -0.8 -1.4 -0.8  1.4 -1.3 -0.9 -1.5 -0.8 -0.1 -0.3  0.4 -1.2 -0.7 -0.3 -0.2  1.6 -0.9  3.7 -0.5 -0.5 -0.4  0.1  4.5 -0.4 -0.4  0.2  0.   1.3  2.6 -0.4  5.8 -1.7 -0.3 -0.5  0.8  3.8 -0.5  1.9  3.1  3.6  3.8 -0.5 -0.7 -0.6  3.3 -1.9 -0.1  5.   0.1  0.1 -0.8 -0.8 -1.7 -0.6  0.5  1.4 -0.5  0.  -0.2 -0.2  2.7  5.5 -1.   1.2 -0.1 -0.3  6.9 -0.2 -0.6 -0.6  1.7  0.8 10.1  0.6 -0.8 -0.  -1.2 -0.2  3.9 -0.3  2.9 -0.3 -0.  -0.1  1.   0.3  2.3  1.7  0.7  0.6 -0.3 -0.1  1.5 -0.7 -1.2 -0.2  1.2 -0.1  2.3  4.1 -0.3 -1.8 -0.9  1.7 -0.3  0.1  0.2 -0.1 -0.4  0.8 -0.  -0.1 -0.3  5.6 -0.3 -0.2 -0.5 -1.6  1.1  8.8  0.5  0.1  3.9 -1.   0.8 -0.8  3.9  2.7 -0.3 -0.4  2.3 -0.6  2.8 -1.3  3.2  1.  -0.8  2.6 -0.5 -0.5  2.  -0.2 -0.2  0.4  3.9  0.9 -0.4 -0.4 -0.4 -0.6 -0.3 -0.4  0.8 -0.2 -0.5 -0.5 -0.4 -0.5  0.9  0.6  2.1  1.3 -0.2 -0.4 -0.6 -0.3 -0.3 -0.3 -0.   3.9 -1.   2.  -0.5 -0.1 -0.6 -1.1 -0.2 -1.1  5.9  0.4  1.3  1.7 -0.3 -0.3 -0.8 -1.4  8.2  0.2  5.5 -0.2 -0.2 -0.3 -0.7  1.6 -0.2 -0.9 -0.4  2.9  0.4  1.4  0.8 -0.5 -0.5  2.  -1.3 -0.6 -0.3 -0.9 -0.6 -0.4 -0.2  1.  -0.8 -0.1  0.  -0.6 -0.2  0.7 -0.9 -0.7 -0.1  5.6 -0.8 -1.  -0.9  0.1  4.9  5.5  1.7  6.4  4.7  9.2 -0.8  4.4 -0.5  0.1 -1.1 -1.6  0.3  0.2 -0.8 -0.6 -1.9 -0.7  6.1 -0.1  4.3  3.3]
ty_50sample [[9 4 3 0 6 5 8 7 2 1]
 [3 9 1 8 5 4 6 6 0 2]
 [6 8 4 3 7 7 5 2 9 1]
 [5 8 9 9 2 1 1 4 4 6]
 [5 2 1 4 3 6 6 0 9 8]
 [6 9 3 5 8 0 2 1 7 4]
 [2 0 7 7 8 4 9 6 1 5]
 [7 1 4 5 9 8 0 3 2 6]
 [2 5 0 4 3 6 6 8 9 1]
 [4 1 0 8 2 3 9 6 5 7]]
tt_50sample [[9 4 3 0 6 5 8 7 2 1]
 [3 9 1 8 5 4 6 7 0 2]
 [6 8 4 3 7 0 5 2 9 1]
 [5 8 9 2 7 3 1 4 0 6]
 [5 2 1 4 3 6 7 0 9 8]
 [6 9 3 5 8 0 2 1 7 4]
 [2 0 3 7 8 4 9 6 1 5]
 [7 1 4 5 9 8 0 3 2 6]
 [2 5 0 4 3 6 7 8 9 1]
 [4 1 0 8 2 3 9 6 5 7]]
vm  [-0.7  1.5 -0.7  5.6 -0.6 -0.4 -0.5 -0.8 -1.  -1.2 -0.3  0.2 -0.1 -0.2 -1.8  4.7 -0.2 -0.1 -0.4 -1.3 -0.2 -0.4  0.1 -0.  -1.3  0.6 -0.2 -0.7  2.4  0.6  0.7 -0.7  0.5 -1.5 -1.4  0.6  2.1  2.5  1.3 -0.8 -0.1 -1.7 -0.3 -0.5 -0.3 -0.4  4.1  0.9 -0.8 -0.6 -0.2 -0.4  3.  -1.  -1.6  5.3  0.7 -0.1 -1.1  1.4  0.2  0.8 -0.5 -1.1 -0.5 -0.1 -0.9  0.1 -0.3  3.8 -0.4 -0.8  0.5 -0.5  4.7 -0.2  2.3 -0.9  2.2 -0.2  5.9 -0.4 -1.1 -0.3 -0.  -1.  -0.  -0.7  3.1 -0.  -0.4  1.2  3.2  1.3  1.5  0.1 -0.   1.9 -0.8 -0.4  4.2 -1.6 -0.   0.4 -0.   1.7  1.  -0.1 -0.4 -1.6 -0.8 -0.1 -0.1  2.1 -0.8  5.1 -0.3 -1.  -0.5  0.1 -0.5  4.5  1.7 -0.3 -0.3 -1.9  3.7  5.6 -0.8  1.4  3.5 -0.7  0.9 -0.4  8.9  5.3  0.6  0.2  2.5 -0.6  0.8 -0.8  0.  -0.2 -0.7  0.9  0.2  1.8  1.8  1.9 -0.8 -0.2 -0.2 -0.5 -0.5 -0.1 -0.4 -0.2 -1.  -1.2 -0.5  3.4 -0.5 -0.2 -1.2 -0.5  4.9  4.6  0.7  3.6 -0.9 -0.7 -1.  -0.1 -0.   0.2 -1.2  1.9  1.3 -0.5  0.4  1.7  0.8 -1.5 -1.  -0.   1.4  1.  -0.3  1.  -0.7 -0.4 -0.6 -1.4  2.4  1.9  2.2  2.6 -0.5 -1.1 -0.2 -0.2 -0.6 -1.  -0.   1.  -0.6  0.9  4.7 -0.5 -0.3  4.3 -1.3  3.4 -0.5 -0.3  3.7 -0.2 -0.   0.1 -0.7  0.2 -0.4 -0.8  1.   3.4 -0.4  2.3 -0.1  1.   0.1 -0.3 -0.8  3.3  0.5  3.5 -0.2  3.8  0.5 10.6 -0.8  6.5 -0.8 -0.2 -0.5 -1.2  0.8  0.8 -0.1 -1.  -1.3 -0.9  1.2 -0.   2.9  1.2]
vy_50sample [[9 6 3 1 8 4 2 5 7 0]
 [7 3 0 1 6 5 8 9 2 4]
 [5 9 8 8 0 1 3 2 6 6]
 [3 8 9 7 6 4 0 5 2 2]
 [3 2 7 9 4 1 0 0 5 6]
 [1 3 3 7 7 4 6 8 2 0]
 [2 7 6 3 0 0 9 1 4 4]
 [6 1 0 3 9 5 2 2 8 7]
 [8 0 9 5 6 4 3 2 1 7]
 [4 8 7 6 3 1 1 9 5 9]]
vt_50sample [[9 6 3 1 8 4 2 5 7 0]
 [7 3 0 1 6 5 8 9 2 4]
 [5 9 8 7 0 1 3 2 6 4]
 [3 8 9 7 6 4 0 5 1 2]
 [3 2 7 9 4 1 8 0 5 6]
 [1 3 9 7 4 5 6 8 2 0]
 [2 7 6 3 0 5 9 1 8 4]
 [6 1 0 3 9 5 4 2 8 7]
 [8 0 9 5 6 4 3 2 1 7]
 [4 8 7 6 3 0 1 2 5 9]]
Epoch  4410: Training cost= 0.4567, Training acc= 0.6979, Validation cost= 0.4565, Validation acc= 0.6985
Epoch  4420: Training cost= 0.4513, Training acc= 0.6982, Validation cost= 0.4481, Validation acc= 0.6987
Epoch  4430: Training cost= 0.5566, Training acc= 0.6984, Validation cost= 0.5767, Validation acc= 0.6990
Epoch  4440: Training cost= 0.4996, Training acc= 0.6986, Validation cost= 0.5296, Validation acc= 0.6991
Epoch  4450: Training cost= 0.5039, Training acc= 0.6988, Validation cost= 0.4763, Validation acc= 0.6993
Epoch  4460: Training cost= 0.4785, Training acc= 0.6990, Validation cost= 0.4740, Validation acc= 0.6996
Epoch  4470: Training cost= 0.5183, Training acc= 0.6992, Validation cost= 0.5526, Validation acc= 0.6998
Epoch  4480: Training cost= 0.5448, Training acc= 0.6994, Validation cost= 0.4758, Validation acc= 0.7000
Epoch  4490: Training cost= 0.4922, Training acc= 0.6996, Validation cost= 0.4621, Validation acc= 0.7002
Epoch  4500: Training cost= 0.4976, Training acc= 0.6998, Validation cost= 0.4930, Validation acc= 0.7004
tm  [-0.6 -0.8  3.3 13.3 -0.4 -1.1 -0.5 -0.5  2.3 -0.4 -0.6  2.7 -1.3 -0.9 -1.7  2.2 -1.4 -0.7 -0.2 -1.4 -0.2  2.8 -0.4 -0.6 -0.7 -0.7 -0.4 -0.4  4.8 -0.5 -0.  -0.8  3.5  2.6 -1.1 -0.9 -0.2 -0.   0.1 -0.6  0.7 -0.4 -0.7 -1.8  0.7 -0.6  9.7  3.4 -0.4 -0.9 -0.6  1.3  4.7 -2.6 -0.9  5.4  1.5  2.6 -0.1  1.4 -1.4 -0.9  0.7 -0.5 -0.1 -0.5 -0.7  1.3  2.5  0.5  0.  -1.1 -0.4 -0.3 -0.3  0.9 -0.9 -0.6 -0.  -0.5 12.7 -0.3 -1.2  0.4 -0.9 -0.  -0.5 -0.7  2.4 -0.  -0.2  1.4  0.8 -0.8  1.4 -0.6  2.  -0.2 -0.8 -0.1  0.5 -0.5 -0.3 -0.  -0.7 -0.3  1.3  0.  -0.8 -1.8  2.3 -0.3 -0.6 -0.1 -0.3  5.7  2.4 -0.2 -0.3  4.4 -0.3  4.6  0.7 -0.7  0.  -1.9  3.8 10.4  0.7 -0.5  5.6 -1.5 -0.2 -0.8  8.1 14.   1.2 -0.4 -0.1 -0.5  1.8  0.5  3.8 -0.2 -1.6  1.9 -0.3 -1.2  1.7  0.5 -1.8 -0.1  1.2  1.7 -0.3  0.4 -0.7  0.8 -1.8 -0.9 -0.9  2.5  2.3 -0.2  1.4 -0.2  2.3  2.8 -1.2  7.3 -1.  -0.5 -1.2 -0.9  1.4 -0.3 -2.1  3.6  1.4  1.7 -0.5 -0.3 -0.2 -1.1 -1.6 -0.8  4.6 -0.  -0.2  3.9 -0.6 -0.6 -1.8 -1.2  6.3 -0.3  2.9 -0.2 -0.7 -1.6 -1.  -0.1  0.3 -0.6 -0.3  5.2  2.  -0.7 -0.4 -0.7 -0.1  5.6 -1.   2.  -1.7  1.2  6.5 -0.2  1.6  1.9 -0.9 -1.   0.4 -0.4  2.1  2.7 -1.7  1.7  0.9  4.2  3.  -0.4 -1.  -0.2 -1.6 -0.6 -0.2  2.9  0.5  9.9 -0.5  5.5 -0.5  0.7 -2.  -2.5  1.6 -0.5 -0.1 -0.2 -2.4 -1.7  1.5 -0.5  5.4  4.7]
ty_50sample [[6 9 3 5 5 1 8 4 2 0]
 [6 5 0 4 3 2 8 7 1 9]
 [1 1 6 8 7 7 3 3 0 2]
 [8 0 4 5 9 3 7 1 1 6]
 [2 2 6 1 1 3 4 7 8 8]
 [8 8 3 6 1 1 5 2 0 4]
 [3 3 5 4 6 8 2 7 0 0]
 [4 4 9 6 3 7 7 1 2 0]
 [3 2 4 7 5 6 0 1 9 8]
 [3 5 7 0 1 9 4 2 6 8]]
tt_50sample [[6 9 3 5 7 1 8 4 2 0]
 [6 5 0 4 3 2 8 7 1 9]
 [1 9 6 4 8 7 3 5 0 2]
 [0 8 4 5 9 3 1 2 7 6]
 [2 0 6 9 1 3 4 7 5 8]
 [8 7 3 9 6 1 5 2 0 4]
 [3 9 5 4 6 8 2 7 1 0]
 [9 8 4 3 6 5 7 1 2 0]
 [3 2 4 7 5 6 0 1 9 8]
 [5 3 7 0 1 9 4 2 6 8]]
vm  [ 3.9 -0.5  5.5 10.6 -1.3 -1.5 -0.5 -0.8 -0.9 -0.6  1.3  0.6 -1.  -0.1  0.8  3.5 -0.1 -0.8  0.2 -1.8 -0.   1.1 -0.1  0.3 -1.1 -1.  -0.  -0.4  2.6 -0.2 -0.2 -1.   1.4  5.9 -1.   1.3  3.2  0.4  2.  -1.   0.1  2.5  4.6 -1.2 -0.2 -0.9  6.6  2.4  2.1 -0.5 -0.9  0.1  1.8 -1.1 -0.8  1.   0.1  4.5 -1.3  1.8 -1.9 -1.  -0.6 -0.4  0.3 -0.1 -0.8 -0.3  0.6 -0.   0.3 -0.5 -0.6 -1.   1.7  0.5 -0.7 -0.1 -1.1 -0.6 10.  -0.2 -1.5  0.9 -1.   4.2  1.8 -0.6  4.3  0.  -0.8  2.7  0.5  0.8 -0.  -0.4  3.5  2.1  0.4  0.1  3.2  2.5 -1.1 -0.7 -0.2 -0.  -0.1 -0.   1.  -2.1  2.  -0.7 -0.5 -0.2 -1.2  4.5  0.6 -0.3  0.3 -0.1  0.2  4.9 -0.1 -1.1 -0.4  0.1  2.7  5.6 -0.1 -0.2  4.1 -0.7 -0.   0.5  0.7  8.6 -0.2 -0.2 -0.6 -0.9 -0.1 -0.3  1.  -0.2 -0.4  1.  -0.6 -2.1  3.3  1.8 -1.4 -0.3  3.8 -0.3 -0.8 -0.1 -0.6  0.1 -1.2 -1.  -0.9  2.3 -0.3  0.1  1.7 -0.1  1.  -0.8 -0.7  5.4 -0.3  2.2 -1.2 -0.7 -0.1 -0.5 -1.  -0.1  0.2 -0.6 -1.5  0.5  0.4 -1.2 -1.  -0.6  5.8 -0.8 -0.4  1.3 -0.4 -0.7 -0.9 -1.2  8.9  0.6  0.4  2.  -0.5 -1.3 -0.6 -1.  -0.2 -0.5 -1.2  0.9  2.8  0.5 -2.4 -0.4 -0.3  2.6 -0.5 -0.5 -1.1  0.8  3.9 -0.1  2.8 -0.2 -0.7 -0.5  1.3  0.1  1.1  3.1 -0.7 -0.6 -0.4  4.9 -0.3 -0.2 -0.5 -1.7 -1.1 -1.3 -0.4  1.3 -0.3 -0.3 -0.3 -0.1 -0.4  1.2 -1.5 -1.  -0.1 -0.2  0.3  0.7 -1.6 -1.3  2.7 -0.3  4.4  2.9]
vy_50sample [[5 9 6 3 3 8 8 4 0 1]
 [9 2 7 8 8 1 0 6 5 4]
 [7 9 8 3 6 2 2 0 5 4]
 [3 8 4 1 9 2 5 0 7 6]
 [7 4 3 0 1 9 8 8 6 5]
 [7 7 8 1 1 5 0 9 3 4]
 [2 8 4 6 6 9 3 5 1 7]
 [5 0 3 2 6 4 8 8 7 7]
 [0 0 6 8 2 1 4 5 9 3]
 [8 9 1 1 4 3 6 0 2 5]]
vt_50sample [[5 9 6 7 3 2 8 4 0 1]
 [9 2 7 8 3 1 0 6 5 4]
 [7 9 8 6 3 1 2 0 5 4]
 [3 8 4 9 1 2 5 0 7 6]
 [7 4 3 0 1 9 2 8 6 5]
 [7 6 8 2 1 5 0 9 3 4]
 [2 8 4 6 9 0 3 5 1 7]
 [5 0 3 2 6 4 9 8 7 1]
 [7 0 6 8 2 1 4 5 9 3]
 [8 9 1 7 4 3 6 0 2 5]]
Epoch  4510: Training cost= 0.4768, Training acc= 0.7000, Validation cost= 0.4723, Validation acc= 0.7006
Epoch  4520: Training cost= 0.5271, Training acc= 0.7002, Validation cost= 0.5287, Validation acc= 0.7008
Epoch  4530: Training cost= 0.4708, Training acc= 0.7004, Validation cost= 0.4739, Validation acc= 0.7011
Epoch  4540: Training cost= 0.4620, Training acc= 0.7006, Validation cost= 0.4789, Validation acc= 0.7012
Epoch  4550: Training cost= 0.4926, Training acc= 0.7009, Validation cost= 0.4693, Validation acc= 0.7015
Epoch  4560: Training cost= 0.4668, Training acc= 0.7011, Validation cost= 0.5176, Validation acc= 0.7017
Epoch  4570: Training cost= 0.4293, Training acc= 0.7013, Validation cost= 0.4569, Validation acc= 0.7019
Epoch  4580: Training cost= 0.4847, Training acc= 0.7015, Validation cost= 0.5010, Validation acc= 0.7022
Epoch  4590: Training cost= 0.4618, Training acc= 0.7017, Validation cost= 0.5056, Validation acc= 0.7024
Epoch  4600: Training cost= 0.5864, Training acc= 0.7019, Validation cost= 0.5244, Validation acc= 0.7025
tm  [-0.6 -0.6 -0.6  3.  -0.8  0.5 -0.3 -0.5  1.8  0.7  1.4  0.9 -1.1 -0.6 -1.2 -1.4 -0.5 -0.5 -0.2 -0.4 -0.9 -0.4  0.9 -0.2 -1.   4.4 -0.2 -0.6 -1.3 -1.6  2.2 -0.4 -0.3 -0.4  1.3 -0.6  0.1  3.4  5.3 -0.6 -0.6  4.8  0.9  2.8 -1.1 -0.1  0.  -0.3 -0.2  2.  -0.6 -0.6  1.5 -0.3  1.3  4.9 -0.6  1.6  2.7 -0.   3.3 -0.8  1.9  4.9  0.8 -0.3  0.3  2.6  1.4  0.6 -0.4  3.1 -0.5 -0.3 -2.2 -0.1  0.3 -0.6  2.  -0.   5.3  0.3  0.7  0.  -0.4  5.2  0.1 -0.5 -0.1 -0.1  0.8 -1.  -1.  -0.3 -0.4 -0.2  2.7 -0.7 -0.2 -0.3 -0.6  0.3  2.  -0.8 -0.2 -0.2 -1.1  2.5  0.7 -0.2 -0.1  1.5 -0.3 -0.5  7.1 -1.1 -0.4  0.7 -0.4  3.8  0.4  0.8 -0.5  1.3 -0.4 -0.8  0.   4.2  3.2 -0.1 -0.7 -0.6 -1.5 -0.2  2.6 -0.5 -0.3 -0.9  1.8 -0.6  0.8 -0.7 -0.3 -0.3 -0.4 -0.3  0.3 -0.2  4.7 -0.7 -0.4 -0.2 -0.3  3.5 -0.5 -0.   0.4 -0.1  2.5 -0.   2.1 -1.  -0.4 -0.5 -0.5 -0.6 -1.2 -0.2 -0.5  2.9  1.2  0.7 -0.1 -0.3 -0.3 -1.2 -0.   1.2 -0.9  1.4 -1.1 -0.8 -0.1 -1.2  1.9 -0.7  0.7  0.6  4.2  7.2 -0.4 -0.9 -0.8 -1.1 -0.2 -0.  -0.8 -0.4 -0.3  0.9 -0.5  2.3 -0.7 -1.1  0.1 -0.2  2.7 -0.1 -1.7 -0.3 -0.2 -0.6 -0.3  4.2 -0.7 -0.5 -0.4 -0.9 -0.9 -0.2 -0.3 -0.3  0.7 -0.9  0.4 -1.  -0.7  2.7  1.  -0.  -0.7  0.2 -0.6 -1.4  4.9  4.5  4.2 -0.7  2.6 -0.6 -0.7 -0.3 -0.6 -0.4 -0.5 -1.1  0.6 -0.3 -0.5 -0.2 -1.1 -0.4  5.6  0.7  2.4  4.4]
ty_50sample [[0 5 1 9 4 4 2 3 7 7]
 [4 7 3 6 8 0 1 2 5 9]
 [2 1 4 5 3 0 9 9 8 6]
 [8 3 7 5 9 2 4 6 0 0]
 [1 3 2 7 6 0 8 8 5 5]
 [7 0 0 5 4 8 3 2 1 6]
 [9 1 0 3 8 2 4 7 5 6]
 [3 4 8 8 6 2 0 1 1 5]
 [0 8 6 9 1 5 2 7 3 4]
 [9 9 4 5 0 6 1 7 3 3]]
tt_50sample [[0 5 1 9 4 8 2 3 6 7]
 [4 7 6 3 8 0 1 2 5 9]
 [2 1 4 5 3 0 9 7 8 6]
 [8 3 7 5 9 2 4 6 1 0]
 [1 3 2 7 6 0 8 4 9 5]
 [7 9 0 5 4 8 3 2 1 6]
 [9 1 0 3 8 2 4 7 5 6]
 [3 4 8 7 6 2 9 0 1 5]
 [0 8 6 9 5 1 2 7 3 4]
 [9 8 4 5 6 0 7 1 2 3]]
vm  [-0.   0.1 -0.4 -1.7 -1.  -0.3 -1.2 -0.9 -1.1  1.9  3.2 -1.   1.4 -0.2  4.9  5.2 -0.3 -0.2 -0.2  1.7 -0.4 -0.2  4.7 -0.  -1.   0.6 -0.4 -0.5  0.4 -0.4 -0.1 -0.3  0.2 -1.3  3.4 -0.2  1.2  2.  -2.2 -0.6 -0.   2.4 -0.3 -0.  -1.  -0.1 -2.2 -1.3 -0.   8.1 -0.8 -1.5 -1.2  8.9 -0.8 -0.4 -0.5 -0.5  2.2  2.5  4.   1.7 -0.4  2.   0.2 -0.7 -0.3  0.8 -0.4 -0.6  0.  -0.1  2.7 -0.2 -3.8 -0.2  0.4  0.8  4.7 -0.3 -2.8 -0.2  2.6 -0.6 -0.7  2.7  0.6 -0.1 -0.7 -0.1 -0.3 -1.  -1.  -0.5 -1.3 -0.  -0.6 -1.3 -0.4 -0.7 -0.9  4.4  1.5 -0.2  1.2  0.8 -2.5  0.2  0.9  2.2 -1.1  0.1  0.3 -0.1  1.1 -0.1 -0.1 -0.3  0.3 -0.  -0.4 -1.1  1.2 -0.5 -0.3  4.9 -1.1 -2.1  1.   0.5  5.2 -0.5 -0.4  0.   6.7  1.6 -0.4 -0.5 -0.5 -0.5 -0.8 -0.8 -0.4  1.  -0.4  1.2 -0.2  0.4 -0.2  2.3  4.4 -0.   2.7 -1.  -0.3 -0.  -0.5 -0.3 -0.7 -1.   3.7  2.   0.8 -1.1 -0.9 -0.4 -0.1  0.9  0.8 -0.7  2.7 -0.   0.3 -0.3 -0.8  2.5 -1.4 -0.7 10.6 -0.7  1.4 -0.   0.8 -1.1  1.3 -0.1 -0.3 -0.2 -0.8 -0.  -0.  -1.   0.7 -1.1 -0.5  0.1 -1.6 -0.2 -0.5  0.2 -0.3  1.2 -0.7 -0.5 -0.2 -2.6 -0.9  1.8  6.3 -0.2 -0.2 -0.  -1.3  3.   0.5 -0.3  2.2 -0.2 -0.2 -0.3 -0.5 -0.5 -0.4 -0.7  3.9  1.9  0.9  3.7 -0.3  1.4  0.1  0.4 -0.5  4.4  0.5  3.5  4.4 -2.   1.9  0.4 -1.2  1.   0.6 -0.4  9.6  1.1 -0.2  1.8 -0.3 -0.2  5.1  2.  -1.9  1.  -0.6  1.9]
vy_50sample [[2 6 8 4 1 7 7 5 9 3]
 [2 6 6 9 5 3 4 1 0 7]
 [8 1 1 1 3 4 2 2 9 9]
 [2 6 0 5 4 8 3 1 7 7]
 [6 7 0 4 3 8 2 1 5 9]
 [7 6 1 9 4 8 5 0 3 2]
 [9 1 4 3 3 5 2 2 7 7]
 [7 5 8 2 0 6 9 4 3 1]
 [4 1 3 5 0 6 2 8 9 7]
 [1 2 4 9 3 8 0 5 5 7]]
vt_50sample [[2 6 8 4 1 0 7 5 9 3]
 [2 9 8 6 5 3 4 1 0 7]
 [8 7 1 4 3 6 5 2 9 0]
 [6 2 0 5 4 8 3 1 7 9]
 [6 7 0 4 3 8 2 1 5 9]
 [7 6 9 1 4 8 5 0 3 2]
 [9 1 4 6 3 5 2 8 0 7]
 [7 5 8 2 0 6 9 4 3 1]
 [4 1 3 0 5 6 2 8 9 7]
 [1 2 9 4 3 8 0 5 6 7]]
Epoch  4610: Training cost= 0.4952, Training acc= 0.7021, Validation cost= 0.6166, Validation acc= 0.7027
Epoch  4620: Training cost= 0.4436, Training acc= 0.7023, Validation cost= 0.4574, Validation acc= 0.7029
Epoch  4630: Training cost= 0.4993, Training acc= 0.7025, Validation cost= 0.4628, Validation acc= 0.7031
Epoch  4640: Training cost= 0.5067, Training acc= 0.7027, Validation cost= 0.4294, Validation acc= 0.7033
Epoch  4650: Training cost= 0.4694, Training acc= 0.7029, Validation cost= 0.5082, Validation acc= 0.7035
Epoch  4660: Training cost= 0.4583, Training acc= 0.7031, Validation cost= 0.4334, Validation acc= 0.7038
Epoch  4670: Training cost= 0.4561, Training acc= 0.7033, Validation cost= 0.5084, Validation acc= 0.7040
Epoch  4680: Training cost= 0.5041, Training acc= 0.7035, Validation cost= 0.6111, Validation acc= 0.7042
Epoch  4690: Training cost= 0.5404, Training acc= 0.7037, Validation cost= 0.5383, Validation acc= 0.7043
Epoch  4700: Training cost= 0.4491, Training acc= 0.7039, Validation cost= 0.5310, Validation acc= 0.7045
tm  [-1.   1.   7.7  6.1 -1.3 -0.6 -0.6 -0.7 -0.4  0.9 -2.   0.4 -0.6 -0.3  5.8 -0.3 -1.   0.8  0.4  0.5 -0.2 -0.4  2.9 -0.6 -0.3 -0.2 -0.2 -0.1  0.2 -0.6 -1.4  0.6 -0.1  0.3  0.4 -0.9 -0.3 -0.3 -0.8 -0.6 -0.5 -0.4 -0.8 -1.4 -0.8  0.3 -1.  -0.   0.1  5.2 -0.8 -0.7 -0.8 -0.  -0.4 -0.4  0.7  2.2  1.   7.   2.9  0.1 -0.2  2.5 -0.8 -0.2 -0.4 -0.9  1.4  2.2  0.1  1.3  3.4  0.4 -2.1 -0.2 -0.1 -0.6  1.9  0.4 -1.8 -0.6  0.5 -0.3 -0.2 -0.5 -0.7 -0.7 -0.2  0.6 -0.2 -0.6 -0.6 -0.5 -0.2 -0.4  1.2 -1.6 -0.3  0.  -0.4  4.8  3.3  0.4 -0.   0.8 -1.5 -1.8 -1.2 -0.5  0.2 -0.1 -0.3 -0.4  2.1 -0.  -0.2  0.8 -0.4  1.4 -0.   1.2  0.8 -0.  -0.2  5.9 -0.1  2.5  1.5  1.5  3.7 -1.2 -0.4 -0.2  1.  -0.1 -0.6 -0.2 -0.5  0.3  1.8 -0.6 -0.1 -0.2 -1.2  0.5 -0.9 -0.5 -1.3 -0.2  0.4 -0.4  2.7 -0.1 -0.4 -0.6 -0.5  0.6 -0.4 -0.4  0.2  2.1  0.9 -0.5 -0.8 -0.4  0.9  3.6 -0.3  2.2 -0.1 -0.5 -0.4 -0.2 -0.2  5.7 -1.1 -0.2  6.6  1.8  1.5 -0.3 -0.2 -0.9  2.  -0.2 -0.2 -0.5 -0.6  3.1 -0.6 -0.3 -0.9 -1.1 -0.2 -0.3 -0.4 -0.9 -0.3 -0.3 -1.1  1.7 -0.3 -0.7  2.1 -1.4 -1.2  1.1  8.6 -0.6 -0.2  1.6 -1.4  3.4 -1.1 -0.5  7.1 -0.3  2.4  0.  -1.6 -0.2 -0.8 -0.4  3.2  1.5 -1.   3.   0.   1.3 -0.2 -0.3 -0.5  4.7  1.7 -2.1  2.3 -0.4  2.6  4.6 -1.4  2.9  0.8 -0.8  6.7 -0.3 -0.7  2.5 -0.9 -0.6  2.6 -1.2 -0.7 -0.1  2.1  1.4]
ty_50sample [[8 7 6 1 0 3 9 2 5 4]
 [8 5 5 4 6 0 1 7 9 3]
 [3 8 9 5 2 2 6 0 0 7]
 [0 8 4 5 3 9 6 2 7 7]
 [5 4 2 7 8 8 9 9 6 1]
 [9 6 7 7 5 3 8 1 4 2]
 [0 6 8 4 7 9 3 5 2 2]
 [5 6 4 9 8 8 0 0 3 3]
 [5 1 9 3 3 4 4 2 8 7]
 [1 2 0 0 6 4 7 3 5 9]]
tt_50sample [[8 7 6 1 0 3 9 2 5 4]
 [8 5 2 4 6 0 1 7 9 3]
 [3 8 9 5 1 2 6 4 0 7]
 [0 8 4 5 3 9 6 1 2 7]
 [5 2 4 7 8 0 3 9 6 1]
 [0 9 6 7 5 3 8 1 4 2]
 [0 6 8 4 7 9 3 5 1 2]
 [5 6 4 9 8 2 1 0 7 3]
 [5 1 9 3 6 0 4 2 8 7]
 [1 2 8 0 6 4 7 3 9 5]]
vm  [ 3.5  1.7 -0.5  2.2 -0.8 -1.3 -0.7 -0.7 -0.4 -0.9 -1.4  0.6 -1.1 -0.3 -0.6 -0.8  1.1  0.3 -0.2 -0.3 -0.6  0.3  0.9  1.5 -0.6  1.1 -0.6 -0.4 -0.5 -0.8 -0.3 -0.5 -0.4 -2.2  1.4 -0.2  1.7  1.   3.2 -1.9 -0.4 -0.2  1.3  2.3 -0.4  1.8 -0.5  1.4  4.4  0.7 -0.5 -1.1 -0.2 -0.2  0.4  2.8 -0.2  2.6  0.2  3.5 -0.9 -0.7 -0.1  3.1 -0.7 -0.4 -0.4 -0.3  1.7  4.1 -0.5  3.   1.3 -0.4 -1.2  0.3 -0.5 -1.1 -0.6  0.4 -0.8 -0.3 -0.4 -0.  -1.3 -0.4  2.3 -0.3  3.8 -0.2 -0.5 -0.7 -0.   1.9 -0.1  0.3  1.5 -0.7  0.2  0.9  1.1 -1.6 -0.7 -0.4  1.1 -0.2 -0.9 -0.6 -0.6 -0.8 -0.1  1.1 -0.3 -0.3  2.2 -0.6 -0.3  2.   0.3  2.4 -0.4  2.9 -0.5 -1.1 -0.7 -0.6 -0.1  2.9  2.7  4.5  3.3 -0.5  1.5 -0.6  4.1 -2.  -0.6 -0.5  1.9 -0.1  1.7 -1.5  1.2 -0.4 -0.4  0.1 -1.2 -0.8  3.9 -0.8  0.8  0.1  6.5 -0.2 -0.8 -0.6 -0.1 -0.3  0.1 -0.9  0.1 -0.5 -0.5 -0.4 -1.2 -0.4  1.4  0.5 -0.1  1.1 -0.1  0.9 -0.5 -0.1 -0.4 -0.8  0.  -0.  -0.  -0.  -0.7 -0.3 -0.6 -1.   3.5 -0.2  4.8 -0.   0.3  6.2 -0.1  0.  -0.6 -1.4  5.8 -0.7 -0.2 -0.6 -0.2  0.  -0.4  1.7  0.1 -1.  -0.9 -1.1 -0.1  1.7  3.4 -0.3 -0.2 -0.2 -1.5 -1.1 -0.5 -0.4 -0.2 -0.1 -0.7 -0.5 -0.7 -0.   0.  -0.9 -0.5  0.1 -0.7 -0.5 -0.6  7.6 -1.   0.3 -0.7  2.   4.1  3.9  2.6 -0.5  3.3 -0.1 -0.6 -0.2 -0.2  0.8  4.4 -0.5 -0.3 -0.1 -0.8 -0.6  1.7 -1.2  3.  -0.4  3.5 -0.6]
vy_50sample [[3 3 8 5 4 4 6 7 7 1]
 [7 1 4 5 9 9 3 0 2 6]
 [5 1 0 0 2 4 8 6 3 9]
 [6 1 3 3 9 4 0 5 8 8]
 [3 1 8 7 5 5 4 9 0 6]
 [4 3 7 7 9 2 0 5 6 1]
 [9 0 6 6 2 4 5 5 7 8]
 [1 6 5 3 0 2 4 7 8 8]
 [9 4 3 5 8 0 0 2 7 1]
 [0 3 5 2 2 4 1 1 7 8]]
vt_50sample [[0 3 8 5 4 9 6 2 7 1]
 [7 1 4 5 9 0 3 8 2 6]
 [5 1 0 7 2 4 8 6 3 9]
 [1 6 3 2 9 0 4 5 7 8]
 [3 1 8 7 5 2 4 9 0 6]
 [4 3 8 7 9 2 0 5 1 6]
 [0 9 6 3 2 1 4 5 7 8]
 [1 6 5 3 0 2 4 7 9 8]
 [9 4 3 5 8 0 6 2 7 1]
 [0 3 5 2 9 4 6 1 7 8]]
Epoch  4710: Training cost= 0.4606, Training acc= 0.7041, Validation cost= 0.4777, Validation acc= 0.7047
Epoch  4720: Training cost= 0.4763, Training acc= 0.7043, Validation cost= 0.5290, Validation acc= 0.7049
Epoch  4730: Training cost= 0.5716, Training acc= 0.7044, Validation cost= 0.5072, Validation acc= 0.7051
Epoch  4740: Training cost= 0.5217, Training acc= 0.7046, Validation cost= 0.5289, Validation acc= 0.7053
Epoch  4750: Training cost= 0.4578, Training acc= 0.7048, Validation cost= 0.5651, Validation acc= 0.7054
Epoch  4760: Training cost= 0.4738, Training acc= 0.7050, Validation cost= 0.4743, Validation acc= 0.7056
Epoch  4770: Training cost= 0.4771, Training acc= 0.7052, Validation cost= 0.5213, Validation acc= 0.7058
Epoch  4780: Training cost= 0.4181, Training acc= 0.7054, Validation cost= 0.4836, Validation acc= 0.7060
Epoch  4790: Training cost= 0.5084, Training acc= 0.7056, Validation cost= 0.5028, Validation acc= 0.7062
Epoch  4800: Training cost= 0.4826, Training acc= 0.7058, Validation cost= 0.5069, Validation acc= 0.7064
tm  [ 2.5 -0.3  3.6 -1.  -1.2 -1.  -1.2 -0.9 -0.9 -0.4  7.  -0.6  0.3 -0.7  7.9  6.5 -0.  -0.1 -0.   1.4 -0.4  1.4  1.2  0.8 -1.4  0.3 -0.7 -0.6  1.3  0.4  1.6 -0.8  2.7  5.7  2.6  1.9  1.   2.1 -2.2 -0.7 -0.3 -0.2 -0.3 -0.3 -1.  -0.1 -1.6 -0.9  2.2  1.4 -1.1 -1.5 -0.3  8.6 -0.8 -1.  -0.7  0.4  0.2 -0.1 -0.2  1.5 -0.3  2.4  2.2 -1.  -0.1  0.7 -0.1 -0.6 -0.2 -0.5 -0.1 -0.4 -3.6 -0.1 -0.8  0.7  1.9 -0.  -0.6  0.2  1.8 -0.  -1.4 -0.2  1.4 -0.4  0.3 -0.4 -0.5 -0.5 -0.3 -0.4 -1.2  0.3 -0.2 -0.9 -0.5 -0.2  0.4  4.7 -0.4 -0.3  0.6  1.4 -2.1  2.3  3.9  1.8 -0.4 -0.2  0.   0.2 -0.4  1.3  1.1  0.7  0.3 -0.1 -0.4 -0.9  1.3 -0.3 -0.6  7.8 -0.9 -2.  -0.2  2.7  6.3 -0.6  0.2  0.6  3.1  8.6 -0.4  0.2 -0.1 -0.8 -0.9 -0.8 -0.3  0.7 -0.2  1.2 -0.5 -0.4 -1.   0.9  2.7 -0.1  4.4 -1.  -0.5  0.2 -0.8 -0.2 -1.3 -1.3  1.8  2.2  1.6 -0.6  1.9 -0.7  0.  -0.1 -0.1 -0.3 -0.2 -0.1 -0.5  0.1 -0.7  4.7 -1.7 -0.5  9.7 -0.5  1.  -0.  -0.2 -1.3 -0.3 -0.9  3.  -0.8 -0.7 -0.1 -0.2 -0.7  0.3 -1.1  2.3  0.5 -1.2 -0.2 -0.4 -0.   0.7 -0.5 -0.5 -0.1 -1.2 -2.  -0.2  0.4  3.5 -0.4 -0.3  0.3 -1.  -0.1  0.8 -0.   2.8 -0.3  1.2 -0.3 -0.6 -0.5  0.1 -0.7  2.8  1.6  1.8  1.7 -0.   4.2  0.6  1.2 -0.6  3.  -0.9 -0.4  2.  -1.8  0.8  1.3 -1.1  1.7 -0.3 -0.   3.7  0.8 -0.3  0.9 -0.2  0.1  0.4  1.5 -1.7  0.8 -0.3 -0.2]
ty_50sample [[2 6 7 4 4 3 0 5 5 1]
 [4 9 3 1 8 0 6 7 5 2]
 [9 5 7 3 1 8 2 6 0 4]
 [2 5 0 0 6 6 1 3 9 9]
 [7 3 1 8 6 4 2 5 5 0]
 [5 8 0 1 9 4 2 7 3 6]
 [9 8 1 5 0 6 2 7 4 3]
 [1 3 2 4 8 0 7 6 9 5]
 [3 9 7 5 4 2 0 8 6 6]
 [3 4 0 1 9 7 2 8 5 6]]
tt_50sample [[2 6 7 4 8 3 0 9 5 1]
 [4 9 3 1 8 0 6 7 5 2]
 [9 5 7 3 1 8 2 6 0 4]
 [7 5 2 0 6 4 1 3 8 9]
 [7 3 1 8 6 4 9 2 5 0]
 [5 8 0 1 9 4 2 7 3 6]
 [9 8 1 5 0 6 2 7 4 3]
 [1 3 2 4 8 0 7 6 9 5]
 [3 9 7 5 4 2 8 0 1 6]
 [3 4 0 1 9 7 2 8 5 6]]
vm  [-0.1 -0.6 -0.7  3.8 -0.3 -0.8 -0.9 -0.4  4.  -0.6  6.3 -0.5 -0.1  0.4 -1.6  6.7 -0.5 -0.5 -0.3 -0.5 -0.8  1.  -0.4 -0.6 -0.8  0.6 -0.3 -0.5  1.9 -1.4  2.  -1.6 -0.4 -0.9  1.8 -0.8 -0.7  6.3  7.5 -1.6 -0.2  1.1 -0.3  3.1 -0.3  0.4  1.8 -1.1  2.3 -0.4 -0.7 -0.6  1.   3.  -1.   4.9 -0.2  4.   5.1  0.6 -0.7 -0.9  1.3  5.3  0.2 -0.5 -0.5  4.5 -0.2 -0.4 -0.4 -0.7 -0.1  0.4 -1.7 -0.2 -1.2 -0.5 -0.2  0.3  4.8 -0.5 -0.1 -0.3 -1.   1.6 -0.1 -0.4  1.  -0.1 -0.4 -1.3 -0.2 -0.9  0.4  0.2 -0.  -0.9 -0.4 -0.1 -0.2 -1.5 -0.1 -0.4 -0.6 -0.3 -0.6  0.9  2.9 -1.1  0.3  0.7 -0.1 -0.7  0.8  3.2 -0.1  2.  -0.1  3.6 -0.5  2.3 -0.4 -0.2 -0.4 -1.5 -0.9 -0.7  8.1  1.4  0.3 -1.  -0.2 -0.4  1.5 -1.2 -0.3 -0.5  0.8 -0.3 -0.7  0.1 -0.4 -0.6 -0.7  2.  -0.8 -0.4  4.8 -0.6  0.7 -0.1  3.1 -0.6 -0.5 -0.4 -0.8 -0.2  2.6 -0.3  1.5 -1.6 -0.3 -0.4 -0.3 -0.6  3.3 -0.  -0.3  2.   0.3  0.8 -0.5 -0.5 -0.6 -1.6 -0.1  0.6 -1.2 -0.7 -1.  -0.4 -1.2 -0.7  1.9 -0.8  3.6  0.7 -0.6  7.8 -0.2 -0.3 -1.6 -0.9  4.7 -1.4  0.3 -0.9 -0.2 -0.  -0.4  1.8 -0.9 -1.1 -0.8 -0.2  1.9  1.4 -1.  -0.5 -0.4  3.4 -1.2  0.1 -0.5  0.  -0.6 -0.6 -0.7 -0.3  0.7 -0.8  0.5 -0.5 -0.6  2.4  1.9  3.4 -0.1  8.5 -1.5 -0.7 -0.7 -0.6 -0.1  4.5  2.  -0.2  1.4 -0.  -0.1 -0.1 -0.2 -0.3 -0.4 -1.3 -0.3 -0.2 -1.  -0.7 -1.3 -0.3  6.6  1.8  1.5  1.4]
vy_50sample [[2 5 3 9 8 8 0 0 7 7]
 [6 9 2 5 0 8 8 7 4 3]
 [0 3 1 7 8 2 2 9 6 4]
 [2 2 8 0 5 6 7 1 9 3]
 [0 0 6 2 2 5 9 3 7 1]
 [8 0 4 6 9 7 2 5 3 1]
 [5 9 3 0 8 6 4 4 2 1]
 [5 3 1 0 8 8 9 6 4 2]
 [3 3 2 4 9 0 0 5 7 1]
 [4 0 0 5 9 1 7 6 8 3]]
vt_50sample [[2 5 3 9 8 4 1 0 7 6]
 [6 9 2 5 0 1 8 7 4 3]
 [0 3 1 7 8 2 5 9 6 4]
 [2 8 4 0 5 6 7 1 9 3]
 [0 2 6 8 4 9 5 3 1 7]
 [8 0 4 6 9 7 2 5 3 1]
 [5 9 3 0 8 7 6 4 2 1]
 [5 3 1 0 7 8 9 6 4 2]
 [8 3 2 4 9 0 5 7 6 1]
 [4 2 0 9 5 1 7 6 8 3]]
Epoch  4810: Training cost= 0.4887, Training acc= 0.7060, Validation cost= 0.4745, Validation acc= 0.7066
Epoch  4820: Training cost= 0.4789, Training acc= 0.7062, Validation cost= 0.4259, Validation acc= 0.7068
Epoch  4830: Training cost= 0.4447, Training acc= 0.7064, Validation cost= 0.4595, Validation acc= 0.7070
Epoch  4840: Training cost= 0.5257, Training acc= 0.7066, Validation cost= 0.4682, Validation acc= 0.7072
Epoch  4850: Training cost= 0.5167, Training acc= 0.7068, Validation cost= 0.4834, Validation acc= 0.7074
Epoch  4860: Training cost= 0.5505, Training acc= 0.7070, Validation cost= 0.5078, Validation acc= 0.7076
Epoch  4870: Training cost= 0.4821, Training acc= 0.7072, Validation cost= 0.4857, Validation acc= 0.7078
Epoch  4880: Training cost= 0.5164, Training acc= 0.7074, Validation cost= 0.5348, Validation acc= 0.7080
Epoch  4890: Training cost= 0.4733, Training acc= 0.7076, Validation cost= 0.5059, Validation acc= 0.7082
Epoch  4900: Training cost= 0.4827, Training acc= 0.7078, Validation cost= 0.4573, Validation acc= 0.7084
tm  [-1.  -0.8  6.  10.3 -1.6 -0.2 -0.1 -0.6 -0.2 -0.9  2.7  2.3 -0.3 -0.4  0.7  3.2 -0.8 -0.2  0.5 -1.6 -0.2 -0.  -1.1 -0.3 -1.2  0.3 -0.4 -0.4  2.4 -0.2  2.  -0.6  1.3  8.9 -1.5  0.9  0.4  2.5  5.9 -0.5  0.1 -2.  -0.8 -0.3 -0.9 -0.9  7.6  2.5 -1.  -2.  -1.2  0.2  4.9 -1.5 -1.4  0.9 -0.4  0.2 -0.6 -0.2 -0.3  1.1 -0.6 -0.4  0.6 -0.4 -0.9  0.  -0.1  1.4  0.5 -0.6 -0.7 -0.4  3.6 -0.2  0.9 -1.1  1.4 -0.6 14.5 -0.3 -1.4  0.  -0.2 -1.5 -0.4 -0.7  2.5 -0.  -0.2  1.3  2.7 -0.2  1.  -0.4  0.8  1.  -0.8 -0.2  3.8  0.5  0.1  0.4 -0.3 -0.1  2.   2.   1.5 -1.8  1.5 -1.1 -0.3 -0.1 -0.5  5.4  0.5 -0.2 -0.5 -0.3 -0.3  5.6 -0.2 -0.1 -0.3  0.3  3.4  7.9 -0.7  0.8  0.1 -1.4 -0.  -0.2 -1.4  8.2  1.6  0.6  1.9 -0.9 -0.1  1.  -0.1 -0.7 -0.8 -0.3 -0.1 -0.4 -1.4 -0.1 -1.5 -0.3 -0.8  0.6 -0.5 -0.1 -0.6 -0.5 -0.5 -0.6 -1.   0.3  0.2 -0.   2.5 -0.7  3.4  5.3 -0.6  5.1 -1.8 -0.8 -1.1 -0.2 -0.3  5.3 -0.9  2.1 -1.  -0.2  0.9  0.6 -0.1 -1.4 -1.2 -1.2  2.  -0.7 -0.4  1.4 -0.6 -0.  -1.2 -0.9  3.   1.8  3.2  1.1 -0.8 -1.3 -0.5 -0.6 -0.5 -0.4 -0.2  3.3  0.1 -0.1  1.3 -0.7 -0.4  4.6 -0.6  4.5 -0.9  0.1  2.5 -0.4  1.4  0.9 -0.9 -0.   0.1 -0.4 -0.3  2.2 -0.7  1.8  0.9 -0.1 -0.3 -0.1 -0.7  0.6 -0.9 -1.5 -0.4  3.   0.1 14.2 -0.7  8.4 -1.2 -0.3 -2.7 -1.7 -0.1 -0.4 -0.2 -0.7 -2.7 -0.9  6.1 -0.3  4.   1.9]
ty_50sample [[9 7 1 1 6 2 2 5 0 0]
 [3 8 5 9 9 0 4 6 1 2]
 [5 2 6 7 9 3 0 1 4 8]
 [9 8 4 0 0 2 3 1 6 6]
 [7 7 0 6 4 5 5 8 9 1]
 [8 7 6 3 0 9 2 5 1 4]
 [8 4 5 3 1 0 2 9 6 7]
 [2 3 7 0 9 5 8 4 6 1]
 [5 3 6 2 4 4 7 0 8 9]
 [0 3 6 5 5 1 4 9 8 8]]
tt_50sample [[9 7 3 1 6 2 4 8 5 0]
 [3 8 5 7 9 0 4 6 1 2]
 [5 2 6 7 9 3 0 1 4 8]
 [9 8 4 5 0 2 3 1 7 6]
 [7 2 0 6 3 4 5 8 9 1]
 [8 7 6 3 0 9 2 5 1 4]
 [8 4 5 3 1 2 0 9 6 7]
 [2 3 7 0 9 5 8 4 6 1]
 [3 5 6 2 4 1 7 0 8 9]
 [0 3 6 7 5 1 4 9 2 8]]
vm  [-1.6 -0.9 -0.3 -1.6 -1.2  0.5 -0.3 -0.7  0.9 -0.8  4.8  0.9 -0.3  1.   4.8  1.7  0.7 -0.5 -0.1  3.2 -0.2 -0.6 -1.  -0.4 -1.2  2.5  0.4 -0.3 -0.3 -1.4  3.9 -1.1 -0.5  4.4 -1.  -0.5 -0.3  5.8  2.  -1.  -0.4  2.5  1.8  4.3 -1.2  0.1 -2.3 -0.2 -0.6 -1.4 -1.  -0.9 -0.6  4.6 -1.  -0.4 -0.1  3.2  2.3 -1.   7.1 -1.1  0.6  3.4 -0.5 -0.  -0.7  1.1 -0.4  1.6  0.1 -0.1 -0.5 -0.1 -3.4 -0.   1.2 -1.   1.2  0.3 -0.  -0.5  1.2 -0.2  1.   4.4 -0.  -0.6  2.3  0.4 -0.5 -0.8 -0.4  0.1 -1.   0.6  1.8 -1.4 -0.6 -0.5  2.3 -0.6  3.8 -0.4 -0.4 -0.1 -2.5  4.4  1.7  2.8  0.5 -0.3 -0.3 -0.7  2.1  1.8 -0.3  0.7 -0.7  0.3 -0.1 -0.9 -0.4  1.7 -0.7  5.6  1.3 -0.5  5.9  5.5 -1.2 -0.9 -0.2  0.3 -1.6 -0.2 -0.2 -0.2  3.2 -0.5  0.1  0.6 -0.2 -0.3 -0.6 -0.3  0.1 -0.3  4.1 -0.7  4.2 -0.4 -1.4  0.7 -0.5 -0.2 -0.5 -0.2  5.4 -0.3 -0.1 -1.  -0.2 -0.4 -0.1 -0.2  1.5  1.7  1.1 -0.7 -0.3  4.7 -1.  -0.5 -1.  -1.4  0.4 -0.9  0.7 -0.  -1.  -0.4 -0.4 -1.   2.1 -0.8 -1.2 -0.2 -0.6  5.3 -0.6 -0.1  0.7 -0.9 -1.6 -0.4 -1.3 -0.5 -0.7 -0.8  0.9  2.5 -0.9 -1.4  1.5 -2.2  3.5 -0.1 -3.1 -0.5 -0.8  0.9 -0.6  5.6 -0.1 -0.1 -1.  -0.2  0.3 -0.1 -0.4  2.3 -0.1 -0.3 -0.7 -0.1 -0.3  1.7  1.6  1.6 -1.2  1.8 -0.4 -2.1  3.8  2.7  0.2 -1.7  0.9 -3.4 -0.3 -1.9 -0.9 -0.7  1.8  1.1 -0.6 -0.3 -0.5 -0.6 -0.1 -0.6  1.2  0.1  5.4 -1.1]
vy_50sample [[5 1 3 4 7 2 0 8 9 6]
 [1 7 7 3 0 4 5 6 8 8]
 [2 7 0 9 6 8 5 4 1 3]
 [3 8 2 1 0 7 4 9 5 6]
 [5 9 9 3 1 0 6 8 7 4]
 [9 6 4 1 2 0 0 8 5 7]
 [9 1 7 3 8 2 0 4 6 6]
 [8 4 6 5 0 1 2 3 9 9]
 [1 1 9 5 0 0 2 6 7 8]
 [0 0 4 4 7 1 9 9 2 8]]
vt_50sample [[5 1 3 4 7 2 0 8 9 6]
 [1 7 9 3 0 4 5 6 8 2]
 [2 7 0 9 6 8 5 4 1 3]
 [3 8 2 1 0 7 4 9 5 6]
 [5 2 9 3 1 0 8 6 7 4]
 [9 6 4 1 2 0 8 3 5 7]
 [9 1 7 3 8 2 0 5 4 6]
 [8 4 6 5 0 1 2 3 7 9]
 [1 3 9 4 5 0 2 6 7 8]
 [0 6 3 4 7 1 9 5 2 8]]
Epoch  4910: Training cost= 0.4815, Training acc= 0.7080, Validation cost= 0.4619, Validation acc= 0.7086
Epoch  4920: Training cost= 0.4434, Training acc= 0.7082, Validation cost= 0.4551, Validation acc= 0.7088
Epoch  4930: Training cost= 0.4687, Training acc= 0.7083, Validation cost= 0.6005, Validation acc= 0.7089
Epoch  4940: Training cost= 0.4993, Training acc= 0.7085, Validation cost= 0.4734, Validation acc= 0.7091
Epoch  4950: Training cost= 0.4661, Training acc= 0.7087, Validation cost= 0.4638, Validation acc= 0.7093
Epoch  4960: Training cost= 0.5233, Training acc= 0.7089, Validation cost= 0.4667, Validation acc= 0.7095
Epoch  4970: Training cost= 0.4227, Training acc= 0.7091, Validation cost= 0.4532, Validation acc= 0.7097
Epoch  4980: Training cost= 0.5078, Training acc= 0.7093, Validation cost= 0.4460, Validation acc= 0.7099
Epoch  4990: Training cost= 0.4691, Training acc= 0.7095, Validation cost= 0.4865, Validation acc= 0.7101
Epoch  5000: Training cost= 0.5134, Training acc= 0.7096, Validation cost= 0.5398, Validation acc= 0.7102
tm  [ 3.1 -0.3  3.6  1.  -1.3 -0.9 -0.9 -0.9 -0.3  2.7  0.1 -0.5 -0.7 -0.7  4.6 -0.6 -0.8 -0.2  0.5  0.1 -0.5 -0.   4.1  0.1 -0.6  1.9 -0.3 -0.1 -0.4 -1.  -0.3  0.9 -0.6  0.9  4.9 -0.7  0.4 -0.2 -0.2 -1.3 -0.6  3.3 -0.5  0.6 -0.7  0.2 -0.8 -0.3  3.6  7.4 -1.1 -0.9 -0.6  2.7  1.6 -0.3 -0.6  0.3  2.9  3.6 -0.4 -0.2  0.4  6.3  0.1 -0.2 -0.1 -0.4  2.6  0.  -0.   3.5  1.   0.2 -3.2 -0.  -0.8  0.1  1.8 -0.2 -1.2 -0.   2.1 -0.  -1.4  2.8  1.3  0.  -0.7  0.  -0.1 -1.2 -1.5 -0.9 -0.5  0.4  0.6 -1.2  1.3 -0.1 -1.5  5.9 -0.3 -0.2  1.6 -0.2 -1.8 -0.4 -0.1 -0.  -0.3  1.5 -0.  -0.5  4.1 -1.3 -0.2  2.3 -0.2  2.1 -0.2 -0.1 -0.3 -1.  -0.6  5.  -1.4 -0.2  2.1 -0.4  4.5 -0.9 -1.  -0.5 -0.2 -0.6 -0.6 -1.  -0.7 -0.  -0.3 -1.2  1.   0.6 -0.5  1.9 -0.6 -0.8 -0.7 -0.1  1.4  0.4  5.6 -0.  -0.3 -0.4 -0.3 -0.3 -0.4 -0.4  4.2 -0.4  1.2 -0.8 -0.1 -0.9 -0.7 -0.2 -0.3  0.5  2.6 -0.5  0.3 -0.3 -0.1  3.8 -0.9 -0.1  3.7  0.5 -0.  -0.7 -0.5 -0.9  2.8 -0.6  3.2 -0.7  1.2  2.5 -0.1 -0.5 -0.6 -0.8  3.4 -0.7 -1.  -0.7 -0.3  1.1 -0.9  1.8 -0.2 -0.5 -0.8 -1.3 -0.5  0.8  5.2 -0.3  0.8 -0.5 -1.4 -0.2 -0.8 -0.6  2.1 -0.3 -0.3  0.1 -1.1 -0.8 -0.5 -1.   3.2 -0.3 -0.5  1.2 -0.3  4.5 -0.6 -0.4 -0.7  2.8  1.9 -0.2  6.1 -1.2  4.2  2.2 -1.   1.   1.4  0.4  5.4 -0.3 -0.2  0.8 -0.7  0.5  1.9 -0.2 -0.1  0.5 -0.3  4. ]
ty_50sample [[0 8 7 2 6 4 5 5 1 1]
 [2 5 1 9 4 0 3 6 8 7]
 [9 3 8 0 7 5 1 4 6 2]
 [4 3 1 7 8 8 0 2 5 9]
 [2 6 0 0 9 7 5 1 3 4]
 [4 1 7 0 5 2 3 6 9 8]
 [2 1 6 0 9 4 5 7 3 8]
 [0 4 6 7 7 3 1 5 2 8]
 [4 2 5 1 8 9 0 7 6 3]
 [0 9 3 2 5 1 4 4 6 8]]
tt_50sample [[0 8 7 6 2 4 9 5 3 1]
 [2 5 1 9 4 0 3 6 8 7]
 [9 3 8 0 7 5 1 4 6 2]
 [4 3 1 7 8 6 0 2 5 9]
 [2 6 0 8 9 7 5 1 3 4]
 [4 1 7 0 5 2 3 6 9 8]
 [2 1 6 0 9 4 5 7 3 8]
 [0 4 6 7 9 3 1 5 2 8]
 [4 2 5 1 8 9 0 7 6 3]
 [0 9 3 2 5 1 7 4 6 8]]
vm  [-0.1 -0.4 -1.1 -2.  -0.9 -0.7 -0.7 -0.7 -0.5 -0.4 -0.5 -0.5 -0.2 -0.1  3.4  6.4 -0.1 -0.5 -0.4  1.6 -0.2 -0.   2.8 -0.4 -1.  -0.7 -0.5 -0.3  4.8 -0.7  1.2 -1.1 -0.6 -1.6  0.6 -0.7 -0.3  5.2  2.2 -1.3  0.  -0.1 -0.6  6.5 -0.9 -0.  -1.1 -0.3  0.6  3.9 -0.5 -1.4 -1.3  5.2 -1.5 -0.1 -0.4 -0.1  4.4  0.5  0.8 -0.5 -0.1  2.8 -0.6 -0.5 -0.6  1.1  0.2 -0.2  0.8 -1.1  1.1  0.7 -3.5  0.4 -0.3 -0.1  2.5 -0.3 -3.  -0.4  1.   0.  -0.9  0.1  1.6 -0.3  2.4 -0.4 -0.3 -1.1 -0.7 -0.7 -0.6 -0.3 -0.6 -1.3 -0.2 -0.6 -0.2 -0.1 -0.1  0.2 -0.  -0.6 -2.1  1.  -0.5  0.6 -0.4 -0.7 -0.1 -0.6 -0.5  5.4 -0.2  1.   0.2  1.  -0.3 -0.5 -0.4 -1.4 -0.4  3.3 -0.3 -0.8  4.4  3.   2.1 -0.3  1.1 -0.1 -1.3 -3.9  0.2 -0.6 -0.5 -0.  -0.5 -0.4  1.4 -0.2 -0.8  2.1 -0.4 -0.4  0.2  0.4  5.7 -0.1  4.8 -0.5 -0.6 -0.5 -1.  -0.5  1.9 -0.5  1.4 -1.6  0.1 -0.7 -0.8 -0.4  3.7  2.   1.  -1.1  1.4  0.1 -0.8 -0.6 -0.7  0.7 -0.6 -0.6  0.1 -0.6 -0.3 -0.  -0.6 -0.6  1.3  1.1  1.3 -0.4 -1.5  1.1 -0.4 -0.7 -0.4 -1.6  1.7 -0.7 -1.1 -0.1 -0.7 -1.  -0.2  2.2 -0.6 -1.  -1.1 -1.7 -0.6 -0.   4.7 -0.3 -0.1  3.5 -1.4  0.8  1.  -0.  -1.5 -0.2 -0.  -0.2 -1.1 -0.5 -0.4 -0.8 -0.3  4.8 -0.2  0.9 -0.6  6.4 -1.1  0.2 -0.7  3.8 -1.   4.9  2.2 -1.7  2.3 -0.3 -0.1  0.2  0.2  0.   9.1 -0.4 -0.1 -0.5 -0.3 -0.6  5.   1.   2.6 -0.1  1.2 -0.2]
vy_50sample [[8 8 2 3 7 5 9 6 6 0]
 [6 5 8 8 3 7 2 9 9 4]
 [2 3 3 9 1 6 6 6 5 7]
 [9 6 1 1 5 8 7 7 3 2]
 [0 8 9 6 4 7 3 5 1 1]
 [3 3 4 5 6 8 7 1 2 0]
 [2 6 6 8 5 9 7 0 1 4]
 [8 1 5 4 2 2 9 9 7 7]
 [6 1 5 8 4 3 2 2 7 9]
 [1 6 9 8 4 5 3 0 2 7]]
vt_50sample [[4 8 2 3 5 7 9 1 6 0]
 [6 5 8 1 3 7 0 2 9 4]
 [2 3 0 4 9 1 6 5 8 7]
 [9 6 0 1 5 8 4 7 3 2]
 [0 8 9 6 4 7 3 2 5 1]
 [9 3 4 5 6 7 8 1 2 0]
 [2 3 6 5 8 7 9 0 1 4]
 [8 5 1 4 3 2 0 9 6 7]
 [6 5 1 8 4 3 0 2 7 9]
 [1 6 9 8 4 5 3 0 2 7]]
Epoch  5010: Training cost= 0.4635, Training acc= 0.7098, Validation cost= 0.4348, Validation acc= 0.7104
Epoch  5020: Training cost= 0.4363, Training acc= 0.7100, Validation cost= 0.5272, Validation acc= 0.7106
Epoch  5030: Training cost= 0.4723, Training acc= 0.7102, Validation cost= 0.4358, Validation acc= 0.7108
Epoch  5040: Training cost= 0.4409, Training acc= 0.7104, Validation cost= 0.5094, Validation acc= 0.7110
Epoch  5050: Training cost= 0.4817, Training acc= 0.7106, Validation cost= 0.5029, Validation acc= 0.7112
Epoch  5060: Training cost= 0.4307, Training acc= 0.7108, Validation cost= 0.3935, Validation acc= 0.7114
Epoch  5070: Training cost= 0.4443, Training acc= 0.7110, Validation cost= 0.4563, Validation acc= 0.7116
Epoch  5080: Training cost= 0.5490, Training acc= 0.7112, Validation cost= 0.4457, Validation acc= 0.7118
Epoch  5090: Training cost= 0.4892, Training acc= 0.7114, Validation cost= 0.4773, Validation acc= 0.7120
Epoch  5100: Training cost= 0.4119, Training acc= 0.7116, Validation cost= 0.4632, Validation acc= 0.7122
tm  [ 1.9 -0.3  3.1 -0.1 -0.9 -0.9 -1.2 -0.9  0.1  2.   4.1 -1.2 -0.  -0.4  5.5  6.8 -0.5 -0.3 -0.3  1.9 -0.3  1.3  4.1 -0.1 -1.  -0.6 -0.3 -0.   3.2 -0.8 -0.6 -1.1 -0.  -0.5  4.2 -0.6 -0.4  2.  -1.4 -1.1 -0.2  4.3 -0.5 -0.4 -0.2 -0.1 -1.4 -1.4  2.1  7.6 -0.9 -0.8 -0.7  8.8 -0.7 -0.5 -0.5  2.7  4.3  4.3 -0.1 -0.6  0.3  5.   1.1 -0.4 -0.2  1.7  0.6 -1.2  0.3 -0.6  0.8  0.6 -4.2 -0.  -1.2  1.9  0.7 -0.3 -2.2 -0.2  2.2 -0.3 -1.3  4.9 -0.1 -0.1 -0.4 -0.1 -0.5 -1.  -1.4 -1.  -0.8 -0.   0.4 -1.6 -0.2 -0.  -1.3  3.9 -0.3 -0.1 -0.1 -0.2 -2.2 -0.6  2.   1.4 -0.2 -0.1 -0.1 -0.5 -0.2  1.8 -0.   0.1  0.5  1.7 -0.5 -0.8  0.5 -1.1 -0.3  4.6 -1.5 -2.2  4.4 -0.2  5.7 -0.9 -0.4 -0.3  4.4  1.4 -0.4 -0.8 -0.8 -0.  -1.1 -0.5 -0.1  0.  -0.9  2.4 -0.5 -0.6  0.7  2.3  2.   0.3  5.8 -1.  -0.2 -0.1 -0.7 -0.4 -0.9 -0.6  3.5 -0.2  1.1 -0.6 -0.1 -0.6 -0.  -0.4 -0.4 -0.2  2.   0.2 -0.4 -0.4 -0.3  0.1 -1.7 -0.7  7.8 -0.7 -0.4 -0.3 -0.4 -1.   1.  -0.2  1.9 -0.4 -1.   2.6 -0.2 -0.9 -0.5 -0.8  2.  -1.  -1.1 -0.4 -0.4 -0.1 -0.4  0.7 -0.5 -0.6 -0.9 -1.7 -0.2  0.5  3.3 -0.3  0.2  1.8 -1.3  0.2 -0.5 -0.1  3.7 -0.3 -0.3 -0.3 -0.9 -0.9 -0.3 -0.6  3.6  3.1  1.1  3.2 -0.2  6.1 -0.3 -0.3 -0.7  2.5 -1.  -0.1  3.8 -2.   1.3 -1.1 -0.9 -0.6  2.3  0.7  7.7  0.1 -0.   1.6 -0.6 -0.   3.8  1.  -1.3  1.9 -0.3  2.6]
ty_50sample [[2 8 6 5 7 4 0 9 3 3]
 [7 7 0 0 4 3 9 8 2 6]
 [2 1 5 6 4 8 3 3 0 7]
 [0 1 2 4 3 6 8 5 7 9]
 [3 8 8 6 4 4 0 7 7 5]
 [7 2 3 5 1 6 4 9 9 8]
 [3 4 5 6 8 1 0 7 9 2]
 [7 0 2 5 6 1 4 3 3 8]
 [0 1 5 2 6 7 3 9 8 4]
 [4 7 2 6 0 8 3 9 5 1]]
tt_50sample [[2 8 6 5 7 4 0 9 3 1]
 [7 5 0 1 4 3 9 8 2 6]
 [2 1 5 4 6 8 3 0 9 7]
 [0 1 2 4 3 6 8 5 7 9]
 [3 8 2 1 6 4 0 7 9 5]
 [7 2 3 5 1 6 4 9 0 8]
 [3 4 5 6 8 1 0 9 7 2]
 [7 0 2 5 6 1 4 9 3 8]
 [0 1 5 2 6 7 3 9 8 4]
 [4 7 2 6 0 8 3 9 5 1]]
vm  [-1.  -1.1  4.5  2.3 -1.1 -0.1 -0.4 -0.5 -0.1  2.2  3.4 -0.3  0.  -0.3  5.3 -0.4 -0.4 -0.7  0.6 -0.1 -0.4 -0.2  0.8 -0.6 -0.8  0.9  0.1 -0.1 -0.5 -1.4  2.1 -0.1 -0.2  6.6  1.4 -0.5 -0.3 -0.2 -1.8 -0.8 -0.5  5.8  1.4 -1.3 -0.8 -0.2 -1.7 -0.2  0.2  1.9 -1.3 -0.6 -1.1  2.6 -0.2 -0.3 -0.4  3.2  1.4  1.3  3.9 -0.7 -0.1  5.1 -0.1  1.9 -0.2  0.2  0.5  0.5 -0.2  1.4 -0.6 -0.3 -2.7 -0.3 -0.1  0.2  2.2  0.3  2.5 -0.2 -0.3 -0.5 -0.1  7.  -0.5 -0.7 -0.6  0.4 -0.4 -0.5 -1.  -0.8 -0.5  0.   2.5 -1.3  0.1 -0.2 -0.5  5.1  2.7  0.4 -0.4 -0.  -1.9  1.1  1.5 -0.3  0.4  1.3 -0.2 -0.8  4.2 -0.4 -0.6  0.5 -0.7 -0.1 -0.2  0.4  1.5  3.2 -0.4  5.2 -0.1 -0.   3.4 -0.1  3.3 -1.5 -0.8 -0.6  5.9 13.7 -0.6 -0.3 -0.7 -0.4 -0.   1.   0.4  1.  -1.  -0.4  0.1 -0.5  2.6  1.   2.3 -0.7 -0.8 -0.1 -0.6 -0.4 -0.1 -0.2 -0.5  0.7  2.4  3.7 -0.2 -0.6 -0.  -0.5 -0.5 -0.1 -0.3  0.3  1.3  2.2 -0.4 -0.8 -0.  -0.3 -1.3 -0.5  9.7  0.7 -1.4 -0.1 -0.4 -0.8  1.7 -0.9 -0.6 -0.6 -0.3  4.   0.2 -0.6 -0.2 -0.5 -0.9 -0.3 -1.  -0.8 -0.3 -0.3 -0.5  1.9 -0.3 -0.7  3.2 -2.1  2.5  0.8 -2.4 -0.1 -0.2 -0.1 -1.   4.1 -1.  -0.5  6.7 -0.3  0.5 -0.4 -0.4  0.1 -0.3 -0.   4.3 -0.8 -0.6  2.7  0.7  1.3  0.8 -0.2 -0.2 -1.8  3.7 -1.   2.4 -1.2  2.3 -2.  -1.1 -1.4  0.4 -0.6 -0.   2.4 -0.6  2.2 -1.2 -0.1 -0.7 -0.9 -1.8  1.4  2.3  2.6]
vy_50sample [[6 5 0 7 7 2 9 4 3 3]
 [7 8 9 9 3 1 2 5 4 0]
 [3 9 1 5 0 7 7 8 2 4]
 [1 8 2 9 0 0 4 3 6 5]
 [1 3 6 4 7 5 2 0 8 9]
 [5 9 1 7 4 2 2 6 3 8]
 [0 5 1 6 9 7 4 3 2 8]
 [5 2 8 1 3 0 4 6 9 7]
 [9 1 8 2 6 0 4 5 5 3]
 [3 1 0 6 5 9 2 8 7 7]]
vt_50sample [[6 5 1 0 7 2 9 8 4 3]
 [7 8 6 9 3 1 2 5 4 0]
 [3 9 1 5 0 6 7 8 2 4]
 [1 8 2 7 9 0 4 3 6 5]
 [1 3 6 4 7 5 2 0 9 8]
 [5 9 1 7 4 2 0 6 3 8]
 [0 5 1 6 9 7 4 3 2 8]
 [5 2 8 1 3 0 4 6 9 7]
 [9 1 8 2 6 0 7 4 5 3]
 [3 1 0 6 5 9 2 8 7 4]]
Epoch  5110: Training cost= 0.5046, Training acc= 0.7118, Validation cost= 0.4323, Validation acc= 0.7124
Epoch  5120: Training cost= 0.4122, Training acc= 0.7120, Validation cost= 0.4583, Validation acc= 0.7126
Epoch  5130: Training cost= 0.4576, Training acc= 0.7122, Validation cost= 0.4023, Validation acc= 0.7128
Epoch  5140: Training cost= 0.4499, Training acc= 0.7124, Validation cost= 0.4850, Validation acc= 0.7130
Epoch  5150: Training cost= 0.4028, Training acc= 0.7126, Validation cost= 0.3999, Validation acc= 0.7132
Epoch  5160: Training cost= 0.3969, Training acc= 0.7128, Validation cost= 0.4525, Validation acc= 0.7134
Epoch  5170: Training cost= 0.4406, Training acc= 0.7130, Validation cost= 0.4173, Validation acc= 0.7136
Epoch  5180: Training cost= 0.3779, Training acc= 0.7132, Validation cost= 0.4462, Validation acc= 0.7138
Epoch  5190: Training cost= 0.4470, Training acc= 0.7134, Validation cost= 0.4862, Validation acc= 0.7140
Epoch  5200: Training cost= 0.4906, Training acc= 0.7136, Validation cost= 0.5032, Validation acc= 0.7141
tm  [ 3.2 -0.9  3.6  4.5 -1.3 -1.7 -0.8 -1.  -0.3 -0.9  1.1  2.2 -1.4 -0.6  2.1 -0.3 -0.1 -0.2 -0.1 -0.8 -0.1  2.1 -1.5  0.8 -0.7 -0.8 -0.3 -0.3 -0.2 -0.6  1.4 -0.6  2.9  6.4 -0.4 -0.   0.7 -0.3 -0.7 -1.3  0.1 -0.4  2.1 -1.  -0.4 -0.6  3.2  1.7  3.  -2.5 -0.9 -0.6 -0.2 -1.  -0.6  0.   0.6  3.5 -0.7 -0.1 -1.1 -0.9 -0.2  0.8 -0.  -0.8 -0.5  0.9  1.6  1.6 -0.1  0.5 -0.9 -0.9 -2.4 -0.2 -0.9 -0.8 -0.8 -1.   8.3 -0.4 -1.1  0.  -1.  -0.5  1.4 -0.7  4.5  0.2 -0.8 -0.1  1.6  1.2 -1.  -0.6  0.7 -0.3  0.2  0.4  2.1 -0.8 -0.7 -0.5 -0.3 -0.4 -1.3  2.4  0.8 -1.1  3.4 -0.4 -0.7 -0.7  1.6  0.5  0.4  2.9  0.2  1.2 -0.3  2.1 -0.2 -0.5 -0.7  1.8  2.5  5.8 -0.2  5.4  4.7 -1.1  1.1 -0.1  4.3 12.1 -0.4  0.5  0.3 -0.7  1.1 -0.1  1.9 -0.6 -0.5 -0.5 -1.2 -1.7  2.6 -0.6 -0.5 -0.   2.7  1.2 -1.  -0.  -0.4 -0.2 -1.4 -0.8 -1.   0.9  0.4 -0.1  2.6 -0.3 -0.   0.7 -0.6  2.2 -1.3  1.6 -1.  -0.4 -0.5 -0.4 -1.1 -0.8  4.6  0.6 -1.  -0.5 -0.  -1.2 -0.1 -1.2  4.  -0.7 -0.2  3.8 -0.3 -0.1 -0.8 -1.4  6.6 -0.3 -0.8 -0.3 -0.6 -1.  -0.  -0.2  0.3 -0.5 -1.5 -1.   2.4 -0.2 -2.3 -0.7 -0.5  0.  -0.7 -0.6 -0.9  1.4  4.1 -0.4  1.2 -0.1 -0.4 -0.2  2.7 -0.5 -0.3 -0.1 -1.5 -0.7 -0.5  7.  -0.4  2.6 -0.6 -1.6 -0.4 -0.5 -0.1 -1.3  1.2 -0.6 -0.6 -0.4 -0.6  0.7 -1.4 -0.6 -0.4 -0.7 -0.1  0.8 -1.7 -1.6 -0.3 -1.1  5.1 -0.9]
ty_50sample [[3 6 5 7 0 0 4 8 2 1]
 [0 6 7 5 8 4 1 9 3 2]
 [0 1 3 5 2 8 6 9 4 7]
 [5 6 6 1 1 4 0 8 7 9]
 [9 1 2 8 3 4 5 6 0 7]
 [6 9 7 2 3 1 0 4 5 8]
 [6 7 8 5 2 4 4 1 3 3]
 [9 9 4 7 3 0 1 8 6 5]
 [5 1 8 3 4 9 0 6 7 2]
 [7 3 9 8 6 5 4 4 0 1]]
tt_50sample [[3 6 5 7 0 9 4 8 2 1]
 [0 6 7 5 8 4 1 9 3 2]
 [0 1 3 5 2 8 6 9 4 7]
 [5 3 6 1 4 2 0 7 8 9]
 [9 1 2 8 3 4 5 6 0 7]
 [9 6 7 2 3 0 1 4 5 8]
 [6 7 8 5 2 4 9 0 1 3]
 [2 9 4 7 3 0 1 8 6 5]
 [5 1 8 3 4 0 9 6 7 2]
 [7 3 9 8 6 5 2 4 0 1]]
vm  [-0.1  1.2  5.4  9.4 -1.  -0.6 -1.1 -0.7 -1.4  1.5  0.4 -0.8  0.2 -0.3 -0.1  1.7  0.9 -0.3 -0.7 -1.7 -0.4 -0.8  4.8  1.  -1.3 -0.6 -0.2 -0.1 -0.4 -0.4 -2.2 -0.5 -0.1 -1.5  0.8  1.4  4.   0.3 -1.1 -0.6 -0.3  5.7  3.5 -1.7 -0.4 -0.4  1.1 -0.6  1.2  8.5 -0.3 -0.2 -0.8  3.7 -0.7  1.5 -0.5  4.3 -0.9  8.3 -0.2 -0.6 -1.3 -0.1 -0.4  0.3 -0.4 -0.2 -0.1 -0.8 -0.2 -0.   1.4 -0.7 -1.   0.9  0.5  0.1 -0.2 -0.3 -0.9 -0.1 -1.1 -0.2 -0.4  7.4  0.1 -0.1  0.5 -0.1 -0.7  1.7 -0.8  1.9 -0.3 -0.5  3.8 -0.4  0.1 -0.2 -0.1  3.8 -0.3 -0.6  1.   0.3 -1.  -1.9  0.8 -1.6 -0.  -0.2 -0.2 -0.2  0.1 -0.   0.1 -0.9  0.3 -0.1  0.3  4.6  0.6 -0.9 -0.2 -0.1 -0.1 -0.3 -0.2 -0.7  3.8 -0.6 -0.6  1.1  8.   4.7 -0.7 -0.7 -1.  -0.3 -0.5 -0.8 -0.5 -0.  -0.4 -0.3 -0.4 -0.9  3.4  2.4 -1.4 -0.3  3.8 -0.9 -0.4 -0.3 -0.1  0.4 -1.3 -1.2  0.5  3.9 -0.4 -0.2 -0.9 -0.2 -0.5 -1.  -0.7  3.1  2.2  1.6 -0.6  0.5 -0.3 -1.1 -1.3 -0.7  6.6 -0.8 -1.2  0.4  2.  -0.9  0.6  2.5  2.  -0.  -0.3  2.6 -0.2 -1.  -0.2 -0.7  3.  -0.2 -0.7  0.9 -0.7 -0.2 -0.3 -0.8 -0.3 -0.3  0.7 -1.3  0.8  2.2  0.8  0.6 -0.2 -0.2 -0.6  0.8 -0.9 -0.1  8.4 -0.3 -0.2 -0.9 -0.4 -0.6 -0.3 -0.4  4.4  1.8 -0.1  1.5 -0.3  1.2  0.2 -0.1 -0.4  1.1  0.5 -1.2  1.7 -0.6 -0.4 -1.  -0.8 -0.6  0.2 -0.6  4.  -0.1  1.2  1.8 -0.3  0.7  0.9 -0.4 -1.1  1.1  0.8  4.8]
vy_50sample [[6 5 8 2 0 9 7 1 3 4]
 [9 9 7 8 6 6 3 0 2 4]
 [2 0 6 1 9 3 5 4 8 7]
 [0 7 8 1 2 9 5 6 3 4]
 [8 1 4 0 2 5 6 7 3 9]
 [5 1 7 7 0 3 9 8 6 4]
 [3 0 2 9 4 5 5 1 6 8]
 [7 7 0 6 9 4 8 8 2 2]
 [4 7 6 6 1 2 0 5 3 9]
 [9 1 6 5 0 7 8 3 2 4]]
vt_50sample [[6 5 8 2 0 9 7 1 3 4]
 [9 7 5 1 8 6 3 0 2 4]
 [2 0 6 1 9 3 5 4 8 7]
 [0 7 8 1 2 9 5 6 3 4]
 [1 8 4 0 2 5 6 7 3 9]
 [5 1 2 7 0 3 9 8 6 4]
 [3 0 2 9 4 5 7 1 6 8]
 [5 7 0 6 9 4 1 8 2 3]
 [4 7 1 6 8 2 5 0 3 9]
 [9 1 6 5 0 7 8 3 2 4]]
Epoch  5210: Training cost= 0.4915, Training acc= 0.7137, Validation cost= 0.4984, Validation acc= 0.7143
Epoch  5220: Training cost= 0.5175, Training acc= 0.7139, Validation cost= 0.4787, Validation acc= 0.7145
Epoch  5230: Training cost= 0.4504, Training acc= 0.7141, Validation cost= 0.4591, Validation acc= 0.7146
Epoch  5240: Training cost= 0.4899, Training acc= 0.7142, Validation cost= 0.4751, Validation acc= 0.7148
Epoch  5250: Training cost= 0.5230, Training acc= 0.7144, Validation cost= 0.5489, Validation acc= 0.7150
Epoch  5260: Training cost= 0.4621, Training acc= 0.7145, Validation cost= 0.4227, Validation acc= 0.7151
Epoch  5270: Training cost= 0.4197, Training acc= 0.7147, Validation cost= 0.4779, Validation acc= 0.7153
Epoch  5280: Training cost= 0.4037, Training acc= 0.7149, Validation cost= 0.4273, Validation acc= 0.7155
Epoch  5290: Training cost= 0.6083, Training acc= 0.7151, Validation cost= 0.4839, Validation acc= 0.7157
Epoch  5300: Training cost= 0.4555, Training acc= 0.7153, Validation cost= 0.5049, Validation acc= 0.7159
tm  [-0.9 -1.1  2.7 -2.7 -2.2 -0.2 -0.4 -0.5  0.8  1.3  2.6  0.5 -0.6 -0.6 12.   2.  -0.8 -0.2  0.9  4.6 -0.3 -0.2  1.8 -0.6 -0.4 -0.  -0.3 -0.2  1.2 -1.1  4.6 -0.4 -0.5  8.4  1.  -0.9 -0.7  3.5  0.1 -0.6 -0.2  3.3 -0.6  5.6 -1.5 -0.1 -2.6 -0.3 -0.2  2.1 -1.3 -1.2 -0.7  5.2 -1.  -2.  -0.6  0.5  4.7 -1.1  6.4 -0.6  1.8  5.4  0.9 -0.6 -0.2  0.5  0.8 -0.3  1.4 -0.8 -0.2  0.1 -5.2 -0.3 -0.3 -0.1  3.8 -0.1 -1.1 -0.2  3.5 -0.  -0.3  4.2  1.3 -0.8 -0.4 -0.2 -0.5 -1.3 -1.3 -1.4 -1.   0.2 -0.4 -2.1 -1.  -0.2 -0.6  7.8  1.7 -0.1 -0.6 -0.4 -3.1  5.7  1.5  4.3  0.7 -0.5 -0.1 -1.3  2.6  0.7  0.1  3.2 -0.8 -0.4 -0.3 -1.6 -0.3  1.1 -0.5 13.2 -0.5 -0.9  6.   1.9 -1.  -1.  -0.3 -0.3 -4.9 -0.8  0.9 -0.4 -0.8 -0.8 -0.2  1.8  0.9 -0.1 -0.8  0.6  0.3 -0.9 -0.8  0.3  6.3 -0.  -0.3  0.9 -0.1 -0.2 -0.7 -0.7  4.2 -0.2  2.6 -1.5  1.4 -0.9  2.5 -0.5 -0.4  1.8  0.3 -0.8  2.1  1.6 -0.7 -0.5 -1.   3.5 -0.3 -0.8  2.3  2.6 -0.6 -0.3 -0.9 -1.1  0.6 -0.7 -1.  -1.2 -0.9  1.2 -0.5 -0.9 -0.1 -1.  -1.4 -0.7 -1.6 -0.8 -1.  -0.8 -0.3  1.6 -0.8 -0.7  0.7 -2.3  1.3 -0.4 -0.6 -0.5 -0.2  0.8 -0.7  5.3  0.7 -0.5 -1.7 -0.3  2.   0.7 -1.2 -0.2 -0.5 -0.3 -0.1  0.5 -0.6  1.2  0.2  2.  -0.8  0.9 -0.3 -0.5 -0.   0.2  3.  -2.5  3.2 -2.1 -0.5 -1.2 -0.4 -0.4  4.7  1.7 -0.8 -0.1 -0.3  0.   0.5  1.1  0.2 -0.1  1.3 -0.1]
ty_50sample [[7 4 1 5 2 0 8 3 6 9]
 [1 4 3 6 9 5 0 0 8 7]
 [6 1 1 7 0 2 8 3 5 4]
 [9 2 2 8 5 0 6 3 1 7]
 [0 8 5 9 4 7 3 1 2 6]
 [1 4 2 0 8 9 9 7 5 6]
 [5 6 3 7 8 9 4 2 1 0]
 [2 4 4 0 7 7 3 9 1 6]
 [9 3 2 6 4 7 1 5 5 8]
 [3 4 1 2 5 5 7 0 8 9]]
tt_50sample [[7 4 1 5 2 0 8 3 6 9]
 [1 4 3 6 9 5 0 2 8 7]
 [6 9 1 7 0 2 8 3 5 4]
 [4 9 2 8 5 0 6 3 1 7]
 [0 8 5 9 4 7 3 1 2 6]
 [1 4 2 0 8 3 9 7 5 6]
 [5 6 3 7 8 9 4 2 1 0]
 [2 5 4 7 0 8 3 9 1 6]
 [9 2 3 6 4 7 1 5 0 8]
 [3 4 1 6 2 5 7 0 8 9]]
vm  [ 1.5 -0.1 -2.8  1.2 -0.5 -0.5 -0.5 -0.2 -0.6 -1.   5.2 -0.  -0.4 -0.8 -3.4  0.7  0.1 -0.2 -0.7 -1.4 -0.8 -0.3 -0.   0.9 -1.1  3.1 -0.6 -0.2 -0.9 -0.4  4.9 -1.1 -0.1 -2.1  2.8  2.1  3.3  3.6  9.2 -1.5 -0.4  1.5  0.4  6.3 -0.4 -0.   6.3 -0.3  1.9 -0.  -0.4 -1.   2.4 -0.1 -0.2  7.2 -0.7 -0.4  0.2 -1.2 -1.3 -0.5  0.6  2.9 -0.1 -0.5  0.7  3.5  0.2  0.2 -1.1  0.7 -0.2 -0.2  2.4 -0.1 -0.2 -0.4  1.6 -0.5 10.5 -0.  -1.1 -0.2 -1.2  1.1  3.5 -0.6  0.7 -0.5 -0.2 -0.6 -0.2  0.4  0.8 -0.1 -0.3  0.4 -0.4 -0.2  1.  -1.5 -1.  -0.5 -0.  -0.1  1.6  5.9  3.4 -1.7 -1.2  1.6 -0.   0.2  3.  -0.5 -0.2 -0.  -0.   0.8 -0.1  5.9 -0.3 -0.  -0.7 -3.3 -0.2  2.5  0.8 -0.5  0.7 -0.7 -0.5 -0.1  6.5 -0.4 -0.4 -0.9  1.8 -0.8 -0.4 -1.1 -0.5 -0.2  0.3  0.7 -0.5 -0.   5.5 -0.6 -0.4  1.3  2.4 -0.1 -0.3 -0.   0.1 -0.6  1.  -0.5  1.9 -1.1 -0.9 -0.9 -0.7 -0.5 -0.5 -0.3  0.8  0.7  0.8 -0.3 -0.1  0.1 -0.3 -1.6 -0.3  3.4 -1.9 -0.6 -0.8 -0.  -0.3 -1.1  0.5 -0.5  5.4  2.   2.7  4.3 -0.3 -0.7 -1.  -1.2  8.4  0.4  2.7 -0.1 -0.5  1.5 -0.1  1.4 -0.7 -0.9 -1.   2.3  0.8  1.7 -0.5 -0.5 -0.4 -0.2 -0.8  0.1  1.8 -0.7 -1.5 -0.3 -1.3 -0.7  2.2 -0.8 -0.3 -1.  -0.2 -0.5  0.8  0.   0.9  4.7 -1.4 -0.6 -0.4 -0.4  3.4  9.6  3.8  2.6  1.8  7.7 -0.5  4.2 -0.8 -0.1 -1.7 -2.   1.3 -0.1 -0.6 -0.4 -2.   1.5  8.7  1.2  0.   4.8]
vy_50sample [[4 9 2 2 5 3 8 6 1 7]
 [2 5 1 7 7 0 9 4 8 3]
 [8 0 2 5 7 7 1 3 4 9]
 [9 2 3 5 6 6 7 0 4 4]
 [0 5 2 1 1 6 6 4 7 7]
 [7 1 2 2 5 5 0 4 8 9]
 [2 0 8 6 9 4 5 1 3 7]
 [9 5 1 8 3 6 2 4 7 0]
 [4 2 3 6 6 7 1 1 8 5]
 [6 3 5 4 8 8 1 0 7 2]]
vt_50sample [[4 9 0 2 5 3 8 6 1 7]
 [2 5 1 6 7 0 9 8 4 3]
 [8 2 0 6 5 7 1 3 4 9]
 [9 2 3 5 8 6 7 0 4 1]
 [0 3 5 2 1 6 8 9 4 7]
 [7 3 1 2 5 6 0 4 8 9]
 [2 0 8 6 4 9 5 1 3 7]
 [9 5 1 8 6 3 4 2 7 0]
 [4 2 3 6 9 7 0 1 8 5]
 [6 3 5 9 4 8 1 0 7 2]]
Epoch  5310: Training cost= 0.4769, Training acc= 0.7154, Validation cost= 0.4558, Validation acc= 0.7161
Epoch  5320: Training cost= 0.4215, Training acc= 0.7156, Validation cost= 0.4147, Validation acc= 0.7163
Epoch  5330: Training cost= 0.4531, Training acc= 0.7158, Validation cost= 0.4120, Validation acc= 0.7165
Epoch  5340: Training cost= 0.4298, Training acc= 0.7160, Validation cost= 0.4832, Validation acc= 0.7166
Epoch  5350: Training cost= 0.4320, Training acc= 0.7162, Validation cost= 0.4537, Validation acc= 0.7168
Epoch  5360: Training cost= 0.4974, Training acc= 0.7163, Validation cost= 0.4725, Validation acc= 0.7170
Epoch  5370: Training cost= 0.5337, Training acc= 0.7165, Validation cost= 0.4434, Validation acc= 0.7171
Epoch  5380: Training cost= 0.5040, Training acc= 0.7167, Validation cost= 0.4461, Validation acc= 0.7173
Epoch  5390: Training cost= 0.4767, Training acc= 0.7168, Validation cost= 0.4247, Validation acc= 0.7175
Epoch  5400: Training cost= 0.5281, Training acc= 0.7170, Validation cost= 0.4487, Validation acc= 0.7176
tm  [-0.8 -0.2  2.6  1.4 -1.4 -0.7 -0.1 -0.6 -0.8 -1.1 -0.4  1.7 -0.7  0.6  3.7  1.   1.6 -0.6  0.4 -1.2 -0.1 -0.2 -0.7 -0.1 -1.3 -0.2  0.6 -0.4  0.6 -0.3  3.4 -0.7 -0.1  7.  -1.2 -0.1  0.9 -0.1 -0.3 -1.2  0.2  2.3  4.6 -0.2 -0.5 -0.4 -0.3  1.9  0.6 -1.2 -1.2 -0.4 -0.4 -1.1 -1.3 -0.4 -0.2  3.6 -1.1 -0.5  0.9 -0.8 -0.5 -0.5 -0.6  2.2 -0.7 -0.2  0.2  3.9  0.  -0.5 -0.7 -0.9 -0.3 -0.1  0.4 -0.5 -0.  -0.1  6.3 -0.4 -1.  -0.   0.1  3.9  0.8 -0.4  3.6  0.1 -0.7  1.6 -0.   0.6 -0.1  0.6  3.3 -0.3 -0.3 -0.3  3.9  1.7 -0.2 -0.1 -0.1  1.1 -0.9  3.3 -0.2 -1.3  0.7 -0.4 -0.6 -0.4 -0.7  5.7 -0.4 -0.3 -0.8 -0.7 -0.4  4.1  0.4  1.  -0.6  4.   4.1  6.   2.   2.4  1.3 -1.1  1.3 -0.1  0.3  8.9 -0.4  0.4 -0.1 -0.9  2.6  1.1  1.9  0.2 -1.2 -0.4 -0.2 -1.2  2.9  1.8  2.3 -0.6 -0.3  0.1 -0.8 -0.4 -0.5 -0.2 -0.3 -0.5 -0.6  2.3 -0.4 -0.1  0.6 -0.1  2.5  0.8  0.6 -0.1 -0.4  2.9 -1.3 -0.9 -0.5 -0.5 -0.8 -0.7  3.5 -0.1 -1.5  1.9 -0.1 -1.3 -0.4 -0.6  0.9 -0.6 -0.9  0.8 -0.2 -0.  -0.  -1.   1.2  0.3 -0.2  0.5 -0.4 -1.3 -0.2 -0.1 -0.2 -0.9  1.7 -1.4  2.7  1.1 -2.6 -0.4 -0.6  3.7 -0.9  2.1 -0.4 -0.3  1.3 -0.3  2.5 -0.3 -0.8  1.5 -0.1  1.6  0.9  2.3 -0.6 -0.5  0.5  3.2 -0.8 -0.2 -0.2 -1.8  1.2 -0.1 -0.6 -0.1  1.1 -1.5 -0.7 -0.8 -0.6 -0.4 -0.6  0.5 -0.6 -0.  -0.4 -0.4 -1.3 -1.3 -0.2 -0.6  6.9 -0.3]
ty_50sample [[5 7 6 3 1 9 9 8 0 0]
 [9 3 7 8 5 6 2 0 4 1]
 [2 8 4 1 0 5 7 6 9 9]
 [2 5 4 8 3 9 7 1 1 0]
 [5 1 1 0 8 4 4 9 3 6]
 [6 3 3 5 5 4 9 9 2 1]
 [7 6 3 3 4 8 8 0 5 2]
 [2 1 5 6 3 7 9 9 8 4]
 [3 4 5 5 2 9 6 1 7 0]
 [4 6 7 7 1 1 3 0 0 5]]
tt_50sample [[5 7 6 3 4 1 9 8 0 2]
 [9 7 3 8 5 6 2 0 4 1]
 [2 8 4 1 0 5 7 3 6 9]
 [5 2 4 8 3 9 7 6 1 0]
 [5 1 2 0 7 8 4 9 3 6]
 [6 7 3 8 5 0 4 9 2 1]
 [7 6 9 3 4 1 8 0 5 2]
 [2 1 5 6 3 7 9 8 0 4]
 [3 4 5 8 9 2 6 1 7 0]
 [4 6 7 8 2 1 3 9 0 5]]
vm  [-0.4  1.3 -0.1 -1.3 -0.7  0.4 -0.9 -0.7 -0.7  0.3  2.9 -0.7  2.1 -0.3  4.5  1.7 -0.  -0.1 -0.5  3.7 -0.4 -0.8  3.1 -0.1 -1.1  1.6 -0.5 -0.2 -1.  -1.  -1.2 -0.1 -0.5 -3.   3.2  0.2  1.8  2.8 -2.5 -0.7 -0.5 -0.5 -0.6 -0.3 -1.1 -0.1 -2.9 -1.5 -0.1  5.8 -0.7 -1.6 -1.4 12.4 -0.1 -0.3 -0.5  0.   2.6  5.4  8.   1.1 -0.3  3.6 -0.3 -0.3 -0.1  1.2 -0.5 -0.1 -0.1  3.5  1.9 -0.6 -5.  -0.1  2.2 -0.6  2.8 -0.3 -4.3 -0.1  2.1 -0.3 -0.1 -0.7 -0.2 -0.4 -0.2 -0.4 -0.4 -1.1 -0.9  2.  -1.4 -0.1  0.2 -1.9 -0.5 -0.4 -0.3 -0.4  3.  -0.6  1.6 -0.1 -3.5 -1.1  1.6  3.4 -0.8  0.8 -0.2 -0.2  4.6 -1.5 -0.6 -0.  -0.1  1.8 -0.2 -1.4  0.2 -0.3 -0.9  5.2 -0.9 -2.9 -0.   5.2  1.2  0.1 -0.8  0.9  7.9 -0.7 -0.9 -0.1  0.3 -0.4 -0.8 -1.3 -1.6 -0.4  1.1 -1.  -0.5  1.6  0.  -0.2  2.7  0.2  2.2 -1.  -0.5 -0.2 -0.  -0.2 -0.4 -1.2  1.9  0.6 -0.2 -0.6 -1.5 -0.6 -0.6  1.6 -0.  -0.4  0.6  0.3  0.5 -0.2 -0.6  2.1 -1.3 -1.4 11.  -0.6  0.5  0.   1.  -1.   4.2  1.7 -0.9 -0.1 -0.3  4.6 -0.5 -0.4  2.2 -0.9 -1.8 -0.1 -2.5 -0.5 -0.3  2.9  1.2  0.8 -0.5 -0.7 -0.3 -3.5 -1.3  0.3  8.5 -0.3 -0.5 -1.2 -0.9  2.  -0.2 -0.9  3.7 -0.3 -0.9 -0.6  0.2 -0.2 -0.3 -1.2  1.8 -0.2  1.7  3.7 -0.5  1.  -0.4  2.5 -0.5  5.8  3.4  2.7  3.8 -2.8 -0.  -0.7 -1.3 -0.1 -0.  -0.4 13.1  4.6 -0.3  0.7 -0.  -0.   8.   0.4 -1.9  1.  -0.7 -1. ]
vy_50sample [[2 2 8 6 1 3 4 7 5 9]
 [5 9 3 1 1 4 8 2 0 6]
 [2 2 3 0 9 8 6 6 7 4]
 [2 1 8 6 9 9 5 4 0 7]
 [7 8 6 2 1 1 9 9 4 0]
 [6 9 4 4 2 0 0 5 8 3]
 [1 4 5 7 8 8 3 6 0 9]
 [3 6 9 2 5 0 8 8 7 7]
 [5 7 3 2 1 8 4 6 9 0]
 [1 6 9 8 5 7 4 2 0 3]]
vt_50sample [[2 0 8 1 6 3 4 7 5 9]
 [5 9 7 3 1 4 8 2 0 6]
 [2 3 1 0 9 8 6 5 7 4]
 [2 1 8 6 9 3 5 4 0 7]
 [7 8 6 2 5 1 9 3 4 0]
 [6 9 7 4 2 0 1 5 8 3]
 [1 4 5 7 2 8 3 6 0 9]
 [6 3 9 2 0 5 1 8 7 4]
 [5 7 3 2 8 1 4 6 9 0]
 [1 6 9 8 5 7 4 2 0 3]]
Epoch  5410: Training cost= 0.5509, Training acc= 0.7171, Validation cost= 0.4762, Validation acc= 0.7178
Epoch  5420: Training cost= 0.4170, Training acc= 0.7173, Validation cost= 0.5812, Validation acc= 0.7179
Epoch  5430: Training cost= 0.5084, Training acc= 0.7174, Validation cost= 0.4946, Validation acc= 0.7180
Epoch  5440: Training cost= 0.5012, Training acc= 0.7175, Validation cost= 0.4783, Validation acc= 0.7182
Epoch  5450: Training cost= 0.4623, Training acc= 0.7177, Validation cost= 0.4428, Validation acc= 0.7183
Epoch  5460: Training cost= 0.4463, Training acc= 0.7179, Validation cost= 0.4707, Validation acc= 0.7185
Epoch  5470: Training cost= 0.4781, Training acc= 0.7180, Validation cost= 0.4414, Validation acc= 0.7186
Epoch  5480: Training cost= 0.4489, Training acc= 0.7182, Validation cost= 0.4500, Validation acc= 0.7188
Epoch  5490: Training cost= 0.4208, Training acc= 0.7184, Validation cost= 0.4601, Validation acc= 0.7190
Epoch  5500: Training cost= 0.4420, Training acc= 0.7185, Validation cost= 0.4613, Validation acc= 0.7192
tm  [-0.6  0.9  4.8  0.1 -0.9 -0.6 -0.9 -0.7 -0.9  4.3 -3.6 -0.1 -1.1 -0.3  7.6 -1.1 -0.2 -0.  -0.6  0.3 -0.3 -0.8  6.1 -0.2 -0.4 -1.3 -0.3 -0.5 -0.6 -1.2 -2.3 -0.  -0.1 -2.4  1.6 -0.8  0.5 -0.7 -2.9 -0.6 -0.3  5.7  0.5 -1.4 -0.9 -0.3 -2.   0.6 -0.1 10.4 -0.2 -0.8 -2.   3.5 -0.4 -0.9 -0.4  3.6  0.3  8.6  5.6 -1.2 -0.7  0.  -0.4 -0.4 -0.3 -0.5  1.6 -0.8  0.1  1.   1.2 -0.7 -5.  -0.   0.8  0.1  1.1 -0.1 -4.8 -0.2 -0.  -0.2 -0.5  7.3 -0.1 -0.1 -0.2 -0.5 -0.4 -0.3 -1.7 -0.  -1.4 -0.8  2.3 -1.7  0.4 -0.1 -1.1  5.3  2.7 -0.6 -0.3 -0.7 -3.5 -2.4 -1.7  1.2  1.9 -0.3 -0.2 -0.9  3.5 -1.  -0.2  0.1  0.5  1.1 -0.3 -0.5  0.7 -1.  -0.3  7.7 -0.1 -0.2  1.4  0.5  2.3 -0.2 -0.3  0.3  6.  -0.7 -0.6 -0.7 -1.6 -0.   1.6 -0.5  0.3 -0.1 -1.2 -0.5 -0.6 -1.1  2.4 -0.   0.5 -0.5  3.4 -0.1 -0.4 -0.2 -0.  -0.1 -1.2 -1.  -0.1  2.   0.9 -0.4 -1.3  0.8 -1.3 -0.1 -0.7 -0.1  2.1  3.3 -0.5 -0.2 -0.4 -0.7 -1.5 -1.9 12.   0.8 -1.4 -0.4  1.  -1.   3.1  2.8 -0.7 -0.3 -0.7  3.5 -0.3 -0.9  0.5 -1.3 -1.1 -0.6 -2.3 -0.5 -0.5 -0.6 -0.3  0.5  1.2 -0.6  1.1 -3.  -0.3 -0.4  3.5 -0.1 -0.1 -0.8 -0.7  3.4 -0.7  0.2  6.9  0.1 -0.4 -0.5 -1.2 -0.3 -0.2 -0.4  4.3  1.7 -1.8  0.4 -0.5  0.8 -0.2  3.1 -0.4  2.2  0.9 -1.1  2.8 -3.  -0.1 -3.7 -1.  -2.2  1.4 -0.3 13.7  4.3 -0.2 -0.3 -0.4  1.8  8.9 -0.9 -2.4 -0.7  3.5  0.1]
ty_50sample [[8 6 5 0 1 7 2 2 3 9]
 [0 7 5 1 4 9 2 8 6 3]
 [2 6 6 5 0 9 3 1 4 8]
 [2 7 0 3 9 5 5 6 8 8]
 [5 8 3 2 1 7 7 9 6 6]
 [5 2 0 0 8 8 9 9 6 3]
 [0 6 1 7 7 5 3 9 4 2]
 [2 2 5 1 6 7 8 3 4 0]
 [0 3 2 6 9 5 1 1 7 7]
 [9 0 3 2 8 7 1 6 5 4]]
tt_50sample [[8 5 6 0 1 7 2 9 4 3]
 [0 7 1 5 4 9 2 8 6 3]
 [2 6 5 7 0 9 3 1 4 8]
 [2 7 0 3 9 1 5 6 8 4]
 [5 8 2 3 1 7 0 4 9 6]
 [5 2 0 1 7 8 4 9 6 3]
 [0 6 1 8 7 5 3 9 4 2]
 [9 2 5 1 6 7 8 3 4 0]
 [0 3 2 6 9 5 1 8 7 4]
 [0 9 3 2 8 7 1 6 5 4]]
vm  [-0.8 -0.2  3.5  8.4 -1.6 -0.7 -0.1 -0.3 -0.4  1.4 -2.1 -0.1 -0.8 -0.3 -0.5  1.4 -1.3 -0.  -0.1 -1.8 -0.5  0.   4.5 -0.3 -0.7 -0.1 -0.2 -0.4  3.  -0.  -0.3  0.2 -0.2  2.7 -0.3 -0.6  0.7 -0.1  8.3 -0.3 -0.2  2.5 -0.5  0.8 -0.6 -0.5  7.3  3.  -0.5  7.5 -0.6  0.1  3.  -2.3 -0.8  2.3 -0.2 -0.3 -0.1  2.  -0.8 -0.2 -0.1 -0.1 -0.3 -0.4 -0.3 -0.7  1.3  0.6 -0.  -0.7  2.3  0.   3.8 -0.1 -0.1  0.3  3.4 -0.3  6.1 -0.1 -0.9 -0.1 -0.3  4.2  0.4 -0.7 -0.4 -0.1  0.6 -0.2 -0.6 -1.4  2.2 -0.2 -0.1 -0.1 -0.7 -0.3 -0.8  7.6 -0.2  0.7 -0.6 -0.1  2.6 -0.4 -1.3 -1.8 -0.2 -0.5 -0.3 -0.1 -0.2  3.8 -0.2 -0.8 -0.2 -0.  -0.4  6.3  0.3 -0.5  1.6 -0.6  0.8 10.3  1.6 -2.3  0.7 -1.  -0.4 -0.4 -1.8 -1.6  1.  -1.  -1.2 -0.3  1.7 -0.2  3.4  1.  -1.4  3.3  1.4 -0.8 -0.9  2.9 -0.7 -0.4  2.1  1.7  0.6  0.2 -0.9 -0.7  0.5 -0.3  1.2 -0.4  0.6 -0.6 -0.2 -0.4 -0.1  1.8 -0.2  4.2  1.8 -0.8 -0.6 -0.7 -0.1  3.9 -0.6  5.3 -1.8  1.2  0.7 -0.  -0.3 -1.3 -1.1 -0.3  2.3 -0.4 -0.4 -0.3 -0.3 -1.  -1.9 -1.1  4.6  0.   6.1  1.3 -0.4 -1.2 -1.3  0.6 -0.5 -0.4  1.4  5.6 -0.7  1.5  5.6 -0.7  0.3  5.4 -1.   5.1 -0.8 -0.5  0.4 -0.2  2.2  1.2 -1.7 -0.8 -0.6 -0.3  2.1  3.4 -1.4  1.9 -0.  -0.1 -0.6 -1.4 -0.7  3.5 -0.4 -0.5  2.7  5.4  2.6 13.3 -0.5  7.4 -0.3 -0.2 -0.7 -2.7  0.2  0.8 -0.5 -0.4 -1.4 -0.3  7.7 -0.1  2.3 10.9]
vy_50sample [[9 7 8 1 4 6 5 2 3 3]
 [7 8 2 5 0 6 1 3 4 9]
 [4 2 1 7 0 6 5 5 3 8]
 [3 9 8 2 1 4 6 0 5 7]
 [2 2 3 6 1 7 7 4 4 5]
 [3 7 8 5 6 9 4 0 2 1]
 [2 0 8 7 1 3 6 4 5 9]
 [5 0 3 7 2 9 4 8 6 1]
 [0 0 7 6 2 5 3 1 8 4]
 [0 9 4 3 6 5 2 1 7 8]]
vt_50sample [[9 7 8 1 4 6 5 0 2 3]
 [7 8 2 5 0 6 1 3 4 9]
 [4 2 1 7 6 0 5 9 8 3]
 [3 9 8 2 1 4 6 0 5 7]
 [0 9 3 2 6 1 7 4 8 5]
 [3 7 8 5 6 9 4 0 2 1]
 [2 0 8 7 1 3 6 4 5 9]
 [5 0 3 7 2 9 4 8 6 1]
 [0 9 7 6 2 5 3 1 8 4]
 [0 9 4 3 6 5 2 1 7 8]]
Epoch  5510: Training cost= 0.4449, Training acc= 0.7187, Validation cost= 0.4515, Validation acc= 0.7194
Epoch  5520: Training cost= 0.4806, Training acc= 0.7189, Validation cost= 0.4174, Validation acc= 0.7195
Epoch  5530: Training cost= 0.4073, Training acc= 0.7191, Validation cost= 0.5052, Validation acc= 0.7197
Epoch  5540: Training cost= 0.4208, Training acc= 0.7192, Validation cost= 0.4158, Validation acc= 0.7199
Epoch  5550: Training cost= 0.4455, Training acc= 0.7194, Validation cost= 0.4189, Validation acc= 0.7200
Epoch  5560: Training cost= 0.4165, Training acc= 0.7196, Validation cost= 0.4345, Validation acc= 0.7202
Epoch  5570: Training cost= 0.4130, Training acc= 0.7198, Validation cost= 0.4461, Validation acc= 0.7204
Epoch  5580: Training cost= 0.4251, Training acc= 0.7200, Validation cost= 0.4291, Validation acc= 0.7206
Epoch  5590: Training cost= 0.4225, Training acc= 0.7201, Validation cost= 0.4441, Validation acc= 0.7207
Epoch  5600: Training cost= 0.3943, Training acc= 0.7203, Validation cost= 0.4430, Validation acc= 0.7209
tm  [ 0.6 -0.5  6.6  4.1 -1.1 -0.8 -0.9 -0.8 -0.1 -0.1  1.7  0.  -0.3 -0.8  6.6  0.2 -1.2 -0.2  0.1  1.5 -0.5 -0.1 -0.6 -0.5 -0.5 -0.1 -0.4 -0.1 -0.3 -0.8 -0.3  0.7  2.4  6.1  0.7 -0.2 -0.  -0.4 -2.3 -0.7 -0.4 -1.9 -1.2 -1.6 -0.7  0.2 -1.1  0.   2.6 -0.8 -1.3 -0.8 -0.5  3.  -0.4 -0.8 -0.1  1.3  0.8  3.3  0.6  1.6 -0.1  3.  -0.1 -0.3 -0.4 -0.1  1.1  1.9 -0.   1.3 -0.3 -0.4 -3.1 -0.2 -1.  -0.8  1.1 -0.4 -0.2 -0.4  0.5 -0.1 -0.7 -2.1 -0.5 -0.3  0.   0.5 -0.5 -0.5  0.8 -0.3 -0.7 -0.1 -0.2 -1.5 -0.5 -0.   0.   1.4  0.1 -0.1  0.2  0.8 -1.6 -0.3  0.8 -0.4  0.5  0.5 -0.2 -0.6  2.5 -0.4 -0.   2.9 -0.3  2.  -0.1 -0.2  0.2  0.3 -0.7  7.1 -0.2  0.1 -0.3  4.6  5.7 -1.3 -0.1 -0.4  4.9 11.8 -0.4  1.9  0.6 -0.6 -0.  -0.4 -0.1 -0.2 -0.9 -0.2 -0.7 -0.6 -1.6 -0.6 -0.  -0.3  1.9 -0.1 -0.6 -0.2 -0.5 -0.  -1.5 -0.8 -0.3  3.3  2.1 -0.5  1.6 -0.5  1.6  4.3 -0.4  2.  -1.  -0.7 -0.3 -0.2 -0.4  7.3 -1.6 -0.4 10.   0.8  2.4 -0.3 -0.4 -0.8  0.1 -0.6  1.4 -1.  -0.4  3.7 -0.2  0.5 -0.4 -0.9  1.1 -0.2 -1.  -0.8 -0.4 -0.2 -0.2 -0.  -0.1 -0.4 -0.5 -1.8 -0.5 -0.2  6.2 -0.4 -0.5 -0.1 -1.5 -0.1 -1.  -0.3  7.9 -0.4  1.3 -0.1 -0.8 -0.4 -0.1 -0.3  1.9 -0.3 -0.7  1.8  0.6  5.   2.   1.2 -0.7  4.1 -0.1 -1.8  0.8 -1.1  2.5  5.7 -1.1  4.3  1.  -0.5  2.4  0.5 -0.5  0.6 -0.6  0.2 -0.2 -1.2 -1.9 -0.2  1.3 -0.9]
ty_50sample [[6 7 3 0 2 8 9 1 4 5]
 [6 5 5 9 7 8 0 2 3 4]
 [4 8 6 0 7 5 3 2 9 1]
 [0 5 4 2 2 1 9 9 8 7]
 [0 6 5 1 9 7 4 8 3 2]
 [4 9 5 6 3 0 1 2 7 8]
 [4 2 5 5 7 8 0 9 6 3]
 [6 9 5 3 7 0 1 8 2 4]
 [4 9 2 2 6 8 7 5 0 3]
 [0 6 5 1 9 9 8 3 3 2]]
tt_50sample [[6 7 3 0 2 8 9 1 4 5]
 [6 1 5 9 7 8 0 2 3 4]
 [4 8 6 0 7 5 3 2 9 1]
 [0 5 4 2 6 1 3 9 8 7]
 [0 6 5 1 9 7 4 8 3 2]
 [4 9 5 6 3 0 1 2 7 8]
 [4 2 1 5 7 8 0 9 6 3]
 [6 9 5 3 7 0 1 8 2 4]
 [4 9 1 2 6 8 7 0 5 3]
 [0 6 5 1 9 7 8 4 3 2]]
vm  [ 0.5  0.5  2.8 -0.3 -1.4 -0.5 -0.5 -0.6 -0.7 -0.7 -0.8 -0.2 -0.1 -0.3  6.7  3.3 -0.3 -0.1  1.2  0.4 -0.3 -0.3  1.1 -0.6 -0.6 -0.5 -0.3 -0.5  1.3 -0.4 -0.2 -0.  -0.2  0.8  0.6 -0.1  0.5  4.4  4.2 -0.9  0.2 -2.1 -1.1  5.1 -1.2 -0.  -0.7  0.4  0.8  1.3 -0.7 -1.  -0.6  3.7 -1.  -0.7 -0.5 -0.5  2.7  3.5  0.6  1.1 -0.2  2.8 -0.3 -0.8 -0.4 -0.6  0.1  2.9  1.6 -0.2  0.8  0.  -2.2  0.6 -0.1 -0.7  1.8 -0.  -2.1 -0.5  0.2 -0.2 -0.8 -2.2  0.3 -0.1  2.5 -0.5 -0.3 -0.6 -0.   0.2 -0.5 -0.4 -1.  -1.3 -0.6 -0.3  2.1  0.9  0.8  0.7  0.9 -0.1 -1.4 -0.3 -0.5 -0.5  0.3 -0.8 -0.3 -0.7 -0.1  2.1 -0.2  1.9 -0.  -0.1 -0.2  0.8 -0.5 -0.9 -0.5  6.5 -0.2 -0.4  1.9  5.7  0.3 -0.8  2.1 -0.1 -3.4 -4.1  0.4  0.5  0.2 -0.2 -0.4 -0.4 -0.2 -0.4 -0.7  1.1 -0.3 -0.4 -1.8 -0.4  3.  -0.4  4.7 -0.4 -0.7 -0.4 -0.5 -0.2  3.2 -1.1 -0.3 -1.5  0.4 -0.4 -0.2 -0.   3.2  4.1  1.5 -0.2 -0.2 -0.5 -0.5 -0.2 -0.8  7.2  1.  -0.6 -0.8 -0.3  2.9 -0.1 -0.5 -0.6  1.1 -0.2  1.2 -0.8 -1.   1.8 -0.2  0.1 -0.3 -1.3  1.6 -0.4 -0.7 -0.3 -0.4 -0.3 -0.1 -0.1 -0.4 -0.5 -0.9 -1.4 -1.4  0.9  9.6 -0.6 -0.5  1.3 -1.3 -0.   1.2 -0.3 -1.  -0.4  1.9 -0.3 -1.1 -0.1 -0.2 -0.7 -1.1  2.9 -0.4  2.  -0.3  5.1 -1.1  0.9 -0.8  6.4 -0.1 -0.3  1.4 -0.8  3.3  7.6 -0.5  4.8 -0.2 -0.2  6.9 -0.3 -0.8 -0.1 -0.4 -0.4  3.1 -0.3  3.5 -0.3  1.7 -0.8]
vy_50sample [[8 3 7 4 2 9 1 0 6 5]
 [6 9 2 5 5 3 4 7 0 8]
 [3 8 8 0 2 4 9 5 6 1]
 [1 7 9 3 4 5 8 2 6 0]
 [5 6 2 2 1 9 4 3 0 7]
 [4 3 7 5 8 2 2 1 6 0]
 [9 1 6 6 5 4 4 2 3 8]
 [7 3 8 9 1 1 4 5 6 0]
 [8 2 2 5 7 7 6 4 9 9]
 [7 7 1 1 8 5 0 2 6 4]]
vt_50sample [[8 3 7 2 4 9 1 0 6 5]
 [6 9 2 1 5 3 4 7 0 8]
 [3 7 8 0 2 4 9 5 6 1]
 [7 1 9 3 4 5 8 2 6 0]
 [5 6 2 8 1 9 4 3 0 7]
 [3 4 7 5 8 9 2 1 6 0]
 [9 1 7 6 5 4 2 0 3 8]
 [7 3 8 2 9 1 4 5 6 0]
 [8 1 2 5 7 6 0 3 4 9]
 [7 9 3 1 8 5 0 2 6 4]]
Epoch  5610: Training cost= 0.4263, Training acc= 0.7205, Validation cost= 0.4701, Validation acc= 0.7210
Epoch  5620: Training cost= 0.4603, Training acc= 0.7206, Validation cost= 0.5069, Validation acc= 0.7212
Epoch  5630: Training cost= 0.4188, Training acc= 0.7208, Validation cost= 0.4150, Validation acc= 0.7214
Epoch  5640: Training cost= 0.4362, Training acc= 0.7210, Validation cost= 0.4779, Validation acc= 0.7216
Epoch  5650: Training cost= 0.4266, Training acc= 0.7212, Validation cost= 0.4280, Validation acc= 0.7217
Epoch  5660: Training cost= 0.4379, Training acc= 0.7213, Validation cost= 0.3786, Validation acc= 0.7219
Epoch  5670: Training cost= 0.4335, Training acc= 0.7215, Validation cost= 0.4132, Validation acc= 0.7221
Epoch  5680: Training cost= 0.4491, Training acc= 0.7217, Validation cost= 0.4914, Validation acc= 0.7223
Epoch  5690: Training cost= 0.4737, Training acc= 0.7218, Validation cost= 0.4405, Validation acc= 0.7224
Epoch  5700: Training cost= 0.5053, Training acc= 0.7220, Validation cost= 0.4926, Validation acc= 0.7226
tm  [-0.3 -0.1  4.3  9.6 -1.7 -0.5 -0.1 -0.5 -0.1 -0.5  2.2 -0.2  0.1 -0.3 -0.3  4.4 -1.  -0.3  2.  -1.5 -0.4  0.   0.1 -0.7 -0.6  1.3 -0.4 -0.5  2.6 -0.2  0.2 -0.  -0.9  5.5 -0.3  0.4 -0.   4.5 14.  -1.  -0.1 -1.8 -1.4  4.6 -1.1 -0.2  7.9  0.6  0.5 -0.1 -0.9 -0.1  3.  -0.9 -0.9  2.  -0.4 -0.3  1.7  2.1 -1.4  1.2 -0.2  4.  -0.4 -0.3 -0.5 -0.6  0.1  2.2  0.1 -0.6  0.7  0.7  7.3 -0.  -0.4 -0.9  1.7  0.8 10.  -0.5 -1.1 -0.2 -0.5 -1.7  0.1 -0.5  0.9 -0.5 -0.2 -0.4  0.8 -0.9  3.5 -0.1 -1.  -0.  -0.7  0.8  1.7  3.1 -0.3  1.   0.8 -0.1  4.9  0.2  0.9 -2.6 -0.3 -0.6 -0.2 -0.2 -0.3  3.3 -0.1  0.4 -0.6 -0.2 -0.   8.  -0.5 -0.3 -0.3 -0.5  0.   5.3  2.9 -0.6 -0.5 -1.3 -0.1 -0.2 -4.5 -3.1  1.5 -0.1 -0.2 -0.6 -0.4 -0.  -0.3 -0.4 -0.8  1.4 -0.1 -0.4 -1.8 -0.2 -0.6 -0.3  2.4 -0.4 -0.2 -0.3 -0.5 -0.5  5.4 -0.5 -0.  -1.8 -0.3 -0.5  0.6 -0.7  3.8  3.6  0.1  3.6 -0.2 -1.1 -0.  -0.4 -0.4  7.   2.2  4.2 -3.6 -0.4  3.  -0.  -1.1 -0.8 -0.5 -0.8  4.  -0.5 -0.6  1.7 -0.1 -0.  -1.9 -1.   6.5 -0.5  6.2  0.  -0.1 -0.4 -0.8 -0.3 -0.9 -0.6 -0.5  4.8 -0.8  1.8  6.6 -0.8 -0.2  4.  -1.5  1.4 -0.6 -0.7 -1.  -0.3  2.1 -0.  -1.  -0.4 -0.5 -0.2 -1.1  1.8 -0.2  2.4  0.2  4.1 -1.3 -1.2 -0.7  4.3 -0.2 -0.8  0.7  8.2  3.1 17.5 -0.2 10.4 -0.2 -0.4 -1.5 -2.3 -0.6  0.7 -0.6 -1.  -2.  -0.4 12.5  1.   1.2  4.4]
ty_50sample [[9 7 7 3 8 1 0 0 5 6]
 [9 6 6 3 3 5 0 4 1 2]
 [7 4 6 5 3 1 8 0 2 9]
 [8 2 3 5 0 6 4 1 9 7]
 [7 1 5 8 4 9 3 0 6 2]
 [2 5 3 7 0 4 6 1 9 8]
 [0 2 6 1 4 7 9 3 8 5]
 [0 8 8 7 4 2 3 1 6 6]
 [6 9 7 5 1 1 2 0 8 3]
 [4 7 0 0 9 9 1 8 3 5]]
tt_50sample [[9 7 2 3 8 4 1 0 5 6]
 [9 6 8 7 3 5 0 4 1 2]
 [7 4 6 5 3 8 1 0 2 9]
 [8 2 3 5 0 6 4 1 9 7]
 [7 1 5 8 4 9 3 0 6 2]
 [2 5 3 7 4 0 6 1 9 8]
 [0 2 6 1 4 7 9 3 8 5]
 [9 8 0 7 4 2 3 1 6 5]
 [6 9 7 5 4 1 2 0 8 3]
 [4 7 2 0 9 6 1 8 3 5]]
vm  [-0.3 -0.7 -1.   2.2 -0.8 -0.1 -0.2 -0.1  2.7  1.9  3.8 -0.3 -0.4 -0.7 -1.6 -0.7 -0.9 -0.3 -0.7 -0.6 -0.9 -0.2  2.1 -0.6 -0.3  4.1 -0.1 -0.4 -0.8 -1.7  2.8  0.2 -0.8 -0.8  4.6 -0.6 -0.2  4.   9.6 -1.  -0.5  0.4 -1.5  5.5 -1.   0.4  3.5 -0.9  0.4  3.1 -0.6 -0.6  1.2  0.2  1.7  5.  -0.6 -0.4  6.9 -0.2 -0.  -0.   2.7  8.2  0.4 -0.4  0.3  3.2  1.3 -0.2 -0.6  2.9 -0.3  0.4 -1.8 -0.1 -0.4 -0.4  3.9 -0.1  5.6 -0.   0.2 -0.3 -0.4 -0.3  0.8 -0.3 -0.8 -0.4 -0.1 -2.  -1.1 -1.7  1.3 -0.4 -0.5 -1.  -0.3  0.3 -1.2  0.4  0.8 -0.2 -0.2 -0.  -0.6  2.8  1.9 -1.  -0.6  1.5 -0.1 -0.6  8.  -1.2 -0.3  2.5 -0.8  3.  -0.1  3.  -0.6  0.3 -0.5 -1.4 -1.1  2.2  4.6 -0.7 -0.5 -1.1 -1.5  0.3 -0.8 -2.4 -0.2 -0.7  0.  -0.4 -0.4 -0.2 -0.7 -0.7 -0.1 -0.1 -0.4  0.   0.3 -1.1 -0.  -0.2  0.9  0.5 -0.4 -0.1 -0.1 -0.2  4.3  1.2  4.1 -2.1 -0.3 -0.9 -0.6 -0.9 -1.   2.1 -0.4  1.5  2.5 -1.   1.4 -0.5 -0.3  2.3  1.4  3.8 -2.3 -0.2  0.1 -0.6 -1.  -0.7  3.  -1.   1.5 -0.2  2.1  7.  -0.4 -0.7 -1.4 -0.8  2.3 -0.9 -0.  -1.1 -0.   2.9 -0.9  2.1 -1.  -1.  -0.6  1.6 -0.4 -0.1  5.  -0.4  0.2 -0.4 -1.   3.1 -0.4 -0.8 -1.3 -0.6 -1.2 -0.4  0.  -1.1 -0.4 -1.2 -0.2 -0.7 -0.1  3.6  0.8  3.  -1.3 -1.  -0.5  3.5  4.   5.5  6.1  0.1  4.6 11.2 -0.7  6.5 -0.3 -0.3 -0.6 -1.6 -0.2  0.6 -0.9 -0.5 -1.2  0.3  9.1  1.3 -0.5  6.2]
vy_50sample [[0 9 4 2 8 8 3 7 5 6]
 [1 5 0 4 6 2 8 3 9 9]
 [2 3 3 0 8 9 1 7 5 6]
 [9 1 8 8 6 7 5 2 3 4]
 [8 2 6 4 9 7 5 0 1 3]
 [4 9 0 1 3 5 2 7 7 6]
 [5 4 2 3 1 8 6 6 9 7]
 [1 3 2 2 8 6 4 7 0 5]
 [5 1 8 7 2 6 4 3 9 0]
 [5 6 9 8 3 7 0 1 4 2]]
vt_50sample [[0 9 2 4 1 8 3 7 5 6]
 [1 5 0 4 2 6 8 3 7 9]
 [2 4 3 8 0 9 1 7 5 6]
 [9 1 8 0 6 7 5 2 3 4]
 [8 2 6 4 9 7 5 0 1 3]
 [4 9 0 1 3 5 2 7 8 6]
 [5 4 2 3 1 8 6 0 9 7]
 [1 3 2 9 8 6 4 7 0 5]
 [5 8 1 2 7 6 4 3 9 0]
 [5 6 8 9 3 7 0 1 4 2]]
Epoch  5710: Training cost= 0.4521, Training acc= 0.7221, Validation cost= 0.4201, Validation acc= 0.7228
Epoch  5720: Training cost= 0.5216, Training acc= 0.7223, Validation cost= 0.4275, Validation acc= 0.7229
Epoch  5730: Training cost= 0.3712, Training acc= 0.7225, Validation cost= 0.4369, Validation acc= 0.7231
Epoch  5740: Training cost= 0.4345, Training acc= 0.7226, Validation cost= 0.4861, Validation acc= 0.7232
Epoch  5750: Training cost= 0.4579, Training acc= 0.7228, Validation cost= 0.4438, Validation acc= 0.7234
Epoch  5760: Training cost= 0.4485, Training acc= 0.7229, Validation cost= 0.5332, Validation acc= 0.7235
Epoch  5770: Training cost= 0.4558, Training acc= 0.7231, Validation cost= 0.4291, Validation acc= 0.7237
Epoch  5780: Training cost= 0.4680, Training acc= 0.7232, Validation cost= 0.4495, Validation acc= 0.7238
Epoch  5790: Training cost= 0.4041, Training acc= 0.7234, Validation cost= 0.4148, Validation acc= 0.7240
Epoch  5800: Training cost= 0.4497, Training acc= 0.7236, Validation cost= 0.4491, Validation acc= 0.7241
tm  [-1.9  2.2 -1.   8.8 -0.4  0.1  0.6 -0.2 -0.5 -0.8 -2.4  1.  -0.6  0.6 -3.   2.4 -0.1 -0.2 -0.8 -1.3 -0.2 -0.6  3.2 -0.  -1.1  0.9 -0.4 -0.2  2.  -0.3 -0.8 -0.8 -0.4 -4.3 -1.6 -0.1  0.8  3.   7.1 -0.8 -0.1 -0.3  0.9 -0.1 -0.4 -0.5  5.3  1.5 -1.   3.5 -0.3 -0.2  2.6 -1.8 -1.5  7.1  0.3  2.4 -0.5  3.9  1.8 -0.6 -0.2 -0.6 -0.8 -0.1 -0.6 -0.4 -0.4  2.1 -0.4 -0.6  2.1 -0.1  7.1 -0.5  3.2 -1.   0.6 -0.1  2.7 -0.  -1.5 -0.4  1.6  1.5 -0.4 -0.8  3.2  0.2 -0.1 -0.   0.6  0.9  1.4 -0.4  1.7  0.5 -0.2 -0.2  3.1 -2.   1.2 -0.5 -0.7 -0.1  1.8 -1.3 -1.2 -2.  -0.3 -0.3 -0.2  0.5 -0.4  5.9 -0.6 -1.  -0.2  0.1 -0.3  6.7 -0.1 -0.3 -0.  -3.4  3.7  8.9  1.2 -0.2 -0.5 -0.5 -0.1 -0.4  7.9 -1.9  0.2 -0.6  0.3 -0.2  1.9 -0.5 -0.2 -0.7 -0.6 -0.3  0.3  1.4  5.6  0.6 -1.1 -0.3  0.5 -0.1 -0.5  0.  -0.2 -0.7  1.3 -0.3 -0.6  0.  -1.  -0.3 -2.2 -0.2  3.   2.9  0.1  3.9 -0.2  0.4 -0.6 -0.6 -0.1 -1.6 -0.7  2.4 -1.1 -0.5 -0.7  1.5 -0.1 -1.3 -0.7  0.8 -0.   1.7 -0.7  4.3 -0.6 -0.4 -1.3 -1.2  1.3  0.8  4.7  0.9 -0.5 -1.  -0.2  1.1 -0.5 -1.2  1.7  3.8 -0.3  2.   3.4 -0.6 -0.4  4.2 -0.7  5.  -0.9 -0.4  1.4 -0.1 -0.6 -0.  -0.4 -0.  -0.6 -0.6 -0.1  4.1 -0.9  1.9 -0.5 -0.1 -1.  -0.9 -0.6  2.4  0.5  3.8 -0.4  4.1 -0.4  6.3 -0.3  3.5 -0.5 -0.6  0.2 -2.   0.4  0.1 -0.2 -1.  -0.7 -1.1  6.5  0.2  4.8  3.7]
ty_50sample [[9 1 8 3 5 6 4 2 0 7]
 [9 6 9 1 2 5 5 8 0 7]
 [7 2 3 3 0 4 1 5 8 6]
 [1 1 2 0 0 6 3 8 4 5]
 [1 1 3 4 6 9 5 8 2 0]
 [2 7 6 1 4 5 8 0 3 9]
 [5 2 9 3 7 1 8 6 4 0]
 [2 3 0 6 7 9 1 1 8 5]
 [9 7 5 4 2 1 6 3 8 0]
 [0 5 6 2 4 7 9 8 3 1]]
tt_50sample [[9 1 8 3 5 6 4 2 0 7]
 [4 6 9 1 2 5 3 8 7 0]
 [7 2 9 3 0 4 1 5 8 6]
 [1 2 7 9 0 6 3 8 4 5]
 [7 1 3 4 6 9 5 8 2 0]
 [2 7 6 1 4 5 8 0 3 9]
 [5 2 9 3 7 1 8 6 4 0]
 [2 3 0 6 7 9 1 4 8 5]
 [9 7 5 4 2 1 6 3 8 0]
 [0 5 6 2 4 7 9 8 3 1]]
vm  [-0.6 -0.5  2.9 -0.6 -2.1 -0.2 -0.3 -0.7 -1.   1.7 -0.1 -0.1 -0.4 -0.4  6.4 -0.7 -0.5  0.4  0.7 -0.8 -0.2 -0.4  3.  -0.  -0.4  2.5 -0.3 -0.3 -0.6 -0.4  3.3  2.6 -0.4  7.7  1.8  0.5  2.4 -0.5  0.5 -0.6 -0.6  2.3 -0.4  2.1 -1.4  0.3 -0.3  0.9  0.3  4.9 -1.3 -0.9 -0.4 -0.3 -0.3 -0.7 -0.9 -0.8  0.1 -0.8  3.   1.3 -0.4  1.9  0.4 -0.2  0.3 -0.3  1.2  1.5 -0.1  2.3 -0.1 -0.2 -1.4 -0.4  1.6 -0.3  5.7 -0.   3.4 -0.2 -0.1 -0.1 -0.3  2.1  1.5 -0.4 -0.6 -0.2 -0.3 -0.5 -0.8 -0.9 -0.2  0.9 -0.2 -0.8 -0.4 -0.3 -0.4  8.6  1.2  0.3  0.8  0.6 -1.   4.4  0.3 -0.9 -0.5 -0.2 -0.1 -0.5  3.6 -0.6 -0.6  0.9 -0.8 -0.6 -0.1  2.6 -0.   1.7 -0.4  6.4 -0.2  3.9 -0.2 -0.8  0.4 -0.9 -0.6 -0.3 -2.   4.5 -0.1 -0.6 -0.6 -0.8  1.  -0.2  0.5  1.  -1.   0.3 -0.  -0.5 -1.6  0.7  2.  -0.2 -0.4  0.3 -0.3 -0.2 -0.1 -0.5  0.7 -0.4  2.3 -0.1  0.2 -0.8  0.8 -0.4 -0.9  2.3 -0.  -0.4  1.5 -0.5 -0.3 -0.  -0.4  6.4 -0.5  0.4  1.7  0.5  0.5 -0.1 -0.2 -1.2 -0.3 -0.9  0.3 -0.9  0.8 -0.2 -0.4 -0.9 -0.5 -0.8 -0.1  0.5 -0.4 -0.1 -0.4 -0.3 -0.5 -0.  -0.5 -0.4  1.9 -1.2 -0.2  0.9  3.7 -0.4  0.3 -0.3 -1.   4.5  0.5 -0.6 -0.4 -0.4  1.5  0.1 -0.7 -0.2 -0.5 -0.6  3.2 -0.4 -0.4  0.9 -0.1 -0.3 -0.5 -0.3 -0.3  2.1  3.1 -0.2  4.2 -0.4  3.7  6.7 -0.8  4.1 -0.4 -0.3 -0.1 -0.4 -0.4  1.1 -0.6 -0.1 -0.8  0.1  0.4 -0.2  0.3  5.8]
vy_50sample [[7 0 4 1 6 9 8 2 5 3]
 [0 4 8 9 9 2 6 6 3 5]
 [6 1 1 4 7 3 8 2 5 5]
 [6 6 1 1 5 8 3 4 7 2]
 [9 4 5 5 7 3 0 2 6 8]
 [7 0 5 2 4 1 1 6 8 9]
 [5 5 0 1 7 9 8 8 6 4]
 [0 7 2 9 6 6 1 5 8 3]
 [2 9 7 1 0 6 5 8 3 4]
 [6 6 9 4 4 5 0 3 1 8]]
vt_50sample [[7 0 4 1 6 9 8 2 5 3]
 [0 4 8 9 7 2 1 6 3 5]
 [6 0 1 4 7 3 8 2 5 9]
 [9 6 0 1 5 8 3 4 7 2]
 [9 4 1 5 7 3 0 2 6 8]
 [7 0 5 2 4 1 3 6 8 9]
 [5 3 0 1 7 9 2 8 6 4]
 [7 0 2 9 4 6 1 5 8 3]
 [2 9 7 1 0 6 5 8 4 3]
 [2 6 9 7 4 5 1 0 3 8]]
Epoch  5810: Training cost= 0.4344, Training acc= 0.7237, Validation cost= 0.4342, Validation acc= 0.7243
Epoch  5820: Training cost= 0.4678, Training acc= 0.7239, Validation cost= 0.4103, Validation acc= 0.7245
Epoch  5830: Training cost= 0.4632, Training acc= 0.7240, Validation cost= 0.4265, Validation acc= 0.7246
Epoch  5840: Training cost= 0.4712, Training acc= 0.7242, Validation cost= 0.4779, Validation acc= 0.7248
Epoch  5850: Training cost= 0.4653, Training acc= 0.7243, Validation cost= 0.4480, Validation acc= 0.7249
Epoch  5860: Training cost= 0.4936, Training acc= 0.7245, Validation cost= 0.5154, Validation acc= 0.7250
Epoch  5870: Training cost= 0.4608, Training acc= 0.7246, Validation cost= 0.4618, Validation acc= 0.7251
Epoch  5880: Training cost= 0.3811, Training acc= 0.7247, Validation cost= 0.4768, Validation acc= 0.7253
Epoch  5890: Training cost= 0.4515, Training acc= 0.7249, Validation cost= 0.4829, Validation acc= 0.7255
Epoch  5900: Training cost= 0.4381, Training acc= 0.7250, Validation cost= 0.4431, Validation acc= 0.7256
tm  [ 0.1  3.1  4.6  0.2 -1.6 -0.  -0.7 -0.7 -1.7 -0.3  0.9 -0.3 -0.3  0.1  6.8 -0.   2.5  0.9  1.4  2.9 -0.1 -0.7  4.2  3.1 -1.7  4.  -0.3  0.5 -1.4 -0.6 -1.2  0.7 -1.1 -0.5  1.4  1.4  3.8  2.9 -1.  -0.8 -0.4  3.   2.6 -0.3 -1.4 -0.1 -2.8 -0.9  0.4  7.3 -0.9 -1.1 -0.6  8.7  0.8 -1.  -0.6  3.2 -0.5  6.5  6.3 -0.3 -0.   3.3 -0.4  0.5  0.2 -1.   0.2 -0.1 -0.2  5.7  2.3 -0.1 -3.   0.1  1.7 -0.3  0.8  0.5 -2.8 -0.1  2.2 -0.2 -0.5  4.6 -0.2 -0.1  0.4  0.3 -0.  -0.6 -1.   3.4 -0.9  0.5  4.4 -1.3 -0.2 -0.2  0.4  5.2  2.  -0.7  3.   0.  -2.5 -1.3  0.6  2.5 -0.7  1.  -0.   0.8  2.3 -1.2 -0.4 -0.4 -0.   0.1 -0.  -0.9 -0.3 -0.  -0.6  8.2 -0.6 -2.  -0.3  2.3  0.2  0.3 -1.1  1.1 -0.3 -1.6 -0.2 -0.7  0.7  1.5 -0.2 -1.4 -0.9  0.2  1.9 -0.6 -0.2 -0.3 -0.2  0.  -0.1 -0.4  3.5 -0.1 -0.3 -0.3  0.2  0.7  2.4 -0.8  2.6  0.3 -0.3 -0.2 -1.1 -0.8 -0.8 -0.6  0.9 -0.   1.5  1.8 -0.2 -0.2 -0.8  2.3 -0.7 -0.8  6.1 -0.6 -0.4 -0.2  0.8 -1.4  2.9  0.  -0.7 -0.5  1.3  2.3 -0.4 -0.5  3.  -1.  -1.1  0.5 -1.3  0.1 -0.3  2.1 -0.2 -0.4 -0.7 -0.8  0.7 -2.3 -0.5  2.   4.6 -0.4 -0.2 -1.1  0.2  1.2 -0.9 -0.7  2.2 -0.3  0.3 -0.4 -0.9  1.  -0.4 -0.9  1.7  0.2 -0.1  2.6 -0.  -0.6 -0.4  0.4 -0.3  2.7  5.9 -0.7  2.6 -1.7  0.6 -1.6 -1.2 -0.8 -0.2 -0.5  9.4  3.1 -0.4  2.7  0.5 -0.4  5.6  0.3 -0.5  2.  -0.2 -0.2]
ty_50sample [[0 8 2 7 5 1 6 3 4 9]
 [4 6 8 3 8 1 7 2 0 9]
 [2 7 4 9 1 5 5 6 3 0]
 [3 0 8 1 6 5 2 9 4 7]
 [8 3 3 6 0 7 1 9 5 4]
 [0 3 8 4 4 9 5 7 6 1]
 [3 4 7 0 0 2 1 8 6 6]
 [4 5 8 1 0 9 2 3 7 6]
 [7 1 8 5 4 3 6 2 9 0]
 [2 3 7 0 0 5 1 6 9 4]]
tt_50sample [[0 8 2 7 1 5 6 3 4 9]
 [4 6 5 8 3 1 7 2 0 9]
 [2 7 4 9 1 8 5 6 3 0]
 [3 0 8 1 6 5 2 4 9 7]
 [8 3 2 0 6 7 1 9 5 4]
 [0 3 4 8 2 9 5 7 6 1]
 [3 4 7 9 0 2 1 8 6 5]
 [4 5 8 1 0 9 2 3 7 6]
 [7 1 8 5 4 3 6 2 9 0]
 [2 3 7 0 8 5 6 1 9 4]]
vm  [-0.3 -0.7  2.4 -0.6 -1.9 -0.3 -0.5 -0.6 -0.7 -1.   7.3 -0.1  2.1 -0.2  4.5  2.4  1.1  0.1  1.2 -1.1 -0.  -0.6 -0.9 -0.1 -0.7  0.9 -0.7 -0.5 -0.6  0.5  6.2  0.5 -0.3 10.1  1.2  3.7  2.   2.5  5.5 -0.8 -0.5 -1.2 -1.   5.4 -1.4 -0.4  1.7 -0.1  1.3 -1.3 -1.6 -0.9 -0.3  3.1 -0.4 -0.4 -0.8 -0.9 -0.  -1.8 -0.1  2.1 -1.   3.3 -0.  -0.5 -0.2  0.3 -0.   0.8 -0.2  0.  -0.6 -0.2 -0.1  0.2  1.2 -0.5  3.8 -0.  10.6 -0.3 -0.9 -0.1 -0.6 -1.1  1.4 -0.4  0.8 -0.7 -0.5 -0.2 -0.  -0.2  0.2 -0.1 -0.8 -0.4 -0.3  0.   3.8  5.4 -0.2  0.1  1.5 -0.  -0.7  6.8  3.6 -1.5 -0.7 -0.5 -0.2 -0.4  1.8  1.  -0.2  1.6 -0.6 -1.  -0.   6.2 -0.2  1.7 -0.6  5.7 -0.1 -0.1 -0.3  1.2 -0.1 -1.1  0.1 -0.1 -3.7  4.1 -0.1  0.  -0.  -1.2 -0.6  0.2 -0.5 -0.1 -0.3  0.1 -0.3 -0.2 -1.8 -0.1  2.1 -0.2 -0.5 -0.6 -0.3 -0.2  0.3 -0.9  2.5 -0.8  1.4 -0.7 -0.4 -0.5  3.1 -0.2 -0.1  2.9  0.8 -0.5 -0.8 -0.5 -0.2  0.7 -0.9  7.4  0.1  0.2 -1.1 -0.4  1.8  0.8 -0.6 -1.1 -0.5 -1.   2.3 -1.1 -0.4 -0.2 -0.2 -0.4 -0.6 -0.7  2.5  0.9 -0.   0.  -0.6  0.2 -0.4 -0.6 -0.6 -0.4 -0.2 -0.8 -0.3  1.5  1.5 -0.4 -0.3 -0.2 -0.9  1.8  2.3 -0.5 -1.1 -0.2  2.2 -0.4 -0.1  0.5 -0.3 -0.6 -0.5 -0.4  1.4  0.4 -0.3  1.6 -1.2 -0.1 -0.2  1.2  2.1 -0.1  1.7  0.   3.2 10.4 -0.8  6.  -0.7 -0.4 -1.8 -0.7 -0.4 -0.2 -0.6 -0.4 -1.9  1.7  4.6 -0.1 -0.   1.1]
vy_50sample [[7 4 2 0 3 9 1 6 8 5]
 [0 9 3 8 1 6 6 4 4 7]
 [8 1 6 6 5 2 7 9 0 3]
 [4 0 2 1 1 9 9 3 5 6]
 [0 9 3 8 5 6 4 2 7 7]
 [8 4 5 9 1 2 2 0 3 6]
 [4 8 1 3 2 6 6 9 0 0]
 [2 0 8 3 6 1 5 9 4 7]
 [2 8 6 9 0 7 4 1 3 5]
 [6 1 9 0 2 5 7 3 4 4]]
vt_50sample [[7 4 2 0 3 9 1 6 8 5]
 [0 9 3 8 1 6 5 2 4 7]
 [1 8 6 4 5 2 7 9 0 3]
 [4 0 2 1 7 8 9 3 5 6]
 [0 9 3 8 5 6 4 2 1 7]
 [4 8 5 9 1 2 7 0 3 6]
 [4 8 1 3 2 6 7 9 5 0]
 [2 0 8 3 1 6 5 4 9 7]
 [2 8 6 9 0 7 4 1 3 5]
 [6 1 9 0 2 5 7 3 4 8]]
Epoch  5910: Training cost= 0.4217, Training acc= 0.7252, Validation cost= 0.4546, Validation acc= 0.7258
Epoch  5920: Training cost= 0.4041, Training acc= 0.7254, Validation cost= 0.4403, Validation acc= 0.7260
Epoch  5930: Training cost= 0.3592, Training acc= 0.7256, Validation cost= 0.3741, Validation acc= 0.7262
Epoch  5940: Training cost= 0.4179, Training acc= 0.7257, Validation cost= 0.4351, Validation acc= 0.7263
Epoch  5950: Training cost= 0.5013, Training acc= 0.7259, Validation cost= 0.3482, Validation acc= 0.7265
Epoch  5960: Training cost= 0.4407, Training acc= 0.7261, Validation cost= 0.4505, Validation acc= 0.7267
Epoch  5970: Training cost= 0.4789, Training acc= 0.7262, Validation cost= 0.5007, Validation acc= 0.7268
Epoch  5980: Training cost= 0.4423, Training acc= 0.7263, Validation cost= 0.4357, Validation acc= 0.7269
Epoch  5990: Training cost= 0.5463, Training acc= 0.7265, Validation cost= 0.4145, Validation acc= 0.7270
Epoch  6000: Training cost= 0.4359, Training acc= 0.7266, Validation cost= 0.4081, Validation acc= 0.7272
tm  [-0.8 -1.1  6.3  6.1 -1.6 -0.4 -0.7 -0.2  3.4 -0.1 11.8 -0.4  1.7 -0.2  3.9  4.3 -0.8 -0.3  1.1 -0.1 -0.6 -0.5 -0.8 -1.  -0.6  1.7 -0.5 -0.3 -0.6 -1.7  1.5 -0.4 -0.8  8.3  2.6 -0.3 -0.5  6.1  5.5 -1.1 -0.5  0.  -1.4  1.2 -1.2 -0.2 -0.5 -1.3  0.8 -1.3 -1.1 -0.7 -0.2  6.8 -0.4 -0.2 -0.7  3.   6.3  0.   2.2 -0.2  0.3  8.   0.6 -0.3 -0.2  1.4 -0.2 -0.4 -0.3  0.5 -0.5  1.1 -2.1 -0.1 -0.6 -0.6  0.9  0.5  7.4 -0.5 -0.2 -0.1 -0.4  0.3 -0.6 -0.6 -0.4 -0.3 -0.3 -1.1 -0.8 -1.1 -0.1 -0.1  0.1 -1.4 -0.7 -0.4 -0.   3.   3.3 -0.5 -0.3 -0.1 -1.2  1.7  5.  -0.6  0.3  0.6 -0.1 -0.7  4.  -0.4  0.2  2.9 -0.6  1.3 -0.4  2.4 -0.4  2.6 -0.3  3.4 -0.8 -1.5  5.5  0.7 -0.7 -1.1 -1.2 -0.2 -3.4  1.5 -0.4 -0.2  0.  -0.4 -1.3  1.5 -1.  -0.8 -0.2 -0.3 -0.6 -0.4 -0.4 -1.2 -0.3 -0.5 -0.9 -0.8 -0.3 -0.3  0.1 -0.4  5.4  0.2  2.7 -1.4 -0.3 -0.3  2.1 -0.8  0.   1.7 -0.7  1.9 -0.4  0.2  0.2 -0.4 -0.7  3.   0.1  0.5 -1.  -0.4 -0.3 -0.7 -0.6 -1.   2.1 -1.1  0.3 -0.7 -0.5  7.4 -0.3 -0.2 -1.  -0.5 -0.2 -1.3 -0.2 -1.2 -0.3  1.2 -0.5 -0.2 -0.9 -0.9 -0.  -1.1  0.8  0.3 -1.2 -0.7 -0.4 -0.2 -0.7  2.8 -0.8 -0.6  0.3 -0.5  0.6 -0.3  0.3 -0.5 -0.3 -0.7 -0.5 -0.6  1.4  5.4 -0.   2.5 -0.8 -0.3 -0.3 -0.9  2.5 -1.6  1.5 -0.7  1.5  2.  -0.8  1.9 -0.3 -0.8 -1.  -0.7 -0.5  0.2 -1.  -0.6 -1.4 -0.3  5.3  1.6 -0.2  0.8]
ty_50sample [[2 7 7 1 3 5 5 4 4 6]
 [5 0 9 7 2 3 6 1 8 4]
 [2 8 1 4 0 9 3 9 5 6]
 [9 2 4 7 6 1 5 0 0 3]
 [8 7 1 9 4 2 6 0 5 3]
 [4 4 6 9 7 3 1 2 8 5]
 [8 5 9 7 0 2 3 6 1 4]
 [2 2 4 8 9 9 1 0 7 5]
 [9 2 3 1 6 4 5 7 8 0]
 [5 2 6 8 0 4 4 1 9 3]]
tt_50sample [[2 7 0 1 3 9 5 4 6 8]
 [5 0 9 7 2 3 6 1 8 4]
 [2 8 1 4 0 7 9 3 5 6]
 [9 2 4 7 6 1 5 8 0 3]
 [8 7 1 9 4 2 6 0 5 3]
 [4 6 0 9 7 3 1 2 8 5]
 [8 5 9 7 0 2 3 6 1 4]
 [2 6 4 8 9 1 3 0 7 5]
 [9 2 3 1 6 4 5 7 8 0]
 [5 2 6 8 0 4 7 9 1 3]]
vm  [-0.9  2.1  5.6  6.6 -1.5 -0.  -0.1 -0.3 -1.5 -0.7 -1.3  1.1 -0.2  0.6  3.3  0.5 -0.4  0.5  2.4 -1.  -0.2 -0.8  2.4 -0.2 -1.1  1.1 -0.4 -0.2 -0.4  0.9 -0.8  1.  -0.4  2.8 -0.9  1.8  2.8  2.5  6.7 -0.3 -0.3 -1.7 -0.4  1.8 -1.3 -0.6  2.3  1.  -0.6  3.1 -0.7 -0.4  0.7 -0.6 -0.8  0.1 -0.4 -0.5 -0.7  4.2  2.5  1.9 -0.4 -0.3 -0.6 -0.4 -0.3 -1.2 -0.3  3.8 -0.1  0.4  2.3 -0.1  3.7  0.2  3.8 -0.8  2.6  0.4  1.  -0.3 -0.9 -0.1  0.4 -1.4 -0.1 -0.6  2.  -0.1  0.5  0.1  0.7  2.   0.6 -0.1 -0.1 -0.2 -0.7 -0.2  3.6  4.3  1.5 -0.2  1.3 -0.1  0.7 -0.7 -0.8 -1.7 -0.2 -0.8 -0.3  0.9 -0.1  0.9 -0.1 -0.6 -0.4 -0.5  0.   5.1 -0.2  0.  -0.2  2.2  2.7  4.9 -0.6  0.8 -1.  -0.5 -0.2  0.2 -3.1 -2.9  0.3 -0.   1.  -0.2  0.8 -0.6 -0.4 -0.2 -0.5 -0.5  0.1 -0.2 -1.8 -0.1 -0.8 -0.4  0.9 -0.1 -0.4 -0.5  0.1 -0.   3.7 -0.8 -0.6 -0.5 -0.3 -0.2 -0.6 -0.1  2.   2.9  0.5  2.2 -0.3 -0.7 -0.3  0.5 -0.5  7.   0.3  0.9 -1.4 -0.3  3.4  0.1  1.1 -1.3 -0.4 -0.2 -0.  -0.6 -0.3  0.4 -0.4 -0.1 -0.5 -1.   0.4  1.4  2.1  2.3 -0.2 -0.3 -0.2 -0.6 -0.6 -0.6  1.   0.8 -1.2  2.1  8.  -0.5 -0.5  0.3 -0.5  4.1 -0.1 -0.4 -0.1 -0.3  3.1  0.  -1.2  0.8 -0.6 -0.6 -0.6  1.7 -0.8  2.1  0.5 -0.7 -0.5 -0.6 -0.4  5.6  2.  -1.5  0.1  3.4  0.9 12.  -0.6  7.5 -0.7 -0.7  1.2 -1.3 -0.3  0.7  0.3 -0.7 -0.4 -0.2  6.9  0.6  1.9  2.3]
vy_50sample [[7 1 8 9 3 0 2 4 6 5]
 [3 5 6 9 2 1 8 4 7 0]
 [2 8 0 9 6 1 3 4 7 5]
 [1 1 4 4 5 2 3 6 8 0]
 [5 0 1 8 9 6 7 3 2 4]
 [3 6 5 2 1 9 0 7 8 4]
 [9 8 2 7 4 0 1 3 6 6]
 [8 9 5 0 3 7 4 4 1 6]
 [3 3 9 5 6 2 0 4 1 8]
 [2 2 9 7 4 4 8 6 0 3]]
vt_50sample [[7 1 9 8 3 0 2 4 6 5]
 [3 5 6 9 2 1 8 4 7 0]
 [2 8 0 6 9 1 3 4 7 5]
 [1 9 7 4 5 2 3 6 8 0]
 [5 0 1 8 9 6 7 3 2 4]
 [3 6 5 2 9 1 0 7 8 4]
 [9 8 2 7 4 0 1 5 3 6]
 [8 9 5 0 3 7 4 6 2 1]
 [3 7 9 5 6 2 0 4 1 8]
 [2 5 1 9 7 4 8 6 0 3]]
Epoch  6010: Training cost= 0.4268, Training acc= 0.7268, Validation cost= 0.4302, Validation acc= 0.7273
Epoch  6020: Training cost= 0.4464, Training acc= 0.7269, Validation cost= 0.4279, Validation acc= 0.7275
Epoch  6030: Training cost= 0.4022, Training acc= 0.7271, Validation cost= 0.4705, Validation acc= 0.7276
Epoch  6040: Training cost= 0.3646, Training acc= 0.7272, Validation cost= 0.4508, Validation acc= 0.7278
Epoch  6050: Training cost= 0.3876, Training acc= 0.7274, Validation cost= 0.4485, Validation acc= 0.7279
Epoch  6060: Training cost= 0.4044, Training acc= 0.7276, Validation cost= 0.4001, Validation acc= 0.7281
Epoch  6070: Training cost= 0.4982, Training acc= 0.7277, Validation cost= 0.4314, Validation acc= 0.7282
Epoch  6080: Training cost= 0.4902, Training acc= 0.7278, Validation cost= 0.4068, Validation acc= 0.7284
Epoch  6090: Training cost= 0.4786, Training acc= 0.7280, Validation cost= 0.4789, Validation acc= 0.7285
Epoch  6100: Training cost= 0.4782, Training acc= 0.7281, Validation cost= 0.4788, Validation acc= 0.7286
tm  [-1.6 -0.4 -0.6  5.6 -0.6 -0.2  0.2 -0.4  0.3 -0.1 -2.1  1.6 -1.  -0.4 -1.7 -1.3 -0.7 -0.2 -0.6 -1.4 -0.6 -0.5  0.3 -0.6 -0.3  1.6 -0.2 -0.3 -0.2 -1.1 -0.4  0.1 -0.2 -2.2 -0.4 -0.5 -0.1 -0.1  5.4 -0.9 -0.7 -1.6 -1.2  0.4 -0.7 -0.4  4.3  1.5 -1.   0.5 -0.5 -0.5  0.4 -1.8 -0.6  4.7 -0.3 -0.7  2.5  2.4  3.8  0.3 -0.2  0.1 -0.4 -0.2 -0.2  1.   0.4  3.3 -0.3  1.7 -0.1 -0.2 -0.8 -0.2  2.2 -1.1  3.7  0.   2.6 -0.3 -0.7 -0.2  1.6 -1.7 -0.5 -0.8  1.5 -0.  -0.3 -1.1 -0.2 -0.7 -0.2 -0.5 -0.6 -0.6 -0.5 -0.2 -0.  -1.2  4.1 -0.1 -0.6 -0.1 -0.7 -0.4 -1.2 -1.6  0.2 -0.1 -0.4 -0.3  6.1 -0.4 -0.4  0.9 -0.6  2.4 -0.3  4.7  0.3 -0.1 -0.5 -1.7  1.3  9.   1.1  1.2 -0.4 -0.9 -0.8 -0.5  4.6 -1.1 -0.4 -0.2  2.4 -0.3  2.5 -0.3  0.1 -0.5 -1.  -0.8 -0.1  1.2 -0.1 -1.  -0.4 -0.3 -0.5  1.3 -0.6 -0.1 -0.1 -0.3 -0.  -0.6 -0.6 -0.8 -0.2 -0.7 -1.3 -0.3 -0.2  6.2 -0.6  2.  -0.4 -0.6 -0.4 -0.4 -0.3  2.3 -0.5  1.3 -0.6  0.7  0.3 -0.3 -0.2 -0.9  1.  -0.6 -0.4  0.4  1.5  6.6 -0.5 -0.4 -1.6 -1.  -0.5  0.2 -0.  -0.5 -0.3 -0.5 -0.7  1.9 -0.5 -0.9  1.7  0.1 -1.  -0.1  7.4 -0.6 -0.3  0.  -1.1  5.1 -1.  -0.2  0.6 -0.5 -0.3  1.1 -0.4 -0.2 -0.1 -1.1 -0.1 -0.1 -1.4  2.4 -0.2  0.1 -0.8 -0.3 -0.7  4.5  2.5  2.8  1.9 -0.   2.2 12.2 -0.7  6.9 -0.8 -0.4 -0.  -1.8 -0.1 -0.5 -0.5 -0.5 -0.7 -1.1  4.7 -0.5  3.4  1.7]
ty_50sample [[1 0 0 3 8 6 6 7 5 2]
 [1 6 8 7 3 0 5 2 4 9]
 [6 4 0 0 7 9 5 2 8 3]
 [9 9 7 3 4 5 8 2 0 6]
 [4 2 7 9 9 3 3 1 8 6]
 [2 9 3 7 8 8 1 1 0 4]
 [6 3 5 7 2 1 8 8 4 9]
 [2 7 4 0 9 6 1 3 8 5]
 [2 6 7 5 9 1 8 3 4 0]
 [3 1 9 4 2 8 6 7 5 0]]
tt_50sample [[1 0 3 9 8 4 6 7 5 2]
 [1 6 8 7 3 0 5 2 4 9]
 [4 6 1 0 7 9 5 2 8 3]
 [1 9 7 3 4 5 8 2 6 0]
 [4 2 7 9 5 3 0 1 8 6]
 [2 9 3 7 5 8 6 1 0 4]
 [6 3 5 7 2 0 1 8 4 9]
 [2 7 0 4 6 9 1 3 8 5]
 [2 6 7 9 5 1 8 3 4 0]
 [3 1 9 4 2 6 8 7 5 0]]
vm  [-1.2 -1.3 -0.6 -2.6 -1.2 -0.2 -0.2 -0.5  4.  -0.4  5.2 -0.  -0.1 -0.5  5.7  2.3 -0.9 -0.5 -0.4  1.1 -0.7 -0.4 -1.3 -1.  -0.2 -0.1 -0.3 -0.4  2.4 -1.3  7.2 -0.9 -0.7  7.5  0.6 -0.7 -1.4  3.   0.3 -1.2  0.1 -1.4 -1.8  5.3 -1.1 -0.3 -2.  -0.6 -0.6 -2.1 -1.2 -1.3 -0.5  4.4 -1.5 -0.8 -0.3 -0.6  6.6 -1.9  6.3 -0.1 -0.1  4.4  1.3  0.1 -0.7  4.   0.5  0.5 -0.2 -0.9 -0.7  0.6 -3.8 -0.1 -0.6 -0.7  4.7 -0.   2.8 -0.5  1.6 -0.   0.  -1.   0.5 -0.5  0.9 -0.1 -0.6 -1.  -0.5 -1.9 -0.5 -0.  -1.2 -2.2 -0.4 -0.3  0.3 -0.3  2.8  1.5 -0.6 -0.  -2.2  7.2  2.2  1.  -0.3 -0.6 -0.3 -1.4  3.7  1.9 -0.   4.7 -1.1  0.  -0.4 -0.3 -0.1  1.3 -0.3  6.4 -0.4 -0.6  6.   5.1 -0.2 -1.6 -0.  -0.5 -1.7  4.9  0.3  1.1  1.3 -0.9 -0.5  3.5 -0.1 -0.5 -1.1 -0.2 -0.2  0.1 -0.7 -0.8  6.5 -0.6 -1.2 -0.  -0.3 -0.1 -0.7 -0.8  2.  -0.1  0.4 -1.1  1.6 -0.8  2.3 -0.4  2.2  7.   0.3 -1.1 -1.  -0.1 -0.7 -0.6 -0.8  3.2 -0.3 -0.6  2.4  0.9 -0.  -0.2 -1.5 -1.   1.8 -1.1 -0.8 -0.7 -0.9  4.7 -0.3 -0.1 -0.8 -0.8 -1.2 -0.8 -1.1 -1.1 -0.7 -0.6 -0.7  3.3 -0.9 -1.  -0.1 -2.2  0.2 -0.4 -0.1 -0.5 -0.4  3.3 -1.5  5.3  0.1 -0.3 -1.1 -0.6  0.6  0.6 -0.5  0.2 -0.4 -0.3 -0.6  0.9 -0.5  2.2  0.2  4.4 -1.3  0.2 -0.3 -0.  -0.1  3.8  1.5 -1.9  5.   0.9 -0.5  0.3 -0.2 -0.2 -0.   0.7 -0.8 -0.7 -1.3 -0.9 -0.8 -0.2 -0.1 -0.3  3.3 -1.3]
vy_50sample [[4 1 3 7 2 6 5 9 8 8]
 [7 1 2 0 9 6 4 8 5 3]
 [9 6 1 7 4 5 3 0 8 8]
 [9 0 7 2 1 8 6 4 3 5]
 [1 9 0 6 5 8 2 7 3 4]
 [6 0 7 9 4 5 2 8 3 1]
 [6 7 8 9 3 2 1 0 5 5]
 [4 3 8 9 6 1 7 2 0 5]
 [6 9 9 2 7 5 4 1 3 8]
 [6 4 7 3 9 5 0 2 1 8]]
vt_50sample [[4 1 3 7 2 6 5 0 9 8]
 [7 1 2 0 9 6 4 8 5 3]
 [9 6 7 1 4 5 3 0 8 2]
 [0 9 2 7 1 8 6 4 3 5]
 [1 9 0 6 5 8 2 7 3 4]
 [0 6 7 9 4 5 2 8 3 1]
 [6 7 8 9 3 2 1 0 5 4]
 [3 4 8 9 6 1 7 2 0 5]
 [6 9 0 2 7 5 4 1 3 8]
 [4 6 3 7 9 5 0 2 1 8]]
Epoch  6110: Training cost= 0.4338, Training acc= 0.7282, Validation cost= 0.4048, Validation acc= 0.7287
Epoch  6120: Training cost= 0.4252, Training acc= 0.7284, Validation cost= 0.3987, Validation acc= 0.7289
Epoch  6130: Training cost= 0.4063, Training acc= 0.7285, Validation cost= 0.4206, Validation acc= 0.7291
Epoch  6140: Training cost= 0.4163, Training acc= 0.7287, Validation cost= 0.4503, Validation acc= 0.7292
Epoch  6150: Training cost= 0.4523, Training acc= 0.7289, Validation cost= 0.4061, Validation acc= 0.7294
Epoch  6160: Training cost= 0.5382, Training acc= 0.7290, Validation cost= 0.3830, Validation acc= 0.7295
Epoch  6170: Training cost= 0.4567, Training acc= 0.7291, Validation cost= 0.4793, Validation acc= 0.7296
Epoch  6180: Training cost= 0.4454, Training acc= 0.7293, Validation cost= 0.3978, Validation acc= 0.7298
Epoch  6190: Training cost= 0.4635, Training acc= 0.7294, Validation cost= 0.4968, Validation acc= 0.7299
Epoch  6200: Training cost= 0.4606, Training acc= 0.7295, Validation cost= 0.4558, Validation acc= 0.7300
tm  [-1.2 -0.9  5.4 10.4 -1.  -0.3 -0.4 -0.3  1.6  2.8 -0.1  0.1 -0.8 -0.4 -0.1 -0.3 -1.4 -0.5 -0.3 -1.4 -0.4  1.5  2.6 -0.8 -0.6  1.  -0.3 -0.3  1.  -0.7  0.3  0.   1.7  6.1 -0.3 -0.4 -0.3 -0.7 -0.3 -0.3  0.   3.7 -0.6 -1.5 -0.  -0.4  5.4  2.  -0.6  3.8 -0.8  0.1  1.7 -1.8 -0.9  2.1 -0.1  0.9  1.3  1.6  0.4 -0.4  0.2  1.3  1.6 -0.1 -0.1 -0.1  1.5 -0.2 -0.2 -0.3 -0.2  0.4 -0.9 -0.4 -0.1  0.7  3.  -0.3 10.2 -0.1 -0.7 -0.1 -0.2  4.8 -0.6 -0.4 -0.4  0.  -0.3 -0.4 -0.8 -1.3 -0.  -0.2  1.4 -0.7 -0.4 -0.2 -0.9  6.3  1.7 -0.1 -0.9 -0.2 -0.1  0.4 -0.2 -1.6  1.2 -0.1 -0.1 -0.7  2.8  1.7  0.6 -0.  -0.5  1.6 -0.4  4.3  1.   1.  -0.1 -0.4  1.3  9.1  1.9 -1.4  3.  -1.4 -0.9 -0.6  5.2 13.6  0.7 -0.6 -0.4 -0.4  1.   2.   2.1  0.1 -1.4  0.4  1.2 -0.7 -0.4  1.3 -1.  -0.2 -0.8  1.7 -0.1 -0.  -0.4 -0.1 -0.8 -0.   0.6  2.4  1.5 -0.7  0.6 -0.3 -0.6  1.8 -0.8  4.5  0.7 -0.4 -0.6 -0.6  0.7  2.8 -1.6  2.9  3.2  1.6 -0.3 -0.3 -0.3 -1.1 -0.9 -0.9  1.4 -0.5 -0.1  2.4 -0.2 -1.1 -1.5 -0.5  0.5 -0.1  1.9 -0.6 -0.4 -1.  -0.8  0.5  0.1 -0.3  2.5  1.5  1.1 -0.3 -0.2 -0.5  0.3  3.3 -0.8  5.7 -1.4 -0.1  6.3 -0.2  1.4  1.  -0.9 -0.6 -0.1 -0.5  4.5 -0.1 -1.4  3.   0.4 -0.2  2.5 -0.6 -0.5 -0.3 -0.6 -1.1  1.9  0.4  0.9  7.5 -0.8  4.4 -0.2 -0.5 -1.7 -2.  -0.1 -0.  -0.6 -0.1 -2.2 -0.6 -0.3  0.1  3.1  9.3]
ty_50sample [[6 9 1 7 5 0 8 4 2 3]
 [6 9 8 7 5 0 1 2 3 4]
 [3 5 1 4 9 0 7 8 6 2]
 [3 0 6 9 9 4 1 8 5 7]
 [5 6 7 2 9 4 1 0 8 3]
 [1 9 3 2 6 4 8 5 7 0]
 [4 9 6 8 8 3 1 0 2 2]
 [2 0 7 4 1 9 8 6 3 5]
 [8 0 3 2 9 7 1 4 5 5]
 [6 1 8 8 3 5 0 4 7 2]]
tt_50sample [[6 9 1 7 0 5 8 4 2 3]
 [6 9 8 7 0 5 1 2 3 4]
 [3 5 4 1 9 0 7 8 6 2]
 [3 0 6 9 2 4 1 8 5 7]
 [5 6 7 2 9 4 1 0 8 3]
 [1 9 3 2 6 4 8 5 7 0]
 [4 9 8 6 3 7 1 0 2 5]
 [2 0 4 7 1 9 8 6 5 3]
 [8 0 3 2 9 7 1 6 4 5]
 [6 1 8 9 3 5 0 4 7 2]]
vm  [-0.9  1.2  3.4  7.7 -0.9 -0.6 -0.9 -0.5 -0.2 -0.7  2.3 -0.5  1.1 -0.2 -0.3  5.9 -0.3 -0.4 -0.5 -0.2 -0.3 -0.4 -0.  -0.5 -1.4 -0.3 -0.3 -0.1  2.1 -0.3 -1.2 -0.9  0.4 -1.2 -0.6 -0.2  0.9  1.8 -1.6 -1.1 -0.1 -0.7 -0.2 -2.  -0.2  0.3 -0.5 -0.7  0.  -0.4 -0.5 -0.7 -0.2  3.7 -1.5  2.3  0.5  4.5 -0.1  5.6  1.  -0.2 -0.6  1.1 -0.5  0.9 -0.6  0.1 -0.3  0.6 -0.3 -0.9  0.4 -0.1 -1.4 -0.  -0.6 -0.8 -0.5 -0.  -0.3 -0.5 -0.6 -0.1 -0.4 -0.5 -0.5 -0.3  1.6  0.3 -0.8  1.   1.4  0.6 -0.1  0.4  1.1 -1.1 -0.4 -0.   1.9 -1.1 -0.   0.5 -0.2  1.9 -1.1 -1.3  1.1 -0.9 -0.3 -0.2 -0.2  0.5 -0.6  4.7 -0.2 -0.5 -0.5  1.3 -0.1  2.6  0.6 -0.4 -0.6 -0.5  1.  -0.3  1.1  3.9  5.  -1.1  1.1 -0.6 10.6  9.4 -0.6  0.9  0.8 -0.5 -0.4 -0.6 -0.5 -0.6 -0.9 -0.  -0.4 -0.2  2.5  1.1 -0.4 -0.3  1.1 -0.7 -0.5 -0.3 -0.5  0.4 -1.4 -0.6 -0.3  3.8 -0.3 -0.4 -0.9 -0.4  4.5  2.5 -0.5  2.8 -0.7 -0.3 -0.7 -0.2 -0.2 -0.4 -1.7 -0.4  8.1 -0.5 -0.5  0.3 -0.4 -1.  -0.1  0.   1.  -0.  -1.2  3.8 -0.3 -0.2 -0.7 -0.8  1.3 -0.4 -0.2 -0.1 -0.6 -0.7 -0.4  0.1 -0.5 -0.8  1.  -1.3  0.2 -0.   2.5 -0.3 -0.7  4.1 -1.6  1.  -1.1 -0.2  8.8 -0.2 -0.  -0.3 -0.3 -0.2 -0.6 -0.4  2.7  3.   0.6  2.6  0.1  5.3  1.1 -0.5 -0.6  2.  -0.4 -0.4 -0.3 -0.2 -0.1  1.1 -0.9  0.6  0.9 -0.7  3.2 -0.3 -0.4  2.3 -0.5 -0.7 -0.1 -1.2 -1.5  0.9  2.2 -0.6]
vy_50sample [[6 3 2 8 8 1 9 7 0 4]
 [6 1 3 8 2 4 7 0 0 5]
 [6 8 3 4 2 5 1 1 7 0]
 [2 9 7 4 5 0 3 3 8 1]
 [9 0 5 2 4 7 7 1 3 3]
 [9 1 6 2 7 3 4 4 8 0]
 [2 4 5 8 9 3 0 7 1 6]
 [1 1 8 2 9 4 7 5 3 6]
 [7 0 3 3 4 5 2 1 9 8]
 [1 1 0 3 2 4 8 7 7 9]]
vt_50sample [[6 3 2 8 5 1 9 7 0 4]
 [6 1 3 8 2 4 7 0 9 5]
 [6 8 3 4 2 5 9 1 7 0]
 [2 9 7 4 0 5 6 3 8 1]
 [9 0 5 2 4 7 6 8 1 3]
 [1 9 6 2 3 7 4 0 5 8]
 [2 4 5 8 9 3 0 7 1 6]
 [0 1 8 2 9 4 7 5 3 6]
 [7 6 0 3 4 5 2 1 9 8]
 [1 6 0 3 2 4 8 5 7 9]]
Epoch  6210: Training cost= 0.4483, Training acc= 0.7297, Validation cost= 0.4612, Validation acc= 0.7302
Epoch  6220: Training cost= 0.4567, Training acc= 0.7298, Validation cost= 0.4546, Validation acc= 0.7303
Epoch  6230: Training cost= 0.4083, Training acc= 0.7299, Validation cost= 0.4532, Validation acc= 0.7304
Epoch  6240: Training cost= 0.4323, Training acc= 0.7301, Validation cost= 0.4201, Validation acc= 0.7306
Epoch  6250: Training cost= 0.4388, Training acc= 0.7302, Validation cost= 0.4484, Validation acc= 0.7308
Epoch  6260: Training cost= 0.4226, Training acc= 0.7304, Validation cost= 0.4197, Validation acc= 0.7309
Epoch  6270: Training cost= 0.4478, Training acc= 0.7305, Validation cost= 0.3953, Validation acc= 0.7311
Epoch  6280: Training cost= 0.4021, Training acc= 0.7307, Validation cost= 0.4123, Validation acc= 0.7312
Epoch  6290: Training cost= 0.4684, Training acc= 0.7308, Validation cost= 0.4809, Validation acc= 0.7314
Epoch  6300: Training cost= 0.4477, Training acc= 0.7310, Validation cost= 0.4647, Validation acc= 0.7315
tm  [ 3.9 -0.7 -2.2 -0.7 -0.5 -1.  -0.5 -0.3  1.5 -1.1  4.2  0.7 -1.2 -1.2 -1.9 -0.3 -0.3 -0.3 -0.8 -1.2 -0.6  0.7 -1.1  0.7 -0.6  2.2 -0.3 -0.2 -0.3 -1.   5.9 -1.1  0.7 -0.3  2.4 -0.1 -0.3  1.9  5.4 -1.5 -0.4 -1.1 -0.8  5.2 -0.3 -0.2  4.3 -0.3  2.5 -1.8 -0.5 -1.   2.2 -0.3 -0.3  5.3 -0.2 -0.4  2.6 -1.3 -1.5 -0.7  1.2  3.   1.3 -0.7  0.1  4.5  2.  -0.  -0.6 -0.2 -0.6 -0.3 -1.8  0.5 -1.  -0.4  1.  -0.4  8.9 -0.2 -0.2 -0.3 -1.5 -1.3  2.1 -0.5  1.4 -0.2  0.7 -1.1 -0.2 -0.5 -0.3 -0.3 -0.6 -0.9 -0.3 -0.1  0.9 -2.1 -1.1 -0.4 -0.3 -0.3 -0.8  6.3  2.4 -1.1 -0.2  0.6 -0.2 -0.7  4.1 -0.4  0.3  3.9 -0.1  2.  -0.3  2.9 -0.5 -0.3 -0.9 -1.8 -0.6  3.3  2.   3.   3.5 -0.9  0.3  0.2  4.9  2.1 -0.2 -0.5  2.9 -0.6 -0.2 -0.3 -0.  -0.4 -0.3  0.6 -0.9 -0.4  2.7 -1.   1.3  0.9  4.7  0.  -0.3 -0.2 -0.7 -0.2 -0.3 -0.4 -0.1 -1.5  0.3 -0.4  0.7 -0.5 -0.2  2.2  0.3 -0.3 -0.6 -0.5 -0.4 -0.2 -0.4 -0.6 -0.7  0.8 -0.8  0.4 -0.3 -0.3 -0.7 -0.8  1.1 -0.9  5.3  1.   1.8  5.3 -0.2 -0.4 -1.3 -1.3  7.8 -0.3 -0.3 -0.6 -0.5 -0.  -0.3  2.5 -0.3 -0.8 -1.7  0.3  0.5 -0.1  0.1 -0.3 -0.3  1.4 -0.8 -0.5  1.1  0.1 -1.2 -0.6 -1.1 -0.   0.3 -0.7  0.  -1.1 -0.6 -0.1 -0.4 -0.2 -0.1  8.6 -1.1 -0.3 -0.8  0.2 -0.1  8.2  3.4 -0.9  3.5  7.5 -0.2  3.7 -0.5  0.5 -1.4 -2.   0.3 -0.6 -0.7 -0.1 -2.  -0.   5.4 -0.6  2.  -0.2]
ty_50sample [[4 3 0 9 2 6 6 8 7 1]
 [2 6 9 4 8 5 3 3 0 1]
 [1 5 8 2 0 4 7 6 9 3]
 [5 1 7 2 8 4 6 3 0 0]
 [8 2 4 0 9 1 6 3 7 5]
 [7 8 6 4 3 5 9 0 1 2]
 [5 9 4 6 3 2 0 7 1 8]
 [7 6 6 4 0 3 8 5 2 1]
 [8 0 6 9 4 1 7 5 2 3]
 [8 3 1 9 4 6 2 0 7 5]]
tt_50sample [[4 3 0 9 2 5 6 8 7 1]
 [2 6 9 4 8 5 3 0 7 1]
 [1 5 2 0 8 4 7 6 9 3]
 [5 1 7 2 8 4 6 3 0 9]
 [8 4 2 0 9 1 6 3 7 5]
 [7 8 6 4 3 5 9 0 1 2]
 [5 9 4 6 2 3 0 7 1 8]
 [7 9 6 4 0 3 8 5 2 1]
 [8 0 9 6 4 1 7 5 2 3]
 [3 8 1 9 4 2 6 0 7 5]]
vm  [ 2.2 -0.3 -1.3 -1.7 -0.5 -0.9 -0.8 -0.7 -0.6 -0.5  1.5 -0.9  0.4 -0.3  1.1  5.9 -0.1 -0.4 -0.3  1.4 -0.6 -0.1  2.1 -0.1 -1.  -0.2 -0.4 -0.3  2.3 -0.2 -0.3 -0.9  0.4 -3.   2.8 -0.2  0.1  5.3 -0.3 -0.8 -0.1 -1.3 -1.1  4.7 -0.7 -0.5 -1.1 -1.   1.   4.8 -0.2 -1.5 -1.2  9.3 -1.   1.2 -0.8 -0.9  4.3  2.  -0.1  0.  -0.1  1.8 -0.3 -1.  -0.3  2.9 -0.4 -0.7 -0.1 -0.7  1.7 -0.1 -4.1  0.8 -0.7 -0.1  2.3 -0.7 -3.4  0.2  1.5 -0.3 -1.5 -1.   1.8 -0.5  2.1 -0.2  0.6 -0.8 -0.4  0.3 -1.  -0.5 -0.9 -1.3 -0.4 -0.7  0.2 -0.9 -0.2 -0.1  0.3 -0.4 -2.5 -0.2  0.5  1.6 -0.  -0.3 -0.4 -0.3  0.1  0.9 -0.2  1.4  1.7  1.7 -0.2 -0.9 -0.5 -1.5 -0.6  1.8 -0.7 -2.1  0.9  4.4  3.7 -0.1 -0.2 -0.2  3.2 -3.1  0.3 -0.4  0.3 -0.  -1.  -1.1 -0.6 -0.3  0.2  1.1 -0.3  0.2 -0.2 -0.4  3.4 -0.   5.8 -1.2 -0.3  0.1 -0.8 -0.5 -0.1 -0.7  1.2 -1.2  0.8 -0.6 -1.  -0.2  1.1  1.9 -0.  -0.9 -0.  -0.8 -0.5 -0.3 -0.3  2.7 -0.9 -0.7  3.5 -0.7  2.4 -0.2 -0.1 -0.6  1.2  2.2  2.6 -0.2 -1.1  2.3 -0.3 -0.9 -0.1 -1.6  2.2 -0.2 -1.4 -0.1 -0.3 -0.1 -0.1  1.5 -0.8 -0.5 -1.9 -1.9 -1.5 -0.3  8.5 -0.3 -0.2  0.5 -1.2 -0.3  0.9 -0.2 -0.8 -0.5 -0.7 -0.5 -0.5 -0.6 -0.3 -1.  -0.3  2.4  1.3  2.2 -0.6  5.5 -0.7  1.8 -1.1  5.8 -0.9  5.4  3.  -2.6  0.6  4.4 -0.7  3.8 -0.3  0.7 10.6 -0.6  1.  -0.7 -0.2 -0.   7.   2.1 -0.1 -0.  -0.4 -0.5]
vy_50sample [[2 8 4 3 6 6 7 1 5 5]
 [4 1 8 0 3 5 5 2 2 7]
 [4 7 9 1 8 2 6 5 3 0]
 [8 7 7 6 0 4 5 1 3 2]
 [2 6 1 0 9 7 4 8 3 5]
 [4 5 3 1 0 9 7 8 2 6]
 [3 8 2 6 0 4 9 5 5 1]
 [2 4 1 3 8 0 9 7 5 6]
 [0 0 4 1 1 3 3 6 5 5]
 [0 9 4 6 5 8 2 2 3 3]]
vt_50sample [[2 8 4 3 6 0 7 9 1 5]
 [4 1 8 0 3 9 5 2 6 7]
 [4 7 9 1 8 2 6 5 3 0]
 [8 9 7 6 0 4 5 1 3 2]
 [2 6 1 0 9 7 4 3 8 5]
 [4 5 3 1 0 9 7 8 2 6]
 [3 8 2 6 0 4 9 7 5 1]
 [2 4 1 3 8 0 9 7 5 6]
 [0 7 4 2 1 3 8 9 6 5]
 [0 9 4 5 6 8 2 1 7 3]]
Epoch  6310: Training cost= 0.4222, Training acc= 0.7311, Validation cost= 0.4513, Validation acc= 0.7316
Epoch  6320: Training cost= 0.4608, Training acc= 0.7312, Validation cost= 0.4338, Validation acc= 0.7318
Epoch  6330: Training cost= 0.3887, Training acc= 0.7314, Validation cost= 0.4433, Validation acc= 0.7319
Epoch  6340: Training cost= 0.4268, Training acc= 0.7315, Validation cost= 0.4466, Validation acc= 0.7321
Epoch  6350: Training cost= 0.4390, Training acc= 0.7317, Validation cost= 0.3949, Validation acc= 0.7322
Epoch  6360: Training cost= 0.3593, Training acc= 0.7318, Validation cost= 0.4544, Validation acc= 0.7324
Epoch  6370: Training cost= 0.4117, Training acc= 0.7320, Validation cost= 0.4333, Validation acc= 0.7325
Epoch  6380: Training cost= 0.4334, Training acc= 0.7321, Validation cost= 0.4360, Validation acc= 0.7327
Epoch  6390: Training cost= 0.3935, Training acc= 0.7323, Validation cost= 0.3965, Validation acc= 0.7328
Epoch  6400: Training cost= 0.4723, Training acc= 0.7324, Validation cost= 0.5341, Validation acc= 0.7329
tm  [-0.8  0.3 -2.  -2.5 -0.7 -0.2 -0.3 -0.6 -0.4 -1.4  2.3  0.2 -0.3 -0.2  0.2  4.1  0.4 -0.6 -0.6  1.4 -0.2 -0.2 -0.6 -0.  -1.3  0.6 -0.1 -0.4  2.1 -0.5  5.1 -1.4 -0.2 -0.9 -0.9 -0.1  0.4  3.3 -0.4 -1.3  0.7 -0.6  1.   5.1 -0.4  0.1 -1.6 -0.2 -0.4 -1.3 -0.6 -1.3 -0.5  4.  -1.7  0.6 -0.3  0.2  1.  -0.9  4.2 -0.7 -0.1 -0.  -0.2 -0.  -0.4  2.1 -0.3  1.2 -0.3 -1.  -0.2  0.4 -2.7 -0.3 -0.2 -0.9  1.7  0.3 -0.8 -0.4  0.4 -0.1 -0.2  0.1  1.2 -0.4  3.9 -0.3 -0.5 -0.1 -0.   1.2 -0.7  0.7 -0.1 -1.2 -0.4 -0.3  3.  -2.   0.4 -0.3 -0.2  0.6 -2.1  4.8  0.5  0.4 -0.6 -0.5 -0.1 -0.5 -0.2  5.1 -0.3  0.3 -0.6 -0.  -0.3 -0.2  0.1 -0.2 -0.9  0.8  1.8 -0.4  3.3  6.9  0.4 -0.9  1.8 -0.2  4.   0.7 -0.1 -0.3  3.2 -0.8 -0.2 -0.1 -0.2 -0.3 -0.7  0.4 -0.1 -0.2  4.8 -0.   5.4 -0.1  0.1 -0.1 -0.7 -0.4 -0.9 -0.4  0.9 -0.5 -0.3 -0.4 -0.2 -0.4 -0.4  0.   4.6  2.8  1.8 -1.1 -0.3  1.6 -1.  -0.4 -0.6 -1.3 -0.5 -1.   3.9 -0.6 -1.3  1.  -0.6 -1.3  0.2 -0.1 -0.3  0.5 -1.2  3.9 -0.5  0.4 -0.  -1.3 -0.8 -0.3 -1.  -0.  -0.8 -0.9 -0.1  2.4 -0.8 -1.5 -0.1 -2.4  1.   0.  -0.8 -0.3 -0.4  3.3 -1.   2.   0.7 -0.1 -1.  -0.4 -0.4 -0.2 -0.5  1.  -0.1 -0.4 -0.6  3.3  0.5  0.2  0.7  4.7 -1.1  0.2 -0.5 -0.6 -0.1  7.4 -0.3 -1.6  2.  -1.9 -0.2 -0.9 -0.5 -0.4  4.3  1.5 -0.2 -0.3 -0.5 -0.6  0.6 -0.4 -0.3 -0.4  4.7 -1.4]
ty_50sample [[4 3 5 1 2 8 6 9 7 0]
 [5 7 3 4 1 2 8 6 6 9]
 [3 8 7 9 2 6 0 5 1 4]
 [4 3 3 5 8 8 1 9 7 0]
 [8 2 4 3 1 5 0 9 9 7]
 [3 5 4 8 9 1 6 0 2 7]
 [0 1 6 3 4 7 7 9 8 5]
 [8 4 5 7 2 1 1 6 0 3]
 [5 9 0 0 3 8 7 6 2 1]
 [9 2 4 6 0 8 5 7 3 1]]
tt_50sample [[3 4 5 1 2 8 6 9 7 0]
 [5 7 3 4 1 8 2 0 6 9]
 [3 8 7 9 2 6 0 5 1 4]
 [4 2 6 3 5 8 1 9 7 0]
 [8 2 4 3 5 1 0 9 6 7]
 [3 5 4 8 9 6 1 0 7 2]
 [0 1 6 3 4 2 7 9 8 5]
 [8 4 5 7 2 9 1 6 0 3]
 [5 9 4 0 3 8 7 6 2 1]
 [9 2 4 6 0 8 5 7 3 1]]
vm  [-1.3 -1.2 -2.5  1.6 -0.8  1.2  0.  -0.2  0.8 -0.3  9.3 -0.3  0.7 -0.5 -3.   1.4 -0.4 -0.5 -0.9 -2.2 -0.5 -0.3 -0.4 -0.3 -1.   0.9 -0.3 -0.3 -0.7 -0.8  7.8 -0.9  1.2  3.4  0.4  1.7  0.6  3.8 10.3 -0.3 -0.3  2.4 -0.9  5.2 -0.7 -0.6 10.5 -0.5 -1.1 -0.6 -0.7 -0.5  2.4 -0.7 -0.7  7.5 -0.7 -1.1  2.1 -2.6  0.5 -0.3  0.1  1.1  0.9 -0.6 -0.3  4.2 -0.3 -0.5 -1.1 -0.2 -0.8 -0.3  4.2 -0.   1.9 -0.2  4.6 -0.6 19.6 -0.  -1.2 -0.6  0.7  2.8  0.9 -0.5  0.1 -0.2  0.5 -0.3 -0.8 -0.9  0.6 -0.7 -0.2  0.8 -0.1 -0.8  0.5  0.2  0.3 -0.4 -1.1 -0.5  1.2  9.   3.1 -2.2 -1.1  0.6 -0.3 -0.2  4.4  0.9 -0.  -0.2 -0.8 -0.  -0.3  8.4  0.4  1.9 -0.3 -3.1 -0.   5.   1.2 -2.  -1.  -1.  -1.1  0.1  3.8  6.4 -0.2 -0.9  1.3 -0.7 -0.9  1.2 -0.6 -0.3 -0.5 -0.5  1.1  1.4  3.4  0.  -0.8 -0.3 -2.  -0.4 -0.3 -0.1 -0.2 -0.6  2.6  0.4  2.1 -0.9 -0.9 -0.6 -0.4 -0.2 -1.1  0.9 -0.   0.7 -0.2 -0.5 -0.7 -0.1 -0.6 -0.4 -0.1  4.5 -2.3 -0.5 -0.2  0.   1.4 -1.2 -0.4 -1.1  0.8  0.5  1.3  2.9 -0.5 -1.4 -1.6 -0.6  2.   1.   4.   0.1 -0.6 -0.4 -0.3  0.4 -1.  -0.9 -0.2  5.1  1.4 -0.3 -1.7 -0.5 -0.2  0.5 -0.2  6.9  2.9 -0.4 -1.5 -0.8 -0.7 -0.5  2.1 -0.6 -0.2 -1.2  1.2 -0.6 -0.1  2.8 -0.  -0.6 -1.  -0.5 -0.2 -1.   1.4  8.2  3.6  2.3  1.  11.6 -0.5  6.4 -1.1 -0.2 -4.  -2.7  1.2 -0.4 -0.5 -0.7 -3.5  1.8  9.2  0.4  0.   9.9]
vy_50sample [[9 4 1 2 0 5 5 3 7 8]
 [9 1 3 0 6 4 2 5 7 8]
 [5 7 3 3 8 0 2 6 1 1]
 [4 4 2 0 8 3 7 1 5 6]
 [7 6 9 5 2 1 3 4 8 0]
 [6 1 0 3 5 4 2 8 7 9]
 [2 2 6 4 0 8 8 7 9 1]
 [4 4 6 3 0 5 5 9 7 7]
 [3 9 2 6 8 5 4 0 1 7]
 [2 1 6 9 8 3 5 0 4 7]]
vt_50sample [[4 9 1 2 0 5 6 3 7 8]
 [9 1 3 0 6 4 2 5 7 8]
 [5 7 4 3 8 0 1 9 6 2]
 [9 4 2 0 8 7 3 1 5 6]
 [7 6 9 5 2 1 3 4 8 0]
 [6 1 0 3 5 4 2 7 8 9]
 [2 3 6 4 5 0 8 7 9 1]
 [1 4 6 3 0 5 9 8 2 7]
 [9 3 2 6 8 5 0 4 1 7]
 [2 1 6 9 8 3 5 0 4 7]]
Epoch  6410: Training cost= 0.4610, Training acc= 0.7325, Validation cost= 0.5130, Validation acc= 0.7331
Epoch  6420: Training cost= 0.4830, Training acc= 0.7326, Validation cost= 0.4542, Validation acc= 0.7332
Epoch  6430: Training cost= 0.4896, Training acc= 0.7328, Validation cost= 0.4289, Validation acc= 0.7333
Epoch  6440: Training cost= 0.4659, Training acc= 0.7329, Validation cost= 0.4469, Validation acc= 0.7334
Epoch  6450: Training cost= 0.4355, Training acc= 0.7330, Validation cost= 0.4232, Validation acc= 0.7336
Epoch  6460: Training cost= 0.4267, Training acc= 0.7332, Validation cost= 0.4415, Validation acc= 0.7337
Epoch  6470: Training cost= 0.3757, Training acc= 0.7333, Validation cost= 0.4202, Validation acc= 0.7339
Epoch  6480: Training cost= 0.3959, Training acc= 0.7335, Validation cost= 0.4384, Validation acc= 0.7340
Epoch  6490: Training cost= 0.4964, Training acc= 0.7336, Validation cost= 0.3838, Validation acc= 0.7341
Epoch  6500: Training cost= 0.4570, Training acc= 0.7337, Validation cost= 0.4605, Validation acc= 0.7343
tm  [ 3.  -0.1  4.2 11.5 -0.8 -1.6 -0.4 -1.  -0.6 -0.2 -3.7  0.1 -1.1 -0.5 -1.2  2.8 -0.8  1.2 -0.  -1.5 -0.2 -0.1  3.3 -0.1 -0.6 -1.1 -0.4 -0.2  5.5  0.6 -1.3 -0.4  0.2 -1.9  0.1 -0.3 -0.6  0.4  8.7 -0.4  0.  -1.  -1.1  0.1 -0.1 -1.3 10.4  0.4  2.8  7.  -0.3 -0.3  1.7 -2.3 -1.4  3.9  0.6 -0.4  0.4  4.4 -2.7 -0.5 -0.1  0.  -0.9 -1.3 -0.7 -0.7  1.6 -0.1 -0.4 -0.7  2.8 -0.2  3.1  0.4 -1.1  0.9  0.3 -1.3  0.8  1.2 -1.  -0.3 -1.8 -0.6  1.1 -0.4  1.8 -0.3  3.2 -0.7 -0.3 -0.9  1.8 -0.7 -0.6 -0.  -0.5 -0.5 -0.4  2.2 -1.4 -0.4 -0.5 -0.3  2.2 -1.9 -1.9 -1.9  1.7 -0.6 -0.5 -0.  -1.   4.2 -0.5  0.4  2.1  1.8 -0.3  5.6 -0.1 -1.9  1.8 -1.5 -0.  10.7  0.  -1.4  5.5 -0.4  0.  -0.7 -0.5 -3.5  1.1 -0.6 -0.9  1.7  1.1 -0.9  2.3  0.6 -0.9  3.3 -0.3 -0.8 -1.4  0.9 -1.1 -0.1  6.9 -0.2 -0.   0.8 -1.1 -0.7 -0.7 -0.5  0.6 -1.   1.6 -0.5 -1.2 -0.7  1.7  2.6 -0.4  5.  -0.5 -1.2 -0.4 -0.4  0.2  5.1 -1.2  5.2 -1.7  1.2  3.4 -0.2 -0.7 -1.  -1.1  0.4  7.  -0.3 -0.8 -0.1 -0.4 -0.7 -2.  -1.5 11.5  0.   6.4 -0.1 -0.1 -1.  -1.1  0.9  0.5 -0.4 -1.6  7.7 -2.  -0.7  9.3 -0.6 -0.3  4.9 -1.7  0.3 -0.8 -0.5  2.6  0.5  1.2  0.7 -1.8 -1.1 -0.6 -0.6  0.9  4.4 -1.7  1.  -0.7  5.  -0.4 -1.2 -1.   6.6 -1.3 -0.9  2.4  4.2  1.3 17.3 -0.1  9.5 -0.3  0.8  0.7 -4.1  2.1 -1.  -0.5 -0.5 -0.2 -0.   7.3 -0.3  1.3  7.3]
ty_50sample [[9 9 7 7 3 4 2 0 5 1]
 [4 5 1 7 2 9 0 6 3 8]
 [3 6 8 7 1 5 9 0 4 2]
 [3 9 0 1 5 2 8 7 4 6]
 [8 6 0 4 9 5 7 1 3 2]
 [5 8 1 7 4 0 2 3 9 6]
 [1 7 9 6 8 5 3 0 4 2]
 [0 4 2 3 5 7 6 9 1 8]
 [9 2 3 8 8 4 5 5 6 1]
 [6 3 9 4 1 7 5 2 0 8]]
tt_50sample [[8 9 7 6 3 4 2 0 5 1]
 [4 5 1 7 2 0 9 6 3 8]
 [3 6 8 7 1 5 9 4 0 2]
 [3 9 0 5 1 2 8 7 4 6]
 [8 6 0 4 9 5 7 1 3 2]
 [5 8 1 7 4 0 2 3 9 6]
 [1 7 9 6 8 5 3 0 4 2]
 [0 4 2 3 5 7 9 6 1 8]
 [2 9 3 7 8 4 5 0 6 1]
 [6 3 9 4 1 7 5 2 0 8]]
vm  [-1.6  0.4  6.6  7.  -1.7  0.1 -0.1 -0.1  0.  -0.7 -1.1  0.7 -0.3  0.1  3.   2.7 -0.7 -0.4  0.2 -0.1 -0.1 -0.2  2.1 -0.7 -1.2  0.6 -0.2 -0.1  3.  -0.9 -0.9 -0.5 -0.7  2.5 -1.  -0.4 -0.2  2.4  4.  -1.1  0.4 -0.1  0.1  0.1 -0.6 -0.  -0.5  1.3 -0.7  1.8 -1.  -0.2  0.6 -0.4 -1.3 -0.1 -0.1  3.5  1.2  4.9  3.6 -0.4 -0.1  2.1 -0.8  0.7 -0.7 -0.7 -0.   1.7  0.8 -0.7  1.2  1.5 -0.6 -0.2 -0.  -0.9  0.   1.3 -0.  -0.5 -0.4 -0.2  0.5  1.5 -0.8 -0.4  2.5  0.5 -0.1 -0.1 -0.2 -0.5  0.4 -0.1  2.6 -1.  -0.6  0.3  1.7  3.   2.2 -0.  -0.1 -0.  -0.7 -1.1 -0.6 -0.9 -0.  -0.6 -0.3 -0.5 -0.3  6.1 -0.1 -0.1 -0.7  0.  -0.1  3.5  0.6 -0.2 -0.1  3.1  2.4  4.4  4.4  1.8 -0.4 -1.2 -0.3 -0.4 -2.  -1.5  0.1 -0.4  0.1 -0.2  0.6  0.6  0.5 -0.4 -1.4  0.   0.  -0.5 -0.3  0.9 -0.2 -0.8  0.3  0.3 -0.5 -0.5 -0.6 -0.3  3.2 -0.3 -0.3 -0.4 -0.1 -0.3 -0.6 -0.3  3.2  3.4 -0.3  2.6 -0.2  0.5 -0.9 -0.5 -0.1  1.8 -0.5  0.4 -0.4  0.  -0.5  0.2 -1.  -1.2 -0.2 -0.5 -0.4 -0.4 -0.9  4.1 -0.6 -0.2 -1.  -0.9 -0.4 -0.6  1.  -0.2 -0.4 -1.2 -0.8  0.6 -0.6 -1.3  2.6 -0.5  0.3  1.   2.1 -0.5 -0.5  5.3 -0.7  4.4 -1.  -0.2  2.  -0.4  1.8  0.5 -1.3  0.3 -0.6 -0.1 -0.3  4.  -0.7  3.  -0.1  1.5 -0.7 -0.8 -0.4  1.8 -0.  -1.6 -0.3  0.9  1.7  1.6 -0.3  0.7 -0.1 -0.7  2.5 -0.9 -0.4  1.2 -0.7 -1.  -0.3 -1.2  3.7  0.   4.9  1.3]
vy_50sample [[1 7 8 3 9 9 6 2 4 0]
 [1 7 0 5 9 9 4 3 6 6]
 [7 2 1 5 4 9 6 8 3 0]
 [4 5 0 3 7 2 8 6 1 1]
 [9 1 8 4 3 5 2 0 0 6]
 [3 6 8 5 7 9 9 4 0 2]
 [5 7 2 3 0 9 8 1 4 4]
 [9 9 3 5 2 2 0 4 4 1]
 [3 6 9 9 4 0 1 5 2 2]
 [5 1 8 8 0 6 6 3 4 2]]
vt_50sample [[1 7 8 3 5 9 6 2 4 0]
 [1 7 0 5 8 9 4 2 3 6]
 [7 2 1 5 4 9 6 8 3 0]
 [4 0 5 3 7 2 8 6 9 1]
 [1 9 4 8 3 5 2 7 0 6]
 [3 6 8 5 7 9 1 4 0 2]
 [5 7 2 3 0 9 8 6 1 4]
 [9 3 6 8 5 2 0 4 7 1]
 [3 6 7 9 4 0 1 5 8 2]
 [5 1 8 9 7 0 6 3 4 2]]
Epoch  6510: Training cost= 0.3986, Training acc= 0.7339, Validation cost= 0.4696, Validation acc= 0.7344
Epoch  6520: Training cost= 0.4807, Training acc= 0.7340, Validation cost= 0.4696, Validation acc= 0.7345
Epoch  6530: Training cost= 0.4842, Training acc= 0.7341, Validation cost= 0.4591, Validation acc= 0.7347
Epoch  6540: Training cost= 0.5654, Training acc= 0.7342, Validation cost= 0.4259, Validation acc= 0.7348
Epoch  6550: Training cost= 0.4753, Training acc= 0.7344, Validation cost= 0.4794, Validation acc= 0.7349
Epoch  6560: Training cost= 0.4426, Training acc= 0.7345, Validation cost= 0.4471, Validation acc= 0.7350
Epoch  6570: Training cost= 0.4273, Training acc= 0.7346, Validation cost= 0.3758, Validation acc= 0.7351
Epoch  6580: Training cost= 0.4382, Training acc= 0.7347, Validation cost= 0.4444, Validation acc= 0.7353
Epoch  6590: Training cost= 0.3906, Training acc= 0.7349, Validation cost= 0.4375, Validation acc= 0.7354
Epoch  6600: Training cost= 0.3955, Training acc= 0.7351, Validation cost= 0.4265, Validation acc= 0.7355
tm  [-0.  -0.7 -0.8 -1.  -1.  -0.5 -0.5 -0.7 -0.2 -0.2  4.7 -0.5 -0.1 -0.9  1.9 -0.3 -0.6 -0.4 -0.3 -0.1 -0.7 -0.1 -0.3 -0.2 -0.6  3.2 -0.2 -0.2 -0.7 -0.5  4.4  0.2  1.3  3.9  3.3 -0.   0.7 -0.3 -1.7 -1.1 -0.4 -0.9 -1.1 -0.2 -0.8  1.  -0.9 -0.6  2.2 -0.2 -1.2 -1.4 -0.5  4.   0.   0.6 -0.5 -1.   2.3 -1.   0.8  1.7 -0.2  4.8 -0.  -0.4 -0.   1.9  0.5  1.3 -0.7  1.5 -0.6 -0.4 -2.7 -0.  -0.4 -0.6  3.8  0.2  3.  -0.   0.5 -0.2 -0.7 -1.1  2.  -0.3 -0.3 -0.1 -0.5 -0.8 -0.6 -0.7 -0.5  0.6 -0.4 -1.5 -0.2 -0.3 -0.1  1.1 -0.3  0.1 -0.1  0.4 -1.5  4.6  2.5 -0.2 -1.   1.6 -0.3 -0.7  4.4 -1.1 -0.2  1.7 -0.6  0.9  0.   0.7 -0.   0.3 -0.6  2.5 -0.8 -0.4 -0.1  1.7  4.9 -1.1 -0.2 -0.3  8.1 12.2 -0.5 -0.2  0.6 -0.7 -0.4 -0.5 -0.3  0.8 -0.8 -0.2 -0.2 -0.  -0.8 -0.4  2.7 -0.1  0.7 -0.4 -0.3 -0.1 -0.3 -0.3 -1.2 -0.5  1.5  1.7  0.5 -0.9  0.  -0.7 -0.3  3.1 -0.2 -0.4 -0.3 -0.9  0.1 -0.1 -0.4  4.2 -1.3 -0.1  8.3 -0.1  1.5 -0.1 -0.6 -0.9  0.9 -0.8  1.5 -0.4 -0.3  1.5 -0.3 -0.6 -0.2 -0.8  1.6  0.  -0.8 -0.5 -0.1  0.5 -0.3  1.8 -0.5 -0.4 -0.4 -1.6 -0.3  0.3  4.1 -0.2 -0.2 -0.5 -1.5  0.9 -0.1 -0.6  2.3 -0.6 -0.4 -0.4 -0.2 -0.5 -0.2 -0.7  2.9 -0.8 -0.1  1.1  0.3  4.2  1.1 -0.  -0.8  2.8  3.   3.9  4.  -1.   3.6  7.4 -1.   4.7 -0.  -0.2  0.  -0.1 -0.3 -0.  -1.  -0.4 -0.7 -0.2 -1.4  0.8 -0.1  0.5]
ty_50sample [[6 0 4 2 3 3 1 8 8 5]
 [5 8 0 9 7 4 3 2 1 6]
 [9 5 0 1 7 6 8 3 2 4]
 [3 1 5 6 0 4 8 9 7 2]
 [7 3 0 6 9 8 5 4 1 2]
 [4 2 9 3 7 1 8 6 0 5]
 [5 9 0 2 1 6 8 4 3 7]
 [6 0 2 4 4 7 9 9 1 5]
 [4 9 1 0 0 6 3 8 7 5]
 [1 7 2 9 3 8 8 4 4 5]]
tt_50sample [[6 0 4 2 3 7 1 9 8 5]
 [5 8 0 9 7 4 3 2 1 6]
 [9 5 0 1 7 6 8 3 2 4]
 [1 3 5 6 0 4 8 9 7 2]
 [3 7 6 0 9 8 5 4 2 1]
 [4 2 9 3 7 1 8 6 0 5]
 [5 9 0 2 1 6 8 4 3 7]
 [6 0 2 4 3 7 9 8 1 5]
 [4 9 1 0 2 6 3 8 7 5]
 [1 7 2 9 3 0 8 6 4 5]]
vm  [ 0.4 -0.2  0.1 -0.1 -0.8 -1.3 -0.  -0.5  2.  -0.1 -2.8  1.1 -1.4 -0.6  1.6 -0.2 -1.5 -0.   1.1  2.  -0.6 -0.1  1.5 -0.7  0.1 -0.1 -0.3 -0.3  2.9 -0.7  0.7 -0.2 -0.3 -0.8  1.9 -1.4 -1.6 -0.4 -0.4 -1.1 -0.3 -1.2 -1.3  0.3 -0.3  0.8 -1.   0.7  2.9  2.9 -0.8 -0.9 -0.  -1.  -1.1  0.2  1.7 -0.3  5.5  2.1 -0.2 -0.3  1.9  3.3 -0.1 -0.3 -0.2 -0.   2.9  2.  -0.2 -0.4  2.2  1.2 -3.  -0.2 -1.6 -0.4  2.4 -0.  -1.3 -0.2  2.4 -0.2 -1.1 -1.2  1.2 -0.4 -0.1 -0.1  1.2 -1.6 -0.6 -1.9 -0.1 -0.2 -0.7 -2.  -0.8 -0.1 -0.8  0.1 -0.3  0.4 -0.5  0.4 -1.3 -0.5 -1.7  0.4  0.3 -0.1 -0.2 -0.9  2.5  0.9 -0.3  4.  -0.1  3.6 -0.2 -0.2 -0.1 -0.5  0.5  1.7 -0.6  5.9  5.1  2.1  5.3 -1.3  0.7 -0.6  2.5 -0.9  0.2 -0.2 -0.3 -0.1  3.2 -0.3  3.4  0.8 -1.4  3.8 -0.6 -0.5 -1.  -0.5  3.9 -0.1  5.2  1.7  0.4  0.5 -1.  -0.4 -0.5  0.2  0.5 -0.7  2.4 -0.6 -0.7 -0.6  2.5  5.8  0.   1.2 -0.5 -1.  -0.5 -0.6 -0.3  4.8 -0.9  1.7  3.3  3.7  1.2 -0.3 -1.4 -1.   0.4 -0.3  2.1 -0.2 -0.6  3.5 -0.3 -0.1 -1.4 -1.4  2.4 -0.9  0.5 -1.5  0.4 -0.6 -0.9  4.1 -0.3 -0.7 -0.5 -0.5 -1.4 -0.3  9.1 -0.5 -0.   4.1 -2.2  1.3 -0.7 -0.6  1.7 -0.4  1.6  2.7 -1.6 -0.8 -0.3 -0.4  0.6  3.1 -1.7  2.5 -0.3  7.2 -0.2 -1.3 -0.8  5.2  0.3  1.5  3.  -0.2  6.2  7.5 -0.6  4.4  1.2  0.3  5.6 -1.3 -0.6 -0.1 -1.4 -0.7  1.7 -0.7 -0.1 -0.9  4.   0.5]
vy_50sample [[8 8 3 7 9 9 0 1 2 5]
 [1 2 9 0 3 4 8 6 5 7]
 [8 0 6 7 3 2 2 9 4 5]
 [8 2 3 6 1 4 9 7 0 5]
 [7 0 2 2 9 9 4 4 8 3]
 [8 6 3 3 7 2 1 9 9 4]
 [2 0 6 5 3 4 9 7 1 8]
 [7 8 9 9 1 1 4 2 3 0]
 [3 3 2 8 1 0 9 4 4 5]
 [2 1 6 9 9 4 4 7 8 8]]
vt_50sample [[8 3 6 7 4 9 0 1 2 5]
 [1 2 9 0 3 4 8 6 5 7]
 [8 0 6 7 3 2 9 1 4 5]
 [8 2 3 6 1 4 9 0 7 5]
 [7 0 2 1 5 9 4 6 8 3]
 [8 6 3 7 5 2 1 9 0 4]
 [2 0 6 3 5 4 9 7 1 8]
 [7 8 9 6 5 1 4 2 3 0]
 [6 3 2 1 0 8 7 4 9 5]
 [2 1 6 5 9 4 3 0 7 8]]
Epoch  6610: Training cost= 0.3923, Training acc= 0.7352, Validation cost= 0.4127, Validation acc= 0.7357
Epoch  6620: Training cost= 0.4075, Training acc= 0.7353, Validation cost= 0.4815, Validation acc= 0.7358
Epoch  6630: Training cost= 0.4653, Training acc= 0.7355, Validation cost= 0.4594, Validation acc= 0.7359
Epoch  6640: Training cost= 0.3976, Training acc= 0.7356, Validation cost= 0.4253, Validation acc= 0.7361
Epoch  6650: Training cost= 0.5116, Training acc= 0.7357, Validation cost= 0.4041, Validation acc= 0.7362
Epoch  6660: Training cost= 0.4636, Training acc= 0.7358, Validation cost= 0.4530, Validation acc= 0.7363
Epoch  6670: Training cost= 0.3830, Training acc= 0.7360, Validation cost= 0.3717, Validation acc= 0.7364
Epoch  6680: Training cost= 0.3984, Training acc= 0.7361, Validation cost= 0.3926, Validation acc= 0.7366
Epoch  6690: Training cost= 0.5000, Training acc= 0.7363, Validation cost= 0.3990, Validation acc= 0.7367
Epoch  6700: Training cost= 0.3584, Training acc= 0.7364, Validation cost= 0.4863, Validation acc= 0.7369
tm  [-1.8 -0.7  3.1  0.5 -1.5  1.4 -0.2 -0.5  0.7  1.3  4.  -0.5  0.2 -0.   4.1  3.6 -0.7 -0.7 -0.4 -0.4 -0.3  0.1  3.4 -0.9 -1.2  0.5  0.1 -0.2  2.6 -1.1  2.7 -0.4 -0.4  5.9 -0.5 -0.4 -0.2  2.9  1.6 -0.5  0.3  4.8 -0.1  1.2 -0.7 -0.4 -0.4 -0.2 -1.4  4.4 -1.  -0.4 -0.1  2.3 -1.4 -0.4 -0.6  1.2  2.8 -0.2  6.5 -0.6 -0.1  2.2  1.5  0.5 -0.4  1.3 -0.4 -0.5  0.4 -0.7 -0.4  0.  -2.4 -0.2  2.  -0.2  3.6 -0.1  3.  -0.2 -0.   0.   1.9  6.6 -0.6 -0.4 -0.4 -0.1 -0.6 -0.3 -1.2 -1.2 -0.7  0.4  1.5 -1.  -0.5 -0.4 -0.3  6.4  3.8  0.1 -0.8 -0.1 -1.5  2.4  1.9 -0.4 -0.  -0.7 -0.3 -0.8  1.1  4.7 -0.2 -0.3 -1.1 -0.2 -0.2  1.   0.9  0.3 -0.1  4.3 -0.2  0.2  5.  -0.7 -0.8 -1.1 -1.1 -0.6 -1.3  3.9 -0.1 -0.6 -0.5 -0.6 -0.5  2.4  0.2 -0.  -1.2 -0.2  1.9 -0.2  1.1  2.1  1.5 -0.5 -1.2 -0.3 -0.2 -0.3 -0.5 -0.4  0.9 -0.1  1.3 -0.2 -0.1 -0.5  0.  -0.4 -0.1  1.8 -0.4  0.6  1.   1.6 -0.9 -0.6 -0.3 -0.1 -0.8 -0.4  1.5 -0.4 -1.1  0.4 -0.3 -1.4 -0.4 -0.7 -1.1 -0.4 -0.8  2.9 -0.4 -0.9 -0.8 -0.4 -1.6 -0.2 -0.9 -0.1 -0.6 -1.  -0.5  1.  -0.9 -0.9  3.  -1.1  1.6  0.5 -1.3 -0.2  0.4  3.5 -0.7  8.7 -0.4  0.   0.1 -0.3  0.6  0.1 -0.6 -0.2 -0.3 -0.5  3.   1.9 -0.1  3.9  0.1 -0.5 -0.8 -0.1 -0.2 -1.1 -0.3 -0.2  1.5 -1.1  1.  -0.9 -0.5 -0.7 -0.3 -0.4 -0.1 -0.1 -0.3  0.5 -0.6 -0.2 -0.8 -0.3  0.9  0.4  2.4  5.1]
ty_50sample [[1 5 5 2 4 6 8 8 0 3]
 [7 3 9 5 4 0 8 2 1 6]
 [7 6 3 5 9 1 2 8 4 0]
 [8 6 7 2 9 4 0 1 3 5]
 [1 4 4 7 9 2 6 0 8 5]
 [2 6 0 4 7 1 5 9 3 8]
 [3 6 8 7 5 9 4 0 1 1]
 [0 9 2 2 1 1 7 5 4 6]
 [8 7 0 5 6 1 9 3 4 2]
 [6 8 0 3 9 7 7 1 2 5]]
tt_50sample [[1 5 7 2 4 6 9 8 0 3]
 [7 3 9 5 4 8 0 2 6 1]
 [6 7 3 5 9 1 2 8 4 0]
 [8 6 7 2 9 4 0 1 3 5]
 [1 4 3 7 9 2 6 0 8 5]
 [2 6 0 4 7 1 5 9 3 8]
 [3 6 8 7 5 9 4 0 1 2]
 [0 9 3 2 8 1 5 7 4 6]
 [8 7 0 5 9 1 6 3 4 2]
 [6 8 0 3 4 9 7 1 2 5]]
vm  [ 1.7 -0.6  3.   4.2 -1.2 -1.  -0.6 -0.7  0.4  1.8 -0.3 -1.  -0.2 -0.2  1.1  7.1 -0.8 -0.3 -0.2 -0.9 -0.2  0.5  4.  -0.4 -0.8 -0.9 -0.3 -0.1  5.8 -0.3 -0.8 -0.6 -0.7 -0.8  2.4 -0.9 -0.3  2.9  5.4 -0.8  0.8  3.  -0.6  2.6 -0.1 -0.6  3.1 -0.7  2.1  8.3 -0.6 -0.6 -0.4  1.6 -1.2  1.1 -0.3  1.   4.5  3.9 -1.2 -0.6 -0.3  3.9 -0.6 -0.3 -0.5  0.5  0.7 -1.1  0.7 -1.1  1.2  1.5 -1.8  0.3 -1.4  1.7  1.  -0.6 -0.9 -0.2 -0.1  0.4 -1.4  4.1  0.4 -0.1 -0.3 -0.3  0.2 -0.7 -1.2 -1.6 -0.1 -0.2 -0.3 -1.  -0.1 -0.6 -1.2  5.1 -0.7  0.2 -0.5 -0.5 -0.8 -1.  -0.2 -0.9  0.1 -0.7 -0.4 -0.4 -0.7  6.  -0.3 -0.   0.6  1.4 -0.2  3.1 -0.  -1.8  0.9  0.6 -0.9  0.3  5.2 -1.3  4.  -0.9 -0.5 -0.6 -1.6 -3.   0.7 -1.2 -1.4 -0.  -0.8 -0.2  0.3 -0.1 -1.2  3.3 -0.3 -1.1 -0.4  2.1  0.4 -0.3  5.7 -0.6  0.3 -0.2 -0.9 -0.8  0.   0.3  3.  -1.4  0.8 -0.7 -0.3 -0.6  1.2  0.8 -0.5  1.7  1.4 -0.5 -0.3 -0.6 -0.1  2.6 -1.   1.8 -1.  -0.7 -0.2 -0.2 -1.  -0.7 -0.4  0.3  4.6 -0.5 -1.1  0.9 -0.2 -0.8 -1.4 -0.9  7.1 -0.9  1.  -0.3 -0.6 -0.7 -1.1  1.3 -0.4 -0.6 -1.1  1.5 -1.  -0.   4.9 -0.4  0.7  6.1 -1.5  0.6 -0.9 -0.3 -0.2 -0.1  0.4 -0.2 -1.4 -0.9 -0.6 -0.5  2.3  4.4 -0.2  2.1 -0.6  6.5 -0.9 -1.  -0.6  3.4 -1.2 -0.   3.  -0.4  2.2  6.3 -0.2  3.5  0.9  0.2  3.9 -2.   0.  -0.1 -0.6 -0.3  2.1  0.6  5.1  0.5  0.2  7.4]
vy_50sample [[8 2 9 7 4 5 6 3 1 0]
 [3 4 4 0 9 6 6 2 7 1]
 [1 2 2 4 7 6 0 8 3 5]
 [8 1 2 7 5 6 3 9 4 0]
 [2 8 6 5 3 0 9 9 1 7]
 [6 6 4 2 2 0 7 1 5 3]
 [2 2 6 7 3 1 9 8 0 5]
 [6 0 1 4 7 9 8 3 5 2]
 [3 4 0 5 8 1 7 2 9 6]
 [2 6 3 7 1 9 8 5 0 4]]
vt_50sample [[8 2 9 7 4 5 6 1 3 0]
 [3 4 8 0 9 5 6 2 7 1]
 [1 9 2 4 7 6 0 8 3 5]
 [8 1 2 5 7 3 6 9 4 0]
 [2 6 8 5 3 0 9 1 4 7]
 [6 9 8 4 2 0 7 1 5 3]
 [4 2 6 7 3 1 9 8 0 5]
 [6 0 1 4 7 9 8 3 5 2]
 [3 4 0 5 8 7 1 2 9 6]
 [2 6 3 7 1 9 8 5 0 4]]
Epoch  6710: Training cost= 0.4006, Training acc= 0.7365, Validation cost= 0.3808, Validation acc= 0.7370
Epoch  6720: Training cost= 0.4286, Training acc= 0.7367, Validation cost= 0.4108, Validation acc= 0.7371
Epoch  6730: Training cost= 0.4423, Training acc= 0.7368, Validation cost= 0.4634, Validation acc= 0.7373
Epoch  6740: Training cost= 0.3614, Training acc= 0.7369, Validation cost= 0.4292, Validation acc= 0.7374
Epoch  6750: Training cost= 0.4343, Training acc= 0.7371, Validation cost= 0.3597, Validation acc= 0.7375
Epoch  6760: Training cost= 0.4060, Training acc= 0.7372, Validation cost= 0.4906, Validation acc= 0.7377
Epoch  6770: Training cost= 0.4477, Training acc= 0.7373, Validation cost= 0.4645, Validation acc= 0.7378
Epoch  6780: Training cost= 0.4472, Training acc= 0.7374, Validation cost= 0.4477, Validation acc= 0.7379
Epoch  6790: Training cost= 0.4626, Training acc= 0.7375, Validation cost= 0.4758, Validation acc= 0.7380
Epoch  6800: Training cost= 0.4226, Training acc= 0.7377, Validation cost= 0.4663, Validation acc= 0.7381
tm  [ 1.4 -0.8  1.5 -0.7 -1.6 -1.1 -0.5 -0.5  2.2 -0.5  4.2  0.4 -0.4 -0.9  5.4 -0.2 -0.9 -0.5  1.2  0.2 -0.5 -0.1 -1.1 -0.6  0.5  1.2 -0.2 -0.1 -0.4 -1.2  4.8 -0.1 -0.7  7.7  3.3 -0.4 -0.9  0.3  1.  -1.7 -0.4 -1.8 -1.6  3.8 -0.8  1.1 -1.1 -0.3  4.1 -1.7 -1.5 -1.1 -0.5  2.3 -0.3 -0.5 -0.4 -0.4  5.  -1.1 -0.5  0.1 -0.4  7.1  0.6  0.3 -0.3  1.5  2.5  2.  -0.3  1.3 -0.6  0.3 -2.5 -0.2 -1.6 -0.7  2.4  0.7  4.3 -0.3  0.9 -0.1 -1.1 -1.9  1.6 -0.3 -0.1 -0.3 -0.3 -1.3 -0.5 -1.5  0.3  0.1 -0.8 -2.  -0.3  0.  -0.1  1.3 -0.2  0.5 -0.  -0.2 -1.3  4.9  2.4 -0.6 -0.1 -0.1 -0.1 -1.   4.7 -0.9 -0.3  5.8 -0.5 -0.   0.4  1.6 -0.3  0.1 -0.7  6.1 -1.   0.2  4.4  4.5  2.6 -1.5 -0.1 -0.3 -2.   4.1 -0.2  0.5  0.3 -0.6 -0.4  0.4 -0.1 -0.3 -0.9  0.  -0.8 -0.8 -1.3 -0.9  4.1 -0.3  2.9 -0.3 -0.  -0.3 -0.2 -0.6  0.7 -0.2  0.7 -1.2  0.7 -0.6  2.  -0.6  1.2  5.2 -0.1 -0.3 -0.9 -0.7 -0.  -0.3 -0.6  6.6 -0.4 -0.3  1.1  0.5  0.8 -0.6 -1.4 -0.5  1.9 -1.1  3.4 -0.9 -0.5  4.6 -0.1 -0.  -1.  -1.   4.  -1.2 -0.4 -1.5 -0.4  0.3 -0.7  2.2 -0.3 -0.9 -0.8 -1.7 -0.2  0.4  3.3 -0.6 -0.1  0.1 -2.  -0.4 -0.5 -0.8 -0.5 -0.5  0.3 -0.  -0.6 -0.4 -0.3 -0.4 -0.6 -0.6 -0.3  0.3 -0.3  8.8 -1.  -0.5 -0.6  1.2  2.4  0.5  2.1 -0.7  6.2  6.  -0.5  3.7  1.1 -0.1 -0.2 -0.2 -0.7 -0.4 -1.4 -0.6 -1.  -0.6  1.4 -0.2  2.  -0.9]
ty_50sample [[0 7 4 4 2 9 6 8 5 5]
 [6 4 9 9 7 2 2 3 0 5]
 [5 4 4 6 6 2 2 1 9 3]
 [8 3 2 5 4 0 7 6 1 9]
 [8 8 2 4 0 7 6 1 9 3]
 [7 3 1 6 9 8 5 2 4 4]
 [3 6 5 4 8 1 9 2 7 7]
 [5 6 0 9 4 7 1 3 3 2]
 [4 0 9 9 6 5 3 8 7 2]
 [1 8 2 5 0 6 4 9 3 7]]
tt_50sample [[0 3 7 4 2 9 6 8 5 1]
 [6 4 1 9 7 2 0 3 8 5]
 [5 8 4 6 0 7 2 1 9 3]
 [8 3 2 5 4 0 7 6 1 9]
 [8 5 2 4 0 7 6 1 9 3]
 [7 3 1 9 6 8 5 2 4 0]
 [3 6 5 4 8 1 9 2 0 7]
 [5 6 0 9 4 7 1 3 8 2]
 [4 0 9 6 5 1 3 7 8 2]
 [1 8 2 5 0 6 4 3 9 7]]
vm  [ 1.  -0.6  4.5  0.2 -1.5 -1.2 -0.6 -0.9 -0.9  2.7 -2.  -0.4 -0.7 -0.3  7.3  0.6 -0.6 -0.1 -0.3 -1.  -0.3 -0.2  4.  -0.2 -0.3 -0.9 -0.3 -0.2  1.8  0.7 -0.6  0.6  0.6  3.   2.  -0.6  1.  -0.8 -0.9 -0.2 -0.2  1.8 -0.5 -0.3 -0.5 -0.3  0.5  0.5  2.5  9.2 -0.5 -0.7 -1.4 -0.3 -0.8 -0.7 -0.4 -0.9  1.5  2.8 -0.5 -0.1 -0.6  0.9 -0.4 -0.6 -0.2 -0.2  1.6 -0.5 -0.1 -0.4  0.8 -0.1 -2.8  0.5 -0.7  1.7  2.7 -0.6 -1.9  0.2 -0.3  0.3 -1.1  2.1  1.2 -0.2 -0.3 -0.3 -0.3 -0.5 -1.1 -0.9 -0.6 -0.3 -0.5 -1.1 -0.1 -0.5 -1.   7.8 -0.2  0.7 -0.5 -0.1 -1.5 -0.6 -1.3 -0.8  0.5 -0.5 -0.2 -0.6  0.1  1.1 -0.4  1.2 -0.  -0.2 -0.4  1.3  0.3 -1.4 -0.   7.2 -0.4  2.8  0.9 -0.8  4.6 -0.9 -0.2 -0.2 -0.4 -0.2 -0.3 -1.  -1.  -0.3  0.5 -0.5  2.1  0.7 -1.3  2.3 -0.3 -1.1 -1.4  1.8  1.6 -0.   4.3 -0.2 -0.2  0.  -0.7 -0.6 -1.1 -0.7  1.6  1.   1.3 -0.8  0.  -0.  -0.3  1.9 -0.2 -0.1  1.  -0.5 -0.6 -0.  -0.1  5.8 -0.9 -0.3  4.7  0.6  1.  -0.3 -0.1 -0.7 -0.3 -0.3  2.3 -0.6 -0.9 -0.5 -0.1 -1.1 -0.7 -1.   3.6 -0.3 -0.8 -0.1 -0.5 -0.8 -0.7  1.7 -0.  -0.1 -0.5 -1.3 -1.   0.1  7.  -0.4  0.8  1.7 -1.3  1.4 -0.2  0.1  2.7 -0.   1.5 -0.2 -1.6 -0.9 -0.2 -0.7  3.6  2.2 -1.   0.3 -0.3  3.7 -0.3 -0.  -0.6  4.5 -0.5 -0.9  3.5 -1.3  2.3  6.  -0.6  3.6  0.4 -0.1  6.8 -0.8 -0.1 -0.3 -0.7  0.3  3.8  0.2 -0.7 -0.5  1.1  5.3]
vy_50sample [[7 8 6 4 9 0 2 1 3 3]
 [3 7 2 2 5 8 9 0 1 4]
 [0 2 9 1 3 3 5 5 6 4]
 [7 3 4 4 9 0 1 6 6 5]
 [3 7 2 1 4 6 0 0 5 8]
 [4 0 7 9 1 6 8 3 5 2]
 [9 9 5 7 7 2 4 0 1 3]
 [8 8 8 1 5 0 2 2 6 4]
 [2 9 6 1 5 8 3 4 0 7]
 [4 8 5 8 2 3 9 7 0 6]]
vt_50sample [[7 8 6 4 9 0 2 5 1 3]
 [3 7 2 6 8 5 9 0 1 4]
 [0 2 9 1 8 3 5 7 6 4]
 [3 7 8 4 9 0 1 6 2 5]
 [3 7 2 1 4 6 0 9 5 8]
 [4 0 7 9 1 6 8 3 5 2]
 [9 5 6 8 7 2 4 0 1 3]
 [7 8 3 1 5 0 2 9 6 4]
 [2 9 6 1 5 8 3 4 0 7]
 [4 8 1 5 2 3 9 7 0 6]]
Epoch  6810: Training cost= 0.5098, Training acc= 0.7378, Validation cost= 0.4810, Validation acc= 0.7382
Epoch  6820: Training cost= 0.3851, Training acc= 0.7379, Validation cost= 0.4141, Validation acc= 0.7384
Epoch  6830: Training cost= 0.3819, Training acc= 0.7380, Validation cost= 0.3966, Validation acc= 0.7385
Epoch  6840: Training cost= 0.4067, Training acc= 0.7382, Validation cost= 0.4660, Validation acc= 0.7387
Epoch  6850: Training cost= 0.5164, Training acc= 0.7383, Validation cost= 0.4269, Validation acc= 0.7388
Epoch  6860: Training cost= 0.3931, Training acc= 0.7384, Validation cost= 0.3989, Validation acc= 0.7389
Epoch  6870: Training cost= 0.4100, Training acc= 0.7385, Validation cost= 0.3922, Validation acc= 0.7390
Epoch  6880: Training cost= 0.4615, Training acc= 0.7387, Validation cost= 0.4070, Validation acc= 0.7391
Epoch  6890: Training cost= 0.4382, Training acc= 0.7388, Validation cost= 0.4695, Validation acc= 0.7393
Epoch  6900: Training cost= 0.4109, Training acc= 0.7389, Validation cost= 0.4104, Validation acc= 0.7394
tm  [-0.6 -0.2  2.4 -1.  -1.5 -0.7 -0.3 -0.5 -0.6 -0.7 -0.8  1.1 -0.9 -0.7  6.3  1.6 -0.5 -0.3 -0.3 -0.3 -0.1  0.2 -0.1 -0.2 -1.  -0.1 -0.3 -0.3  3.1  0.8  4.  -0.5  0.8  7.8 -0.7 -0.1  0.2 -0.5 -1.1 -0.7 -0.1 -0.7 -0.   0.4 -0.5 -0.1 -0.4  1.7 -0.2 -0.3 -1.1 -0.8 -0.2 -0.8 -1.6 -0.8 -0.3 -0.4 -0.3 -0.9  1.2 -0.  -0.4 -0.3  0.8 -0.4 -0.4  0.4  1.2  1.7 -0.2 -1.  -0.2 -0.4 -2.  -0.2 -0.3 -0.4  2.8 -0.1  2.3  0.1 -0.3  0.3 -0.5 -0.4  1.7 -0.4  2.1 -0.2 -0.3  0.5  0.3 -0.6 -0.5  0.1 -0.1 -1.1 -0.5 -0.1  1.6  4.2 -0.2  0.1 -0.2  0.3 -1.2  4.1 -0.3 -0.5 -0.2 -0.7 -0.2 -0.4 -0.5  5.6  0.2 -0.  -0.5 -0.4 -0.3  0.9  1.4 -0.2 -0.4  6.8  2.5  5.  -0.   2.5  3.1 -0.8  1.6 -0.4 -0.5  8.3 -0.1 -0.2 -0.2 -1.   2.4  0.3  2.6  0.2 -1.2  1.  -0.2 -0.7 -1.2  1.8  2.6 -0.2  0.5  0.5 -0.4 -0.1 -0.8 -0.6 -1.  -0.9 -0.2  1.3  2.  -0.2  1.6 -0.6  2.3  3.7  0.5 -0.4 -0.6 -0.3 -1.  -0.1 -0.3  4.6 -1.3 -0.2  5.2  1.2 -0.1  1.1 -0.5 -1.3 -1.1 -0.5  1.1 -0.4 -0.8 -0.6 -0.4 -0.4 -0.6 -1.3  0.8  1.1 -0.5  0.1 -0.4 -1.2 -0.3  0.6 -0.3 -0.5  0.2 -1.2 -0.  -0.3  2.  -0.4 -0.4  4.6 -1.1  3.2 -0.1 -0.1  0.7 -0.2  2.3 -0.  -1.3 -0.2 -0.3 -0.4  1.4  2.7 -0.9 -0.1 -0.1  2.1 -0.1 -0.  -0.3  1.5 -0.6 -0.1  0.3 -0.9  2.3  3.2 -0.6  2.4 -0.4 -0.6  0.6 -0.3 -0.5 -0.3 -0.4 -0.2 -0.6 -0.2 -0.6 -0.5  3.5 -0.1]
ty_50sample [[7 6 4 3 1 9 8 5 2 0]
 [4 1 6 9 7 2 8 0 5 3]
 [1 1 9 8 8 2 5 3 6 4]
 [1 5 8 9 9 3 4 0 6 2]
 [0 0 9 9 8 2 2 1 5 4]
 [9 7 5 2 8 4 0 6 3 1]
 [0 5 1 4 9 2 7 8 3 6]
 [1 8 0 4 5 9 7 7 2 6]
 [2 9 3 8 4 4 7 5 6 0]
 [0 5 7 8 1 9 4 3 6 2]]
tt_50sample [[7 6 4 3 1 9 8 5 2 0]
 [4 1 6 9 7 2 8 0 5 3]
 [1 0 9 7 8 2 5 3 6 4]
 [1 5 8 7 9 3 4 0 6 2]
 [0 7 6 9 8 2 3 1 5 4]
 [9 7 5 2 8 4 0 6 3 1]
 [0 5 1 4 9 2 7 8 3 6]
 [8 1 0 4 5 9 7 3 6 2]
 [2 9 3 8 1 4 7 5 6 0]
 [0 5 7 8 1 9 4 3 6 2]]
vm  [-0.6 -0.1 -0.9  5.9 -0.7 -0.5 -0.7 -0.3  2.5 -1.1  8.4 -0.4  0.3 -0.  -2.3  7.1 -0.4 -0.7 -0.2 -1.5 -0.5  0.1 -0.8 -0.5 -1.3  1.4 -0.3 -0.4  2.2 -0.9  3.4 -1.8 -0.3 -0.1 -0.1 -0.3 -0.1  6.2 10.1 -1.1 -0.1  0.5 -0.3  3.1 -0.3 -0.2  6.  -1.   0.3 -1.3 -0.5 -0.7  2.2  1.2 -1.5  5.7 -0.3  2.4  2.2 -0.7 -0.9 -0.8  0.1  2.9  0.  -0.5 -0.3  3.2 -0.6 -0.2 -0.6 -0.9 -0.3 -0.3  1.3  0.1 -0.6 -0.3 -0.   0.2 11.7 -0.5 -0.6 -0.2 -0.3  2.  -0.1 -0.5  1.6 -0.4 -0.6 -0.4 -0.1 -0.6  0.6  0.1  0.2 -0.6 -0.5 -0.4  2.7 -1.5 -0.2 -0.3 -0.8  0.2  0.6  2.9  3.8 -1.8 -0.4  0.  -0.4 -0.5 -0.2  4.9 -0.1 -0.2 -0.6  1.7 -0.4  5.8  0.6 -0.1 -0.3 -2.2 -0.1  0.2  5.5 -0.1 -0.3 -0.9 -0.3 -0.2  1.1 -0.1 -0.2 -0.7  2.1 -0.4 -0.9  0.8 -0.6 -0.4 -0.7 -0.1 -0.2 -0.3  5.1 -0.2 -0.3 -0.2 -0.2 -0.9 -0.4 -0.3 -0.7 -0.1  2.7 -0.4 -0.  -1.2 -0.7 -0.5  0.3 -0.4  2.3  0.1  0.3  2.1 -0.4  0.7 -0.7 -0.4 -0.5 -1.7 -0.1  1.3 -1.9 -1.  -1.2  0.4 -0.8 -1.1 -0.4 -0.7  3.2  0.7 -0.6  6.3 -0.4 -0.3 -1.5 -0.6  4.7 -0.7  2.3 -0.4 -0.1 -0.4 -0.3  0.4 -0.6 -1.1 -0.5  1.5  2.3  1.2 -2.2 -0.5 -0.3  5.1 -0.9  2.2 -0.4 -0.1 -0.6 -0.6 -0.4 -0.4  0.8 -0.6  0.4 -0.6 -0.6  2.5  1.8  2.9 -0.2  5.6 -1.6 -0.9 -0.5 -1.5 -0.2  4.6  0.9  1.8 -0.2  2.8 -0.1  1.5 -0.6 -0.3 -1.8 -2.1  0.1 -0.2 -0.9 -0.9 -2.4 -0.3  8.1  1.7  1.7  2.5]
vy_50sample [[2 9 5 3 4 1 8 8 0 0]
 [3 2 6 7 4 9 9 0 5 1]
 [6 0 8 1 9 3 7 5 4 2]
 [8 1 0 3 7 7 9 6 4 5]
 [1 0 7 5 9 9 3 4 8 2]
 [3 5 7 2 8 0 9 4 1 1]
 [5 8 2 9 3 0 7 6 1 4]
 [6 9 9 0 7 5 5 5 4 2]
 [8 4 0 6 5 9 2 7 1 3]
 [1 0 2 8 7 9 6 6 5 3]]
vt_50sample [[2 9 5 3 4 1 8 6 7 0]
 [3 2 6 7 4 9 8 5 0 1]
 [6 0 8 1 9 3 7 5 4 2]
 [8 1 0 3 7 2 9 6 4 5]
 [1 0 5 7 6 9 3 4 8 2]
 [3 5 7 2 8 0 9 4 6 1]
 [5 8 2 9 3 0 7 6 1 4]
 [6 9 0 1 3 7 5 8 2 4]
 [8 4 0 6 5 9 7 2 1 3]
 [1 0 2 8 7 9 6 3 4 5]]
Epoch  6910: Training cost= 0.4593, Training acc= 0.7390, Validation cost= 0.3577, Validation acc= 0.7395
Epoch  6920: Training cost= 0.4058, Training acc= 0.7392, Validation cost= 0.4491, Validation acc= 0.7397
Epoch  6930: Training cost= 0.3768, Training acc= 0.7393, Validation cost= 0.3750, Validation acc= 0.7398
Epoch  6940: Training cost= 0.4153, Training acc= 0.7394, Validation cost= 0.4130, Validation acc= 0.7399
Epoch  6950: Training cost= 0.4241, Training acc= 0.7396, Validation cost= 0.4530, Validation acc= 0.7401
Epoch  6960: Training cost= 0.3888, Training acc= 0.7397, Validation cost= 0.4335, Validation acc= 0.7402
Epoch  6970: Training cost= 0.4618, Training acc= 0.7398, Validation cost= 0.4475, Validation acc= 0.7403
Epoch  6980: Training cost= 0.4171, Training acc= 0.7399, Validation cost= 0.4097, Validation acc= 0.7404
Epoch  6990: Training cost= 0.4206, Training acc= 0.7400, Validation cost= 0.4142, Validation acc= 0.7405
Epoch  7000: Training cost= 0.4180, Training acc= 0.7401, Validation cost= 0.3955, Validation acc= 0.7406
tm  [-1.6 -0.  -0.9 -1.  -0.4 -0.1 -0.6 -0.5 -0.3 -0.4  2.  -0.3  1.3 -0.2  0.4  3.2 -0.6 -0.2 -0.8  2.9 -0.7 -0.6  0.2 -1.  -1.   0.7 -0.3 -0.2  0.3 -0.8 -0.1 -0.4  1.  -2.3 -0.3 -0.4 -0.   0.9 -2.9 -0.8 -0.6 -1.8 -1.2 -0.9 -0.6 -0.1 -1.8 -0.8 -0.9 -0.2 -0.5 -1.2 -1.2  6.6 -1.4  0.5 -0.2 -0.4  2.9  1.7  8.4  1.3 -0.3  0.3 -0.2  0.1 -0.6  2.2 -0.7  1.5 -0.3 -0.4 -0.1 -0.3 -3.8 -0.5  1.4 -0.9  2.7 -0.1 -2.1 -0.4  0.4 -0.4  1.6 -1.9 -0.5 -0.6  0.5  0.9 -1.  -0.5  0.2 -0.3 -1.   0.2 -0.4 -1.5 -0.6 -0.2  0.7 -1.6  3.4  0.9 -0.4  0.3 -2.5 -0.   0.6  0.5 -0.5 -0.2 -0.1 -0.2  2.5  1.6 -0.3 -0.1 -0.7  1.  -0.4 -0.7  1.1  0.  -0.8 -0.  -0.  -1.1  1.   6.   1.7 -1.1 -0.2 -0.5 12.5  8.7 -0.6  1.1  0.7 -0.5 -0.4 -0.2 -0.9 -0.4 -0.6 -0.8 -0.1  1.3  0.7 -0.3  3.  -0.1 -0.5 -0.8 -0.4 -0.4 -0.2 -0.  -1.2 -0.8 -0.3  3.1  0.5 -0.6 -1.3 -0.6  3.1  5.7 -0.5 -0.3 -0.6 -0.4 -0.4 -0.  -0.1  0.8 -1.6 -1.  12.1 -0.4  1.4  0.  -0.1 -1.   1.6 -0.1 -1.2  0.6 -1.   4.5 -0.4 -0.2 -0.1 -0.9 -1.8 -0.2 -1.6 -0.3 -0.5 -0.3 -0.   1.3 -0.7 -0.7  1.9 -2.8 -0.8  0.2  6.3 -0.4 -0.5  0.3 -1.7  5.  -0.5 -0.3  4.8 -0.3 -0.3 -0.2  0.  -0.2 -0.3 -0.8  2.   1.2 -0.   4.   0.3  1.9  1.3  1.5 -0.5  4.3  1.1  3.2  0.5 -1.7  1.1  2.8 -0.9  2.2 -0.1 -0.7  7.   3.1 -0.1  0.7 -0.7 -0.3  3.5 -0.7 -2.4  0.6  0.6 -1.4]
ty_50sample [[6 1 3 2 8 4 0 9 7 5]
 [5 7 2 8 9 1 6 4 3 0]
 [7 7 2 5 3 3 0 1 6 8]
 [5 7 7 2 6 6 1 8 4 9]
 [4 5 6 9 0 0 7 2 1 3]
 [5 8 2 9 7 3 4 1 6 0]
 [4 5 0 0 1 3 8 7 2 6]
 [4 4 0 6 7 3 1 9 2 5]
 [8 2 4 1 1 9 0 7 5 3]
 [0 3 8 8 5 6 6 2 1 9]]
tt_50sample [[6 1 3 2 8 4 0 9 7 5]
 [5 7 2 8 9 1 6 4 3 0]
 [7 4 2 9 5 3 0 1 6 8]
 [5 3 7 2 0 6 1 8 4 9]
 [4 5 6 9 0 8 7 2 1 3]
 [5 8 2 9 7 3 4 1 6 0]
 [4 5 0 9 1 3 8 7 2 6]
 [4 8 0 6 7 3 1 9 2 5]
 [8 2 4 1 6 9 0 7 5 3]
 [0 3 8 4 7 5 6 2 9 1]]
vm  [ 1.8 -0.6  4.6  7.4 -1.3 -1.  -0.4 -0.6 -0.7 -0.1  6.6 -0.4 -0.4 -0.6  0.7  1.7 -0.3 -0.1  0.2 -1.6 -0.5  0.6 -0.4  1.2 -0.8 -0.1 -0.2 -0.3 -0.8  0.9  4.6 -0.2  1.8 10.8  0.9  2.7  1.8 -0.4  0.3 -0.5 -0.4  1.8 -0.2 -0.9 -0.1 -0.4  6.8  0.1  4.  -0.4 -1.3 -0.7  1.2 -0.6 -0.4  0.8 -0.5 -0.1 -0.8 -1.1 -2.   0.2 -0.3  2.7  0.9 -0.8 -0.1 -0.1  0.8 -0.4 -0.6 -0.  -0.3 -0.8  1.6 -0.4 -0.7  0.6  1.3 -0.7 16.4  0.3 -1.1  0.2 -1.4  2.   1.9 -0.3 -0.1 -0.2 -0.2  0.   0.1 -0.4  0.1  0.3 -0.   0.3  0.3 -0.1  0.3  6.6 -1.1 -0.3 -0.4 -0.1  0.7  4.1  3.2 -1.8 -0.2 -0.1 -0.1 -0.1  0.1 -0.1 -0.3  0.   0.3 -0.4 -0.2  7.2  1.1  0.  -0.2  0.7 -0.1  4.8 -0.5 -1.3  6.5 -0.8  0.2 -0.1  3.2 16.3 -0.2 -0.6 -0.7 -1.  -0.4 -0.2 -0.   1.4 -0.4  1.4 -0.2 -1.  -1.   1.2 -1.  -0.   1.1 -0.5 -0.1 -0.  -0.1 -0.6 -1.5 -0.3  1.6  3.4 -0.1 -0.6  1.9 -0.7 -0.6 -0.2 -0.1  2.9 -0.3 -0.5  0.3  0.  -0.1  4.9 -1.4  2.6  2.2 -0.3 -0.3 -0.  -0.3 -1.  -1.3 -0.8  6.6 -0.7  0.6 -0.5 -0.3 -0.8 -1.2 -0.8  9.4  1.4  2.9  0.2 -0.2 -0.  -0.3 -0.2  0.8  0.3 -0.9  3.2  0.7  0.  -1.  -0.5 -0.3  1.  -1.  -0.4 -0.3 -0.4  4.9 -0.1  1.3 -0.5 -0.5 -1.  -0.3 -0.7  4.4 -0.6 -0.4 -0.3 -0.2  3.3  1.5 -0.5 -0.5 -0.7 -0.1 -0.9  2.3  2.7  1.3 10.8 -0.6  5.4 -0.3 -0.2 -3.1 -1.7  0.5 -0.1 -0.6  0.3 -3.  -0.   0.3  1.  -0.2  7.6]
vy_50sample [[6 7 9 0 0 4 5 3 3 8]
 [1 6 7 4 0 3 5 8 2 9]
 [3 4 5 9 7 8 1 2 0 6]
 [8 7 9 1 3 3 6 0 5 2]
 [5 5 1 1 0 0 2 2 7 6]
 [6 5 2 9 8 1 3 4 7 0]
 [1 3 4 6 0 0 7 2 5 8]
 [2 9 7 6 6 5 4 3 1 0]
 [6 4 4 7 1 8 5 0 2 9]
 [2 1 0 3 7 4 5 6 8 9]]
vt_50sample [[6 9 7 0 2 4 5 3 8 1]
 [6 1 0 4 7 3 5 8 2 9]
 [4 3 5 9 7 8 1 2 0 6]
 [8 7 9 4 1 3 6 0 5 2]
 [8 5 4 1 0 9 2 3 7 6]
 [6 5 2 9 8 1 3 4 7 0]
 [1 3 4 6 0 9 2 7 5 8]
 [2 9 7 6 8 5 4 3 1 0]
 [6 4 3 7 1 8 5 0 2 9]
 [2 1 0 3 7 4 5 6 8 9]]
Epoch  7010: Training cost= 0.5347, Training acc= 0.7402, Validation cost= 0.4980, Validation acc= 0.7408
Epoch  7020: Training cost= 0.4482, Training acc= 0.7403, Validation cost= 0.4443, Validation acc= 0.7409
Epoch  7030: Training cost= 0.4033, Training acc= 0.7405, Validation cost= 0.3990, Validation acc= 0.7410
Epoch  7040: Training cost= 0.4144, Training acc= 0.7406, Validation cost= 0.4271, Validation acc= 0.7411
Epoch  7050: Training cost= 0.3832, Training acc= 0.7407, Validation cost= 0.4132, Validation acc= 0.7413
Epoch  7060: Training cost= 0.3815, Training acc= 0.7408, Validation cost= 0.3622, Validation acc= 0.7414
Epoch  7070: Training cost= 0.4265, Training acc= 0.7410, Validation cost= 0.4170, Validation acc= 0.7415
Epoch  7080: Training cost= 0.3925, Training acc= 0.7411, Validation cost= 0.4168, Validation acc= 0.7416
Epoch  7090: Training cost= 0.4722, Training acc= 0.7412, Validation cost= 0.4329, Validation acc= 0.7417
Epoch  7100: Training cost= 0.4214, Training acc= 0.7413, Validation cost= 0.4540, Validation acc= 0.7418
tm  [ 1.3 -0.1 -0.3 -1.8 -1.3 -0.5 -0.4 -0.7 -0.5 -1.1 10.2 -0.4  0.7 -0.4  5.   0.4  1.8 -0.3  0.1  0.8 -0.4 -0.4 -1.2  1.5 -1.4  3.1 -0.6 -0.4 -1.5 -0.6  5.3 -0.2 -0.1  6.   2.9  1.7  1.5  3.3 -0.7 -1.2 -0.5 -0.7 -0.5  2.8 -1.1 -0.6 -1.7 -1.   2.6 -2.1 -1.1 -1.4 -0.8  9.3  0.4 -0.3 -0.8 -0.4  0.2 -1.5  2.5  0.3 -0.5  4.9 -0.2 -0.8  0.1  2.2 -0.   0.2 -0.6  4.  -1.  -0.7 -3.4 -0.  -0.2 -0.6  2.4 -0.2  3.5 -0.  -0.1 -0.3 -1.  -0.8  1.6 -0.4  1.2 -0.1 -0.5 -0.9 -0.2  1.  -0.9  0.1 -0.2 -1.1  0.1 -0.2  2.6 -0.2 -0.2 -0.4  1.1 -0.2 -2.6  5.3  4.6  1.9 -0.9  1.  -0.2 -0.3  4.1 -1.3 -0.5  0.6 -0.2 -0.2 -0.3 -0.3 -0.2  1.4 -0.7  5.7 -0.4 -2.2 -0.5  6.2  1.7 -0.3 -0.4  0.1  0.8  7.3 -0.5  0.   2.2 -0.8 -0.8 -0.8 -1.  -0.   1.6 -0.8 -0.5 -0.1 -0.  -0.9  2.7 -0.1 -0.2 -0.6 -0.9 -0.1  0.4 -0.4  0.1 -0.6  1.7 -0.5 -0.4 -0.3  1.5 -0.7 -0.9  0.9  0.1 -0.7 -0.8 -0.   0.1 -0.2 -0.8  3.  -0.6 -0.7  4.8 -0.6 -0.2  0.3 -0.  -1.3  1.6 -1.1  1.3 -0.7  0.5  3.1 -0.2 -0.2  2.  -1.2  0.4  0.7 -1.7 -0.2 -0.4  2.4  1.  -0.2 -0.4 -0.6 -0.9 -2.5 -0.1  0.  -0.9 -0.4 -0.2 -1.1 -0.4  0.1  0.6 -0.5 -0.3 -0.5 -0.6 -0.2 -0.   0.  -0.1 -1.3 -0.3 -1.3  2.   0.9 -0.3  2.7 -1.   1.4 -0.5 -0.6  3.5  2.5  3.1 -2.1  1.7 -0.3 -1.1  0.4 -0.8 -0.1 -0.2  2.  -0.1 -0.4 -0.4 -0.1 -0.8  0.2 -0.4 -0.  -0.2 -1.2]
ty_50sample [[0 2 3 4 7 6 5 1 9 8]
 [4 3 0 9 2 1 1 5 6 7]
 [6 7 1 5 3 8 0 9 4 2]
 [0 2 5 4 6 3 1 9 8 8]
 [3 6 1 7 4 9 2 5 0 8]
 [9 4 8 7 3 6 0 1 5 2]
 [7 1 9 6 6 3 8 0 4 5]
 [0 7 8 2 3 1 6 5 4 9]
 [4 4 8 5 3 6 6 1 1 9]
 [6 3 2 1 0 7 4 9 5 8]]
tt_50sample [[0 2 3 4 7 6 5 1 9 8]
 [4 3 0 9 2 8 1 5 6 7]
 [6 7 1 5 3 8 9 0 4 2]
 [0 2 5 4 6 3 1 9 7 8]
 [3 6 1 7 4 9 2 5 0 8]
 [9 4 8 3 7 6 0 1 5 2]
 [7 1 9 2 6 3 8 0 4 5]
 [0 7 8 2 3 1 6 5 9 4]
 [4 8 0 5 3 6 7 2 1 9]
 [6 3 2 1 0 7 4 9 5 8]]
vm  [ 0.8  0.9  1.  -1.  -1.4 -0.8 -0.4 -0.5 -1.2 -1.1 -0.8  0.9 -0.6 -0.3  5.8  0.6  0.1 -0.1  0.6  0.5 -0.5 -0.2  0.1 -0.1 -0.9  1.1 -0.3 -0.4  0.2 -0.1  1.7 -0.3 -0.1  2.4 -0.2  0.6  1.4  3.   3.5 -1.  -0.2 -2.1 -0.5  5.6 -1.1 -0.  -0.5  0.7  1.8 -0.2 -0.7 -1.  -0.2  0.9 -0.8 -0.3 -0.6 -1.   0.4  0.4  0.4  0.6 -0.1  0.9 -0.3 -0.8 -0.3 -0.3  0.3  2.9 -0.1 -0.2  0.7 -0.1 -2.3  0.8 -0.5 -0.7  1.8 -0.1 -1.1 -0.1  0.3 -0.2 -1.  -2.1  2.2 -0.6  2.7 -0.2 -0.2 -0.5  0.7  0.9 -0.7 -0.2 -0.6 -1.  -0.6 -0.2  2.7  0.4 -0.3 -0.   1.  -0.1 -1.5  1.6 -0.5 -0.3 -0.2 -0.6 -0.  -0.4  0.5  0.4 -0.   1.7  0.1 -0.2 -0.1 -0.1 -0.5 -0.6 -0.6  5.9  1.2  1.7 -0.1  5.6 -0.  -0.4  1.3  0.1 -2.7 -2.6  0.3 -0.2  2.4 -0.2  0.4 -0.7 -0.1 -0.2 -0.2  0.1 -0.3 -0.6 -1.4 -0.6  2.1  0.1  4.5  0.5 -0.6 -0.2 -0.3 -0.2  2.  -0.9 -0.3 -1.2  0.8 -0.4 -0.  -0.1  2.4  3.5  1.5 -0.2 -0.3 -0.5 -0.5  0.7 -0.3  5.7  0.3 -0.4 -0.4 -0.1  2.  -0.3 -0.  -1.  -0.1 -0.5  1.9 -0.5 -0.4  1.5 -0.2 -0.  -0.2 -1.5  2.   0.1 -0.6 -0.  -0.5 -0.3  0.   0.8 -0.3 -0.7 -0.7 -1.1 -1.  -0.   6.8 -0.4 -0.4  0.7 -0.9  0.1  1.  -0.2 -1.2 -0.3  1.6 -0.1 -1.3  0.1  0.2 -0.7 -1.   1.5 -1.   0.3  0.3  3.6 -0.8  0.4 -0.6  4.5  0.1  0.9  0.9 -0.8  3.2  6.7 -0.5  4.3 -0.5 -0.4  4.8 -0.6 -0.3 -0.5 -0.3 -0.3  1.4 -0.2  3.8 -0.5  2.6 -1. ]
vy_50sample [[3 7 8 8 0 9 2 1 6 5]
 [6 6 5 5 0 0 7 2 9 8]
 [4 8 9 5 7 2 3 0 1 6]
 [1 9 5 3 7 8 2 0 4 6]
 [2 6 6 5 4 0 3 8 7 9]
 [0 5 5 7 2 1 4 6 8 9]
 [6 7 4 1 8 2 9 5 3 0]
 [6 8 7 3 5 0 1 9 4 2]
 [6 1 3 5 2 7 0 8 4 4]
 [2 2 3 5 5 0 8 6 6 7]]
vt_50sample [[3 4 7 8 9 0 2 1 6 5]
 [3 6 4 5 0 1 7 2 9 8]
 [4 8 9 5 7 2 3 0 1 6]
 [1 9 5 3 7 8 2 4 0 6]
 [2 6 1 5 4 0 3 8 7 9]
 [0 3 5 7 2 1 4 6 8 9]
 [6 7 4 1 8 2 9 5 3 0]
 [6 8 7 3 5 0 1 4 9 2]
 [6 1 3 5 2 7 0 8 9 4]
 [2 3 1 9 5 0 8 4 6 7]]
Epoch  7110: Training cost= 0.4110, Training acc= 0.7414, Validation cost= 0.4412, Validation acc= 0.7420
Epoch  7120: Training cost= 0.3941, Training acc= 0.7416, Validation cost= 0.3831, Validation acc= 0.7421
Epoch  7130: Training cost= 0.4561, Training acc= 0.7417, Validation cost= 0.3674, Validation acc= 0.7422
Epoch  7140: Training cost= 0.4900, Training acc= 0.7418, Validation cost= 0.4473, Validation acc= 0.7423
Epoch  7150: Training cost= 0.4547, Training acc= 0.7419, Validation cost= 0.4785, Validation acc= 0.7424
Epoch  7160: Training cost= 0.4527, Training acc= 0.7420, Validation cost= 0.4183, Validation acc= 0.7425
Epoch  7170: Training cost= 0.4802, Training acc= 0.7421, Validation cost= 0.4396, Validation acc= 0.7426
Epoch  7180: Training cost= 0.3951, Training acc= 0.7422, Validation cost= 0.4149, Validation acc= 0.7427
Epoch  7190: Training cost= 0.4519, Training acc= 0.7423, Validation cost= 0.4192, Validation acc= 0.7429
Epoch  7200: Training cost= 0.4160, Training acc= 0.7424, Validation cost= 0.4367, Validation acc= 0.7430
tm  [-1.4 -0.1  2.9 10.5 -1.1 -0.6 -0.1 -0.3 -0.5 -0.5 -4.2  3.  -1.1 -0.2 -1.5  1.3 -0.4 -0.1 -0.1 -0.9 -0.2 -0.2  4.6 -0.3 -1.3 -0.1 -0.3 -0.2  3.4 -0.4 -1.8 -0.5 -0.4 -2.6 -1.3 -0.6 -0.2  2.7  9.6 -0.2  0.5  1.9 -0.1  1.3 -0.3 -0.9  6.2  1.5 -0.9  7.2 -0.4  1.1  2.4 -2.1 -1.3  4.3 -0.2  2.6  0.1  4.2  0.1 -0.9  0.7 -0.1 -1.4 -1.  -0.8 -0.7 -0.  -0.  -0.2 -0.7  3.   0.5  1.7 -0.1  0.4 -0.4  0.5 -0.4 -0.   0.7 -0.9 -0.3 -0.3  4.  -0.2 -0.2  1.9 -0.1  3.6 -0.4 -0.4 -0.4  1.6 -0.7  2.4 -0.1 -0.5 -0.4  0.3  2.9  0.  -0.5 -0.6 -0.6  0.3 -2.1 -2.2 -1.3  0.4 -0.8 -0.8  0.2 -0.3  6.8  0.7 -0.5  0.4  1.  -0.1  4.8 -0.  -0.9  3.  -1.5  3.  10.3  2.5 -1.1 -0.7 -0.2 -0.6 -0.5 -1.3 -4.8  1.3 -1.  -0.7  2.1  2.1 -0.4  2.3 -0.3 -0.9  0.6  0.5 -0.5  1.6  0.3 -1.3 -0.5  2.2  2.3 -0.2 -0.  -0.5 -0.7  2.9 -0.3 -0.2 -1.3  0.4 -0.  -1.7 -0.8  1.3  1.5 -0.5  3.7 -0.2 -0.  -0.9 -0.5 -0.  -0.2 -0.7  4.3 -2.   1.2 -0.3  0.4 -0.1 -1.3 -0.9  1.6  0.2 -0.  -1.   2.2 -0.5 -0.7 -1.6 -1.3  2.4 -0.1  4.4  0.4 -0.5 -1.2 -0.9  0.5 -0.2 -1.   0.9  6.5 -0.8 -0.5  4.1 -0.7 -0.3  4.7 -0.5  5.8 -1.2 -0.4  0.1 -0.   0.8 -0.  -1.5 -0.5 -0.7 -0.8 -0.2  4.9 -2.1  1.8 -0.6 -0.4 -0.5 -0.9 -0.5  3.1 -0.8 -0.3 -0.2  3.4 -0.1  7.  -0.1  3.5 -0.7 -0.4  1.9 -3.2  1.8 -0.6 -0.2 -0.9  0.4 -0.5  8.9  0.7  4.1  5.9]
ty_50sample [[8 9 1 5 7 3 4 6 2 0]
 [1 7 4 8 3 6 9 0 5 2]
 [9 4 3 8 1 5 0 7 6 2]
 [8 4 5 0 0 6 1 3 3 2]
 [2 7 4 5 9 3 1 8 0 0]
 [5 9 2 3 0 0 1 8 7 4]
 [7 2 8 6 1 5 3 4 0 0]
 [9 7 2 4 8 3 6 1 0 5]
 [1 8 4 7 5 3 6 0 9 2]
 [3 5 2 4 8 6 0 0 1 1]]
tt_50sample [[8 9 1 5 7 3 4 6 2 0]
 [1 7 4 8 3 6 9 0 5 2]
 [9 4 3 1 8 5 0 7 2 6]
 [8 4 5 0 7 6 1 3 9 2]
 [2 7 4 5 9 3 1 8 0 6]
 [5 9 2 3 0 6 1 8 7 4]
 [7 2 8 6 1 5 3 4 0 9]
 [9 7 2 4 8 3 6 1 0 5]
 [1 8 4 7 5 3 0 6 9 2]
 [3 5 2 4 8 6 0 9 1 7]]
vm  [ 0.1  0.7  5.6 11.7 -1.3 -0.3 -0.7 -0.5 -0.3 -0.5  4.3 -0.3 -0.1 -0.4 -0.4  0.2  0.1 -0.   0.9 -0.9 -0.5 -0.4  1.7 -0.1 -1.1  3.5 -0.6  0.1 -1.  -1.1 -1.6 -0.2 -0.7 -0.3  1.9  0.2  1.7  5.2  7.8 -0.9 -0.6 -0.4 -0.9  0.1 -0.8 -0.1  3.3 -1.   0.8  2.3 -0.7 -0.4  1.2  3.8  1.1  2.  -0.5  2.5  1.3  5.9 -0.5 -0.2  0.6  5.  -0.4 -0.2  0.3 -0.3 -0.3 -0.2 -0.5  3.8  0.3 -0.2 -0.8  0.6 -0.2 -0.5 -0.3 -0.   2.7 -0.3 -0.3 -0.1 -0.8 -0.6 -0.4 -0.3  1.2 -0.3 -0.2 -0.9 -0.3  1.5 -0.3 -0.3  1.3 -0.5 -0.2 -0.1  0.4 -0.1 -0.3 -0.7  0.4 -0.  -0.8 -1.3  2.4 -1.2 -0.1  0.5 -0.2  0.7  3.5 -1.3 -0.   0.2  0.4  1.  -0.2  3.8 -0.3 -0.4 -0.4 -0.5 -0.5 -0.4 -0.   0.6 -0.4 -0.3 -1.2  0.6 -1.6 -2.4 -0.5 -0.6  2.  -0.4 -0.8 -1.3 -1.2 -0.6  1.4 -0.8 -0.5 -0.4 -0.5 -1.1 -1.4 -0.1  3.3 -0.3 -0.2 -0.2  0.5  0.4  2.5 -0.7 -0.1 -1.3 -0.4 -0.3 -0.4 -0.6 -0.7 -0.2 -0.7  4.  -0.  -0.4 -0.   0.2 -0.4  3.  -0.2  1.6 -1.5 -0.5 -0.1 -0.5 -0.2 -0.7  1.3 -0.4  2.9 -0.2  1.6  6.1 -0.5 -0.7 -0.9 -0.9  4.  -0.5 -0.2 -0.3 -0.3  1.5 -0.2 -0.4 -0.4 -0.5 -0.6  1.9 -0.6 -0.2  4.9 -0.2 -0.4 -0.8 -0.4 -0.2 -0.8 -0.3  1.7 -0.4 -0.6 -0.2 -0.3 -0.8 -0.4 -1.2 -0.5 -0.4  0.9  3.5 -0.2  1.5 -1.  -0.5 -0.6  3.2  2.9 -1.3  2.6 -0.  -0.2  8.2 -0.8  5.1 -0.3 -0.2  0.9 -1.5  0.3  0.6 -0.2 -0.6 -0.6 -0.8  7.   2.1 -0.5  2. ]
vy_50sample [[0 2 9 8 3 7 1 5 6 4]
 [5 4 8 6 7 2 3 9 1 0]
 [0 5 3 6 8 7 7 1 9 4]
 [6 8 4 5 3 7 7 0 0 2]
 [4 5 6 0 3 7 8 1 1 2]
 [2 0 6 3 5 5 1 9 7 8]
 [2 9 9 0 0 7 5 1 6 6]
 [3 6 0 1 7 2 9 4 5 8]
 [5 7 4 8 6 9 2 0 1 3]
 [2 7 6 9 1 8 5 0 3 4]]
vt_50sample [[2 0 9 8 3 7 1 5 6 4]
 [4 5 8 6 7 2 3 1 9 0]
 [0 5 3 6 8 7 2 9 1 4]
 [6 8 4 5 1 3 7 0 2 9]
 [4 5 6 0 3 7 8 1 9 2]
 [2 0 6 3 4 5 1 9 7 8]
 [2 8 9 0 7 4 5 1 6 3]
 [6 3 0 1 7 2 9 4 5 8]
 [5 7 4 8 6 9 2 0 1 3]
 [2 7 6 9 1 8 5 0 3 4]]
Epoch  7210: Training cost= 0.4199, Training acc= 0.7425, Validation cost= 0.3651, Validation acc= 0.7431
Epoch  7220: Training cost= 0.3853, Training acc= 0.7427, Validation cost= 0.4040, Validation acc= 0.7432
Epoch  7230: Training cost= 0.4009, Training acc= 0.7428, Validation cost= 0.3822, Validation acc= 0.7433
Epoch  7240: Training cost= 0.3651, Training acc= 0.7429, Validation cost= 0.3710, Validation acc= 0.7435
Epoch  7250: Training cost= 0.3964, Training acc= 0.7431, Validation cost= 0.3645, Validation acc= 0.7436
Epoch  7260: Training cost= 0.3470, Training acc= 0.7432, Validation cost= 0.4079, Validation acc= 0.7437
Epoch  7270: Training cost= 0.3433, Training acc= 0.7434, Validation cost= 0.4376, Validation acc= 0.7439
Epoch  7280: Training cost= 0.3855, Training acc= 0.7435, Validation cost= 0.3735, Validation acc= 0.7440
Epoch  7290: Training cost= 0.4028, Training acc= 0.7436, Validation cost= 0.3931, Validation acc= 0.7441
Epoch  7300: Training cost= 0.3876, Training acc= 0.7437, Validation cost= 0.3898, Validation acc= 0.7442
tm  [ 2.1 -0.6  5.3  4.6 -0.7 -0.9 -1.  -0.3  1.3  2.2  0.9 -0.  -0.8 -1.1  3.4 -0.6 -1.  -0.7 -0.1  3.  -0.2  0.9  3.6 -0.2 -0.6 -0.1 -0.5 -0.2 -0.8 -1.4 -1.4 -0.1  3.  -0.7  2.9 -0.9 -0.2 -0.2 -3.3 -0.9 -0.   3.3 -1.1 -1.9  0.7 -0.2 -0.9 -0.6  1.8  4.4 -0.6 -0.7 -0.7  5.5  0.9 -0.2 -0.3  2.6  4.5  5.9  0.5 -0.9  1.3  4.6  0.1 -0.8  0.   0.8  2.5 -1.  -0.1  1.5 -0.2 -0.2 -5.4  0.3 -1.2  0.2 -0.2 -0.2 -1.6 -0.1  1.4 -0.1 -1.7  2.3 -0.2 -0.  -0.4 -0.1 -0.4 -1.2 -1.2 -0.4 -1.2 -0.4  2.1 -1.9  0.9 -0.1 -1.   3.3 -0.3 -0.5 -0.2 -0.5 -2.9 -1.3  0.7  1.8  1.3  1.5 -0.  -0.5  5.8 -1.6  2.1  4.6  0.1  3.6 -0.2 -1.1 -0.1 -0.9 -0.6  3.4 -1.1 -0.7  1.7  0.2  5.1 -1.  -1.1  0.1  8.3 10.3 -0.2 -1.  -0.6 -0.3 -0.6 -0.8 -0.2 -0.3 -0.7 -0.  -0.5 -1.4  0.8 -0.5 -0.7 -0.   4.7 -0.2 -0.4 -0.3 -0.2  1.  -1.7 -0.6  0.9  1.4  3.5 -0.8 -0.6 -0.7 -1.2 -0.3 -1.4  1.4  0.7 -0.2 -0.4 -0.1 -0.   0.3 -2.4 -0.6 12.2  0.9 -0.3 -1.  -0.1 -0.8  1.5 -0.3  2.2 -0.3 -0.1  5.  -0.4 -0.8 -0.5 -1.1  1.6 -1.2 -1.7 -1.5 -0.3  0.3 -0.1  0.6  1.  -0.2 -1.3 -1.6 -0.1 -1.   3.5 -0.2 -0.2 -1.1 -0.6 -0.6 -1.   0.1  7.5 -0.2 -0.3  0.1 -0.8 -1.1 -0.2 -1.5  3.4 -0.5 -0.9  2.5 -0.2  4.3  4.2  1.9 -0.7  2.9 -0.3 -1.1  3.3 -2.5  0.7 -0.6 -0.7 -0.3 -0.   1.   6.7 -0.3  0.6 -0.2  0.   1.4  3.2 -0.9 -2.5 -0.  -0.   0.7]
ty_50sample [[6 0 8 2 5 7 3 1 1 4]
 [6 6 2 4 3 7 8 1 5 0]
 [1 3 5 4 7 8 6 0 2 9]
 [8 7 2 1 9 3 5 0 4 4]
 [1 7 0 4 2 5 9 6 3 8]
 [3 2 0 1 6 5 8 9 9 4]
 [2 3 5 0 6 9 1 8 7 4]
 [3 1 6 2 8 4 0 5 9 7]
 [3 9 0 5 7 2 8 4 1 6]
 [5 1 6 2 0 4 9 7 3 8]]
tt_50sample [[6 0 8 2 5 7 3 9 1 4]
 [6 9 2 4 3 7 8 1 5 0]
 [1 3 5 4 7 8 6 0 2 9]
 [8 7 2 1 9 3 5 0 6 4]
 [1 7 0 4 2 5 9 6 3 8]
 [3 2 0 1 6 5 8 9 7 4]
 [2 3 5 0 6 9 1 8 7 4]
 [3 1 6 2 8 4 0 5 9 7]
 [3 9 0 5 7 2 8 4 1 6]
 [5 1 6 2 0 4 9 7 3 8]]
vm  [ 2.1 -0.4 -1.4 -3.  -1.  -0.6 -0.4 -0.6  0.4 -0.7  5.7  0.2 -0.6 -1.1  5.  -0.5 -0.4 -0.5 -0.5  3.7 -0.7 -0.2 -1.   0.4 -0.9  3.  -0.3 -0.3 -0.7 -1.1  5.7 -0.6 -0.1  4.1  3.3 -0.2 -0.2  1.3 -1.2 -1.4 -0.4 -1.  -0.8  4.6 -0.8  0.2 -2.6 -0.5  3.7 -1.5 -0.9 -1.6 -0.5  6.8  0.4 -0.4 -0.5 -0.6  3.4 -1.5  1.6 -0.4  0.6  6.   1.  -0.1 -0.1  2.6  1.9  0.7 -0.8  1.5 -0.6 -0.2 -4.4  0.5 -1.3 -0.6  3.   0.2 -0.6  0.4  3.1  1.4 -1.2 -1.   2.7 -0.5  0.7 -0.2 -0.2 -1.2 -0.5 -0.7 -0.8  0.8 -0.5 -2.  -0.1 -0.3  0.1 -0.6 -0.5 -0.2  0.3 -0.2 -2.6  6.2  2.8  3.7 -0.7  0.6  0.  -0.6  5.2 -1.4 -0.3  4.1 -0.2  0.8  0.1 -1.2 -0.2  0.1 -0.7  5.5 -0.7 -1.2  1.8  6.   3.4 -0.8 -0.4 -0.   3.   5.4 -0.4 -0.1  2.3 -0.7 -0.3 -0.7 -0.4 -0.  -0.3 -0.1 -0.4 -0.4  0.2 -1.1  5.3 -0.1  2.  -0.2 -0.5  0.1 -0.4 -0.5 -0.3 -0.2  1.5 -0.8  1.1 -0.7  0.7 -0.7 -0.4  2.3  0.4 -1.3 -0.5 -0.5 -0.3  0.1 -0.8  1.8 -0.7 -0.6  6.1  0.9 -0.  -0.5 -0.7 -1.   2.7 -1.1  1.4 -0.5 -0.2  4.  -0.2 -0.2  0.5 -1.2  0.8 -0.5 -1.3 -1.  -0.4  1.4 -0.1  2.8 -0.6 -0.8 -0.9 -2.4  0.4 -0.3  0.7 -0.2 -0.4 -0.7 -1.2 -0.3 -0.1 -0.5 -0.8 -0.5 -0.6 -0.1 -0.6 -0.2 -0.3 -0.9 -0.3 -0.8 -0.2 -0.   1.1  6.7 -0.8  0.3 -0.7  0.4  2.9  5.   3.3 -2.1  4.5 -0.5 -0.7 -0.2 -0.   0.2  3.7  2.  -0.1 -0.3 -0.9 -0.4  0.6 -0.1 -0.8 -0.1  1.5 -1.5]
vy_50sample [[4 0 3 2 6 7 5 8 1 9]
 [9 3 1 6 8 5 4 2 0 7]
 [8 3 2 1 7 4 9 0 6 5]
 [2 7 1 0 6 4 8 3 5 9]
 [5 3 3 7 7 8 8 6 0 4]
 [3 5 7 2 6 8 9 1 0 4]
 [1 2 6 6 9 4 5 0 3 7]
 [1 8 7 2 5 6 0 9 3 4]
 [2 7 9 0 6 1 8 4 3 5]
 [6 0 1 5 7 9 4 2 8 3]]
vt_50sample [[4 0 3 2 6 7 5 8 1 9]
 [3 9 1 6 8 5 4 2 0 7]
 [8 3 2 1 7 4 9 0 5 6]
 [2 7 1 0 6 4 8 3 5 9]
 [5 3 1 9 7 8 2 6 0 4]
 [3 5 7 2 6 8 9 1 0 4]
 [1 2 6 8 9 4 5 0 3 7]
 [1 8 7 2 5 6 0 9 3 4]
 [2 7 9 0 6 1 8 4 3 5]
 [6 0 1 5 7 9 4 2 8 3]]
Epoch  7310: Training cost= 0.4216, Training acc= 0.7439, Validation cost= 0.3864, Validation acc= 0.7444
Epoch  7320: Training cost= 0.3566, Training acc= 0.7440, Validation cost= 0.3845, Validation acc= 0.7445
Epoch  7330: Training cost= 0.3593, Training acc= 0.7441, Validation cost= 0.3674, Validation acc= 0.7446
Epoch  7340: Training cost= 0.4750, Training acc= 0.7442, Validation cost= 0.4322, Validation acc= 0.7447
Epoch  7350: Training cost= 0.3973, Training acc= 0.7444, Validation cost= 0.4486, Validation acc= 0.7449
Epoch  7360: Training cost= 0.3912, Training acc= 0.7445, Validation cost= 0.3531, Validation acc= 0.7450
Epoch  7370: Training cost= 0.4211, Training acc= 0.7446, Validation cost= 0.4516, Validation acc= 0.7451
Epoch  7380: Training cost= 0.4070, Training acc= 0.7447, Validation cost= 0.3971, Validation acc= 0.7452
Epoch  7390: Training cost= 0.4152, Training acc= 0.7448, Validation cost= 0.4209, Validation acc= 0.7453
Epoch  7400: Training cost= 0.3800, Training acc= 0.7450, Validation cost= 0.4021, Validation acc= 0.7454
tm  [-1.1 -0.2  3.6 12.8 -1.   0.3 -0.6 -0.2  0.1 -0.3  1.8  0.4 -0.6 -0.4 -1.3 -0.5 -0.6 -0.2 -0.4 -0.9 -0.5 -0.1  0.  -0.3 -1.1  2.7 -0.4 -0.2 -0.8 -1.2 -1.  -0.3  1.5 -0.4 -0.5 -0.2  1.8  0.2 -0.6 -0.5 -0.4 -0.3 -0.7 -2.1 -0.5 -0.1  4.1 -0.  -1.  -0.5 -0.4 -0.3  1.7 -0.6 -0.3  4.6 -0.2  2.8 -0.1  4.4  2.7 -0.3  0.5  1.9  0.3 -0.4 -0.3  0.3 -0.1 -0.2 -0.3  1.5 -0.4 -0.2 -0.8 -0.3  1.1 -0.7  0.7 -0.1  7.8 -0.2 -0.5 -0.4  0.1 -0.4 -0.8 -0.5 -0.1  0.1 -0.3 -0.2  0.2 -0.  -0.3 -0.2  1.7 -0.6 -0.1 -0.2  0.1 -0.7  2.5 -0.4 -0.6 -0.1 -0.7 -0.7  0.2 -1.5 -0.   0.8 -0.3 -0.1  4.  -0.6 -0.1 -0.3 -0.4  2.  -0.1  3.4 -0.   0.4 -0.5 -1.5  1.1  5.3 -0.3 -0.1  1.  -0.9 -1.  -0.1 10.7 11.8 -0.3 -0.3  2.  -0.3 -0.  -0.6 -0.5 -0.4 -0.5 -0.7 -0.  -0.1  1.5 -0.3 -1.9 -0.4 -0.7  1.1 -0.3 -0.1  0.4  0.9 -1.  -0.6 -0.4  2.1 -0.1 -0.2 -0.8 -0.6 -0.5  1.8 -0.9  5.5 -0.5 -0.3 -0.4 -0.1 -0.  -0.2 -1.7  1.2  4.4  0.4 -0.2 -0.4  0.7 -0.9 -0.1 -0.7 -0.1  0.   1.5  5.7 -0.4 -0.7 -1.  -0.7 -0.   1.1  0.  -0.3 -0.8 -0.4 -0.3 -0.1 -0.1 -0.6  1.   1.6  0.1 -0.5  0.8 -0.3 -0.6 -0.  -0.3  3.8 -1.3 -0.3  8.1 -0.7 -0.5 -0.1 -0.4 -0.7  0.3 -1.2  2.7 -0.4 -1.   4.4  0.1 -0.1  2.3 -0.2 -0.6  0.8  0.9 -0.6  0.7  0.1 -0.1  7.4 -0.9  3.8 -0.3 -0.2 -1.  -1.7  0.8  1.2 -0.5 -0.5 -1.7 -1.4 -0.4  0.8  1.6  2.7]
ty_50sample [[6 1 0 9 3 3 5 7 7 4]
 [8 6 5 7 7 0 3 3 4 2]
 [9 5 0 6 4 2 3 1 7 8]
 [1 5 7 3 2 2 9 4 4 6]
 [0 0 6 3 7 7 2 2 4 5]
 [9 7 0 3 5 1 1 6 4 2]
 [5 7 6 1 9 4 2 8 3 0]
 [0 6 9 2 8 4 4 7 5 5]
 [5 7 8 2 2 6 1 4 4 0]
 [3 5 7 1 2 6 8 9 0 4]]
tt_50sample [[6 1 0 9 3 8 5 2 7 4]
 [8 6 5 7 9 0 1 3 4 2]
 [9 5 0 6 4 2 3 1 7 8]
 [1 5 7 3 2 8 9 0 4 6]
 [0 1 6 3 9 7 2 8 4 5]
 [9 7 0 3 5 8 1 6 4 2]
 [5 7 6 9 1 4 2 8 3 0]
 [0 6 9 2 8 4 1 7 3 5]
 [5 7 8 2 9 6 1 4 3 0]
 [3 5 7 1 2 6 8 9 0 4]]
vm  [ 1.9  1.  -0.2 11.7 -0.7 -1.1 -0.7 -0.3  1.  -0.8  4.1 -0.4 -0.1 -0.2 -2.9  3.4 -0.2 -0.5  0.2 -1.6 -0.6 -0.1 -0.2 -0.1 -0.8  1.1 -0.3 -0.2  0.1 -1.  -0.8 -0.9 -0.5 -2.6  0.3 -0.   1.2  4.1  8.3 -1.6 -0.3 -0.7 -0.3 -0.  -0.1  0.8  6.4 -0.6  4.  -0.6 -0.5 -0.6  2.1  0.  -0.5  6.9 -0.3  3.2  1.1  4.6 -2.2 -0.5 -0.2  4.2 -0.2 -0.  -0.5  0.6 -0.   1.1 -0.5 -0.   0.6 -0.3  4.4 -0.1 -1.1 -0.9 -0.7  0.2  6.9 -0.3 -0.8 -0.1 -1.3 -0.8  0.5 -0.6  1.7 -0.1 -0.4 -0.4  1.1 -0.   1.9 -0.1  1.3 -0.3  0.1  0.8  2.  -2.5 -0.8  0.  -0.  -0.1  2.4 -0.8  2.5 -2.3 -0.2  0.  -0.  -0.   0.4  0.6 -0.1  0.5  0.1  2.2 -0.3  7.8 -0.4 -0.8 -0.6 -3.  -0.3  2.3  3.5  0.7  2.3 -0.8 -0.1 -0.3  5.5 -0.9 -0.3 -0.3  1.3 -0.3 -0.7 -0.8 -1.  -0.7 -0.3 -0.2 -0.8 -0.7  4.5 -0.4 -1.3 -0.   5.2 -0.9 -0.3 -0.3 -0.  -0.3 -0.  -0.4 -0.1 -0.8 -0.8 -0.3 -1.  -0.6  2.3 -0.1 -0.3  4.4 -0.6 -0.2 -0.2  0.  -0.1 -1.2 -0.2  2.5 -1.6 -0.7 -0.7 -0.3 -0.6 -0.7  0.3 -0.4  6.8  1.5 -0.   7.9 -0.2  0.2 -1.8 -0.7  9.1 -1.   3.8 -0.6 -0.1  0.9 -0.4  0.1 -0.3 -0.8 -0.9  2.8  0.3  1.3  2.3 -0.3 -0.5  2.6 -1.3 -1.3 -1.1 -0.4  1.4 -0.2 -0.6 -0.4  0.2 -0.5 -0.2 -0.8 -0.7  1.3  1.6  1.7 -0.2  8.2 -1.3 -0.9 -0.6  1.9  1.3  3.3  0.9  4.4  1.1  7.7 -0.4  3.8  0.5 -0.1 -0.8 -2.  -0.1  1.2 -1.  -0.9 -1.5 -1.   7.1  0.9  1.2  1.7]
vy_50sample [[9 3 2 8 5 0 6 4 7 7]
 [4 2 9 3 6 8 0 1 5 7]
 [7 0 4 1 5 6 2 9 3 8]
 [2 3 1 5 8 9 7 7 0 4]
 [5 4 0 8 3 9 7 2 6 6]
 [0 2 5 7 9 3 4 4 8 6]
 [3 4 6 7 8 2 5 1 0 9]
 [2 0 9 4 7 6 5 3 1 8]
 [0 6 8 8 1 7 3 5 4 9]
 [6 9 7 7 1 4 5 0 3 2]]
vt_50sample [[9 2 3 8 5 0 6 4 7 1]
 [4 2 9 3 6 8 0 1 5 7]
 [7 0 4 1 6 5 2 9 3 8]
 [2 3 1 5 8 9 7 6 0 4]
 [5 4 0 3 8 9 7 2 6 1]
 [0 2 5 7 3 9 1 4 8 6]
 [3 4 6 7 8 2 5 1 9 0]
 [2 0 9 4 7 6 5 3 1 8]
 [0 6 8 2 1 7 5 3 4 9]
 [6 9 8 7 1 4 5 0 3 2]]
Epoch  7410: Training cost= 0.4116, Training acc= 0.7451, Validation cost= 0.4700, Validation acc= 0.7455
Epoch  7420: Training cost= 0.4143, Training acc= 0.7452, Validation cost= 0.4015, Validation acc= 0.7456
Epoch  7430: Training cost= 0.4988, Training acc= 0.7453, Validation cost= 0.4442, Validation acc= 0.7457
Epoch  7440: Training cost= 0.4022, Training acc= 0.7454, Validation cost= 0.4441, Validation acc= 0.7458
Epoch  7450: Training cost= 0.3730, Training acc= 0.7455, Validation cost= 0.3794, Validation acc= 0.7460
Epoch  7460: Training cost= 0.3966, Training acc= 0.7456, Validation cost= 0.4299, Validation acc= 0.7461
Epoch  7470: Training cost= 0.3742, Training acc= 0.7457, Validation cost= 0.4255, Validation acc= 0.7462
Epoch  7480: Training cost= 0.4067, Training acc= 0.7458, Validation cost= 0.4202, Validation acc= 0.7463
Epoch  7490: Training cost= 0.5187, Training acc= 0.7459, Validation cost= 0.4503, Validation acc= 0.7464
Epoch  7500: Training cost= 0.3895, Training acc= 0.7460, Validation cost= 0.3937, Validation acc= 0.7465
tm  [ 1.7  0.3 -1.4 -0.6 -0.8 -0.9 -0.4 -0.6 -0.1 -0.4  4.8 -0.9 -0.3 -0.3 -0.5  6.1 -0.  -0.2 -0.3  1.4 -0.5  0.4  3.3  0.3 -1.4  1.7 -0.1 -0.1  1.4 -0.5  1.1 -1.1 -0.  -2.2  2.2 -0.3 -0.1  4.4  0.3 -0.9 -0.3  2.6 -0.1  2.7 -0.4 -0.1 -0.9 -1.3  3.3  5.4 -0.3 -1.3  0.1  7.  -0.9  2.5 -0.3  0.1  2.7  0.9 -0.6 -0.4  1.6  4.3  0.5 -0.6  0.1  1.7 -0.3 -0.5 -0.5 -0.2  1.1  0.9 -2.8 -0.1 -1.2  0.3  1.1 -0.3 -1.1 -0.1  2.  -0.3 -1.7  2.9  1.7 -0.5  0.   0.5  0.3 -1.1 -0.7 -0.6 -0.3 -0.2  0.9 -1.3 -0.3 -0.1 -0.4 -0.5 -0.9 -0.1 -0.3  0.1 -1.5  0.2  2.2  0.9 -0.7  0.5 -0.1 -0.3  0.1  1.7 -0.3 -0.1  0.6  1.4 -0.2 -0.6 -0.3 -0.7 -0.2 -0.4 -0.8 -1.6  3.3  0.2  4.1 -0.6 -0.5 -0.   6.4 -0.9  0.  -0.7  0.  -0.1 -0.8 -0.8 -0.5 -0.1  0.4  2.1 -0.2 -0.3  3.8  0.4  1.9  0.3  5.5 -0.7 -0.1  0.1 -0.7 -0.5 -0.1 -0.2  3.1 -0.6 -0.3 -0.7 -0.5 -0.8  0.2 -0.3  0.6 -0.1  1.5 -0.3 -0.4 -0.3 -0.3 -0.7 -0.9  1.3  2.3 -0.5 -0.6 -0.4 -0.6 -1.  -0.1 -0.4  3.3  0.3 -0.5  2.9 -0.1 -0.8 -0.4 -1.2  4.4 -0.4 -0.2 -0.6 -0.1  0.6 -0.3  1.9 -0.6 -0.5 -0.9 -0.7 -0.2  1.4  2.9 -0.3 -0.2  2.5 -1.  -0.1 -0.3 -0.5 -0.3 -0.2 -0.6 -0.1 -0.6 -0.5 -0.2 -0.8  1.9  2.6  2.2  2.4 -0.3  5.7 -0.7 -0.5 -0.6  2.  -0.1  6.6  3.2 -0.9  2.1  0.2 -0.8  0.1  0.7  0.3  4.8 -0.8  0.1  0.7 -0.7 -0.3  1.4  1.1  0.5  1.5 -0.4  2.7]
ty_50sample [[2 8 4 5 6 9 0 3 1 7]
 [9 3 0 8 2 1 4 7 5 6]
 [3 9 0 0 2 1 8 6 7 4]
 [3 9 4 5 5 8 2 1 0 7]
 [8 9 6 7 5 2 4 1 3 0]
 [9 8 4 4 7 7 2 3 1 0]
 [1 9 3 2 7 7 4 5 6 0]
 [3 8 1 2 6 5 4 9 7 0]
 [4 6 5 2 8 3 7 0 9 9]
 [0 6 8 7 1 9 3 4 2 5]]
tt_50sample [[2 8 4 5 6 0 9 3 1 7]
 [9 3 0 8 2 1 4 7 5 6]
 [3 9 0 5 2 1 8 6 7 4]
 [3 9 4 5 6 8 2 1 0 7]
 [8 9 6 7 5 2 4 1 3 0]
 [9 8 4 5 6 7 2 3 1 0]
 [1 9 3 2 8 7 4 5 6 0]
 [3 8 1 2 6 5 4 9 7 0]
 [4 6 5 2 8 3 7 0 1 9]
 [0 6 8 7 1 3 9 4 2 5]]
vm  [-0.8 -0.9  0.6 -0.5 -1.9 -0.6  1.  -0.3  0.  -1.4  6.9  0.4  0.8 -0.   2.9  3.4  0.2 -0.6  0.8 -0.5 -0.5 -0.7 -1.6 -0.5 -0.7  0.3 -0.3 -0.5 -0.1 -0.4  7.4 -0.5 -0.6 10.6 -0.5  1.3 -0.2  2.7  6.1 -1.3  0.5 -0.7 -0.2  5.7 -0.8 -0.5 -0.1  0.1  1.9 -2.9 -1.7 -0.8 -0.3  0.3 -1.2 -0.2 -0.3  0.4  1.7 -2.5  0.1 -0.4 -0.6  4.  -0.4 -0.  -0.6  0.6  0.3  2.1 -0.2 -0.6 -0.3  1.4 -0.6 -0.3 -0.5 -0.8  1.3 -0.3 12.6 -0.3 -0.8 -0.1 -0.3 -0.4  1.5 -0.   2.  -0.2 -0.2  0.   0.7 -0.6  0.8  0.5 -0.3 -1.2 -0.2 -0.4  3.6  1.6 -0.2  0.6 -0.2 -0.3 -0.6  7.3  2.4 -1.  -0.4 -0.9 -0.3 -0.8 -0.2  5.  -0.4  2.2 -0.4 -0.8  1.   6.3 -0.2  1.  -0.4  2.8  1.3  2.6  4.2  3.8 -0.3 -1.1  1.3 -0.5 -3.2  5.3  0.   0.4  0.1 -0.7 -0.7  2.4  0.7 -0.1 -0.6  0.4 -0.3 -0.5 -0.6 -0.1  2.9 -0.4 -1.  -0.3 -0.5 -0.3 -0.3 -0.8  3.5  0.8 -0.1 -0.9 -0.4 -0.6  1.8 -0.2  3.2  3.   1.3 -0.3 -1.2  0.3 -0.6 -0.2 -0.6  2.8  1.3 -0.2 -1.1 -0.3 -0.6  0.6 -0.9 -1.1 -0.3 -0.7  2.5 -0.8 -0.7  1.6 -0.3  0.9 -0.8 -0.8  2.3 -0.6  0.9 -0.3 -0.6 -0.4 -0.4  1.2 -0.3 -1.2  0.4 -0.8  0.7  0.6 -2.2 -0.3 -0.4  3.4 -1.1  1.4  0.4 -0.6 -1.2 -0.3  1.5 -0.2 -0.2  0.3 -0.5 -0.3 -0.8 -0.1 -0.4 -0.2 -0.2  4.7 -1.2 -0.6 -0.3 -1.7  2.   1.3 -0.1  1.1  3.8  2.7 -0.2  1.4 -0.5 -0.3 -2.3 -0.5 -0.3 -0.3 -1.  -0.8 -2.5 -0.3  4.8 -0.3  4.  -0.4]
vy_50sample [[4 4 7 9 9 2 1 0 6 8]
 [1 6 9 8 7 5 3 2 0 4]
 [2 4 6 6 3 3 1 5 5 7]
 [6 9 3 8 1 5 5 2 4 0]
 [9 6 8 3 0 7 1 4 5 2]
 [5 0 9 3 4 1 6 7 2 8]
 [1 1 2 2 8 4 3 5 0 6]
 [2 3 4 5 7 0 0 1 9 6]
 [1 5 4 6 2 9 7 3 0 0]
 [1 2 6 6 3 5 9 4 0 8]]
vt_50sample [[3 4 7 9 5 2 1 0 6 8]
 [1 6 9 8 7 5 3 2 0 4]
 [2 4 8 6 3 9 0 1 5 7]
 [6 9 3 8 7 1 5 2 4 0]
 [9 6 8 3 0 7 1 4 5 2]
 [5 0 9 3 4 1 6 7 2 8]
 [9 1 7 2 8 4 3 5 0 6]
 [2 3 4 5 7 0 8 1 9 6]
 [1 5 4 6 2 9 7 3 8 0]
 [1 2 7 6 3 5 9 4 0 8]]
Epoch  7510: Training cost= 0.4396, Training acc= 0.7461, Validation cost= 0.4845, Validation acc= 0.7466
Epoch  7520: Training cost= 0.4023, Training acc= 0.7462, Validation cost= 0.4112, Validation acc= 0.7467
Epoch  7530: Training cost= 0.4067, Training acc= 0.7463, Validation cost= 0.3797, Validation acc= 0.7468
Epoch  7540: Training cost= 0.4034, Training acc= 0.7464, Validation cost= 0.4530, Validation acc= 0.7469
Epoch  7550: Training cost= 0.4213, Training acc= 0.7465, Validation cost= 0.3836, Validation acc= 0.7470
Epoch  7560: Training cost= 0.4013, Training acc= 0.7467, Validation cost= 0.4115, Validation acc= 0.7471
Epoch  7570: Training cost= 0.3718, Training acc= 0.7468, Validation cost= 0.3702, Validation acc= 0.7473
Epoch  7580: Training cost= 0.4599, Training acc= 0.7469, Validation cost= 0.4473, Validation acc= 0.7474
Epoch  7590: Training cost= 0.4099, Training acc= 0.7470, Validation cost= 0.3631, Validation acc= 0.7475
Epoch  7600: Training cost= 0.4443, Training acc= 0.7471, Validation cost= 0.3974, Validation acc= 0.7476
tm  [-0.  -0.4 -1.8 -1.7  0.4 -1.4 -0.4 -0.8 -0.5 -0.4 -4.   2.5 -1.6 -0.5 -0.3 -0.4 -0.4 -0.1 -0.5 -0.2 -0.1 -0.1  1.5 -0.1 -0.3 -0.4 -0.3 -0.5  2.3 -0.3  0.6 -0.4  1.7 -3.5 -0.1 -1.  -0.5 -0.   0.3 -0.8  0.2 -1.6 -1.2  3.  -0.8 -0.9  0.6  1.8  0.7  4.1 -0.4 -0.9 -1.1 -0.8 -1.2  2.6 -0.3 -1.2  4.5  0.8 -0.  -0.4 -0.3 -0.3 -0.6 -1.  -0.3  1.4  2.1  0.7 -0.5 -0.7  1.2 -0.2 -3.5  1.2 -0.6 -0.2  2.9 -0.6 -3.2 -0.2 -0.1 -0.2 -1.2 -1.8  2.  -0.5  2.2 -0.5  0.8 -0.6 -0.5 -0.4 -0.8 -0.8 -0.8 -1.3 -0.6 -1.  -0.  -1.2 -0.1 -0.1 -0.3 -0.2 -2.1 -0.1 -2.3 -0.3  1.1 -0.6 -0.1 -0.3  2.2  2.   0.1  3.2 -0.2  2.4 -0.1 -0.1 -0.3 -1.2 -0.3 -0.3  0.5  5.7  0.7  3.7  3.5 -0.1  0.5 -0.5  4.4 -2.9  0.4 -0.3  0.   0.8  2.4 -0.6  3.3  0.1 -0.6  0.9 -0.6 -0.5 -0.2 -0.5  3.5  0.   4.9  0.6 -0.6  0.2 -0.9 -0.7 -0.4 -0.8 -0.5 -0.9  0.5 -0.4 -1.3 -0.3  1.4  4.8 -0.1 -0.9 -0.6 -0.8 -0.8 -0.5 -0.6  2.6 -1.  -0.3  2.3  2.3  1.7 -0.5 -0.1 -0.5  0.   2.2  2.1  0.2 -1.   2.3 -0.4 -0.4 -0.6 -1.8  2.7 -0.1 -0.8 -0.8 -0.4 -0.8 -0.2  2.7 -0.2 -0.5 -1.1 -1.2 -1.3 -0.6  9.2 -0.4 -0.1  2.  -1.5  0.5  0.9 -0.  -0.8 -0.1 -0.1 -0.2 -1.3 -0.6 -0.5 -1.1 -0.4  3.5 -2.  -0.3 -0.5  4.9 -0.4  1.8 -0.8  6.1 -0.9  5.5  1.7 -1.9  1.5  6.9 -0.5  4.3 -0.5 -0.   8.9 -1.7  2.  -1.5 -0.5  0.6  6.8  0.4 -0.  -1.1  3.7 -0.4]
ty_50sample [[8 4 3 6 9 0 0 7 5 2]
 [8 3 2 1 1 7 7 9 4 6]
 [5 9 7 2 6 8 1 0 4 3]
 [0 5 6 7 4 4 3 9 2 1]
 [7 2 5 9 3 6 8 4 0 1]
 [3 8 7 1 1 5 6 9 0 2]
 [6 4 8 5 2 1 1 3 3 7]
 [0 8 4 3 5 5 1 9 6 7]
 [0 4 2 8 3 3 5 1 7 6]
 [9 0 3 6 4 1 2 5 7 8]]
tt_50sample [[8 4 3 9 6 7 0 1 5 2]
 [8 3 2 5 1 7 0 9 4 6]
 [5 9 7 2 6 8 1 0 4 3]
 [0 5 6 7 8 4 3 9 2 1]
 [7 2 5 9 3 6 8 4 0 1]
 [3 8 7 4 1 5 6 0 9 2]
 [6 4 8 5 2 0 1 9 3 7]
 [0 8 4 3 5 1 2 9 7 6]
 [0 4 2 8 3 5 9 1 7 6]
 [9 0 3 6 4 1 2 5 7 8]]
vm  [-0.7  0.5 -0.7  9.2 -1.  -0.4 -0.2 -0.2  0.3 -0.1  1.4 -0.6  0.8  0.4 -2.4  3.7 -0.8 -0.2 -0.2 -1.1 -0.8 -0.2  3.7 -0.2 -0.8  3.2  0.3 -0.2 -0.2 -0.8 -0.4 -0.3 -0.5 -2.6  0.9 -0.2 -0.1  3.4  8.3 -0.6 -0.4 -0.  -0.6  1.2 -0.5  0.1  3.9 -0.7  0.3  6.2 -0.6 -0.8  3.6 -0.3 -0.6  6.5 -0.1  0.3  2.6  2.9 -0.6  0.4  1.9  5.7 -0.5 -0.  -0.   0.  -0.3  0.4 -0.7  1.2  2.9  1.8  4.4 -0.4 -0.1 -0.7  1.6 -0.1  5.6 -0.1 -0.2 -0.2 -0.4  0.8 -0.1 -0.6 -0.2  0.3  2.1 -0.8 -0.6 -1.1  3.1 -0.3  0.6 -0.4 -0.2  0.8 -0.4 -0.3 -0.  -0.  -0.1 -0.2  3.1 -0.8  0.5 -1.5 -1.1  0.8 -0.1 -0.1  2.7  0.3 -0.7 -0.7 -0.2  0.9 -0.   6.1 -0.1 -0.   0.5 -2.7 -0.4  3.5  3.6 -1.6  0.2 -1.  -1.  -0.3  4.4 -2.2  0.8 -0.5 -0.3  0.2 -0.3 -0.5 -0.7 -0.2 -0.1  0.9 -0.1  0.   1.3  0.5 -0.7 -0.1  2.2 -0.3  0.4 -0.1 -0.2 -0.6  3.3  1.9  3.3 -0.7 -0.7 -0.5 -1.2 -1.1  0.1  1.8  0.4  4.1  1.4 -1.1  0.5 -0.6 -0.   0.1 -0.1  6.3 -1.8 -0.4  0.8 -0.2 -0.9 -1.2 -0.2 -0.7  1.9  0.9 -0.   4.1 -0.1 -0.7 -1.5 -0.5  4.1 -0.5  6.6 -0.5  0.   1.6 -0.6  2.9 -0.9 -1.   0.7  4.5 -0.8  2.6  7.  -0.4 -0.3  3.6 -1.4  3.6 -1.2 -1.2  0.3 -0.4 -0.5  0.9 -0.4 -0.4 -0.4 -0.8  0.9  2.  -0.1  4.7 -0.3  1.5 -0.6 -1.9 -0.3  4.4  2.8  4.5  2.8  6.9  3.8 14.  -0.9  7.1  0.7 -0.2 -0.6 -2.4 -0.2  2.  -1.3 -1.  -1.5 -0.2  8.   2.3 -0.2  8.7]
vy_50sample [[9 8 2 1 0 4 6 3 5 7]
 [2 0 9 7 5 3 6 6 4 1]
 [0 1 9 9 4 7 3 5 8 2]
 [3 4 2 5 9 8 6 7 7 1]
 [5 6 0 1 7 3 3 8 4 9]
 [2 1 4 3 0 5 8 6 9 7]
 [8 9 0 2 1 5 4 7 6 3]
 [2 9 5 3 0 1 8 6 6 7]
 [5 3 9 2 8 7 4 6 0 1]
 [3 7 0 9 8 4 1 2 6 5]]
vt_50sample [[9 8 2 1 0 4 3 6 5 7]
 [2 0 9 7 3 5 6 1 8 4]
 [0 1 6 9 4 7 3 5 8 2]
 [3 4 5 2 8 0 9 6 7 1]
 [5 6 0 1 2 7 3 8 4 9]
 [2 1 4 3 0 5 8 6 9 7]
 [8 9 0 2 1 5 4 7 6 3]
 [2 9 5 3 0 1 8 4 6 7]
 [5 3 9 2 8 7 4 6 0 1]
 [3 7 0 9 8 4 2 1 6 5]]
Epoch  7610: Training cost= 0.4102, Training acc= 0.7472, Validation cost= 0.3959, Validation acc= 0.7477
Epoch  7620: Training cost= 0.4226, Training acc= 0.7473, Validation cost= 0.3924, Validation acc= 0.7478
Epoch  7630: Training cost= 0.4249, Training acc= 0.7475, Validation cost= 0.4024, Validation acc= 0.7479
Epoch  7640: Training cost= 0.4548, Training acc= 0.7476, Validation cost= 0.3918, Validation acc= 0.7481
Epoch  7650: Training cost= 0.4417, Training acc= 0.7477, Validation cost= 0.5684, Validation acc= 0.7481
Epoch  7660: Training cost= 0.4192, Training acc= 0.7478, Validation cost= 0.3845, Validation acc= 0.7482
Epoch  7670: Training cost= 0.4260, Training acc= 0.7479, Validation cost= 0.4701, Validation acc= 0.7483
Epoch  7680: Training cost= 0.4265, Training acc= 0.7479, Validation cost= 0.4339, Validation acc= 0.7484
Epoch  7690: Training cost= 0.4600, Training acc= 0.7480, Validation cost= 0.3661, Validation acc= 0.7485
Epoch  7700: Training cost= 0.4055, Training acc= 0.7481, Validation cost= 0.4002, Validation acc= 0.7486
tm  [-0.9  0.6 -0.5  7.  -1.2 -0.3  0.1 -0.1  1.4 -1.3  3.5  0.4 -0.2 -0.3 -1.9  5.5 -0.8 -0.4 -0.2 -1.  -0.7  0.5 -0.3 -0.3 -1.1  2.8 -0.1 -0.2  3.5 -0.7  1.6 -1.  -0.4 -0.4 -0.7 -0.2 -0.2  5.7  9.4 -1.1  1.1 -1.7 -1.   3.7 -0.5 -0.   4.7 -0.5 -0.1 -1.2 -0.6 -0.6  5.6 -0.6 -1.3  5.1  0.4  0.9  2.5  0.4 -0.7 -0.4  2.2  3.4  0.3 -0.1 -0.3  1.1 -0.3  1.3 -0.4 -1.   1.1  1.5  2.1 -0.1 -0.6 -0.9  0.3  0.7  9.1 -0.3  0.  -0.4 -0.4 -1.2 -0.1 -0.5  1.9 -0.   0.9 -0.4  1.9 -0.8  2.6 -0.1  0.2 -0.5 -0.5  0.4  2.6 -1.7 -0.2  0.3 -0.4 -0.   2.3  1.3  1.8 -1.2 -0.6 -0.4 -0.2 -0.4 -0.2  5.1 -0.  -0.  -0.1  0.9 -0.   4.2 -0.2  0.8 -0.2 -1.9  1.3  5.   4.   0.9 -0.2 -0.7 -0.1 -0.3 -0.3 -1.2  1.3 -0.1  2.9 -0.1 -0.4 -0.  -0.3 -0.4 -0.4  1.2  0.1 -0.1  0.9 -0.  -0.6 -0.4  1.4  0.  -0.2 -0.2 -0.8  0.3  3.7  0.9 -0.2 -1.5 -0.1 -0.2 -0.3 -0.5  4.5  3.7  0.7  3.1 -0.6 -0.6 -0.4 -0.2 -0.5  1.   0.1  3.7 -2.1 -0.3  0.3 -0.1 -1.1 -1.2 -0.6 -0.5  2.9  0.4 -0.6  4.9 -0.2 -0.  -1.5 -1.   4.  -0.6  4.4 -0.3 -0.4 -0.5 -0.4  2.2 -0.8 -1.3 -0.3  5.3 -0.2  1.2  3.4 -0.2 -0.1  6.7 -1.2  2.3 -0.9 -0.4 -0.7 -0.3 -0.3  1.3 -0.6 -0.1 -0.4 -0.6 -1.   3.6 -0.4  3.5  0.8  4.  -0.7 -1.4 -0.5  2.4 -0.4  3.4 -0.2  4.8  2.7 11.8 -0.1  6.4 -0.2 -0.2 -1.4 -2.5 -0.   0.5 -1.  -1.3 -2.2 -0.6  8.7  1.3  2.9  1.7]
ty_50sample [[9 3 2 2 4 8 5 7 6 0]
 [8 7 6 2 1 5 9 4 3 0]
 [2 4 0 7 6 5 9 8 8 3]
 [6 3 5 1 4 0 7 8 9 9]
 [9 7 3 1 4 4 5 0 0 6]
 [7 2 4 5 1 0 0 8 3 3]
 [1 4 0 0 7 7 3 3 9 5]
 [7 2 9 1 5 8 3 4 0 6]
 [6 8 5 4 9 7 1 3 0 2]
 [0 7 9 4 3 6 2 5 1 8]]
tt_50sample [[9 3 2 1 4 8 7 5 6 0]
 [8 7 6 2 1 5 9 4 3 0]
 [2 4 0 7 6 5 9 1 8 3]
 [6 3 5 1 4 0 7 8 2 9]
 [9 7 3 1 4 8 5 2 0 6]
 [7 2 4 5 9 1 0 8 6 3]
 [1 4 6 8 0 7 3 9 2 5]
 [7 2 9 1 5 8 3 4 0 6]
 [6 8 4 5 9 7 1 3 0 2]
 [0 7 9 4 3 6 2 5 1 8]]
vm  [-1.7 -0.6  4.7 -1.7 -2.   0.  -0.4 -0.6  0.2 -0.7  5.8  0.   0.5  1.  11.8  4.1 -0.1 -0.6  0.1  3.2 -0.1 -0.5 -0.6 -0.9 -1.1 -0.2 -0.3 -0.3  0.8 -1.   2.4 -0.7 -1.2  8.  -0.4 -0.4 -0.3  5.3  0.6 -1.1 -0.3  1.8 -0.   2.8 -1.1 -0.2 -2.8 -0.8 -0.7 -1.1 -1.3 -0.6 -1.4  9.3 -1.6 -1.9 -0.7  3.1  3.2 -0.2  9.1 -0.6 -0.4  2.8 -0.5  0.2 -0.7 -0.1 -0.6 -0.2  0.5 -0.7 -0.5 -0.2 -4.3 -0.2  0.3 -0.8  1.1  0.5 -1.3 -0.4 -0.2 -0.3  1.1  3.2 -0.6 -0.4  1.  -0.  -0.9 -0.3 -0.5 -0.5 -1.1  0.7  0.2 -1.6 -0.5 -0.5  3.   4.1  3.8 -0.2 -0.3 -0.4 -3.1  1.9  2.   2.1  0.2 -0.7 -0.2 -0.9  0.   4.1 -0.2  1.1 -0.9 -0.8 -0.2 -0.6 -0.1 -0.1 -0.5 13.   0.7 -2.3  6.   6.1 -1.3 -1.  -0.3 -0.4 -4.3 -0.8 -0.6 -0.2 -0.1 -0.7 -0.5  2.4 -0.5 -0.4 -0.4 -0.7  0.  -0.4  0.5 -0.1  4.9 -0.6 -1.2 -0.6 -0.4 -0.4 -0.4 -0.2  4.3 -0.8 -0.3 -1.1 -0.1 -0.4  1.  -0.3  1.5  1.7 -0.4 -0.9 -0.5  3.  -1.2 -0.5 -0.4  0.2  0.2 -1.8  2.7 -0.3 -1.3 -0.1 -0.8 -1.3  1.9 -0.6 -1.6 -1.4 -1.2  4.7 -0.5 -0.1  0.6 -0.6 -2.3 -0.8 -1.9 -0.3 -0.3 -0.8 -0.2 -0.  -0.7 -0.9  2.  -4.   2.5 -0.2 -2.2 -0.3 -0.4  0.9 -0.8  4.5 -0.4 -0.2 -0.5 -0.2  1.3 -0.3 -0.5  0.  -0.3  0.4 -0.7  1.6  0.4  1.8 -0.1  2.5 -1.4  1.6 -0.2 -1.6  0.3 -1.3 -0.2 -2.2 -0.1 -3.9 -0.4 -2.2 -0.5 -0.5  5.3  5.8 -0.5 -0.1 -0.6 -0.3  2.  -0.5 -0.1 -0.1  3.5 -2. ]
vy_50sample [[7 1 1 2 3 4 8 0 6 9]
 [2 2 9 3 8 1 5 0 6 4]
 [3 8 6 9 2 0 1 5 5 4]
 [3 3 6 7 7 8 8 0 1 4]
 [5 2 6 4 0 7 7 3 8 9]
 [6 9 0 4 8 7 1 2 5 3]
 [7 9 4 6 0 0 3 2 2 5]
 [7 7 4 0 2 8 1 5 3 9]
 [5 1 7 2 8 3 0 9 4 6]
 [7 1 6 6 8 4 9 5 3 2]]
vt_50sample [[7 5 1 2 3 4 8 0 6 9]
 [2 7 9 8 3 1 5 0 6 4]
 [3 8 6 9 2 0 1 7 5 4]
 [3 2 6 9 7 8 0 5 1 4]
 [5 2 6 4 0 7 1 3 8 9]
 [6 9 0 4 8 7 1 2 5 3]
 [7 9 4 6 8 0 3 1 2 5]
 [7 6 4 0 2 8 1 5 3 9]
 [5 1 7 2 8 3 9 0 4 6]
 [7 1 0 6 8 4 9 5 3 2]]
Epoch  7710: Training cost= 0.4295, Training acc= 0.7483, Validation cost= 0.4353, Validation acc= 0.7488
Epoch  7720: Training cost= 0.3669, Training acc= 0.7484, Validation cost= 0.4602, Validation acc= 0.7489
Epoch  7730: Training cost= 0.4142, Training acc= 0.7485, Validation cost= 0.4150, Validation acc= 0.7490
Epoch  7740: Training cost= 0.4854, Training acc= 0.7486, Validation cost= 0.3610, Validation acc= 0.7491
Epoch  7750: Training cost= 0.3655, Training acc= 0.7487, Validation cost= 0.3665, Validation acc= 0.7492
Epoch  7760: Training cost= 0.3820, Training acc= 0.7488, Validation cost= 0.3872, Validation acc= 0.7493
Epoch  7770: Training cost= 0.3389, Training acc= 0.7489, Validation cost= 0.3664, Validation acc= 0.7494
Epoch  7780: Training cost= 0.3653, Training acc= 0.7490, Validation cost= 0.3996, Validation acc= 0.7495
Epoch  7790: Training cost= 0.3433, Training acc= 0.7492, Validation cost= 0.3901, Validation acc= 0.7496
Epoch  7800: Training cost= 0.4337, Training acc= 0.7493, Validation cost= 0.4600, Validation acc= 0.7497
tm  [-1.1  0.2  3.2 -0.6 -1.5  0.1 -0.1 -0.7 -1.1  0.1 -2.5  0.4 -0.4 -0.1  7.2 -2.1 -0.6 -0.4  0.2 -0.2 -0.6 -0.9  2.3 -0.5 -0.4  2.8 -0.3 -0.  -1.4 -1.1 -0.3  2.8 -0.5  1.1  1.  -0.3  2.6 -0.6 -0.2 -0.9 -0.5 -1.4 -0.7  1.7 -1.2  0.3 -1.1  1.  -0.   3.7 -1.  -0.7 -1.6 -0.3  1.4 -0.8 -0.7 -1.2  1.5  2.3  6.8  1.6 -0.6  2.1 -0.7  1.2  0.2 -0.6  0.7  4.8 -0.4  5.  -0.3 -0.6 -2.1 -0.2  2.1 -0.9  3.7  1.2 -2.2 -0.2 -0.3 -0.2  1.6 -1.6 -0.  -0.1  0.  -0.4 -0.7 -0.9 -0.7  0.  -0.6 -0.1 -0.3 -1.5  0.1 -0.3 -0.   2.6  3.6  0.1  0.8 -0.1 -2.  -0.3 -1.4 -0.8 -0.5  0.2 -0.1 -0.7  5.8 -1.5 -0.7  2.1 -0.9 -0.3 -0.1  3.1 -0.1  0.  -0.7  6.9 -0.1  3.4 -0.1  4.1 -0.6 -0.8 -0.9 -0.3 -1.4 -1.8 -1.   0.3 -0.1 -0.4  2.4 -0.8 -0.2  0.1 -1.  -1.  -0.6  0.2 -1.6 -0.9  2.8 -0.5 -0.2  0.1 -0.5 -0.4  0.8  0.7  1.3 -1.1 -0.4 -0.4 -0.5 -0.7 -0.7  0.5 -0.4  4.2 -0.1 -0.3 -0.2 -0.4 -0.1 -0.3 -0.3  6.4  0.3 -1.2  3.6 -0.   0.1 -0.  -0.1 -0.9  2.9 -0.6 -0.7 -0.6  0.5  4.  -0.5 -0.1  0.4 -0.7 -1.3 -0.1 -1.3 -0.3  0.4  0.1 -0.4  1.3 -0.1 -0.8  1.6 -2.8 -1.1  0.9  8.7 -0.2 -0.2 -1.  -1.3  2.9 -0.  -0.5 -0.1 -0.5 -0.3 -0.3 -0.7 -0.1 -0.2 -0.9 -0.1 -0.6 -1.1  0.7  0.4  0.  -1.3  0.9 -0.7  4.9  7.  -0.6  2.8 -0.9  3.3  6.1 -0.9  4.2 -0.3 -0.3  8.2  4.1 -0.6 -0.4 -0.7 -0.2  4.2 -1.4 -0.1 -0.5  3.7 -0.5]
ty_50sample [[0 1 8 7 3 4 6 9 2 5]
 [3 1 8 5 2 7 9 0 6 4]
 [4 8 0 5 2 6 1 7 9 3]
 [1 8 4 3 5 5 2 9 6 6]
 [0 7 4 1 1 8 3 2 9 6]
 [5 7 1 2 2 6 3 3 4 0]
 [6 1 8 8 7 3 4 2 0 9]
 [5 2 7 7 4 0 1 9 6 8]
 [6 9 1 2 0 4 5 3 8 7]
 [9 8 8 3 6 1 1 7 4 5]]
tt_50sample [[0 1 8 7 3 4 6 9 2 5]
 [3 1 8 5 2 7 9 0 6 4]
 [8 4 0 5 2 6 1 9 7 3]
 [1 8 4 3 5 0 2 9 7 6]
 [0 7 4 1 5 8 3 2 9 6]
 [5 7 1 2 9 6 3 0 4 8]
 [6 1 8 5 7 3 4 2 0 9]
 [5 2 3 7 4 1 9 0 6 8]
 [6 9 0 1 2 4 5 3 8 7]
 [9 0 8 3 6 1 2 7 4 5]]
vm  [-0.6 -0.3  3.9  2.3 -0.8 -0.3 -0.5 -0.5 -0.4  1.9 -0.4 -0.4 -0.3 -0.2  3.5 -0.4 -0.7 -0.1 -0.1  0.5 -0.6 -0.4  4.  -0.2 -0.9  1.1 -0.2 -0.2 -0.9 -0.7 -1.2  1.   0.3 -1.2  2.1 -0.6  1.  -0.6 -2.6 -0.4 -0.6  2.4 -0.6 -1.5 -0.2 -0.2 -1.2 -0.5 -0.1  7.9 -0.7 -0.6 -1.1  4.3 -0.  -0.1 -0.3  0.8  2.   4.8  5.2 -0.  -0.2  2.7 -0.4 -0.4 -0.2  0.5  1.1 -0.4 -0.3  2.5  0.6 -0.1 -3.9 -0.1  0.7  0.2  2.7 -0.2 -2.2 -0.3  0.4 -0.1 -0.2  2.4 -0.5  0.3 -0.6 -0.2 -0.6 -0.8 -0.9 -0.3 -1.  -0.   0.8 -1.4 -0.1 -0.4 -1.1  4.8  2.  -0.3 -0.1  0.3 -2.5 -1.2 -0.4 -0.1 -0.4  0.3 -0.1 -0.4  4.  -1.  -0.4  0.4 -0.1  1.4 -0.1 -0.3  0.1 -0.3 -0.4  3.8 -0.7 -0.5 -0.  -0.1  2.7 -0.9 -0.8 -0.3  8.5  6.4 -0.4 -0.6 -0.5 -0.2 -0.1 -0.8 -0.3  0.6 -0.6 -0.1 -0.4 -0.2 -0.5 -0.1  0.1 -0.2  1.2  0.  -0.3 -0.2 -0.3 -0.2 -1.2 -0.6  1.8  2.5  1.1 -0.6 -0.9 -0.6 -0.8  1.3 -0.5  1.   1.9 -0.4  0.1 -0.2 -0.4  2.8 -1.6 -0.7 10.4 -0.3  0.9 -0.5 -0.  -0.9  0.9 -0.2 -0.6 -0.3 -0.2  2.8 -0.4 -1.1 -0.2 -1.  -0.8 -0.2 -1.4 -0.3 -0.4 -0.  -0.6  0.8  0.5 -0.4  0.8 -2.1 -0.8 -0.2  6.5 -0.2 -0.1 -0.6 -0.8  3.4 -0.8 -0.2  6.5 -0.3 -0.3  0.6 -0.6 -0.7 -0.4 -1.3  4.5 -0.1 -0.8  3.3 -0.2 -0.1  2.   0.8 -0.4  3.8  1.9 -0.6  3.7 -1.7  1.6  1.7 -0.9  1.4 -0.2 -0.2  7.7  0.2  0.5  0.  -0.5 -0.   4.4 -0.5 -2.1  0.8 -0.2  3.1]
vy_50sample [[6 0 8 1 2 7 9 9 4 3]
 [9 9 0 5 1 8 4 3 7 2]
 [9 6 5 1 7 7 3 4 2 8]
 [0 3 2 5 7 4 8 9 1 6]
 [8 2 5 3 3 7 6 6 4 0]
 [1 5 8 4 7 2 0 3 9 6]
 [9 6 5 3 2 0 1 8 7 4]
 [9 6 0 4 8 3 5 5 2 1]
 [4 7 8 3 0 9 6 1 2 5]
 [4 8 6 7 1 2 9 5 3 0]]
vt_50sample [[6 0 8 1 2 7 9 5 4 3]
 [9 6 0 5 1 8 4 3 2 7]
 [9 6 5 1 0 7 3 4 2 8]
 [0 3 2 5 7 4 8 9 1 6]
 [2 8 5 9 3 7 6 1 4 0]
 [1 8 5 4 2 7 0 3 9 6]
 [9 6 5 3 2 0 1 8 4 7]
 [9 6 0 4 8 3 5 2 7 1]
 [4 7 8 3 0 9 6 1 2 5]
 [4 8 6 7 1 2 9 5 3 0]]
Epoch  7810: Training cost= 0.3704, Training acc= 0.7494, Validation cost= 0.5183, Validation acc= 0.7498
Epoch  7820: Training cost= 0.4133, Training acc= 0.7495, Validation cost= 0.4441, Validation acc= 0.7499
Epoch  7830: Training cost= 0.4172, Training acc= 0.7496, Validation cost= 0.4076, Validation acc= 0.7500
Epoch  7840: Training cost= 0.3804, Training acc= 0.7497, Validation cost= 0.3858, Validation acc= 0.7501
Epoch  7850: Training cost= 0.4229, Training acc= 0.7498, Validation cost= 0.3541, Validation acc= 0.7502
Epoch  7860: Training cost= 0.4451, Training acc= 0.7499, Validation cost= 0.4013, Validation acc= 0.7503
Epoch  7870: Training cost= 0.4625, Training acc= 0.7500, Validation cost= 0.4654, Validation acc= 0.7504
Epoch  7880: Training cost= 0.4125, Training acc= 0.7501, Validation cost= 0.4001, Validation acc= 0.7505
Epoch  7890: Training cost= 0.4118, Training acc= 0.7502, Validation cost= 0.5094, Validation acc= 0.7506
Epoch  7900: Training cost= 0.3661, Training acc= 0.7503, Validation cost= 0.3805, Validation acc= 0.7507
tm  [-0.5 -0.7 -0.4 -0.6 -0.4 -0.5 -0.5 -0.8  1.2  2.9 -1.7 -0.2 -0.9 -0.3  1.2 -0.9 -0.5 -0.1 -0.6  2.1 -0.6 -0.7  3.9 -0.4 -0.5 -0.2  0.5 -0.1 -0.8 -1.5 -1.  -0.7 -0.4 -3.7  2.  -1.3 -0.8  2.2 -0.9 -0.5 -0.7  7.4  1.6 -0.1 -0.6 -0.4 -2.  -0.5 -0.2  8.2 -0.7 -0.7 -1.5  5.2 -0.4  0.5 -0.4  4.7  3.7  4.5  6.5 -1.2 -0.1  3.2 -0.2 -0.6 -0.2  2.1  0.8 -0.9 -0.4  1.3 -0.1 -0.5 -5.3 -0.1 -0.2 -0.   0.2 -0.4 -3.6 -0.2  0.7  0.4 -0.4  8.3 -0.2 -0.4 -0.3 -0.2 -0.2 -1.  -1.4 -0.5 -1.4 -0.5  1.1 -1.8 -0.1 -0.4 -1.1 -0.1  1.8 -0.6 -0.4 -0.3 -3.2 -1.2 -0.7  2.   2.  -0.3 -0.1 -1.   5.2 -1.  -0.3  0.7 -0.3  3.5 -0.3 -1.2  0.3 -0.7 -0.3  1.3 -0.7 -0.6  4.9  1.9 -0.  -0.7 -0.8 -0.3  7.5 -2.  -0.6 -1.  -0.7 -0.4  0.3 -0.3 -0.2 -0.2 -0.7 -0.5 -0.4 -0.6  7.2 -0.4  1.6 -0.2  1.9  0.9 -0.3  0.3 -0.1 -0.4 -0.2 -0.4  0.7 -0.5  0.2 -0.6 -1.  -0.3 -0.9  0.1 -0.7 -0.1  1.5  2.8 -0.5 -0.4 -0.5 -2.5 -0.8 -1.3  5.3  0.6 -1.7 -0.5 -0.  -1.1  2.3  1.9 -0.7 -0.1 -0.5  7.1 -0.4 -0.8 -0.5 -1.1 -1.  -0.9 -2.3 -0.7 -0.2 -0.  -0.2  2.  -0.5 -0.3 -0.1 -2.6  2.  -0.3 -1.  -0.3 -0.3 -0.5 -0.7  3.3 -0.6  0.1  2.5 -0.4 -0.8  0.2 -0.7 -0.5  0.8 -0.6  1.8 -0.1 -1.2  2.8 -0.6  1.9 -0.7  0.9 -0.3 -0.8  1.1  3.1  3.6 -2.6  0.8 -4.7 -0.6 -2.5 -0.2 -0.3 10.6  2.3  0.  -0.4 -0.7  0.9  7.2 -0.3 -0.7 -0.3  2.9  0.4]
ty_50sample [[5 8 0 1 6 2 4 3 9 7]
 [9 0 6 8 2 2 1 4 5 3]
 [1 5 7 3 0 2 8 8 9 6]
 [6 2 2 5 3 4 4 7 0 1]
 [8 4 5 9 9 3 7 1 2 0]
 [5 9 7 7 3 0 8 1 4 6]
 [8 5 3 2 6 1 4 9 7 0]
 [7 9 1 0 0 3 6 4 2 2]
 [0 0 1 9 9 2 4 4 3 7]
 [4 6 8 9 7 1 5 3 0 2]]
tt_50sample [[5 8 0 1 6 2 4 3 7 9]
 [9 0 6 8 2 7 1 4 5 3]
 [1 5 7 3 0 2 4 8 9 6]
 [6 2 8 5 3 9 4 7 0 1]
 [8 4 5 6 9 3 7 1 2 0]
 [5 2 9 7 3 0 8 1 4 6]
 [8 5 3 2 6 1 4 9 7 0]
 [7 9 5 1 0 3 8 6 4 2]
 [6 0 1 9 5 8 2 4 3 7]
 [4 6 8 9 7 1 5 3 0 2]]
vm  [-1.3 -0.7 -0.6 -0.5 -0.6 -0.1 -0.2 -0.4  4.3  0.8 -0.5  1.3 -1.3 -0.6  0.6 -0.2 -1.2 -0.4 -0.5  2.5 -0.3  0.5  0.1 -0.8 -0.5  0.  -0.1  0.1  1.5 -1.5  1.1 -0.8  1.6 -0.9 -0.3 -1.6 -1.1 -0.2 -2.2 -0.9 -0.1  2.3 -0.6 -0.9  0.1  0.2 -1.8 -0.  -0.7 -0.1 -0.6 -0.6 -0.2  0.6 -1.2  0.9 -0.   2.5  5.5  1.   6.3 -1.1  2.   2.7  0.8 -0.2 -0.4  2.3  1.3 -0.1 -0.2 -0.9 -0.4 -0.1 -4.8 -0.2 -0.7 -0.1  1.2  0.1 -0.8 -0.2  1.1 -0.1 -0.4  3.1 -0.3 -0.4 -0.1  0.1 -0.4 -0.9 -0.9 -1.3 -0.8 -0.5  0.7 -2.2 -0.4 -0.2 -0.6 -0.9  3.2 -0.1 -0.9 -0.2 -2.6  0.6 -0.4  1.8  1.   0.1 -0.2 -1.1  4.5  2.7  0.1  2.4 -0.6  3.7 -0.4 -1.3 -0.1  0.4 -0.3  1.2  0.3  2.5  6.   2.9  2.2 -1.4 -0.6 -0.4 10.9 10.3  0.1 -0.6 -0.2 -0.2  1.4  1.1  1.4 -0.3 -1.5  0.1 -0.1 -0.5  4.8 -0.1  1.8 -0.3 -0.4  2.5 -0.3 -0.2 -0.6  0.8 -0.9 -0.2  0.1  1.1  1.9 -0.4 -0.1 -0.3  0.3  3.6 -0.6  0.  -0.3  1.5 -1.1 -0.9 -0.1 -1.3 -1.6 -0.4 10.1  2.6 -1.  -0.3 -0.7 -1.2  0.  -0.5 -1.  -0.1 -0.8  7.2 -0.3 -0.5 -0.7 -0.9 -1.2 -1.  -1.3 -1.4 -0.1 -1.  -0.4  3.8 -0.3 -0.8  1.1 -1.9  1.4 -0.7 -0.9 -0.2 -0.3  3.6 -0.9  4.3 -1.  -0.1  4.1 -0.4 -0.3  0.2 -1.  -0.5  0.7 -0.4  2.6  1.  -1.7  3.5 -0.1  3.4  0.6 -0.  -0.4 -0.7 -0.4  3.1  0.7 -2.1  2.9 -1.8 -0.6 -1.1 -0.  -0.1  4.3  0.1 -0.2 -0.3 -1.  -0.4  0.4 -1.  -1.9 -0.4  4.6 -0.5]
vy_50sample [[6 1 5 3 8 4 0 9 7 7]
 [8 0 7 9 3 1 1 4 2 5]
 [0 9 8 3 5 7 4 2 6 1]
 [3 7 5 4 2 8 0 6 1 1]
 [1 3 0 2 2 4 6 8 5 7]
 [2 6 9 7 0 4 1 3 8 8]
 [8 3 7 5 9 2 4 1 6 0]
 [2 0 3 7 1 5 8 4 6 9]
 [2 0 1 9 5 3 6 7 4 8]
 [2 3 7 4 8 6 5 1 0 9]]
vt_50sample [[6 1 5 3 8 4 0 2 7 9]
 [8 0 9 7 3 1 6 2 4 5]
 [0 9 8 3 5 7 4 2 6 1]
 [3 7 5 4 2 8 0 6 9 1]
 [1 3 0 9 2 4 6 8 5 7]
 [2 6 9 7 0 4 1 3 8 5]
 [8 3 7 5 2 9 4 1 6 0]
 [2 0 3 1 7 5 8 4 6 9]
 [2 0 1 9 5 3 6 7 4 8]
 [2 3 7 4 8 6 5 0 1 9]]
Epoch  7910: Training cost= 0.4210, Training acc= 0.7504, Validation cost= 0.3855, Validation acc= 0.7508
Epoch  7920: Training cost= 0.4012, Training acc= 0.7505, Validation cost= 0.4756, Validation acc= 0.7509
Epoch  7930: Training cost= 0.4172, Training acc= 0.7506, Validation cost= 0.3941, Validation acc= 0.7510
Epoch  7940: Training cost= 0.3936, Training acc= 0.7507, Validation cost= 0.3854, Validation acc= 0.7511
Epoch  7950: Training cost= 0.3756, Training acc= 0.7508, Validation cost= 0.4651, Validation acc= 0.7512
Epoch  7960: Training cost= 0.4147, Training acc= 0.7509, Validation cost= 0.3944, Validation acc= 0.7513
Epoch  7970: Training cost= 0.3876, Training acc= 0.7510, Validation cost= 0.4060, Validation acc= 0.7515
Epoch  7980: Training cost= 0.4076, Training acc= 0.7511, Validation cost= 0.4343, Validation acc= 0.7516
Epoch  7990: Training cost= 0.4159, Training acc= 0.7512, Validation cost= 0.3699, Validation acc= 0.7517
Epoch  8000: Training cost= 0.4143, Training acc= 0.7513, Validation cost= 0.4040, Validation acc= 0.7518
tm  [ 0.7  0.7  8.4 12.  -1.7 -1.1 -0.2 -0.4 -0.7 -1.1  1.3  1.8 -1.  -0.5  2.9  1.4 -0.3 -0.3  0.3 -0.9 -0.2 -0.  -1.   1.2 -1.4 -0.  -0.2 -0.2  0.1 -0.2 -0.3 -0.8  0.9  8.2 -1.2  1.   1.9  0.6  2.7 -0.5  0.1 -0.8  0.7 -1.2 -0.3 -0.1  4.4  1.7  1.8 -1.7 -1.  -0.1  3.6 -1.2 -0.8 -0.1 -0.   4.3 -1.   2.7 -1.4 -0.6 -0.1  0.6 -0.1 -0.3 -0.3 -0.6  0.2  0.9 -0.  -0.4 -0.3 -0.3  0.6 -0.3 -0.8 -0.5 -0.7 -0.4 10.3 -0.1 -0.9 -0.1 -1.1 -0.4  0.4 -0.4  2.3  0.3 -0.1  1.5  2.2  1.5  0.5 -0.2  2.3 -0.2 -0.1  0.5  3.6  2.2 -0.8 -0.3 -0.4 -0.1 -0.  -0.2  0.3 -1.4  1.5 -0.7 -0.2 -0.2 -0.7  3.2  0.1 -0.3  0.5 -0.3 -0.   4.2 -0.  -0.  -0.2  2.6  3.5  7.5 -0.4  1.6  2.4 -0.6  0.5 -0.1 -1.3  7.4  0.2  0.1  0.3 -0.6  0.5 -0.5  0.1 -0.5 -0.3  0.6 -0.3 -1.3 -0.4  0.1 -1.6 -0.1  1.9  0.7 -0.5 -0.1 -0.6 -0.1 -0.7 -0.2 -0.7  0.5  0.1  0.3  1.6 -0.4  1.2  0.2 -0.4  4.4 -1.  -0.2 -0.6 -0.4 -0.1  3.  -0.8  1.1 -0.1  0.5 -0.6 -0.4 -0.  -1.1 -1.  -0.6  4.8 -0.7 -0.2  1.5 -0.3  0.  -1.1 -1.   6.9  1.2  1.4  0.3 -0.5 -0.6 -0.5 -0.6  0.1 -0.4 -1.   3.2  1.3 -0.2 -1.1 -0.4 -0.5  3.  -0.3 -0.2 -1.2 -0.2  5.1 -0.1  1.6 -0.  -1.2 -0.3  0.7 -0.3 -0.4  1.2 -1.  -0.1  0.6  2.4 -0.4 -0.4 -0.4 -0.7 -0.7 -2.4 -0.4  2.2 -0.   4.9 -0.2  2.9 -0.2 -0.4 -1.7 -1.7 -0.3 -0.1 -0.  -0.5 -2.3 -1.1  2.8 -0.4  3.9  0.8]
ty_50sample [[7 3 9 6 5 8 8 1 4 4]
 [0 5 2 3 1 6 6 4 9 9]
 [9 0 3 8 2 1 7 4 6 5]
 [2 1 4 5 3 8 7 6 0 9]
 [9 9 5 6 1 7 0 4 2 3]
 [0 4 7 6 5 9 9 2 2 8]
 [2 5 6 1 8 0 9 7 4 3]
 [6 5 2 3 8 8 9 0 4 7]
 [9 6 8 1 1 2 0 4 4 3]
 [6 8 1 4 3 7 2 5 0 9]]
tt_50sample [[7 3 9 6 5 8 2 1 0 4]
 [0 5 2 3 1 6 4 8 7 9]
 [9 0 3 8 2 1 7 4 6 5]
 [2 1 4 5 8 3 7 6 9 0]
 [8 9 5 6 1 7 0 4 2 3]
 [0 4 7 6 5 9 1 3 2 8]
 [5 2 1 6 8 0 9 7 4 3]
 [6 2 5 3 8 1 9 0 4 7]
 [9 6 8 1 2 0 7 5 4 3]
 [6 8 1 4 3 7 2 5 0 9]]
vm  [-1.1  2.2 -0.3  2.9 -0.8  0.6 -0.5 -0.8 -1.1 -1.4  7.3 -0.9  2.5  0.5 -0.5  6.   0.5 -0.4 -0.1 -1.  -0.4 -0.4  0.6 -0.2 -1.7  2.9 -0.  -0.4 -0.1  1.3  1.4 -0.4 -0.2 -0.3 -0.4  1.8  4.   3.2  0.2 -0.5 -0.3 -1.5 -0.4 -0.2 -1.1 -0.2  1.8 -1.1 -1.  -0.2 -0.5 -0.9  0.4  4.8 -1.5  2.2 -0.2 -0.7 -0.8  0.5  3.1  2.  -0.7 -0.3 -0.   0.8 -0.3 -0.1 -0.9  2.  -0.4 -0.1  0.  -0.4  1.7 -0.4  3.1 -0.7  2.6  1.   3.5 -0.3 -0.5 -0.1  1.  -1.3 -0.1 -0.5  1.2  0.3 -0.5  0.7  1.2  1.1 -0.2  0.8 -0.2 -0.2 -0.4 -0.1  3.5 -0.6  1.7  0.3  0.6  1.8 -0.4  1.8  3.4 -1.4 -1.4 -0.1 -0.1  2.4 -0.3  2.3 -0.4 -1.3 -0.6 -0.4 -0.4  4.5  0.1  0.2 -0.2 -0.7  1.4 -0.9 -0.8  1.2  0.9 -0.7 -0.4 -0.   6.4  5.2 -0.3  0.8  2.8 -0.7 -0.5 -0.7 -1.3 -0.2  0.5 -0.7 -0.   2.  -0.2  1.9 -0.2 -0.2 -0.5 -1.2 -0.5 -0.3 -0.4  0.3 -0.4 -0.7 -0.   2.3 -0.7 -0.3 -0.6 -0.2  1.9  2.7  1.1  1.2 -0.3 -0.8 -0.5 -0.1 -0.4  2.5 -0.7  0.7  2.9 -1.   1.2  2.   0.4 -1.4 -0.6 -0.5 -0.3 -0.2 -0.5  1.5 -0.4 -0.3 -0.3 -0.9 -0.3  2.3  1.   2.5 -0.4 -0.1 -0.3 -0.4 -0.8 -0.7  1.6 -0.8 -0.7  2.   4.8 -0.3 -0.3  2.3 -0.9  4.4 -0.2 -0.8  2.  -0.4 -0.1 -0.6 -0.2  0.7 -0.3 -0.8  0.9  2.1  2.4  3.8  0.6 -0.5 -0.5 -0.5 -0.7  3.2  1.   2.8 -0.1  0.9 -0.  10.5 -1.1  6.3 -0.4 -0.6 -0.1 -0.7 -0.   1.8 -0.3 -1.  -1.  -0.1  0.4  1.5 -0.2  1.3]
vy_50sample [[2 1 6 3 3 4 8 0 0 5]
 [3 1 7 2 4 5 9 8 0 6]
 [3 5 7 1 8 4 9 2 0 6]
 [2 3 9 6 8 0 4 1 5 7]
 [2 3 4 8 6 0 5 1 7 9]
 [7 6 2 1 5 9 4 3 8 0]
 [0 6 4 5 8 7 3 2 9 1]
 [9 0 7 1 6 8 4 3 2 5]
 [3 5 2 4 0 1 9 7 6 8]
 [5 4 0 7 3 9 6 1 8 2]]
vt_50sample [[2 1 6 3 9 4 8 7 0 5]
 [3 1 7 2 4 5 9 8 0 6]
 [3 5 7 1 8 4 2 9 0 6]
 [2 3 9 6 8 0 4 1 5 7]
 [2 3 4 8 6 0 5 1 7 9]
 [7 6 2 1 5 9 4 3 8 0]
 [0 6 4 5 8 7 3 2 9 1]
 [9 0 1 7 6 8 4 3 2 5]
 [3 5 2 4 0 1 9 7 6 8]
 [5 4 0 7 3 9 6 1 8 2]]
Epoch  8010: Training cost= 0.4144, Training acc= 0.7514, Validation cost= 0.4982, Validation acc= 0.7519
Epoch  8020: Training cost= 0.4012, Training acc= 0.7515, Validation cost= 0.4384, Validation acc= 0.7520
Epoch  8030: Training cost= 0.4181, Training acc= 0.7516, Validation cost= 0.4255, Validation acc= 0.7521
Epoch  8040: Training cost= 0.3971, Training acc= 0.7517, Validation cost= 0.4212, Validation acc= 0.7522
Epoch  8050: Training cost= 0.4663, Training acc= 0.7518, Validation cost= 0.4661, Validation acc= 0.7523
Epoch  8060: Training cost= 0.4681, Training acc= 0.7519, Validation cost= 0.4073, Validation acc= 0.7524
Epoch  8070: Training cost= 0.4126, Training acc= 0.7520, Validation cost= 0.3965, Validation acc= 0.7525
Epoch  8080: Training cost= 0.4331, Training acc= 0.7521, Validation cost= 0.3837, Validation acc= 0.7526
Epoch  8090: Training cost= 0.4003, Training acc= 0.7522, Validation cost= 0.4786, Validation acc= 0.7527
Epoch  8100: Training cost= 0.4291, Training acc= 0.7523, Validation cost= 0.3610, Validation acc= 0.7528
tm  [-1.2 -0.4  6.2  4.1 -1.3 -0.2 -0.1 -0.6  0.9 -0.1 -0.4  0.1 -0.6 -0.2  6.3  1.7 -0.9 -0.8 -0.4  0.3 -0.2 -0.2  0.9 -0.7 -1.3 -0.2 -0.  -0.2  2.4 -0.9 -0.6 -0.7  0.4  4.4 -0.8 -0.6 -0.3 -0.2 -2.  -0.7  0.5  3.   0.8 -1.3 -0.   0.2 -1.4  0.8 -0.5  1.7 -1.  -0.2 -0.7  0.9 -1.  -0.5 -0.2  5.   1.7  3.9  4.7 -0.8 -0.   1.9 -0.1  1.3 -0.3  0.3  0.7  0.3 -0.1 -0.9 -0.4 -0.4 -3.1 -0.  -0.4 -0.3 -0.   0.2 -0.6 -0.1 -0.3  0.6  0.4  4.4 -0.8 -0.2  0.2 -0.1 -0.4  0.3 -0.5 -0.6 -0.5  0.1  3.  -1.5 -0.4 -0.2  0.1  3.5  1.3  0.  -0.5  0.4 -1.9 -0.7 -0.2 -0.3  1.2 -0.4 -0.2 -0.7 -0.1  5.9 -0.3 -0.1 -0.7  0.  -0.4  0.1  0.2 -0.1 -0.3  6.6  1.9  1.8  3.7  2.3  2.5 -1.2 -0.4 -0.5  3.9  8.9 -0.1 -0.3 -0.5 -0.7  0.6  0.6  0.7 -0.1 -1.5 -0.  -0.1 -0.5  2.   1.3  0.5 -0.6 -0.1  0.2 -0.4  0.3 -0.7 -0.3 -0.9 -0.3 -0.   2.9  0.2 -0.2 -0.2 -0.4  1.6  2.4 -0.5  1.2 -0.4  1.  -1.  -0.7 -0.1 -0.1 -1.5 -0.6  8.8  0.6 -1.3 -0.2 -0.6 -1.2 -0.3 -0.4 -0.5 -0.7 -1.   3.7 -0.1 -0.6 -0.6 -0.8 -1.  -0.6 -1.  -0.2 -0.3 -1.  -0.6  0.9 -0.5 -0.8  1.7 -2.2  1.5 -0.1 -1.1 -0.2 -0.1  5.2 -0.9  3.5 -1.3 -0.2  6.  -0.2  1.  -0.1 -1.1 -0.3 -0.2 -0.1  2.6  2.8 -0.7  2.   0.5  2.6 -0.  -0.2 -0.3 -0.9 -0.4 -1.6 -0.2 -1.2  1.6 -2.1 -0.5 -1.1  0.6 -0.5  3.7  1.7 -0.4  1.  -0.8 -0.3  0.5 -1.3 -1.5 -0.2  4.9 -0. ]
ty_50sample [[6 5 1 7 8 3 9 2 4 0]
 [8 2 3 9 6 5 0 4 1 7]
 [8 1 1 3 7 6 2 9 4 0]
 [3 6 8 7 0 5 2 4 1 9]
 [0 8 7 5 3 3 9 4 2 6]
 [9 6 2 4 4 8 3 7 0 5]
 [3 1 9 7 4 5 2 6 0 8]
 [5 3 2 0 4 6 8 7 1 9]
 [7 6 0 3 2 4 5 9 8 1]
 [8 3 3 2 7 1 4 5 0 6]]
tt_50sample [[6 5 1 7 8 3 9 2 4 0]
 [8 2 3 9 6 5 0 4 1 7]
 [8 1 5 3 7 6 2 9 4 0]
 [3 6 8 7 0 5 2 4 1 9]
 [0 8 7 1 5 3 9 4 2 6]
 [6 9 2 1 4 8 3 7 0 5]
 [3 1 9 7 4 5 2 6 8 0]
 [5 3 2 0 4 6 8 7 1 9]
 [7 6 0 3 2 4 5 9 1 8]
 [8 3 9 2 7 1 4 5 6 0]]
vm  [-0.2  1.8  7.5  7.2 -1.6 -0.6 -0.2 -0.3 -0.6 -1.1  4.6 -0.2 -0.3 -0.3  4.8  6.  -0.3  0.1  0.8 -0.4 -0.4 -0.  -0.1 -0.1 -1.3  1.2 -0.2 -0.2  2.3  0.3 -0.3 -0.5  0.2  6.5 -0.6  1.2  1.7  4.2  4.6 -0.5 -0.1 -1.3 -0.5 -0.  -0.8 -0.1  2.5 -0.3 -0.1 -0.2 -0.8 -0.3  3.1  2.8 -1.3 -0.5 -0.2  0.6 -0.4  2.6 -0.4  0.1  0.3  0.3  1.1 -0.9 -0.1 -0.4 -0.5 -0.1  0.6 -0.8  0.5 -0.2 -0.8 -0.3 -0.3 -0.5  0.1 -0.2  4.3 -0.  -0.2 -0.2 -1.  -1.3 -0.1 -0.4  1.6 -0.2 -0.  -0.   1.1  0.8 -0.1 -0.1 -0.3 -0.4 -0.8  0.7  3.   3.5 -0.4 -0.4 -0.1  0.2 -0.5 -0.2  2.6 -0.8 -0.1 -0.6  0.1  0.7 -0.9  4.9  0.3 -0.6  0.7 -0.2 -0.3  1.8 -0.2 -0.2 -0.4  5.   1.7  0.  -0.4  1.6  1.1 -0.3  0.4  0.7 -2.7  0.   0.3  0.1  0.8 -0.7 -0.5 -0.8 -0.7 -0.3  0.2  0.8 -0.2 -0.5 -1.9  1.2 -0.8 -0.   3.  -0.3 -0.1  0.9 -0.7 -0.3 -0.1 -0.5 -0.1 -0.5  0.2  0.3  1.6 -0.5  1.7  2.1 -0.3  3.3 -0.6 -0.8 -0.4  0.5 -0.5  6.8 -0.6  1.8 -0.6 -0.5  1.7 -0.1 -0.4 -1.2 -1.1 -0.4  2.7 -0.8 -0.6 -0.  -0.3 -0.3 -0.8 -1.   3.4  1.7  0.9  1.  -0.6 -0.3 -0.  -0.6 -0.4 -0.2 -0.7  1.2 -0.5 -0.2  5.1 -0.3 -0.4  3.7 -0.6  1.3 -0.5 -0.3  1.8 -0.2  0.6  0.6 -1.1 -0.3 -0.  -0.3 -0.3  3.3 -0.   2.7  0.2  1.1 -0.5 -0.5 -0.5  3.4 -0.8 -1.7 -0.2  0.9  0.1 10.  -0.6  5.5 -0.3 -0.3 -0.4 -1.6 -0.1  0.8 -0.1 -0.5 -1.2 -0.1  4.4  0.4  0.   1.1]
vy_50sample [[7 2 9 3 8 6 1 4 0 5]
 [2 5 3 4 4 7 0 8 1 1]
 [7 2 9 5 3 1 4 8 0 6]
 [0 2 4 3 7 5 9 1 6 8]
 [6 4 3 8 1 0 9 7 2 5]
 [7 2 3 8 6 0 5 9 1 4]
 [6 3 0 0 7 1 9 4 2 5]
 [8 8 1 0 3 5 6 4 9 7]
 [1 9 8 4 6 2 5 3 7 0]
 [1 1 4 0 7 6 8 3 2 2]]
vt_50sample [[7 2 9 3 8 6 1 4 5 0]
 [2 5 3 4 6 7 0 8 1 9]
 [7 2 9 5 3 1 4 8 0 6]
 [0 2 4 3 7 5 9 1 6 8]
 [6 4 8 3 0 1 9 7 2 5]
 [7 2 3 8 6 5 0 9 1 4]
 [6 3 0 8 7 1 9 4 2 5]
 [2 8 1 0 3 5 6 4 9 7]
 [1 9 8 4 2 6 5 3 7 0]
 [1 4 9 0 7 8 6 3 2 5]]
Epoch  8110: Training cost= 0.4168, Training acc= 0.7524, Validation cost= 0.3957, Validation acc= 0.7529
Epoch  8120: Training cost= 0.3953, Training acc= 0.7525, Validation cost= 0.3188, Validation acc= 0.7530
Epoch  8130: Training cost= 0.4316, Training acc= 0.7526, Validation cost= 0.3806, Validation acc= 0.7531
Epoch  8140: Training cost= 0.3793, Training acc= 0.7527, Validation cost= 0.4486, Validation acc= 0.7532
Epoch  8150: Training cost= 0.3432, Training acc= 0.7528, Validation cost= 0.4134, Validation acc= 0.7533
Epoch  8160: Training cost= 0.3522, Training acc= 0.7530, Validation cost= 0.4236, Validation acc= 0.7534
Epoch  8170: Training cost= 0.3724, Training acc= 0.7531, Validation cost= 0.3707, Validation acc= 0.7535
Epoch  8180: Training cost= 0.4850, Training acc= 0.7532, Validation cost= 0.3877, Validation acc= 0.7536
Epoch  8190: Training cost= 0.3885, Training acc= 0.7533, Validation cost= 0.4355, Validation acc= 0.7537
Epoch  8200: Training cost= 0.4011, Training acc= 0.7534, Validation cost= 0.3688, Validation acc= 0.7538
tm  [-0.1  2.1  4.4 12.6 -1.1 -0.8 -0.1 -0.6 -0.5 -0.9 -1.7  1.2 -0.8 -0.6 -1.2 -1.3 -0.3 -0.   0.2 -1.  -0.4 -0.2 -0.   1.5 -0.8  2.8 -0.4 -0.3 -1.1 -0.9 -1.2  0.5 -0.1 -0.9 -0.4 -0.   1.7 -0.2  4.5 -1.  -0.3 -1.2 -0.3 -1.1 -0.4  0.7  4.2  1.5  1.9  0.  -0.7 -0.2  2.5 -1.6  1.5  3.8  0.5  2.7 -0.4  5.4 -0.8 -0.2 -0.   2.9 -0.6  0.2 -0.2 -0.8  1.9  3.4 -0.6  3.9  0.3 -0.5  2.6 -0.1 -0.1 -0.9 -0.4  0.5  4.4 -0.2 -0.5 -0.1 -0.7 -1.1 -0.2 -0.4  1.3  0.6 -0.1 -0.2 -0.   0.9  0.8 -0.3  2.2 -0.5 -0.1  0.3  1.5 -1.  -0.3 -0.5 -0.  -0.1  0.  -1.4 -0.9 -1.6 -0.3  2.   0.   0.6  2.7 -1.3 -0.4  0.4 -0.1  1.3 -0.   5.7 -0.2  0.  -0.5 -1.1  0.7  8.6 -0.3  1.   2.2 -0.7 -0.5 -0.2  4.3 -0.1 -0.4 -0.3  2.4  0.   2.3 -1.3 -0.  -0.2 -0.4 -0.3 -0.6 -0.4 -0.  -0.8 -1.5 -0.2  2.7  1.2 -0.6 -0.  -0.  -0.  -0.4 -0.4 -0.2 -0.  -0.2 -0.2 -1.1 -0.5 -0.2  1.8 -0.5  4.5 -0.5 -0.4 -0.  -0.1 -0.4  2.  -0.6  2.7 -0.3  1.   0.  -0.5 -0.4 -1.   0.4 -0.7  3.4 -0.1  1.8  5.  -0.3 -0.1 -1.2 -0.9  5.3  0.2  2.  -0.4 -0.1  0.2 -0.7  0.  -0.1 -0.7 -0.2  2.7 -0.6 -0.   5.3 -0.  -0.5 -0.3 -0.8 -0.2 -1.3 -0.6  4.7 -0.1 -0.3 -0.  -0.9 -0.2 -0.2 -1.  -0.1 -0.1 -1.1  1.1 -0.3  2.5 -0.6 -0.8 -0.6  3.1  3.8 -0.8  1.3  4.1  2.3 10.2 -0.8  4.9 -0.2  0.2 -0.2 -1.9  0.   0.3 -0.6 -0.8 -1.  -1.7  3.6 -0.3  3.7  1.3]
ty_50sample [[9 9 3 8 6 6 1 5 2 4]
 [2 6 5 0 3 3 4 8 7 1]
 [1 5 4 8 8 6 9 2 3 7]
 [6 3 8 9 7 0 2 1 4 5]
 [1 5 6 4 8 0 7 2 9 3]
 [5 1 6 2 4 3 8 8 7 9]
 [1 9 2 5 0 8 7 7 6 4]
 [0 1 8 4 7 5 9 9 3 6]
 [6 2 2 9 4 7 3 1 0 5]
 [2 9 9 1 8 4 3 6 5 7]]
tt_50sample [[9 0 3 8 6 7 1 5 2 4]
 [2 6 5 0 9 3 4 8 7 1]
 [1 5 4 8 0 6 9 2 3 7]
 [6 3 8 9 7 0 2 1 4 5]
 [1 5 6 4 8 0 2 7 9 3]
 [5 1 6 2 4 3 0 8 7 9]
 [1 9 2 5 0 8 7 3 6 4]
 [0 1 8 4 7 5 2 9 3 6]
 [6 2 8 9 4 7 3 1 0 5]
 [2 9 0 1 8 4 3 6 5 7]]
vm  [-1.7 -1.  -0.6  2.1 -0.7 -0.  -0.2 -0.8 -0.2 -0.4  6.  -0.2  0.2  0.4 -1.1  3.9 -0.3 -0.7 -0.6 -1.4 -0.4 -0.2 -0.6 -0.7 -1.4 -0.4 -0.  -0.3  1.7 -0.2  5.6 -0.9  1.8  5.3 -0.6  0.7  0.9  0.9 -0.8 -0.4 -0.1  4.5  1.  -0.7 -0.4 -0.7  3.5 -0.1 -0.8 -0.8 -0.9 -0.5 -0.4 -0.1 -1.4  3.5 -0.2  0.8  0.4 -1.4  2.4 -0.7 -0.6 -0.   0.4 -0.3 -0.6  3.  -0.5 -0.2 -0.6 -0.9 -0.7 -0.5 -0.8 -0.3  1.4 -0.4  1.7 -0.8 13.2 -0.1 -1.4 -0.3  0.3  5.5 -0.3 -0.2  0.5 -0.3 -0.7  0.7 -0.7 -0.2 -0.4 -0.3  0.7 -0.6 -0.3 -0.3  1.7  0.6  0.8 -0.  -0.8 -0.3 -1.   4.7  2.2 -1.4 -0.5 -0.4 -0.4 -0.5 -0.1  6.9 -0.2 -0.7 -1.   0.2 -0.3  6.5  1.  -0.  -0.2 -1.   1.5  2.9  2.9 -0.6  2.  -1.  -0.1 -0.4  9.7 17.5 -0.2 -0.4 -0.5 -1.  -0.5  2.4  0.1  0.2 -1.1 -0.3  1.3 -0.2  4.1  1.7  0.4 -0.5 -1.8 -0.5 -0.4 -0.2 -0.4 -0.4 -1.1 -0.2 -0.1  3.7 -0.6 -0.5 -0.1 -0.3  1.   1.5 -0.3  0.  -0.4  0.7 -1.  -0.5 -0.5 -1.4 -1.6 -0.2  5.6 -0.4 -1.4  1.5 -0.1 -1.2 -0.8 -0.3 -0.2 -0.1 -0.8  1.2 -0.1 -0.7 -0.9 -0.6 -0.1  0.5 -0.1  0.7 -0.1 -1.1 -0.3  0.4 -0.5 -0.5  1.9 -0.8  1.5  0.3 -3.7 -0.4 -0.1  4.3 -0.8  5.4  0.2 -0.1  3.7 -0.4 -0.2 -0.5 -0.1 -0.3 -0.2 -0.3  3.8  1.  -0.2  1.3 -0.2  0.8  0.3 -0.4 -0.2 -2.6 -0.1  3.2 -0.  -0.2  0.2 -0.3 -0.5 -0.3 -0.6 -0.2 -2.5 -0.6 -0.1 -0.4 -0.9 -0.4 -2.7 -0.5 -0.9 -0.1  2.7  4.6]
vy_50sample [[6 1 1 4 9 2 7 3 8 8]
 [8 6 1 2 5 0 3 7 9 4]
 [5 9 7 2 6 1 4 0 8 3]
 [6 0 4 2 1 9 9 7 5 3]
 [4 6 6 9 3 8 0 2 7 1]
 [6 1 8 3 0 2 4 9 5 7]
 [0 0 7 8 8 4 2 3 9 1]
 [2 7 9 3 1 4 0 5 6 8]
 [0 4 5 9 9 9 2 1 8 7]
 [0 8 8 2 7 3 6 9 5 1]]
vt_50sample [[6 1 5 4 9 2 7 3 0 8]
 [8 6 1 2 5 0 3 7 9 4]
 [5 9 7 2 6 4 1 0 3 8]
 [6 0 4 2 1 9 8 7 5 3]
 [4 6 5 9 3 8 0 2 7 1]
 [6 1 8 3 0 2 4 9 5 7]
 [0 5 6 7 8 4 2 3 9 1]
 [2 7 9 3 1 4 0 5 6 8]
 [0 4 5 9 6 3 2 1 8 7]
 [0 8 2 4 7 3 6 9 5 1]]
Epoch  8210: Training cost= 0.3801, Training acc= 0.7535, Validation cost= 0.3775, Validation acc= 0.7539
Epoch  8220: Training cost= 0.3655, Training acc= 0.7536, Validation cost= 0.4364, Validation acc= 0.7540
Epoch  8230: Training cost= 0.3775, Training acc= 0.7537, Validation cost= 0.4031, Validation acc= 0.7541
Epoch  8240: Training cost= 0.4489, Training acc= 0.7538, Validation cost= 0.3966, Validation acc= 0.7542
Epoch  8250: Training cost= 0.3760, Training acc= 0.7539, Validation cost= 0.3834, Validation acc= 0.7543
Epoch  8260: Training cost= 0.3962, Training acc= 0.7540, Validation cost= 0.3613, Validation acc= 0.7544
Epoch  8270: Training cost= 0.4442, Training acc= 0.7541, Validation cost= 0.4209, Validation acc= 0.7545
Epoch  8280: Training cost= 0.3825, Training acc= 0.7542, Validation cost= 0.3716, Validation acc= 0.7546
Epoch  8290: Training cost= 0.3146, Training acc= 0.7543, Validation cost= 0.4608, Validation acc= 0.7547
Epoch  8300: Training cost= 0.3683, Training acc= 0.7544, Validation cost= 0.4592, Validation acc= 0.7548
tm  [-0.8  1.3  2.6 -0.7 -1.4 -0.3 -0.4 -0.4 -1.9 -0.3 -4.5  2.1 -1.  -0.3  6.1 -1.   0.7 -0.  -0.3 -1.3 -0.4 -0.5  3.1 -0.2 -0.9 -0.2 -0.4 -0.5 -0.   1.  -0.3  0.5 -0.1  0.3 -0.6 -0.   3.2 -0.2  4.2 -0.6  0.3 -1.1 -0.   4.  -1.4 -0.   2.2  2.9 -0.5  4.8 -0.1 -0.6 -1.2 -1.6 -1.2 -0.7 -1.  -1.3 -0.5  2.7  3.3 -0.  -0.6 -1.1 -0.7 -0.6 -0.1 -0.5  0.3  2.3 -0.1 -0.4  1.6 -0.4 -1.4 -0.2  1.9 -0.3  2.9  0.  -2.3 -0.1 -0.9 -0.2 -0.4 -1.3  1.9 -0.2  2.6 -0.9 -0.1 -0.2 -0.3  1.7 -0.4 -0.4 -0.7 -0.6 -0.5 -0.6  1.8  3.9  1.5 -0.   0.1 -0.2 -1.3 -0.4 -2.2 -1.4  0.9 -0.8 -0.2 -0.6 -0.1  2.9 -0.2 -0.2 -0.2 -0.7 -0.4  4.4 -0.2 -0.5 -0.6  6.2  3.3  7.9 -0.5  2.8 -0.4  0.2  0.8  0.8 -3.2 -4.2 -0.4 -0.3 -0.7 -0.1  3.  -0.4  2.   0.2 -1.  -0.4 -0.3 -0.6 -1.5 -0.1  1.7 -0.4  2.6  0.7 -0.4 -0.4 -0.3  0.3  1.4 -1.3 -0.8 -0.8 -0.3 -0.4 -0.5  1.9 -0.   3.1  1.6 -0.5 -0.2 -0.5 -0.7 -0.2 -0.3  5.9 -0.1 -0.8 -0.3  0.7  0.   1.5  1.1 -0.9 -0.3  0.6 -0.1 -0.5 -1.  -0.3 -0.4 -0.3 -0.1 -1.3 -0.1  1.  -0.6  1.  -0.3 -0.8 -0.  -0.2 -0.1 -0.3 -0.1 -1.4 -1.4 -0.1  8.9 -0.4 -0.4  1.7 -0.7  2.2  2.1  0.1 -1.  -0.6  1.1 -0.6 -1.5  0.5 -0.1 -0.9 -0.4  3.1 -1.8 -0.4 -0.  -0.  -1.1  1.  -0.4  6.4 -0.  -0.2 -0.3 -0.9  1.   7.5 -0.5  5.  -0.9 -0.4  7.3 -0.3 -0.5 -0.9 -0.1  0.   4.  -0.2  4.  -0.8  4.2  0.6]
ty_50sample [[8 7 4 1 3 9 0 6 5 2]
 [7 1 9 3 4 8 0 6 2 5]
 [6 9 1 0 2 4 5 5 7 8]
 [6 0 2 7 7 5 1 1 8 4]
 [8 6 0 1 7 2 3 9 5 4]
 [4 4 7 9 6 3 2 5 5 0]
 [6 4 1 7 8 5 9 0 3 2]
 [1 0 2 8 4 3 5 9 6 7]
 [3 4 5 9 8 2 7 7 0 1]
 [3 6 7 8 9 0 5 1 4 2]]
tt_50sample [[8 7 4 1 3 9 0 6 5 2]
 [7 1 9 3 4 0 8 6 2 5]
 [6 9 1 0 2 4 3 5 7 8]
 [6 0 2 7 9 5 3 1 8 4]
 [8 6 0 1 7 2 3 9 5 4]
 [1 4 7 9 6 3 8 2 5 0]
 [6 4 1 7 8 5 9 0 3 2]
 [1 0 2 4 8 3 9 5 6 7]
 [3 4 9 5 8 2 6 7 0 1]
 [3 6 7 8 9 0 5 1 4 2]]
vm  [ 1.2  1.1 -1.2 -1.  -0.7 -0.8 -0.8 -0.6 -0.8 -0.5  5.5 -0.6 -0.1 -0.5 -0.4  2.1  1.  -0.1 -0.2  1.1 -0.8 -0.3  0.6  0.3 -1.5  3.3 -0.4 -0.1 -0.9 -0.3  2.8 -0.4  0.1 -1.2  1.9 -0.1  2.7  0.8 -2.1 -0.9 -0.5  1.   0.3 -0.6 -0.5  0.7 -1.7 -1.1  3.6  0.7 -0.5 -1.3 -0.5  6.9 -0.5  1.1 -0.4  0.  -0.2 -0.1 -0.1 -0.  -0.   3.4 -0.  -0.4 -0.2  1.2  0.2  0.2 -0.7  1.5  0.2 -0.4 -2.8 -0.3 -0.5 -0.3  1.1 -0.  -0.5 -0.3  0.1  0.4 -1.1  0.5  1.8 -0.4 -0.  -0.2 -0.5 -0.6 -0.2  0.2 -0.5  0.9  0.2 -1.5 -0.4 -0.2  0.9 -0.5 -0.7 -0.2  0.5  1.5 -1.7  2.8  2.4  0.2 -1.   0.7 -0.3 -0.   0.6 -0.4 -0.5 -0.3 -0.   0.8 -0.1 -0.3  0.  -0.1 -0.4 -0.3 -0.4 -1.4  0.4  2.5  5.5 -0.6 -0.1 -0.1 12.1 10.6 -0.5 -0.3  0.7 -0.3 -0.3 -0.9 -0.6  0.8  0.   0.2 -0.2 -0.2  2.7 -0.   2.2 -0.1  2.7 -0.5 -0.2 -0.3 -0.1 -0.2 -1.5 -0.8  2.7  2.7 -0.2 -0.6 -0.7 -0.9 -0.1 -0.1  0.5 -0.1  0.4  0.  -0.  -0.1 -0.3 -0.7 -1.2 -0.3  9.4 -0.4 -0.5 -0.  -0.4 -0.9  0.7 -0.3  1.6  0.7 -0.3  1.8 -0.2 -0.6  0.8 -1.1  2.8 -0.1 -0.7 -0.1 -0.3  0.9 -0.3  0.1 -0.1 -0.3 -0.  -1.9 -0.   1.1  0.  -0.2 -0.5 -0.3 -1.3 -0.2  0.1 -0.6  4.  -0.5 -0.6 -0.5 -0.  -0.5 -0.2 -0.7  3.7 -0.4  0.5  1.4  0.7  4.4  1.3 -0.3 -0.5  0.5  3.6  4.8  2.7 -0.8  1.7 -0.4 -0.7 -0.2 -0.  -0.3  3.1  0.8 -0.2  1.9 -0.7 -0.4  0.5  0.1 -1.8  2.1 -0.5 -0.1]
vy_50sample [[6 2 0 4 5 3 8 9 1 7]
 [2 4 5 6 7 3 3 1 8 8]
 [0 5 2 9 7 8 3 4 6 1]
 [3 9 6 8 2 7 1 5 0 4]
 [1 0 5 3 2 7 8 6 9 4]
 [3 7 8 5 4 1 2 6 0 9]
 [4 9 8 9 6 1 1 2 7 0]
 [2 1 6 0 4 4 5 5 8 3]
 [9 0 8 7 4 1 6 3 5 2]
 [4 0 5 9 3 7 2 6 8 1]]
vt_50sample [[6 2 0 4 5 3 8 9 1 7]
 [2 4 5 6 7 3 9 1 0 8]
 [0 5 2 9 7 8 4 3 6 1]
 [3 9 6 8 2 7 1 5 0 4]
 [1 0 5 3 2 7 8 6 9 4]
 [3 7 8 5 4 1 2 6 0 9]
 [4 9 3 8 6 1 5 2 7 0]
 [2 1 6 0 7 4 9 5 8 3]
 [9 8 7 0 1 4 6 3 5 2]
 [4 0 5 9 7 3 2 6 8 1]]
Epoch  8310: Training cost= 0.4932, Training acc= 0.7545, Validation cost= 0.4092, Validation acc= 0.7549
Epoch  8320: Training cost= 0.4371, Training acc= 0.7546, Validation cost= 0.4492, Validation acc= 0.7550
Epoch  8330: Training cost= 0.4371, Training acc= 0.7546, Validation cost= 0.3661, Validation acc= 0.7550
Epoch  8340: Training cost= 0.3724, Training acc= 0.7547, Validation cost= 0.4561, Validation acc= 0.7551
Epoch  8350: Training cost= 0.4267, Training acc= 0.7548, Validation cost= 0.4510, Validation acc= 0.7552
Epoch  8360: Training cost= 0.4541, Training acc= 0.7549, Validation cost= 0.4083, Validation acc= 0.7553
Epoch  8370: Training cost= 0.4456, Training acc= 0.7550, Validation cost= 0.4804, Validation acc= 0.7554
Epoch  8380: Training cost= 0.4099, Training acc= 0.7551, Validation cost= 0.4497, Validation acc= 0.7555
Epoch  8390: Training cost= 0.3301, Training acc= 0.7552, Validation cost= 0.3975, Validation acc= 0.7556
Epoch  8400: Training cost= 0.4633, Training acc= 0.7553, Validation cost= 0.4433, Validation acc= 0.7557
tm  [-0.8 -0.7 -1.2 -3.1 -1.3  0.7 -0.2 -0.7 -0.4  0.6  2.8 -0.  -0.7 -0.5  6.  -0.6 -0.3 -0.4 -0.5  0.1 -0.3 -0.   1.7  0.1 -0.7  2.6 -0.1 -0.2 -0.7 -0.6  5.8  0.1  0.6  4.5  1.6  0.1  0.8 -0.2 -1.7 -0.6 -0.3  1.  -0.7  2.9 -1.  -0.2 -1.2 -0.2 -0.7  2.3 -0.9 -1.1 -0.6  3.5 -0.5 -0.4 -0.7 -1.5  2.7 -1.5  8.2 -0.   0.6  1.9  2.6 -0.6 -0.3  2.2  0.8 -0.3 -0.7  1.2 -0.5 -0.3 -4.2 -0.1  1.6 -0.4  5.6 -0.3 -0.2 -0.1  1.3 -0.1 -0.1  0.8  0.6 -0.3  0.1 -0.  -0.7 -0.7 -1.  -0.8 -1.3 -0.3 -0.6 -1.4 -0.  -0.4 -0.3  3.9  2.3 -0.2 -0.3 -0.  -2.9  6.8  1.8  2.  -0.8  0.  -0.2 -0.6  6.4 -0.8 -0.3  1.7 -0.6 -0.1 -0.2 -1.  -0.2  0.5 -0.8  6.4 -0.5 -0.3 -0.1  0.9 -0.  -0.8 -0.7 -0.1  3.6  8.8 -0.3 -0.5  0.9 -0.9  0.4 -0.1 -0.1 -0.1 -0.7 -0.5  0.4  0.7 -0.5 -0.   4.1 -0.3 -0.9  1.3 -0.5 -0.2 -0.3 -0.  -0.6 -0.5  2.1 -0.1  1.  -0.6 -0.2 -0.4 -1.2  3.2  0.4 -1.2  1.4 -0.3 -0.5 -0.  -0.7  3.9 -1.2 -0.8  7.5  0.3  0.7 -0.3 -0.1 -1.3  0.1 -1.1 -1.1 -0.3 -0.1  0.6 -0.2 -1.1 -0.2 -1.  -1.8  1.4 -1.7 -0.3 -0.7 -0.3 -0.1  1.2 -0.5 -0.4  0.2 -2.3 -0.1 -0.4  2.3 -0.3 -0.4 -0.7 -0.6  5.6  1.7 -0.2 -0.7 -0.7 -0.3  0.4 -0.5 -0.1 -0.4 -1.5  2.7 -0.5 -0.9  1.6 -0.2 -0.3 -0.3  2.  -0.4  1.5  1.7  4.6  4.2 -2.8  2.1  1.1 -0.6  0.1 -0.6  0.4  2.7  1.4 -0.1 -0.3 -0.3 -0.  -0.1  0.3 -1.3 -0.4  0.8  1.3]
ty_50sample [[4 1 0 6 7 2 2 3 9 9]
 [8 7 6 5 2 1 9 3 4 0]
 [4 7 8 2 5 9 3 0 1 6]
 [7 4 9 2 5 0 3 1 6 8]
 [1 0 0 6 5 3 8 4 9 9]
 [3 7 8 2 1 0 4 6 5 9]
 [0 1 3 5 2 6 9 9 8 4]
 [9 8 7 1 6 5 0 3 4 2]
 [9 5 4 2 3 7 8 0 6 1]
 [1 1 0 0 9 4 8 3 7 5]]
tt_50sample [[4 1 0 6 7 2 8 5 3 9]
 [8 7 6 5 2 9 1 3 4 0]
 [4 7 8 2 5 9 3 0 1 6]
 [7 4 9 2 5 0 3 1 6 8]
 [1 2 0 6 5 3 8 4 9 7]
 [3 7 8 0 2 1 4 6 5 9]
 [0 1 3 5 6 2 7 9 8 4]
 [9 8 7 1 6 0 5 3 4 2]
 [9 5 4 3 2 7 8 0 6 1]
 [2 1 6 0 9 4 3 8 7 5]]
vm  [-0.6  0.1  8.6  7.2 -2.1 -0.6 -0.5 -0.1 -0.1 -0.7  1.5  0.7 -0.4 -0.2  5.5  1.6 -0.4 -0.1  1.6  0.6 -0.4 -0.4 -0.1 -0.5 -0.6  0.4 -0.5 -0.1 -0.3 -1.2 -1.1 -0.3 -0.9  4.8 -0.3 -0.1 -0.1  4.1  7.5 -1.3 -0.4 -0.7 -0.6  1.6 -0.8  1.3 -0.7 -0.1  2.3 -0.4 -1.  -0.4 -0.1  2.6 -0.6 -0.6 -0.2  4.   2.5  5.   0.6 -0.3 -0.2  5.1 -0.7 -0.3 -0.5 -0.8 -0.   1.1  0.1  0.8  0.9  0.8 -1.5  0.4 -0.6 -1.1 -0.5  0.3 -0.2 -0.5 -0.4 -0.  -0.7 -0.6 -0.6 -0.2  1.7 -0.1 -0.5 -0.4 -0.2 -0.2 -0.2  0.   0.9 -1.4 -0.4  1.   2.7  2.9  0.  -0.2  0.2 -0.1 -1.  -1.1  0.5 -0.9  0.2 -0.4 -0.1 -0.5  1.   0.9  0.2  2.1 -0.2 -0.2  0.3  3.4 -0.4 -0.2 -0.6  6.   0.4  0.1  3.7  3.8 -0.7 -1.1  0.1 -0.4 -5.  -3.1 -0.2 -0.3 -0.  -0.3 -0.4 -0.3 -0.5 -0.4 -0.4 -0.3 -0.6 -1.  -0.9 -0.5 -0.4 -0.4  2.8 -0.3 -0.2 -0.5 -0.2 -0.2  5.  -0.5 -0.2 -1.5 -0.2 -0.2 -0.1 -0.5  2.2  1.8 -0.6  1.6 -0.5 -0.1 -0.4 -0.2 -0.6  3.9  2.4 -0.2 -1.5 -0.3 -0.5 -0.4 -0.9 -0.8  1.1 -0.6  1.1 -0.8 -0.6  5.1 -0.2  0.4 -0.7 -0.7  1.7 -1.1 -0.2 -0.5 -0.3 -0.1 -0.4 -0.2 -0.4 -0.9 -0.2 -1.2  0.2  0.2  3.  -0.3 -0.7  0.7 -0.9 -0.1 -0.9 -0.3 -0.1 -0.1  1.7 -0.1 -0.8 -0.2 -0.5 -0.4 -1.3  1.  -0.3  1.9  0.4  5.  -0.9 -0.4 -0.3  2.1  2.4 -2.4  0.3  0.3  1.5  1.3 -0.3  1.   0.4 -0.6  3.  -0.3 -0.6  1.  -0.8 -0.7 -0.1 -1.1  5.9  0.2  2.6 -0.7]
vy_50sample [[7 3 8 2 0 5 1 1 4 6]
 [1 0 3 4 7 9 9 5 2 6]
 [9 6 5 3 4 2 1 0 0 7]
 [9 9 2 2 4 7 0 5 1 6]
 [3 8 0 0 4 7 2 1 9 5]
 [7 2 1 6 9 8 5 3 4 4]
 [9 5 5 6 1 0 4 3 7 7]
 [5 0 1 2 3 6 4 9 8 7]
 [3 8 1 5 4 6 9 2 7 0]
 [7 9 3 2 1 5 8 6 4 0]]
vt_50sample [[7 3 8 0 2 5 1 9 4 6]
 [1 0 3 4 7 8 5 9 2 6]
 [9 6 5 3 4 2 1 0 8 7]
 [3 8 9 2 4 7 0 5 1 6]
 [3 8 6 0 4 7 2 1 5 9]
 [7 2 1 6 9 8 5 3 4 0]
 [9 5 8 6 1 0 3 4 2 7]
 [5 0 1 2 3 6 4 9 8 7]
 [3 8 1 5 4 6 9 2 7 0]
 [7 9 3 2 1 5 8 6 4 0]]
Epoch  8410: Training cost= 0.4079, Training acc= 0.7554, Validation cost= 0.4355, Validation acc= 0.7558
Epoch  8420: Training cost= 0.4060, Training acc= 0.7555, Validation cost= 0.3614, Validation acc= 0.7559
Epoch  8430: Training cost= 0.3740, Training acc= 0.7556, Validation cost= 0.3954, Validation acc= 0.7560
Epoch  8440: Training cost= 0.4016, Training acc= 0.7557, Validation cost= 0.4192, Validation acc= 0.7561
Epoch  8450: Training cost= 0.3418, Training acc= 0.7558, Validation cost= 0.3307, Validation acc= 0.7562
Epoch  8460: Training cost= 0.4168, Training acc= 0.7559, Validation cost= 0.4020, Validation acc= 0.7563
Epoch  8470: Training cost= 0.3662, Training acc= 0.7560, Validation cost= 0.3741, Validation acc= 0.7564
Epoch  8480: Training cost= 0.4050, Training acc= 0.7561, Validation cost= 0.3945, Validation acc= 0.7565
Epoch  8490: Training cost= 0.4197, Training acc= 0.7562, Validation cost= 0.4020, Validation acc= 0.7566
Epoch  8500: Training cost= 0.3716, Training acc= 0.7563, Validation cost= 0.3891, Validation acc= 0.7567
tm  [-1.2 -0.4 -0.8  1.2 -0.8 -0.1 -0.3 -0.6  1.7 -0.5  6.9 -0.5 -0.1  0.  -0.9  6.2 -0.7 -0.8 -0.3 -0.4 -0.2  0.7  1.2 -0.8 -1.4  0.7  0.5 -0.2  3.6 -0.9  3.1 -1.5  0.   0.6 -0.2 -0.4 -0.2  4.9  2.6 -0.6  0.3  5.4  1.   1.4 -0.3 -0.2 -0.  -0.8 -0.5  1.5 -0.6 -0.6  0.3  3.6 -1.6  2.6 -0.1  3.3  2.7 -0.5  2.9 -1.   0.6  2.2  1.4 -0.3 -0.2  3.2 -0.5 -0.5 -0.4 -1.1 -0.5 -0.1 -2.1  0.5 -0.4 -0.1  0.6 -0.1  5.1 -0.1 -0.1 -0.2 -0.2  6.8 -0.2 -0.4  0.2 -0.1 -0.2 -0.4 -0.9 -0.9 -0.4 -0.   1.5 -1.2 -0.4 -0.2  0.9 -0.   0.2 -0.2 -0.7  1.  -1.2  2.6  2.9 -0.5 -0.3 -0.4 -0.5 -0.7 -0.1  6.2 -0.2 -0.4 -0.6  1.8  0.   1.3  0.9  0.7 -0.2 -0.6 -0.1 -0.4  6.1 -0.3 -0.1 -0.9 -0.5 -0.2  4.2  4.5 -0.2 -0.6 -0.1 -0.6 -0.8  1.4 -0.3  0.4 -1.   0.9  0.3 -0.1  5.3  1.1  1.6 -0.1 -0.6 -0.3 -0.3 -0.1 -1.  -0.3  0.1 -0.2  1.2 -0.3 -0.1 -0.5 -0.1 -0.4  1.1 -0.  -0.   0.3  0.1  1.  -0.9 -0.5 -0.3 -1.8 -0.8 -0.   0.5 -0.4 -1.6  0.4 -0.4 -1.4 -0.4 -0.2 -0.2 -0.  -0.8  3.7 -0.1 -0.6 -0.9 -0.8 -0.2 -0.7 -0.5 -0.2 -0.3 -0.7  0.1  1.1 -0.9 -1.1  0.1 -0.8  1.9  0.6 -2.9 -0.3  0.1  5.3 -0.9  5.3 -0.4 -0.1 -0.  -0.5 -0.2 -0.2 -0.3 -0.5 -0.  -0.4  1.7  2.9  0.8  3.7 -0.1  2.4 -0.7 -0.6 -0.5 -2.1 -0.6  3.4  0.7 -0.7  0.  -1.9 -0.1 -0.9 -0.3 -0.1 -0.5 -0.9 -0.  -0.  -0.6 -0.4 -1.3 -0.1  1.6  0.2  1.6  3.7]
ty_50sample [[5 2 1 9 4 6 8 3 7 0]
 [7 0 0 3 5 6 2 8 1 4]
 [2 6 9 9 7 5 5 4 3 0]
 [0 7 6 2 3 8 8 4 1 5]
 [8 6 7 9 9 0 1 4 5 2]
 [3 0 5 7 6 2 2 1 4 8]
 [9 1 3 7 6 4 2 8 5 0]
 [9 4 6 8 5 1 0 3 2 7]
 [5 8 2 9 6 1 0 4 7 3]
 [7 1 2 8 5 0 6 4 3 9]]
tt_50sample [[5 2 1 9 4 6 3 8 7 0]
 [7 9 0 3 5 6 2 8 1 4]
 [2 6 9 7 8 1 5 4 3 0]
 [0 7 6 2 3 8 9 4 1 5]
 [8 6 7 9 3 0 1 4 5 2]
 [3 0 7 5 6 9 2 1 4 8]
 [9 1 3 7 6 4 2 8 5 0]
 [9 4 6 8 5 1 0 3 2 7]
 [5 8 2 9 6 1 0 4 7 3]
 [7 1 2 8 5 6 0 4 3 9]]
vm  [ 0.2 -0.3  7.7 11.8 -1.2 -0.7 -0.5 -0.2 -0.3 -0.2  7.6 -0.2  0.4 -0.5  1.6  3.  -0.6 -0.2 -0.3 -1.8 -0.6  1.4 -0.8 -0.1 -0.7 -0.2 -0.4 -0.4 -0.1 -0.   2.7 -0.3  2.7 11.1  0.5  2.1  1.2  0.2  0.4 -0.2  1.1 -1.3 -1.1 -1.1 -0.3 -0.4  9.  -0.1  1.6 -1.3 -1.4 -0.2  1.1 -0.4 -0.7  0.7 -0.6 -0.3 -0.3 -0.3 -1.8  1.4 -0.5  1.2  1.7 -0.9 -0.2  0.8 -0.1 -0.6 -0.2 -0.6 -0.6 -0.6  1.4 -0.4 -0.5 -0.4  0.3 -0.7 16.8  0.8 -1.2 -0.1 -1.  -1.5 -0.3 -0.7  0.3 -0.4 -0.3  1.2  0.4 -0.3  0.5 -0.4 -0.4  0.1 -0.2  0.4  1.5  4.4 -0.6 -0.1 -0.7 -0.2  0.7  2.   3.4 -2.4  0.8 -0.3 -0.  -0.7  0.6  1.7 -0.   1.4 -0.  -0.3 -0.2  7.7  0.1  0.5 -0.7  2.4  0.2  3.8 -0.7 -0.5  4.5 -0.9 -0.1 -0.1  0.4 15.3 -0.1 -0.1 -0.5 -1.  -0.9  0.6 -0.6 -0.5 -0.5  1.  -0.5 -0.8 -1.8  0.3 -1.5 -0.2  0.2 -0.7 -0.2 -0.1 -0.1 -0.3 -1.4 -0.6 -0.3  2.3 -0.2 -0.4  2.4 -0.3 -0.1  1.8 -0.7  4.5 -1.  -1.2 -0.1 -0.  -0.4  8.1 -1.7  1.6  1.1 -0.5  1.4 -0.  -0.4 -0.6 -1.4 -0.7  5.9 -0.9 -0.2  0.4 -0.5 -0.3 -1.5 -0.5  8.4  0.6  1.7 -0.4 -0.3 -0.  -0.2 -0.7  0.5  0.6 -1.1  2.7 -0.1  0.2  2.1 -0.4 -0.3  2.3 -0.8 -0.1 -0.4 -0.1  5.  -0.5  0.3 -0.3 -0.4 -0.8  0.3 -0.7  1.6 -0.3  0.   1.2 -0.3  3.   0.8 -0.2 -0.3  1.8 -0.9 -1.9  0.1  1.3 -0.  16.1 -0.3  9.2 -0.6 -0.3 -3.2 -1.8 -0.2 -0.5 -0.4  0.3 -3.4 -0.5  1.2  0.4 -0.2  4.8]
vy_50sample [[7 6 9 2 3 0 4 1 5 5]
 [9 1 1 5 4 2 7 6 8 8]
 [4 2 5 0 1 1 7 3 8 8]
 [1 9 8 6 0 7 5 4 3 2]
 [2 3 4 5 1 8 9 0 7 6]
 [7 9 0 8 2 6 3 4 5 1]
 [3 7 8 0 6 9 4 2 1 5]
 [9 3 5 1 8 7 2 6 4 0]
 [3 0 7 7 9 2 2 1 5 6]
 [6 9 1 2 0 7 4 5 3 8]]
vt_50sample [[7 6 9 2 3 0 4 1 8 5]
 [9 3 1 5 4 2 7 6 8 0]
 [4 2 5 0 1 6 7 3 9 8]
 [1 9 8 6 0 7 5 4 3 2]
 [2 3 4 5 8 1 9 0 7 6]
 [7 9 0 8 2 6 3 4 1 5]
 [3 7 8 0 9 6 4 2 1 5]
 [9 3 5 1 8 7 2 6 4 0]
 [3 0 8 7 9 4 2 5 1 6]
 [6 9 1 2 0 7 4 5 3 8]]
Epoch  8510: Training cost= 0.3759, Training acc= 0.7564, Validation cost= 0.4208, Validation acc= 0.7568
Epoch  8520: Training cost= 0.3894, Training acc= 0.7565, Validation cost= 0.3232, Validation acc= 0.7569
Epoch  8530: Training cost= 0.4015, Training acc= 0.7566, Validation cost= 0.4073, Validation acc= 0.7570
Epoch  8540: Training cost= 0.3815, Training acc= 0.7567, Validation cost= 0.4247, Validation acc= 0.7571
Epoch  8550: Training cost= 0.4451, Training acc= 0.7568, Validation cost= 0.3769, Validation acc= 0.7572
Epoch  8560: Training cost= 0.3959, Training acc= 0.7569, Validation cost= 0.4551, Validation acc= 0.7573
Epoch  8570: Training cost= 0.4529, Training acc= 0.7570, Validation cost= 0.3701, Validation acc= 0.7573
Epoch  8580: Training cost= 0.4118, Training acc= 0.7570, Validation cost= 0.4919, Validation acc= 0.7574
Epoch  8590: Training cost= 0.5263, Training acc= 0.7571, Validation cost= 0.4587, Validation acc= 0.7575
Epoch  8600: Training cost= 0.3860, Training acc= 0.7572, Validation cost= 0.4204, Validation acc= 0.7576
tm  [-1.2  1.   5.6 -0.5 -1.5  0.1 -0.4 -0.4 -0.1 -0.7  2.1 -0.6  1.5  1.   9.2  7.6 -0.5 -0.4  0.5  3.8 -0.1 -0.3  2.6 -0.9 -1.1 -0.3 -0.2 -0.1  2.1 -0.7 -1.5 -0.4 -0.8 -0.6 -0.  -0.4 -0.1  4.7 -1.1 -0.9 -0.  -0.5 -0.6 -0.1 -0.6 -0.2 -2.8 -0.8 -0.6  4.  -0.8 -0.5 -1.  11.  -1.4 -1.1 -0.3  3.1  3.4  5.7  8.  -0.2 -0.2  2.8 -0.5 -0.1 -0.5 -0.2 -0.5 -0.2 -0.1 -0.7  0.7  1.  -3.8 -0.1  0.3 -0.6  0.3  0.1 -4.  -0.5  0.6 -0.1 -0.1 -0.3 -0.7 -0.   1.1  0.3 -0.3 -0.2 -0.4 -0.  -0.6  0.1  0.5 -1.7 -0.4 -0.1  1.8  2.4  2.4 -0.1  0.7  0.1 -2.6 -1.5  1.3  2.2 -0.5 -0.5 -0.5 -0.5 -0.2  5.2 -0.3 -0.2 -0.6 -0.2 -0.3 -0.6 -0.1 -0.5 -0.4  9.3 -0.  -2.9  4.   6.  -0.3 -0.8 -0.3 -0.5 -1.4 -2.2 -0.2 -0.1 -0.3 -0.1 -0.7 -0.2 -0.9 -0.1 -0.6 -0.3 -0.4  0.1 -0.6  0.9  3.  -0.8  1.7 -0.7 -0.3 -0.2 -0.6 -0.1  1.9 -0.5  0.5 -0.4 -0.2 -0.1 -0.6 -0.4  2.9  2.4 -0.2 -0.5 -0.4 -0.1 -0.8 -0.3 -0.4  3.  -0.6 -1.2  6.1 -0.6 -0.4  0.9 -0.7 -1.2  1.3 -0.2 -1.2 -0.8 -1.4  3.8 -0.4 -0.5  0.6 -0.6 -1.7 -0.8 -1.5 -0.4 -0.2 -0.3 -0.3 -0.  -0.8 -1.1  0.5 -3.5 -0.5  0.   6.1 -0.3 -0.2  3.3 -0.7  3.5 -0.5 -0.3  2.2 -0.2 -0.  -0.3 -0.7  0.4 -0.7 -0.3 -0.1  4.3  1.8  4.6 -0.5  2.7 -0.8  0.4 -0.1  3.5 -0.4 -1.3 -0.1 -1.8 -0.  -1.4 -0.7 -0.8  0.6 -0.3 12.6  4.8 -0.5  2.1 -0.5 -0.7  7.7 -0.3 -0.8  1.2  0.3 -1.4]
ty_50sample [[2 8 1 7 3 6 5 4 9 0]
 [5 7 9 3 8 2 6 4 0 1]
 [7 0 6 5 4 1 9 3 2 8]
 [4 4 5 6 3 2 7 9 1 8]
 [7 3 6 6 0 9 1 2 4 8]
 [3 0 2 5 7 1 6 4 8 9]
 [3 5 0 0 4 4 8 8 7 7]
 [3 8 8 5 2 4 9 7 1 6]
 [4 4 1 0 3 9 8 8 2 5]
 [3 8 9 4 7 1 2 5 6 0]]
tt_50sample [[2 8 7 1 3 6 5 4 9 0]
 [5 7 9 8 3 6 2 4 0 1]
 [7 0 6 5 4 1 3 9 2 8]
 [4 0 5 6 3 2 7 9 1 8]
 [7 3 6 5 0 9 1 2 4 8]
 [3 0 2 5 7 1 6 4 8 9]
 [3 5 0 2 4 9 8 1 6 7]
 [3 0 8 5 2 4 9 7 1 6]
 [6 4 1 0 9 3 8 7 2 5]
 [3 8 9 4 7 1 2 5 6 0]]
vm  [ 0.3  0.1 -1.5 -3.6 -0.8 -0.4 -0.6 -0.9 -0.9  1.7  2.  -0.9  0.7 -0.1  4.9  3.1  0.5 -0.1 -0.2  2.8 -0.8 -0.8  4.2 -0.2 -1.1  0.8 -0.2 -0.1 -0.6 -0.3 -0.2  0.2 -0.5 -3.2  2.9 -0.5  1.8  5.  -1.2 -0.4 -0.5 -0.1 -0.8  4.7 -1.5 -0.9 -1.8 -1.3 -0.2  9.5 -0.3 -1.1 -2.  12.5 -0.5 -0.2 -1.1 -1.6  3.8  1.9  6.   0.8 -0.4  0.4 -0.4 -0.9 -0.4  2.8 -0.5 -1.1 -0.5  0.3  1.  -0.1 -5.7 -0.  -0.  -0.   3.  -0.8 -5.1 -0.1  1.7 -0.2 -0.5 -0.2  1.4 -0.1  0.  -0.  -0.4 -0.9 -0.9  0.5 -1.5 -0.1 -0.9 -1.6 -0.4 -0.9 -0.5  2.4  1.  -0.4  0.7 -0.2 -3.5  0.5  0.5  3.8 -0.3 -0.5 -0.4 -0.4  3.4 -0.9 -0.1 -0.1  0.5  1.4 -0.4 -1.7 -0.4 -0.8 -0.7  6.  -0.9 -3.2 -0.2  2.3  0.8  0.2 -0.9 -0.   2.9 -3.2 -0.4 -0.7 -0.4 -0.1 -0.9 -1.1 -0.9 -0.1  0.8 -0.7 -0.3  0.1 -0.5 -0.4  4.3 -0.3  3.6 -0.7 -0.2 -0.1 -0.3 -0.3 -0.  -0.4  0.7 -0.9 -0.  -0.3 -1.1 -0.1 -1.   1.5 -0.3 -1.2  1.6 -0.8 -0.2 -0.3 -0.3  3.9 -0.8 -1.1  5.7 -0.7  2.8  0.3  1.6 -0.8  2.1  1.6 -0.4 -0.5 -1.2  0.3 -0.4 -1.2  2.4 -1.4 -1.  -0.1 -2.5 -0.  -0.4  0.3 -0.1  0.4 -0.6 -0.3 -1.  -3.  -1.1 -0.5  9.5 -0.3 -0.  -1.  -0.6  2.   1.   0.6 -0.9 -0.4 -0.9 -0.6 -0.3 -0.4 -0.5 -1.   1.6  0.3  0.9  2.6 -0.4  0.9 -1.1  3.3 -0.6  6.3 -0.2  6.1  4.2 -3.4 -0.1  1.  -0.8  1.1 -0.3 -0.2 14.7  3.2  1.8 -0.7 -0.   0.6 10.5  3.8 -0.7  0.2 -1.  -0. ]
vy_50sample [[2 8 4 0 1 6 7 3 5 5]
 [0 6 7 1 2 3 9 4 5 5]
 [4 5 5 9 2 2 1 1 3 6]
 [3 8 1 9 9 5 0 0 7 2]
 [1 6 7 5 3 2 2 4 8 0]
 [9 4 1 5 7 0 6 8 2 3]
 [2 3 6 0 0 7 5 9 1 4]
 [6 0 3 4 9 8 7 1 2 5]
 [1 9 0 7 6 8 5 5 4 2]
 [6 0 7 4 8 9 2 3 5 1]]
vt_50sample [[2 8 4 0 1 6 7 3 5 9]
 [0 6 7 1 2 3 4 9 5 8]
 [4 5 8 0 2 9 1 3 6 7]
 [3 8 1 6 9 5 0 4 7 2]
 [1 6 7 5 3 9 2 4 8 0]
 [9 1 4 5 7 0 6 8 2 3]
 [2 3 6 8 0 7 5 9 1 4]
 [6 0 3 4 9 8 7 1 2 5]
 [1 9 0 7 6 8 3 5 4 2]
 [6 0 7 4 8 9 2 3 5 1]]
Epoch  8610: Training cost= 0.3993, Training acc= 0.7573, Validation cost= 0.3915, Validation acc= 0.7577
Epoch  8620: Training cost= 0.4177, Training acc= 0.7574, Validation cost= 0.3725, Validation acc= 0.7578
Epoch  8630: Training cost= 0.4269, Training acc= 0.7575, Validation cost= 0.3828, Validation acc= 0.7579
Epoch  8640: Training cost= 0.3851, Training acc= 0.7576, Validation cost= 0.3943, Validation acc= 0.7580
Epoch  8650: Training cost= 0.3781, Training acc= 0.7576, Validation cost= 0.4537, Validation acc= 0.7581
Epoch  8660: Training cost= 0.3837, Training acc= 0.7577, Validation cost= 0.4015, Validation acc= 0.7582
Epoch  8670: Training cost= 0.3865, Training acc= 0.7578, Validation cost= 0.3818, Validation acc= 0.7583
Epoch  8680: Training cost= 0.3959, Training acc= 0.7579, Validation cost= 0.3780, Validation acc= 0.7584
Epoch  8690: Training cost= 0.3607, Training acc= 0.7580, Validation cost= 0.3435, Validation acc= 0.7585
Epoch  8700: Training cost= 0.3843, Training acc= 0.7581, Validation cost= 0.3687, Validation acc= 0.7586
tm  [-1.4  0.6 -0.9  0.4 -0.6  0.2 -0.4 -0.6 -0.5 -0.7 -0.8 -0.5  1.4  0.6 -0.6  5.5 -0.1 -0.4 -0.5 -1.  -0.2 -0.5  2.3 -0.6 -1.  -0.1 -0.1 -0.1  2.5 -0.9 -0.8 -0.7 -0.8 -3.3 -0.4 -0.1  0.9  5.   6.4 -1.  -0.2 -1.3 -0.4  4.4 -0.6 -0.2  0.2 -0.4 -0.7  2.9 -0.3 -0.4 -1.   3.8 -1.7  2.7 -0.5 -0.1  2.4  4.4  3.9 -0.1 -0.7  0.9 -0.8 -0.2 -0.4  0.9 -0.5  0.2 -0.2 -0.8  0.6 -0.2 -1.3  0.5  0.5 -0.9  0.6 -0.1 -2.2 -0.2 -0.8  0.5  0.1 -1.2 -0.2 -0.   3.3 -0.3 -0.4 -0.2 -0.2  0.5 -0.1 -0.1 -0.4 -0.7 -0.5 -0.4  2.9 -1.6  1.3  0.2 -0.3 -0.2 -1.2 -0.9 -0.4 -1.3 -0.3 -0.9 -0.2 -0.5 -0.1  6.  -0.5 -0.3 -0.4 -0.  -0.4  4.8 -0.1 -0.5 -0.6 -0.7  1.6 -0.2  3.7  4.7 -0.9 -0.6 -0.2 -0.3 -0.4 -4.8 -0.4 -0.2  1.2 -0.1 -0.5 -0.1 -0.7 -0.4 -0.9 -0.3 -0.2  0.3  2.2 -0.   1.6 -0.4  1.7 -0.6 -0.4 -0.2 -0.3 -0.4  3.2 -0.5 -0.4 -1.3 -0.9 -0.5 -1.5 -0.   3.6  3.2  0.6 -0.2 -0.4 -0.2 -0.8 -0.2 -0.2 -0.2  0.8 -0.7 -1.  -0.8 -0.7  0.6 -0.6 -1.   0.5  0.8 -0.3 -0.2 -1.5  5.4 -0.6 -0.3 -0.9 -0.8 -0.4 -0.9 -0.5  0.4 -0.2 -0.9 -0.2  0.2 -0.8 -1.2  0.2 -1.9 -0.6  0.9  6.2 -0.2 -0.3  4.1 -1.   2.2 -0.2 -0.2 -0.9 -0.2 -0.2 -0.6 -0.3  0.1 -0.5 -0.7 -1.   4.  -0.2  1.6 -0.5  3.7 -1.6 -0.1 -0.5  4.2 -0.4  3.5 -0.1 -0.8 -0.1  3.  -0.3  1.7 -0.3 -0.5  7.7 -0.3 -0.2 -0.3 -0.4 -0.6  3.2 -0.2  4.8  0.1  1.8 -0.6]
ty_50sample [[8 3 1 2 4 9 5 7 6 0]
 [6 4 1 9 7 5 8 2 0 3]
 [3 6 6 2 2 8 8 9 0 4]
 [8 6 1 0 4 3 5 2 9 7]
 [3 4 8 2 0 7 6 6 5 1]
 [0 5 1 8 4 6 7 9 2 3]
 [8 0 4 7 1 2 6 9 3 5]
 [6 1 3 0 2 8 5 4 7 9]
 [8 7 6 5 9 2 3 4 0 1]
 [5 3 0 2 8 9 4 6 7 1]]
tt_50sample [[8 3 1 2 4 9 5 7 6 0]
 [6 4 1 9 7 5 8 0 2 3]
 [3 7 6 5 2 8 1 0 9 4]
 [8 6 1 0 4 3 5 2 9 7]
 [3 4 8 2 0 7 9 6 5 1]
 [0 5 1 8 4 6 7 9 2 3]
 [8 0 4 7 1 2 6 9 3 5]
 [6 1 3 0 8 2 5 4 7 9]
 [8 7 6 5 9 2 3 4 0 1]
 [5 3 0 2 8 9 4 6 7 1]]
vm  [-1.2 -0.9  2.8  7.7 -1.1  0.2  0.6 -0.6  2.3  0.7  9.4 -0.2 -0.2 -0.2 -0.3 -0.7 -0.3 -0.4 -0.1 -0.2 -0.9 -0.4 -0.8 -0.3 -0.9  2.8 -0.2 -0.1 -1.6 -2.   2.4 -0.3 -0.3  5.5  1.7 -0.7 -0.1  1.9  0.9 -0.5 -0.7  2.4 -0.8 -1.  -0.8 -0.2 -0.2 -1.  -0.3 -1.6 -1.  -0.7  0.1  3.2  2.   2.8 -0.6  3.4  3.3 -0.5  4.8 -0.5  0.7  6.8  1.   0.1  0.5  2.1 -0.1 -0.3 -0.6  3.8 -0.8 -0.2 -2.9 -0.3  0.8 -0.4  0.7 -0.4 10.2 -0.  -0.2 -0.1  0.5  1.8 -0.9 -0.6 -0.5 -0.1  1.3 -1.3 -0.8 -1.  -0.5 -0.4  1.1 -1.3  0.3 -0.7 -0.6 -0.   2.9 -0.6 -0.6 -0.2 -1.9  2.1  2.6 -0.  -0.1  1.1 -0.3 -0.5  6.6 -1.5 -0.4  0.8  0.4  2.5  0.   1.7  0.1  1.8 -0.1 -0.3 -0.6 -0.1  1.6 -0.1 -0.2 -0.5 -1.6  0.9  6.4 10.6 -0.6 -0.5  2.  -0.3 -0.7 -0.1 -0.6 -0.5  0.3 -0.6  0.1  0.1  2.5 -1.  -0.8 -0.2 -2.   0.7 -0.5 -0.3  0.1 -0.3  0.1  3.   2.  -0.2 -0.2 -0.3 -0.4 -0.7 -1.   0.5 -0.9  2.8 -0.6 -0.  -0.4 -0.5 -0.1 -0.1 -0.6  1.5  1.7 -0.1 -0.4 -0.3 -0.1 -0.9  1.9 -1.2 -0.5 -0.4  1.7  8.4 -0.2 -0.8 -0.5 -0.6 -0.6 -0.4 -0.6 -0.7 -0.2  0.8 -0.2  1.5 -0.5 -0.7  1.8 -0.4  0.6 -0.3 -2.3  0.4 -0.4 -0.9 -0.2  3.8 -1.1 -0.4  4.6 -0.8 -0.8 -0.2  0.7 -0.6 -0.1 -1.3  2.6 -1.8 -0.1  4.9 -0.  -0.2 -0.4 -0.5 -0.4 -1.6  3.2 -0.3  2.5 -1.   1.5  2.1 -0.7  1.2 -0.6 -0.1 -1.9 -0.9  0.4  0.2 -0.9 -0.4 -2.1 -0.8  1.   1.3 -0.3  3.2]
vy_50sample [[0 1 2 6 9 5 3 7 4 8]
 [5 0 1 6 8 8 9 9 7 2]
 [1 8 2 6 3 9 0 0 5 7]
 [4 9 6 5 1 0 8 7 2 2]
 [0 7 4 3 2 6 1 8 9 5]
 [0 4 1 7 5 6 3 9 2 8]
 [7 6 8 2 9 3 5 4 0 1]
 [1 4 7 9 8 5 0 6 6 2]
 [6 0 0 4 5 2 9 1 7 8]
 [2 5 1 1 9 0 4 3 6 8]]
vt_50sample [[0 1 2 6 9 5 3 7 4 8]
 [5 0 1 6 3 8 4 9 7 2]
 [1 8 2 6 3 9 0 4 5 7]
 [4 9 6 5 1 0 8 7 2 3]
 [0 7 4 3 2 6 1 8 9 5]
 [0 4 1 7 5 6 3 9 8 2]
 [7 6 8 9 2 3 5 4 0 1]
 [1 4 7 9 8 5 0 3 6 2]
 [6 0 3 4 2 5 9 1 7 8]
 [2 5 7 1 9 0 4 3 6 8]]
Epoch  8710: Training cost= 0.3939, Training acc= 0.7582, Validation cost= 0.3661, Validation acc= 0.7587
Epoch  8720: Training cost= 0.3499, Training acc= 0.7583, Validation cost= 0.3911, Validation acc= 0.7588
Epoch  8730: Training cost= 0.3889, Training acc= 0.7584, Validation cost= 0.4190, Validation acc= 0.7589
Epoch  8740: Training cost= 0.4040, Training acc= 0.7585, Validation cost= 0.4124, Validation acc= 0.7590
Epoch  8750: Training cost= 0.4745, Training acc= 0.7586, Validation cost= 0.3791, Validation acc= 0.7591
Epoch  8760: Training cost= 0.3529, Training acc= 0.7587, Validation cost= 0.4045, Validation acc= 0.7591
Epoch  8770: Training cost= 0.4080, Training acc= 0.7588, Validation cost= 0.4349, Validation acc= 0.7592
Epoch  8780: Training cost= 0.3474, Training acc= 0.7589, Validation cost= 0.3782, Validation acc= 0.7593
Epoch  8790: Training cost= 0.3754, Training acc= 0.7590, Validation cost= 0.3906, Validation acc= 0.7594
Epoch  8800: Training cost= 0.3519, Training acc= 0.7591, Validation cost= 0.3472, Validation acc= 0.7595
tm  [-0.2  0.2  5.   1.2 -1.8 -0.7 -0.3 -0.2 -0.8 -1.1  6.5 -0.2 -0.2 -0.3  5.5  6.2 -0.1 -0.1  0.4 -0.4 -0.2 -0.1 -0.3 -0.2 -1.4  0.9 -0.2 -0.3  2.3  2.5  3.9 -0.5 -0.4 10.  -0.2  1.   2.1  1.3  1.  -0.6 -0.1  0.9  0.6  0.1 -0.6  0.4 -0.3 -0.5  2.3 -0.5 -1.1 -0.7  1.3  3.  -1.6 -0.8 -0.3  0.2 -0.5 -0.9 -0.5 -0.1 -0.4  1.4  0.2 -0.3 -0.2 -0.4 -0.1  0.2 -0.1 -0.7 -0.  -0.1 -0.5 -0.3 -0.6 -0.2  1.2  0.3  7.3 -0.2 -0.3 -0.  -0.8  1.6  1.9 -0.1  0.7 -0.3  0.2 -0.  -0.1 -0.5  0.7  0.9 -0.2 -1.  -0.6  0.   3.2  7.3 -0.8 -0.2 -0.1  1.5 -0.3  3.5  2.5 -0.7 -0.6 -0.8 -0.   0.  -1.1  7.6 -0.2 -0.5 -0.1 -0.7 -0.   3.4  0.6  0.9 -0.2  6.3  1.1 -0.2  1.3 -0.   3.5 -0.4  1.6 -0.6 -1.9  7.9  0.  -0.  -0.4 -0.8 -0.3 -0.1  0.5  0.7 -0.5  1.8 -0.  -0.4 -1.3  2.4  1.4 -0.2  0.5 -0.6 -0.2 -0.1 -0.5 -0.4 -0.5 -0.1  0.9  0.8 -0.1 -0.2  0.9 -0.9  2.5  0.5  0.2  0.  -0.4 -0.3 -0.5 -0.2 -0.2  4.2 -0.7  1.2  2.  -0.5 -0.5  0.8 -1.  -1.2 -1.2 -0.4  3.2 -0.7 -0.9 -0.8 -0.3 -0.2 -0.7 -0.7  3.8  1.1  1.6  0.7 -0.4 -0.2 -0.4 -0.4 -0.3 -0.5 -0.  -0.5 -0.1  0.1 -1.  -0.6 -0.3  5.  -1.1  1.2 -0.2 -0.6  0.9  0.2  2.  -0.2 -0.9 -0.3 -0.4 -0.1  2.   1.9  1.   0.9  0.2  2.5 -0.4 -0.9 -0.3 -0.6 -0.4 -0.9 -0.1  1.7  1.1  2.8 -0.5  1.9  0.5 -0.3 -1.1 -1.  -0.3  1.6 -0.4 -0.6 -1.5  1.4  0.5  0.6 -0.1  2.6]
ty_50sample [[7 2 6 4 9 5 3 1 8 0]
 [8 7 9 3 4 6 2 1 5 0]
 [0 5 3 9 4 1 8 2 6 6]
 [4 0 7 2 5 8 9 3 3 1]
 [5 6 7 0 9 8 2 4 3 1]
 [5 3 4 0 7 2 1 9 6 8]
 [9 4 1 0 3 7 8 5 6 2]
 [9 6 4 7 2 3 1 0 8 5]
 [0 1 8 3 6 7 4 2 5 9]
 [3 6 4 5 9 0 1 7 8 2]]
tt_50sample [[7 2 6 4 9 5 3 1 8 0]
 [8 7 9 3 4 6 2 1 5 0]
 [5 0 3 9 4 1 8 7 2 6]
 [4 0 7 2 5 8 9 6 3 1]
 [5 6 7 0 9 2 8 4 1 3]
 [5 3 4 0 7 2 1 9 6 8]
 [9 4 1 0 3 8 7 5 6 2]
 [9 4 6 7 2 3 1 0 8 5]
 [0 1 8 3 6 7 4 2 5 9]
 [3 4 6 5 9 0 1 7 8 2]]
vm  [-1.5 -0.2  2.4 10.6 -1.1  0.9 -0.3 -0.5 -0.5 -0.1  2.3 -0.7  0.4 -0.3 -1.5  5.3 -0.1 -0.2 -0.2 -1.5 -0.6 -0.2  4.2 -0.2 -1.5  2.2 -0.2 -0.4  1.  -0.3 -1.3 -0.6 -0.8 -1.8 -0.5 -0.   2.5  5.9 11.  -0.2 -0.1  3.5 -0.2  2.3 -0.6 -0.7  7.3 -0.9 -1.5  7.8 -0.3 -0.1  0.2  1.5 -1.2  4.1 -0.5  2.   0.1  3.9  2.4 -0.4 -0.4  0.  -0.5 -0.4 -0.4  0.3 -0.4 -0.9 -0.4 -0.6  0.5 -0.1  0.6 -0.   2.6 -0.3  1.5 -0.4  2.3  0.2 -0.5  0.5  1.9  5.6 -0.6 -0.2 -0.1 -0.1  0.1 -0.4 -0.9 -0.4 -0.  -0.1  1.6  0.9 -0.5 -0.4 -0.1  4.3  1.4 -0.4 -0.4 -0.3 -0.2 -1.   1.2 -1.5 -0.3 -0.6 -0.2  0.4 -0.1  2.9  0.5 -1.2 -0.3  0.2 -0.2  4.9 -0.2 -0.5  0.6 -1.6  0.7  1.4  1.9 -1.7 -1.5 -0.3 -1.4 -0.2 -1.7 -3.7  0.  -0.7 -0.2 -0.7 -0.7 -0.5 -0.6 -0.6 -0.4 -0.4  1.4  0.8  1.7  1.8 -1.3 -0.2 -0.1 -0.2 -0.  -0.  -0.3 -0.5  3.5 -0.1  1.4 -1.6 -0.2 -0.4 -1.2 -0.4 -0.3 -0.3 -0.8  3.3  2.3 -0.2 -0.6  0.2 -0.3 -0.3 -0.3  2.1 -2.6 -0.7 -0.4 -0.2  0.7 -1.1 -0.7  0.2 -0.4 -0.1 -0.7  2.3 -0.5 -1.1 -1.3 -0.9  0.2 -0.   1.6  1.9 -0.5 -0.4 -0.2 -0.5 -0.5 -0.8  0.9  4.6  0.1 -0.2  2.1 -0.5 -0.   2.  -0.   6.4 -0.9 -0.3 -0.4 -0.4 -0.1 -0.1 -0.5 -0.6 -0.2 -1.   0.3  2.2 -0.1  4.4 -0.1 -1.  -0.8 -0.6 -0.3  2.  -0.6 -0.1  0.8  1.6 -0.6  6.1 -0.6  3.5 -0.6 -0.4 -0.  -2.6  2.2 -0.1  0.4 -0.6 -0.6  0.3  9.4  2.  -0.4  9.6]
vy_50sample [[1 2 9 8 5 7 0 4 3 6]
 [4 0 2 7 1 6 9 5 3 3]
 [7 2 6 4 8 5 9 1 0 3]
 [0 6 9 2 8 4 5 7 3 1]
 [7 9 1 8 4 5 3 6 2 0]
 [0 7 3 1 9 5 8 4 2 6]
 [7 4 5 3 9 2 0 0 8 8]
 [6 8 8 3 0 0 9 2 4 4]
 [5 6 8 1 9 2 7 0 4 4]
 [4 0 5 8 8 7 6 6 2 3]]
vt_50sample [[1 2 9 8 5 7 0 4 3 6]
 [4 0 2 7 1 6 9 8 5 3]
 [7 2 6 4 8 5 9 1 0 3]
 [0 6 9 2 8 4 5 7 3 1]
 [7 9 8 1 4 5 3 6 2 0]
 [7 0 3 1 9 5 8 4 2 6]
 [7 4 5 3 9 2 6 0 8 1]
 [6 8 1 3 5 9 0 2 7 4]
 [5 6 8 1 9 2 7 0 3 4]
 [4 0 5 9 8 7 1 6 2 3]]
Epoch  8810: Training cost= 0.3538, Training acc= 0.7592, Validation cost= 0.3608, Validation acc= 0.7596
Epoch  8820: Training cost= 0.3563, Training acc= 0.7593, Validation cost= 0.4118, Validation acc= 0.7597
Epoch  8830: Training cost= 0.4230, Training acc= 0.7594, Validation cost= 0.3723, Validation acc= 0.7598
Epoch  8840: Training cost= 0.4342, Training acc= 0.7595, Validation cost= 0.5099, Validation acc= 0.7599
Epoch  8850: Training cost= 0.4198, Training acc= 0.7595, Validation cost= 0.4618, Validation acc= 0.7600
Epoch  8860: Training cost= 0.4241, Training acc= 0.7596, Validation cost= 0.4432, Validation acc= 0.7600
Epoch  8870: Training cost= 0.4703, Training acc= 0.7597, Validation cost= 0.3945, Validation acc= 0.7601
Epoch  8880: Training cost= 0.4597, Training acc= 0.7598, Validation cost= 0.4259, Validation acc= 0.7602
Epoch  8890: Training cost= 0.3674, Training acc= 0.7599, Validation cost= 0.3189, Validation acc= 0.7603
Epoch  8900: Training cost= 0.3578, Training acc= 0.7600, Validation cost= 0.3775, Validation acc= 0.7604
tm  [-0.9  2.1  4.1 -2.  -0.9 -0.4 -0.6 -0.6 -1.  -0.1 -3.8  1.7 -1.3 -0.1 10.5 -0.1 -0.2  0.2 -0.3  5.5 -0.2 -0.7  3.2 -0.2 -1.2 -0.5 -0.2 -0.3  1.4  0.6 -1.2 -0.3  1.  -1.3 -0.9 -0.6 -0.1 -0.5 -3.8 -0.4 -0.1 -0.1  0.2 -1.2 -0.8 -0.3 -3.5  0.4 -0.5  5.7 -0.5 -0.5 -1.2  3.8 -1.2 -1.5 -0.1  2.4  0.2  4.1  9.  -0.3 -0.1 -0.5 -0.6 -0.5 -0.5 -0.5  0.6  0.3 -0.5 -0.6  1.6 -0.3 -5.4 -0.3  0.6 -0.3  0.9  0.  -5.4  0.1  1.6 -0.1 -0.2  0.4 -0.1 -0.1  1.3 -0.1 -0.1  0.2 -0.1  0.8 -1.1 -0.1  0.3 -2.  -0.4 -0.3  1.1  3.3  2.1 -0.4 -0.3  0.5 -3.1 -1.5 -1.9  5.4  0.4 -0.5 -0.3 -0.1 -0.1  3.9 -0.2 -0.  -0.3  0.8 -0.4 -2.   0.4 -0.2 -0.1 11.   2.1 -0.5  0.3  5.8  1.9 -0.3  1.2 -0.   5.   1.  -0.2  0.4 -0.6  0.2  3.1 -0.6  2.6  0.5 -1.1 -0.  -0.1 -0.2 -0.4  0.1  4.1 -0.3  1.8  0.6 -0.3 -0.4 -0.7 -0.  -1.3 -0.9 -0.1  3.4  1.5  0.4 -1.1 -0.5  1.4  2.6  0.3 -0.6 -0.5 -0.1 -0.8 -0.2 -0.4  2.1 -1.6 -1.5 13.8  2.3 -0.1  0.7 -0.2 -1.2 -0.2  0.7 -1.6 -0.2 -1.4  0.5 -0.3 -0.3  2.4 -1.4 -2.1  0.2 -1.7 -0.2 -0.4 -0.8 -0.3  0.3 -0.2 -0.5  0.8 -3.2 -0.7 -0.6  5.9 -0.4 -0.7  1.5 -0.8  4.3 -0.5 -0.1  5.5 -0.1  1.5 -0.  -1.6  0.3 -0.5 -0.6  2.7  4.1 -1.9  1.1 -0.4 -0.   0.6  1.1 -0.2  3.8 -0.2 -0.7 -0.2 -2.5  0.5 -2.5 -0.9 -1.3 -0.1 -0.1 15.5  4.1 -0.2 -0.3 -0.2 -0.3 11.5 -0.5 -3.  -0.4  4.1 -1.7]
ty_50sample [[6 8 7 1 3 5 4 0 2 9]
 [8 4 7 9 0 6 5 2 3 1]
 [4 6 8 8 2 7 1 1 5 3]
 [9 6 4 1 2 8 3 7 5 0]
 [9 1 8 3 2 4 6 6 7 7]
 [0 7 9 1 5 2 8 3 6 4]
 [4 5 8 1 2 7 0 9 9 6]
 [9 5 1 2 2 3 0 4 6 7]
 [5 7 7 8 3 2 6 1 4 9]
 [9 2 5 0 3 3 6 1 8 4]]
tt_50sample [[6 8 1 7 3 5 4 0 2 9]
 [8 4 7 9 0 6 5 2 1 3]
 [4 6 8 2 0 9 7 1 5 3]
 [9 6 4 1 2 8 3 7 5 0]
 [9 1 8 3 2 4 6 0 5 7]
 [0 7 9 1 2 5 8 3 6 4]
 [4 5 8 1 7 2 0 9 3 6]
 [5 1 9 2 3 8 0 4 6 7]
 [5 7 8 0 3 2 6 1 4 9]
 [2 9 5 7 0 3 6 1 8 4]]
vm  [-1.1 -0.6  7.3 15.3 -1.7 -0.2 -0.3  0.5 -0.1  0.4  5.4 -0.5  0.6 -0.2 -0.7  1.7 -1.1 -0.6  1.4 -2.  -0.5 -0.1  1.7 -0.7 -0.4  1.1 -0.4 -0.3 -0.3 -0.9 -0.1 -0.3 -1.1  7.8  0.5  0.1  0.6  1.7 12.5 -0.7 -0.6  3.  -0.5 -0.1 -0.3 -0.   7.9 -0.3 -0.2  3.2 -0.9  0.5  2.3 -1.  -0.8  1.9 -0.6  2.3  1.6  2.5 -0.7  0.1 -0.2  3.8  0.3  0.4 -0.1 -0.6 -0.1  0.4 -0.2  0.3 -0.   0.5  8.9 -0.1 -0.1 -0.2  1.8  0.4 14.9 -0.3 -1.1  0.3 -0.1  3.8 -0.9 -0.7 -0.5 -0.4  0.4 -0.3 -1.1 -1.4  2.6  0.2  0.9  0.1 -0.4 -0.1 -0.2  7.8  1.3 -0.2 -0.1 -0.1  4.2 -0.3  1.4 -2.9 -0.6 -0.3 -0.3 -0.3  1.3  0.7 -0.2 -0.4 -0.6 -0.6  0.  10.5  0.3  1.1  0.2 -0.9 -0.1  5.7  2.6 -2.4 -0.6 -1.2 -1.1 -0.7 -3.3 -0.   0.1 -0.7 -0.5 -0.7 -0.3  0.2 -0.3 -0.3 -0.7 -0.   0.6 -0.  -1.   0.2 -1.3 -0.2 -0.5 -0.5  0.2 -0.1 -0.  -0.2  3.5  0.5  2.  -0.7 -0.6 -0.4 -0.  -1.  -0.1  0.8 -0.7  4.5  0.6 -0.6 -0.3 -0.3 -0.1  3.4  0.5  4.7 -2.8 -0.3 -0.8 -0.2 -0.6 -1.2 -0.3 -0.6  1.7 -0.5  0.9  3.6 -0.4 -0.6 -1.7 -0.2  4.2 -0.4  5.8 -0.3 -0.1  0.1 -0.6 -0.3 -0.3 -0.7  2.1  5.   1.3  1.6 -0.2 -0.3  0.2  1.3 -0.9  4.  -1.  -0.7  1.4 -0.4  1.9 -0.1 -0.6 -0.8 -0.3 -0.3  1.2 -0.3 -0.   4.5  1.1 -0.1 -0.5 -1.4 -0.1 -0.3  1.6 -2.1  0.9  7.5  1.3 11.8 -0.3  6.4 -0.  -0.2 -2.8 -2.7 -0.3  1.9 -0.9 -0.7 -3.2 -0.5 10.   1.4 -0.2 10.8]
vy_50sample [[9 7 1 2 0 5 8 6 4 3]
 [8 7 4 6 3 2 9 0 1 5]
 [3 2 2 8 6 5 7 0 9 4]
 [2 6 6 4 4 9 7 8 5 1]
 [2 1 1 3 0 8 7 5 6 4]
 [3 8 8 1 9 7 2 4 5 0]
 [8 2 1 5 9 4 3 0 7 6]
 [6 4 8 2 9 3 7 0 1 5]
 [8 9 7 3 5 2 0 1 4 6]
 [1 3 3 8 5 4 9 2 0 6]]
vt_50sample [[9 7 1 2 0 5 8 6 4 3]
 [8 7 4 6 3 2 9 0 1 5]
 [3 2 1 8 6 5 0 7 9 4]
 [2 3 6 4 0 9 7 8 5 1]
 [2 9 1 3 0 8 7 5 6 4]
 [3 8 6 9 1 7 2 4 5 0]
 [8 2 1 5 9 4 3 0 7 6]
 [6 4 8 2 9 3 7 0 1 5]
 [8 9 7 3 5 2 0 1 4 6]
 [1 7 3 8 5 4 9 2 0 6]]
Epoch  8910: Training cost= 0.4142, Training acc= 0.7601, Validation cost= 0.3468, Validation acc= 0.7605
Epoch  8920: Training cost= 0.3524, Training acc= 0.7602, Validation cost= 0.3522, Validation acc= 0.7606
Epoch  8930: Training cost= 0.4136, Training acc= 0.7603, Validation cost= 0.4427, Validation acc= 0.7607
Epoch  8940: Training cost= 0.4062, Training acc= 0.7604, Validation cost= 0.4195, Validation acc= 0.7608
Epoch  8950: Training cost= 0.3258, Training acc= 0.7605, Validation cost= 0.3342, Validation acc= 0.7609
Epoch  8960: Training cost= 0.4004, Training acc= 0.7606, Validation cost= 0.3492, Validation acc= 0.7610
Epoch  8970: Training cost= 0.3556, Training acc= 0.7607, Validation cost= 0.3384, Validation acc= 0.7611
Epoch  8980: Training cost= 0.4202, Training acc= 0.7608, Validation cost= 0.3862, Validation acc= 0.7612
Epoch  8990: Training cost= 0.3840, Training acc= 0.7609, Validation cost= 0.3644, Validation acc= 0.7613
Epoch  9000: Training cost= 0.3786, Training acc= 0.7609, Validation cost= 0.4074, Validation acc= 0.7614
tm  [-0.   1.2  3.5  2.9 -1.8 -0.5 -0.3 -0.2 -1.6 -0.9 -1.3  0.4 -0.5  0.2  2.5  4.   0.9 -0.2 -0.1 -1.7  0.4 -0.   1.9  0.1 -1.3 -0.3 -0.2 -0.3  2.5  2.2  0.8 -0.5 -0.6  4.4 -1.   1.1  3.7  1.7 11.5 -0.8 -0.1  0.8  2.4  5.3 -0.4  0.2  5.4  2.3  0.9  2.3 -0.4 -0.1  0.7 -1.3 -1.4 -0.2 -0.4 -0.1 -1.   0.9 -1.2 -0.2 -0.5 -0.7 -0.6 -0.2 -0.3 -1.  -0.1  0.8  0.4 -1.2  0.6 -0.4  5.1  0.6 -0.2 -0.1  0.4  0.8  3.4 -0.  -1.2  0.4 -0.9  2.   2.5 -0.1  3.7 -0.4  0.2  1.5 -0.   1.   1.6  0.   0.1  2.2 -0.5 -0.3  3.7  4.9 -0.9 -0.3  0.5 -0.4  1.7  1.  -0.6 -2.  -0.3 -0.9 -0.1  0.7 -1.6  8.5 -0.1 -0.8  0.  -1.2 -0.7  7.6 -0.2 -0.9 -0.1  2.1  3.2  6.8  0.4 -0.4 -0.1 -0.4  1.5 -0.1 -4.6 -3.4  0.1 -0.7 -0.6 -0.6  0.9 -0.4  1.5 -0.3 -0.6  1.4  0.7 -1.1 -0.6  2.2 -0.2 -0.1  3.3 -0.3 -0.1 -0.5 -0.6 -0.6  3.2 -0.6 -0.4 -1.1 -0.4 -0.2  0.2 -0.2  2.2 -0.2  0.7 -0.   0.9 -0.1 -0.8 -0.3  0.   2.9  1.   1.8 -2.4 -0.6 -0.8  0.  -0.4 -1.3 -1.3 -0.1  4.  -0.8 -0.7 -0.6 -0.4 -0.2 -0.9 -1.   6.9  0.5  4.   2.8 -0.5 -1.  -0.6 -0.3 -0.4 -0.4 -0.4  2.4  0.1 -0.1  2.5 -0.2 -0.3  4.3 -0.3 -0.1  0.1 -0.4 -1.2  0.4  1.6 -0.4 -1.4 -0.1 -0.4 -0.  -0.8  4.8 -0.6 -0.5 -0.2  2.3 -1.1 -0.7 -0.3  2.  -0.8 -0.4 -0.6  4.7  0.3  5.6 -0.   3.3 -0.4 -0.4 -0.1 -1.9 -0.3 -0.3 -0.3 -0.8 -0.8  0.1  9.2 -0.1  2.4  4.4]
ty_50sample [[7 9 4 8 5 3 2 1 6 0]
 [9 1 4 7 8 8 2 3 5 0]
 [6 6 9 2 0 1 7 3 4 5]
 [3 8 1 1 5 7 0 4 9 2]
 [6 1 8 2 9 0 5 3 7 4]
 [4 9 5 8 8 2 7 7 0 0]
 [7 8 6 3 4 4 2 2 5 0]
 [8 6 9 0 0 1 5 3 2 4]
 [0 0 2 2 9 8 6 3 5 1]
 [0 5 6 1 7 3 2 2 4 8]]
tt_50sample [[7 9 8 4 5 3 2 1 6 0]
 [9 1 6 7 4 8 2 3 5 0]
 [6 8 9 2 0 1 7 3 4 5]
 [3 8 6 1 5 7 0 4 9 2]
 [6 1 8 2 9 0 5 3 7 4]
 [9 4 5 1 8 2 6 7 0 3]
 [7 8 6 3 9 4 2 5 0 1]
 [8 6 9 7 0 1 5 3 2 4]
 [4 0 7 2 9 8 6 3 5 1]
 [0 5 6 1 7 3 2 9 4 8]]
vm  [-0.6 -0.1  5.6 10.  -1.1 -0.2 -0.3 -0.4 -0.7  1.2  3.1 -0.9  1.2 -0.2  0.4  3.3 -0.8 -0.4 -0.  -1.7 -0.6 -0.1  3.2 -0.4 -0.9  0.8 -0.2 -0.4  0.1  0.1 -0.7  0.1  0.8  3.3  0.4  0.   2.6 -0.3 -0.4 -0.3 -0.3  1.1 -0.5 -1.2 -0.1  0.3  4.5 -0.6  0.2  7.2 -0.7 -0.2 -0.   0.5 -0.7  1.1 -0.3 -0.1  0.1  3.7 -0.5  1.4 -0.7  1.6 -0.3 -0.2 -0.2 -0.2  0.3 -0.3 -0.2 -0.2  0.7 -0.   0.4  0.1 -0.1  0.3  1.4 -0.2  4.6 -0.2 -0.7  0.1 -0.4  1.7 -0.4 -0.1 -0.5 -0.1 -0.3 -0.  -0.6 -0.7  0.2  0.   0.3 -0.3 -0.2 -0.1 -0.5  7.2  0.1  0.5 -0.1  0.2  0.1 -0.7  1.3 -2.  -0.8 -0.2 -0.1 -0.  -0.   2.4 -0.3 -0.6 -0.5 -0.2 -0.3  7.1  0.6 -0.3 -0.2 -0.1 -0.2  1.9 -0.2 -1.7  3.7 -1.  -0.6 -0.4  4.2  7.5 -0.1 -0.5 -0.7 -0.7 -0.5 -0.5 -0.3 -0.  -1.1  0.6 -0.  -0.3 -1.3  2.  -0.6 -0.2  1.4 -0.7 -0.  -0.3 -0.4 -0.3 -1.2 -0.4  1.5  3.7 -0.1 -0.5 -0.5 -0.3 -0.   1.3 -0.4  2.7  1.3 -1.  -0.1 -0.1 -0.1  4.5 -1.   1.6  3.2 -0.7  1.3  1.1 -0.3 -0.7 -0.6 -0.4  2.4 -0.3 -0.4 -0.1 -0.2 -0.8 -1.3 -0.5  3.   0.   1.6  0.8 -0.3 -0.3 -0.5 -0.2 -0.4 -0.3  0.4 -0.  -0.5  1.7  5.9 -0.3  0.6  2.4 -1.1  2.4 -0.7 -0.4  5.7 -0.4  0.9 -0.  -0.8 -0.4 -0.3 -0.7  4.9  1.4  0.   3.   0.9  0.6  1.7 -0.7 -0.1  3.7 -0.3 -1.3  1.8  2.3  1.3 12.4 -0.6  7.   0.3 -0.2 -0.3 -1.5 -0.1  1.4 -0.7 -0.5 -1.1 -0.5 -0.2  1.4 -0.3  9.1]
vy_50sample [[6 9 7 2 8 1 0 4 5 3]
 [6 7 1 2 0 9 3 4 5 8]
 [8 5 7 6 0 9 3 1 2 4]
 [2 4 7 6 9 1 8 3 0 5]
 [1 8 0 0 9 3 7 2 6 4]
 [4 1 0 9 7 6 2 3 8 8]
 [3 4 9 6 5 8 0 1 2 7]
 [9 7 6 2 8 5 0 4 1 3]
 [0 4 2 3 7 1 1 8 8 6]
 [8 3 1 0 5 7 4 2 6 9]]
vt_50sample [[6 9 7 2 8 1 0 4 5 3]
 [6 7 1 2 0 9 3 4 5 8]
 [8 5 7 6 0 9 3 1 2 4]
 [2 4 7 6 9 1 8 3 5 0]
 [1 8 0 5 9 3 7 2 6 4]
 [4 1 0 9 7 6 2 3 8 5]
 [3 4 9 6 5 8 0 1 2 7]
 [9 7 6 2 8 5 0 4 1 3]
 [0 4 2 3 7 1 5 8 9 6]
 [8 3 1 0 5 7 4 2 6 9]]
Epoch  9010: Training cost= 0.3709, Training acc= 0.7610, Validation cost= 0.3903, Validation acc= 0.7615
Epoch  9020: Training cost= 0.4123, Training acc= 0.7611, Validation cost= 0.4080, Validation acc= 0.7616
Epoch  9030: Training cost= 0.3911, Training acc= 0.7612, Validation cost= 0.3719, Validation acc= 0.7617
Epoch  9040: Training cost= 0.4291, Training acc= 0.7613, Validation cost= 0.4180, Validation acc= 0.7617
Epoch  9050: Training cost= 0.3524, Training acc= 0.7614, Validation cost= 0.3707, Validation acc= 0.7618
Epoch  9060: Training cost= 0.3818, Training acc= 0.7615, Validation cost= 0.4551, Validation acc= 0.7619
Epoch  9070: Training cost= 0.4760, Training acc= 0.7616, Validation cost= 0.4070, Validation acc= 0.7620
Epoch  9080: Training cost= 0.4164, Training acc= 0.7616, Validation cost= 0.3413, Validation acc= 0.7621
Epoch  9090: Training cost= 0.4418, Training acc= 0.7617, Validation cost= 0.3227, Validation acc= 0.7622
Epoch  9100: Training cost= 0.3499, Training acc= 0.7618, Validation cost= 0.3988, Validation acc= 0.7622
tm  [ 2.1  0.4  3.8 -3.  -1.7 -0.8 -0.7 -0.8 -1.2 -0.6 -1.4  0.4 -0.9 -0.3 13.6 -0.4 -0.1  0.3 -0.   3.4 -0.5 -0.4 -0.2 -0.  -0.8 -0.1 -0.5 -0.1 -0.3 -0.3  1.  -0.1  0.   4.4  0.1 -0.2  1.  -0.1 -1.8 -0.9 -0.3 -2.  -0.4  3.  -1.1  0.2 -2.6  0.4  2.6 -0.2 -0.8 -1.  -1.4  4.6 -0.7 -1.9 -0.7 -1.1  0.4  0.5  2.9  1.1 -0.6 -0.  -0.3 -0.3 -0.2 -0.3  0.8  1.4  0.2 -0.1 -0.1 -0.6 -5.   0.1 -0.7 -0.6  0.6 -0.2 -3.7 -0.3  0.5  0.6 -1.  -2.1  3.2 -0.5  2.3 -0.1 -0.6 -0.1 -0.   1.3 -1.   0.2 -0.7 -1.6 -0.5 -0.4  2.7  2.6 -0.3 -0.3  0.3  0.3 -3.   1.2 -0.8  2.9  0.5 -0.5  0.4 -0.5  0.6  0.  -0.   2.6  0.5 -0.5 -0.2 -1.3 -0.2 -0.8 -0.6 14.1  0.1 -0.8 -0.3  9.4  2.3 -0.4  2.6 -0.  -2.2 -0.9 -0.4 -0.1  0.5 -0.4  1.2 -0.8  0.6 -0.2 -0.4 -0.3 -0.5 -1.  -1.8 -0.4  4.6 -0.1  4.  -0.3 -0.4 -0.  -0.3 -0.1 -0.5 -1.2 -0.5 -0.3  0.4 -0.4  0.3 -0.1  0.5  3.5  0.6 -1.2 -0.8 -0.4 -0.3  0.3 -0.4  6.6 -0.5 -1.8  7.4  0.7  1.  -0.  -0.1 -1.   0.  -0.3  0.1 -1.  -0.8  0.5 -0.4  0.3  1.7 -1.3 -0.1 -0.2 -1.9 -0.3 -0.3 -0.2  0.2  0.  -0.1 -0.2 -0.8 -3.5 -0.8 -0.6  6.1 -0.4 -0.7 -0.7 -1.  -0.4  1.2 -0.  -0.3 -0.2  1.5 -0.3 -1.3  0.  -0.1 -0.6 -0.4  1.3 -1.1 -0.4  0.4  4.3 -0.7  2.  -0.4  4.4  0.2 -0.5  1.4 -2.5  2.4 -0.4 -0.5 -0.1 -0.1 -0.2 11.4  4.9 -0.4 -0.7 -0.4  0.   7.9 -0.1 -1.4 -0.6  3.4 -2.6]
ty_50sample [[7 3 4 8 0 6 2 5 1 9]
 [4 6 9 3 5 2 8 0 1 7]
 [3 1 9 6 5 2 4 8 7 7]
 [1 4 7 6 6 0 3 5 2 9]
 [2 9 5 4 8 6 3 1 7 0]
 [3 7 0 9 2 1 4 5 6 8]
 [1 5 8 9 4 7 0 3 2 6]
 [5 0 4 8 6 3 1 9 2 7]
 [1 9 3 3 0 5 8 6 4 2]
 [4 6 0 1 5 9 2 7 3 8]]
tt_50sample [[7 3 4 8 0 6 2 1 5 9]
 [4 6 3 9 5 2 8 0 1 7]
 [3 1 9 6 5 2 4 0 8 7]
 [1 4 7 6 8 0 5 3 2 9]
 [2 9 5 4 8 6 3 1 7 0]
 [3 7 0 9 2 1 4 5 6 8]
 [1 5 8 4 9 7 3 0 2 6]
 [5 0 4 8 6 3 1 9 2 7]
 [1 9 3 7 0 5 8 6 4 2]
 [4 6 0 1 5 9 2 7 3 8]]
vm  [-0.7 -0.  -0.1 -0.7 -0.8 -1.  -0.6 -0.6  0.5  0.8 -4.4  2.3 -1.7 -0.5  2.9 -1.  -0.1 -0.1 -0.5  2.9 -0.3 -0.5  3.4  0.2 -0.3 -0.4 -0.3 -0.2 -0.3 -0.9 -1.6 -0.5  0.3 -4.5 -0.4 -1.1 -0.5 -0.2 -2.3 -0.7  0.3  3.2  0.2 -0.8 -0.5 -0.4 -2.3  0.4  0.6  6.6 -0.3 -0.7 -1.5  1.1 -0.6  0.3 -0.1  4.3  2.4  5.1  5.  -1.  -0.3  0.4 -0.9 -0.5 -0.5 -0.   1.4 -0.3 -0.4 -0.1  0.6 -0.6 -5.1 -0.  -0.4 -0.1 -0.2 -0.2 -5.1 -0.   0.8  0.3 -0.8  3.9 -0.3 -0.3  0.5 -0.2  0.4 -0.2 -0.8 -0.  -0.8 -0.4  1.3 -2.2 -0.3 -0.2 -0.1 -0.7  1.  -0.3 -0.5 -0.1 -3.1 -1.8 -2.2  2.6  2.  -0.3 -0.  -0.8  2.8  1.3 -0.3  2.2 -0.1  2.2 -0.6 -1.3 -0.3 -0.8 -0.2  3.8  1.   1.6  3.8  4.3  2.3 -0.5  0.9 -0.4  9.5 -1.2 -0.2 -0.3 -0.6  1.5  3.2 -0.5  1.5 -0.2 -1.  -0.2 -0.5 -0.5  5.6 -0.2  2.  -0.2  3.9  0.6 -0.5 -0.  -0.3 -0.4 -0.9 -0.8  0.3  0.9 -0.2 -0.2 -1.6 -0.1 -0.2  1.6 -0.4 -0.3 -0.3  2.4 -0.7 -0.4 -0.4 -1.4 -1.4 -1.2  9.9  2.6 -1.4 -0.3 -0.3 -1.   1.   1.6 -0.6 -0.  -1.3  5.  -0.3 -0.4 -0.3 -1.2 -0.8 -0.7 -1.8 -0.9 -0.4 -0.7 -0.5  1.5 -0.  -0.5  0.1 -2.8 -0.1 -0.8  3.1 -0.3 -0.4 -0.1 -0.8  1.1 -0.8 -0.2  4.1 -0.2 -0.2 -0.4 -1.1 -0.  -0.5 -0.5  2.   2.4 -1.8  0.6 -0.7  3.6 -0.3  2.1 -0.4  2.3 -0.1  2.5  0.8 -2.5  0.5 -3.5 -0.8 -2.1  0.5 -0.3 14.8  2.2  0.4 -0.7 -0.8 -0.  10.5 -1.  -1.9 -0.9  5.7 -1.1]
vy_50sample [[8 5 6 3 3 0 4 7 2 9]
 [4 4 6 5 3 1 7 9 2 0]
 [0 3 5 1 6 4 2 2 7 8]
 [2 0 6 6 7 4 1 1 5 9]
 [3 4 5 7 0 2 6 1 9 8]
 [7 2 6 3 8 5 9 4 1 1]
 [6 4 0 7 7 3 3 5 2 8]
 [0 7 1 4 3 6 8 2 5 9]
 [1 5 6 6 9 9 7 2 8 0]
 [9 6 6 2 2 0 5 1 3 4]]
vt_50sample [[8 5 6 3 0 1 4 7 2 9]
 [8 4 6 5 3 1 7 2 9 0]
 [0 3 5 1 6 4 2 9 7 8]
 [2 0 3 6 7 4 8 1 5 9]
 [3 4 5 7 0 2 6 1 9 8]
 [7 2 6 3 8 5 9 0 4 1]
 [6 4 0 7 9 3 1 5 2 8]
 [0 7 1 4 3 6 8 2 5 9]
 [1 5 4 6 9 3 7 2 0 8]
 [9 6 8 7 2 0 5 1 3 4]]
Epoch  9110: Training cost= 0.4121, Training acc= 0.7619, Validation cost= 0.4100, Validation acc= 0.7623
Epoch  9120: Training cost= 0.3735, Training acc= 0.7620, Validation cost= 0.4060, Validation acc= 0.7624
Epoch  9130: Training cost= 0.3989, Training acc= 0.7621, Validation cost= 0.3737, Validation acc= 0.7625
Epoch  9140: Training cost= 0.3788, Training acc= 0.7622, Validation cost= 0.3715, Validation acc= 0.7626
Epoch  9150: Training cost= 0.3523, Training acc= 0.7623, Validation cost= 0.3398, Validation acc= 0.7627
Epoch  9160: Training cost= 0.4563, Training acc= 0.7623, Validation cost= 0.3948, Validation acc= 0.7628
Epoch  9170: Training cost= 0.3961, Training acc= 0.7624, Validation cost= 0.3246, Validation acc= 0.7628
Epoch  9180: Training cost= 0.4280, Training acc= 0.7625, Validation cost= 0.3628, Validation acc= 0.7629
Epoch  9190: Training cost= 0.4058, Training acc= 0.7626, Validation cost= 0.3677, Validation acc= 0.7630
Epoch  9200: Training cost= 0.3727, Training acc= 0.7627, Validation cost= 0.3604, Validation acc= 0.7631
tm  [ 0.  -0.1 -0.  -1.1 -1.  -0.6 -0.6 -0.6 -0.5 -0.6  3.3  0.3 -0.6 -0.7  3.8 -0.6 -0.3 -0.4 -0.4 -0.1 -0.7 -0.3 -1.2 -0.  -0.7  2.6 -0.3 -0.1 -0.8 -0.4  4.3 -0.   0.7  5.8  0.4 -0.2  1.2 -0.7 -1.9 -0.9 -0.4 -1.9 -0.8 -0.4 -0.7 -0.  -0.8 -0.1  2.2 -1.8 -1.2 -0.9 -0.4  1.4 -0.4 -0.2 -0.2 -0.9  0.1 -1.   0.8  0.5 -0.2  2.7 -0.1 -0.5 -0.2  0.6  0.9  1.6 -0.6  1.9 -0.5 -0.5 -2.7 -0.  -0.6 -0.8  1.4 -0.3  3.6 -0.2 -0.2 -0.3 -0.7 -2.1  1.2 -0.2  1.2 -0.  -0.6  0.3  0.3 -0.3 -0.6 -0.1 -0.5 -1.4 -0.1 -0.3  1.4 -0.4 -0.5 -0.1 -0.2  0.5 -1.6  4.5  2.  -0.2 -0.5  0.8 -0.3 -0.6  3.6 -0.7 -0.3  1.2 -0.2 -0.1 -0.1  0.7  0.4  0.3 -0.9  4.7 -0.1  1.5 -0.6  5.2  4.6 -0.8  0.7 -0.4  6.6 13.4 -0.2  0.8  1.5 -0.7  0.9 -0.4 -0.   0.  -0.5 -0.5 -0.2 -0.5 -1.  -0.4  2.3 -0.1  0.2 -0.1 -0.5 -0.2 -0.3 -0.3 -1.6 -0.7 -0.2  1.9  0.1 -0.3 -0.  -0.6  0.3  4.  -0.1 -0.3 -0.9 -0.8 -0.1 -0.  -0.7  5.1 -1.3 -0.6  7.8  1.   1.7 -0.  -0.2 -0.8  0.1 -0.7  1.4 -0.4 -0.   1.4 -0.4 -0.1 -0.1 -0.8  1.8  1.6 -0.9 -0.3 -0.5 -0.1 -0.1  0.3 -0.2 -0.4 -0.3 -1.7 -0.3 -0.1  2.9 -0.1 -0.5 -0.2 -1.2  0.  -0.3 -0.4  2.7 -0.5 -0.3 -0.2 -0.5 -0.4 -0.2 -0.9  1.7 -0.8 -0.7 -0.1  0.7  4.3  1.2  0.2 -0.5  1.8  1.9  1.7  2.6 -1.1  2.4  6.6 -0.6  3.4 -0.2 -0.3 -0.3 -0.  -0.  -0.4 -0.6 -0.2 -1.  -0.6 -1.5 -0.2  2.  -1.1]
ty_50sample [[6 3 0 4 7 9 9 1 8 5]
 [0 1 9 9 2 4 3 7 6 5]
 [7 8 4 3 2 9 5 6 1 0]
 [8 8 0 4 1 3 2 9 7 6]
 [6 5 5 4 2 2 3 8 7 1]
 [3 8 4 5 2 9 0 1 7 6]
 [0 3 6 5 8 2 1 4 9 7]
 [8 4 6 3 2 5 0 7 7 9]
 [4 4 6 8 3 7 1 0 2 2]
 [7 9 6 1 8 3 4 5 0 0]]
tt_50sample [[6 0 3 4 7 2 9 1 8 5]
 [0 1 9 8 2 3 4 7 6 5]
 [7 8 4 3 2 9 5 6 1 0]
 [8 5 4 0 1 3 2 9 7 6]
 [6 5 0 9 4 2 3 8 7 1]
 [3 4 8 5 2 0 9 1 7 6]
 [0 3 5 6 8 2 1 4 9 7]
 [8 4 6 3 2 5 0 1 7 9]
 [4 9 6 8 3 7 1 5 0 2]
 [7 9 6 1 8 3 5 4 2 0]]
vm  [-0.2  1.5  8.1  9.  -1.5 -0.3 -0.1 -0.5 -1.3 -0.4  2.7 -0.4 -0.  -0.2  5.   4.3  0.4  1.3 -0.  -1.  -0.5 -0.8  2.6  0.3 -1.1  0.3 -0.3 -0.1 -0.4  0.4 -1.9  0.7 -0.1  1.6  0.5  1.2  2.8  4.6  6.1 -0.1  0.1 -0.9 -0.7  0.5 -0.9 -0.7  3.5 -0.7  0.3  6.1 -0.5 -0.4 -0.1  5.3 -0.7 -0.4 -0.5  0.1 -0.5  5.9 -0.1  0.7 -0.1 -0.1 -0.8 -0.8 -0.2 -0.3 -0.6 -0.8  0.   0.4  1.1 -0.4 -1.3  0.4  0.4 -0.1 -0.2 -0.3 -1.3  0.4 -0.4 -0.5 -1.  -1.  -0.1 -0.1  1.5 -0.6  1.2 -0.2 -0.3  2.5 -0.4 -0.4 -0.2 -0.7 -0.5 -0.7  1.3  5.1 -0.1 -0.6 -0.  -0.3 -1.  -1.7  0.7 -1.   1.3 -0.2 -0.2 -0.  -0.3 -0.2 -0.2 -0.6  0.7 -0.3 -0.2  3.1 -0.6 -0.7 -0.4  5.6 -0.1 -0.8 -0.8 -0.2 -0.1  1.3 -0.5  1.4 -3.1 -3.4  0.1 -0.1  0.3 -0.2 -1.  -1.4 -1.1 -0.4  0.9 -0.6 -0.3 -0.2 -2.1 -0.2 -1.3 -0.   3.9 -0.8 -0.2 -0.2 -0.7 -0.1  1.5 -0.5 -0.4 -0.7 -0.3 -0.1 -0.2 -0.1 -0.3  0.  -0.4  2.6 -0.2 -0.7 -0.2  0.7 -0.5  7.4 -0.2  0.3 -1.  -0.8  3.  -0.1  1.  -0.4 -0.6 -0.   2.1 -0.7 -0.6  0.2 -0.5 -0.3 -0.3 -0.9  3.5  1.1 -0.3  1.6 -0.5 -0.2  0.6 -0.7 -0.3 -0.  -0.7  0.5 -1.4 -0.3  8.6 -0.  -0.6 -0.1 -0.1  0.2 -0.5 -0.3  1.9 -0.4 -0.3 -0.5 -0.8 -0.4 -0.  -0.5 -0.3  1.6  1.2  3.1  0.4 -0.3 -0.7 -0.  -0.5  6.5 -0.4 -2.   0.9 -0.2 -0.6 11.5 -0.8  7.3 -0.5  0.4  4.8 -1.4 -0.2 -0.2 -0.1 -0.   2.2  1.   5.9  0.9 -0.8  3.8]
vy_50sample [[2 8 8 9 0 3 1 6 4 5]
 [0 1 6 3 5 7 9 4 2 8]
 [7 1 1 9 4 8 0 6 5 3]
 [1 7 2 6 5 8 3 9 9 4]
 [4 6 7 9 5 3 2 0 1 8]
 [4 3 0 2 5 7 1 6 9 8]
 [7 4 9 5 0 2 3 8 1 6]
 [8 4 4 3 0 0 5 5 1 9]
 [3 7 9 2 6 1 8 8 4 4]
 [3 2 4 7 1 6 9 0 8 5]]
vt_50sample [[2 7 8 9 0 3 1 6 4 5]
 [0 1 3 6 5 7 9 4 2 8]
 [7 1 2 9 4 0 8 6 5 3]
 [1 7 2 6 5 8 3 9 0 4]
 [4 6 7 9 5 3 2 0 1 8]
 [4 3 0 2 5 7 1 6 9 8]
 [7 4 9 5 0 3 2 8 1 6]
 [8 4 3 7 6 0 2 5 1 9]
 [3 7 9 2 6 1 8 5 0 4]
 [3 2 4 1 7 6 9 0 8 5]]
Epoch  9210: Training cost= 0.3777, Training acc= 0.7628, Validation cost= 0.3921, Validation acc= 0.7632
Epoch  9220: Training cost= 0.3615, Training acc= 0.7629, Validation cost= 0.4253, Validation acc= 0.7633
Epoch  9230: Training cost= 0.3556, Training acc= 0.7629, Validation cost= 0.4052, Validation acc= 0.7634
Epoch  9240: Training cost= 0.3364, Training acc= 0.7630, Validation cost= 0.4577, Validation acc= 0.7635
Epoch  9250: Training cost= 0.4741, Training acc= 0.7631, Validation cost= 0.3833, Validation acc= 0.7635
Epoch  9260: Training cost= 0.4004, Training acc= 0.7632, Validation cost= 0.3541, Validation acc= 0.7636
Epoch  9270: Training cost= 0.3440, Training acc= 0.7633, Validation cost= 0.4743, Validation acc= 0.7637
Epoch  9280: Training cost= 0.4247, Training acc= 0.7634, Validation cost= 0.4241, Validation acc= 0.7638
Epoch  9290: Training cost= 0.3957, Training acc= 0.7634, Validation cost= 0.3964, Validation acc= 0.7639
Epoch  9300: Training cost= 0.3882, Training acc= 0.7635, Validation cost= 0.3666, Validation acc= 0.7639
tm  [-0.1  2.5  4.3  7.2 -1.3 -0.4 -0.3 -0.6 -0.7 -0.9  3.9 -0.6 -0.3 -0.   0.6  5.   1.6 -0.3  0.1 -0.2 -0.1 -0.5  2.7  0.8 -1.8  1.3  0.2  0.  -0.2 -0.2 -1.1 -0.8 -0.3 -0.7 -0.3  0.4  2.3  3.4 -0.1 -0.7 -0.2  5.1  2.9 -1.  -0.3 -0.  -0.4 -0.8  1.8  4.4 -0.7 -0.3  1.5  5.5 -0.7  0.9 -0.   6.3 -0.7  5.1 -0.2 -0.5  0.2  2.  -0.1  0.6 -0.  -0.6 -0.3 -0.  -0.3  0.2  0.6 -0.1 -0.8 -0.  -0.3 -0.1 -0.3  0.1 -0.3 -0.3 -0.2 -0.4 -0.9  6.3 -0.2 -0.2  0.5  0.4 -0.3 -0.  -0.3  1.7 -0.1 -0.   3.5 -0.7 -0.3 -0.1  2.4  2.5 -0.4 -0.4  0.3  1.1 -0.9 -1.1  1.9 -0.6 -0.4  0.4 -0.1  1.  -0.8  2.3 -0.2 -0.9 -0.1 -0.2 -0.   1.6  0.  -0.2 -0.   0.2  0.3 -1.1  0.9 -0.2  3.  -0.4 -0.3 -0.1  3.9  0.9 -0.3 -0.5  0.3 -0.2 -0.7 -0.7 -0.5 -0.1  0.2  0.4 -0.2 -0.2  4.1  1.1 -0.8 -0.4  3.1 -0.6 -0.5 -0.1 -0.5  1.1 -0.2 -0.7  1.3  1.8 -0.5 -0.  -0.7 -0.6 -0.1 -0.9 -0.1  2.   0.3  1.5 -0.6 -0.5 -0.4 -0.8 -0.8  0.9  2.5 -0.6 -1.2 -0.  -0.3 -1.2 -0.1 -0.3  1.9 -0.3 -0.2  2.9 -0.1 -0.5 -0.3 -0.9  2.7  0.1 -0.   0.1 -0.  -0.1 -0.4 -0.4 -0.4 -0.5 -0.1 -0.7  0.9  1.4 -0.7 -0.1 -0.7  1.6 -0.   0.5 -0.8 -0.6  4.4 -0.2  0.5 -0.2 -0.5  0.1 -0.4 -0.4  2.5  2.4  1.9  2.9 -0.1  1.8 -0.5 -0.6 -0.3 -0.3  0.9 -0.7  0.1  0.5 -0.2 -1.3 -0.5 -0.8  1.1 -0.2  2.6 -0.8  0.   2.2 -0.3 -0.4  0.  -0.1 -0.1  1.4  0.5  3.1]
ty_50sample [[5 2 8 6 9 9 0 3 3 4]
 [8 7 1 3 9 0 5 4 6 2]
 [1 0 5 7 6 9 4 3 8 2]
 [4 5 0 2 6 1 8 9 3 7]
 [5 3 2 1 7 6 4 8 8 0]
 [4 0 2 2 1 5 7 8 3 3]
 [7 7 1 9 4 6 8 2 5 0]
 [1 0 9 5 8 4 2 6 7 3]
 [7 6 3 2 8 1 0 4 5 9]
 [2 3 8 6 4 9 7 1 0 5]]
tt_50sample [[5 2 8 6 9 7 0 3 1 4]
 [8 7 1 3 9 0 5 4 6 2]
 [1 0 5 7 6 9 4 3 8 2]
 [4 5 2 0 6 1 8 9 3 7]
 [5 3 2 1 7 6 4 0 9 8]
 [4 0 2 6 1 5 7 8 3 9]
 [7 3 1 9 4 6 8 2 5 0]
 [1 0 9 5 8 4 2 6 7 3]
 [7 6 3 2 8 1 0 4 9 5]
 [2 3 8 6 4 9 7 1 0 5]]
vm  [ 0.9  1.1 -0.7  9.  -0.5 -1.  -0.2 -0.8 -0.6 -0.8 -1.6 -0.4 -0.1 -0.5 -2.8  5.4  0.2 -0.3 -0.3 -2.  -0.1 -0.4  2.1 -0.  -0.9 -0.5 -0.2 -0.1  3.6  0.2 -1.1 -0.8  1.3 -4.3 -0.5 -0.2  1.3  1.   3.4 -0.8  0.3 -1.3 -0.5 -0.4 -0.  -0.6  8.9 -0.3  1.7  4.4 -0.2 -0.4 -0.  -0.7 -1.4  6.5 -0.2 -0.3 -0.3  3.9 -2.2 -0.3 -0.7 -0.2 -0.8 -0.5 -0.4  0.9 -0.2 -0.  -0.2 -1.1  0.3 -0.4  3.   0.2 -0.6 -0.2 -0.2 -0.5 -0.1 -0.1 -1.2 -0.2 -1.3 -1.   1.1 -0.2  2.8 -0.4  0.9  1.6  0.7  1.2  0.9 -0.4  0.4  0.7 -0.2 -0.4  2.1 -1.7 -0.9 -0.  -0.5 -0.6  1.5 -1.5 -0.8 -2.2 -0.  -0.5 -0.3  0.1 -1.   5.8 -0.2 -0.3 -0.1  1.  -0.4  7.  -0.1 -1.4 -0.4 -2.9  0.6  5.3 -0.2 -0.2  4.9  0.2  1.2 -0.3 10.  -1.   0.3 -0.5 -0.2  0.  -0.2 -0.9 -0.3 -0.2 -0.4  0.7 -0.4 -0.3  2.7  0.9 -1.   0.6  5.2 -0.9 -0.4 -0.  -0.5 -0.5 -1.3 -0.6 -0.1  1.  -0.9 -0.5 -1.5 -0.2  2.5  1.4 -0.2  3.3 -0.6 -0.7 -0.8 -0.1 -0.1 -0.3 -1.3  1.4 -0.2 -0.5 -0.1 -0.1 -0.1 -0.6 -0.8  1.6  6.3  0.3 -1.1  1.9 -0.4 -0.6 -1.6 -1.   9.9 -0.1  2.5  0.2 -0.4 -0.7 -0.3  0.1 -0.1 -0.5 -1.2  2.8 -0.9 -0.2  7.4 -0.2 -0.1  4.7 -1.3 -0.4 -0.4 -0.6  2.5 -0.1 -0.2 -0.5 -0.6 -0.6 -0.5 -0.8  0.6  4.  -0.3  0.6 -0.8  4.9 -0.5 -0.3 -0.4  4.9 -1.2  4.2  0.3  2.4 -0.2 12.4 -0.2  6.4  0.1  1.   1.7 -2.7  0.6 -0.6 -0.5 -0.2 -0.2 -0.4  2.7 -0.2  0.8  3.7]
vy_50sample [[8 9 6 3 2 4 5 5 1 0]
 [4 3 6 2 7 0 1 5 9 8]
 [8 3 4 1 9 2 0 6 5 7]
 [6 4 8 3 3 9 2 0 5 7]
 [6 4 8 2 9 5 1 0 3 7]
 [7 3 8 9 2 2 0 1 4 5]
 [1 2 7 4 3 8 0 5 6 9]
 [5 4 1 7 3 6 8 9 0 2]
 [6 2 0 5 7 4 9 3 8 1]
 [2 1 0 3 7 8 8 5 6 4]]
vt_50sample [[8 9 6 3 2 4 5 1 0 7]
 [4 3 6 2 7 0 1 5 9 8]
 [8 3 4 1 9 2 0 6 5 7]
 [6 4 8 3 1 9 2 0 5 7]
 [6 4 9 8 2 5 1 0 3 7]
 [3 7 8 9 2 0 6 1 4 5]
 [1 2 7 4 3 8 0 5 6 9]
 [5 4 1 7 3 6 8 9 0 2]
 [6 2 0 5 7 4 9 3 1 8]
 [2 1 0 3 7 9 8 5 6 4]]
Epoch  9310: Training cost= 0.4058, Training acc= 0.7636, Validation cost= 0.4239, Validation acc= 0.7640
Epoch  9320: Training cost= 0.3792, Training acc= 0.7637, Validation cost= 0.4388, Validation acc= 0.7641
Epoch  9330: Training cost= 0.3854, Training acc= 0.7638, Validation cost= 0.3727, Validation acc= 0.7642
Epoch  9340: Training cost= 0.3971, Training acc= 0.7639, Validation cost= 0.3787, Validation acc= 0.7643
Epoch  9350: Training cost= 0.3689, Training acc= 0.7639, Validation cost= 0.3790, Validation acc= 0.7643
Epoch  9360: Training cost= 0.4490, Training acc= 0.7640, Validation cost= 0.4646, Validation acc= 0.7644
Epoch  9370: Training cost= 0.4875, Training acc= 0.7641, Validation cost= 0.5012, Validation acc= 0.7645
Epoch  9380: Training cost= 0.4091, Training acc= 0.7642, Validation cost= 0.3529, Validation acc= 0.7646
Epoch  9390: Training cost= 0.3603, Training acc= 0.7643, Validation cost= 0.3523, Validation acc= 0.7646
Epoch  9400: Training cost= 0.3949, Training acc= 0.7643, Validation cost= 0.3538, Validation acc= 0.7647
tm  [ 1.9 -0.5  2.6 -1.4 -1.8 -0.9 -0.2 -0.5 -0.3 -0.4  6.1 -0.2 -0.4 -0.2  8.2  3.9  0.3 -0.6 -0.4 -0.5 -0.2  0.7 -0.3 -0.  -1.1 -0.5  0.4 -0.   1.2  0.2  5.9 -0.8 -0.2 11.2 -0.   0.6  0.2  1.6 -0.1 -0.9  0.7  4.4  2.4  3.3 -0.3 -0.5 -0.1  0.1  2.2 -0.9 -1.2 -0.5 -1.1  2.6 -1.4 -1.  -0.4  2.  -0.2 -1.7 -0.6 -0.9 -0.3  1.1  1.9 -0.8 -0.3  0.8 -0.1 -0.3  0.2 -0.9 -0.4 -0.2 -3.1 -0.2 -0.6 -0.1 -0.1 -0.6  7.6 -0.4 -0.8  0.3 -1.2  4.9  2.9 -0.3  1.4 -0.3 -0.7 -0.  -0.4 -0.1 -0.8 -0.3 -0.1 -1.1 -0.1 -0.2  0.9  5.8 -0.9  0.1 -0.5 -0.5 -2.   5.9  3.  -0.6  1.4 -0.7 -0.2 -1.2 -0.1  5.1 -0.2  1.7 -0.1 -0.5 -0.3  1.9 -0.3 -0.1 -0.7  9.3 -0.1 -0.1  2.9  1.9  2.6 -0.7  0.1 -0.  -2.5  7.6 -0.3 -0.4 -0.9 -0.8 -0.4  2.2  0.3 -0.1 -0.5  0.5 -0.2 -1.2  0.9  0.4  2.3 -0.3  0.9 -0.3 -0.4 -0.3 -0.4 -0.6 -0.5 -0.5 -0.3 -0.5 -0.1 -0.6  2.8 -0.3 -0.4 -0.2 -0.1 -0.4 -0.3  2.4 -0.5 -0.3 -0.2  0.4 -1.1 -1.2  2.7 -0.3 -1.9  0.1 -0.3 -1.1 -0.7 -0.4  3.2 -1.1 -0.6 -0.2 -0.4 -0.4 -0.5 -0.9  4.7 -0.3 -1.3 -0.  -0.4 -0.5 -0.2 -0.2 -0.2 -0.4 -1.  -1.9  1.1  0.1 -3.5 -0.4 -0.6  2.7 -0.2 -0.2  0.2  0.4 -0.6 -0.3  1.2 -0.5 -0.3 -0.1  0.1 -0.3  0.5  1.4 -0.2 -0.6 -0.5  5.1 -1.1  1.3 -0.3 -2.6 -0.6 -0.1  0.5 -1.6  0.4 -2.5 -0.  -1.3 -0.4 -0.3 -1.2  1.4 -0.5 -0.7 -0.2  1.5 -1.7  1.2  0.3 -0.6  2.3  0.9]
ty_50sample [[5 7 4 2 6 3 9 0 8 8]
 [9 9 6 8 8 7 4 3 5 2]
 [7 3 4 1 9 0 5 6 8 2]
 [1 3 2 5 7 7 0 8 9 4]
 [0 4 5 5 7 1 6 2 8 3]
 [5 8 9 9 1 2 3 0 6 7]
 [1 6 5 2 7 3 8 4 9 0]
 [9 7 2 8 0 3 5 6 4 4]
 [6 3 3 5 1 8 9 2 4 7]
 [4 7 9 6 0 2 1 3 8 5]]
tt_50sample [[5 7 4 2 6 3 9 8 0 1]
 [9 6 1 0 8 7 4 5 3 2]
 [7 3 4 1 9 0 5 6 8 2]
 [1 3 2 5 6 7 0 8 9 4]
 [0 4 5 9 7 1 6 2 8 3]
 [5 8 9 4 1 2 3 0 6 7]
 [1 6 5 2 7 3 8 4 9 0]
 [9 7 2 8 3 0 5 6 4 1]
 [6 0 3 5 1 8 9 2 4 7]
 [4 7 9 6 0 2 1 3 8 5]]
vm  [ 0.9 -0.2  5.4  5.2 -1.1 -0.8 -0.5 -0.6 -0.3  1.9 -2.5 -0.  -1.  -0.5  3.2 -1.  -0.4 -0.2 -0.2 -0.  -0.4 -0.6  5.   0.6 -0.7 -0.2 -0.5 -0.5 -1.  -0.8 -2.2  0.9  0.7 -2.6  1.5 -0.7  1.2 -0.6 -2.2 -0.6 -0.1  4.5 -0.2 -1.4 -0.5 -0.4 -0.8 -0.2  1.1  9.3 -0.5 -0.5 -1.7  2.9  1.1 -0.1 -0.4  4.4  1.   7.3  1.9 -0.8 -0.6  2.6 -0.5 -0.3 -0.2 -0.3  2.  -0.6 -0.5  2.8 -0.1 -0.5 -3.9  0.3 -0.4  0.1 -0.2 -0.4 -3.4  0.  -0.3  0.7 -1.   5.2 -0.3 -0.1 -0.3 -0.2 -0.4 -0.2 -1.1 -0.1 -1.  -0.3  1.9 -1.5  0.6 -0.4 -0.7  3.9 -0.2 -0.4 -0.2 -0.3 -2.4 -2.1 -1.1 -0.2  0.7 -0.2 -0.1 -0.4  3.3 -1.4 -0.2  1.6 -0.1  2.  -0.3 -0.  -0.2 -1.3 -0.3  3.6 -0.5  0.4  0.8  0.3  3.1 -0.7 -0.6 -0.2  6.6 -0.1 -0.3 -0.9 -0.7 -0.2 -0.2 -0.8  0.2 -0.3 -0.6 -0.4 -0.7 -0.6  2.4 -0.3 -0.7 -0.4  4.7 -0.4 -0.4 -0.1  1.1 -0.1 -1.2 -0.7  0.4  1.4  0.2 -0.3 -1.2 -0.1 -1.1 -0.4 -0.7  0.9  0.1  1.6 -0.3  0.1 -0.3 -0.5 -1.5 -1.1  8.4  0.1 -0.8 -0.5  0.1 -0.9  2.  -0.1  0.8 -0.2 -0.4  4.1 -0.2 -0.9 -0.5 -1.   0.9 -0.8 -1.7 -0.5 -0.2 -0.1 -0.6 -0.1  0.7 -0.5 -0.6 -2.3 -0.1 -0.5  3.4 -0.2 -0.2 -0.9 -0.7 -0.2 -0.9 -0.   6.3 -0.1 -0.1 -0.3 -0.8 -0.4 -0.4 -1.2  3.6  0.  -1.2  1.  -0.4  1.6 -0.   2.  -0.5  2.4  1.2 -1.   3.  -1.8  1.1 -2.  -0.5 -1.1 -0.1 -0.1 10.4  1.4  1.1 -0.4 -0.4  0.9  7.6 -0.8 -1.7 -0.1  1.9  2.2]
vy_50sample [[8 0 6 5 7 7 1 3 3 4]
 [0 3 6 2 2 5 7 7 1 8]
 [3 4 8 2 0 1 6 5 7 9]
 [3 8 6 9 7 4 1 1 5 2]
 [1 4 8 6 2 2 5 0 7 9]
 [0 1 3 6 8 7 7 2 9 9]
 [0 3 9 9 7 6 6 4 5 5]
 [5 9 3 8 6 2 0 4 1 7]
 [4 0 2 9 3 7 8 6 5 1]
 [9 5 1 3 6 7 2 0 8 4]]
vt_50sample [[8 0 6 5 7 2 1 9 3 4]
 [0 3 6 2 9 5 4 7 1 8]
 [3 4 8 2 0 1 6 5 7 9]
 [3 6 8 9 7 4 0 1 5 2]
 [1 4 8 6 2 3 5 0 9 7]
 [0 1 3 6 8 7 2 5 4 9]
 [0 3 1 9 7 6 8 4 2 5]
 [5 9 3 8 6 2 0 4 1 7]
 [4 0 2 9 3 7 8 6 5 1]
 [9 5 1 3 6 7 2 0 8 4]]
Epoch  9410: Training cost= 0.3858, Training acc= 0.7644, Validation cost= 0.3677, Validation acc= 0.7648
Epoch  9420: Training cost= 0.3686, Training acc= 0.7645, Validation cost= 0.3591, Validation acc= 0.7649
Epoch  9430: Training cost= 0.5079, Training acc= 0.7646, Validation cost= 0.4047, Validation acc= 0.7650
Epoch  9440: Training cost= 0.3619, Training acc= 0.7647, Validation cost= 0.4658, Validation acc= 0.7651
Epoch  9450: Training cost= 0.4136, Training acc= 0.7647, Validation cost= 0.4043, Validation acc= 0.7651
Epoch  9460: Training cost= 0.4058, Training acc= 0.7648, Validation cost= 0.3016, Validation acc= 0.7652
Epoch  9470: Training cost= 0.4017, Training acc= 0.7649, Validation cost= 0.3500, Validation acc= 0.7653
Epoch  9480: Training cost= 0.3992, Training acc= 0.7650, Validation cost= 0.3931, Validation acc= 0.7654
Epoch  9490: Training cost= 0.3458, Training acc= 0.7651, Validation cost= 0.4113, Validation acc= 0.7655
Epoch  9500: Training cost= 0.3819, Training acc= 0.7651, Validation cost= 0.3733, Validation acc= 0.7655
tm  [ 2.8  0.9  0.4  8.  -1.2 -0.8 -0.3 -0.6 -1.1 -0.3 -0.4 -0.3 -0.8 -0.4 -1.4 -0.3 -0.2 -0.6 -0.1 -1.9 -0.4  0.   3.1  1.4 -1.3  2.  -0.   0.4 -0.6  0.7  1.1  0.2 -0.6  1.  -0.2  1.1  3.1 -0.4  5.2 -0.8 -0.2  6.1  3.1 -0.1  0.8  0.4  5.1  1.4  4.1  5.5 -0.7 -0.3  3.1 -1.7  0.   4.  -0.1  2.2 -1.   1.5 -2.3 -0.4 -0.2  1.6 -0.4  1.5 -0.  -0.9  1.1  2.2 -0.5  0.9 -0.  -0.4  8.2  0.4 -0.4  0.2  0.6  0.5  9.8 -0.1 -0.8 -0.1 -1.1  7.1  1.7 -0.4 -0.2  0.4  0.4 -0.1 -0.7 -0.2  1.6  0.1  2.5  0.7  0.2  0.4  0.7  3.7 -1.  -0.2  0.4  0.4  4.1  0.4 -0.3 -2.1 -1.   0.7 -0.4  0.7 -0.4 -0.2 -0.5 -0.8 -0.4 -0.6 -0.3  7.8  0.1 -0.4 -0.  -1.6 -0.   8.3  0.8 -2.   4.5 -0.6 -0.4 -0.6  3.8  4.4 -0.2 -0.8 -0.3 -0.2  1.6 -0.6  1.4  1.5 -0.6  1.   1.2 -0.7  3.7  1.7 -0.6 -0.3  3.7 -0.3 -0.1 -0.1 -0.3 -0.2 -0.8 -0.5  1.7  2.5 -0.5 -0.4 -0.5 -0.7 -0.4 -0.7  0.7  2.5  1.1  0.7 -0.2 -0.5  0.1 -0.6 -0.5  3.5 -0.6 -0.1 -1.6 -0.3 -0.5 -1.2 -0.3 -0.5  4.8 -0.   1.4  0.2  0.  -0.4 -0.9 -0.8  9.1  0.4  4.7  1.1  0.4 -0.2 -0.7  0.2 -0.3 -0.5 -0.1  4.2  1.2  1.6 -0.8  0.5 -0.3  2.  -0.9 -0.3 -0.7 -1.   2.4 -0.1  0.6 -0.1 -1.  -0.1 -0.  -0.4  3.7  0.7 -0.5 -0.1  0.3  3.2 -0.3 -1.5 -0.3 -0.6  3.4  1.5  1.6  8.1  2.6  5.3 -0.3  1.9  0.3  0.1 -1.4 -2.3 -0.2  2.  -0.8 -0.6 -2.  -0.5  4.2  0.1  2.4  9.7]
ty_50sample [[9 5 6 0 8 4 7 2 1 3]
 [7 6 9 1 8 5 0 4 3 3]
 [4 7 2 1 8 8 9 3 5 6]
 [6 0 8 4 9 3 7 2 5 1]
 [9 4 2 6 7 0 8 8 1 5]
 [7 3 8 0 4 1 5 9 2 6]
 [8 6 0 3 9 7 2 4 5 5]
 [6 5 4 0 9 2 3 1 7 7]
 [6 4 1 5 7 0 3 8 2 9]
 [2 3 6 6 5 0 9 9 1 4]]
tt_50sample [[9 5 6 0 8 4 7 2 3 1]
 [7 6 1 9 8 5 4 0 3 2]
 [4 7 2 1 8 0 9 3 5 6]
 [6 0 8 4 9 3 7 2 5 1]
 [9 4 6 2 7 3 0 8 1 5]
 [7 3 8 0 4 1 5 9 2 6]
 [8 6 0 3 9 7 2 4 5 1]
 [6 5 4 9 0 2 3 1 8 7]
 [6 4 1 5 7 0 3 8 2 9]
 [2 3 6 5 7 0 9 8 1 4]]
vm  [ 0.7  0.7  2.4  8.1 -1.1 -0.8 -0.4 -0.7 -0.4 -0.9  6.9 -0.7  1.2 -0.4 -0.9  5.1 -0.4 -0.1  1.1 -1.5 -0.7 -0.1 -0.4 -0.3 -0.8  0.9 -0.2 -0.   0.4  0.9  2.5 -0.4 -0.2  5.8  0.5  0.7  1.6  1.3  4.7 -0.9 -0.3 -1.5 -0.8 -0.2 -0.7 -0.1  6.  -0.8  3.1 -0.6 -1.2 -0.4  2.9 -0.  -1.   3.1 -0.1 -0.7 -0.  -0.4 -2.1  2.1 -0.5  2.9  0.1  0.7 -0.2 -0.2  0.5  2.1 -0.5 -0.5 -0.1 -0.3  7.4 -0.1 -0.9 -0.4  0.9  1.5 13.7 -0.4 -0.7 -0.2 -1.1 -1.6  0.9 -0.3  0.3 -0.1  0.6 -0.1  0.5 -0.7  2.1 -0.1 -0.4 -0.1 -0.5 -0.1  2.2  2.2 -0.8  0.1  0.4  0.7  4.5  2.1  3.2 -2.3 -1.2  0.3 -0.2  0.9 -0.4  2.6 -0.2 -0.3 -0.4 -0.5 -0.   9.1  0.9  0.1 -0.  -1.2 -0.4  2.7 -0.3 -0.9  4.6 -0.9  0.2 -0.7  2.7  8.6 -0.3  0.  -0.  -0.3 -0.7 -0.6 -0.5  0.9 -0.6 -0.  -0.3 -0.3 -1.5  0.2 -0.6 -0.2  1.9 -1.3  0.4 -0.3 -0.2 -0.4 -0.8 -0.4  0.7  2.1 -0.3 -0.4 -0.3 -0.7  2.6  2.  -0.   2.8 -0.9 -1.4 -0.1 -0.3 -0.2  5.4 -0.6  4.3 -0.3 -0.5  2.5  0.9 -0.6 -0.8 -0.7 -0.4  5.7 -0.5 -0.2  0.6 -0.2 -0.2 -1.3 -0.7  8.9  0.   5.4 -0.3  0.  -0.1 -0.3 -0.3 -0.7 -0.5 -0.3  3.3 -0.3  1.8  4.6 -0.4 -0.3  3.5 -1.6 -0.2 -0.4 -1.   3.3 -0.5  1.  -0.2 -0.5 -0.5 -0.2 -0.6  1.8  0.4  1.4  2.5  0.8  4.3 -0.2 -1.4 -0.3  3.6  0.5 -0.2  0.3  7.6  2.4 18.4 -0.5 10.2  0.4 -0.2 -2.4 -2.3 -0.1  1.7 -1.  -0.9 -2.8 -0.1  4.   1.6 -0.3  5.3]
vy_50sample [[9 2 6 7 3 4 0 8 1 5]
 [8 0 1 7 6 9 5 4 3 2]
 [0 3 9 6 4 2 8 5 7 1]
 [1 5 9 7 3 4 0 8 2 6]
 [2 6 4 9 1 1 0 3 5 7]
 [8 4 5 7 2 9 0 6 3 1]
 [2 5 7 6 4 8 1 1 3 0]
 [2 7 6 8 9 1 4 0 5 3]
 [9 6 4 3 7 2 0 5 8 1]
 [9 9 8 8 2 7 1 5 0 6]]
vt_50sample [[9 2 6 7 3 4 0 8 1 5]
 [8 0 1 7 6 9 5 4 3 2]
 [0 3 9 6 4 2 8 5 7 1]
 [1 5 9 7 3 4 0 8 2 6]
 [2 6 4 9 8 1 0 3 5 7]
 [8 4 5 2 7 9 0 6 3 1]
 [2 5 6 4 7 8 1 9 3 0]
 [2 7 6 8 9 1 4 0 5 3]
 [9 6 4 3 7 2 0 5 8 1]
 [9 4 8 3 2 7 1 5 0 6]]
Epoch  9510: Training cost= 0.3852, Training acc= 0.7652, Validation cost= 0.4710, Validation acc= 0.7656
Epoch  9520: Training cost= 0.3615, Training acc= 0.7653, Validation cost= 0.4129, Validation acc= 0.7657
Epoch  9530: Training cost= 0.4353, Training acc= 0.7654, Validation cost= 0.4058, Validation acc= 0.7658
Epoch  9540: Training cost= 0.3977, Training acc= 0.7654, Validation cost= 0.3619, Validation acc= 0.7659
Epoch  9550: Training cost= 0.3505, Training acc= 0.7655, Validation cost= 0.3821, Validation acc= 0.7659
Epoch  9560: Training cost= 0.2921, Training acc= 0.7656, Validation cost= 0.3493, Validation acc= 0.7660
Epoch  9570: Training cost= 0.4219, Training acc= 0.7657, Validation cost= 0.3689, Validation acc= 0.7661
Epoch  9580: Training cost= 0.3866, Training acc= 0.7658, Validation cost= 0.4511, Validation acc= 0.7662
Epoch  9590: Training cost= 0.4481, Training acc= 0.7658, Validation cost= 0.3812, Validation acc= 0.7662
Epoch  9600: Training cost= 0.4696, Training acc= 0.7659, Validation cost= 0.4326, Validation acc= 0.7663
tm  [ 0.6  1.4 -0.7 -0.1 -1.1 -0.7 -0.4 -0.5 -1.5 -0.9 -1.9  1.3 -1.2 -0.6 -0.5 -0.1  0.8 -0.4 -0.4 -2.  -0.3  0.1  1.2  1.7 -1.4 -0.3 -0.3 -0.3 -0.   3.5  4.1 -0.5  0.7  2.4 -1.1  1.5  4.2 -1.  -0.1 -0.7 -0.2  2.3  3.1  0.3 -0.4 -0.1  6.3  1.8  0.9  1.7 -0.5 -0.2 -0.  -2.5 -1.4  1.6 -0.4 -0.1 -1.6 -0.9 -1.4 -0.1 -0.7 -1.2 -0.  -0.2 -0.3 -0.1  0.5  1.  -0.5 -1.  -0.1 -0.6  2.9 -0.3 -0.1  0.1  2.  -0.   7.2 -0.3 -1.3 -0.  -0.6  3.6  3.9 -0.1  2.4 -0.4 -0.7  2.8  0.   2.2 -0.1 -0.1 -0.1  1.3 -0.5 -0.3  2.3  2.3 -0.7 -0.4 -0.  -0.1 -0.1  4.8 -0.9 -2.2 -0.4 -0.7 -0.1  0.6 -0.9  5.4  0.5 -0.9 -0.5 -0.6 -0.7  6.4 -0.1 -0.5 -0.4 -0.6  3.8 10.9 -0.6 -0.8  3.5 -0.3  1.4 -0.1  5.1  8.8 -0.2 -0.5 -0.4 -1.3  3.2 -0.5  3.1 -0.  -0.6 -0.3 -0.1 -1.1  2.   2.1 -0.2  0.2  2.3 -0.1 -0.4 -0.4 -0.5 -0.2 -1.4 -1.3 -0.5  3.  -0.4 -0.1 -0.2  0.8 -0.1 -0.2  1.2 -0.  -0.1 -0.1 -0.9 -0.1 -0.1 -0.  -1.4  0.5  1.9 -0.2 -1.2  0.2  1.1 -1.2 -1.1 -0.2  4.  -0.1 -0.3 -1.  -0.2 -0.7 -0.7 -1.6  6.9  2.9  1.3  3.  -0.3 -0.9 -0.4 -0.3 -0.1 -0.3 -0.3  0.8  0.3 -0.3 -0.8  0.2 -0.8  2.8 -0.5  1.3  1.7 -0.4  0.8 -0.1  1.3 -0.3 -1.2 -0.2 -0.1 -0.5  2.7  3.5 -1.4 -1.   0.3  1.7 -0.1 -0.3 -0.3 -0.6 -0.6  2.9 -0.3  2.5  0.6  3.1 -0.2  1.2 -0.5 -0.5 -1.  -1.4 -0.2 -0.3 -0.   0.1 -1.5 -0.1  0.3 -0.6  3.6  4.5]
ty_50sample [[6 4 9 5 7 7 3 1 0 2]
 [2 3 3 4 7 1 6 6 5 0]
 [8 1 2 3 6 4 7 5 0 0]
 [9 7 7 0 5 3 6 4 2 8]
 [0 2 5 3 1 8 9 4 7 6]
 [2 8 3 5 1 7 7 0 6 9]
 [3 6 9 2 5 4 1 8 0 7]
 [9 2 5 4 0 3 1 7 6 8]
 [1 6 6 9 5 2 0 7 3 8]
 [2 1 4 8 3 9 5 6 7 0]]
tt_50sample [[4 6 9 5 7 3 8 1 0 2]
 [2 9 3 4 7 1 8 6 5 0]
 [8 1 2 3 6 4 7 5 9 0]
 [1 9 7 0 5 3 6 4 2 8]
 [0 2 5 3 1 9 8 7 4 6]
 [2 8 3 5 1 7 4 0 6 9]
 [3 6 9 2 5 4 1 8 0 7]
 [9 2 5 4 0 3 1 7 8 6]
 [1 6 4 5 9 2 0 7 3 8]
 [2 1 4 8 3 9 5 6 7 0]]
vm  [ 1.9  0.1  5.9 -0.6 -1.8 -1.1 -0.7 -0.5 -1.3  0.9 -3.4 -0.  -1.5 -0.3 10.1 -0.8 -0.  -0.1 -0.5 -0.6 -0.1 -0.2  4.5  1.3 -1.  -0.7 -0.5 -0.2 -0.5  0.4 -1.  -0.  -0.2  1.8  0.8 -0.3  1.8 -0.7 -0.9 -1.2 -0.4  5.   2.2  0.9 -0.4 -0.1 -0.8  0.8  3.8  8.9 -0.6 -0.6 -1.7 -0.2 -0.6 -1.3 -0.5  2.3 -0.4  4.4 -0.3 -0.6 -1.1  0.1 -0.5 -0.7 -0.2 -0.6  1.2 -0.4 -0.3  0.7  0.7 -0.2 -3.5  0.1 -0.5  0.1  0.3 -0.2 -3.2  0.2 -0.5 -0.3 -1.3  5.7  2.5 -0.3  1.  -0.3 -0.4  0.1 -1.   0.2 -0.9  0.   0.  -1.2  0.  -0.3 -0.2  7.7 -0.6 -0.2 -0.1 -0.4 -2.  -0.8 -1.7 -0.4  1.5 -0.4 -0.4 -0.6  0.2  0.2 -0.3  0.6 -0.2 -0.4 -0.6  0.8 -0.1 -1.3 -0.4 10.3  0.2  2.3  0.8  0.5  3.1 -0.3  0.3 -0.2 -2.  -1.9 -0.4 -1.  -1.  -0.4  2.4 -0.6  2.5  0.3 -0.7 -0.3 -0.5 -1.5 -0.4  1.   2.2 -0.2  5.9 -0.2 -0.2 -0.1 -0.3 -0.3 -0.6 -1.2 -0.1 -0.1 -0.2 -0.2 -0.3  1.  -0.8 -0.3  0.3 -0.2  1.1  1.5 -0.6  0.3 -0.3  2.4 -0.8 -1.3  4.7  0.5 -1.5 -0.4 -0.2 -0.8  0.3 -0.2  2.4 -0.5 -0.7 -0.2 -0.  -0.3 -0.1 -1.   3.7 -0.2 -1.5  0.3 -0.  -0.4 -0.5 -0.2  0.3 -0.2 -0.8 -2.4 -0.2 -0.2  2.8 -0.2 -0.3 -0.4 -0.5 -0.5  0.1  0.1  1.5 -0.1  0.6 -0.4 -1.7 -0.2 -0.2 -0.6  2.3  1.8 -1.3 -0.7 -0.4  3.8 -0.5  1.3 -0.3  2.5  0.4 -1.4  1.7 -1.6  0.5 -2.1 -0.3 -1.1 -0.1 -0.5 10.3  2.3 -0.4 -0.7 -0.5  0.9  6.9 -0.2 -0.6 -0.8  2.6  1.7]
vy_50sample [[7 8 5 0 6 4 9 9 2 1]
 [8 4 6 5 3 1 0 7 7 2]
 [9 1 8 2 7 4 3 5 0 6]
 [0 1 6 4 2 8 7 7 9 5]
 [2 4 0 7 8 8 3 5 1 9]
 [5 5 7 7 1 3 2 0 9 6]
 [9 6 5 4 3 8 7 2 0 1]
 [0 5 1 7 6 2 8 9 4 3]
 [1 3 4 8 9 7 0 2 5 6]
 [3 9 7 7 8 6 0 5 4 1]]
vt_50sample [[7 8 5 0 6 4 9 3 2 1]
 [8 4 5 6 3 1 0 9 7 2]
 [9 1 8 2 7 4 3 5 0 6]
 [0 1 6 2 4 8 7 3 9 5]
 [2 4 0 7 6 8 3 5 1 9]
 [5 8 4 7 1 3 2 0 9 6]
 [9 6 5 4 3 8 7 2 0 1]
 [0 5 1 7 6 2 8 9 4 3]
 [1 3 4 8 9 7 0 2 5 6]
 [3 9 2 7 8 6 0 5 4 1]]
Epoch  9610: Training cost= 0.3175, Training acc= 0.7660, Validation cost= 0.4090, Validation acc= 0.7664
Epoch  9620: Training cost= 0.3241, Training acc= 0.7661, Validation cost= 0.3861, Validation acc= 0.7665
Epoch  9630: Training cost= 0.3862, Training acc= 0.7662, Validation cost= 0.3946, Validation acc= 0.7666
Epoch  9640: Training cost= 0.4251, Training acc= 0.7662, Validation cost= 0.4531, Validation acc= 0.7666
Epoch  9650: Training cost= 0.4729, Training acc= 0.7663, Validation cost= 0.3752, Validation acc= 0.7667
Epoch  9660: Training cost= 0.4024, Training acc= 0.7664, Validation cost= 0.3891, Validation acc= 0.7668
Epoch  9670: Training cost= 0.3558, Training acc= 0.7665, Validation cost= 0.3993, Validation acc= 0.7669
Epoch  9680: Training cost= 0.4024, Training acc= 0.7665, Validation cost= 0.3698, Validation acc= 0.7670
Epoch  9690: Training cost= 0.4336, Training acc= 0.7666, Validation cost= 0.3973, Validation acc= 0.7670
Epoch  9700: Training cost= 0.3959, Training acc= 0.7667, Validation cost= 0.4397, Validation acc= 0.7671
tm  [ 1.8 -0.2 -1.2 -0.8 -0.8 -1.1 -0.2 -0.4  1.8 -0.9 -0.3  2.3 -1.5 -0.7 -0.2  0.4 -0.5 -0.4 -0.5 -0.2 -0.2  1.4 -1.2 -0.3 -0.7 -0.  -0.2 -0.2  2.2 -0.8  4.5 -0.8  0.5  1.2 -0.1 -0.8 -0.5 -0.4 -0.5 -1.3  0.5 -1.2 -0.6  1.3 -0.2 -0.  -0.   0.5  3.1 -2.1 -0.6 -0.6  0.1 -0.6 -1.3  1.5  0.4 -0.2  2.8 -0.9 -1.  -0.9 -0.   1.3  1.3 -0.5  0.   2.4  2.2  0.3 -0.2 -0.9 -0.5 -0.2 -2.9  0.4 -1.4 -0.5 -0.  -0.   3.4 -0.2 -0.1  0.6 -1.3 -1.2  2.4 -0.1  2.3 -0.6  0.  -0.4 -0.1 -0.8 -0.4 -0.2 -0.3 -1.4 -0.3 -0.1  1.1 -1.9 -0.8 -0.  -0.3 -0.2 -1.6  3.5 -0.4 -0.5  0.5 -0.4 -0.2 -0.9  1.7  4.   0.2  3.5 -0.3  2.  -0.2  1.3 -0.2 -0.6 -0.6 -0.   0.6  5.2  3.9  5.3  4.7 -1.   1.1 -0.3  5.4  7.   0.2 -0.3  1.1 -0.4  0.9 -0.   2.2 -0.  -1.   0.7 -0.6 -1.1  1.8 -0.3  2.  -0.1  4.3  0.8 -0.3 -0.1 -0.7 -0.1 -1.  -0.5 -0.6 -0.4  1.  -0.3  0.2 -0.2  1.6  3.  -0.1 -0.4 -1.1 -0.3 -0.9 -0.2 -0.2 -0.4 -1.1 -0.7  3.6  1.2 -0.7 -0.2 -0.8 -1.  -0.2 -0.4  3.9 -0.2 -0.5  4.1 -0.3  0.3 -1.  -1.1  5.3 -0.7 -0.6 -0.7 -0.5 -0.8 -0.4  2.2 -0.3 -0.7 -1.1 -1.   0.  -0.5 -0.2 -0.3 -0.1  4.6 -1.2 -0.5 -0.3  0.2 -0.  -0.3  0.4  0.6 -0.9 -0.3 -0.  -0.7 -0.6  2.5 -1.1 -0.3  0.   8.6 -0.5 -0.2 -0.3 -0.2 -0.7  4.5  0.5 -0.8  3.1  1.4 -0.1 -0.  -0.1  0.5 -0.2 -0.7 -0.2 -0.6 -1.  -0.2 -1.  -0.8 -0.3 -0.8  5.  -1.2]
ty_50sample [[3 4 6 9 9 8 7 0 2 1]
 [5 2 6 7 9 4 8 3 0 1]
 [6 2 1 9 3 5 7 4 0 0]
 [2 9 0 1 7 4 8 6 5 3]
 [9 2 3 6 7 8 5 1 0 4]
 [1 8 7 7 4 2 0 0 9 5]
 [7 4 2 8 5 1 0 3 6 9]
 [4 6 6 3 7 0 9 2 2 8]
 [8 1 0 0 5 9 3 2 7 6]
 [4 1 2 6 6 5 5 0 7 3]]
tt_50sample [[3 4 6 9 5 8 7 0 2 1]
 [5 2 6 7 9 8 4 3 0 1]
 [6 2 1 9 3 5 7 4 8 0]
 [2 9 0 1 7 4 8 6 5 3]
 [9 2 3 6 7 8 5 1 0 4]
 [1 8 7 6 2 4 0 3 9 5]
 [7 4 2 8 5 1 0 3 6 9]
 [4 6 5 3 0 7 9 2 1 8]
 [8 1 0 4 5 9 3 2 7 6]
 [1 4 2 6 8 5 0 9 7 3]]
vm  [-1.2  1.1 -1.5 -0.1 -0.9 -0.1 -0.2 -0.6 -0.5 -0.2 -0.9 -0.4 -0.   0.4 -1.   0.9 -0.4  0.5 -0.4  1.1 -0.7 -0.7  3.4 -0.3 -0.8  2.6 -0.2  0.2 -0.7 -0.7  0.4 -0.1 -0.5 -3.1 -0.1 -0.4  1.  -0.  -0.2 -0.8 -0.9 -0.2  0.1 -0.2 -0.8  1.9 -1.3 -0.3 -0.2  5.4 -0.4 -1.   0.1  1.4 -0.9  2.1 -0.2 -0.4  1.4  1.6  4.5  1.3  0.2  3.3 -0.5  0.  -0.  -0.2 -0.1  1.9 -0.5  2.   2.1  0.3 -1.5 -0.8  1.  -0.5  2.5 -0.  -1.  -0.3  0.4 -0.1  0.2  0.  -0.1 -0.4 -0.2  0.2 -0.  -0.7 -0.3 -0.5 -0.2  0.4 -0.3 -1.3 -0.2  0.6 -0.2 -0.7  2.7  0.3 -0.2  1.  -0.8 -0.2 -0.9 -0.4 -1.1  0.5  0.  -0.3  2.5  0.2 -0.8 -0.5 -0.2  0.6 -0.2  1.9 -0.1  1.  -0.3 -1.1  0.2  1.2  1.5  0.2  1.1 -0.8 -0.3 -0.2  9.3 -0.1 -0.5 -0.4  0.3 -0.2  1.4 -0.5 -0.3  0.1 -0.4  0.5  0.2  1.4  1.4  0.2  2.2 -0.1  0.   0.2  0.  -0.1 -0.1 -0.3 -0.2  0.1  1.8  1.8 -0.6 -0.4 -1.5 -0.7  0.6  3.2  0.9  1.1  0.5 -0.5  0.1 -0.3 -0.2 -0.2 -0.1  1.2  3.7 -0.3  0.1  0.5 -0.6 -1.2  0.7 -0.2 -0.7  1.3 -0.2  2.6 -0.3 -0.4 -0.3 -0.7 -0.8  0.   0.6  0.4 -0.4  0.1 -0.4  2.3 -0.5 -1.   3.6 -1.2 -0.7  2.3  6.4 -0.2 -0.7  1.3 -1.6  4.7 -0.5 -0.9  2.2 -0.3 -0.4  0.3 -0.3 -0.1 -0.2 -0.9  2.8  1.3 -0.6  3.4 -0.3  0.1 -0.2 -1.  -0.4  4.2  4.9  5.2  2.1  0.9  3.3  5.  -0.5  2.2  0.4 -0.3  4.7 -0.4 -0.3  2.2 -1.2 -0.6  0.6 -0.4 -0.3  0.6  0.6  2.5]
vy_50sample [[8 1 6 4 4 2 9 3 5 7]
 [0 4 1 6 8 7 3 5 9 2]
 [5 3 0 9 2 6 6 8 1 7]
 [3 4 8 6 1 2 7 9 5 5]
 [3 7 7 4 5 5 9 8 8 2]
 [6 7 9 0 5 2 2 3 8 1]
 [6 7 8 4 1 1 0 3 5 9]
 [5 1 8 3 7 6 2 9 0 4]
 [1 9 2 6 5 8 4 7 0 3]
 [4 7 5 6 1 3 2 0 8 9]]
vt_50sample [[8 1 6 0 4 2 9 3 5 7]
 [0 1 4 6 8 7 3 5 9 2]
 [5 3 0 4 9 2 6 8 1 7]
 [3 4 8 1 6 2 7 9 0 5]
 [1 3 7 4 0 5 9 6 8 2]
 [6 7 9 0 5 4 2 3 8 1]
 [6 7 8 2 4 1 0 5 3 9]
 [5 1 8 3 7 6 2 9 0 4]
 [1 9 2 6 5 8 4 0 7 3]
 [4 7 5 6 1 3 2 0 8 9]]
Epoch  9710: Training cost= 0.3766, Training acc= 0.7668, Validation cost= 0.3547, Validation acc= 0.7672
Epoch  9720: Training cost= 0.3509, Training acc= 0.7669, Validation cost= 0.3951, Validation acc= 0.7673
Epoch  9730: Training cost= 0.2954, Training acc= 0.7670, Validation cost= 0.3510, Validation acc= 0.7674
Epoch  9740: Training cost= 0.3358, Training acc= 0.7671, Validation cost= 0.3185, Validation acc= 0.7675
Epoch  9750: Training cost= 0.3930, Training acc= 0.7671, Validation cost= 0.3489, Validation acc= 0.7675
Epoch  9760: Training cost= 0.3371, Training acc= 0.7672, Validation cost= 0.3706, Validation acc= 0.7676
Epoch  9770: Training cost= 0.3898, Training acc= 0.7673, Validation cost= 0.3600, Validation acc= 0.7677
Epoch  9780: Training cost= 0.4215, Training acc= 0.7674, Validation cost= 0.5201, Validation acc= 0.7678
Epoch  9790: Training cost= 0.4343, Training acc= 0.7675, Validation cost= 0.3986, Validation acc= 0.7679
Epoch  9800: Training cost= 0.3627, Training acc= 0.7675, Validation cost= 0.3917, Validation acc= 0.7679
tm  [-1.4 -0.7 -0.8 -2.5 -1.3  1.4 -0.2 -0.8 -0.2 -0.3  3.1 -0.1 -0.1 -0.1  6.4 -0.4 -0.3 -0.5 -0.7 -0.3 -0.4 -0.5 -0.8 -0.1 -0.3  1.2 -0.2  0.3 -0.8 -0.5  6.8  1.3  0.3  7.9 -0.1  0.4  0.5 -0.7 -1.8 -0.8  0.9 -1.  -0.7  1.6 -1.2 -0.1 -0.8  0.5 -0.8 -1.3 -1.3 -1.  -1.2  1.2 -1.  -0.5 -0.5 -1.5  1.8 -2.   7.9  1.6 -0.5  1.4  0.  -0.1 -0.2  1.5 -0.2  1.8 -0.4  0.8 -0.7 -0.1 -2.6 -0.4  3.2 -0.6  4.  -0.4  4.8 -0.1 -0.6 -0.3  1.  -0.8  0.1 -0.1  0.5  0.3 -0.7 -0.  -0.4 -0.7 -0.9 -0.1 -0.7 -1.2  1.2  0.2  0.8  1.2  4.  -0.  -0.5 -0.5 -2.3  6.3  1.2 -0.3 -0.8  0.3 -0.2 -0.8  4.9  0.3 -0.4  1.  -0.8 -0.8 -0.3  2.6  0.3 -0.1 -1.   7.   0.6  1.  -0.   3.7  0.8 -1.1 -0.5 -0.3  4.3 12.9 -0.5 -0.2  1.  -1.   0.3  1.8  0.2 -0.2 -0.6 -1.  -0.3  1.3 -1.   0.2  3.7 -0.8 -2.1 -0.2 -0.4 -0.1  0.1 -0.5 -0.7 -0.5  0.1  1.8 -0.4 -0.4 -0.   0.1 -0.4  5.5  0.4 -0.7 -0.8 -0.3 -0.6 -0.1 -0.5  4.7 -1.  -0.9  7.5 -0.  -0.1 -0.  -0.3 -0.9  0.1 -1.  -1.2 -0.7 -0.5  1.4 -0.2 -0.4 -0.2 -0.4 -2.   2.6 -1.3 -0.3 -0.5 -0.3 -0.4  1.2 -0.5 -0.7  2.  -3.  -0.2  0.1  0.5 -0.1 -0.7  0.2 -0.7  5.1  0.7 -0.4 -0.1 -0.7 -0.3 -0.2 -0.3  1.  -0.1 -1.   2.1 -0.7 -0.3  1.6 -0.7  0.1 -0.7  1.3 -0.3 -0.1  3.1  3.6  1.5 -1.8  2.8  4.4 -0.7  2.  -0.5 -0.2 -0.7  4.2 -0.4 -0.4 -0.9  0.3 -1.3 -0.5 -1.3 -0.7  2.4 -0.5]
ty_50sample [[1 4 6 0 7 3 9 2 5 8]
 [0 5 8 6 4 3 7 9 2 1]
 [7 3 9 2 1 4 5 8 0 6]
 [1 9 8 2 3 0 6 5 4 7]
 [5 2 7 3 6 8 9 4 0 1]
 [0 6 9 2 3 4 4 1 7 5]
 [0 3 7 9 1 5 6 6 2 8]
 [9 3 1 7 6 8 2 5 0 4]
 [0 8 8 9 5 1 1 6 3 2]
 [9 4 4 5 3 1 8 6 7 2]]
tt_50sample [[1 4 6 0 7 3 9 2 5 8]
 [0 5 8 6 4 3 7 9 2 1]
 [7 3 9 2 1 4 5 8 0 6]
 [1 9 2 8 3 0 6 5 4 7]
 [5 2 7 6 3 8 9 4 0 1]
 [0 6 9 2 3 8 4 1 7 5]
 [0 3 7 9 1 5 4 6 2 8]
 [3 9 1 7 6 8 2 5 0 4]
 [0 8 9 7 5 1 4 6 3 2]
 [0 9 4 5 3 1 8 6 7 2]]
vm  [-0.5  2.2  2.9 -0.5 -1.5 -0.3 -0.4 -0.7 -1.6 -1.4  4.1 -0.3  0.6  0.4  5.3  6.8  1.3 -0.   0.3 -1.  -0.3 -0.4 -0.7  0.1 -1.6  0.  -0.3 -0.3  2.4  1.2  0.8 -0.6 -0.6  4.7 -0.8  0.7  4.1  5.1  5.3 -0.5 -0.  -2.3 -0.2  3.7 -1.3 -0.4  1.3 -0.5 -0.4 -0.9 -0.4 -0.4 -0.2  4.7 -1.6 -0.5 -0.4 -0.8 -0.8  0.1  0.5  1.1 -0.7 -0.9 -0.2 -0.2 -0.3 -0.5 -0.6  0.5 -0.1 -1.  -0.2 -0.3 -1.3  0.2 -0.3 -0.5 -0.1  0.4 -0.5 -0.3 -0.7 -0.  -0.6 -2.   1.6  0.3  4.4 -0.3 -0.6  2.3  2.1  3.1 -0.3 -0.2 -0.6 -0.1 -0.7 -0.6  4.8 -0.1 -0.2 -0.1  0.3 -0.1 -1.2  1.9  2.  -1.  -0.2 -0.9 -0.1  2.1 -1.1  6.8 -0.3 -0.9 -0.2 -0.5 -0.6  3.1 -0.3 -0.7 -0.5  5.7  2.8 -0.7 -0.7  5.1  0.5 -0.2  1.1 -0.2 -2.5 -1.7 -0.1 -0.   2.2 -0.5 -0.8 -0.8 -0.5 -0.6 -0.1 -0.6 -0.3 -0.4 -1.3  0.5  0.1 -0.1  1.6 -0.6 -0.9 -0.3 -0.5  0.2  0.2 -0.7 -1.  -1.1 -0.1  0.2  0.5  0.7  2.7  1.6  0.  -0.2 -0.6 -0.8 -0.6 -0.  -0.3  5.1 -0.1 -0.5 -0.7 -1.3  1.   1.6  0.5 -1.1 -0.9 -0.1  1.1 -1.2 -1.1 -0.1 -0.3 -0.1 -0.1 -1.7  2.4  1.6 -0.2  2.7 -0.5 -0.9 -0.3 -0.5 -0.7 -0.3 -0.4 -0.9 -0.8 -0.2  4.7 -0.2 -0.1  2.9 -0.6  0.6 -0.1 -0.2 -0.7  0.2  0.8 -0.5 -0.9 -0.1 -0.2 -0.4 -1.   4.1  0.5  1.1  1.   1.3 -1.4 -0.  -0.5  3.2 -1.  -0.1 -0.7 -0.6 -0.3  6.8 -0.6  4.5 -0.4 -0.1  3.2 -0.4 -0.2 -0.4 -0.1 -0.5  0.4  0.5  4.3 -0.1  1.  -1.1]
vy_50sample [[3 2 2 4 8 9 9 6 5 0]
 [3 2 4 5 6 0 9 7 1 8]
 [4 7 2 0 6 1 5 3 8 9]
 [0 5 1 9 8 4 2 6 3 7]
 [2 9 1 0 5 6 8 7 4 3]
 [7 2 8 3 5 9 9 1 0 4]
 [8 5 2 2 4 1 0 9 9 6]
 [6 5 3 3 9 7 0 2 1 8]
 [1 0 9 6 3 5 4 7 2 8]
 [8 6 2 4 4 3 9 7 0 1]]
vt_50sample [[3 7 2 4 8 9 1 6 5 0]
 [3 2 4 5 6 0 7 9 1 8]
 [4 7 2 0 6 5 1 3 8 9]
 [0 5 1 9 8 4 2 6 3 7]
 [2 9 1 0 5 6 8 7 4 3]
 [7 2 8 3 5 6 9 1 0 4]
 [8 5 2 3 4 1 0 9 7 6]
 [6 5 4 3 9 7 0 2 1 8]
 [1 0 9 6 3 4 5 2 7 8]
 [8 6 2 5 4 3 9 7 0 1]]
Epoch  9810: Training cost= 0.3708, Training acc= 0.7676, Validation cost= 0.4251, Validation acc= 0.7680
Epoch  9820: Training cost= 0.3791, Training acc= 0.7677, Validation cost= 0.3639, Validation acc= 0.7681
Epoch  9830: Training cost= 0.4040, Training acc= 0.7678, Validation cost= 0.3861, Validation acc= 0.7682
Epoch  9840: Training cost= 0.3745, Training acc= 0.7678, Validation cost= 0.4132, Validation acc= 0.7682
Epoch  9850: Training cost= 0.3628, Training acc= 0.7679, Validation cost= 0.3963, Validation acc= 0.7683
Epoch  9860: Training cost= 0.3402, Training acc= 0.7680, Validation cost= 0.3243, Validation acc= 0.7684
Epoch  9870: Training cost= 0.3709, Training acc= 0.7681, Validation cost= 0.3620, Validation acc= 0.7685
Epoch  9880: Training cost= 0.3163, Training acc= 0.7682, Validation cost= 0.5073, Validation acc= 0.7686
Epoch  9890: Training cost= 0.4557, Training acc= 0.7682, Validation cost= 0.3686, Validation acc= 0.7686
Epoch  9900: Training cost= 0.4040, Training acc= 0.7683, Validation cost= 0.4088, Validation acc= 0.7687
tm  [ 1.3  0.2  2.2  2.2 -1.8 -0.3 -0.2 -0.4 -1.1 -0.2  3.5 -0.4 -0.4 -0.5  1.5 -0.1 -0.3 -0.1  0.7 -1.3 -0.2 -0.2  2.8  0.7 -1.   2.9 -0.2 -0.2 -1.1 -0.   2.9  0.6 -0.3  6.2  1.9  1.2  3.5  0.7  5.8 -0.8 -0.3  2.  -0.1  2.8 -0.7 -0.1  4.3 -0.2  2.5  5.1 -1.  -0.6  1.3 -0.2 -0.   0.2 -0.7 -0.8 -0.3 -0.5 -0.9  0.5 -0.3  3.   0.4 -0.2 -0.2 -0.5  1.4 -0.1 -0.4  3.2  0.1 -0.3  1.4 -0.  -0.1 -0.   3.1 -0.1  7.6 -0.  -0.4  0.4 -1.2  2.   1.9 -0.3 -0.4 -0.2 -0.1 -0.4 -0.8 -0.4  0.4  0.3 -0.3 -0.1 -0.2  0.3 -0.1  8.  -0.6 -0.4  0.9  0.1 -0.2  3.4  2.  -1.4 -0.9  0.3  0.6  0.7  2.2 -1.  -0.4 -0.2 -0.2 -0.6 -0.3  5.3 -0.2 -0.1 -0.4  1.5 -0.5  3.2 -0.5 -1.5  1.7 -0.3 -0.6 -0.4 -2.3  0.5 -0.2 -0.7 -0.3 -0.8 -0.1 -0.9 -0.2  0.7 -0.2 -0.1 -0.1 -0.4 -1.3  0.4 -0.1  0.2  2.1 -0.3 -0.3 -0.  -0.1 -0.4  0.4 -0.4  2.5 -0.5 -0.2 -0.5 -0.  -0.9 -1.   0.  -0.1  0.3  1.3 -0.8 -0.  -0.  -0.2  5.2 -0.3  2.4 -0.9 -0.3  0.  -0.1 -0.4 -1.1 -0.5 -0.8  3.3 -0.5  1.9 -0.4 -0.3 -0.7 -0.8 -0.9  5.5  1.4  1.2  1.  -0.4  0.6 -0.2 -0.3 -0.5 -0.4 -0.5  0.7 -0.1  0.7  3.2 -0.4 -0.  -0.4 -0.8  1.   0.  -0.6 -0.5 -0.2 -0.1  0.2 -0.7 -0.3 -0.4 -1.   2.5 -0.7 -0.2  0.8  0.   1.  -0.7 -0.6 -0.2  2.   2.5 -0.1  3.6  2.3  2.1 10.5 -0.4  5.5 -0.3 -0.  -1.1 -1.6 -0.3  1.1 -0.4 -0.4 -1.8  0.8  5.2  0.1 -0.5  8. ]
ty_50sample [[0 7 9 4 2 8 6 1 5 3]
 [6 5 0 1 4 8 8 2 7 3]
 [2 2 3 6 1 1 7 0 4 5]
 [0 7 2 1 3 8 9 6 4 5]
 [0 6 3 4 5 7 9 2 8 1]
 [5 1 4 2 3 7 8 0 6 9]
 [7 7 3 6 2 2 4 8 9 5]
 [7 0 8 9 2 6 1 5 4 3]
 [1 1 0 0 9 6 5 3 2 4]
 [9 5 1 1 8 0 3 2 4 7]]
tt_50sample [[0 7 9 4 2 8 6 1 5 3]
 [6 5 0 1 4 9 8 2 7 3]
 [2 8 3 9 6 1 7 0 4 5]
 [0 7 2 1 3 8 9 6 4 5]
 [0 6 3 4 5 7 9 2 8 1]
 [5 1 2 4 7 3 8 0 6 9]
 [7 3 1 0 6 2 4 8 9 5]
 [7 0 8 9 2 6 1 5 4 3]
 [1 7 8 0 9 6 5 3 2 4]
 [9 5 6 1 8 0 3 2 4 7]]
vm  [-0.8  0.5  6.2 13.1 -1.8 -0.7 -0.1 -0.1 -0.2 -0.8 -1.1  2.5 -0.8 -0.2 -0.7 -0.9 -0.9 -0.5  0.9 -1.6 -0.6 -0.4 -0.9 -0.5 -0.6  1.8 -0.4 -0.1 -0.8 -1.1 -0.2  0.  -0.8  6.1 -0.6 -0.1  0.8 -0.3 10.3 -1.3 -0.4 -0.6 -0.2 -0.1 -0.3  0.8  5.6  2.3  1.9 -1.5 -1.   0.3  2.3 -2.7 -0.6  2.5 -0.1  3.5 -0.1  2.7 -0.8 -0.3 -0.3  3.  -0.9  1.8 -0.2 -0.9  1.5  3.5 -0.3  1.   0.   0.2  7.4 -0.2 -0.4 -1.  -0.1  1.8 11.5 -0.3 -1.  -0.2 -0.2 -0.4 -0.4 -0.3  0.6 -0.2  0.5  0.  -0.2 -0.6  2.1  0.5  1.2 -0.4 -0.3  0.1  2.5  0.3  0.3 -0.1  1.4  0.5  3.7 -0.3 -0.9 -2.6 -0.3 -0.1 -0.3 -0.3  1.2  0.6 -0.1  0.5 -0.5 -0.5 -0.1 10.3 -0.   0.6 -0.6 -0.8  2.1 12.1  3.1 -0.  -0.2 -1.2 -0.5 -0.7 -2.4 -0.3 -0.1 -0.4  0.7 -0.5  2.4 -0.   0.8 -0.2 -1.1 -0.4 -0.3 -0.6 -0.2 -0.7 -1.  -0.5 -0.1  0.7 -0.2 -0.2 -0.2 -0.2  2.9 -0.4 -0.6 -0.9 -0.6 -0.2 -0.2 -0.4  1.6  2.6 -0.2  3.6 -0.9 -0.3 -0.3 -0.4 -0.2  1.8  1.7  2.2 -2.   0.9 -1.2 -0.3 -0.8 -1.1  0.7 -0.5  2.9 -0.3  0.9  5.2 -0.1  1.2 -1.3 -0.7  4.9 -0.7  4.5 -0.3 -0.2 -0.1 -0.6  0.  -0.3 -1.1  0.6  2.5  0.8  0.8 -0.6 -0.1 -0.2  2.2 -1.2  0.9 -1.2 -0.7  1.4 -0.3  0.7  0.9 -0.9 -0.1  0.1 -0.2 -0.8 -0.2 -1.2  0.3  1.7  4.2 -1.  -1.6 -0.3 -0.4  4.5 -1.6 -0.2  7.5  3.1  7.9 -0.2  4.3 -0.1 -0.4 -1.9 -2.  -0.2  1.6 -1.2 -0.8 -2.7 -1.6  8.6 -0.4  6.2  2.9]
vy_50sample [[9 3 7 0 5 1 8 6 4 2]
 [2 0 3 5 9 6 7 4 1 8]
 [9 3 2 4 6 5 5 0 1 8]
 [1 7 8 9 9 5 4 0 6 2]
 [1 5 4 7 8 3 6 6 2 9]
 [3 1 0 6 2 4 5 8 9 7]
 [8 6 1 2 5 3 4 7 0 9]
 [0 2 4 5 6 3 8 1 9 9]
 [5 7 4 1 3 6 9 8 8 2]
 [6 3 8 4 0 9 5 7 2 2]]
vt_50sample [[9 3 7 0 1 5 8 6 4 2]
 [2 0 3 9 5 6 7 4 8 1]
 [9 3 2 4 6 7 5 0 1 8]
 [1 7 8 9 3 5 4 0 6 2]
 [1 5 4 7 3 8 0 6 2 9]
 [1 3 0 6 2 4 5 8 9 7]
 [8 6 1 2 5 3 7 4 0 9]
 [0 2 4 5 6 3 8 1 9 7]
 [5 7 4 1 6 3 9 0 8 2]
 [6 3 8 4 9 0 5 7 1 2]]
Epoch  9910: Training cost= 0.3742, Training acc= 0.7684, Validation cost= 0.3984, Validation acc= 0.7688
Epoch  9920: Training cost= 0.4502, Training acc= 0.7684, Validation cost= 0.4373, Validation acc= 0.7688
Epoch  9930: Training cost= 0.4227, Training acc= 0.7685, Validation cost= 0.4477, Validation acc= 0.7689
Epoch  9940: Training cost= 0.3920, Training acc= 0.7686, Validation cost= 0.4224, Validation acc= 0.7690
Epoch  9950: Training cost= 0.4254, Training acc= 0.7686, Validation cost= 0.3640, Validation acc= 0.7690
Epoch  9960: Training cost= 0.3844, Training acc= 0.7687, Validation cost= 0.3633, Validation acc= 0.7691
Epoch  9970: Training cost= 0.3400, Training acc= 0.7688, Validation cost= 0.3719, Validation acc= 0.7692
Epoch  9980: Training cost= 0.3425, Training acc= 0.7689, Validation cost= 0.3802, Validation acc= 0.7693
Epoch  9990: Training cost= 0.3668, Training acc= 0.7689, Validation cost= 0.3243, Validation acc= 0.7693
Epoch 10000: Training cost= 0.4043, Training acc= 0.7690, Validation cost= 0.3835, Validation acc= 0.7694
tm  [-0.8 -0.1  0.2  1.3 -1.  -0.6 -0.2 -0.5 -0.7 -0.3 -1.2  1.7 -1.5 -0.3  0.4 -0.8 -0.1 -0.4 -0.3 -0.8 -0.6 -0.1  1.2 -0.2 -1.3  0.9 -0.1 -0.1 -0.1  0.4  2.8 -0.5  1.1  3.9 -0.8 -0.1  1.1 -0.9 -1.2 -0.2 -0.5  5.8  2.6 -0.8 -0.5 -0.1 -0.2  2.   0.2  2.4 -0.7 -0.5  0.6 -1.6 -1.2  0.8 -0.2  2.4 -0.6 -0.5  2.3 -0.5 -0.2 -0.1 -0.2 -0.3 -0.1 -0.2  0.3  1.4 -0.3 -0.3  0.5 -0.4 -1.9 -0.1  0.6 -0.1  1.9 -0.2  5.5 -0.2 -0.5 -0.3 -0.2  6.8  1.3 -0.1 -0.2 -0.2 -0.3  0.5 -0.3 -0.2 -0.3 -0.3  0.3 -1.2 -0.5 -0.2  1.3  3.7  0.2 -0.1 -0.6  1.3 -1.   3.  -0.6 -1.1 -0.2 -0.4 -0.2 -0.3  0.1  2.2 -0.1 -0.5 -0.3 -0.1 -0.3  3.1  0.3  1.2 -0.1  0.6  2.8  8.5  1.7 -0.6  1.6 -0.5 -0.  -0.2  7.2 12.4 -0.1 -0.1 -0.5 -0.5  2.3 -0.1  3.2 -0.  -1.  -0.   0.9 -0.6  3.2  1.3  1.2 -0.4 -0.5  1.4 -0.4 -0.3 -0.8 -0.1 -1.1 -0.7 -0.2  3.8 -0.1 -0.4 -0.4 -0.4 -0.2 -0.   0.4  0.5 -0.   0.7 -0.8 -0.3 -0.2 -0.7 -1.1  0.6  5.3  1.8 -1.5  0.  -0.3 -0.9 -0.6 -0.1 -0.1  0.2 -0.4  0.   0.2 -0.5 -0.5 -1.   0.3  1.  -0.1  1.1 -0.  -0.8 -0.1  0.4  0.1 -0.4  1.6 -0.4  0.8 -0.2 -2.4 -0.  -0.5  2.3 -0.8  4.5 -0.2 -0.6  3.7 -0.2  1.5 -0.3 -0.9 -0.2 -0.2 -0.2  4.5  0.1 -1.8 -0.3  1.2  0.4  1.7 -0.7 -0.3 -1.7  1.2  0.8  0.6 -0.   1.4 -1.  -0.3 -0.6 -0.2 -0.3 -0.6 -1.1 -0.1 -0.  -0.6 -0.  -1.4 -0.5 -1.1 -0.2  4.9  4.6]
ty_50sample [[6 5 1 1 9 7 0 8 3 2]
 [5 8 4 9 3 6 6 0 2 2]
 [6 3 1 9 7 4 0 2 8 5]
 [0 0 2 2 7 1 9 5 5 3]
 [4 3 1 2 9 6 5 7 0 8]
 [3 4 6 7 0 9 1 2 2 8]
 [7 7 6 6 3 9 2 0 4 1]
 [9 6 1 5 4 3 8 2 0 7]
 [3 6 5 0 4 8 9 7 1 2]
 [2 3 0 9 8 6 5 7 4 1]]
tt_50sample [[6 5 1 4 9 7 0 8 3 2]
 [5 8 4 9 3 6 0 1 7 2]
 [6 3 1 9 7 4 0 2 8 5]
 [4 0 6 2 7 1 9 5 8 3]
 [4 3 1 2 9 6 5 7 0 8]
 [3 4 6 0 7 1 9 5 2 8]
 [7 8 5 6 3 9 2 0 4 1]
 [9 6 1 5 4 3 8 2 0 7]
 [3 6 5 0 4 8 9 7 1 2]
 [2 3 0 9 8 6 5 7 4 1]]
vm  [-0.9 -0.8  2.5 -2.2 -1.5 -0.2 -0.3 -0.5  1.6 -0.1  1.   0.9 -0.5 -0.2 10.4  0.8 -1.3 -0.3 -0.2  2.  -0.6 -0.2 -0.3 -0.9 -0.1  0.2 -0.2  0.1  1.  -0.6  4.8 -0.3 -0.1  9.1  0.2 -0.5 -0.5 -0.4 -1.3 -1.  -0.1 -1.3 -1.2  1.7 -1.  -0.1 -1.7 -0.  -0.6 -0.7 -1.4 -0.7 -0.7  1.5 -1.6 -1.3 -0.6 -1.2  4.5 -1.1  6.7  0.8  0.1  2.4  1.7 -0.2 -0.2  1.5  1.2  1.  -0.2 -0.6 -0.3 -0.1 -3.8 -0.5 -0.2 -0.4  2.8  0.2 -0.1 -0.1  0.6  0.6 -0.  -1.1  0.1 -0.3 -0.3 -0.3 -0.1 -0.3 -0.5 -1.7 -0.5  0.4 -1.  -2.  -0.4  0.1 -0.   4.5  1.9  0.4 -0.3 -0.1 -2.2  4.6  0.4  1.2 -0.4 -0.5 -0.1 -1.   3.5  3.5 -0.1  2.3 -0.5 -0.6 -0.4 -0.3  1.4  0.6 -0.5 11.   0.2  0.8  3.1  4.2  0.6 -1.4 -0.  -0.4 -1.5  7.4  0.   0.  -0.1 -0.9  1.   1.7  0.5 -0.2 -1.  -0.3 -0.3 -0.2 -2.1  0.1  4.8 -0.5 -0.8 -0.   0.3  0.3 -0.3 -0.6 -0.2 -0.5  0.6 -0.2  0.8 -0.4  0.9 -0.6  1.6  6.4  0.  -0.6 -0.9 -0.9 -0.5 -0.  -0.4  6.5 -0.8 -0.8  6.5  1.9  1.7 -0.2 -0.8 -1.  -0.1 -0.7 -0.7 -0.8 -0.6  2.1 -0.2 -0.2 -0.6 -0.7 -1.5 -0.4 -1.2 -0.8 -0.4 -0.4 -0.1  1.5 -0.6 -0.7  0.3 -2.9 -0.3 -0.3  3.8 -0.4 -0.2  2.8 -1.5  4.4 -0.2 -0.5 -0.2 -0.4  0.8  0.3 -0.9 -0.3 -0.2 -0.6  1.   1.1 -0.6  2.3 -0.1  2.5 -0.5  0.7 -0.2  1.8 -0.2 -0.2  1.2 -1.7  4.4  3.  -0.4  1.8 -0.2 -0.2  2.3  3.  -0.3 -0.3 -1.  -0.2 -0.2 -0.3 -1.  -0.5  2.4 -0.7]
vy_50sample [[7 1 4 6 3 8 8 9 5 5]
 [8 2 0 9 9 3 4 6 1 7]
 [5 2 0 6 3 8 4 1 7 9]
 [4 8 2 3 7 9 6 1 0 5]
 [4 3 9 8 7 6 1 2 0 5]
 [5 4 2 9 8 7 6 3 1 0]
 [7 3 4 9 8 2 1 6 6 5]
 [1 2 8 5 7 7 4 3 6 9]
 [9 4 3 0 5 8 7 2 6 1]
 [0 3 8 6 2 5 1 4 7 9]]
vt_50sample [[7 1 4 6 3 0 8 2 9 5]
 [8 2 0 5 9 3 4 6 1 7]
 [5 2 0 6 3 8 4 1 7 9]
 [4 8 2 3 7 9 6 1 0 5]
 [4 3 9 8 7 6 1 2 0 5]
 [5 4 2 9 8 7 6 3 1 0]
 [7 3 4 9 8 2 1 0 6 5]
 [1 2 8 5 7 0 4 3 6 9]
 [9 4 3 0 5 8 7 2 6 1]
 [0 3 8 6 2 5 1 4 7 9]]
Epoch 10010: Training cost= 0.3598, Training acc= 0.7691, Validation cost= 0.4158, Validation acc= 0.7695
Epoch 10020: Training cost= 0.4312, Training acc= 0.7692, Validation cost= 0.3380, Validation acc= 0.7696
Epoch 10030: Training cost= 0.3662, Training acc= 0.7693, Validation cost= 0.3783, Validation acc= 0.7697
Epoch 10040: Training cost= 0.3789, Training acc= 0.7693, Validation cost= 0.3941, Validation acc= 0.7697
Epoch 10050: Training cost= 0.4092, Training acc= 0.7694, Validation cost= 0.4067, Validation acc= 0.7698
Epoch 10060: Training cost= 0.4618, Training acc= 0.7695, Validation cost= 0.4363, Validation acc= 0.7699
Epoch 10070: Training cost= 0.4448, Training acc= 0.7695, Validation cost= 0.4425, Validation acc= 0.7699
Epoch 10080: Training cost= 0.4123, Training acc= 0.7696, Validation cost= 0.3266, Validation acc= 0.7700
Epoch 10090: Training cost= 0.3880, Training acc= 0.7697, Validation cost= 0.3846, Validation acc= 0.7701
Epoch 10100: Training cost= 0.3961, Training acc= 0.7697, Validation cost= 0.4122, Validation acc= 0.7701
tm  [ 1.8  0.3 -3.1 -1.6 -0.3 -0.1 -0.3 -0.4 -0.7 -0.5  2.5  0.1 -0.5 -0.5 -1.7 -0.8  0.4  0.  -0.3 -0.3 -0.7 -0.3 -0.1  0.8 -1.2  3.6 -0.3 -0.2 -1.6 -1.   4.4 -0.4 -0.4 -2.6  2.  -0.2  2.7  0.8  0.8 -1.3 -0.4  2.8  0.9  4.9 -0.4  0.4 -0.6 -0.3  3.6 -0.1 -0.3 -1.1 -0.5  2.5  1.1  3.1 -0.8 -0.3  0.4 -0.9 -0.2 -0.7 -0.3  3.  -0.2 -0.2  0.1  1.7  0.8  0.5 -0.4  3.2 -0.2 -0.4 -2.4 -0.1 -0.5 -0.2  1.3 -0.1  0.2 -0.1 -0.3  0.9 -1.1  2.1  4.  -0.5  1.1 -0.5 -0.5 -0.8 -0.7  1.4 -0.6  0.3  0.6 -1.1  0.1 -0.3  0.4 -1.7 -0.8 -0.4  1.7  0.7 -1.6  4.9  1.6 -0.5 -0.7 -0.1  0.3 -0.3  4.  -1.6 -0.3  1.1  1.   0.1  0.2  1.9 -0.4 -0.5 -0.6 -1.8 -0.5 -0.1  2.   2.9  1.8 -0.5 -0.3  0.7  7.9  0.5 -0.5 -0.7  0.5 -0.7 -0.1 -0.9 -0.3 -0.2  0.4 -0.4 -0.5 -0.7  5.9 -0.9  2.4  0.6  2.9 -0.3 -0.1 -0.3  0.6  0.3 -0.1 -0.4  0.3 -0.7 -0.3 -0.8 -0.6 -0.5 -0.8 -0.5  0.  -0.7  0.5  0.3 -0.1 -0.2 -0.1 -1.8 -0.2 -0.4  1.4 -0.5 -1.3 -0.1 -0.2 -1.1  1.5 -0.3  2.5  2.1  1.   4.4 -0.4 -0.5 -0.1 -1.2  4.1 -0.3 -1.1 -0.  -0.2  1.1 -0.1  1.  -0.1 -0.4 -0.6 -1.5  0.7  0.6 -0.8 -0.2 -0.5 -1.2 -0.7 -0.5  1.2 -0.1 -0.9 -0.3 -1.  -0.4  0.6 -0.2 -0.4 -0.8  0.1 -0.9 -0.2 -0.4 -0.   4.3 -1.1  0.  -0.3 -0.5  4.8  8.4  3.5 -1.   1.5 -1.  -0.1 -0.6 -0.4 -0.1  2.4 -0.  -0.1  0.  -0.7 -0.3 -0.2  0.2  0.8 -0.1  1.  -0.1]
ty_50sample [[0 4 5 3 2 8 9 9 1 7]
 [5 3 2 2 4 8 7 0 1 9]
 [8 1 2 5 9 3 4 7 0 6]
 [4 3 3 8 8 2 0 7 1 5]
 [7 6 1 2 2 4 4 9 3 0]
 [4 0 9 7 5 6 2 2 3 1]
 [0 3 1 2 6 4 5 7 9 8]
 [0 3 3 7 1 9 5 2 8 4]
 [7 7 0 1 4 4 8 9 3 5]
 [9 9 0 4 3 8 6 5 2 7]]
tt_50sample [[0 4 5 3 2 8 6 9 1 7]
 [5 3 6 2 4 8 7 0 1 9]
 [8 1 2 5 9 3 4 7 0 6]
 [4 9 3 6 8 2 0 7 1 5]
 [7 6 1 2 5 4 8 9 3 0]
 [4 0 9 7 5 6 8 2 3 1]
 [0 3 1 2 6 4 5 7 9 8]
 [6 0 3 7 9 1 5 2 8 4]
 [6 7 0 1 4 2 8 9 3 5]
 [9 1 0 4 3 8 2 6 5 7]]
vm  [-0.3 -0.3 -0.2 -3.3 -1.8  0.3 -0.1 -0.3 -0.4 -0.8  4.8 -0.2 -0.1 -0.4  9.8  4.3 -0.  -0.6 -0.1  4.  -0.4 -0.2  1.9 -0.  -1.4  1.9 -0.2 -0.3 -0.3 -0.2  4.7 -0.4 -0.5  5.6 -0.3 -0.1  1.   3.9 -0.4 -1.   0.1  3.2  1.5  5.3 -0.9 -0.1 -2.9 -0.8  0.5  2.4 -1.1 -0.8 -0.6  8.1 -1.3 -1.4 -0.7 -0.1  0.9 -1.1  6.3 -0.2  1.   2.8  0.5 -0.2 -0.1 -0.  -0.  -0.  -0.1 -0.4  0.3  0.4 -4.4 -0.  -0.  -0.3  2.6  0.1 -1.6 -0.2  2.   0.4 -0.5  4.9  1.6 -0.1  0.   0.1 -0.2 -0.2 -0.7 -0.4 -0.8  0.2 -0.1 -1.8 -0.6  0.   1.7  6.4 -0.1 -0.1  0.1 -0.4 -2.6  5.1  2.5  4.2 -0.8 -0.4 -0.  -0.6  0.5  2.6 -0.   0.1 -0.4 -0.4  0.  -1.7 -0.4  0.1 -0.4 10.9  0.1 -1.9  3.5  2.8 -0.3 -0.4 -0.2 -0.4 -2.9 -0.7 -0.  -0.5  0.1 -0.7 -0.  -0.1 -0.1  0.1 -0.2  0.7  0.3 -0.4 -0.1  0.9  5.  -0.3  0.4  0.  -0.4 -0.3 -0.5  0.   3.6 -0.4  2.1 -0.9  0.5 -0.6 -0.1 -0.6  0.  -0.   1.7 -1.   1.2  1.  -0.6 -0.1 -0.4  2.1 -0.3 -0.7  3.  -0.3 -0.7 -0.3 -0.6 -1.5 -0.3 -0.4 -0.7 -0.8 -0.6 -0.  -0.3 -0.6  1.6 -1.2 -1.3 -0.3 -1.5 -0.1 -0.2 -0.2 -0.1  0.1 -0.5 -0.8 -0.1 -2.8  0.6 -0.1 -0.9 -0.3 -0.7  1.1 -0.5  3.5  0.2 -0.6 -1.4 -0.4  2.   0.3 -0.8  0.  -0.5 -0.5 -0.   1.1 -0.1  1.4  0.3  1.5 -0.6  0.9 -0.4 -0.7  0.9  2.4  1.4 -2.   2.1 -2.7 -0.2 -1.4 -0.1 -0.3  6.4  2.6 -0.1  0.  -0.1 -0.3  2.9  1.9 -0.3 -0.1  0.9 -0.5]
vy_50sample [[4 7 2 1 1 8 0 3 6 9]
 [6 8 1 9 0 3 7 2 4 5]
 [6 3 1 9 5 0 7 8 2 4]
 [1 4 9 7 2 6 0 3 3 5]
 [7 3 8 4 9 2 0 1 6 5]
 [9 9 7 0 6 1 1 3 2 4]
 [2 5 8 3 0 0 6 6 9 4]
 [0 1 2 6 8 3 5 7 4 9]
 [3 8 0 4 6 2 2 9 1 5]
 [5 8 4 7 3 2 6 6 1 9]]
vt_50sample [[4 7 5 2 1 8 0 3 6 9]
 [6 8 1 9 0 3 7 2 4 5]
 [6 3 1 9 5 0 7 8 2 4]
 [1 4 9 7 2 6 0 3 8 5]
 [7 3 8 4 9 2 0 1 6 5]
 [9 5 7 0 6 8 1 3 2 4]
 [2 8 5 3 7 0 1 6 9 4]
 [0 1 2 6 8 3 5 7 4 9]
 [3 8 0 4 6 2 7 9 1 5]
 [8 5 4 7 3 2 0 6 1 9]]
Epoch 10110: Training cost= 0.3459, Training acc= 0.7698, Validation cost= 0.3812, Validation acc= 0.7702
Epoch 10120: Training cost= 0.3509, Training acc= 0.7699, Validation cost= 0.4257, Validation acc= 0.7703
Epoch 10130: Training cost= 0.3924, Training acc= 0.7700, Validation cost= 0.3836, Validation acc= 0.7704
Epoch 10140: Training cost= 0.4254, Training acc= 0.7700, Validation cost= 0.4982, Validation acc= 0.7704
Epoch 10150: Training cost= 0.3772, Training acc= 0.7701, Validation cost= 0.4529, Validation acc= 0.7705
Epoch 10160: Training cost= 0.3463, Training acc= 0.7702, Validation cost= 0.4122, Validation acc= 0.7706
Epoch 10170: Training cost= 0.3674, Training acc= 0.7703, Validation cost= 0.3648, Validation acc= 0.7706
Epoch 10180: Training cost= 0.4266, Training acc= 0.7703, Validation cost= 0.3871, Validation acc= 0.7707
Epoch 10190: Training cost= 0.3823, Training acc= 0.7704, Validation cost= 0.3703, Validation acc= 0.7708
Epoch 10200: Training cost= 0.3884, Training acc= 0.7705, Validation cost= 0.4039, Validation acc= 0.7709
tm  [-0.   0.4 -0.4  2.1 -0.8 -1.  -0.3 -0.6 -0.3 -0.6  7.7 -0.4  0.1  0.2 -0.8  7.  -0.1 -0.6 -0.2 -1.  -0.4  0.7 -0.1 -0.4 -1.4 -0.2 -0.2 -0.2  4.1  0.8  3.4 -1.2  2.3  2.4 -0.2 -0.1  1.6  3.  -0.8 -0.6  0.6  4.5  1.6 -0.4 -0.2 -0.5  3.2 -0.8  0.9 -0.5 -0.5 -0.3 -0.4  3.9 -1.8  2.4 -0.2  2.3 -0.2 -0.6 -0.9 -1.  -0.6 -0.2  2.2 -1.  -0.2  3.  -0.1 -0.6 -0.4 -1.3 -0.4 -0.4 -1.8  0.5 -0.9 -0.2 -0.2 -0.4  8.1 -0.  -0.8 -0.2 -1.   4.9  1.2 -0.1  1.3 -0.4 -0.7  0.5 -0.3  0.3 -0.4 -0.7  0.3 -0.6 -0.3  0.3  2.4 -0.1 -1.2 -0.1 -0.5 -0.3 -1.2  2.8  3.3 -1.  -0.1 -0.6 -0.6 -0.5 -0.8  6.9  0.6 -0.5 -0.4  2.2 -0.3  3.5  0.3 -0.3 -0.4 -0.8  1.2 -0.7  2.4  0.5  3.6 -0.6  0.5 -0.1  7.9 11.7 -0.2 -0.4 -0.8 -1.1 -0.9  0.4 -0.2 -0.1 -0.6  0.3 -0.2 -1.   4.6  0.8  0.  -0.4  2.3 -1.  -0.4 -0.4 -0.5 -0.1 -1.4 -0.8 -0.4  1.   0.1 -0.2  0.5  0.4  0.5 -0.6 -0.4  0.9 -0.2  0.8 -0.8 -0.1 -0.3 -1.7 -1.6 -0.6  4.6 -0.7 -1.8  1.  -0.2 -1.3 -0.8  1.2  4.3 -0.1 -0.7  0.9 -0.1 -0.6 -0.9 -0.9  6.1 -0.1 -0.7  1.1 -0.3 -0.7 -0.2 -0.6 -0.6 -0.4 -0.9 -0.9  1.6 -0.1 -3.2 -0.3 -0.1  4.4 -0.7  0.2 -0.1  1.5  2.3 -0.7  0.6  0.2 -0.1 -0.4  0.5 -0.4  1.9  2.6  0.6  0.6 -0.2  4.8 -0.2  0.5 -0.2 -2.4 -1.3  2.3 -0.1 -0.4 -0.2 -1.8 -0.1 -0.9 -0.4 -0.  -1.3 -0.5 -0.1 -0.3 -0.4  0.1 -1.9 -0.  -0.4 -0.3  0.9  2.4]
ty_50sample [[5 2 2 9 4 3 7 8 1 0]
 [9 8 6 7 2 4 5 0 3 1]
 [2 3 7 8 5 6 1 9 0 4]
 [5 8 1 3 4 0 9 7 6 2]
 [1 9 0 5 4 4 7 6 2 3]
 [2 0 6 4 3 7 8 5 9 1]
 [0 6 3 8 7 5 5 4 1 2]
 [7 7 4 3 3 8 2 1 5 5]
 [1 2 5 0 4 8 3 6 9 7]
 [9 2 5 6 7 0 3 8 4 1]]
tt_50sample [[5 6 2 9 4 3 7 8 1 0]
 [9 8 6 7 2 4 5 0 3 1]
 [2 3 7 8 5 6 1 9 0 4]
 [5 8 1 3 0 4 9 7 6 2]
 [1 9 0 5 8 4 7 6 2 3]
 [2 0 6 4 3 7 8 5 9 1]
 [6 0 8 3 7 9 5 4 1 2]
 [7 4 9 0 3 8 2 1 6 5]
 [1 2 5 0 4 8 3 6 9 7]
 [9 2 5 6 7 0 3 4 8 1]]
vm  [-0.6  0.4  6.6 -1.1 -1.8 -0.5 -0.6  0.7 -0.5 -0.2 -3.3  2.3 -1.3 -0.3 12.5 -0.7  0.4  0.5 -0.1  5.4 -0.3 -0.2  3.2 -0.1 -0.7 -0.  -0.4 -0.1 -0.8 -0.7 -1.4 -0.2 -0.4  1.3 -0.3 -0.4 -0.   1.9  0.5 -0.6 -0.5  2.3  0.6  3.5 -0.7  0.3 -3.4  1.1  2.   5.3 -0.6 -0.8 -0.6  2.8 -0.5 -1.8 -0.3  3.8  1.6  4.8  5.7 -0.5  1.6  2.5 -1.3 -0.9 -0.3 -0.9 -0.   0.7 -0.2  1.   2.3  0.3 -5.2  0.1 -0.2 -0.2 -0.3  0.7 -4.5 -0.2  1.5 -0.3 -0.9  2.  -0.1 -0.3  1.  -0.3  1.3 -0.6 -0.6 -0.  -1.  -0.3  0.7 -2.2 -0.6 -0.1  1.1  4.7  0.8 -0.3 -0.2 -0.1 -2.6 -1.4 -1.7  3.5  0.2 -0.  -0.2 -0.4  2.1 -0.2  1.1  1.9  0.3 -0.4  0.4 -1.3 -0.5 -0.3 -0.2 13.7  0.8 -0.2  4.2  5.4 -0.9 -0.2 -0.   0.2 -5.1 -5.2 -0.1 -0.6 -0.3  2.   2.8 -0.6  0.9  0.2 -0.6 -0.   0.1 -0.8 -0.5 -0.5  2.8 -0.5  3.4  1.7 -0.5 -0.4 -0.5  0.2  5.5 -0.3 -0.  -1.4 -0.  -0.2 -0.5 -0.3 -0.1 -0.   0.1 -0.6  0.8  0.8 -0.6 -0.3 -0.3  2.3  2.4 -0.7  1.2  2.1 -0.7 -0.  -0.6 -0.7 -0.  -0.4 -0.9 -0.8 -0.8  2.6 -0.2  0.1  2.3 -0.8 -1.2 -0.8 -1.  -0.5 -0.1 -0.3  0.2  1.4  0.3 -0.3 -0.  -2.3 -0.3 -0.3  4.8 -0.3 -1.1 -0.5 -0.3  1.2 -0.2 -0.2 -0.5  0.1  0.8 -0.4 -1.4  0.  -0.3 -0.3 -1.   1.1 -1.4  0.4 -0.2  1.8 -0.4  0.3 -0.4  3.6  2.5 -1.7  0.6 -1.8  1.1 -2.3 -0.4 -1.1 -0.1 -0.7 14.1  2.7 -0.4 -0.2 -0.5 -0.6 10.  -0.5  0.8 -0.1  4.3 -1.3]
vy_50sample [[7 8 0 5 1 4 4 2 9 9]
 [5 0 1 2 4 7 7 8 9 3]
 [3 2 2 7 9 9 5 6 4 1]
 [0 2 5 6 9 8 1 7 4 3]
 [0 0 8 8 7 5 5 4 1 1]
 [1 6 5 7 4 8 0 3 2 9]
 [0 1 6 2 7 4 9 3 5 8]
 [8 9 2 5 4 3 7 0 1 6]
 [7 2 4 1 9 5 5 8 0 3]
 [9 4 5 0 2 3 1 8 7 7]]
vt_50sample [[7 8 0 5 3 1 4 2 6 9]
 [5 0 1 4 2 6 7 8 9 3]
 [3 2 7 0 8 9 5 6 4 1]
 [0 2 5 6 9 8 1 7 4 3]
 [9 0 8 2 7 3 5 4 1 6]
 [1 6 5 7 4 8 0 3 2 9]
 [0 1 6 2 4 7 9 3 5 8]
 [8 9 2 5 4 3 7 0 1 6]
 [7 2 4 1 9 5 6 8 3 0]
 [9 4 5 2 0 3 1 8 6 7]]
Epoch 10210: Training cost= 0.4229, Training acc= 0.7706, Validation cost= 0.3823, Validation acc= 0.7709
Epoch 10220: Training cost= 0.3788, Training acc= 0.7706, Validation cost= 0.3939, Validation acc= 0.7710
Epoch 10230: Training cost= 0.3419, Training acc= 0.7707, Validation cost= 0.3410, Validation acc= 0.7711
Epoch 10240: Training cost= 0.3472, Training acc= 0.7708, Validation cost= 0.3472, Validation acc= 0.7711
Epoch 10250: Training cost= 0.3516, Training acc= 0.7709, Validation cost= 0.3677, Validation acc= 0.7712
Epoch 10260: Training cost= 0.3937, Training acc= 0.7709, Validation cost= 0.3464, Validation acc= 0.7713
Epoch 10270: Training cost= 0.3611, Training acc= 0.7710, Validation cost= 0.3648, Validation acc= 0.7714
Epoch 10280: Training cost= 0.4256, Training acc= 0.7711, Validation cost= 0.4558, Validation acc= 0.7715
Epoch 10290: Training cost= 0.3954, Training acc= 0.7712, Validation cost= 0.4878, Validation acc= 0.7715
Epoch 10300: Training cost= 0.3940, Training acc= 0.7712, Validation cost= 0.3459, Validation acc= 0.7716
tm  [-0.7 -0.2  4.4  2.3 -1.2 -0.2  0.  -0.7 -0.5 -1.   5.8  1.9 -0.2  0.7  5.6 -0.2  1.9 -0.5  0.9  0.  -0.5 -0.5 -2.2  0.4 -1.2  1.3  0.4 -0.  -1.2 -1.2  2.   0.1  0.2  8.1 -0.6  0.2  1.1  1.6 -0.9 -0.6 -0.1  1.8  3.  -0.6 -0.8 -0.3 -1.6  0.3 -0.1 -3.6 -1.3 -0.6 -0.9  2.7 -0.2 -0.4 -0.1  6.1 -0.3 -0.4  5.4 -0.5 -0.5  1.5 -0.8 -0.1 -0.3 -0.4 -0.3  1.8  0.1  2.4 -0.4 -0.2 -3.1 -0.2  1.4 -0.8 -0.6 -0.9  6.  -0.5 -0.7 -0.7 -0.1  1.5 -0.4 -0.3  1.   0.9 -0.4  0.2  1.1  2.3 -0.7 -0.4  2.7 -1.   0.6 -0.4  4.1 -0.9  1.7 -0.2 -0.3 -0.1 -2.3  1.3  1.5 -0.2  0.6 -0.  -0.4 -0.3  1.9 -0.4 -0.3  0.   0.1 -0.3  0.   1.8 -0.   0.3 -0.8  6.2  1.9 -0.3  1.9  8.1 -0.2 -0.4 -0.4 -0.3  1.6  9.2 -0.3 -0.2  1.8 -0.1 -0.2  0.3  0.1 -0.1 -0.  -0.5 -0.4 -0.6  5.8 -0.5 -0.1 -0.6 -1.6  0.4 -0.9 -0.5 -0.1 -0.1  0.9  0.3 -0.9  0.6 -0.3  0.1 -0.2 -0.3  0.   0.2 -0.1  0.1 -1.3  3.  -0.4 -0.8 -0.7 -0.9 -0.4 -1.4  4.8 -0.4 -1.7 -0.  -0.1 -1.1  1.5 -0.5 -0.7 -0.8 -0.3  7.2 -0.1  1.8  0.9 -0.9 -1.1  0.2 -1.3 -0.3 -0.2 -0.3 -0.1 -0.  -0.3 -0.7  0.8 -2.5  0.9  0.2 -4.8 -0.5 -0.7 -0.7 -0.   1.2 -0.8 -0.3  2.8 -0.4  0.2 -0.3 -0.2  1.6  0.7 -0.4 -0.6 -1.4 -0.3  0.1 -0.7  0.9 -0.7  1.9 -0.2 -3.4  3.8 -1.  -0.3 -1.5 -0.1 -3.2 -0.5 -1.8 -0.6 -0.1 -1.   3.8 -0.4 -0.2 -0.6 -0.4 -1.5 -1.4 -0.7 -0.7  5.4 -1.9]
ty_50sample [[5 3 0 1 6 7 2 9 4 8]
 [5 2 2 8 8 3 6 9 0 7]
 [0 9 3 7 8 6 5 4 1 2]
 [7 1 2 9 8 0 0 4 5 6]
 [5 7 9 0 4 8 2 1 3 6]
 [0 5 1 7 6 4 9 9 3 2]
 [0 3 9 4 8 2 6 7 5 1]
 [7 0 1 5 2 9 6 3 8 4]
 [3 4 9 7 5 0 2 6 1 8]
 [5 1 0 8 2 4 3 7 9 6]]
tt_50sample [[5 3 0 1 7 6 2 9 4 8]
 [5 2 1 4 8 3 6 9 0 7]
 [0 9 3 7 8 6 5 4 1 2]
 [7 1 2 9 8 0 3 4 5 6]
 [7 5 9 0 4 8 2 1 3 6]
 [0 5 1 7 6 4 8 9 3 2]
 [0 3 9 4 8 2 6 7 5 1]
 [7 0 1 5 2 9 6 3 8 4]
 [3 4 9 7 5 0 6 2 1 8]
 [5 1 8 0 2 4 3 7 9 6]]
vm  [-0.8  2.2  1.9  4.8 -1.2  0.  -0.2 -0.7 -1.3 -1.2  2.5  1.4 -0.4 -0.2 -0.2  1.3  0.6  0.2  0.7 -0.9 -0.5 -0.3 -1.3  1.5 -1.6  2.8 -0.2 -0.2 -0.2  1.1  2.2 -0.2  0.8  5.1 -1.4  2.2  3.7 -0.3  0.6 -0.2 -0.2 -2.4 -0.1 -0.6 -1.1 -0.4  3.9  0.1 -1.2 -2.4 -0.8 -0.3  3.  -1.  -1.4  0.6 -0.  -0.7 -1.5 -0.4  2.4  1.2 -0.3 -0.8  0.7 -0.4 -0.6 -0.5 -0.2  2.1 -0.2 -0.1  0.1 -0.3  0.7 -0.4  2.7 -1.1  1.  -0.4  9.5 -0.2 -0.4 -0.1  1.1 -2.2  0.7 -0.2  2.   1.  -0.   0.8  3.1  2.4 -0.4  0.  -0.4  1.2 -0.3 -0.   4.9 -0.8  1.3 -0.4 -0.2  0.4 -0.2  2.8  0.8 -1.1 -0.6 -0.3  0.2  2.6 -0.2  1.7 -0.1 -1.  -0.  -0.4 -0.2  3.6 -0.1  0.6 -0.5 -0.2  3.1  6.2 -1.4  3.4 -0.2 -0.3  1.5 -0.1  3.6  9.2  0.3  0.7  3.8 -0.9  1.  -0.7 -0.2 -0.3 -0.  -0.8  0.2  0.5 -0.8  0.2 -0.8 -0.3 -1.3  0.2 -0.6 -0.2 -0.2 -0.2 -0.7 -0.5 -0.7  1.   0.1  0.  -0.3 -0.3  2.   3.5 -0.1  1.9 -1.1 -0.8 -0.2  0.5 -0.7  4.1 -0.9  0.2  1.4 -0.5  2.7 -0.2  1.  -1.4 -1.  -0.6 -0.4 -0.2 -0.2  0.1 -0.2  0.4 -0.5 -1.3 -0.1  4.8  1.9  3.3 -0.6 -0.5  0.3 -0.7 -0.6 -0.7  0.5  2.2 -0.4 -0.4  2.4 -0.5 -0.8 -0.1 -0.7  4.7 -0.4 -0.3  2.  -0.4  0.4  1.3 -0.9  0.8  0.6 -0.6 -0.1 -0.  -0.8  0.8  0.5 -1.  -0.  -0.4 -0.3  1.7  0.1 -0.1 -0.4  1.2 -0.1 11.3 -0.6  6.1 -0.8 -0.1 -1.7 -1.5  0.4  0.3  0.6 -0.7 -2.1 -0.6  0.2 -0.5  2.8 -0.4]
vy_50sample [[3 6 6 9 7 4 0 2 8 5]
 [0 9 1 2 4 6 5 8 3 7]
 [1 0 5 8 6 7 7 2 2 4]
 [0 1 2 6 7 5 8 4 9 3]
 [4 1 6 7 3 5 2 8 0 9]
 [0 6 3 2 5 8 1 1 9 4]
 [5 4 4 0 2 1 3 9 6 7]
 [7 2 4 6 8 9 0 5 3 1]
 [6 0 9 4 5 7 2 8 3 1]
 [7 1 2 8 4 5 0 0 6 3]]
vt_50sample [[3 6 1 9 7 4 0 2 8 5]
 [0 9 1 2 4 6 5 8 3 7]
 [1 0 5 8 6 7 3 9 2 4]
 [0 1 2 6 7 8 5 4 9 3]
 [4 1 6 7 3 5 2 8 0 9]
 [0 6 2 3 5 8 7 1 9 4]
 [8 5 4 0 2 1 3 9 6 7]
 [2 7 4 6 8 9 0 5 3 1]
 [6 0 9 4 5 7 2 8 3 1]
 [7 1 2 8 4 5 0 9 6 3]]
Epoch 10310: Training cost= 0.3730, Training acc= 0.7713, Validation cost= 0.3667, Validation acc= 0.7717
Epoch 10320: Training cost= 0.3626, Training acc= 0.7714, Validation cost= 0.3981, Validation acc= 0.7717
Epoch 10330: Training cost= 0.4183, Training acc= 0.7714, Validation cost= 0.3592, Validation acc= 0.7718
Epoch 10340: Training cost= 0.3309, Training acc= 0.7715, Validation cost= 0.4110, Validation acc= 0.7719
Epoch 10350: Training cost= 0.3576, Training acc= 0.7716, Validation cost= 0.3218, Validation acc= 0.7720
Epoch 10360: Training cost= 0.3877, Training acc= 0.7717, Validation cost= 0.4143, Validation acc= 0.7720
Epoch 10370: Training cost= 0.3516, Training acc= 0.7717, Validation cost= 0.3194, Validation acc= 0.7721
Epoch 10380: Training cost= 0.3636, Training acc= 0.7718, Validation cost= 0.3419, Validation acc= 0.7722
Epoch 10390: Training cost= 0.3741, Training acc= 0.7719, Validation cost= 0.3967, Validation acc= 0.7723
Epoch 10400: Training cost= 0.3504, Training acc= 0.7720, Validation cost= 0.4088, Validation acc= 0.7723
tm  [-0.2  2.   6.4 10.8 -1.  -1.  -0.4 -0.6 -1.4 -0.6 -3.1  1.  -0.6 -0.1 -0.1 -0.2 -0.1  0.4  0.5 -0.8 -0.7 -0.6  2.4 -0.  -0.6 -0.2 -0.2 -0.2 -0.2  1.8 -1.6  0.1  2.2 -0.9 -0.6  0.4  2.  -0.7 -0.6 -0.3 -0.5 -1.6 -0.4 -1.7 -0.3 -0.2  4.   1.8  2.4  4.5 -0.5 -0.3  0.2 -1.6 -0.7  1.2  0.5  0.1 -0.6  5.6 -0.8  0.4 -0.1 -0.2 -1.1 -0.5 -0.2 -0.7 -0.   2.6 -0.6 -0.   1.8 -0.1  0.8 -0.1 -0.1 -0.2 -0.2 -0.2 -0.2 -0.3 -0.6 -0.3 -0.9 -1.9  0.3  0.2  1.1 -0.1  0.3  0.3  0.8  1.5 -0.2 -0.2 -0.1 -0.6 -0.5 -0.4  1.9  1.8 -0.3 -0.1 -0.3  1.2  0.7 -1.7 -1.6 -1.7 -0.3 -0.2 -0.4  1.3 -0.2  0.9 -0.1 -0.2 -0.3 -0.   0.1  6.1 -0.2 -0.1 -0.  -0.3  1.1  8.6 -0.9 -0.1  3.2 -0.5  0.4 -0.1  5.5  4.  -0.4  0.4 -0.2  0.8  1.8 -1.2  0.7  0.5 -0.6  0.3 -0.3 -0.4 -1.6 -0.4 -0.9  0.2  3.1 -0.2 -0.3 -0.6 -0.4 -0.1 -1.4 -0.9 -0.2  5.2 -0.3 -0.4 -1.  -0.3  1.6  1.8  1.1  3.2 -0.5 -1.  -0.1  0.7 -0.2  6.1 -1.   2.1  3.8  0.9  3.3  0.4  0.1 -0.2 -0.7  0.3  2.6 -0.2 -0.7 -0.   0.2 -0.2 -0.9 -0.6  5.   1.3  2.6 -0.1 -0.3 -0.3 -0.2 -0.1  0.4 -0.2  0.1  2.7 -1.2 -0.  10.3  0.4 -0.7  1.1 -1.1  0.2 -0.5 -0.5  7.4 -0.1  1.2 -0.3 -0.8 -0.1 -0.4 -0.7  2.1  2.2 -1.3  0.6 -0.1  0.9  2.  -0.7 -0.2  6.4  0.7 -1.5 -0.   3.5  1.  16.3 -0.5  8.7 -0.2 -0.3  2.  -1.9 -0.3 -0.3 -0.5 -0.4 -0.1 -0.9 -0.4  0.4  2.7  2.7]
ty_50sample [[6 8 9 7 3 0 1 2 4 5]
 [5 1 2 8 4 0 6 7 3 9]
 [2 4 6 1 3 9 9 0 8 5]
 [9 3 0 6 8 7 2 5 4 1]
 [4 5 2 8 6 7 3 0 1 9]
 [6 7 2 0 8 3 1 9 5 4]
 [8 9 5 7 1 0 3 2 6 4]
 [8 3 0 7 7 6 6 2 4 9]
 [9 6 4 8 0 5 2 7 3 1]
 [5 8 2 6 3 0 0 4 9 7]]
tt_50sample [[6 8 9 7 3 0 1 2 4 5]
 [5 1 2 8 4 0 6 7 3 9]
 [2 4 6 1 3 9 7 0 8 5]
 [9 3 0 6 8 7 2 5 4 1]
 [4 5 2 8 6 7 3 0 9 1]
 [6 7 0 2 8 3 1 9 5 4]
 [8 9 5 7 1 0 3 2 6 4]
 [8 3 0 5 7 6 2 4 1 9]
 [9 6 4 8 0 5 2 7 3 1]
 [5 8 2 6 3 0 4 1 9 7]]
vm  [-0.7  1.4  2.7 10.8 -1.  -0.6 -0.4 -0.4 -0.4 -0.6 -0.3 -0.1  0.  -0.1 -1.4  4.6  0.  -0.4 -0.2 -1.1 -0.2 -0.3  0.6 -0.4 -1.1 -0.3 -0.2  0.1  2.9 -0.1 -1.4 -0.9  0.8 -1.9 -1.2 -0.1  2.3 -0.1 -0.9 -0.6 -0.1  1.4  0.8 -1.7 -0.  -0.   4.   0.1  0.   0.4 -0.6 -0.3  0.4 -0.2 -1.2  3.4 -0.1  5.4 -0.5  4.8 -0.6 -0.6 -0.6 -0.2 -0.4 -0.2 -0.3 -0.2 -0.3 -0.  -0.  -1.3  0.4 -0.2 -0.3  0.7 -0.4 -0.3 -0.5 -0.1  2.2 -0.2 -1.1  0.3 -0.4  2.2 -0.1  0.2  2.3 -0.6 -0.6  2.4  1.2  2.1  0.3 -0.3  2.1 -0.4 -0.1  0.1  2.9 -1.1 -0.5 -0.1 -0.3 -0.  -0.5 -1.3 -0.  -1.6 -0.2 -0.9 -0.4  0.8 -1.   7.6  0.2 -0.7 -0.4  0.8 -0.3  5.8 -0.  -0.6 -0.2 -1.6  3.   3.7  0.8  1.5  2.6 -0.8  0.5 -0.1  9.9  8.2 -0.5 -0.  -0.6 -0.7 -0.2 -0.6  0.  -0.2 -0.9  0.9 -0.1 -0.8  4.9  0.9 -0.9 -0.2  2.  -0.4 -0.1 -0.4 -0.5 -0.3 -1.5 -1.  -0.6  4.  -0.4 -0.3 -0.7 -0.2  2.8 -0.1 -0.3  2.9 -0.4 -0.1 -0.9 -0.1 -0.  -1.3 -1.5 -0.   4.6 -0.4 -1.5  0.6 -0.2 -0.8 -0.9  2.   2.9 -0.1 -0.8  2.4 -0.1 -0.2 -1.1 -0.7  4.2 -0.2  0.3  1.2 -0.5 -1.  -0.4 -0.4 -0.3 -0.4  0.  -0.2  0.8 -0.2 -0.4  0.5 -0.5  4.6 -0.8  0.2 -0.9 -0.2  7.2 -0.3  0.3 -0.3 -0.4 -0.1 -0.3 -0.4  2.   4.1 -0.4  0.5 -0.3  3.7  0.9 -0.2 -0.  -0.2 -0.9 -0.3 -0.5  1.2 -0.4  0.6 -0.1  0.2  0.3 -0.2  0.5 -1.2  0.3  0.5 -0.5 -0.6 -0.7 -1.  -0.7 -0.1  3.4  0.9]
vy_50sample [[6 5 3 8 8 2 1 7 4 0]
 [0 6 7 5 4 2 8 3 1 1]
 [8 4 9 6 3 3 5 5 7 2]
 [8 7 6 0 4 5 2 1 3 9]
 [6 0 7 2 3 1 8 5 9 4]
 [1 7 6 5 0 0 9 3 2 2]
 [2 7 7 3 8 5 0 0 6 1]
 [7 9 3 4 2 0 1 6 5 8]
 [9 6 0 2 1 4 8 7 3 5]
 [7 0 9 2 6 8 3 3 1 5]]
vt_50sample [[6 5 3 9 8 2 1 7 4 0]
 [0 6 7 5 4 2 8 3 9 1]
 [8 4 9 6 0 3 5 1 7 2]
 [8 7 6 0 4 5 2 1 3 9]
 [6 0 7 3 2 8 1 5 9 4]
 [1 7 6 5 9 0 4 3 8 2]
 [2 9 7 8 3 5 0 4 6 1]
 [7 9 3 4 2 0 1 6 5 8]
 [9 6 0 2 1 4 8 7 3 5]
 [7 0 9 2 6 4 8 3 1 5]]
Epoch 10410: Training cost= 0.4477, Training acc= 0.7720, Validation cost= 0.3369, Validation acc= 0.7724
Epoch 10420: Training cost= 0.3558, Training acc= 0.7721, Validation cost= 0.3553, Validation acc= 0.7725
Epoch 10430: Training cost= 0.3440, Training acc= 0.7722, Validation cost= 0.3482, Validation acc= 0.7726
Epoch 10440: Training cost= 0.3869, Training acc= 0.7723, Validation cost= 0.4189, Validation acc= 0.7726
Epoch 10450: Training cost= 0.3810, Training acc= 0.7723, Validation cost= 0.3755, Validation acc= 0.7727
Epoch 10460: Training cost= 0.3892, Training acc= 0.7724, Validation cost= 0.3304, Validation acc= 0.7728
Epoch 10470: Training cost= 0.3760, Training acc= 0.7725, Validation cost= 0.3212, Validation acc= 0.7729
Epoch 10480: Training cost= 0.4103, Training acc= 0.7725, Validation cost= 0.5360, Validation acc= 0.7729
Epoch 10490: Training cost= 0.4178, Training acc= 0.7726, Validation cost= 0.4161, Validation acc= 0.7730
Epoch 10500: Training cost= 0.4002, Training acc= 0.7726, Validation cost= 0.4025, Validation acc= 0.7730
tm  [-0.4  0.9  3.3  9.1 -1.1 -0.4 -0.1 -0.8 -1.2  0.5 -1.  -0.5 -0.4 -0.4 -0.5 -0.9 -0.  -0.5 -0.1 -1.6 -0.5 -0.3  4.2  0.6 -1.3  1.8 -0.2 -0.3 -1.1 -0.4 -1.1  1.  -0.3 -1.2  0.5  0.8  3.9 -0.5 -0.1 -0.2 -0.3  6.8  2.1 -1.1 -0.4 -0.2  3.1  0.6  0.6  8.7 -0.6 -0.2 -0.4 -0.4  1.8  2.  -0.6  4.2 -0.9  4.9 -0.1 -0.5 -0.8  1.  -0.3  0.8  0.2 -0.5  1.2 -0.1 -0.6  2.9 -0.3 -0.6 -0.2 -0.   1.   0.2  1.  -0.   0.7 -0.1 -0.7 -0.  -0.2  7.9 -0.1 -0.1 -0.4 -0.2 -0.4 -0.2 -0.8  1.4 -0.2 -0.1  2.3 -0.3 -0.  -0.2 -0.3  4.4 -0.2 -0.3  0.4 -0.1 -0.5 -1.1 -0.4 -1.6 -0.6 -0.1 -0.1  0.1  1.6 -1.3 -0.6 -0.7 -0.5 -0.2 -0.3  5.9 -0.2 -0.4 -0.1 -0.6 -0.2  4.3 -0.2 -1.4  1.6 -0.4 -0.8 -0.1  6.1  3.2 -0.3 -0.5 -0.5 -0.4  0.3 -0.9  0.1  0.  -0.3 -0.3 -0.1 -0.4  3.7  0.3 -1.  -0.3  2.  -0.3 -0.2 -0.2 -0.1 -0.2 -0.9 -0.5  0.2  2.5 -0.4 -0.3 -0.8 -0.2 -0.9 -0.7 -0.3  2.4  1.4  1.   0.3 -0.2 -0.3 -0.9 -0.9 -0.2  2.5 -0.2 -1.7 -0.1  0.3 -1.1  0.  -0.1  1.2 -0.2  1.1  1.8 -0.1 -0.7 -0.6 -0.9  2.6  0.7 -0.3  1.7 -0.4 -0.  -0.6 -0.3 -0.1 -0.3  0.4 -0.5  0.1  1.2 -0.2  0.6 -0.  -0.7 -0.2  1.5 -0.7 -0.5  5.  -0.3 -0.3 -0.3 -0.5 -0.1 -0.1 -0.8  4.5 -0.3 -0.8  0.9  0.4 -0.2 -0.4 -0.4 -0.4 -0.3  3.8 -0.6  2.3  1.2  1.2 -0.3 -0.3 -0.3 -0.2 -0.2  1.5 -0.9  0.7  1.1 -0.6 -0.2 -0.2 -0.6 -0.1  0.2  1.8  8.3]
ty_50sample [[0 0 6 8 9 1 7 7 4 3]
 [6 8 4 1 3 7 2 5 5 9]
 [7 5 8 1 9 2 3 0 4 6]
 [4 4 3 3 0 0 6 5 2 7]
 [7 3 4 2 5 9 0 6 1 8]
 [1 0 7 7 8 5 6 9 3 3]
 [3 1 5 4 7 9 2 0 6 8]
 [3 7 9 4 1 0 0 2 6 5]
 [2 2 3 1 4 7 5 6 9 9]
 [8 3 4 9 6 2 5 5 7 1]]
tt_50sample [[0 5 6 8 9 1 7 2 4 3]
 [6 8 4 1 3 7 2 5 0 9]
 [7 5 8 1 9 2 3 0 4 6]
 [4 9 1 3 0 8 6 5 2 7]
 [7 3 4 2 5 9 6 0 1 8]
 [1 0 2 7 8 5 6 4 9 3]
 [3 1 5 4 7 9 2 0 8 6]
 [3 7 9 4 1 0 8 2 6 5]
 [2 8 3 1 4 7 5 0 6 9]
 [8 3 4 9 6 2 0 5 7 1]]
vm  [-0.7  0.5 -1.5  6.6 -0.5 -0.1 -0.3 -0.3 -0.7 -0.2  0.4  0.7 -0.6 -0.8 -2.9 -1.3 -0.  -0.2 -0.2 -1.1 -0.7 -0.1 -0.1  0.2 -1.4  3.9 -0.4 -0.2 -1.5 -0.9  1.7 -0.1  0.2 -2.2 -0.1 -0.1  3.7 -0.8 -0.  -0.5 -0.6  3.6  0.8 -0.7 -0.4 -0.2  3.4  1.2  0.5 -0.  -0.4 -0.5  1.3 -1.2  0.7  5.3 -0.8  2.4 -0.3  0.1 -0.  -0.4 -0.2  1.5 -0.4 -0.2 -0.2 -0.   0.9  0.5 -0.5  2.6 -0.1 -0.6 -0.2 -0.3  1.3 -0.   0.9 -0.1  8.6 -0.  -0.5 -0.1 -0.1  3.4  0.4 -0.3  0.4 -0.6 -0.2 -0.4 -0.4  1.5 -0.2 -0.2  1.7 -0.2 -0.5 -0.4 -0.  -1.4 -0.1 -0.4 -0.1  0.5 -0.4  1.6  0.5 -1.5 -0.8 -0.  -0.1  0.3  3.1 -1.3 -0.5 -0.5  0.5  0.5 -0.2  6.  -0.1  0.4 -0.3 -3.1  0.4  7.6 -0.1 -0.7  1.  -0.5 -0.6 -0.1 12.7 10.2 -0.2 -0.6 -0.3 -0.6  1.5 -1.  -0.1  0.5 -0.4 -0.3  0.9 -0.3  5.8 -0.4 -0.6  0.3 -0.4  0.7 -0.2 -0.5 -0.1 -0.3 -1.  -0.5  0.1  1.7 -0.4 -0.6 -0.9 -0.7 -0.6 -0.2 -0.3  1.9 -0.   0.  -0.  -0.1 -0.  -1.8 -1.1  1.6  2.6 -0.1 -1.4  0.2  0.3 -1.  -0.1 -0.2  1.3  2.7  1.2  4.1 -0.4 -0.5 -0.7 -1.1  2.8  1.6  1.3  0.3 -0.4 -0.1 -0.3  0.1 -0.2 -0.5  0.8  1.3  0.4  0.4 -1.5  0.4 -0.4 -1.  -0.7  1.6 -0.5 -0.4  3.8 -0.5 -0.8 -0.6 -0.1 -0.4 -0.1 -0.7  3.  -1.2 -1.1  0.7  0.9  0.4  0.4 -0.5 -0.5 -1.1  4.6  3.9  1.5  2.2  0.3  3.8 -0.1  1.6 -0.4 -0.2 -1.4 -1.6  0.6 -0.  -0.4 -0.5 -2.  -0.7 -0.   1.   2.2  4.6]
vy_50sample [[0 0 9 5 1 3 4 2 2 7]
 [0 4 2 5 7 7 9 1 6 8]
 [7 0 2 5 4 3 8 8 6 9]
 [5 4 4 9 3 3 8 6 0 2]
 [6 6 1 3 5 2 7 8 8 0]
 [6 7 8 3 3 4 5 2 9 1]
 [2 1 5 3 0 7 6 8 4 4]
 [7 4 8 3 6 5 0 9 1 2]
 [8 5 7 1 3 2 2 4 6 6]
 [6 5 2 7 4 1 8 3 9 0]]
vt_50sample [[6 0 9 5 1 4 3 8 2 7]
 [0 4 2 5 7 3 9 1 6 8]
 [7 0 2 5 4 3 8 1 6 9]
 [5 4 9 1 7 3 8 6 0 2]
 [6 9 1 5 3 2 7 8 4 0]
 [6 7 8 0 3 4 5 2 9 1]
 [2 1 5 3 0 7 6 8 9 4]
 [7 4 8 3 6 5 0 9 1 2]
 [8 5 7 1 3 2 0 4 9 6]
 [6 5 7 2 4 8 1 3 9 0]]
Epoch 10510: Training cost= 0.3724, Training acc= 0.7727, Validation cost= 0.3744, Validation acc= 0.7731
Epoch 10520: Training cost= 0.3756, Training acc= 0.7728, Validation cost= 0.3833, Validation acc= 0.7732
Epoch 10530: Training cost= 0.3636, Training acc= 0.7728, Validation cost= 0.3494, Validation acc= 0.7732
Epoch 10540: Training cost= 0.3494, Training acc= 0.7729, Validation cost= 0.3481, Validation acc= 0.7733
Epoch 10550: Training cost= 0.3980, Training acc= 0.7730, Validation cost= 0.4488, Validation acc= 0.7734
Epoch 10560: Training cost= 0.3940, Training acc= 0.7731, Validation cost= 0.3467, Validation acc= 0.7735
Epoch 10570: Training cost= 0.3093, Training acc= 0.7731, Validation cost= 0.4181, Validation acc= 0.7735
Epoch 10580: Training cost= 0.4340, Training acc= 0.7732, Validation cost= 0.4149, Validation acc= 0.7736
Epoch 10590: Training cost= 0.4863, Training acc= 0.7733, Validation cost= 0.3503, Validation acc= 0.7737
Epoch 10600: Training cost= 0.3749, Training acc= 0.7733, Validation cost= 0.3704, Validation acc= 0.7737
tm  [ 0.8  0.6 -0.9  3.4 -1.4 -0.2  0.3 -0.5 -0.6 -1.1  4.3  0.2 -0.1 -0.8 -1.1 -0.7 -0.3 -0.5 -0.3 -1.1 -0.9 -0.1 -0.7  1.4 -1.2  4.9 -0.4 -0.3 -1.4 -1.   3.2  0.  -0.5  2.2  0.5  1.2  3.6  2.7  9.3 -1.1 -0.1 -1.1 -0.4  5.5 -1.   0.2  3.6 -0.2  2.  -1.4 -0.7 -0.8  1.8 -0.3  1.8  3.7 -0.6 -0.7 -0.2 -0.7 -0.9 -0.3  0.5  4.3 -0.2 -0.1 -0.1 -0.1  0.2  1.8 -0.3  3.5 -0.5 -0.5  2.   0.4 -0.5 -0.9  1.5  0.5  9.3  0.6 -0.2  0.2 -0.7 -1.1  2.  -0.4  1.5 -0.3  0.5 -0.3 -0.3  0.3  0.7 -0.1 -0.1 -0.2 -0.  -0.2  2.4 -1.  -0.7 -0.6  1.2 -0.2  0.   4.2  2.5 -1.1 -1.   1.  -0.1 -0.4  3.6 -1.6 -0.4  0.  -0.2 -0.1  0.4  5.  -0.3 -0.  -0.4 -1.1 -0.2  4.2  0.2  1.1 -0.3 -0.3 -0.6 -0.4 -1.2 -0.9  0.5 -0.4  3.4 -0.8  0.3 -1.  -0.5 -0.2  0.5 -0.5 -0.2 -0.6  1.  -0.7 -0.4 -0.   0.9 -0.1 -0.2  0.2 -0.1 -0.2  3.2 -0.2 -0.2 -1.6 -0.3 -0.4 -0.1 -0.6 -0.3  1.  -0.   0.9 -0.4 -0.4  0.3 -0.  -0.5  1.1  0.5  1.4 -1.9 -0.2 -0.1 -0.3 -0.3 -1.3  0.6 -0.7  3.2 -0.3  1.6  4.4 -0.  -0.1 -0.7 -0.9  5.6 -0.   1.2 -0.  -0.3  1.2 -0.3 -0.1 -0.5 -0.8 -0.3  1.   0.1  0.6  0.8  0.4 -0.2 -0.5 -0.9 -0.  -0.7 -0.8 -1.3 -0.5 -0.7 -0.1 -0.6 -0.1 -0.1 -1.  -1.2 -1.  -0.5  0.4  0.9  2.9 -1.2 -0.8 -0.5  0.8  4.5  4.1  2.4  2.6  2.5  8.5 -0.4  4.1 -0.5  0.3 -1.3 -1.9  0.2 -0.2 -0.8 -0.9 -2.1 -0.6  7.9 -0.1  2.   1.2]
ty_50sample [[0 9 3 4 2 2 5 8 8 6]
 [4 4 1 3 6 8 2 0 7 5]
 [8 5 0 0 7 9 1 6 4 2]
 [4 0 5 6 8 3 1 1 2 7]
 [0 7 4 5 5 2 1 3 8 9]
 [3 1 5 2 2 6 0 7 8 4]
 [6 5 0 8 1 4 7 3 2 9]
 [7 4 1 3 3 6 2 8 0 5]
 [7 4 6 0 2 5 1 8 9 3]
 [1 2 9 9 3 0 6 7 5 4]]
tt_50sample [[0 9 3 4 2 7 1 5 8 6]
 [9 4 1 3 6 8 2 0 7 5]
 [8 5 3 0 7 9 6 1 4 2]
 [4 0 5 6 8 3 1 9 2 7]
 [0 7 4 5 6 2 1 3 8 9]
 [3 1 5 9 2 6 0 7 8 4]
 [6 5 0 8 1 4 7 3 2 9]
 [7 4 1 9 3 6 2 8 0 5]
 [7 4 6 0 2 5 1 8 9 3]
 [1 2 8 9 3 6 0 7 5 4]]
vm  [-1.7 -0.8 -2.6  0.  -0.7  1.4 -0.1 -0.4  1.  -0.3  5.5 -0.4 -0.2 -0.3 -2.5  1.5 -0.5 -0.8 -0.6 -1.5 -0.4  0.1 -0.2 -0.5 -0.9  0.8 -0.   0.5 -0.  -0.8  6.8 -0.9  1.5  1.9 -0.4 -0.   0.9  0.9  4.  -0.4 -0.   4.  -0.4  2.4 -0.4 -0.5  6.3 -0.1 -1.2 -0.4 -0.6 -0.4  0.1 -0.7 -1.4  5.  -0.6 -0.3  2.5 -2.1  3.2 -0.4 -0.  -0.   2.  -0.3 -0.4  3.4 -0.2 -0.2 -0.6 -0.9 -0.3 -0.3 -0.3  0.4  1.7 -0.1  3.1 -0.5 14.   0.1 -0.7 -0.1  0.7  5.2 -0.  -0.3  0.5 -0.2 -0.4 -0.2 -0.9 -0.6 -0.4 -0.3  0.1 -0.4 -0.1 -0.7  1.1 -0.3  2.6 -0.3 -0.7 -0.4 -0.6  6.2  1.3 -1.3 -0.7 -0.  -0.5 -0.7  2.9  4.1 -0.3 -0.3 -0.3  0.2 -0.3  5.5  0.4  0.  -0.3 -2.4  0.5  5.3  3.6 -1.3 -0.4 -1.  -0.8  0.1  7.7 10.2 -0.2 -0.6  0.2 -0.8 -0.4  1.6 -0.3 -0.  -1.  -0.4  1.3  0.4  5.4  0.1 -0.1 -0.2 -2.  -0.2 -0.3 -0.1 -0.4 -0.1 -0.1 -0.2  1.3 -0.  -0.3 -0.6 -0.5 -0.1 -0.4  1.8 -0.2 -0.3 -0.2  0.6 -0.8 -0.2 -0.3 -1.4 -0.9  1.5 -0.2 -0.2 -0.8 -0.2 -0.3 -1.4 -0.3 -0.6 -0.4  1.2 -0.4  3.1 -0.3 -0.6 -1.3 -0.5 -0.3  0.2  0.8 -0.2 -0.1 -0.7 -0.2  1.4 -0.6 -0.9  0.9  0.5  1.4 -0.  -2.8 -0.2 -0.5  2.5 -0.4  6.1  1.2  0.  -0.7 -0.7 -0.6 -0.6 -0.2 -0.3 -0.2 -1.   2.4 -0.2 -0.7  2.3 -0.1 -0.1 -0.8 -0.2 -0.3 -1.9 -0.1  7.5  0.8 -0.6  0.5  3.5 -0.2  1.7 -0.7 -0.1 -2.8 -1.8  0.5 -0.6 -0.6 -0.4 -2.9  0.3  2.8 -0.3  2.1  7.2]
vy_50sample [[1 4 9 5 6 2 0 3 7 8]
 [3 4 7 6 2 0 9 9 5 5]
 [5 1 0 6 4 3 3 8 7 2]
 [2 6 3 3 7 9 0 8 4 1]
 [8 7 9 9 4 0 1 5 5 6]
 [1 8 4 0 3 9 5 6 2 7]
 [2 3 0 6 8 8 1 9 4 7]
 [6 9 0 2 5 5 8 8 3 1]
 [7 9 9 2 0 6 5 4 8 1]
 [5 4 1 3 9 7 8 2 0 0]]
vt_50sample [[1 4 9 5 6 2 0 3 7 8]
 [3 4 7 6 2 0 1 9 5 8]
 [5 1 0 6 4 3 9 8 7 2]
 [2 6 3 7 5 9 0 8 4 1]
 [8 7 2 9 4 1 0 3 5 6]
 [1 8 4 0 3 9 5 6 2 7]
 [2 3 0 6 8 1 5 9 4 7]
 [6 9 0 2 5 7 4 8 3 1]
 [7 3 9 2 0 6 5 4 8 1]
 [5 4 1 3 9 7 8 2 0 6]]
Epoch 10610: Training cost= 0.3201, Training acc= 0.7734, Validation cost= 0.3944, Validation acc= 0.7738
Epoch 10620: Training cost= 0.3710, Training acc= 0.7735, Validation cost= 0.4612, Validation acc= 0.7739
Epoch 10630: Training cost= 0.3665, Training acc= 0.7736, Validation cost= 0.3537, Validation acc= 0.7740
Epoch 10640: Training cost= 0.3554, Training acc= 0.7736, Validation cost= 0.4116, Validation acc= 0.7740
Epoch 10650: Training cost= 0.3333, Training acc= 0.7737, Validation cost= 0.3562, Validation acc= 0.7741
Epoch 10660: Training cost= 0.3385, Training acc= 0.7738, Validation cost= 0.3236, Validation acc= 0.7742
Epoch 10670: Training cost= 0.3090, Training acc= 0.7739, Validation cost= 0.3936, Validation acc= 0.7742
Epoch 10680: Training cost= 0.3378, Training acc= 0.7740, Validation cost= 0.3565, Validation acc= 0.7743
Epoch 10690: Training cost= 0.4218, Training acc= 0.7740, Validation cost= 0.4434, Validation acc= 0.7744
Epoch 10700: Training cost= 0.3422, Training acc= 0.7741, Validation cost= 0.3395, Validation acc= 0.7745
tm  [-1.5 -0.2  2.7  1.2 -1.3  0.5 -0.2 -0.8 -0.3 -0.1  4.4 -0.7  0.7  0.4  4.1  6.2  0.2 -0.1 -0.1  0.3 -0.5 -0.6  2.7 -0.3 -1.7  1.9 -0.2 -0.1  0.1 -0.9 -0.8 -0.7 -0.7 -0.4 -0.2 -0.2  2.   6.8  3.6 -0.2 -0.3  3.7 -0.   2.5 -1.  -0.5 -0.6 -1.3 -1.5  5.7 -0.7 -0.3 -0.8  9.  -1.3 -0.3 -0.8  2.7  1.   3.   8.7 -0.4 -0.4  0.3  1.2 -0.6 -0.3  2.4 -0.3 -1.1 -0.1 -0.2 -0.1 -0.2 -3.8 -0.2  1.3 -0.4  1.8 -0.1 -1.8 -0.2 -0.1 -0.1  1.8  4.5 -0.8 -0.1  0.  -0.2 -0.9 -0.3 -0.8  0.1 -1.  -0.3  0.9 -1.1 -0.4 -0.6  0.5  3.7  2.6 -0.5 -0.3 -0.3 -2.6 -0.6  2.4  0.5 -0.1 -0.4 -0.1 -0.4  0.2  2.9 -0.2 -0.8 -0.6  0.8 -0.3 -0.5 -0.2 -0.5 -0.3  4.3  0.6 -2.   2.3  1.1 -1.4 -0.1 -1.   1.1 -2.  -2.8 -0.2 -0.4  0.4 -0.9 -0.9 -0.3 -0.9 -0.5 -0.  -0.5  0.2 -0.   1.6  0.1 -0.3 -0.4 -0.4 -0.3 -0.1 -0.1 -0.4 -0.1  2.9 -0.2  0.3 -1.5 -0.2 -0.3 -0.8 -0.3 -0.3 -0.2 -0.7  0.6  1.1  0.7 -0.7  0.7 -0.7 -0.5 -0.4 -1.1 -0.3 -0.6 -0.9 -0.4  0.4 -1.3 -0.2 -0.  -1.3 -0.5 -0.5  3.6 -0.4 -1.  -0.1 -1.2 -1.9 -0.2 -1.6  1.7 -0.3 -0.4 -0.1 -0.5 -0.7 -0.5  0.4 -2.   0.4 -0.3 -0.6 -0.2 -0.4  0.5  0.5  6.3 -0.4  0.  -0.4 -0.6 -0.2 -0.  -0.5 -0.5  0.7 -1.1 -0.1  2.1  0.4  4.6 -0.1 -0.7 -1.   2.2 -0.4 -0.5 -0.4 -0.2  1.  -2.1 -0.6 -2.4 -0.7 -1.1 -0.5 -0.3  6.5  0.5  0.6  0.  -0.1 -0.3  4.   0.7  3.   0.1 -0.3  2.1]
ty_50sample [[1 2 5 8 7 7 4 3 3 6]
 [1 4 3 0 6 5 8 2 7 9]
 [9 3 3 0 1 5 4 2 6 7]
 [2 7 3 6 8 5 1 0 4 9]
 [2 5 0 9 4 7 3 6 1 8]
 [9 3 8 1 4 7 6 0 2 5]
 [0 2 5 3 6 8 9 1 7 4]
 [3 7 5 8 0 2 4 6 9 1]
 [0 6 3 3 5 7 8 9 2 4]
 [9 8 7 5 5 4 3 6 2 1]]
tt_50sample [[1 2 5 8 7 9 0 4 3 6]
 [1 4 3 0 6 5 8 2 7 9]
 [9 8 3 0 1 5 4 2 6 7]
 [2 7 3 6 8 5 1 0 4 9]
 [2 5 0 9 4 7 3 6 8 1]
 [9 8 3 1 4 7 6 0 2 5]
 [0 2 5 3 6 8 9 1 7 4]
 [3 7 5 8 0 2 4 6 9 1]
 [0 6 3 7 5 1 8 9 2 4]
 [9 8 7 5 0 4 6 3 2 1]]
vm  [-1.4 -0.1  3.5 -0.8 -1.6  0.7 -0.1  0.2 -0.2 -0.7 -1.5  1.  -0.5  0.3  7.3  2.7 -0.5 -0.3 -0.1  1.7 -0.1  0.1  2.8 -0.5 -1.3  1.4 -0.2 -0.1  2.5 -0.4  0.2 -0.5 -0.4  4.1 -0.9 -0.3  1.   0.4 -0.2 -0.9  0.3  1.5  0.7  2.5 -0.5 -0.1 -1.7  1.1 -0.9  3.  -1.   0.  -0.2  0.6 -1.5 -0.9 -0.5  0.4  1.5  1.2  7.7 -0.1 -0.2  0.7 -0.3 -0.  -0.2 -0.4  0.6  1.3  0.7 -0.9  1.5  1.2 -2.6 -0.1  1.1 -0.6  2.2  0.9 -1.5 -0.1 -0.1  0.7  1.3  2.9 -0.4 -0.1  1.3 -0.1 -0.4  0.3 -0.3 -0.5 -0.1 -0.1  1.  -1.4 -0.5  0.9  2.3  5.   2.3  0.2 -0.  -0.3 -1.6  0.  -0.6  1.3 -0.5 -0.6 -0.3 -0.3 -0.3  8.  -0.  -0.4 -0.5 -0.4 -0.3 -0.1  0.2 -0.2 -0.   7.4  3.1  1.9  3.7  2.4 -0.8 -0.8 -0.2 -0.3 -2.5 -1.   0.2 -0.4 -0.3 -0.5  1.8  0.5  1.6 -0.2 -0.9  0.1  1.4 -0.2 -0.5  0.6  2.6 -0.5 -0.3  1.3 -0.1 -0.1 -0.3 -0.4  2.6 -0.4  0.3 -0.4  0.2 -0.3 -0.5 -0.6  2.6  2.8 -0.1 -0.3 -0.1 -0.  -0.9 -0.2 -0.1  2.4 -0.7 -0.5  2.3  0.1 -0.7 -0.2 -0.8 -1.5 -0.4 -0.1 -1.2 -0.6 -0.7  1.2 -0.3 -0.2 -0.2 -1.  -1.8 -0.5 -0.5 -0.1 -0.3 -0.7 -0.3  0.1 -0.5 -0.8  2.5 -2.   0.   0.2  1.3 -0.2 -0.4  4.5 -0.6  5.8 -0.5 -0.2 -0.4 -0.1  0.8  0.5 -1.3 -0.  -0.3 -0.5 -0.1  4.1 -1.1  1.3  0.  -0.1 -0.3 -0.  -0.1  1.4 -0.3 -0.6 -0.2 -0.9  2.  -1.1 -0.2 -0.4 -0.4 -0.4  6.   0.6 -0.2 -0.  -0.4 -0.6  3.  -0.3 -0.  -0.4  4.1 -0.1]
vy_50sample [[1 7 8 5 4 3 6 9 2 0]
 [0 5 1 4 2 9 8 6 3 7]
 [3 2 1 4 9 0 5 8 6 7]
 [8 9 7 4 5 2 3 6 1 0]
 [0 2 8 7 5 4 6 1 9 3]
 [1 5 3 6 6 7 4 8 2 2]
 [0 5 5 3 6 1 9 7 4 8]
 [5 1 3 0 0 4 6 2 8 7]
 [8 5 9 2 4 7 6 3 1 0]
 [9 6 0 7 2 4 1 3 5 8]]
vt_50sample [[1 7 8 5 4 3 6 2 9 0]
 [0 5 1 4 2 9 8 6 3 7]
 [3 2 1 4 9 0 5 8 6 7]
 [8 9 7 4 5 2 6 3 1 0]
 [0 2 8 7 5 4 6 1 9 3]
 [1 5 3 9 6 7 4 8 2 0]
 [0 2 5 3 6 1 9 7 4 8]
 [1 5 3 9 0 6 4 2 8 7]
 [8 9 5 2 4 7 6 3 1 0]
 [9 6 0 7 2 4 1 3 5 8]]
Epoch 10710: Training cost= 0.3604, Training acc= 0.7742, Validation cost= 0.4720, Validation acc= 0.7745
Epoch 10720: Training cost= 0.3664, Training acc= 0.7742, Validation cost= 0.3922, Validation acc= 0.7746
Epoch 10730: Training cost= 0.3898, Training acc= 0.7743, Validation cost= 0.3998, Validation acc= 0.7747
Epoch 10740: Training cost= 0.3849, Training acc= 0.7744, Validation cost= 0.3530, Validation acc= 0.7747
Epoch 10750: Training cost= 0.3432, Training acc= 0.7745, Validation cost= 0.4156, Validation acc= 0.7748
Epoch 10760: Training cost= 0.4033, Training acc= 0.7745, Validation cost= 0.3514, Validation acc= 0.7749
Epoch 10770: Training cost= 0.3811, Training acc= 0.7746, Validation cost= 0.4295, Validation acc= 0.7750
Epoch 10780: Training cost= 0.3501, Training acc= 0.7747, Validation cost= 0.3260, Validation acc= 0.7750
Epoch 10790: Training cost= 0.3585, Training acc= 0.7747, Validation cost= 0.3422, Validation acc= 0.7751
Epoch 10800: Training cost= 0.3541, Training acc= 0.7748, Validation cost= 0.3706, Validation acc= 0.7752
tm  [-1.8 -0.4 -0.2  6.6 -1.   1.1  0.8 -0.3  0.3 -0.3  3.7  0.7 -0.5 -0.1 -1.5  3.5 -0.4 -0.8 -0.3 -1.7 -0.3  1.3  0.2 -0.5 -1.3  0.8  0.5 -0.2  3.7 -0.3  4.6 -0.9  1.2  6.1 -1.2  0.   0.5  0.6  5.2 -0.1  0.6  4.1  0.3 -0.  -0.2 -0.4  7.8  0.8 -1.7 -0.2 -0.7  0.5  2.6 -1.6 -1.5  3.9 -0.4  1.4 -0.  -1.1  1.9 -0.5 -0.3 -0.4  1.8 -0.3 -0.4  1.3 -0.1 -0.1 -0.2 -1.3  0.3 -0.3  2.2  0.   2.6 -0.4  2.  -0.4 16.4 -0.1 -0.8 -0.   1.2  6.5 -0.5 -0.1  0.2 -0.2 -0.3  1.2 -0.5 -0.5  0.1 -0.4  1.5  0.3 -0.3 -0.3  1.8  2.9  1.9 -0.1 -0.9 -0.4  0.1  4.1  1.4 -1.5 -0.3 -0.5 -0.3 -0.4 -0.2  8.2  0.2 -0.9 -0.7 -0.1 -0.3  6.7  0.2  0.2 -0.  -1.4  2.8  8.6  2.3 -1.7 -0.5 -0.7 -0.7 -0.4  3.7 10.5  0.2 -0.4 -0.1 -0.9 -0.3  1.   1.1 -0.2 -0.9 -0.2  1.6  0.7  3.   1.6 -0.7 -0.  -1.8  0.1 -0.2  0.1 -0.5 -0.6 -0.3  0.6  0.3  0.9 -0.1 -0.5 -0.3 -0.1  0.1  1.2 -0.6  1.4 -0.3  0.2 -0.9 -0.4 -0.1 -0.5 -1.2  2.4 -0.6 -0.3 -1.1 -0.  -0.4 -1.5 -0.9 -0.2 -0.2 -0.2 -0.4  1.5 -0.2 -0.7 -1.4 -0.7  0.   1.7  2.2  1.3 -0.2 -1.  -0.2  0.1 -0.5 -0.8  1.3  4.1  1.1 -0.3 -2.8  0.1  0.1  5.8 -0.3  7.1 -0.6 -0.   0.9 -0.3 -0.1 -0.1 -0.8 -0.3  0.  -0.6  2.7  1.9 -0.8  1.7  0.2 -0.5 -0.5 -0.5 -0.  -2.  -0.9  2.2 -0.1  1.9  0.2  4.1 -0.1  1.9 -0.4  0.5 -3.3 -2.3  0.5 -0.5 -0.6 -0.4 -3.5 -0.3  4.1 -0.3  3.1  8.7]
ty_50sample [[1 9 5 6 4 7 2 3 8 0]
 [8 8 1 1 6 5 0 4 2 9]
 [2 7 9 5 8 4 6 1 3 0]
 [9 8 2 7 4 4 6 1 3 5]
 [8 3 5 0 4 6 9 7 1 2]
 [8 2 3 4 9 1 7 6 0 5]
 [4 7 3 8 6 2 1 0 5 9]
 [5 9 1 6 4 0 7 3 2 8]
 [4 8 5 7 3 2 9 0 6 1]
 [1 2 7 3 8 6 4 0 9 5]]
tt_50sample [[1 9 5 6 4 7 2 3 8 0]
 [8 3 7 1 6 5 0 4 2 9]
 [2 7 9 5 8 4 6 1 3 0]
 [9 8 7 2 4 0 6 1 3 5]
 [8 3 5 0 4 6 9 7 1 2]
 [8 2 3 4 9 1 7 6 0 5]
 [4 7 3 8 6 2 1 0 5 9]
 [5 9 1 6 4 0 7 3 2 8]
 [4 8 5 3 7 2 9 0 6 1]
 [1 2 7 3 8 6 4 0 9 5]]
vm  [ 0.6 -0.1 -0.2  3.1 -1.5 -0.7  1.4 -0.6 -1.  -0.7  5.   0.9 -0.4 -0.5 -0.7 -0.2  0.8 -0.3  0.4 -1.4 -0.7 -0.6 -1.3  2.3 -1.   0.8 -0.2 -0.  -1.3  3.3  6.8 -0.2  0.2 10.7 -0.5  2.7  1.5 -0.6  1.8 -0.4 -0.6  0.8  1.5 -0.2 -0.5 -0.4  5.1  1.8  3.4 -2.2 -1.2 -0.4  1.6 -1.8 -0.2  2.  -0.2 -0.3 -1.3 -2.9 -1.7  0.6 -0.6  0.9 -0.5 -0.4 -0.2 -0.2  1.2  1.1 -0.7  1.3  1.6 -0.2  6.6 -0.6  0.2 -0.4  1.4 -0.7 20.8 -0.2 -1.2 -0.1 -1.   1.4  3.7 -0.2  1.  -0.1  1.1  1.3  1.3  1.4  0.4 -0.3 -0.1  1.5  0.2 -0.1  3.1  3.9 -1.1 -0.4 -0.1 -0.7  2.2  6.6  1.8 -1.4 -0.9 -0.1 -0.1  0.9 -0.1  0.3 -0.3 -0.5  0.2 -0.8 -0.2  8.3  0.1  0.1 -0.2 -0.9  1.   9.  -0.9 -0.9  4.2  0.1  1.  -0.5  4.9 17.1 -0.1 -0.2 -0.3 -1.   1.  -0.5  1.7  0.5  0.5 -0.1  0.4 -0.1 -0.5  0.7 -0.5  0.5 -0.8  0.1 -0.  -0.2 -0.1 -0.9 -1.1  2.1  1.3  3.1 -0.5 -0.5 -0.1 -0.6 -0.4  0.4  0.9  0.6 -0.8 -0.4 -0.3  0.4 -0.5  3.1 -0.8  3.4  0.5 -0.  -0.3  0.2 -0.3 -1.  -0.8 -0.3  4.3 -0.3  0.4 -0.9 -0.4 -0.8 -0.7 -0.8  7.8  3.6  4.4  1.1 -0.2 -0.2 -0.1  0.2 -0.3 -0.4 -0.2  4.4 -0.1 -0.2 -2.8 -0.1 -0.8 -0.1 -0.7 -0.1  0.4 -0.9  2.3 -0.2  0.4 -0.3 -0.7 -0.2 -0.5 -0.6  3.5 -1.2 -0.9 -0.5 -0.3  1.9  1.  -1.2  0.4 -2.   2.7  1.4  0.9  5.6  1.8  9.7 -0.2  4.9 -0.3 -0.1 -4.5 -2.2  0.1 -0.3 -0.3 -0.5 -4.2  0.4  1.2 -0.   1.8  5.5]
vy_50sample [[9 6 4 7 0 3 5 2 1 8]
 [0 6 3 8 2 4 5 5 7 9]
 [9 4 2 3 7 1 0 6 5 8]
 [0 2 3 9 5 8 6 6 4 1]
 [0 0 8 3 2 6 6 9 1 7]
 [9 0 7 6 6 8 8 2 4 1]
 [1 4 5 7 0 8 9 3 6 2]
 [9 3 4 8 0 1 7 6 5 2]
 [3 1 1 6 4 0 9 5 7 8]
 [7 6 6 0 2 5 4 1 1 3]]
vt_50sample [[9 6 4 7 0 5 3 2 1 8]
 [0 6 3 8 2 4 5 1 7 9]
 [9 4 2 3 7 1 0 6 5 8]
 [0 2 3 9 5 8 7 6 4 1]
 [0 5 8 3 2 6 4 9 1 7]
 [9 0 3 7 6 8 2 5 4 1]
 [1 4 5 0 7 8 9 3 6 2]
 [9 3 4 8 0 1 7 6 5 2]
 [3 2 1 6 4 0 9 5 7 8]
 [7 9 6 0 2 5 4 8 1 3]]
Epoch 10810: Training cost= 0.3933, Training acc= 0.7749, Validation cost= 0.4134, Validation acc= 0.7753
Epoch 10820: Training cost= 0.3575, Training acc= 0.7750, Validation cost= 0.3428, Validation acc= 0.7753
Epoch 10830: Training cost= 0.3029, Training acc= 0.7750, Validation cost= 0.3281, Validation acc= 0.7754
Epoch 10840: Training cost= 0.3279, Training acc= 0.7751, Validation cost= 0.4312, Validation acc= 0.7755
Epoch 10850: Training cost= 0.3868, Training acc= 0.7752, Validation cost= 0.3229, Validation acc= 0.7755
Epoch 10860: Training cost= 0.3680, Training acc= 0.7752, Validation cost= 0.3492, Validation acc= 0.7756
Epoch 10870: Training cost= 0.3725, Training acc= 0.7753, Validation cost= 0.4309, Validation acc= 0.7757
Epoch 10880: Training cost= 0.3728, Training acc= 0.7754, Validation cost= 0.4260, Validation acc= 0.7758
Epoch 10890: Training cost= 0.3953, Training acc= 0.7754, Validation cost= 0.3641, Validation acc= 0.7758
Epoch 10900: Training cost= 0.3188, Training acc= 0.7755, Validation cost= 0.3765, Validation acc= 0.7759
tm  [-0.9 -0.4  2.7 -0.1 -1.7 -0.5 -0.2 -0.2 -0.6 -0.2 -0.8  0.9 -0.7 -0.4  4.2  2.1 -0.5  0.6 -0.5 -1.3 -0.3  0.2  1.7 -0.4 -0.5  0.3 -0.1 -0.   3.3  1.1  3.5 -0.6  0.3  7.8 -0.3 -0.2  1.3 -0.   5.5 -0.2 -0.1 -0.9 -0.6  2.2 -0.8 -0.2  4.5  1.1 -0.8  2.7 -0.7 -0.2  0.7 -1.4 -1.5 -0.4 -0.4 -1.6  0.4 -1.   0.1 -0.1  0.1 -0.2  1.2 -0.8  0.1  0.5 -0.  -0.  -0.1 -1.1  0.7 -0.4 -0.9 -0.3  0.3 -0.4  2.4 -0.2  6.4 -0.4 -0.4 -0.5 -0.3 -0.8  1.  -0.6  0.6 -0.3 -0.3  0.1 -0.  -0.7 -0.1 -0.6 -0.9 -0.6 -0.4  0.2  0.2  5.4 -0.1 -0.1 -0.8  0.1 -0.5  4.3 -0.3 -1.4 -0.1 -0.6  0.5 -0.4 -0.   5.1 -0.  -0.3 -0.3 -0.5 -0.1  4.2 -0.3  0.9 -0.1  4.2  1.6  7.7 -0.2 -0.8  0.  -0.4  0.3  0.2 -2.7  1.  -0.  -0.2 -0.4 -1.   1.6 -0.3  1.2 -0.4 -0.6  0.2 -0.2 -0.2 -2.2  0.6  0.4 -0.1 -0.4  0.6 -0.2 -0.  -0.5 -0.3 -0.2 -0.4 -0.2 -0.3  0.2 -0.3  1.3 -0.3  0.1  4.3 -0.3 -0.  -0.2 -1.  -0.7  0.2 -0.3  7.1 -0.6  2.4 -0.7 -0.   2.4  0.1 -0.3 -1.3 -1.3 -0.2  0.5 -0.7 -0.4 -0.5 -0.4 -0.7 -1.2 -1.   1.7  1.8  1.1  0.4 -0.4 -0.9  0.1  0.7 -0.5 -0.1 -0.   2.  -0.5 -0.3  5.9 -0.1 -0.   4.1 -1.1  4.6  0.6 -0.1 -0.6 -0.3  0.1  0.7 -1.3 -0.4 -0.  -0.6  1.2  2.8 -1.2  1.1 -0.1 -0.3 -0.4 -0.5 -0.1  3.6 -1.  -0.1  0.6 -0.2  1.5 14.2 -0.2  7.1 -0.3  0.3 -1.  -1.8 -0.5 -0.4 -0.7 -0.1 -1.7  0.   4.6 -0.4  1.3  5.3]
ty_50sample [[7 4 9 1 8 6 3 2 0 5]
 [7 9 5 6 4 3 0 1 2 8]
 [3 4 0 8 6 7 9 2 5 1]
 [7 1 8 4 2 3 6 5 9 0]
 [7 6 1 8 2 0 9 5 4 3]
 [6 8 7 9 5 0 1 3 4 2]
 [9 0 5 2 3 1 4 4 7 6]
 [9 8 3 5 6 1 0 7 4 2]
 [7 5 6 2 4 0 1 3 9 8]
 [2 7 3 0 0 9 6 1 1 8]]
tt_50sample [[7 4 9 1 8 6 3 2 0 5]
 [7 9 5 6 4 3 0 1 2 8]
 [3 4 0 8 6 7 9 5 2 1]
 [7 1 8 4 2 3 6 5 9 0]
 [7 6 1 8 2 0 9 5 4 3]
 [8 6 7 5 9 0 1 3 4 2]
 [9 5 0 2 3 1 8 4 7 6]
 [9 8 3 5 6 1 0 7 4 2]
 [7 6 5 2 4 0 1 3 9 8]
 [2 7 3 4 0 9 6 5 1 8]]
vm  [-1.5 -0.5  2.7 17.1 -0.5 -0.2 -0.2 -0.5  2.8  1.1  3.2 -0.3 -0.2 -0.2 -3.   2.5 -1.  -0.2 -0.2 -2.  -0.7 -0.3  3.1 -0.7 -0.6  1.4  0.6 -0.   0.2 -1.8 -1.4 -1.  -0.7 -2.   0.4 -0.7 -0.6  3.6 11.2 -0.1 -0.6 -0.2 -1.6 -0.8 -0.5 -0.4 10.6 -1.2 -1.7  5.  -0.3  0.4  2.5 -0.4 -0.8  6.8 -0.3  2.7  4.1  5.   0.5 -0.3  1.5  1.8  0.2 -0.1 -0.5  2.7 -0.4 -1.  -0.6 -0.2  0.5 -0.2  1.4 -0.5  1.  -0.3 -0.1 -0.2  9.5 -0.6 -0.5 -0.3  1.1 -0.1 -1.7 -0.4 -0.3  0.4 -0.  -1.  -0.9 -1.3  0.2 -0.5  0.6 -0.1 -0.3 -0.4 -0.8 -0.2  2.  -0.7 -0.7  0.7  0.8 -1.2  1.6 -2.3 -0.1 -0.1 -0.2  0.1  3.7  0.2  0.2 -0.5 -0.3  2.5 -0.3  8.  -0.  -0.2  0.2 -3.2 -0.3  4.4  2.3 -1.9 -1.  -0.8 -1.5  1.2  4.9 -1.4 -0.6 -0.5  0.4 -0.7 -0.7 -0.4 -1.  -0.6 -0.2 -0.7 -0.   0.5  0.2 -0.3 -1.9 -0.  -0.5 -0.3  0.7 -0.3 -0.7  0.2  0.4  1.3  0.  -0.9 -0.2 -0.2 -1.2 -0.6 -0.3  2.3 -1.4  5.  -0.2 -0.9 -0.5 -0.1 -0.5  0.3 -0.5  4.8 -2.1 -0.5  1.4 -0.  -0.2 -0.8 -0.3 -0.2 -0.1  0.  -0.1  7.6 -0.5 -1.1 -2.  -0.6  1.8 -0.4  3.6 -0.3 -0.3 -0.4 -0.  -0.  -0.6 -0.5  0.8  8.  -0.3 -0.4  4.8 -0.1 -0.3  1.7 -0.6  5.5 -1.3 -0.2  3.6 -0.7 -0.6  0.5 -0.5 -1.  -0.  -1.2  1.6  1.1 -0.1  6.5 -0.2 -0.6 -0.6 -1.2 -0.   3.5 -0.5 -0.2  2.   2.8 -0.2 15.7 -0.7  8.  -0.5 -0.3 -1.5 -3.5  0.9  1.4 -0.7 -0.8 -2.1 -0.4  8.9  1.2 -0.6  9.7]
vy_50sample [[1 9 2 8 0 6 3 5 7 4]
 [1 3 7 7 0 0 9 5 8 4]
 [2 5 9 3 1 6 7 4 8 0]
 [3 4 7 9 1 0 8 5 2 6]
 [1 0 6 4 7 5 2 8 3 9]
 [6 3 1 5 7 8 0 0 4 2]
 [0 8 8 2 1 7 5 6 4 3]
 [5 5 0 0 2 8 3 4 6 7]
 [6 0 0 4 3 2 9 1 5 7]
 [5 9 7 8 2 0 6 4 1 3]]
vt_50sample [[1 9 2 8 0 6 3 5 7 4]
 [3 1 7 2 6 0 9 5 8 4]
 [2 5 9 3 1 6 7 4 8 0]
 [3 4 7 9 1 8 0 5 2 6]
 [1 0 6 4 7 5 2 8 3 9]
 [6 3 1 5 7 8 9 0 4 2]
 [0 8 9 2 1 7 6 5 4 3]
 [5 1 9 0 2 8 3 4 6 7]
 [6 0 8 4 3 2 9 1 5 7]
 [9 5 7 8 2 0 6 4 1 3]]
Epoch 10910: Training cost= 0.4559, Training acc= 0.7756, Validation cost= 0.3787, Validation acc= 0.7759
Epoch 10920: Training cost= 0.3650, Training acc= 0.7756, Validation cost= 0.4068, Validation acc= 0.7760
Epoch 10930: Training cost= 0.3754, Training acc= 0.7757, Validation cost= 0.3639, Validation acc= 0.7761
Epoch 10940: Training cost= 0.4118, Training acc= 0.7758, Validation cost= 0.3941, Validation acc= 0.7761
Epoch 10950: Training cost= 0.3893, Training acc= 0.7758, Validation cost= 0.3391, Validation acc= 0.7762
Epoch 10960: Training cost= 0.3729, Training acc= 0.7759, Validation cost= 0.4415, Validation acc= 0.7763
Epoch 10970: Training cost= 0.3895, Training acc= 0.7759, Validation cost= 0.4535, Validation acc= 0.7763
Epoch 10980: Training cost= 0.4151, Training acc= 0.7760, Validation cost= 0.4258, Validation acc= 0.7764
Epoch 10990: Training cost= 0.3652, Training acc= 0.7761, Validation cost= 0.3540, Validation acc= 0.7764
Epoch 11000: Training cost= 0.3787, Training acc= 0.7761, Validation cost= 0.3640, Validation acc= 0.7765
tm  [ 1.9 -0.  -0.6  3.4 -1.5 -0.6 -0.4 -0.3 -0.4 -0.3  0.1 -0.3 -0.4 -0.5 -0.9  3.5 -0.4 -0.5 -0.  -1.  -0.4  0.8  3.3 -0.4 -1.   0.8 -0.4 -0.2  0.2 -0.1  2.1 -0.3 -0.7 -0.3  0.5 -0.   1.2  3.5 11.1 -1.1 -0.1  2.5 -0.   5.9 -0.3  1.4  4.1 -0.3  4.3  5.8 -0.5 -0.6  2.3 -0.6 -0.7  3.2 -0.2 -0.4  1.4  0.3 -1.9 -0.4  0.4  3.8 -0.5 -0.2 -0.3 -0.4  0.8  0.9 -0.2 -0.3  1.6  1.8  3.4 -0.2 -1.  -0.4  1.   0.5  5.1 -0.3  0.1 -0.1 -1.3  3.2  2.5 -0.4  0.3  0.4  0.5 -0.5 -0.8 -0.9  1.3 -0.1 -0.1 -0.8 -0.2  0.7  0.4  4.2 -1.   0.3  0.6 -0.2  2.2  1.3 -0.2 -1.6 -1.3 -0.2 -0.  -0.4 -0.1  2.  -0.  -0.2 -0.1 -0.3 -0.   6.3 -0.2 -0.6  0.2 -1.  -0.3  4.4  4.5 -1.6  0.7 -0.8 -0.2 -0.4 -2.4 -3.   0.  -0.8 -0.5 -0.1 -0.1 -0.6  0.4  0.6 -0.4  1.1 -0.2 -0.7  0.4  1.3  0.4 -0.2  5.  -0.2  0.7 -0.2 -0.4 -0.1  3.2  0.2  2.2 -1.1 -0.3 -0.6 -0.6 -0.6  1.  -0.1  0.8  0.8  1.7 -0.5 -0.2 -0.1 -0.2  1.   1.9  4.  -2.3 -0.3 -0.7 -0.4 -0.9 -1.  -0.3 -0.3  5.  -0.2 -0.1  0.9 -0.1 -0.7 -1.4 -0.7  8.3 -0.8  5.  -0.1 -0.  -0.2 -0.6  1.  -0.4 -0.6 -0.6  3.3 -0.2  1.3  2.7 -0.1 -0.2  3.4 -1.1 -0.3 -0.4 -0.7 -1.5 -0.2  1.3 -0.1 -1.1 -0.2 -0.1 -0.6 -0.3  2.7 -0.1  0.7 -0.1  5.8 -0.6 -1.5 -0.2  2.5  1.6  3.4  1.8  5.6  3.4  8.  -0.4  3.9  0.  -0.2 -0.4 -2.3 -0.2  0.7 -1.1 -0.9 -1.4 -0.1  9.4  0.5  0.6  7.9]
ty_50sample [[9 4 8 2 7 5 0 3 1 6]
 [3 6 1 7 2 0 5 9 8 4]
 [5 5 0 7 3 9 4 1 6 2]
 [5 8 4 3 6 1 7 2 9 9]
 [2 5 7 7 0 4 3 1 8 6]
 [1 5 6 4 8 8 2 3 0 7]
 [1 2 0 8 8 3 5 9 6 4]
 [3 5 6 4 7 8 1 0 2 9]
 [2 5 0 1 9 8 3 6 7 4]
 [2 3 0 0 1 4 8 5 7 9]]
tt_50sample [[9 4 8 2 7 5 0 3 1 6]
 [3 6 1 7 2 0 5 9 8 4]
 [5 0 8 7 3 9 4 1 6 2]
 [5 8 3 4 6 1 7 2 0 9]
 [2 5 9 7 0 4 3 1 8 6]
 [1 5 6 4 8 2 9 3 0 7]
 [1 2 0 8 7 3 5 9 6 4]
 [3 5 6 4 7 8 1 0 2 9]
 [2 5 0 1 9 8 3 6 7 4]
 [2 3 0 6 1 8 4 5 7 9]]
vm  [-0.4 -0.2  7.1  9.3 -1.1 -0.5 -0.5 -0.3 -0.1 -0.4  4.3  0.4 -0.4 -0.4  2.4 -0.3 -0.4 -0.4 -0.2 -0.5 -0.8 -0.1 -1.3 -0.1 -0.6  1.8 -0.4 -0.3 -0.8 -1.3 -0.3  0.6  1.6  6.6 -0.1 -0.2  0.4 -0.4 -1.3 -0.5 -0.1 -1.7 -0.7 -1.8 -0.3 -0.3  1.4 -0.3  1.4 -2.2 -1.  -0.2 -0.2  0.6 -0.3 -0.1 -0.1  2.4  0.5  2.9  0.1 -0.2 -0.2  3.3  0.4 -0.4 -0.2 -0.2  0.9  0.2 -0.   1.7 -0.3 -0.3 -2.  -0.1 -0.6 -0.8 -0.3 -0.3  7.4 -0.1 -0.4 -0.2 -0.7 -1.9 -0.7 -0.4  1.   0.2 -0.5 -0.2  1.  -0.1 -0.4 -0.2  0.1 -1.  -0.1 -0.   1.3 -0.5 -0.2 -0.3 -0.5 -0.1 -1.2 -0.2  1.4 -1.2  1.   0.5  0.1 -0.5  3.3 -0.8 -0.2  1.6 -0.2  1.1  0.1  3.1  0.1  0.1 -0.7  3.1 -0.   2.2 -0.6  4.2  3.3 -0.7 -0.5 -0.4  5.4 13.4 -0.2  0.   1.6 -0.6 -0.1 -0.4 -0.2 -0.2 -0.2 -0.4 -0.4 -0.5 -0.9 -0.7 -1.  -0.3 -0.1 -0.1 -0.4 -0.1  0.4 -0.1 -1.3 -0.6 -0.6  2.3  0.1  0.2  0.  -0.6  0.3  2.4 -0.6  3.  -1.2 -0.7 -0.1 -0.1 -0.5  4.5 -1.4 -0.3  5.6  0.1  0.5 -0.3 -0.1 -0.9 -0.1 -0.6  2.  -0.6  0.4  5.3 -0.3  0.6 -0.8 -0.4  2.3  0.6 -0.7 -0.7 -0.2 -0.3 -0.3 -0.5 -0.2 -0.1 -0.4 -1.  -0.  -0.1  1.5 -0.1 -0.4 -0.2 -0.9  0.1 -1.  -0.   7.6 -0.6 -0.1 -0.  -0.4 -0.4 -0.  -0.7  1.  -0.9 -0.5  1.4  0.5  3.3  1.2  0.7 -0.4  0.6  1.1 -1.7  1.  -0.9  0.5  6.7 -0.4  3.9 -0.1 -0.3 -1.2 -0.6 -0.2 -0.2 -0.6 -0.1 -1.9 -1.2 -1.  -0.2  2.2 -0.8]
vy_50sample [[6 3 0 7 9 2 1 8 8 4]
 [2 5 4 6 8 9 1 3 0 7]
 [2 2 4 1 9 6 0 7 3 5]
 [3 7 5 1 4 9 2 0 8 6]
 [4 9 3 7 8 6 5 2 1 1]
 [1 0 7 5 2 3 9 8 8 4]
 [6 7 9 0 5 2 1 3 4 8]
 [4 5 6 6 0 9 1 2 8 3]
 [5 8 2 9 1 0 4 3 6 7]
 [2 8 6 4 1 3 0 7 9 5]]
vt_50sample [[6 3 0 7 9 2 1 5 8 4]
 [2 5 4 6 8 9 1 3 0 7]
 [8 2 1 4 9 6 0 7 3 5]
 [3 7 5 1 4 9 2 0 8 6]
 [4 9 3 7 8 6 5 2 1 0]
 [1 0 7 5 2 3 9 8 6 4]
 [6 7 9 0 5 2 1 3 4 8]
 [4 5 6 0 7 9 1 2 8 3]
 [5 8 2 9 1 0 4 3 6 7]
 [2 8 6 4 1 3 7 0 9 5]]
Epoch 11010: Training cost= 0.3865, Training acc= 0.7762, Validation cost= 0.3450, Validation acc= 0.7766
Epoch 11020: Training cost= 0.3705, Training acc= 0.7763, Validation cost= 0.2808, Validation acc= 0.7767
Epoch 11030: Training cost= 0.4032, Training acc= 0.7763, Validation cost= 0.3782, Validation acc= 0.7767
Epoch 11040: Training cost= 0.3450, Training acc= 0.7764, Validation cost= 0.3662, Validation acc= 0.7768
Epoch 11050: Training cost= 0.3371, Training acc= 0.7765, Validation cost= 0.4019, Validation acc= 0.7769
Epoch 11060: Training cost= 0.4446, Training acc= 0.7765, Validation cost= 0.3836, Validation acc= 0.7769
Epoch 11070: Training cost= 0.3551, Training acc= 0.7766, Validation cost= 0.3844, Validation acc= 0.7770
Epoch 11080: Training cost= 0.3926, Training acc= 0.7767, Validation cost= 0.3421, Validation acc= 0.7770
Epoch 11090: Training cost= 0.4043, Training acc= 0.7767, Validation cost= 0.3736, Validation acc= 0.7771
Epoch 11100: Training cost= 0.3594, Training acc= 0.7768, Validation cost= 0.3507, Validation acc= 0.7772
tm  [-0.2 -0.6 -1.8 -0.2 -0.5 -0.4 -0.5 -0.5  1.2 -0.2 10.9 -1.   1.8 -0.  -1.7  4.5 -0.2 -0.7 -0.4 -0.8 -0.9 -0.2 -0.6 -0.7 -0.8  0.3 -0.4 -0.3 -0.5 -0.8  5.7 -0.6  1.5  1.1  3.3 -0.2  0.6  2.4 -0.4 -0.6 -0.2  3.2 -0.4  0.9 -0.2 -0.2  0.9 -1.2  3.  -1.  -0.5 -0.9 -0.8  6.2 -0.9  3.7 -0.5 -0.1  3.8 -1.7 -0.5 -0.4 -0.3  4.4 -0.1 -0.6 -0.   3.2 -0.2 -0.1 -0.8 -0.4 -0.1 -0.  -1.8 -0.2 -1.1  0.2  0.9 -0.2 10.3 -0.  -0.6  0.1 -1.   2.8  1.2 -0.4 -0.  -0.2 -0.3 -0.9 -0.8 -0.9 -0.3 -0.2 -0.1 -1.5 -0.2 -0.4  0.5 -0.6 -0.5 -0.  -0.2 -0.2 -1.1  5.1  3.3 -1.2 -0.9  0.  -0.4 -0.7  2.8  1.6 -0.2  0.7 -0.2  1.  -0.2  4.9  1.3  0.2 -0.1 -1.6 -0.9 -1.2  4.8 -0.2  3.2 -0.9 -0.3 -0.2 10.4 12.4 -0.3 -0.4 -0.4 -0.4 -0.8  0.9 -0.8  0.6 -0.5 -0.  -0.3 -0.4  4.9 -0.3  1.  -0.4 -0.3 -1.  -0.3  0.1 -0.  -0.2 -0.6 -0.   1.9  0.9 -0.6 -0.4 -0.3 -0.5 -0.1  0.2  0.6 -0.1 -0.3  0.2 -0.4 -0.2 -0.3 -1.3 -0.9 -0.1  3.4 -0.7 -1.1  0.4 -0.5 -1.   0.  -0.4  2.3  0.3 -0.5  4.  -0.2 -0.6 -0.9 -0.4  4.7 -0.9 -0.1 -0.5 -0.   0.1 -0.2  0.5 -0.5 -0.8 -0.3 -1.4  0.2  0.9 -2.8 -0.5 -0.4  2.1 -1.   1.1  0.1 -0.2  1.3 -0.8 -0.4 -0.6  1.4 -0.6 -0.2 -0.6  2.5 -0.5  2.   2.9 -0.   6.4 -0.7 -0.4 -0.2 -1.9  2.8  6.4  2.4 -0.6  1.1  0.4 -0.2  0.4 -0.  -0.3 -1.9 -0.6 -0.1 -0.3 -1.2 -0.4 -2.2  0.3 -0.4  0.7 -0.2  3.4]
ty_50sample [[2 6 4 5 0 0 3 1 8 7]
 [5 7 8 9 3 2 6 1 4 0]
 [9 4 5 0 6 8 3 7 2 1]
 [3 5 6 0 7 8 2 1 9 4]
 [7 0 6 8 4 5 9 3 2 1]
 [9 9 4 8 0 6 5 2 7 1]
 [4 2 3 1 6 6 0 8 9 5]
 [9 8 0 6 1 2 5 7 4 3]
 [6 9 7 8 3 5 0 4 2 1]
 [2 0 0 4 3 8 7 9 5 5]]
tt_50sample [[2 6 4 5 9 0 3 1 7 8]
 [5 7 8 9 3 2 6 1 4 0]
 [9 4 5 0 6 8 3 7 2 1]
 [3 5 6 0 7 8 2 1 9 4]
 [7 0 6 8 4 5 9 3 2 1]
 [9 3 4 8 0 6 5 2 7 1]
 [4 2 3 1 6 7 0 8 9 5]
 [9 8 6 0 1 2 5 7 4 3]
 [6 9 7 8 3 5 0 4 2 1]
 [2 6 0 4 3 8 7 9 1 5]]
vm  [-0.1  0.9  3.1  8.2 -1.2 -0.6 -0.2 -0.4 -1.2 -0.   8.  -0.7  0.3  0.1 -0.5  2.   1.3 -0.5 -0.  -1.8 -0.7 -0.1  1.3  1.  -1.7  2.4 -0.3 -0.2 -1.1 -0.   2.1  0.3  1.1  5.5  1.   2.   4.1  1.4 -0.5  0.  -0.3  4.1  1.5 -1.3 -0.7 -0.4  5.7 -0.9  0.1  1.5 -0.7 -0.4 -0.   2.4 -0.4  2.2 -0.6  2.2 -1.2 -0.  -0.7 -0.  -0.4  1.2  1.2 -0.7 -0.  -0.  -0.4 -0.6 -0.7  2.2 -0.3 -0.8 -0.  -0.3  0.6 -0.1  1.2 -0.4 12.1  0.2 -0.9 -0.4 -0.8  5.   0.2 -0.1 -0.3  0.1 -0.5 -0.3 -0.5  1.1 -0.2 -0.4  1.3  0.8 -0.1 -0.3  1.1  4.2 -0.5 -0.3 -0.3 -0.3 -0.4  1.4  3.1 -1.7 -0.6  0.6 -0.1  0.6  0.6 -0.9 -0.4 -1.  -0.3 -0.3 -0.4  5.7  0.5  0.4 -0.1 -0.5 -0.1 -0.1 -0.9 -1.4  2.4  0.6 -0.7 -0.2  7.3 12.9 -0.3 -0.5 -0.3 -0.6 -0.5 -0.6 -0.6  0.2  1.6 -0.5 -0.1 -0.1  1.8  0.6 -1.2 -0.3 -0.3 -1.  -0.5 -0.  -0.1 -0.  -1.2 -0.5  0.7  2.2 -0.6 -0.2 -0.3 -0.5 -1.2 -0.8 -0.3  2.7  0.7 -0.1 -0.1 -0.  -0.3 -0.2 -1.4  0.9  3.  -0.6 -1.   0.4  0.3 -1.  -0.5 -0.6  2.  -0.5  1.   0.5 -0.2 -0.7 -0.5 -0.9  4.6  3.2  0.   1.7 -0.1 -0.  -0.3 -0.8 -0.1 -0.2 -0.4 -0.1  0.1  0.  -2.2 -0.2 -0.3 -0.6 -0.2  1.9 -0.4 -0.4  5.1 -0.4 -0.5 -0.2 -0.  -0.5  0.6 -0.8  4.5 -0.9  0.9  2.2 -0.  -0.1  0.2 -0.2 -0.5 -1.5  2.  -0.6  2.   1.2 -0.5  2.6 -0.4  1.3 -0.4 -0.3 -2.4 -1.3 -0.1 -0.2 -0.2  0.1 -2.8  0.  -0.3  1.1 -0.5  7.7]
vy_50sample [[6 2 0 5 5 7 1 4 8 3]
 [5 8 0 1 7 6 3 9 4 2]
 [1 6 8 8 4 5 3 0 7 2]
 [2 0 1 9 7 3 8 6 4 5]
 [0 3 5 4 8 2 6 6 1 9]
 [8 6 6 2 2 1 5 9 3 3]
 [8 9 3 3 6 7 1 2 0 5]
 [4 3 7 0 9 6 1 5 2 8]
 [5 0 3 4 1 6 2 9 8 7]
 [5 3 1 2 9 6 6 0 7 4]]
vt_50sample [[6 2 0 9 5 7 1 4 8 3]
 [5 8 0 1 7 6 3 9 4 2]
 [1 6 8 9 4 5 3 0 7 2]
 [2 0 9 1 3 7 8 6 4 5]
 [0 3 5 4 8 7 2 6 1 9]
 [8 6 4 2 1 7 5 9 0 3]
 [8 9 3 4 6 7 1 2 0 5]
 [4 3 7 0 9 6 1 5 2 8]
 [5 0 3 4 1 6 2 9 8 7]
 [5 3 1 2 9 8 6 0 7 4]]
Epoch 11110: Training cost= 0.4001, Training acc= 0.7769, Validation cost= 0.3445, Validation acc= 0.7772
Epoch 11120: Training cost= 0.3717, Training acc= 0.7769, Validation cost= 0.3005, Validation acc= 0.7773
Epoch 11130: Training cost= 0.3973, Training acc= 0.7770, Validation cost= 0.3202, Validation acc= 0.7774
Epoch 11140: Training cost= 0.4013, Training acc= 0.7771, Validation cost= 0.4413, Validation acc= 0.7774
Epoch 11150: Training cost= 0.4159, Training acc= 0.7771, Validation cost= 0.4386, Validation acc= 0.7775
Epoch 11160: Training cost= 0.3291, Training acc= 0.7772, Validation cost= 0.4055, Validation acc= 0.7776
Epoch 11170: Training cost= 0.3702, Training acc= 0.7772, Validation cost= 0.4327, Validation acc= 0.7776
Epoch 11180: Training cost= 0.3407, Training acc= 0.7773, Validation cost= 0.3711, Validation acc= 0.7777
Epoch 11190: Training cost= 0.3392, Training acc= 0.7773, Validation cost= 0.4139, Validation acc= 0.7777
Epoch 11200: Training cost= 0.3336, Training acc= 0.7774, Validation cost= 0.3825, Validation acc= 0.7778
tm  [ 1.2 -0.2 -1.3  1.9 -0.6 -0.5 -0.3 -0.4  1.3 -1.   5.5 -0.4 -0.1 -0.3 -1.5  4.5 -0.4 -0.4 -0.2 -1.1 -0.7  0.1 -0.5 -0.4 -0.9  1.5 -0.1 -0.1  1.4 -0.9  2.9 -0.6 -0.1 -0.6  1.2 -0.2 -0.   3.   5.5 -1.1 -0.1 -2.3 -1.1  3.  -0.8 -0.1  5.4 -0.9  2.5 -1.1 -0.6 -0.5  1.1  1.8 -1.2  4.4 -0.2 -1.   2.9 -0.2 -1.6 -0.1  0.4  3.1  1.3 -0.2 -0.3  2.3  0.3 -0.  -0.4 -0.5 -0.2 -0.1 -0.1  0.6 -1.3 -0.5 -0.1  0.2  6.1 -0.1 -0.   0.  -1.  -2.2  0.7 -0.3  1.2  0.1 -0.3 -0.4  0.2 -0.9  0.4 -0.4 -0.5 -0.7 -0.1 -0.1  2.4 -1.7 -0.9 -0.2 -0.  -0.2 -0.3  2.4  2.3 -1.4 -0.7 -0.  -0.2 -0.7  1.9  2.2 -0.3  1.2 -0.3  1.5 -0.3  4.1  0.  -0.2 -0.4 -1.5 -0.6  1.   2.3  1.9  3.6 -1.   0.2 -0.3  3.5 -0.   0.  -0.1  2.1 -0.4 -0.6 -0.4 -0.7 -0.1 -0.5  0.6 -0.5 -0.4 -0.3 -0.4 -0.  -0.2  4.4 -0.8 -0.2 -0.1 -0.4 -0.2 -0.1 -0.2 -0.1 -0.7 -0.2 -0.3 -0.4 -0.6  1.9  3.2 -0.   0.7 -0.8 -1.1 -0.3  0.1 -0.6  1.9 -0.6  0.5 -0.7 -0.3  1.2 -0.4 -0.6 -0.9 -0.1 -0.5  5.2 -0.2 -0.1  4.9 -0.  -0.1 -1.5 -0.7  7.4 -0.7  1.1 -0.7 -0.1 -0.2 -0.4  0.2 -0.6 -0.6 -1.  -0.1 -0.3  1.1  4.9 -0.1 -0.2  4.4 -1.4 -0.5 -0.3 -0.3 -0.4 -0.6 -0.4  0.2 -0.5 -0.5 -0.1 -0.9 -0.8  2.4  0.5  2.   0.2  7.4 -0.8 -0.6 -0.3  3.6 -0.2  4.7  1.9  0.4  2.1 12.9 -0.3  6.6 -0.1 -0.1 -0.9 -2.  -0.  -0.3 -1.2 -0.5 -1.7 -0.3  5.  -0.1  0.9  0.3]
ty_50sample [[3 2 9 4 8 6 0 7 1 5]
 [7 2 6 5 9 9 8 1 3 4]
 [3 6 6 8 1 0 7 4 2 2]
 [8 6 0 1 7 5 9 2 3 4]
 [2 6 4 0 7 9 5 1 3 8]
 [3 1 8 0 4 7 9 5 2 6]
 [5 6 0 8 2 9 1 3 4 7]
 [0 2 1 7 8 9 3 5 6 4]
 [1 8 2 9 5 3 7 6 0 4]
 [3 4 5 1 8 2 7 9 6 6]]
tt_50sample [[2 3 9 4 8 6 0 7 1 5]
 [7 2 6 5 0 9 8 1 3 4]
 [3 9 6 8 1 0 7 4 5 2]
 [8 6 0 1 7 5 9 2 3 4]
 [2 6 4 0 7 9 5 1 3 8]
 [3 1 8 0 4 7 9 5 2 6]
 [5 6 0 8 2 9 1 3 4 7]
 [0 2 1 8 7 9 5 3 6 4]
 [1 8 2 9 5 3 7 6 4 0]
 [3 4 5 1 8 2 7 9 0 6]]
vm  [ 1.4  0.4 -1.3  0.1 -0.7 -0.4 -0.2 -0.4 -0.5 -0.7  5.3 -1.   0.8 -0.1 -1.   8.5  1.6 -0.5 -0.3 -1.1 -0.2 -0.1  1.8 -0.1 -1.5 -0.2 -0.1 -0.1  3.4  0.4  1.6 -1.1 -0.3 -1.2  0.2 -0.   2.4  3.9  5.  -0.7 -0.   0.9  0.1  3.4 -0.5  0.2  3.  -1.   2.6  3.6 -0.3 -0.6 -0.1  4.6 -1.3  2.7 -0.4 -0.3 -0.  -0.  -1.6 -0.1 -0.4  0.7 -0.1  0.5 -0.1  0.8 -0.4 -0.3 -0.5 -1.2 -0.1  0.2 -0.4 -0.1 -1.   0.4  0.2 -0.1  1.1 -0.2 -0.4 -0.1 -1.   2.   2.1 -0.   1.6 -0.3 -0.2  0.2 -0.1 -0.3  0.2 -0.2  0.1 -0.6 -0.1 -0.3  2.5 -0.1 -1.1  0.  -0.   0.1 -0.3  1.7  2.4 -1.3 -0.9 -0.3 -0.2 -0.2 -1.1  7.9 -0.3 -0.6 -0.  -0.1 -0.3  5.3 -0.1 -0.7  0.1 -1.  -0.3 -0.9  2.3 -0.4  3.  -0.5 -0.1 -0.3  3.3 -1.  -0.2 -0.4 -0.1 -0.1 -1.1 -0.6 -0.4 -0.  -0.4  1.2 -0.3 -0.4  2.9  1.4  1.2 -0.3  4.9 -0.9 -0.3 -0.1 -0.7 -0.1 -0.3 -0.1  0.6 -0.3 -0.5 -0.3 -0.4 -0.1  1.4 -0.3  0.9 -0.2  0.3 -0.4 -0.8 -0.3 -0.1 -0.5 -0.4  1.1 -0.6 -1.1 -1.1  0.5 -0.7 -0.8 -0.5  0.   5.1 -0.2 -0.8  0.1 -0.2 -0.5 -0.9 -0.6  7.9 -0.2  1.3  1.4 -0.3 -0.5 -0.3 -0.1 -0.3 -0.3 -0.6 -0.2 -0.1  1.2  2.3  0.2  0.2  6.2 -0.6 -0.5  0.5 -0.3 -0.6 -0.2 -0.3 -0.7 -0.4 -0.3 -0.3 -0.8  0.6  5.   3.5  0.8 -0.2  5.6 -0.9 -0.5 -0.1  2.6 -0.7  5.1  0.4  0.6 -0.   5.  -0.3  2.3 -0.1 -0.1  1.  -1.2 -0.1  0.  -0.8 -0.7 -0.5  1.   4.   1.  -0.3  4.5]
vy_50sample [[2 4 9 9 5 5 7 7 1 1]
 [1 7 3 6 4 5 8 9 0 2]
 [8 7 5 2 3 1 9 4 9 6]
 [7 0 8 2 5 6 1 9 4 3]
 [5 5 7 0 8 2 1 4 3 9]
 [3 2 6 0 1 5 7 9 8 4]
 [1 5 0 4 7 3 6 8 9 2]
 [8 5 3 3 7 7 0 4 2 1]
 [8 7 9 1 9 2 3 4 6 5]
 [6 2 5 1 3 9 4 8 8 0]]
vt_50sample [[2 4 9 8 5 6 3 7 1 0]
 [1 7 3 6 4 5 8 9 0 2]
 [8 7 5 2 3 1 0 4 9 6]
 [7 0 8 2 5 6 1 9 4 3]
 [5 7 6 0 8 2 1 4 3 9]
 [3 2 6 0 1 5 7 9 8 4]
 [1 5 0 4 7 3 6 8 9 2]
 [8 5 6 3 7 9 4 0 2 1]
 [8 7 1 9 0 2 3 4 6 5]
 [6 2 5 3 1 9 4 7 8 0]]
Epoch 11210: Training cost= 0.3711, Training acc= 0.7775, Validation cost= 0.3749, Validation acc= 0.7779
Epoch 11220: Training cost= 0.3610, Training acc= 0.7776, Validation cost= 0.3452, Validation acc= 0.7780
Epoch 11230: Training cost= 0.3591, Training acc= 0.7776, Validation cost= 0.3712, Validation acc= 0.7780
Epoch 11240: Training cost= 0.3373, Training acc= 0.7777, Validation cost= 0.4377, Validation acc= 0.7781
Epoch 11250: Training cost= 0.4082, Training acc= 0.7777, Validation cost= 0.4416, Validation acc= 0.7781
Epoch 11260: Training cost= 0.3483, Training acc= 0.7778, Validation cost= 0.3951, Validation acc= 0.7782
Epoch 11270: Training cost= 0.4127, Training acc= 0.7779, Validation cost= 0.3850, Validation acc= 0.7783
Epoch 11280: Training cost= 0.3497, Training acc= 0.7779, Validation cost= 0.3758, Validation acc= 0.7783
Epoch 11290: Training cost= 0.3809, Training acc= 0.7780, Validation cost= 0.3295, Validation acc= 0.7784
Epoch 11300: Training cost= 0.3547, Training acc= 0.7781, Validation cost= 0.3974, Validation acc= 0.7785
tm  [-1.5 -0.6 -3.  -0.4 -0.6 -0.1 -0.4  0.3 -0.1  0.3 -0.8  0.4 -0.9 -0.4 -2.5 -0.4 -0.7 -0.3 -0.5 -1.3 -0.4  0.1  3.  -0.4 -0.9  2.  -0.4 -0.3 -0.4 -1.1  3.7 -0.3  2.9 -2.3 -0.  -0.1  1.1 -0.8 -0.2 -0.4  0.5  2.2 -0.8  1.6 -0.3 -0.4  6.3  0.3 -1.5  4.3 -0.2 -0.4 -0.  -1.4 -1.   5.3 -0.8 -1.1  2.7 -1.   4.5 -0.3 -0.  -0.4  1.9 -0.7 -0.3  2.8  0.3 -0.2 -0.4 -0.2 -0.2 -0.1 -1.4  0.1  3.1 -0.3  2.9 -0.3  6.4 -0.2 -0.3 -0.3  0.9  2.6 -0.4 -0.4 -0.2 -0.3 -0.7 -0.3 -0.9 -0.8 -0.5 -0.5 -0.2 -0.6 -0.  -0.1 -0.4 -0.2  3.3  0.  -0.5 -0.4 -1.5  4.5 -0.3 -1.5 -0.5 -0.2 -0.  -0.7  5.4  0.1  0.3  0.3 -0.2  0.9 -0.3  4.5 -0.1 -0.2 -0.3 -2.6 -0.1  7.6  1.3 -1.2 -0.5 -0.9 -0.7 -0.  10.9  7.9 -0.  -0.7 -0.1 -0.9  1.2 -0.2  0.1 -0.1 -1.  -0.4  0.3 -0.1  3.7 -0.1 -0.2 -0.2 -1.   0.  -0.2 -0.4 -0.  -0.1 -0.6 -0.6  0.9 -0.  -0.1 -0.4 -1.  -0.3 -0.7  2.5 -0.6 -0.2  0.7 -0.5 -0.8 -0.  -0.2 -0.8 -1.7  0.4  2.5 -0.  -0.5 -0.2  0.3 -1.3 -0.4 -0.6 -0.5  1.6  0.3  3.3 -0.6 -0.8 -1.3 -1.1 -0.7  0.5 -0.3 -0.4 -0.5 -0.4 -0.   0.1 -0.1 -0.7 -0.1 -0.4  0.  -0.4  2.6 -0.4 -0.2 -0.1 -0.5  5.9  1.8  0.1 -0.5 -0.8 -0.7 -0.3 -0.3 -0.3 -0.1 -1.6  3.3 -0.1 -1.3  2.4 -0.3 -0.5 -0.1  1.4 -0.2  2.1 -0.2  7.7  1.9 -1.1 -0.   7.8 -0.1  3.8 -0.7  0.  -0.8 -1.7  0.6 -0.4 -0.7 -0.  -1.6 -0.2 -0.3 -0.8  2.   7.7]
ty_50sample [[1 4 6 9 0 8 5 2 2 7]
 [7 9 5 3 2 8 6 4 1 0]
 [8 1 6 9 5 2 0 4 3 7]
 [8 4 1 3 3 5 2 9 0 6]
 [3 2 6 5 9 9 8 8 7 1]
 [9 0 1 6 7 7 4 5 3 2]
 [2 3 8 9 4 1 5 0 7 6]
 [3 3 1 7 8 9 0 2 4 6]
 [3 1 4 5 9 7 6 6 2 8]
 [0 5 3 8 7 6 1 1 2 4]]
tt_50sample [[1 4 6 9 0 8 5 2 3 7]
 [7 9 5 3 2 8 6 4 1 0]
 [8 1 6 9 5 2 0 4 3 7]
 [8 4 1 7 3 5 2 9 6 0]
 [3 2 6 5 9 0 4 8 7 1]
 [9 0 1 6 7 4 5 3 8 2]
 [2 3 8 9 4 1 5 0 7 6]
 [3 5 1 7 8 9 0 2 6 4]
 [3 1 4 5 9 7 6 0 2 8]
 [0 5 3 8 7 6 1 2 9 4]]
vm  [ 1.4  0.4  4.3  1.4 -1.6 -1.  -0.  -0.2 -0.6 -1.3 10.  -0.5  1.3  0.3  4.9  6.3  2.7 -0.4  1.6 -0.3 -0.4 -0.4 -1.1 -0.1 -1.3 -0.1 -0.6 -0.4 -0.6  0.4  3.8 -0.3 -0.2  9.4  0.5  2.2  2.3  3.9  1.5 -1.  -0.1 -0.3  0.9  1.  -0.5 -0.1 -0.6 -0.9  4.4 -2.2 -1.  -0.7 -0.4  6.6 -1.2 -0.5 -0.3  1.3 -0.2 -1.2 -0.9 -0.1 -0.6  2.8 -0.2 -0.4 -0.2 -0.4 -0.3  1.  -0.2 -0.1  1.4  0.2 -1.1 -0.6 -1.  -0.5 -0.3 -0.4  9.5 -0.3 -0.7 -0.3 -1.4 -0.2  2.4 -0.1  1.  -0.4 -0.2 -0.2  0.   0.8 -0.2 -0.1 -0.1 -1.1 -0.3 -0.2  4.7  3.6 -1.   0.1  0.7 -0.1 -0.8  3.5  3.2 -0.8 -0.7 -0.4 -0.2 -0.1 -0.5  3.8 -0.  -0.1 -0.  -0.9 -0.2  5.  -0.  -0.1 -0.1  5.  -0.1 -1.7  1.4  3.2  2.5 -0.5  0.5 -0.5 -1.9  7.7 -0.3  0.1 -0.3 -0.3 -0.9 -0.1 -0.5 -0.   1.2  0.2 -0.5 -0.6 -0.6 -0.   0.4 -0.3  1.2 -1.1 -0.5 -0.4  0.1 -0.2  0.4 -0.2 -0.2 -0.2 -0.5 -0.3  1.1 -0.5  0.2 -0.3  0.9  0.3 -0.9 -0.1 -0.4 -0.3 -0.4  3.  -0.5 -0.1  1.2 -0.7 -1.   0.1 -0.5 -1.  -0.3 -0.2  4.  -0.7 -0.6  1.  -0.2 -0.  -0.1 -0.6  6.2 -0.   0.3 -0.3 -0.3  0.6 -0.3 -0.5  0.1 -0.7 -0.6 -1.2 -0.2  1.8 -2.1 -0.5 -0.6  1.6 -0.6 -0.9  0.5 -0.6 -0.  -0.2  1.1 -0.4 -0.1 -0.1 -0.4 -0.5 -0.2 -0.2  3.3  0.5 -0.5  5.3 -0.7 -0.5 -0.  -1.2  1.7 -0.7 -0.2 -0.   0.5  0.6 -0.5  0.3 -0.2 -0.3 -1.8 -0.1 -0.3  0.3 -0.3 -0.5 -2.1  0.5  1.4  0.2 -0.  -0.2]
vy_50sample [[2 7 3 3 5 6 9 0 8 1]
 [5 4 7 7 6 6 3 8 9 1]
 [8 2 6 1 5 7 9 3 4 4]
 [1 8 2 4 3 6 5 9 0 7]
 [4 2 2 0 7 8 1 5 3 9]
 [1 4 2 0 5 3 8 6 9 7]
 [0 2 1 6 6 4 4 8 5 5]
 [0 3 9 1 7 2 5 8 8 6]
 [7 3 2 2 8 5 1 9 6 4]
 [8 9 7 2 4 5 3 0 1 6]]
vt_50sample [[2 7 3 5 4 6 9 0 8 1]
 [5 4 2 7 0 6 3 8 9 1]
 [8 2 6 1 5 7 3 9 0 4]
 [1 8 2 4 3 6 5 9 0 7]
 [4 2 6 0 7 8 1 5 3 9]
 [1 4 2 0 5 3 8 6 9 7]
 [0 2 6 9 1 4 8 3 5 7]
 [0 3 9 1 7 2 5 4 8 6]
 [7 3 2 0 8 5 1 9 6 4]
 [8 9 7 2 4 5 3 0 1 6]]
Epoch 11310: Training cost= 0.3543, Training acc= 0.7781, Validation cost= 0.3428, Validation acc= 0.7785
Epoch 11320: Training cost= 0.3116, Training acc= 0.7782, Validation cost= 0.3922, Validation acc= 0.7786
Epoch 11330: Training cost= 0.3682, Training acc= 0.7783, Validation cost= 0.3554, Validation acc= 0.7787
Epoch 11340: Training cost= 0.3883, Training acc= 0.7784, Validation cost= 0.3482, Validation acc= 0.7788
Epoch 11350: Training cost= 0.4087, Training acc= 0.7784, Validation cost= 0.3425, Validation acc= 0.7788
Epoch 11360: Training cost= 0.3448, Training acc= 0.7785, Validation cost= 0.4075, Validation acc= 0.7789
Epoch 11370: Training cost= 0.4268, Training acc= 0.7785, Validation cost= 0.3653, Validation acc= 0.7789
Epoch 11380: Training cost= 0.3706, Training acc= 0.7786, Validation cost= 0.3722, Validation acc= 0.7790
Epoch 11390: Training cost= 0.3123, Training acc= 0.7787, Validation cost= 0.3882, Validation acc= 0.7791
Epoch 11400: Training cost= 0.3232, Training acc= 0.7787, Validation cost= 0.3180, Validation acc= 0.7791
tm  [ 3.3  2.3  3.1 10.9 -1.  -1.5 -0.2 -0.7 -1.  -0.1 -4.8  1.4 -1.3 -0.7 -1.3 -0.9  0.9 -0.2 -0.3 -2.  -0.4 -0.5  3.6  1.6 -0.8 -0.8 -0.3 -0.3 -0.3  2.  -1.9 -0.5  0.4 -3.1 -0.5  0.6  2.1 -0.9  1.5 -0.3 -0.1  3.6  2.4 -0.9  0.  -0.2  8.1  2.3  3.6  7.1 -0.2  0.  -0.6 -2.6 -0.3  3.5 -0.3  4.1 -1.4  5.8 -2.3 -0.4 -0.7 -0.7 -0.6 -0.6 -0.3 -0.5  1.  -0.3 -0.3  0.4 -0.1 -0.5  1.  -0.  -0.8  0.4 -0.4 -0.5 -0.4 -0.2 -1.3 -0.  -1.5  3.9  2.1 -0.3  1.4 -0.5  1.   2.  -0.2  2.9 -0.2 -0.4  0.3 -0.3  0.1 -0.4  1.1  1.4 -1.3 -0.2 -0.2 -0.2  0.5 -1.9 -2.  -2.3  1.5 -0.4 -0.3 -0.  -0.4  0.3 -0.1 -0.6  0.7  1.1 -0.5  7.3 -0.1 -1.2 -0.1 -1.3  1.6 11.7 -0.4 -0.8  4.5  0.4  1.9 -0.1  6.3 -0.8 -0.4 -0.6 -0.8  0.8  2.6 -1.2  3.7 -0.2 -0.5 -0.  -0.5 -1.1  3.7  0.2 -1.2 -0.   6.9 -0.2 -0.2 -0.2 -0.1 -0.6 -1.6 -0.9 -0.4  2.1 -0.4 -0.1 -1.   1.4 -0.6 -0.6 -0.2  3.5 -0.4  0.7 -0.6 -0.1 -0.4 -0.6 -1.1  1.1 -0.   1.6 -1.6 -0.1  0.1 -0.8 -0.5  1.9  7.2  0.1 -0.4 -0.   0.3 -0.3 -1.2 -0.9 11.3  0.9  1.7  0.3 -0.2 -0.3 -0.4 -0.5  2.1 -0.  -1.1  2.6 -0.3 -0.7  2.9 -0.1 -0.5  0.3 -0.5 -0.7 -0.3 -0.3  5.1 -0.   0.1 -0.4 -1.2 -0.4 -0.  -0.6  2.4  2.3 -1.7 -0.7 -0.6  3.4 -0.1 -0.3  0.5  3.  -0.5 -0.3  0.8  2.3 -0.   2.3 -0.3  0.6 -0.4  0.2  2.5 -2.  -0.1 -0.8 -0.4  1.   0.6 -0.8  2.  -0.4  4.1  5.8]
ty_50sample [[8 9 5 6 0 3 7 4 2 1]
 [5 8 7 3 2 4 1 9 6 6]
 [8 9 4 6 2 5 3 7 0 1]
 [3 7 5 2 0 1 9 4 4 6]
 [7 2 5 1 8 4 6 0 9 3]
 [1 4 0 2 7 3 6 6 8 5]
 [6 2 5 9 8 4 0 7 1 3]
 [4 9 8 1 2 7 3 0 5 6]
 [6 7 2 2 5 4 4 1 0 8]
 [7 2 2 0 5 6 1 8 4 3]]
tt_50sample [[8 9 5 6 0 3 7 4 2 1]
 [5 8 7 3 2 4 9 1 6 0]
 [8 9 4 6 2 5 3 7 0 1]
 [3 7 5 2 0 9 1 4 6 8]
 [7 2 5 1 8 4 6 0 9 3]
 [1 4 0 2 7 3 9 6 8 5]
 [6 2 5 9 8 4 0 7 1 3]
 [4 9 8 1 2 7 3 0 5 6]
 [6 7 2 5 9 4 3 1 0 8]
 [7 2 9 0 5 6 1 8 4 3]]
vm  [-0.1 -0.7 -1.5 -0.2 -1.  -0.3  0.  -0.5  0.8 -0.3  0.9  1.8 -1.1 -0.5 -0.9 -2.2 -0.2 -0.4 -0.4 -1.  -0.7 -0.3 -1.1 -0.2 -0.5  3.4 -0.2 -0.  -1.5 -1.4  6.1  0.1  0.1  5.   1.7 -0.2  0.2 -0.9  2.3 -0.9 -0.4 -0.5 -0.6  2.1 -0.6 -0.2  2.   1.6  1.2 -2.  -0.9 -0.8  0.6 -1.6  2.   2.8 -0.4 -0.7  2.4 -2.  -0.  -0.4 -0.2  4.1 -0.1  0.2  0.1  2.2  1.9  1.  -0.4  3.5 -0.2 -0.2 -1.7 -0.  -0.4 -0.5  1.4 -0.2 11.7 -0.3 -0.3 -0.1 -0.7 -0.7  1.7 -0.  -0.  -0.3  0.7 -1.  -0.6 -0.8 -0.3 -0.2 -0.5 -1.2  0.5 -0.2 -0.5 -0.7 -0.2 -0.5 -0.2  0.1 -1.   7.  -0.  -1.  -0.2  1.3 -0.2 -0.4  7.3 -1.8 -0.4  2.1  0.4  0.8 -0.1  4.9 -0.1  0.  -0.6 -0.8 -0.5  9.3  0.8  0.6  2.5 -0.4 -0.3 -0.2  5.3  9.8 -0.2 -0.2  0.5 -0.8  1.9 -0.4  1.6 -0.1 -0.4 -0.4 -0.3 -0.4  0.6 -0.8  1.1 -0.1 -0.8  1.8 -0.2 -0.  -0.3 -0.4 -0.6  0.8 -0.2 -0.5 -0.2 -0.3 -0.  -0.6 -1.1  3.1 -0.3 -0.  -0.7 -0.6 -0.1 -0.2 -0.3  1.5 -0.5  1.6  0.3  1.1 -0.2  0.5 -0.7 -0.9  1.4 -0.7  2.1 -0.4  1.2  4.1 -0.4 -0.3 -0.9 -0.7  2.8  0.2 -0.2 -0.5 -0.4 -0.  -0.2  1.8 -0.4 -0.6 -0.2 -0.  -0.3 -0.3 -0.9 -0.1 -0.3 -0.8 -1.1  1.2 -0.2 -0.6 -0.4 -0.8 -1.1 -0.1 -0.6 -0.3 -0.5 -0.9  1.1 -1.6 -1.4 -0.3  0.   2.9 -0.6 -0.8 -0.2 -0.7  4.4  5.1  3.2 -0.3  3.9  7.3 -0.5  3.7 -0.3 -0.  -2.2 -1.1 -0.1 -0.2 -1.1 -0.5 -2.6 -0.5  1.9 -0.5  3.6  2.2]
vy_50sample [[0 4 9 6 3 1 7 5 8 2]
 [1 6 9 3 0 8 7 4 5 2]
 [4 1 0 2 8 9 6 7 5 3]
 [9 9 2 4 1 1 5 7 8 3]
 [4 3 0 9 7 8 2 5 1 6]
 [5 9 2 7 0 3 4 1 1 8]
 [1 9 3 2 6 4 7 5 8 0]
 [7 7 1 5 5 4 3 8 2 0]
 [1 4 8 2 5 0 6 9 3 7]
 [1 5 0 2 8 6 9 7 4 3]]
vt_50sample [[0 4 9 6 3 1 7 5 8 2]
 [1 6 9 3 0 8 7 4 5 2]
 [4 1 0 2 8 9 6 7 5 3]
 [9 0 4 2 1 6 5 7 8 3]
 [4 3 0 9 7 8 2 5 1 6]
 [9 5 2 7 0 3 1 4 6 8]
 [1 9 3 2 6 4 7 5 8 0]
 [7 1 6 9 5 4 3 8 2 0]
 [1 4 8 2 5 0 6 9 3 7]
 [1 5 0 2 8 6 9 7 4 3]]
Epoch 11410: Training cost= 0.3297, Training acc= 0.7788, Validation cost= 0.3474, Validation acc= 0.7792
Epoch 11420: Training cost= 0.3422, Training acc= 0.7789, Validation cost= 0.3301, Validation acc= 0.7793
Epoch 11430: Training cost= 0.3688, Training acc= 0.7789, Validation cost= 0.3685, Validation acc= 0.7793
Epoch 11440: Training cost= 0.3621, Training acc= 0.7790, Validation cost= 0.4008, Validation acc= 0.7794
Epoch 11450: Training cost= 0.4207, Training acc= 0.7791, Validation cost= 0.3613, Validation acc= 0.7795
Epoch 11460: Training cost= 0.3243, Training acc= 0.7791, Validation cost= 0.3075, Validation acc= 0.7796
Epoch 11470: Training cost= 0.3303, Training acc= 0.7792, Validation cost= 0.4340, Validation acc= 0.7796
Epoch 11480: Training cost= 0.4115, Training acc= 0.7793, Validation cost= 0.4043, Validation acc= 0.7797
Epoch 11490: Training cost= 0.4336, Training acc= 0.7793, Validation cost= 0.3891, Validation acc= 0.7797
Epoch 11500: Training cost= 0.3864, Training acc= 0.7794, Validation cost= 0.4738, Validation acc= 0.7798
tm  [ 2.  -0.3  4.3 -3.3 -2.1 -0.9 -0.4 -0.3 -0.5  0.   4.3 -0.4 -0.3 -0.2 15.1  3.8 -0.2 -0.1 -0.3  2.3 -0.1 -0.3  2.9 -0.3 -1.1 -0.5 -0.2  0.   1.   0.7  3.5 -0.5 -0.4  9.8  0.7 -0.4  0.9  1.7 -1.3 -1.  -0.1  4.9  0.9  2.9 -0.4  0.5 -2.2 -0.5  2.3  3.8 -0.9 -0.6 -1.   8.7 -1.4 -2.2 -0.4  0.9  0.7 -0.9  1.1 -0.6 -0.3  1.   1.6 -0.6 -0.2 -0.1  0.1 -0.6  0.  -0.7 -0.1 -0.5 -5.5 -0.1 -0.8  0.4 -0.  -0.3 -2.  -0.4  0.8  0.6 -1.2  5.7  3.  -0.1 -0.1 -0.3 -0.6 -0.4 -0.6 -0.2 -0.9 -0.2 -0.4 -1.8 -0.4 -0.1 -0.   8.3 -0.7 -0.1 -0.5 -0.2 -3.1  3.7  2.   2.9  0.2 -0.6 -0.1 -1.  -0.3  3.5 -0.1  1.8 -0.3 -0.7 -0.3 -1.4 -0.4 -0.4 -0.5 16.2 -0.2 -2.2  3.1  2.   1.9 -0.5  0.6 -0.3 -3.8  1.3 -0.4 -0.6 -1.1 -0.9 -0.5  0.5 -0.3 -0.2 -0.3 -0.2 -0.2 -0.9 -0.7  0.1  4.5  0.1  3.  -0.8 -0.4 -0.2 -0.5 -0.2 -0.3 -0.8  0.3 -0.7 -0.  -0.5  1.8 -0.  -0.9 -0.1 -0.  -1.   1.   0.9 -0.5 -0.2 -0.4  2.1 -0.8 -1.7  6.  -0.3 -1.6 -0.1 -0.2 -1.2 -0.5 -0.3  0.6 -1.  -0.8 -0.4 -0.5 -0.5  0.4 -1.2  0.9 -0.4 -2.1 -0.1 -0.4 -0.4  0.  -0.1 -0.  -0.1 -1.  -3.4  0.8 -0.1 -1.6 -0.2 -0.2  0.8 -0.3 -0.4  1.3  0.  -0.7 -0.2  0.5 -0.3 -0.7 -0.2 -0.3 -0.2  1.9  1.6 -0.1 -0.3 -0.   4.7 -0.9  2.  -0.3 -1.2 -0.8 -0.8  0.8 -2.6 -0.  -4.  -0.3 -2.2  0.2 -0.1  7.2  5.6 -0.6 -0.3 -0.2  1.2  3.9  1.6 -1.  -0.4 -0.  -0.2]
ty_50sample [[7 5 4 2 6 6 0 3 1 9]
 [9 1 7 4 8 6 5 2 0 3]
 [3 9 0 6 5 4 7 1 2 8]
 [9 4 2 3 8 0 7 6 5 1]
 [6 3 4 9 1 1 0 8 7 2]
 [1 5 5 9 9 8 3 4 2 2]
 [4 3 6 8 5 1 9 7 2 0]
 [9 4 3 6 7 8 2 1 5 0]
 [8 5 9 7 1 2 4 3 6 0]
 [9 6 1 7 8 4 3 5 2 0]]
tt_50sample [[7 5 4 2 6 8 0 3 1 9]
 [1 9 7 4 5 8 6 2 0 3]
 [3 9 0 6 5 4 7 1 8 2]
 [9 4 2 3 8 0 7 6 5 1]
 [6 3 4 1 5 9 0 8 7 2]
 [1 5 7 9 0 8 3 4 6 2]
 [4 3 6 8 5 1 9 7 2 0]
 [9 4 3 6 7 8 2 1 5 0]
 [8 5 9 7 1 2 4 3 6 0]
 [1 6 9 7 4 8 3 5 2 0]]
vm  [ 0.7 -0.2 -1.4  1.8 -0.8 -0.8 -0.5 -0.6 -0.6 -0.4 -1.8  0.8 -0.7 -0.2 -1.6 -1.3 -0.  -0.3 -0.2 -0.8 -0.7  0.1  2.   1.2 -1.2  2.6 -0.5 -0.1 -1.2 -1.2 -0.1 -0.2 -0.7 -3.3 -0.  -0.2  3.4  1.9  7.7 -1.1 -0.2  1.5  1.3  4.5 -0.6 -0.2  3.   0.   1.9  2.7 -0.3 -0.4 -0.8 -0.4  0.7  4.4 -0.6  1.4  0.2  2.6 -0.5 -0.5 -0.5  1.9 -0.4 -0.4 -0.1  0.2  1.5 -0.2 -0.5  3.   0.3 -0.5 -1.5  0.1 -0.3 -0.6 -0.   0.3 -0.8 -0.1 -0.7  0.6 -0.8  1.3  1.3 -0.3  2.1 -0.1 -0.5 -0.3 -0.4  1.8 -0.6 -0.3  1.  -0.7 -0.1 -0.3  0.9 -1.6 -0.6 -0.3  0.2 -0.5 -1.4 -0.2 -0.7 -1.2 -0.1 -0.  -0.2 -0.4  3.3 -1.5 -0.2  0.1 -0.2  1.7 -0.4  3.7 -0.3 -0.9 -0.7 -1.7  0.4  5.   1.9  2.2 -0.1 -0.2 -0.3 -0.1  0.8 -3.7 -0.2 -0.7  1.  -0.6  1.1 -1.2  0.6 -0.2 -0.1 -0.5 -0.4 -0.8  5.7 -0.5 -0.4  0.2  4.9 -0.1 -0.4 -0.2  0.8 -0.3  2.4 -0.6 -0.3 -1.5 -0.3 -0.4 -1.  -0.3 -0.5 -0.4 -0.6  0.7  0.1  0.7 -0.2  0.  -0.5 -1.5  0.8 -0.2 -1.2 -0.2 -1.2 -0.4  0.4 -1.2  1.  -0.2  3.7  0.   0.3  6.3 -0.7 -0.4 -0.8 -1.4  4.8 -0.5 -0.8 -0.3 -0.2 -0.1 -0.1 -0.3 -0.2 -0.4 -0.7 -1.1  0.4 -0.3  0.8 -0.2 -0.5 -0.8 -0.4 -0.6 -0.3  0.1 -1.  -0.6 -0.6 -0.2 -0.6 -0.4 -0.2 -1.  -1.  -0.4 -1.2 -0.1 -0.4  2.6 -1.1  1.2 -0.4  0.3  2.4  4.8  3.3 -0.7  0.7 -0.6 -0.3 -0.3 -0.6 -0.3  4.5 -1.1  1.2 -0.5 -0.8 -0.1  1.2 -0.7  6.6 -0.6  2.8  0.8]
vy_50sample [[0 5 5 3 4 9 2 1 7 6]
 [4 4 6 7 3 3 0 0 5 2]
 [1 5 3 6 0 4 7 9 9 2]
 [6 3 7 0 2 9 1 8 5 4]
 [7 6 4 2 8 5 9 1 3 0]
 [6 8 3 2 5 1 4 7 7 0]
 [7 3 0 0 6 1 8 5 5 5]
 [7 1 5 8 0 0 6 3 4 2]
 [7 0 4 9 2 1 8 6 3 5]
 [4 5 7 1 9 0 8 3 6 2]]
vt_50sample [[0 5 8 3 4 9 2 1 6 7]
 [4 8 6 7 3 1 0 9 2 5]
 [1 5 3 6 0 4 7 8 9 2]
 [3 6 7 0 2 9 1 8 5 4]
 [7 6 2 4 8 5 9 1 3 0]
 [6 8 3 2 5 1 4 7 9 0]
 [7 3 0 9 6 1 8 4 5 2]
 [7 1 5 8 9 0 6 3 4 2]
 [7 0 4 2 9 1 8 6 3 5]
 [4 5 1 7 9 8 0 3 6 2]]
Epoch 11510: Training cost= 0.3436, Training acc= 0.7794, Validation cost= 0.4002, Validation acc= 0.7798
Epoch 11520: Training cost= 0.3798, Training acc= 0.7795, Validation cost= 0.3349, Validation acc= 0.7799
Epoch 11530: Training cost= 0.3750, Training acc= 0.7796, Validation cost= 0.3651, Validation acc= 0.7800
Epoch 11540: Training cost= 0.3630, Training acc= 0.7796, Validation cost= 0.3932, Validation acc= 0.7800
Epoch 11550: Training cost= 0.3666, Training acc= 0.7797, Validation cost= 0.3480, Validation acc= 0.7801
Epoch 11560: Training cost= 0.3589, Training acc= 0.7798, Validation cost= 0.3520, Validation acc= 0.7802
Epoch 11570: Training cost= 0.3379, Training acc= 0.7798, Validation cost= 0.3436, Validation acc= 0.7802
Epoch 11580: Training cost= 0.3195, Training acc= 0.7799, Validation cost= 0.3915, Validation acc= 0.7803
Epoch 11590: Training cost= 0.3872, Training acc= 0.7800, Validation cost= 0.3475, Validation acc= 0.7804
Epoch 11600: Training cost= 0.3088, Training acc= 0.7800, Validation cost= 0.3811, Validation acc= 0.7804
tm  [-1.3 -0.4  7.   9.7 -1.4 -0.  -0.  -0.3 -0.5  1.1  3.4 -0.5  0.7 -0.1  2.6  4.6 -0.8 -0.1 -0.3 -1.9 -0.6 -0.2  3.1 -0.5 -0.6  0.8 -0.1 -0.1  1.5  0.5 -0.2 -0.4 -0.2  6.9 -0.1 -0.2  1.8  1.4  6.5 -0.1 -0.2  1.  -0.7 -0.2 -0.3 -0.2  6.5 -0.2 -1.1  7.  -0.6 -0.2  1.5 -0.3 -1.3 -0.1 -0.5 -0.4  1.   2.3  0.3  0.4 -0.2  0.5  0.7 -0.2 -0.2 -0.  -0.3 -0.5 -0.2 -0.9 -0.1 -0.1  1.3 -0.3  0.2 -0.   2.  -0.2  7.4 -0.2 -0.6  0.2  0.2  2.  -0.8 -0.3 -0.3 -0.1 -0.1 -0.  -0.5 -1.   0.7 -0.1 -0.3 -0.  -0.3  0.3 -0.5  8.4  2.2 -0.1 -0.4 -0.   0.5 -0.3  1.2 -1.9 -0.5 -0.6  0.3 -0.3  0.3  4.6 -0.5 -0.7 -0.5 -0.8 -0.2  6.8 -0.1 -0.3  0.1  2.2 -0.2  3.2  0.4 -2.1 -0.2 -0.8 -0.7 -0.3 -2.2  0.2 -0.  -0.3 -0.5 -1.  -0.4 -0.2 -0.4 -0.3 -0.5  0.1  0.1  1.1 -2.   1.5 -0.7  0.1 -0.3 -0.4  0.3 -0.1 -0.2 -0.4 -0.1 -0.1  1.6 -0.  -0.4 -0.3 -0.1 -0.6  0.1  2.5 -0.4  2.7  0.6 -1.  -0.2  0.5 -0.2  5.8 -0.6  2.3 -0.9 -0.8  0.6  0.2 -0.4 -1.  -0.9 -0.4 -0.  -0.6 -0.4 -0.  -0.3 -0.7 -1.5 -0.4  1.2  0.3  2.3  1.1 -0.5 -0.5 -0.4 -0.  -0.6 -0.3  1.   2.2 -0.3  0.3  5.3 -0.3  1.1  3.9 -0.9  5.  -0.5 -0.5  2.1 -0.5 -0.1  0.2 -0.9 -0.5  0.1 -0.8  2.9  2.4 -0.2  3.6  0.2 -0.4 -0.4 -0.8 -0.1  3.  -0.5 -1.6  1.   2.1  0.6 14.2 -0.4  7.2 -0.  -0.2 -1.1 -2.  -0.3  0.6 -0.8 -0.6 -1.8 -0.1  5.3  0.6 -0.3 10.8]
ty_50sample [[7 9 1 2 8 6 4 0 5 3]
 [3 7 0 8 6 9 4 2 1 5]
 [3 3 7 6 9 9 2 5 4 0]
 [5 0 9 9 6 1 4 3 2 7]
 [7 6 6 8 4 4 9 1 0 3]
 [5 7 1 3 9 9 0 2 8 4]
 [1 2 7 9 8 8 4 5 3 6]
 [5 6 8 0 7 1 3 2 9 4]
 [6 4 4 8 1 0 9 5 2 3]
 [7 6 2 5 0 4 9 3 8 1]]
tt_50sample [[7 9 1 2 8 6 4 0 5 3]
 [3 7 0 8 6 9 4 2 1 5]
 [1 3 8 6 7 9 2 5 4 0]
 [5 0 8 9 6 1 4 3 2 7]
 [7 6 5 4 8 2 9 1 0 3]
 [5 7 1 3 9 6 0 2 8 4]
 [1 2 7 9 0 8 4 5 3 6]
 [5 6 8 0 7 1 3 2 9 4]
 [6 7 4 8 1 9 0 5 2 3]
 [7 6 2 5 0 4 9 3 8 1]]
vm  [-0.9 -0.1 -0.8  4.2 -0.8 -0.3 -0.1 -0.4 -0.3 -1.2  8.4  1.   1.  -0.2 -1.6  2.7  1.9 -0.4 -0.2 -1.7 -0.8 -0.2 -1.8 -0.2 -0.9  2.2 -0.4  0.2 -0.6 -1.1  3.7 -0.4 -0.2  3.2  0.3  2.   1.2  4.   8.8 -0.3 -0.2 -2.8 -1.4  3.3 -1.1 -0.5  8.3 -0.9 -0.8 -3.1 -0.6 -0.3  0.3  1.2 -0.9  4.  -0.2 -1.1  0.6 -1.1  0.8  0.5 -0.5 -0.1  0.5 -0.4 -0.1  1.9 -0.7  0.2 -0.4  1.2 -0.2 -0.5  1.7  0.6  1.1 -1.1  0.  -0.1 14.4 -0.2 -0.9 -0.4  0.5 -2.9 -0.3 -0.5  1.4 -0.3 -0.8 -0.   1.1  0.2 -0.4 -0.4 -0.8  0.6 -0.5 -0.1  4.1 -2.   1.3 -0.3 -0.5 -0.1 -0.5  4.2  2.9 -2.2 -0.6 -0.1 -0.4 -0.   3.  -0.2  0.8 -0.1 -0.3 -0.3 -0.4  8.2 -0.2 -0.2 -0.3 -1.6  0.1  0.4 -0.4  3.4 -0.9 -0.6 -0.5 -0.1 -0.3  3.6 -0.2  0.6  3.5 -0.9 -0.8 -0.1 -1.2 -0.3  0.2 -0.9 -0.2  0.1 -0.7 -0.6 -0.4 -0.3 -1.2 -0.8 -0.1 -0.2 -0.  -0.2  1.8 -0.9 -1.1 -1.1 -0.5 -0.3 -0.  -0.1  0.   3.6 -0.4  0.8 -1.1 -0.9 -0.3  0.5 -0.8  3.  -0.3 -0.2 -1.6 -0.7  1.3 -0.1  0.3 -1.2 -0.1 -0.4  0.2 -0.3 -0.1  6.  -0.1  1.1 -1.2 -0.5  1.3  1.7  0.8 -0.  -0.4 -0.  -0.  -0.4 -0.5 -0.7 -0.2  0.5 -0.1 -0.2  3.2 -0.2  0.2 -0.3 -0.7  2.9  0.9  0.3 -0.7 -0.5 -0.5  0.   1.  -0.2  0.9 -1.  -1.3 -0.5  0.5  1.7 -0.1  0.4 -1.6 -0.1 -0.4  2.7  1.   2.7  0.1  0.5 -0.6 16.3 -0.6  8.7 -0.5 -0.4 -2.8 -1.8  0.2 -0.5 -0.7 -0.7 -3.2 -0.7  7.2 -0.4  1.7 -0.4]
vy_50sample [[3 3 1 1 0 4 7 6 8 5]
 [3 2 5 8 1 9 7 4 6 0]
 [6 6 9 7 7 3 2 4 8 1]
 [2 1 5 4 9 6 6 7 8 3]
 [8 3 6 7 7 0 5 4 4 2]
 [1 8 3 2 4 5 0 6 7 9]
 [3 0 4 9 5 1 7 6 2 8]
 [4 3 2 6 5 1 8 7 0 9]
 [2 1 5 5 3 4 9 6 8 0]
 [5 2 3 4 9 8 7 0 6 1]]
vt_50sample [[3 2 9 1 4 0 7 6 8 5]
 [3 2 5 8 1 9 7 4 6 0]
 [9 6 5 0 7 3 2 4 8 1]
 [2 1 5 4 9 0 6 7 8 3]
 [8 6 3 7 9 0 1 5 4 2]
 [1 8 3 2 5 4 0 6 7 9]
 [3 4 0 9 5 1 7 6 2 8]
 [4 3 2 6 5 8 1 7 9 0]
 [2 7 1 5 3 9 4 6 8 0]
 [5 2 3 4 9 8 7 0 6 1]]
Epoch 11610: Training cost= 0.3937, Training acc= 0.7801, Validation cost= 0.3268, Validation acc= 0.7805
Epoch 11620: Training cost= 0.3425, Training acc= 0.7801, Validation cost= 0.4369, Validation acc= 0.7806
Epoch 11630: Training cost= 0.4168, Training acc= 0.7802, Validation cost= 0.4164, Validation acc= 0.7806
Epoch 11640: Training cost= 0.3401, Training acc= 0.7803, Validation cost= 0.2911, Validation acc= 0.7807
Epoch 11650: Training cost= 0.3380, Training acc= 0.7803, Validation cost= 0.3426, Validation acc= 0.7807
Epoch 11660: Training cost= 0.3404, Training acc= 0.7804, Validation cost= 0.3723, Validation acc= 0.7808
Epoch 11670: Training cost= 0.3887, Training acc= 0.7805, Validation cost= 0.3976, Validation acc= 0.7809
Epoch 11680: Training cost= 0.3547, Training acc= 0.7805, Validation cost= 0.3287, Validation acc= 0.7809
Epoch 11690: Training cost= 0.4010, Training acc= 0.7806, Validation cost= 0.3028, Validation acc= 0.7810
Epoch 11700: Training cost= 0.3802, Training acc= 0.7806, Validation cost= 0.3754, Validation acc= 0.7811
tm  [ 0.4 -0.5 -1.1 -0.8 -0.9 -0.6  0.2 -0.5  1.8 -1.  10.1  0.6 -0.1 -0.4  0.4  1.9  0.3 -0.4 -0.1 -0.1 -1.  -0.3 -2.1  0.  -1.   1.7 -0.4 -0.2 -0.9 -1.6  5.2 -0.6 -0.1  4.3  0.9 -0.2 -0.   4.3  0.4 -0.9  0.  -1.6 -0.8  3.  -0.9 -0.3 -1.1 -0.9  2.8 -4.  -0.6 -0.9 -0.2  6.  -0.4  1.1 -0.2 -0.1  3.1 -1.6  0.6 -0.5  0.3  4.3 -0.2 -0.4 -0.   2.2 -0.3  0.3 -0.5  0.7 -0.1  0.  -3.6  0.1 -1.  -0.8 -0.4 -0.5  6.4 -0.1  0.4 -0.3 -1.1 -1.8  1.6 -0.4  1.1 -0.3 -0.1 -0.8  0.7 -0.4 -0.4 -0.1 -0.5 -1.7 -0.1 -0.6  2.8 -2.5 -0.5 -0.1 -0.3 -0.1 -1.8  5.3  2.6  0.3 -0.3  0.3 -0.4 -0.7  3.9 -0.5 -0.2  2.3  0.8  1.  -0.1  0.  -0.3  0.6 -0.4  0.4 -0.3 -1.1  3.8  7.4  1.1 -0.4  0.1 -0.1  3.5  6.3 -0.1  0.4  3.2 -0.3 -0.8 -0.1 -0.7 -0.2  0.1 -0.1 -0.5 -0.7  3.  -0.7  1.5 -0.3 -0.3 -0.4 -0.5  0.1 -0.6 -0.2  1.5  1.  -0.4 -1.1 -0.1 -0.2 -0.  -0.3  0.2  1.9  0.5 -0.2 -1.3 -0.3 -0.3 -0.2 -0.8 -0.1 -0.2 -0.7  1.2 -0.3 -0.3 -0.3 -0.3 -1.2  1.2 -0.8  1.8 -0.2 -0.6  7.6 -0.   1.  -0.4 -0.9  2.2 -0.9 -0.8 -0.7 -0.3 -0.1  0.1  0.4 -0.3 -1.2 -0.7 -1.6 -0.1  0.1 -1.9 -0.  -0.3 -0.  -0.8 -0.3 -0.4 -0.2 -0.5 -0.7 -0.6 -0.2 -0.  -0.2 -0.3 -0.8 -1.1 -1.1  0.1  0.9  0.1  5.7 -1.  -0.1 -0.5 -1.2  2.1  4.1  0.8 -1.5  1.5 -0.1 -0.3  0.2 -0.5 -0.3 -1.1 -0.3 -0.1 -0.6 -1.  -0.6 -1.4 -0.5  0.9 -0.2  2.2 -1.8]
ty_50sample [[3 2 0 0 5 5 6 7 7 8]
 [1 6 8 4 9 7 3 5 2 0]
 [1 4 9 5 2 7 8 3 0 6]
 [5 4 9 7 0 8 3 6 2 1]
 [5 0 2 8 7 7 9 1 6 4]
 [5 2 0 4 8 9 1 3 7 6]
 [9 5 1 8 2 6 3 7 4 4]
 [6 5 1 4 9 3 8 7 7 2]
 [4 1 3 7 5 0 6 9 8 8]
 [9 0 8 1 4 5 3 7 6 2]]
tt_50sample [[3 2 0 4 5 6 9 1 7 8]
 [6 1 8 4 9 3 7 5 2 0]
 [4 1 9 5 2 7 8 3 0 6]
 [5 4 9 0 7 8 3 6 2 1]
 [5 0 2 8 7 3 9 1 6 4]
 [5 2 0 4 8 9 1 3 7 6]
 [9 5 1 8 2 6 3 7 4 0]
 [6 5 1 4 9 3 0 8 7 2]
 [4 3 1 7 5 0 6 9 8 2]
 [9 0 8 1 4 3 5 7 6 2]]
vm  [ 0.6 -0.3 -1.1 -2.  -0.9 -0.4 -0.2 -0.2  0.9 -0.6 -0.3  3.  -1.4 -0.8  3.4 -1.5 -0.3 -0.5 -0.3  2.6 -0.5  1.1 -1.6 -0.1 -0.9  2.  -0.5 -0.2 -0.9 -1.7  3.  -0.3  2.4  0.4  0.4 -0.8  0.2 -0.7 -2.9 -1.   0.3 -1.7 -0.9 -0.2 -0.5 -0.3 -1.9  0.4  1.1 -2.9 -0.6 -0.8 -0.3  2.2 -0.2 -0.3 -0.3 -0.3  3.  -0.5  4.5 -0.7  0.8  2.   0.2 -1.   0.   2.   1.7  0.6 -0.2  1.8 -0.5 -0.6 -5.9  0.9 -0.7 -0.7 -0.4 -0.4 -1.1 -0.1  1.2 -0.  -1.  -1.8  0.8 -0.2  1.2 -0.3 -0.5 -0.7 -0.1  0.2 -0.9 -0.4 -0.4 -2.  -0.2 -0.3  1.  -2.3 -0.2 -0.3 -0.4 -0.2 -3.4  3.1 -0.2  3.9  0.1  0.7 -0.3 -0.9  6.6 -1.5  0.7  4.1  0.1  2.9 -0.1 -1.6 -0.3 -0.  -0.6  4.2 -0.1  0.6  1.5 10.2  1.8 -0.5 -0.  -0.2  8.3  9.7 -0.2 -0.2  2.1 -0.7  1.4 -0.3  0.7 -0.3 -0.6 -0.4 -0.3 -1.   2.4 -0.8  2.3 -0.4  0.3  2.  -0.5  0.  -0.3  0.7 -1.  -0.8 -0.7 -0.5  1.8 -0.3  0.  -0.4 -0.5  2.6 -0.6 -0.7 -1.1 -0.2 -0.3 -0.2 -0.5 -0.1 -1.5 -1.8  9.9  2.3 -0.2 -0.4 -0.  -1.4  1.5 -0.9 -0.4 -0.1 -0.1  6.4 -0.4  0.7  0.  -1.3 -0.7 -0.2 -2.3 -0.9 -0.4 -0.4 -0.   0.3 -0.  -0.6 -1.  -3.   0.2 -0.7 -0.2 -0.3 -0.3 -0.9 -0.6 -0.2 -0.2  0.8  1.2 -0.7 -0.5  0.6 -0.7 -0.3  0.4 -1.  -0.4 -1.  -1.8 -0.2 -0.   4.4 -0.2  3.8 -0.5  0.1  0.8  3.9  1.5 -3.2  1.4 -1.5 -0.3 -0.8 -0.6 -0.   4.8  3.1  0.  -0.6 -0.5 -0.1  1.8 -1.1 -2.2 -1.   5.4 -3. ]
vy_50sample [[3 0 6 4 5 1 8 7 2 9]
 [2 1 4 6 8 7 3 0 0 5]
 [7 0 9 2 3 6 5 8 1 4]
 [6 4 5 7 7 1 2 2 0 3]
 [1 7 8 6 3 5 4 4 2 0]
 [1 3 4 9 6 7 2 5 8 8]
 [5 2 6 9 4 0 1 3 7 8]
 [2 6 8 4 1 5 3 7 0 0]
 [1 7 9 9 0 6 8 3 5 4]
 [0 0 2 6 9 4 3 3 7 5]]
vt_50sample [[3 0 6 4 5 1 8 7 2 9]
 [2 1 4 6 8 7 3 9 5 0]
 [7 0 2 9 3 6 5 8 1 4]
 [6 4 5 7 8 1 9 2 3 0]
 [1 7 8 6 3 5 9 4 2 0]
 [1 3 4 9 6 7 2 5 8 0]
 [5 2 6 9 4 0 1 3 7 8]
 [2 6 8 4 1 5 3 7 9 0]
 [1 7 2 9 6 8 0 3 5 4]
 [0 8 2 6 9 4 1 3 7 5]]
Epoch 11710: Training cost= 0.3908, Training acc= 0.7807, Validation cost= 0.4354, Validation acc= 0.7811
Epoch 11720: Training cost= 0.3954, Training acc= 0.7808, Validation cost= 0.3702, Validation acc= 0.7812
Epoch 11730: Training cost= 0.3823, Training acc= 0.7808, Validation cost= 0.4185, Validation acc= 0.7812
Epoch 11740: Training cost= 0.2992, Training acc= 0.7809, Validation cost= 0.3950, Validation acc= 0.7813
Epoch 11750: Training cost= 0.3535, Training acc= 0.7809, Validation cost= 0.3629, Validation acc= 0.7814
Epoch 11760: Training cost= 0.3498, Training acc= 0.7810, Validation cost= 0.3183, Validation acc= 0.7814
Epoch 11770: Training cost= 0.2868, Training acc= 0.7811, Validation cost= 0.4113, Validation acc= 0.7815
Epoch 11780: Training cost= 0.4063, Training acc= 0.7811, Validation cost= 0.3416, Validation acc= 0.7815
Epoch 11790: Training cost= 0.3386, Training acc= 0.7812, Validation cost= 0.3559, Validation acc= 0.7816
Epoch 11800: Training cost= 0.3589, Training acc= 0.7812, Validation cost= 0.3599, Validation acc= 0.7817
tm  [-0.9  0.4 -1.1 -2.8 -0.9 -0.1 -0.2 -0.4 -0.7  0.6 -2.5 -0.1 -0.7 -0.1  5.3 -0.4 -0.2  0.3 -0.4  3.5 -0.6 -0.4  4.2  1.6 -1.4  2.2 -0.3 -0.2 -0.8 -0.5 -0.6 -0.1  1.  -3.6 -0.2 -0.3  2.5 -0.3 -3.3 -0.2 -0.1  2.7  0.5 -0.2 -1.1 -0.5 -2.5 -0.2 -1.2  9.6 -0.4 -0.8 -1.6  6.1 -0.6 -0.5 -1.1 -0.3  0.4  2.6 11.8 -0.2 -0.2 -0.4 -0.5 -0.3 -0.3  0.9 -0.  -0.6 -0.4  1.5 -0.1 -0.5 -5.7 -0.4  2.6 -0.3  2.8 -0.1 -5.4 -0.1  2.1  0.8  1.4  3.4 -0.3  0.1 -0.3 -0.1 -0.4 -0.2 -0.8  0.8 -1.2 -0.1 -0.2 -1.7 -0.3 -0.7 -0.5  2.5  4.  -0.4 -0.3 -0.3 -3.5 -0.7 -1.2  4.4 -0.3 -0.2 -0.  -0.3  3.1 -0.7 -0.4 -0.3 -0.1  1.3 -0.5 -2.  -0.5 -0.3 -0.2  5.8 -0.1 -1.  -0.2  2.5 -0.3  0.4 -0.4 -0.1  8.7 -0.8 -0.3 -0.6 -0.2 -0.1  0.7 -0.8 -0.2 -0.4 -0.4 -0.4 -0.   0.7  2.6 -0.1  2.3 -0.4  0.2 -0.2 -0.4 -0.1 -0.  -0.4 -0.6 -0.3  1.2  1.  -0.2  0.1 -1.3 -0.5 -0.7  1.1 -0.1 -0.6 -0.  -0.3 -0.2 -0.1 -0.3 -0.1 -1.3 -1.6 10.6 -0.  -0.2 -0.1  1.4 -1.2 -0.   0.  -2.  -0.1 -0.8  1.4 -0.3 -0.7  2.5 -1.6 -3.   1.  -2.1  0.1 -0.3 -0.4 -0.3 -0.1  0.2 -0.8  0.5 -3.6 -0.7 -0.6  6.5 -0.4 -0.5 -0.7 -0.4  5.8  0.6 -0.2  1.4 -0.5 -0.4 -0.2 -0.8 -0.1 -0.3 -1.2  4.1  0.7 -1.4  2.1 -0.6 -1.  -0.2  3.1 -0.5  3.9  1.4  3.6  1.4 -3.1  0.6 -2.3 -0.3 -1.3 -0.2 -0.3 16.   5.5  1.3 -0.4 -0.3  0.5 11.9  0.  -2.6 -0.5  1.1 -0.3]
ty_50sample [[1 8 6 0 4 5 2 7 3 9]
 [1 1 7 0 9 5 2 4 3 6]
 [1 0 8 2 6 3 5 7 9 4]
 [0 1 5 4 8 2 3 7 6 9]
 [2 7 5 1 0 6 8 4 3 9]
 [3 1 1 0 5 8 6 4 9 9]
 [2 5 7 3 4 6 9 8 8 1]
 [2 8 0 1 4 3 5 9 6 7]
 [1 9 8 8 2 2 4 0 7 3]
 [2 9 8 5 0 6 6 1 3 4]]
tt_50sample [[1 8 6 0 4 5 2 7 3 9]
 [8 7 1 0 9 5 2 4 3 6]
 [1 0 8 2 6 3 5 7 9 4]
 [0 1 5 4 8 3 2 7 6 9]
 [2 7 5 1 0 6 8 4 3 9]
 [3 1 2 0 5 8 4 6 7 9]
 [2 5 7 3 4 6 9 8 0 1]
 [2 8 0 1 4 3 5 6 7 9]
 [1 9 6 8 2 5 4 0 7 3]
 [2 9 8 5 6 7 0 1 3 4]]
vm  [ 2.  -0.2  7.5 11.8 -1.8 -0.8 -0.3 -0.1 -0.2 -0.5  4.6 -0.1 -0.4 -0.3 -0.   2.6 -0.3 -0.4  1.6 -1.  -0.4 -0.1  0.7 -0.1 -0.9  1.1 -0.4 -0.2 -0.6 -0.7 -0.5 -0.3 -0.6  5.8  0.2  0.3  0.8  3.6 10.9 -1.1 -0.1  2.2  0.1  1.9  0.2  0.4  5.7 -0.4  4.6  1.3 -0.8 -0.2  3.2 -0.4 -0.3  0.9 -0.3  3.8  0.5  3.4 -2.2 -0.4  0.8  4.5  0.1 -0.1 -0.3 -0.7  0.4 -0.   0.4  1.   0.5  0.6  2.5  0.  -1.3 -0.2 -0.6  0.2  9.4 -0.2 -0.3 -0.2 -1.6  2.1  1.1 -0.3  0.5 -0.3 -0.1 -0.5 -0.5 -0.4  1.   0.2  1.3 -0.7 -0.3  0.8  1.3  4.9 -1.1 -0.1 -0.1  0.3  1.6 -0.4  1.5 -1.8 -0.4  0.2 -0.  -0.3  0.4 -0.2 -0.   0.6 -0.1 -0.3  0.2  6.2 -0.1 -0.4 -0.1  0.1 -0.4  3.7  3.1 -1.1  1.1 -0.7 -0.4 -0.5 -3.9 -1.3  0.1 -0.7 -0.2 -0.4 -0.4 -0.7 -0.2  0.4 -0.1  0.6 -0.1 -1.  -0.5 -0.2 -1.1  0.   5.  -0.4  0.1 -0.2 -0.1 -0.4  3.5 -0.4  0.9 -1.1 -0.2 -0.3 -0.  -0.6  0.2 -0.5 -0.2  3.1 -0.1 -0.4 -0.2 -0.1 -0.3  2.9  0.5  3.9 -2.1 -0.2 -0.9 -0.8 -0.6 -1.  -0.4 -0.4  6.8 -0.5 -0.1  3.  -0.1 -0.4 -1.2 -0.4 10.3 -0.9  4.  -0.4 -0.1  0.1 -0.2 -0.3 -0.1 -0.4 -1.   3.8  0.7  0.  -0.  -0.1 -0.5  0.7 -0.7 -0.9 -0.9 -0.2 -0.1 -0.3  0.6 -0.2 -0.9 -0.3 -0.3 -0.5 -0.5  0.1  0.3  0.9 -0.   5.7 -0.4 -1.  -0.3  0.   1.5 -1.9  0.7  5.   1.3  7.3 -0.2  3.6 -0.2 -0.3 -1.5 -2.5 -0.5  1.  -0.8 -0.5 -2.2 -0.5  8.8  1.  -0.   6.3]
vy_50sample [[9 7 2 0 5 8 3 4 6 1]
 [7 1 0 5 3 6 9 8 2 4]
 [5 4 7 2 3 1 6 6 0 9]
 [2 8 3 1 1 9 7 0 6 4]
 [7 4 9 6 5 8 2 0 1 3]
 [5 0 8 3 2 4 4 7 9 9]
 [2 2 9 5 5 0 3 7 4 6]
 [0 4 6 7 5 1 2 9 3 8]
 [4 0 6 7 3 1 8 9 5 2]
 [5 2 9 8 1 3 0 4 6 7]]
vt_50sample [[9 7 2 0 5 3 8 4 6 1]
 [7 1 0 5 3 6 9 8 2 4]
 [5 4 7 2 3 1 8 6 0 9]
 [2 8 3 1 5 9 7 0 6 4]
 [7 4 9 6 5 8 2 0 1 3]
 [5 0 8 3 6 2 4 7 9 1]
 [2 8 9 1 5 0 3 7 4 6]
 [0 4 6 7 5 1 2 9 3 8]
 [4 0 6 7 3 1 8 9 5 2]
 [5 2 9 8 1 3 0 4 6 7]]
Epoch 11810: Training cost= 0.3452, Training acc= 0.7813, Validation cost= 0.3743, Validation acc= 0.7817
Epoch 11820: Training cost= 0.3443, Training acc= 0.7814, Validation cost= 0.3014, Validation acc= 0.7818
Epoch 11830: Training cost= 0.3283, Training acc= 0.7815, Validation cost= 0.3183, Validation acc= 0.7819
Epoch 11840: Training cost= 0.3561, Training acc= 0.7815, Validation cost= 0.3482, Validation acc= 0.7819
Epoch 11850: Training cost= 0.3194, Training acc= 0.7816, Validation cost= 0.3710, Validation acc= 0.7820
Epoch 11860: Training cost= 0.3367, Training acc= 0.7816, Validation cost= 0.3997, Validation acc= 0.7821
Epoch 11870: Training cost= 0.4024, Training acc= 0.7817, Validation cost= 0.3285, Validation acc= 0.7821
Epoch 11880: Training cost= 0.4028, Training acc= 0.7818, Validation cost= 0.3426, Validation acc= 0.7822
Epoch 11890: Training cost= 0.3842, Training acc= 0.7818, Validation cost= 0.3822, Validation acc= 0.7822
Epoch 11900: Training cost= 0.3790, Training acc= 0.7819, Validation cost= 0.3265, Validation acc= 0.7823
tm  [ 0.8  0.3  3.8  4.1 -1.6 -0.6 -0.6 -0.3 -1.1  0.   0.  -1.2  0.6 -0.1  3.   4.8  0.6 -0.  -0.3 -1.2 -0.4 -0.4  4.5  0.3 -1.1 -0.2 -0.4 -0.2 -0.2  0.8 -1.1  0.1 -0.6 -0.5  1.3 -0.1  2.9  4.   7.4 -0.6  0.2  4.5  1.3  3.2 -0.2 -0.4  2.9 -0.8  2.2 10.8 -0.6 -0.4 -0.7  3.6 -0.8 -0.1 -0.5  1.5 -0.5  4.6 -0.7 -0.1 -0.7  0.9 -0.8 -0.5 -0.2 -0.4 -0.1 -0.5 -0.2 -0.1  0.3 -0.1 -0.7  0.1 -0.3  0.5 -0.  -0.1 -1.1 -0.2 -0.4 -0.2 -1.1  5.4  1.2  0.4 -0.1  0.1 -0.2 -0.2 -0.8  0.1 -0.3 -0.1  0.9 -0.7 -0.4 -0.4  0.   7.2 -0.4  0.4 -0.1 -0.4 -0.6 -1.   0.1 -1.4 -0.4 -0.3 -0.2 -0.2 -0.5  1.5 -0.4 -0.7 -0.5 -0.4 -0.3  4.6 -0.2 -0.9 -0.   3.  -0.3 -0.6  1.2 -1.4  0.6 -0.3 -0.3 -0.1 -3.1 -4.   0.  -0.5 -0.6  0.5 -0.6 -0.8 -0.4  0.2 -0.6  0.2 -0.4 -0.5 -0.4  1.6 -0.3 -0.3  5.  -0.6 -0.3 -0.2 -0.3 -0.2  2.3 -0.5  1.5 -0.8 -0.5 -0.2 -0.5 -0.3 -0.2 -0.6  0.1  1.3  2.4 -0.3 -0.1  0.3 -0.2  1.9  0.4 -0.2 -1.2 -0.8 -1.  -0.2 -0.2 -0.7 -0.4 -0.2  3.2 -0.6 -0.6 -0.1 -0.2 -0.6 -0.6 -0.4  5.2 -0.1  0.   1.1 -0.1 -0.3 -0.4 -0.5 -0.2 -0.3 -0.7 -0.6 -0.4  0.2  4.4 -0.   0.3  0.9 -0.3 -0.3 -0.2 -0.2 -0.4 -0.4  0.2 -0.4 -0.6  0.1 -0.3 -0.6  1.6  1.7  1.4  1.5 -0.4  2.6 -0.8 -0.2 -0.4  3.2  0.4 -0.5  2.1 -0.1  0.   2.7 -0.2  1.2 -0.  -0.1  5.  -1.  -0.4  0.1 -0.2 -0.4  2.   0.5  5.7 -0.  -0.6  8.4]
ty_50sample [[8 2 7 9 5 0 4 1 6 3]
 [2 0 7 5 3 1 9 4 8 6]
 [0 4 7 5 5 6 2 2 1 3]
 [4 8 8 3 1 9 7 5 6 2]
 [7 3 4 9 2 8 0 5 1 6]
 [4 5 7 1 1 6 2 8 0 3]
 [4 8 9 0 2 6 7 1 3 5]
 [0 7 1 6 2 3 9 5 4 8]
 [7 3 1 0 2 4 5 9 6 8]
 [4 6 0 8 1 3 9 2 7 5]]
tt_50sample [[8 2 7 9 5 0 4 1 6 3]
 [2 0 7 5 1 3 9 4 8 6]
 [0 4 7 9 5 6 2 8 1 3]
 [4 8 3 0 1 9 7 5 6 2]
 [7 3 4 2 9 0 8 5 1 6]
 [4 5 7 1 9 6 2 8 0 3]
 [4 8 9 0 2 6 7 1 3 5]
 [0 7 1 6 2 3 9 5 8 4]
 [7 3 1 0 2 4 5 6 9 8]
 [6 4 0 8 1 3 9 2 7 5]]
vm  [-0.3 -0.6 -2.1 -2.8 -0.8 -0.5 -0.2 -0.2 -0.1  0.2 -1.   1.2 -1.3 -0.4  1.3 -2.2 -0.6 -0.5 -0.2  1.2 -0.3 -0.2  2.  -0.1 -1.2  2.5 -0.1 -0.1 -1.6 -1.4  4.3 -0.1  1.  -1.2  2.1 -0.3  1.  -0.5 -1.9 -0.8  0.   5.8  0.4  1.9 -0.7 -0.4 -1.7  0.4 -0.1  3.  -0.7 -0.6 -1.   1.8  0.3 -0.1 -0.8  1.   2.6 -0.9  6.  -0.9 -0.1  1.6  0.6 -0.7 -0.2  2.5  1.6 -0.6 -0.5  3.6 -0.3 -0.6 -5.4  0.1  0.3 -0.   1.2 -0.2 -1.3 -0.1  0.5  0.  -0.5  6.   1.5 -0.2 -0.3 -0.5 -0.7 -0.8 -1.3  0.3 -1.2 -0.4 -0.  -1.8 -0.1 -0.4 -0.6  0.   1.1 -0.5 -0.1  0.2 -3.2  4.1 -0.4  1.8 -0.2  0.9 -0.5 -0.7  6.8 -2.3 -0.4  2.1 -0.2  2.1  0.6 -0.9 -0.2 -0.1 -0.4  1.9 -0.5  0.9  3.2  2.5 -0.1 -0.4 -0.4 -0.1  7.1  5.3 -0.3 -0.5 -0.2 -1.   1.9 -0.6  0.3 -0.2 -0.5 -0.6 -0.2 -0.6  6.  -0.5  3.5 -0.3 -0.2  0.5 -0.6 -0.  -0.1  0.8 -0.5 -0.8 -0.1 -0.3  0.4 -0.5 -0.4 -0.4 -1.5  0.1 -0.3 -0.8 -0.   1.7 -0.3 -0.2 -0.3 -1.8 -1.1 -1.5  6.9  0.6 -1.6 -0.3 -0.  -1.4  1.5 -0.5 -0.7 -0.1  0.6  4.9 -0.5 -0.7  0.2 -1.6 -1.3 -0.3 -2.4 -0.6 -0.2 -0.1  0.2  0.5 -0.4 -0.6 -0.4 -3.1  0.2 -0.5 -2.5 -0.1 -0.4 -1.7 -0.4  2.   1.4 -0.2 -0.5 -0.7 -0.9 -0.1 -0.5 -0.1  0.4 -0.9  2.  -1.2 -1.6 -0.1 -0.3  1.  -0.7  3.1 -0.4 -1.9  3.5  5.4  3.2 -2.5  1.  -4.4 -0.3 -2.3 -0.4  0.1  5.7  4.3  0.6 -0.5 -0.7  0.9  2.8 -0.3 -1.4 -0.8  3.8 -0.1]
vy_50sample [[0 5 4 1 6 8 3 3 2 9]
 [9 3 1 7 7 0 4 4 6 2]
 [3 4 6 9 7 0 8 2 1 5]
 [5 8 1 3 9 4 6 7 0 0]
 [2 5 3 0 7 1 6 8 4 9]
 [2 6 9 8 5 1 7 4 3 0]
 [4 6 0 1 3 7 5 8 9 2]
 [9 9 7 7 6 5 4 3 0 2]
 [7 3 1 5 4 0 0 8 9 2]
 [5 4 2 1 7 8 6 6 9 0]]
vt_50sample [[0 5 4 1 6 8 3 7 9 2]
 [9 3 1 5 7 0 4 8 6 2]
 [3 4 6 7 9 0 8 2 1 5]
 [5 1 8 3 9 4 6 7 2 0]
 [2 5 3 0 7 1 6 8 4 9]
 [2 6 9 8 5 1 7 4 3 0]
 [4 6 0 1 3 7 5 8 9 2]
 [1 9 8 7 6 5 4 3 0 2]
 [7 3 1 5 4 0 6 8 9 2]
 [5 4 2 1 7 8 3 6 0 9]]
Epoch 11910: Training cost= 0.3443, Training acc= 0.7819, Validation cost= 0.3572, Validation acc= 0.7824
Epoch 11920: Training cost= 0.3180, Training acc= 0.7820, Validation cost= 0.3769, Validation acc= 0.7824
Epoch 11930: Training cost= 0.3341, Training acc= 0.7821, Validation cost= 0.3799, Validation acc= 0.7825
Epoch 11940: Training cost= 0.3676, Training acc= 0.7821, Validation cost= 0.3613, Validation acc= 0.7825
Epoch 11950: Training cost= 0.3163, Training acc= 0.7822, Validation cost= 0.3247, Validation acc= 0.7826
Epoch 11960: Training cost= 0.4676, Training acc= 0.7822, Validation cost= 0.3882, Validation acc= 0.7827
Epoch 11970: Training cost= 0.3742, Training acc= 0.7823, Validation cost= 0.4569, Validation acc= 0.7827
Epoch 11980: Training cost= 0.3680, Training acc= 0.7823, Validation cost= 0.3704, Validation acc= 0.7828
Epoch 11990: Training cost= 0.3554, Training acc= 0.7824, Validation cost= 0.3885, Validation acc= 0.7828
Epoch 12000: Training cost= 0.4115, Training acc= 0.7824, Validation cost= 0.3669, Validation acc= 0.7829
tm  [ 3.6  0.2  1.7  9.6 -0.8 -1.4 -0.5 -0.6  0.2 -0.4 10.1 -0.3 -0.1 -0.2 -1.9  2.8  0.2 -0.4  0.6 -1.6 -0.9 -0.1 -0.7  0.2 -1.2  1.5 -0.2 -0.  -0.6 -1.1  2.  -0.8 -0.4  3.7  2.1 -0.1  0.9  5.3 10.3 -0.8 -0.4  3.2  0.3  1.4 -0.5 -0.3  8.4 -1.2  4.1 -1.3 -0.4  0.6  1.6  2.5 -0.4  4.5 -0.5  3.9 -0.1 -0.2 -2.4 -0.6 -0.   1.5  2.3 -0.5 -0.   1.8 -0.2 -0.7 -0.4  1.1  0.2 -0.7 -0.1 -0.  -1.1  0.4 -0.6 -0.2 15.  -0.3 -0.7 -0.1 -1.7  2.8  1.6 -0.4  0.4 -0.3 -0.3 -0.8 -0.5 -0.1 -0.2 -0.2  0.5 -0.2 -0.5 -0.5  1.2 -0.4 -1.4 -0.3 -0.1  0.1 -0.1  2.6  4.  -1.8  1.1 -0.2 -0.3 -0.2  0.5 -0.7 -0.  -0.  -0.   2.5 -0.2  6.9  0.1 -0.1 -0.3 -2.  -0.7 -0.1  1.8 -0.6  2.2 -0.4 -0.3  1.3 -0.2  2.8 -0.6 -0.7 -0.  -0.6 -0.9 -0.5 -0.6  0.5 -0.  -0.2 -0.2 -1.   3.9 -0.7 -1.1  0.8  3.4 -1.1  0.3 -0.4 -0.4 -0.1  0.2 -0.4 -0.2 -1.1 -0.  -0.2  0.6 -0.1 -0.8 -0.8 -0.4  2.8 -0.4 -0.1 -0.4 -0.  -0.6 -1.  -0.3  2.1 -1.8 -0.4 -1.3 -0.1  0.3 -1.3 -0.2 -0.   7.6 -0.1  0.4  5.4 -0.4 -0.6 -1.1 -0.7 12.2 -0.5  1.  -0.   0.4  0.2  1.1 -0.6 -0.1 -0.4 -1.4  3.6  1.5 -0.1 -2.9 -0.4 -0.2 -0.2 -0.5 -0.9 -0.2  0.9  0.7 -0.8 -0.4 -0.1 -0.1 -0.8  0.8 -0.8 -0.4 -0.8  2.2  1.9  0.7  5.2 -1.  -0.3 -0.3 -2.  -0.1 -0.1  2.2  1.9 -0.5  2.6 -0.2  1.2 -0.5 -0.  -2.9 -2.5  0.2 -0.4 -0.8 -0.1 -3.3 -0.3  8.8  0.6 -0.4  4.7]
ty_50sample [[2 9 5 0 3 7 4 6 8 1]
 [0 1 9 3 8 4 2 7 5 6]
 [0 8 4 9 3 2 7 5 1 6]
 [4 3 2 9 0 7 5 8 8 6]
 [0 7 3 6 4 8 5 1 2 9]
 [4 0 2 5 8 7 1 3 6 9]
 [0 3 3 8 5 1 9 2 4 6]
 [7 4 8 6 2 5 0 1 9 3]
 [2 1 4 9 3 7 0 8 5 6]
 [6 5 1 3 3 9 7 7 2 4]]
tt_50sample [[2 9 5 0 3 7 4 6 8 1]
 [0 9 1 3 8 4 2 7 5 6]
 [0 8 4 9 3 2 7 5 1 6]
 [4 3 2 9 7 0 5 1 8 6]
 [0 7 3 6 4 8 5 1 2 9]
 [4 2 0 5 7 8 1 3 6 9]
 [0 3 7 8 5 1 9 2 4 6]
 [7 4 8 6 2 5 0 1 9 3]
 [2 1 9 4 3 7 0 8 5 6]
 [6 5 1 3 8 9 0 7 4 2]]
vm  [ 0.7  0.7 -0.2 -0.5 -1.5 -0.6  0.3 -0.2 -1.1 -0.7  2.8  0.9 -0.5 -0.4  1.2  1.3  2.3 -0.  -0.2 -0.7 -0.5 -0.5  0.6  0.7 -1.2  1.3  0.5  0.4 -0.6  1.1  4.3 -0.8 -0.8  5.9 -0.5  1.6  3.   3.8 12.7 -0.5 -0.7  6.   3.6  6.7 -0.5  0.   1.9 -0.1  2.8  1.3 -0.8 -0.4  2.3 -0.3 -0.9 -0.1 -0.5  1.7 -1.1 -1.4 -1.  -0.6  1.2 -0.  -0.3 -0.6 -0.  -0.4 -0.4 -0.3 -0.1 -0.1  1.  -0.2 -1.2 -0.3 -0.1 -0.   0.5 -0.2  7.4 -1.  -0.6 -0.6 -0.9  5.8  4.4 -0.2  1.4 -0.2 -0.2 -0.1 -0.3  2.3 -0.3 -0.2  0.3 -0.7 -0.8 -0.1  2.   5.2 -0.7 -0.3 -0.3  0.3 -0.5  5.1  1.5 -1.7 -0.4 -0.5  0.3 -0.3 -0.7  0.7 -0.2 -0.5  1.  -0.6  0.2  5.5 -0.7  0.6 -0.5  2.2  1.4  3.6  1.5 -0.6 -0.8 -0.1  0.7  0.1 -4.5 -2.5 -0.3 -0.3 -0.2 -0.7  0.4 -0.6  0.3  0.2 -0.  -0.3 -0.1 -0.9  1.8  0.4  0.1  0.9  1.8 -0.1 -0.3 -0.4 -0.7 -0.1  4.1 -0.5 -0.3 -1.4 -0.3 -0.5 -0.  -0.2 -0.8 -0.7  0.2 -0.1  1.4  0.6 -0.5 -0.3 -0.4 -0.3  3.8  1.7 -2.7 -0.4 -1.6  1.1 -0.4 -0.8 -0.8  0.2  3.7 -0.6 -0.2 -0.4 -0.6 -0.6 -0.5 -0.9  6.3  2.1  1.   3.1 -0.1 -0.4  1.2 -0.   0.2 -0.1 -0.6  2.3 -0.  -0.2 -2.3 -0.5 -0.7 -0.2 -0.2 -0.1  2.3 -0.3 -2.  -0.3  0.8 -0.4 -0.4 -0.1 -0.2  0.  -0.5 -0.1 -0.5 -0.6  0.6  1.5 -1.  -0.6 -0.4 -1.6  0.9  2.   0.2  2.2 -0.2 -0.5 -0.1 -0.4 -0.2 -0.1 -1.2 -1.6 -0.5 -0.1  0.  -0.1 -1.8  1.   9.8  1.   0.9  4.8]
vy_50sample [[5 4 7 9 2 0 8 3 1 6]
 [3 0 6 7 8 5 9 9 4 1]
 [6 1 8 7 2 5 9 0 3 4]
 [6 8 8 0 5 5 2 7 4 1]
 [1 6 8 2 5 9 4 7 0 3]
 [7 8 2 3 5 6 1 0 9 4]
 [3 5 8 7 6 4 9 2 1 1]
 [9 8 0 5 4 3 6 6 1 2]
 [7 3 1 2 8 8 9 6 0 5]
 [5 1 8 2 3 4 7 0 9 6]]
vt_50sample [[5 4 7 9 2 0 3 8 1 6]
 [3 0 6 7 5 8 9 2 4 1]
 [6 1 8 7 2 5 0 9 3 4]
 [6 8 9 0 3 5 2 7 4 1]
 [1 6 8 2 5 9 4 7 0 3]
 [7 8 2 3 5 6 1 0 9 4]
 [3 5 8 7 6 4 9 2 1 0]
 [9 8 0 5 4 3 6 7 1 2]
 [7 3 1 2 8 9 4 6 0 5]
 [5 1 8 2 3 4 7 0 6 9]]
Epoch 12010: Training cost= 0.3184, Training acc= 0.7825, Validation cost= 0.3747, Validation acc= 0.7829
Epoch 12020: Training cost= 0.3443, Training acc= 0.7826, Validation cost= 0.3774, Validation acc= 0.7830
Epoch 12030: Training cost= 0.3764, Training acc= 0.7826, Validation cost= 0.3417, Validation acc= 0.7831
Epoch 12040: Training cost= 0.3704, Training acc= 0.7827, Validation cost= 0.3429, Validation acc= 0.7831
Epoch 12050: Training cost= 0.3607, Training acc= 0.7828, Validation cost= 0.3254, Validation acc= 0.7832
Epoch 12060: Training cost= 0.3655, Training acc= 0.7828, Validation cost= 0.3140, Validation acc= 0.7833
Epoch 12070: Training cost= 0.3295, Training acc= 0.7829, Validation cost= 0.3355, Validation acc= 0.7833
Epoch 12080: Training cost= 0.3443, Training acc= 0.7830, Validation cost= 0.3447, Validation acc= 0.7834
Epoch 12090: Training cost= 0.3232, Training acc= 0.7830, Validation cost= 0.3935, Validation acc= 0.7835
Epoch 12100: Training cost= 0.3820, Training acc= 0.7831, Validation cost= 0.3092, Validation acc= 0.7835
tm  [-1.3  1.  -0.2 -0.  -1.1  0.2  0.3 -0.5 -0.8 -0.7  6.2 -0.  -0.5 -0.2  1.   3.5  1.  -0.2 -0.2  0.3 -0.5 -0.2 -0.2  0.4 -2.3  2.1 -0.1 -0.1 -0.1 -0.1  2.5 -0.6  0.7  3.5 -0.9  0.2  2.9  1.3 -1.6 -0.  -0.4  4.3  2.6 -0.9 -1.  -0.4 -0.8 -0.5 -0.8 -0.1 -0.5 -0.4  1.1  4.5 -1.3  0.3 -0.5  2.6 -0.9 -0.7  6.3 -0.4 -0.1 -0.2  1.1 -0.3 -0.1  0.4 -0.4 -0.3 -0.2 -0.5 -0.  -0.3 -2.8 -0.3  2.1 -0.1  1.3 -0.3  3.8 -0.   0.5 -0.1  0.   6.1  0.2  0.4  0.4 -0.  -0.2 -0.  -0.2  0.8 -0.5 -0.3  1.  -0.8 -0.6 -0.6  2.3  2.1  1.9 -0.4 -0.6  0.3 -1.6  2.9  2.2  0.7 -0.5 -0.4 -0.1  0.9 -0.4  3.2 -0.2 -1.2  0.2  0.2 -0.1 -0.3 -0.2  1.1  0.5  1.3  1.7 -0.4 -0.1  0.1  0.   0.6 -0.3 -0.1  8.6 11.5 -0.1 -0.1  0.5 -0.4 -0.7 -0.3 -0.1 -0.1  0.2 -0.2  1.3 -0.   4.   0.1 -0.2 -0.3 -1.4 -0.2 -0.5 -0.2 -0.5  0.4 -0.9 -0.1  0.4  3.1 -0.1 -0.  -0.5 -0.5 -0.3 -0.2 -0.1  0.4  0.   0.7 -0.6 -0.2 -0.4 -0.9 -1.1 -0.1  6.3 -0.5 -0.9  0.8 -0.1 -1.3 -0.6 -0.2 -0.8 -0.3 -0.4  0.9 -0.1 -0.6  0.5 -1.1 -1.2  2.9 -0.5  2.4 -0.  -0.5  0.  -0.3 -0.2 -0.5  1.1 -1.   0.2 -0.2 -2.9  0.3 -0.9  1.2 -0.3  5.8 -0.2 -0.2  3.  -0.3 -0.  -0.5 -0.5 -0.2 -0.1 -0.4  3.7 -0.1 -0.5  2.   1.4 -0.9  0.7  0.2 -0.5 -1.8 -0.   1.7 -0.1 -0.9 -0.2 -1.8 -0.3 -1.  -0.3 -0.2 -0.3 -0.6  0.2 -0.  -0.2 -0.5 -0.8  0.5 -1.5  0.7  0.2  1.9]
ty_50sample [[6 1 2 2 4 4 7 3 8 8]
 [3 0 4 5 8 9 6 1 2 7]
 [1 3 4 5 2 0 7 9 8 6]
 [8 7 2 2 5 3 4 4 6 6]
 [1 0 8 3 7 2 5 6 4 9]
 [1 5 7 2 3 9 0 6 8 4]
 [7 6 8 3 5 4 0 0 2 9]
 [3 5 2 0 9 7 4 6 8 1]
 [5 4 0 3 2 2 9 1 7 6]
 [0 4 1 2 9 6 8 3 5 7]]
tt_50sample [[6 5 1 2 4 7 9 0 3 8]
 [3 0 4 5 9 8 6 1 2 7]
 [1 3 4 5 0 2 7 9 8 6]
 [8 7 9 2 5 3 0 4 1 6]
 [1 0 8 3 7 5 2 6 9 4]
 [1 5 7 2 3 9 0 6 8 4]
 [7 6 8 3 5 4 0 1 2 9]
 [5 3 2 0 9 7 4 6 8 1]
 [5 4 0 8 3 2 1 9 7 6]
 [0 4 1 2 9 6 8 3 5 7]]
vm  [-0.2  0.8 -0.6  6.3 -1.  -0.9 -0.3 -0.3 -1.  -0.  -1.   1.8 -1.4 -0.7 -2.  -1.2 -0.4 -0.4 -0.  -2.  -0.7 -0.1  1.2  0.2 -0.9  0.9 -0.1 -0.2 -0.7  1.6  4.3 -0.5  1.3  4.2 -0.5  0.6  1.9 -1.   1.6 -0.3 -0.3  6.1  2.4 -0.6 -0.3 -0.3  7.8  2.6  1.7  2.3 -0.5 -0.2  2.8 -3.4 -0.6  4.  -0.4  1.4 -1.2 -1.3 -1.5 -0.7 -0.  -0.2 -0.2 -0.5 -0.2 -0.2  0.8  0.5 -0.4 -0.   0.2 -0.4  2.9 -0.   0.  -0.1  0.7 -0.2 17.  -0.3 -1.  -0.6 -0.7  7.   2.6 -0.2 -0.5 -0.4 -0.4  0.6 -0.6  0.5 -0.  -0.6 -0.1 -0.1 -0.5  0.1  0.6  4.1 -0.6 -0.2 -0.4  1.2  2.4  5.4 -0.3 -2.9 -0.4 -0.4 -0.1 -0.2  0.5 -0.2 -0.1 -0.6 -0.2 -0.2 -0.   8.9 -0.5  1.1  0.3 -2.   2.5 14.8 -0.  -2.2  1.5 -0.3  0.6 -0.5  8.  14.7  0.  -0.1 -1.  -0.7  2.4 -0.3  2.4 -0.1 -0.5 -0.5 -0.1 -0.9  2.9  0.9 -0.5  0.7 -0.1  0.1 -0.1 -0.6 -0.6 -0.1 -1.4 -0.5 -0.4  2.6 -0.4 -0.4 -0.3  0.1 -0.7 -0.1  0.1  1.5 -0.1 -0.  -0.6 -0.  -0.1 -0.7 -1.1  3.8  0.3  1.  -1.6  0.7 -0.2 -0.8 -0.8  0.4  4.2 -0.3  0.  -0.6  0.  -0.6 -0.9 -0.9  8.   1.3  3.7  1.8  0.6 -0.6  0.4  0.2  0.1 -0.3 -0.   6.   0.1 -0.2 -3.1  0.5 -0.3 -0.1 -0.9  1.2  0.9 -0.5  1.7 -0.2  0.7 -0.3 -0.8 -0.1 -0.  -0.1  4.4 -0.5 -2.  -0.7  1.1  1.3  1.6 -1.3 -0.2 -2.2  0.7  2.3  0.9  6.1  1.3  4.1 -0.3  1.6 -0.2 -0.  -3.4 -2.7 -0.3 -0.  -0.7  0.3 -3.7 -0.3  1.1 -0.   4.2 11.1]
vy_50sample [[9 6 5 4 0 7 1 8 3 2]
 [7 6 9 4 3 2 8 1 5 0]
 [3 7 0 8 5 5 2 1 6 4]
 [0 5 4 7 8 6 6 9 3 3]
 [7 5 4 3 0 2 8 6 1 9]
 [3 6 0 7 9 4 1 8 5 2]
 [4 1 9 7 6 5 2 3 0 8]
 [4 5 0 3 7 7 9 6 1 1]
 [0 9 6 4 1 8 3 5 7 2]
 [1 4 8 6 2 7 5 0 3 9]]
vt_50sample [[9 6 5 4 0 7 1 8 3 2]
 [7 9 6 4 3 2 8 1 5 0]
 [3 7 8 0 5 9 2 1 6 4]
 [0 5 4 7 8 6 2 1 9 3]
 [7 5 4 3 0 2 8 6 1 9]
 [3 6 0 7 9 4 1 8 5 2]
 [4 1 9 7 6 5 2 3 0 8]
 [4 5 0 3 2 7 9 6 1 8]
 [0 9 6 4 1 8 3 5 7 2]
 [1 4 8 6 2 7 5 0 3 9]]
Epoch 12110: Training cost= 0.3479, Training acc= 0.7832, Validation cost= 0.3504, Validation acc= 0.7836
Epoch 12120: Training cost= 0.4058, Training acc= 0.7832, Validation cost= 0.3332, Validation acc= 0.7836
Epoch 12130: Training cost= 0.3702, Training acc= 0.7833, Validation cost= 0.3528, Validation acc= 0.7837
Epoch 12140: Training cost= 0.3468, Training acc= 0.7833, Validation cost= 0.3915, Validation acc= 0.7837
Epoch 12150: Training cost= 0.3040, Training acc= 0.7834, Validation cost= 0.3375, Validation acc= 0.7838
Epoch 12160: Training cost= 0.3742, Training acc= 0.7834, Validation cost= 0.3056, Validation acc= 0.7839
Epoch 12170: Training cost= 0.2995, Training acc= 0.7835, Validation cost= 0.3671, Validation acc= 0.7839
Epoch 12180: Training cost= 0.3350, Training acc= 0.7836, Validation cost= 0.3682, Validation acc= 0.7840
Epoch 12190: Training cost= 0.2853, Training acc= 0.7836, Validation cost= 0.3705, Validation acc= 0.7840
Epoch 12200: Training cost= 0.3425, Training acc= 0.7837, Validation cost= 0.3503, Validation acc= 0.7841
tm  [ 0.3  1.8 -1.3 -3.3 -0.8 -0.5 -0.2 -0.5 -0.9 -1.  -1.5  3.1 -1.4 -0.5  5.9 -0.6  1.1 -0.1 -0.2  3.6 -0.4  0.1 -0.3  1.5 -1.6  1.5 -0.  -0.2 -0.2  0.5  3.7 -0.7  0.7 -0.1 -0.7 -0.1  2.2 -0.6 -2.6 -0.6  0.   2.8  3.9  1.8 -0.3 -0.1 -2.6  1.8  2.  -0.5 -0.6 -0.6 -0.3  1.4 -1.  -0.7 -0.3  2.1 -0.9 -0.7  3.9 -0.8  0.8 -0.5 -0.1 -0.3 -0.1 -0.   0.5  0.4 -0.4 -0.3 -0.1 -0.2 -5.2  0.  -0.3 -0.  -0.1 -0.2 -2.2 -0.4  1.8  0.2 -0.9  3.8  3.7 -0.1  3.  -0.2 -0.2  0.3 -0.2  3.4 -0.7 -0.1  0.4 -1.6 -0.6 -0.2  2.6 -0.4 -0.3 -0.6 -0.   0.4 -2.9  3.7 -0.6  3.4 -0.3 -0.5 -0.2 -0.3 -0.3  1.8 -0.3 -0.1  1.1 -0.1 -0.4 -1.5 -0.4 -0.1 -0.2  6.6  2.1  0.8  1.3  7.6  1.8 -0.4  2.   0.5  4.8  5.5 -0.3 -0.2 -0.1 -0.6  3.  -0.6  2.8 -0.1 -0.4 -0.   0.  -1.2  4.8 -0.1  3.3 -0.2  3.3  1.1 -0.5 -0.2 -0.6  0.2 -0.8 -1.  -0.3  1.3  0.8  0.1  0.5 -0.2 -0.1 -0.3  1.  -1.  -0.2  1.7 -0.7 -0.3 -0.3 -1.1 -1.2 -1.4  8.7 -0.  -1.6  0.  -0.1 -1.5 -0.5 -0.4 -0.1 -0.2 -0.3  0.2 -0.3 -0.1  2.4 -1.8 -0.6  1.4 -1.7 -0.  -0.1 -0.6  0.2 -0.1 -0.2 -0.5 -0.5 -2.9 -0.2 -0.6 -1.8 -0.4 -0.9 -0.1 -0.1  0.7  0.8 -0.1 -0.3 -0.5  0.4 -0.3 -1.1  0.4  1.2 -0.3  0.3  1.6 -1.6 -0.7 -0.2  1.9 -0.2  1.8 -0.4 -1.3 -0.   4.1 -0.3 -2.1  1.4 -4.3 -0.3 -2.3 -0.3 -0.1  8.3  3.3 -0.1 -0.3 -0.1 -0.2  4.7  0.2 -2.  -0.5  5.7 -2. ]
ty_50sample [[5 4 6 3 8 7 0 1 2 9]
 [1 5 7 6 6 0 0 3 2 8]
 [9 5 4 2 6 3 1 1 7 8]
 [9 6 8 3 4 4 7 2 5 1]
 [1 0 7 5 5 8 8 4 3 2]
 [7 0 0 1 3 5 9 2 6 4]
 [8 0 2 1 6 3 4 9 7 5]
 [6 5 0 1 8 9 7 3 2 4]
 [0 1 5 9 7 6 4 3 2 8]
 [4 3 8 7 1 9 5 2 6 0]]
tt_50sample [[5 4 3 6 8 7 0 1 2 9]
 [1 5 7 6 4 0 9 3 2 8]
 [5 9 4 2 6 3 1 0 7 8]
 [9 6 8 3 4 0 7 2 5 1]
 [1 0 7 5 6 9 8 4 3 2]
 [7 8 0 1 3 5 9 6 2 4]
 [8 0 2 1 6 3 4 9 7 5]
 [6 5 0 1 8 9 7 3 2 4]
 [0 1 5 9 7 6 4 3 2 8]
 [4 3 8 7 1 9 5 2 6 0]]
vm  [-0.9 -0.5  7.5 -1.1 -1.5 -0.1 -0.3 -0.3 -0.7 -0.5 -1.6  1.2 -0.5  0.  13.3  3.8 -0.5  0.7 -0.3  2.3 -0.3 -0.6  1.7 -0.5 -0.9 -0.2 -0.5 -0.2  2.7 -0.3 -1.  -0.5  0.4  3.4 -0.4 -0.5  0.4  2.7 -0.4 -0.1 -0.2 -1.5 -0.6  2.2 -0.9 -0.4 -2.  -0.  -0.8  3.3 -0.7 -0.5 -1.   5.8 -1.6 -1.6 -0.3 -0.3  2.   4.   7.3 -0.4 -0.2 -0.2 -0.6 -0.8 -0.1  0.6 -0.2 -0.4 -0.1 -1.3 -0.3 -0.2 -5.   0.5 -0.1 -0.6  0.  -0.2 -4.4  0.3  0.4  0.2 -0.4 -1.6 -0.3 -0.1  2.  -0.6  0.   0.2  0.8 -0.1 -0.7 -0.3 -0.5 -1.7 -0.9 -0.4  1.9  3.2  1.  -0.4 -0.3 -0.5 -2.6 -1.  -0.7  2.3  0.6 -0.9 -0.2 -0.3 -0.2  6.2 -0.4  0.1 -0.3 -0.3 -0.3 -1.  -0.4 -0.4 -0.2 13.5  1.6 -0.9  0.8  6.6 -0.4 -0.2  0.5 -0.2 -4.  -3.5 -0.   0.1 -0.1 -0.3 -0.  -0.5 -0.4 -0.3 -0.6  0.2 -0.1 -0.2 -2.2 -0.5  1.9 -0.4  1.9 -0.3 -0.3 -0.2 -0.5 -0.5  1.8 -0.3 -0.4 -1.1  0.4 -0.   0.1 -0.1  1.4  3.3 -0.4 -0.5 -0.5 -0.7 -0.5  0.8 -0.6  5.8 -0.5 -1.2  3.1 -0.1  1.7 -0.1 -0.  -0.9 -0.4 -0.2 -0.9 -0.9 -1.3  1.3 -0.3 -0.1 -0.1 -1.1 -1.5 -0.2 -1.5  0.  -0.5 -0.4 -0.1 -0.2 -0.4 -0.3 -0.4 -2.9 -0.7 -0.6  7.8 -0.3 -0.4  2.3 -0.8  2.9 -0.1  0.4 -0.1 -0.3 -0.2 -0.2 -1.2 -0.3 -0.4 -0.7 -0.9  3.7 -0.9  1.3 -0.1  1.1 -0.6  1.4 -0.7  4.9 -1.  -1.7  0.  -2.2  0.6 -0.2 -0.5  0.1 -0.5 -0.3 12.9  2.3 -0.3 -0.5 -0.3 -0.2  9.8  0.2 -0.1 -0.3  2.1 -1.7]
vy_50sample [[7 8 1 1 2 4 6 5 0 9]
 [2 1 9 8 3 3 6 0 7 4]
 [6 3 4 0 8 9 5 7 2 1]
 [0 3 4 2 5 8 7 7 6 1]
 [2 4 5 0 8 6 6 7 3 1]
 [7 8 6 1 3 5 9 0 2 4]
 [6 5 3 2 0 7 4 1 8 9]
 [6 4 8 2 7 9 1 0 5 3]
 [8 9 7 0 6 1 1 4 5 3]
 [0 3 6 4 7 5 8 2 1 9]]
vt_50sample [[7 8 3 1 2 4 6 5 0 9]
 [2 1 9 8 5 3 6 0 7 4]
 [6 3 0 4 8 9 5 7 2 1]
 [0 3 4 2 5 8 7 9 6 1]
 [2 4 5 0 8 6 9 7 3 1]
 [7 8 6 1 3 5 9 0 2 4]
 [6 5 3 2 0 7 4 1 8 9]
 [6 4 8 2 7 1 9 0 5 3]
 [8 9 7 0 6 2 1 4 5 3]
 [0 3 6 4 7 5 8 2 1 9]]
Epoch 12210: Training cost= 0.3635, Training acc= 0.7838, Validation cost= 0.3438, Validation acc= 0.7842
Epoch 12220: Training cost= 0.3389, Training acc= 0.7838, Validation cost= 0.3625, Validation acc= 0.7842
Epoch 12230: Training cost= 0.3201, Training acc= 0.7839, Validation cost= 0.3769, Validation acc= 0.7843
Epoch 12240: Training cost= 0.3813, Training acc= 0.7840, Validation cost= 0.3580, Validation acc= 0.7844
Epoch 12250: Training cost= 0.3699, Training acc= 0.7840, Validation cost= 0.3709, Validation acc= 0.7844
Epoch 12260: Training cost= 0.3326, Training acc= 0.7841, Validation cost= 0.3475, Validation acc= 0.7845
Epoch 12270: Training cost= 0.3511, Training acc= 0.7841, Validation cost= 0.3927, Validation acc= 0.7845
Epoch 12280: Training cost= 0.3666, Training acc= 0.7842, Validation cost= 0.3305, Validation acc= 0.7846
Epoch 12290: Training cost= 0.3685, Training acc= 0.7843, Validation cost= 0.3778, Validation acc= 0.7847
Epoch 12300: Training cost= 0.3682, Training acc= 0.7843, Validation cost= 0.3736, Validation acc= 0.7847
tm  [-0.7 -0.4  6.1 -1.4 -1.6 -0.1 -0.2 -0.2 -0.2 -0.2  0.5 -0.2 -0.1 -0.4 12.4  6.8 -0.4  0.3 -0.   4.  -0.1 -0.2  2.7 -0.5 -1.1 -0.1 -0.5 -0.3  3.5 -0.3 -0.9 -0.6 -0.3  3.  -0.2 -0.7 -0.1  4.  -0.4 -0.4  0.3  1.9 -0.2  2.7 -0.3 -0.3 -2.7 -0.7 -0.3  5.8 -0.8 -0.6 -0.5  9.  -1.6 -1.6 -0.4  2.1  3.1  3.6  5.5 -0.7 -0.1  1.5 -0.7 -0.6 -0.  -0.1 -0.2 -0.6  0.1 -1.6 -0.2  1.2 -5.5  0.4 -0.6 -0.1 -0.2 -0.2 -3.9  0.   1.5 -0.1 -0.8  3.3  0.4  0.4  1.3 -0.2 -0.2 -0.2 -0.3 -0.6 -0.5 -0.2  0.1 -2.1 -0.9 -0.   0.1  6.5  0.1 -0.1 -0.4 -0.1 -2.5 -0.7  0.4  3.6 -0.2 -0.6 -0.3 -0.5 -0.6  8.6 -0.3 -0.1 -0.1 -0.2 -0.3 -1.4 -0.4 -0.5  0.6 13.3  1.3 -2.4  4.5  2.8 -0.1 -0.6 -0.2 -0.3 -3.9 -3.   0.7 -0.5 -0.6 -0.3 -0.5 -0.3 -0.1 -0.4 -0.6  1.4  0.1 -0.5 -1.   0.3  3.  -0.3  2.9 -0.2 -0.3 -0.2 -0.5 -0.3  2.9 -0.2  1.  -1.1  0.9 -0.3  0.  -0.3  1.6  0.7 -0.3 -0.4  0.4 -0.3 -0.7  0.  -0.1  3.1 -0.6 -0.9  3.1 -0.4 -0.6  0.3 -0.8 -0.9 -0.5 -0.3 -0.6 -0.7 -1.4  0.9 -0.3 -0.4  0.3 -0.8 -1.1 -0.9 -1.2 -0.2 -0.2 -0.6 -0.1 -0.1 -0.1 -0.5 -0.4 -2.6 -0.2 -0.6  3.4 -0.2 -0.3  4.  -0.4  1.6 -0.6 -0.2 -0.3 -0.1 -0.2 -0.4 -1.1 -0.2 -0.4 -0.4 -0.3  4.2 -0.1  1.4 -0.1  3.2 -0.6  0.3 -0.5  2.8 -1.  -1.2  0.2 -2.1  0.7 -2.  -0.3 -1.  -0.3 -0.4 12.5  2.5 -0.4 -0.2 -0.4 -0.3  9.1  0.6 -0.3  0.2  0.1 -0.5]
ty_50sample [[7 8 2 5 1 4 6 6 9 9]
 [0 7 6 4 3 5 1 9 8 2]
 [5 2 7 0 0 6 8 4 1 3]
 [6 9 0 7 1 8 3 5 4 2]
 [9 2 1 4 4 8 8 0 6 3]
 [6 6 3 3 8 9 7 0 2 1]
 [4 0 9 2 6 5 8 3 7 1]
 [4 6 0 9 5 3 7 1 1 8]
 [2 5 9 1 8 3 0 0 6 4]
 [2 4 1 6 9 0 5 7 3 8]]
tt_50sample [[7 8 2 1 5 4 3 6 9 0]
 [0 7 6 4 3 5 1 9 8 2]
 [5 2 7 0 9 6 8 4 1 3]
 [6 9 7 0 1 8 3 5 4 2]
 [9 7 2 1 4 8 5 0 6 3]
 [6 4 5 3 8 9 7 0 2 1]
 [0 4 9 2 6 5 8 3 7 1]
 [4 6 0 9 5 3 7 2 1 8]
 [2 5 1 9 8 7 3 0 6 4]
 [2 4 1 6 9 0 7 5 3 8]]
vm  [ 0.9 -0.5 -1.  -0.6 -1.2 -0.4  0.3 -0.4 -0.2 -0.3 -0.9  0.6 -0.8 -0.5 -0.1 -0.9 -0.3 -0.3 -0.3 -1.  -0.9  0.1  0.3 -0.3 -0.7  1.9 -0.2 -0.3 -0.8 -1.   3.   0.1 -0.6 -0.2  2.2 -0.2  1.5  2.3  8.6 -1.  -0.1 -1.6 -1.   7.3 -0.8 -0.2  3.8  0.3  2.9  0.3 -0.4 -0.5 -0.3 -0.6  0.5  1.6 -0.6 -1.8  3.2 -0.4 -0.7  0.  -0.2  3.2 -0.3 -0.3 -0.1  1.   1.   0.1 -0.1  1.9 -0.2 -0.2 -1.4  0.6 -0.7 -0.4  1.3 -0.1  1.3 -0.2 -0.5 -0.2 -0.9 -2.1  3.2 -0.2  0.1 -0.4 -0.4 -0.7 -0.5 -0.6  0.3 -0.2 -1.  -1.1 -0.2 -0.1 -0.1 -0.3 -0.6 -0.3  0.3 -0.2 -0.9  2.9 -0.4 -1.4 -0.5 -0.2 -0.2 -0.6  4.8 -1.5 -0.2  2.4 -0.6  0.3  0.6  4.8 -0.3 -0.7 -0.6 -0.1 -0.4  5.1  2.1  1.7 -0.1 -0.7 -0.2 -0.3 -2.5 -2.9 -0.1 -0.3  0.6 -0.6  0.3 -0.9  0.1 -0.1 -0.2 -0.2 -0.3 -0.7 -1.2 -0.6  1.5 -0.   3.4 -0.1 -0.  -0.2 -0.1  0.1  2.4 -0.6 -0.3 -1.7 -0.2 -0.6 -0.2 -0.3 -0.4  3.2 -0.2 -0.3 -0.4 -0.8 -0.1 -0.  -0.4  4.7  0.8 -0.1 -1.6 -0.1  1.4 -0.1 -0.3 -0.7  0.6 -0.5  3.9 -0.4  0.3  4.  -0.1 -0.3 -1.  -0.9  5.2 -0.5 -0.4 -0.4 -0.2 -0.1 -0.2  0.5 -0.5 -0.4 -0.8 -0.7 -0.6 -0.1  6.4  0.4 -0.2 -0.6 -1.1 -0.3  0.9 -0.1 -1.7 -0.6 -0.5 -0.1 -0.8 -0.3 -0.1 -0.7 -1.1 -0.4 -0.9 -0.3 -0.1  5.  -1.1 -0.5 -0.3  4.2  2.1  3.7  2.6 -0.2  3.4 12.1 -0.2  6.2 -0.5  0.4  1.3 -1.3 -0.3 -0.4 -0.9 -0.  -0.5 -0.3  7.2 -0.4  1.8  0.4]
vy_50sample [[4 0 3 8 8 7 2 1 5 5]
 [2 7 5 6 3 0 1 1 8 8]
 [4 3 7 2 1 0 5 8 6 6]
 [1 5 5 6 7 2 0 0 9 3]
 [8 6 7 9 3 4 2 5 5 0]
 [3 2 4 6 6 7 5 0 0 9]
 [3 9 6 0 7 5 8 8 4 2]
 [2 2 7 7 4 1 3 6 0 8]
 [5 4 9 9 0 2 8 8 3 3]
 [4 7 1 2 0 3 8 5 9 6]]
vt_50sample [[4 0 3 9 8 7 2 1 5 6]
 [2 7 5 6 3 0 1 9 4 8]
 [4 3 7 2 1 0 5 8 9 6]
 [1 8 5 6 7 2 0 9 4 3]
 [8 6 7 9 3 4 2 1 5 0]
 [3 2 4 8 6 7 5 0 1 9]
 [9 3 6 7 0 5 8 1 4 2]
 [9 5 2 7 4 1 3 6 0 8]
 [5 4 9 6 0 2 7 8 3 1]
 [4 7 1 2 0 3 8 5 9 6]]
Epoch 12310: Training cost= 0.4071, Training acc= 0.7844, Validation cost= 0.4052, Validation acc= 0.7848
Epoch 12320: Training cost= 0.3834, Training acc= 0.7844, Validation cost= 0.4317, Validation acc= 0.7848
Epoch 12330: Training cost= 0.3531, Training acc= 0.7845, Validation cost= 0.4186, Validation acc= 0.7848
Epoch 12340: Training cost= 0.4027, Training acc= 0.7845, Validation cost= 0.3753, Validation acc= 0.7849
Epoch 12350: Training cost= 0.3555, Training acc= 0.7846, Validation cost= 0.3171, Validation acc= 0.7850
Epoch 12360: Training cost= 0.3374, Training acc= 0.7846, Validation cost= 0.4148, Validation acc= 0.7850
Epoch 12370: Training cost= 0.4110, Training acc= 0.7847, Validation cost= 0.3765, Validation acc= 0.7851
Epoch 12380: Training cost= 0.3347, Training acc= 0.7847, Validation cost= 0.4237, Validation acc= 0.7851
Epoch 12390: Training cost= 0.3179, Training acc= 0.7848, Validation cost= 0.3004, Validation acc= 0.7852
Epoch 12400: Training cost= 0.3280, Training acc= 0.7849, Validation cost= 0.3383, Validation acc= 0.7853
tm  [-0.1  0.2 10.4  7.1 -1.9 -0.7 -0.3 -0.1 -0.6 -0.7 -1.1  2.  -1.  -0.3  8.1 -1.  -0.2  0.6 -0.   0.2 -0.4 -0.4 -0.4  0.8 -0.7  1.6 -0.6 -0.2 -1.  -0.8 -1.1 -0.1 -0.1  6.8 -0.3 -0.   1.1 -0.4 -0.4 -0.7 -0.4 -0.7  0.4 -0.9 -0.3  0.2 -0.7  1.1  2.9 -0.7 -0.6 -0.3 -0.1 -0.3 -0.1 -0.9 -0.2  3.6 -0.3  4.5  0.5 -0.3 -0.2  2.2 -0.4 -0.3 -0.  -0.8  1.3  0.9 -0.2  2.  -0.1 -0.2 -2.5 -0.1 -0.6 -0.6 -0.7 -0.1 -0.3 -0.3 -0.1 -0.1 -0.9 -1.  -0.1 -0.2  1.1 -0.1 -0.1 -0.1  0.1  0.7 -0.2 -0.1  1.1 -1.4 -0.1 -0.2  2.4  3.1 -0.2 -0.3 -0.   1.  -1.3 -0.8 -0.6 -0.7  0.3 -0.1 -0.  -0.2  2.1 -0.8 -0.2  1.7 -0.1 -0.3  0.8  1.5 -0.3  0.4 -0.4  8.7  0.7  4.3 -0.2  5.4  1.6 -0.4 -0.1 -0.1 -2.3  2.9 -0.4 -0.1  0.6 -0.3  1.5 -0.9  0.7 -0.2 -0.5 -0.3 -0.5 -0.8 -1.4 -0.5 -0.7 -0.2  2.4  0.5 -0.3  0.2 -0.1 -0.3 -0.3 -0.5 -0.5  0.1  0.3 -0.1  0.6 -0.5 -0.2  1.2 -0.2  0.9 -1.  -0.3 -0.3 -0.1 -0.3  4.7 -0.5 -0.5  3.3  1.  -0.6 -0.4 -0.1 -1.  -0.1 -0.5  1.5 -0.4  0.1  3.   0.1  0.3 -0.4 -0.8  2.  -0.  -0.6 -0.5 -0.4 -0.1 -0.3 -0.3  0.3 -0.2 -0.4 -1.5 -0.1 -0.4  2.5 -0.3 -0.7 -0.7 -0.7 -0.2 -0.7 -0.1  4.6 -0.2 -0.1 -0.1 -1.1 -0.1 -0.3 -0.5 -0.3 -0.2 -1.1 -0.2 -0.1  2.4 -0.4 -0.1 -0.4  1.7  2.6 -2.6  0.7 -0.6  1.3  0.6 -0.2  0.4  0.3 -0.4  3.1 -0.1 -0.2  0.2 -0.6 -0.4  0.1 -0.9 -0.3 -0.5  3.8 -1. ]
ty_50sample [[7 3 0 6 8 5 9 1 2 4]
 [9 7 3 1 1 5 8 4 6 0]
 [9 9 5 2 3 0 0 8 1 4]
 [0 6 4 5 7 3 8 2 9 1]
 [5 8 9 2 7 7 3 0 6 1]
 [4 6 6 1 8 0 3 9 5 2]
 [7 4 9 6 5 0 2 1 3 8]
 [7 1 6 0 2 8 5 3 4 9]
 [8 3 5 1 2 4 0 9 6 7]
 [5 2 6 0 8 4 9 7 3 3]]
tt_50sample [[7 3 0 6 8 5 9 1 2 4]
 [9 7 3 1 2 5 8 4 6 0]
 [9 6 5 2 3 0 7 8 1 4]
 [0 6 4 5 7 3 8 2 9 1]
 [5 8 9 2 7 4 3 0 6 1]
 [4 6 1 7 8 0 3 9 5 2]
 [7 4 9 6 5 0 2 1 3 8]
 [7 1 6 0 2 8 5 3 4 9]
 [8 3 5 1 2 4 0 9 6 7]
 [5 2 6 0 8 4 9 7 3 1]]
vm  [-0.8 -0.8  2.   1.9 -1.1 -0.5 -0.7 -0.6  1.9 -0.1 -1.7 -0.1 -0.2 -0.3  1.3  2.9 -0.6 -0.2 -0.1  1.7 -0.6 -0.5  2.8 -0.2 -0.4 -0.2 -0.4 -0.   0.4 -1.9 -2.2 -0.5 -0.7 -4.2 -0.1 -0.7 -0.6  5.3  3.  -0.5  0.3  1.7 -0.5  2.1 -0.1 -0.2 -1.4 -0.7  0.6  5.7 -0.5 -0.5 -1.1  6.4 -0.9  0.8 -0.3  5.2  5.3  5.9  3.3 -0.6  1.   3.4 -1.2 -0.6 -0.3  0.7 -0.3 -0.3 -0.3 -0.4 -0.2 -0.  -4.3 -0.  -0.8 -0.4 -0.8 -0.2 -4.4 -0.1  0.2 -0.2 -1.2  2.7 -0.4  0.1  0.7 -0.1  0.7 -0.6 -0.3 -0.5 -0.4 -0.3  1.  -2.2 -0.1 -0.4  0.3 -1.1 -0.2 -0.2 -0.2 -0.4 -2.2 -2.3 -0.6  0.3  0.  -0.2 -0.2 -0.8  2.2  2.5 -0.2  2.6 -0.1  0.9 -0.1 -0.5 -0.1 -0.8  0.   1.6 -0.1 -1.2  7.2  4.2 -0.6 -0.9 -0.5 -0.3 -0.7 -5.7 -0.2 -0.6 -0.3  2.5 -0.5 -0.2 -0.6 -0.5 -0.2 -0.2 -0.2 -0.5  5.4 -0.5 -0.1 -0.6  4.  -0.5 -0.2  0.4 -0.2 -0.6  4.4 -0.5 -0.1 -1.6 -0.5 -0.4 -1.1 -0.2  0.3  0.6 -0.4 -0.  -0.1  1.  -0.7 -0.3 -0.4 -1.2 -0.1 -0.7 -0.1 -0.3 -1.1 -0.3 -0.8 -0.9  1.2  0.4 -0.1 -0.3 -1.3  8.1 -0.  -0.2 -0.9 -0.3 -0.3 -2.  -0.8 -1.  -0.2 -0.3 -0.3  0.5 -0.2 -0.7 -0.5 -2.4 -0.3 -0.6  3.9 -0.1 -0.8  1.8 -0.4 -0.  -1.1 -0.4  0.5 -0.2 -0.3 -1.  -0.3 -0.2 -0.6 -0.8 -1.1  2.6 -0.3  2.9 -0.8  5.7 -1.1 -0.1 -0.5  2.8 -0.3  0.7  0.5 -1.6  1.  -2.2 -0.2 -1.2 -0.2 -0.5 13.1  0.5 -0.3 -0.6 -0.8 -0.5  9.6 -0.5  2.2  1.2  1.7 -0.8]
vy_50sample [[8 5 2 3 1 0 7 4 6 6]
 [7 1 2 6 3 8 5 9 9 4]
 [3 6 4 0 9 5 1 2 8 8]
 [3 1 0 2 9 7 6 4 8 5]
 [6 1 3 4 0 7 8 2 5 5]
 [0 2 2 7 5 6 9 1 4 3]
 [7 9 2 6 1 4 4 3 5 5]
 [5 2 8 9 4 0 1 6 3 7]
 [2 3 6 8 9 5 0 4 7 1]
 [3 5 1 6 7 9 8 4 0 2]]
vt_50sample [[8 5 2 3 1 0 7 9 4 6]
 [7 1 6 2 3 8 5 0 9 4]
 [3 6 4 0 9 5 1 2 7 8]
 [3 1 0 2 9 7 4 6 8 5]
 [6 1 3 4 0 7 8 2 9 5]
 [0 8 2 7 5 6 9 1 4 3]
 [7 9 2 6 1 4 8 3 5 0]
 [5 2 8 9 4 0 1 6 3 7]
 [2 3 6 8 9 5 4 0 7 1]
 [3 5 6 1 7 9 8 4 0 2]]
Epoch 12410: Training cost= 0.3647, Training acc= 0.7849, Validation cost= 0.3419, Validation acc= 0.7853
Epoch 12420: Training cost= 0.3393, Training acc= 0.7850, Validation cost= 0.3453, Validation acc= 0.7854
Epoch 12430: Training cost= 0.3673, Training acc= 0.7851, Validation cost= 0.3498, Validation acc= 0.7855
Epoch 12440: Training cost= 0.3659, Training acc= 0.7851, Validation cost= 0.3752, Validation acc= 0.7855
Epoch 12450: Training cost= 0.3417, Training acc= 0.7852, Validation cost= 0.2968, Validation acc= 0.7856
Epoch 12460: Training cost= 0.3219, Training acc= 0.7852, Validation cost= 0.3097, Validation acc= 0.7857
Epoch 12470: Training cost= 0.3616, Training acc= 0.7853, Validation cost= 0.3341, Validation acc= 0.7857
Epoch 12480: Training cost= 0.2841, Training acc= 0.7854, Validation cost= 0.3116, Validation acc= 0.7858
Epoch 12490: Training cost= 0.3752, Training acc= 0.7854, Validation cost= 0.3910, Validation acc= 0.7858
Epoch 12500: Training cost= 0.3547, Training acc= 0.7855, Validation cost= 0.3841, Validation acc= 0.7859
tm  [ 0.3 -0.   4.   7.  -1.6 -1.1 -0.4 -0.3 -0.8 -0.9 -3.6  1.9 -0.8 -0.4 -0.5 -0.4  0.4  0.   0.7 -0.5 -0.6 -0.   2.   1.2 -0.7 -0.  -0.6 -0.4 -0.6 -0.7 -1.6 -0.1 -0.5 -2.4 -0.2  0.   0.4  3.8 10.8 -1.   0.2 -0.7  0.2  4.1 -0.2 -0.3  2.9  1.1  4.4  4.1 -0.5 -0.4 -0.  -1.1 -0.3  1.7 -0.2  2.3  0.5  4.9 -1.1 -0.4 -0.   2.2 -1.4 -1.  -0.2 -0.9  0.4  1.  -0.4  2.7  2.  -0.  -0.8  0.6 -0.8 -0.5 -0.6 -0.3 -1.3  0.2 -0.5 -0.4 -1.6 -0.7  1.2 -0.3  2.1  0.   1.8 -0.2 -0.1  1.5 -0.1 -0.4  1.1 -1.2 -0.1 -0.4  2.9 -0.5 -0.8 -0.1 -0.1 -0.6 -0.3 -1.9 -1.8 -1.2 -0.3 -0.2 -0.4 -0.3  0.9 -0.4  0.1  1.  -0.2  0.4  0.2  4.6 -0.4 -0.6 -0.1 -0.4  0.3  6.4  2.7  1.7 -0.5 -0.4 -0.1 -0.4 -3.3 -6.2  0.4 -0.5  0.   3.9  1.2 -1.1  0.9  0.6 -0.1  0.4 -0.3 -0.9  0.2 -0.6 -0.5 -0.   5.6  0.3 -0.2 -0.4 -0.1 -0.5  4.8 -0.3 -0.2 -1.9 -0.3 -0.4 -1.2 -0.3  0.2 -0.2 -0.2  1.6 -0.1 -0.1 -0.3 -0.2 -0.5  2.   1.8  2.4 -2.1  0.3 -0.5 -0.3 -0.5 -0.9 -0.1  1.1  4.  -0.4 -0.6  3.9  0.3  0.  -1.  -0.6  6.3 -0.5  2.1 -0.5 -0.1 -0.1 -0.4 -0.   0.2 -0.7 -0.6  1.4 -0.7 -0.4  6.9 -0.2 -0.6 -0.3 -0.3 -0.6 -0.8 -0.3 -0.7  0.1  0.8 -0.5 -0.9 -0.1 -0.4 -0.8 -1.8  0.9 -1.5  0.1 -0.8  3.5 -0.6 -0.7 -0.3  4.6  1.5 -0.5  0.3  2.8  1.7  6.3 -0.3  3.  -0.8 -0.2  5.6 -2.2 -0.3 -0.9 -0.7 -0.3  2.2 -0.8  8.9  0.2  3.5  0.5]
ty_50sample [[8 3 9 0 7 5 4 2 1 6]
 [7 4 0 1 2 6 8 5 9 3]
 [1 8 3 5 0 4 7 6 2 9]
 [0 3 5 7 7 2 9 9 4 8]
 [6 8 9 3 5 7 0 2 1 4]
 [5 0 3 1 9 8 6 7 4 2]
 [1 2 0 0 9 6 4 5 3 7]
 [6 5 9 0 8 2 4 7 1 3]
 [6 0 7 4 2 5 1 3 9 8]
 [0 8 9 3 3 2 4 6 1 5]]
tt_50sample [[8 3 9 0 7 5 4 2 1 6]
 [7 4 0 1 2 6 8 5 9 3]
 [1 8 3 5 0 4 7 6 2 9]
 [0 3 5 1 7 2 6 9 4 8]
 [6 8 9 3 5 7 0 2 1 4]
 [5 0 3 1 9 8 6 7 4 2]
 [1 2 8 0 9 6 4 5 3 7]
 [6 5 9 0 8 2 4 1 7 3]
 [6 0 7 4 2 1 5 3 9 8]
 [0 8 9 3 7 4 2 6 1 5]]
vm  [-1.4  0.4  2.   1.7 -1.  -0.2 -0.2 -0.6 -0.5 -0.9 -2.6  2.1 -1.1 -0.3  1.6 -0.1 -0.3 -0.1 -0.   0.5 -0.5 -0.3 -0.1 -0.1 -1.   1.5 -0.2 -0.3  1.7 -0.4 -0.6 -0.5  0.4 -1.  -1.1 -0.3  0.8 -0.4 -0.7 -0.5 -0.1 -1.7 -0.3 -0.5 -0.7 -0.5 -0.3  1.3 -1.1 -0.2 -0.7 -0.3 -0.2 -0.6 -1.3  0.2 -0.2  0.3  0.1  2.7  6.2 -0.4  0.  -0.4 -0.2 -0.1 -0.2  0.   1.   0.9 -0.1 -0.5  0.6 -0.1 -2.7  0.1  0.8 -0.7  0.  -0.2 -1.5 -0.2  0.3  0.6  0.9 -1.6 -0.7 -0.3  2.  -0.2 -0.3  0.2  0.9  0.4 -0.7 -0.   0.1 -1.2 -0.5 -0.5  2.6 -0.8  2.1 -0.3 -0.3  0.2 -1.6 -0.7 -1.3  0.2 -0.1 -0.5 -0.3  0.1  0.5  3.8 -0.2 -0.2 -0.2  1.1 -0.2 -0.1 -0.1 -0.1 -0.2  1.3  2.   5.2 -0.1  5.8 -0.2 -0.5 -0.1 -0.1  4.2  0.3 -0.1 -0.2  1.9 -0.3  2.5 -0.6  1.7 -0.2 -0.6  0.2 -0.1 -0.  -0.4 -0.3 -0.  -0.1 -0.1  1.  -0.3  0.  -0.4 -0.2 -0.5 -0.5 -0.3 -0.   0.6 -0.2 -0.8 -0.4  2.1  3.5 -0.3  0.6 -1.  -0.4 -0.6  0.1 -0.6  2.4 -1.  -0.4  4.   0.8  0.6 -0.1  0.1 -1.6 -0.5  0.5 -0.8 -0.2 -0.5  2.7 -0.6 -0.2 -0.6 -1.4 -1.4  1.4 -0.6  0.  -0.2 -0.6 -0.1  0.  -0.3 -0.8  1.4 -1.1 -0.5 -0.4  6.1 -0.5 -0.5  2.5 -0.7  5.8 -0.6 -0.   1.9 -0.3  1.   0.8 -1.2 -0.3 -0.3 -1.1 -0.3  3.4 -1.8  1.5 -0.1 -0.3 -0.1  0.5 -0.5  3.6 -0.3 -0.1 -0.3 -1.   1.4  3.7 -0.5  2.2 -0.6 -0.2  5.9 -0.9  1.  -0.3 -0.5 -0.3  3.1 -0.7 -0.6 -0.6  5.4 -1. ]
vy_50sample [[1 3 8 6 7 9 4 0 5 2]
 [7 6 1 3 3 0 0 5 2 2]
 [0 8 2 5 9 7 6 3 4 1]
 [2 7 6 5 5 1 9 9 4 8]
 [1 4 5 0 2 7 9 3 8 8]
 [0 2 4 6 3 8 1 5 9 7]
 [5 4 2 1 8 6 0 3 9 7]
 [5 8 3 4 1 6 2 7 9 9]
 [5 0 0 2 9 3 7 8 4 6]
 [2 8 4 3 7 0 9 1 6 5]]
vt_50sample [[1 3 8 6 7 9 4 0 5 2]
 [7 6 1 3 4 0 8 5 2 9]
 [0 8 2 5 9 7 6 3 4 1]
 [2 7 6 3 1 5 9 0 4 8]
 [1 4 5 0 2 7 9 3 8 6]
 [0 2 4 6 3 8 1 5 9 7]
 [5 4 1 2 8 6 0 3 9 7]
 [5 8 3 4 1 6 0 2 7 9]
 [5 1 0 2 3 9 7 8 4 6]
 [2 8 4 3 7 0 9 1 6 5]]
Epoch 12510: Training cost= 0.3225, Training acc= 0.7856, Validation cost= 0.3750, Validation acc= 0.7860
Epoch 12520: Training cost= 0.3603, Training acc= 0.7856, Validation cost= 0.4165, Validation acc= 0.7860
Epoch 12530: Training cost= 0.4435, Training acc= 0.7857, Validation cost= 0.3789, Validation acc= 0.7861
Epoch 12540: Training cost= 0.3445, Training acc= 0.7857, Validation cost= 0.4113, Validation acc= 0.7861
Epoch 12550: Training cost= 0.4238, Training acc= 0.7858, Validation cost= 0.4189, Validation acc= 0.7862
Epoch 12560: Training cost= 0.3621, Training acc= 0.7858, Validation cost= 0.3761, Validation acc= 0.7862
Epoch 12570: Training cost= 0.3600, Training acc= 0.7859, Validation cost= 0.3862, Validation acc= 0.7863
Epoch 12580: Training cost= 0.3684, Training acc= 0.7859, Validation cost= 0.3339, Validation acc= 0.7863
Epoch 12590: Training cost= 0.4187, Training acc= 0.7860, Validation cost= 0.3082, Validation acc= 0.7864
Epoch 12600: Training cost= 0.3627, Training acc= 0.7860, Validation cost= 0.3967, Validation acc= 0.7865
tm  [-1.7 -0.9 -1.6 -1.5 -0.8  0.1 -0.3 -0.7 -0.   1.4 -2.1 -0.2 -0.9 -0.1 -0.2  1.5 -0.6 -0.3 -0.5 -0.4 -0.2 -0.4  3.9 -0.6 -1.  -0.   0.3 -0.2  3.9 -0.6  1.5 -1.1 -0.2 -1.9 -0.5 -1.1 -0.1 -0.1  1.4 -0.3 -0.2  3.  -0.6  1.6 -0.5 -0.6  0.6 -0.1 -1.4  8.7 -0.6 -0.1 -0.5 -0.2 -1.2  1.8 -0.3 -0.7  4.5 -0.2  5.5 -0.5 -0.2 -0.3 -0.3 -0.  -0.4  1.6  0.3 -0.5 -0.5 -1.2 -0.2  0.4 -3.2  0.4  0.5 -0.   2.  -0.3 -1.6 -0.5 -0.1 -0.4  0.7  4.6 -0.6 -0.1 -0.1 -0.2 -0.5 -0.4 -0.8 -1.4 -0.6 -0.3 -0.3 -1.4 -0.3 -0.6 -0.6  3.8  2.3 -0.1 -0.8 -0.  -1.7  1.7 -1.2 -0.5 -0.1 -0.6 -0.2 -0.5  1.6  5.9 -0.1 -0.2 -0.3  1.2 -0.4  0.9  0.5 -0.3  1.2 -0.3  0.1  4.4  3.  -1.  -0.2 -0.8 -0.6 -0.4  4.7 -1.4 -0.3 -0.5 -0.3  0.  -0.1 -0.2  2.1 -0.3 -1.   0.2  0.2  0.3  2.4  0.4  2.3 -0.1 -0.4  1.4 -0.1 -0.2 -0.2 -0.2 -0.4  0.4  0.8 -0.5  0.2 -0.1 -0.8 -0.2 -0.1  3.2 -0.5 -0.4 -0.1 -0.5 -0.8 -0.6 -0.3 -0.3 -0.8 -0.1  1.4 -0.  -0.5  0.8 -0.3 -1.4 -0.5 -0.  -0.9 -0.3 -1.   1.5 -0.6 -0.7 -0.9 -1.1 -1.2 -0.3 -0.6 -0.2 -0.2 -1.1 -0.3  1.9 -0.2 -0.9  1.2 -0.7 -0.2 -0.5  4.2 -0.1  0.8  4.5 -0.8  6.4 -0.2  0.5 -0.6 -0.2 -0.1 -0.3 -1.3 -0.6 -0.6 -1.2  3.5  3.5 -1.7  1.9 -0.1 -0.1 -0.7  0.4 -0.5  2.7 -1.1  5.   0.8 -1.4  1.7  2.6 -0.4  1.1 -0.1 -0.1  5.8 -1.2  1.4 -0.5 -0.9 -0.1  3.1  0.4  0.5 -0.4  2.3  6.3]
ty_50sample [[1 4 8 6 6 5 7 2 0 3]
 [3 6 7 2 8 4 1 5 9 0]
 [9 4 6 1 8 2 2 0 5 3]
 [7 1 4 6 6 8 0 2 5 3]
 [2 0 1 9 4 4 8 3 7 5]
 [2 2 0 4 8 5 7 9 6 3]
 [5 8 3 9 2 4 0 6 7 1]
 [0 4 4 5 8 7 2 3 3 6]
 [4 1 6 9 0 8 7 2 3 5]
 [4 2 0 5 1 8 7 9 6 3]]
tt_50sample [[1 4 8 9 6 5 7 2 0 3]
 [3 6 7 2 8 4 1 5 0 9]
 [9 4 6 1 8 2 0 7 5 3]
 [7 1 4 9 6 8 0 2 3 5]
 [2 0 1 9 4 6 8 3 7 5]
 [1 2 0 4 7 8 5 9 6 3]
 [5 8 3 9 2 4 0 6 1 7]
 [0 9 4 5 8 7 2 3 1 6]
 [4 1 6 9 0 8 7 2 3 5]
 [4 2 5 0 1 8 7 9 6 3]]
vm  [-1.4 -0.6  5.7  6.6 -1.5 -0.2 -0.1 -0.6  1.1 -0.2  5.5  3.  -1.2  0.6  2.9 -0.1 -0.  -0.2 -0.2  0.3 -0.6 -0.3 -1.9 -0.7 -0.9  0.6  0.6 -0.4 -0.4 -1.8  1.  -0.6 -0.3  8.1 -0.9 -0.6 -0.1  1.8  0.8 -0.1 -0.2  2.   1.  -0.7 -0.8 -0.6 -0.4 -0.3 -1.4 -3.4 -0.9 -0.  -0.5  0.7 -1.2 -0.1 -0.5  6.2  1.4  0.5  7.9 -0.7 -0.4 -0.1  1.8 -0.6 -0.4  1.9 -0.4 -0.7  1.2 -0.2  0.3 -0.2 -4.3 -0.3  1.6 -0.9 -0.6 -0.9  7.5 -0.6 -0.4 -0.4  0.7  1.6 -1.1 -0.4  1.  -0.2 -0.4 -0.1  1.1 -0.2 -1.  -0.5  0.1 -1.3 -0.1 -0.6  1.5 -0.8  3.  -0.3 -0.6 -0.2 -2.6  2.   0.7 -0.3  3.2 -0.9 -0.3 -0.9  1.3  2.1 -0.1  1.   1.8  2.5  0.4 -0.  -0.1 -0.2 -0.4  3.4  2.2  1.7  3.5  6.4 -1.  -0.3 -0.5  0.4 -0.5  7.9 -0.2 -0.3  1.7 -0.8 -0.6  1.7  0.3 -0.3 -0.2 -0.4  0.1 -0.3  3.6 -0.9 -0.7 -0.2 -2.4  2.3 -0.1 -0.3 -0.4  0.3  0.4  0.6 -0.7 -0.7  0.2 -0.2 -0.3 -0.2  0.3  1.3 -1.   1.9 -1.2  1.3 -0.7 -0.1 -0.7 -1.  -0.6 -1.3  1.6  0.4 -1.3 -0.5  1.9 -1.2  0.3  0.5 -1.1 -0.4 -0.2  8.  -0.3 -0.4 -0.5 -1.  -2.   0.2 -1.6 -0.1 -0.2 -0.8  0.9 -0.3 -0.2 -0.3  0.2 -1.5  0.1 -0.8 -4.9 -0.4 -0.6 -0.2 -0.2  5.7 -0.6  1.8  2.8 -0.8  0.2  0.4 -0.5 -0.3  1.2 -0.5 -0.4 -0.7 -1.3  1.4 -0.  -0.4 -0.5  2.9 -0.  -3.4 -0.4 -1.  -0.1 -2.4 -0.5 -3.3  0.1 -1.6 -0.5 -0.  -1.4 -0.4 -0.1 -0.6 -0.4 -0.4 -1.8 -1.1  0.2 -0.6  4.3 -1.6]
vy_50sample [[1 3 3 7 7 6 2 2 4 4]
 [5 4 2 3 8 7 6 6 0 9]
 [2 5 1 0 9 3 4 4 6 6]
 [0 0 3 6 2 7 5 9 4 1]
 [7 0 2 4 5 3 9 6 1 8]
 [8 5 0 3 3 6 9 4 1 2]
 [2 4 1 7 9 6 8 8 3 5]
 [2 0 4 8 6 1 9 5 5 7]
 [5 6 1 4 4 2 0 3 8 8]
 [6 9 7 3 0 4 2 1 8 5]]
vt_50sample [[1 5 3 7 6 0 9 2 4 8]
 [5 4 2 3 8 7 1 6 9 0]
 [2 5 1 9 0 3 4 6 8 7]
 [0 8 3 6 2 7 5 9 4 1]
 [7 0 2 4 5 3 9 6 1 8]
 [8 5 0 3 7 6 9 4 1 2]
 [2 4 1 7 9 6 0 8 3 5]
 [2 0 4 8 6 1 9 3 5 7]
 [5 6 1 9 4 2 0 3 7 8]
 [9 6 7 0 3 4 2 1 8 5]]
Epoch 12610: Training cost= 0.3247, Training acc= 0.7861, Validation cost= 0.3357, Validation acc= 0.7865
Epoch 12620: Training cost= 0.3570, Training acc= 0.7862, Validation cost= 0.3464, Validation acc= 0.7866
Epoch 12630: Training cost= 0.4150, Training acc= 0.7862, Validation cost= 0.3532, Validation acc= 0.7866
Epoch 12640: Training cost= 0.3497, Training acc= 0.7863, Validation cost= 0.4141, Validation acc= 0.7867
Epoch 12650: Training cost= 0.3385, Training acc= 0.7863, Validation cost= 0.3104, Validation acc= 0.7867
Epoch 12660: Training cost= 0.3199, Training acc= 0.7864, Validation cost= 0.3567, Validation acc= 0.7868
Epoch 12670: Training cost= 0.3361, Training acc= 0.7864, Validation cost= 0.3721, Validation acc= 0.7869
Epoch 12680: Training cost= 0.3666, Training acc= 0.7865, Validation cost= 0.3107, Validation acc= 0.7869
Epoch 12690: Training cost= 0.3507, Training acc= 0.7866, Validation cost= 0.3546, Validation acc= 0.7870
Epoch 12700: Training cost= 0.3202, Training acc= 0.7866, Validation cost= 0.3806, Validation acc= 0.7870
tm  [-1.5 -0.3 -0.7  1.3 -0.9  0.4 -0.3 -0.2 -0.1 -0.8 -0.9  2.1 -0.9 -0.1 -0.7 -1.  -0.1 -0.3 -0.2 -0.2 -0.4 -0.4 -0.8 -0.3 -1.   2.8 -0.2 -0.3 -0.8 -1.6  2.   0.2 -0.2 -0.4 -0.5 -0.1  2.1 -0.7 -0.3 -0.8 -0.2  1.6  1.4  0.  -0.6 -0.2 -0.5  1.8 -0.7 -1.5 -0.9 -0.4 -0.3 -1.  -0.6  2.1 -0.5  3.3  1.3 -0.1  6.7 -0.2 -0.3  1.2 -0.4  1.3 -0.2 -0.1 -0.1  1.8 -0.1  1.1 -0.1  0.1 -1.5 -0.1  2.1 -0.5  0.2  0.1  3.7 -0.1 -0.4 -0.2  2.   2.1 -0.7 -0.1  0.6 -0.4 -0.2 -0.  -0.2 -0.2 -0.3 -0.   1.3 -1.4 -0.1 -0.1  2.4 -1.4  3.5 -0.  -0.2 -0.  -1.5  1.9 -0.6 -0.8 -0.4 -0.2 -0.2 -0.3  3.4  0.5 -0.3 -0.1 -0.3 -0.  -0.   3.9  0.1  0.1 -0.4 -0.7  1.6  6.   3.9  3.8 -0.5 -0.9 -0.8 -0.5  6.3  5.9 -0.3 -0.4  1.2 -0.1  2.  -0.1  1.2 -0.  -0.6 -0.3  0.3 -0.   5.5 -0.5  1.1 -0.3 -1.4  1.4 -0.2 -0.1 -0.1 -0.1  0.7 -0.5 -0.3  0.5 -0.3 -0.2 -1.  -0.4  1.1  2.2 -0.2 -0.  -0.6  1.4 -0.6 -0.3 -0.3 -1.2 -0.8 -0.5  3.1  0.4 -1.7 -0.2 -0.4 -1.4  1.1 -0.4 -0.9  0.4 -0.1  6.8 -0.1 -0.1 -0.4 -0.9 -1.6 -0.1 -0.4 -0.5 -0.2 -0.5 -0.4 -0.1 -0.2 -0.7  2.5 -1.7  0.2  0.  -2.1 -0.1 -0.5 -0.1 -0.7  4.9 -0.6 -0.3  1.  -0.6 -0.2 -0.2 -0.5  0.3 -0.2 -0.5 -0.1 -0.3 -1.2  0.7 -0.   0.6 -0.7 -0.  -0.4 -1.5  3.9  2.4 -0.1 -0.6  1.6 -1.3 -0.3 -0.7 -0.6 -0.1 -0.2  0.1 -0.1 -0.  -1.  -0.6 -0.9 -1.2 -0.2 -0.6  6.  -0.6]
ty_50sample [[1 5 3 0 6 4 9 8 7 2]
 [1 6 5 0 8 7 4 9 3 2]
 [7 9 3 1 5 8 2 4 6 0]
 [7 8 3 5 4 4 6 1 2 0]
 [9 7 1 0 3 2 4 8 6 5]
 [2 1 4 4 8 0 3 6 5 9]
 [8 4 6 1 2 7 7 3 5 5]
 [9 7 3 2 4 5 5 8 1 6]
 [9 2 0 7 5 3 4 6 1 8]
 [9 0 4 5 1 2 7 3 8 6]]
tt_50sample [[1 5 3 0 6 4 9 8 7 2]
 [1 6 5 0 8 7 4 9 3 2]
 [7 9 3 1 5 8 2 6 4 0]
 [7 8 3 5 9 4 6 1 2 0]
 [9 7 1 0 3 2 4 8 6 5]
 [2 1 7 4 8 0 3 6 5 9]
 [8 4 6 1 2 7 0 3 9 5]
 [9 7 3 2 0 4 5 8 1 6]
 [2 9 7 0 5 3 4 6 1 8]
 [9 0 4 5 1 2 7 3 8 6]]
vm  [ 1.  -0.1  2.8 -0.7 -1.8 -0.6 -0.1 -0.3 -0.7 -0.5  4.6 -0.3 -0.5 -0.4  6.3  2.8  0.8 -0.2 -0.3 -0.5 -0.2 -0.3  1.7  0.4 -1.4  0.7 -0.2  0.2  0.5  2.2  3.9 -0.5 -0.2  9.3 -0.3  0.8  1.6  1.3  1.3 -0.7 -0.2  6.   2.6  1.7 -0.4 -0.3  0.2 -0.2  2.   2.3 -1.  -0.3  0.6  1.4 -1.3 -0.7 -0.4  2.1 -0.7 -1.3 -0.3 -0.5 -0.1  1.   1.7 -0.5  0.3 -0.2 -0.1 -0.2 -0.2 -0.7 -0.1 -0.3 -2.5 -0.2 -0.3 -0.1  0.3 -0.4  5.9 -0.3 -0.2  0.  -1.   7.   2.9 -0.1  0.2 -0.3 -0.6 -0.2 -0.5  0.1 -0.4 -0.5  0.1 -1.1 -0.4 -0.2  1.   7.2 -0.7 -0.2 -0.7  0.  -1.4  4.6  1.8 -0.5 -0.1 -0.5 -0.  -0.4 -0.5  3.5 -0.4 -0.3 -0.2 -0.5 -0.2  0.7 -0.   0.5 -0.2  6.7  0.5  1.3  1.  -0.6  2.7 -0.4  0.5 -0.3 -2.2  5.8 -0.1 -0.4 -0.5 -0.7 -0.2 -0.1  0.4 -0.2 -0.3  0.2  0.2 -0.6  0.2  0.4  0.6 -0.2  0.4 -0.1 -0.4 -0.1 -0.5 -0.1 -0.5 -0.3  0.9 -0.2 -0.2 -0.6  1.1 -0.3 -0.7 -0.4 -0.1 -0.2  1.   1.2 -0.6 -0.3 -0.4  0.5 -0.8 -0.2  1.5 -0.3 -1.4 -0.  -0.5 -1.3 -1.  -0.2  2.8 -0.6 -0.4 -0.7 -0.2 -0.6 -0.4 -1.   4.2  1.  -0.5  1.3 -0.2 -0.3 -0.1 -0.3 -0.3 -0.4 -0.7 -0.7  0.3 -0.2 -2.7 -0.3 -0.6  2.2 -0.4  1.1 -0.1 -0.2 -0.4 -0.2  0.3 -0.2 -0.7 -0.3 -0.3 -0.5  2.9  0.5 -0.6 -0.3 -0.1  2.4 -0.7  0.2 -0.5 -1.9 -0.4 -0.2  0.8 -0.9  0.3 -1.5 -0.3 -0.9 -0.1 -0.3 -0.8 -1.1 -0.3 -0.3 -0.1  0.5 -1.5  0.8  0.6 -0.1  0.9  4.9]
vy_50sample [[7 5 4 6 2 9 0 1 3 3]
 [3 2 6 4 0 8 7 5 9 1]
 [3 8 5 5 1 1 7 7 0 0]
 [5 8 1 4 7 2 0 9 3 6]
 [5 3 0 7 4 9 2 1 6 8]
 [6 1 8 7 7 5 3 9 0 2]
 [5 7 8 0 0 3 6 6 9 2]
 [4 9 9 1 1 5 0 7 8 3]
 [1 0 6 9 2 8 5 4 3 7]
 [9 8 0 5 4 1 2 3 6 7]]
vt_50sample [[7 5 4 6 2 9 8 0 1 3]
 [3 2 6 4 8 0 7 5 9 1]
 [3 8 5 4 6 1 2 7 0 9]
 [8 5 1 4 2 7 0 9 6 3]
 [5 3 0 7 4 9 2 6 1 8]
 [6 1 8 4 7 5 9 3 0 2]
 [5 7 8 1 0 3 6 4 9 2]
 [4 9 2 1 6 5 0 7 8 3]
 [1 0 6 9 2 8 5 4 3 7]
 [9 8 0 5 4 1 2 3 6 7]]
Epoch 12710: Training cost= 0.2997, Training acc= 0.7867, Validation cost= 0.3160, Validation acc= 0.7871
Epoch 12720: Training cost= 0.3833, Training acc= 0.7867, Validation cost= 0.3418, Validation acc= 0.7871
Epoch 12730: Training cost= 0.3525, Training acc= 0.7868, Validation cost= 0.4143, Validation acc= 0.7872
Epoch 12740: Training cost= 0.3432, Training acc= 0.7868, Validation cost= 0.3113, Validation acc= 0.7873
Epoch 12750: Training cost= 0.4128, Training acc= 0.7869, Validation cost= 0.3527, Validation acc= 0.7873
Epoch 12760: Training cost= 0.3974, Training acc= 0.7869, Validation cost= 0.3737, Validation acc= 0.7874
Epoch 12770: Training cost= 0.3714, Training acc= 0.7870, Validation cost= 0.3848, Validation acc= 0.7874
Epoch 12780: Training cost= 0.3414, Training acc= 0.7871, Validation cost= 0.3559, Validation acc= 0.7875
Epoch 12790: Training cost= 0.3629, Training acc= 0.7871, Validation cost= 0.3152, Validation acc= 0.7875
Epoch 12800: Training cost= 0.3199, Training acc= 0.7872, Validation cost= 0.3330, Validation acc= 0.7876
tm  [ 1.1 -0.2 -1.8 -3.1 -1.1 -0.2 -0.  -0.4 -0.8 -1.1  5.   0.4 -0.1 -0.3  4.1  0.7  1.  -0.7 -0.5  1.6 -0.7 -0.1 -0.7  0.4 -1.4  3.  -0.1 -0.2 -0.7 -0.7  5.1 -0.5 -0.4  2.9  0.1  1.1  3.2  3.2  0.9 -1.   0.1  2.5  2.   6.8 -0.7 -0.1 -1.6 -0.3  1.8 -1.3 -0.8 -0.7 -0.9  6.6 -0.8 -0.4 -0.7  0.7 -0.3 -1.6  2.2 -0.6 -0.   1.4 -0.  -0.3 -0.   1.  -0.4  0.  -0.5  0.5 -0.2 -0.5 -4.2 -0.  -0.3 -0.5  0.5 -0.  -0.6 -0.3 -0.1 -0.2 -0.8  2.6  3.5 -0.6  2.2 -0.2 -0.6  0.2  0.1  2.5 -0.6 -0.1 -0.2 -1.4  0.4 -0.3  2.6 -0.8 -0.6 -0.6  0.2 -0.1 -2.9  5.5  2.3  0.5 -0.8 -0.3 -0.3 -0.8  1.5 -0.4 -0.2 -0.  -0.3 -0.1  0.8 -0.5 -0.4 -0.5 -0.6  4.9  0.3 -1.4  3.   7.  -0.5 -0.6 -0.2  0.4 -1.  -0.8 -0.3 -0.3  1.5 -0.8 -0.2 -0.6 -0.3 -0.   0.3 -0.3 -0.4 -0.8  5.  -0.4  2.6 -0.2  0.8 -0.3 -0.6  0.3 -0.3  1.1  2.7 -0.8 -0.5 -1.3 -0.4 -0.4  0.4 -0.4 -0.3 -0.3  1.2 -1.   0.6  1.6 -0.5 -0.2 -0.4 -1.4 -0.2 -1.3  1.2 -0.6 -1.6 -0.1 -0.4 -1.6  0.2 -0.4  0.1 -0.6 -0.5  3.  -0.3 -0.4  0.6 -1.3  0.1 -0.2 -1.5  0.3 -0.2 -0.1 -0.2 -0.2 -0.4 -0.5 -0.6 -3.2  0.1 -0.3 -2.9 -0.5 -0.6 -0.6 -0.4  0.4  0.9 -0.3 -1.7 -0.8 -0.4 -0.2 -0.4  0.2  0.2 -0.6 -0.9 -0.4 -0.4 -0.2  1.1  3.2 -1.2  1.9 -0.4 -2.   1.7  5.6  0.9 -2.1  0.  -3.8 -0.1 -1.9 -0.5 -0.1  3.7  2.9 -0.3 -0.5 -0.6 -0.2  0.8 -0.3  0.9 -0.2  2.2 -1.6]
ty_50sample [[5 5 3 2 2 7 7 1 6 6]
 [6 2 3 0 4 1 7 9 5 8]
 [4 9 9 8 1 3 2 5 7 6]
 [6 3 7 5 1 0 8 2 4 9]
 [8 3 5 0 9 6 1 4 2 7]
 [3 2 4 1 8 5 7 7 6 0]
 [5 6 2 9 4 4 7 1 0 8]
 [6 4 8 3 9 2 2 1 5 5]
 [7 3 6 4 8 9 5 1 0 2]
 [5 9 0 3 8 4 2 7 6 1]]
tt_50sample [[4 5 3 2 0 7 1 8 6 9]
 [6 2 3 0 4 1 7 9 5 8]
 [4 9 0 8 1 3 2 5 7 6]
 [6 3 7 1 5 0 8 2 4 9]
 [8 3 5 0 9 1 6 4 2 7]
 [3 2 4 1 9 8 5 7 6 0]
 [5 6 2 9 3 4 7 1 0 8]
 [6 4 8 3 9 7 2 1 0 5]
 [7 3 6 4 8 9 5 1 0 2]
 [5 9 0 3 8 4 2 7 6 1]]
vm  [ 0.7 -0.6 -0.  -3.6 -1.7 -0.   0.3 -0.3 -0.6 -0.6  5.4 -0.   0.1 -0.7 11.5 -0.4  1.6 -0.8  0.6  4.2 -0.5 -0.3 -0.3  0.3 -1.4  2.5 -0.1 -0.2 -1.7 -0.7  5.   0.9 -0.5  7.6  0.7  1.2  2.   2.4 -1.5 -1.   0.3  6.1  2.3  4.4 -0.8 -0.4 -3.2 -0.4  0.8 -0.7 -1.1 -0.7 -1.   8.6 -0.1 -1.6 -1.   2.2  0.2 -1.6  7.8 -0.3 -0.4  3.  -0.2 -0.3 -0.1 -0.1  0.3  0.2 -0.4  2.6 -0.4 -0.7 -5.4 -0.1  1.4 -0.2  1.1  0.2 -1.2 -0.1  0.2  0.5 -0.5  5.9  2.2 -0.3 -0.2 -0.  -0.3 -0.2 -0.4  1.2 -0.8 -0.2  1.3 -1.8 -0.2 -0.4  1.5  4.6  0.7 -0.3  1.1 -0.3 -3.6  4.8  1.8  4.8 -0.7  0.8 -0.2 -0.5  3.5 -1.3 -0.3  1.  -0.4 -0.5  0.1 -1.5 -0.2 -0.1 -0.5 12.6 -0.3 -2.1  3.1  5.5 -0.5 -0.3 -0.6 -0.4 -2.4  3.  -0.2 -0.4 -0.1 -0.8 -0.1 -0.5 -0.1 -0.   0.8 -0.3 -0.  -0.6  3.6 -0.2  3.8 -0.3 -1.  -0.2 -0.8  0.5 -0.2 -0.   2.2 -0.3  0.3 -0.7 -0.3 -0.4 -0.  -0.8 -0.8 -0.3  0.5 -1.   0.3  2.6 -0.2 -0.2 -0.2 -0.3 -0.4 -1.9  5.9 -0.4 -1.6 -0.4 -0.2 -1.5  0.8 -0.6 -1.1 -0.9 -0.2  2.5 -0.1 -0.6  2.6 -1.1 -1.9 -0.1 -2.5 -0.2 -0.2  0.3 -0.1 -0.3 -0.3 -0.6 -0.  -4.4 -0.1 -0.2 -3.6 -0.  -0.9 -1.2 -0.3  2.  -0.2 -0.5 -0.9 -0.5 -0.2 -0.2 -0.3  0.7 -0.3 -0.7 -0.1 -1.1 -0.3  0.  -0.2  0.7 -0.8  2.8 -0.4 -2.7  4.   1.5  1.8 -2.6  1.3 -5.2 -0.3 -2.7 -0.5  0.2  5.2  7.4 -0.3 -0.3 -0.3  0.4  2.8 -0.3 -1.1 -0.5  1.8 -1.6]
vy_50sample [[5 0 4 7 2 1 3 6 8 9]
 [3 6 0 5 1 2 9 7 8 8]
 [8 6 1 7 4 5 0 2 9 3]
 [0 7 8 4 1 1 2 5 5 3]
 [8 6 3 7 1 4 5 9 2 0]
 [9 3 5 1 2 6 0 4 7 8]
 [9 2 0 6 1 4 8 7 5 3]
 [5 3 7 1 6 9 2 4 0 8]
 [7 1 3 4 5 6 0 0 9 2]
 [3 8 1 5 9 4 2 6 0 7]]
vt_50sample [[5 0 4 7 2 1 3 6 8 9]
 [3 6 0 5 1 2 9 7 8 4]
 [8 6 1 7 4 5 0 2 9 3]
 [0 7 8 4 1 9 2 6 5 3]
 [8 6 3 7 1 4 5 9 2 0]
 [9 3 5 1 2 6 0 4 7 8]
 [9 2 0 6 1 4 8 7 5 3]
 [5 3 7 1 6 9 2 0 4 8]
 [7 1 3 5 4 6 0 8 9 2]
 [3 8 1 5 9 4 2 6 0 7]]
Epoch 12810: Training cost= 0.3266, Training acc= 0.7872, Validation cost= 0.4117, Validation acc= 0.7876
Epoch 12820: Training cost= 0.3267, Training acc= 0.7873, Validation cost= 0.3387, Validation acc= 0.7877
Epoch 12830: Training cost= 0.3417, Training acc= 0.7873, Validation cost= 0.3352, Validation acc= 0.7878
Epoch 12840: Training cost= 0.3130, Training acc= 0.7874, Validation cost= 0.3285, Validation acc= 0.7878
Epoch 12850: Training cost= 0.2694, Training acc= 0.7875, Validation cost= 0.3488, Validation acc= 0.7879
Epoch 12860: Training cost= 0.3485, Training acc= 0.7875, Validation cost= 0.3190, Validation acc= 0.7879
Epoch 12870: Training cost= 0.3745, Training acc= 0.7876, Validation cost= 0.3232, Validation acc= 0.7880
Epoch 12880: Training cost= 0.3337, Training acc= 0.7876, Validation cost= 0.4215, Validation acc= 0.7881
Epoch 12890: Training cost= 0.3776, Training acc= 0.7877, Validation cost= 0.3654, Validation acc= 0.7881
Epoch 12900: Training cost= 0.3413, Training acc= 0.7877, Validation cost= 0.3637, Validation acc= 0.7882
tm  [-1.1 -0.1  8.9 15.2 -1.7 -0.6 -0.3 -0.2  0.1 -1.   0.4  2.  -0.6 -0.4 -0.2 -0.2 -0.5 -0.4  0.2 -0.9 -0.5 -0.4 -1.1 -0.3 -0.6  1.5 -0.4 -0.4 -0.4 -1.4 -0.3 -0.1 -0.4  7.2 -1.  -0.2  0.1 -0.2  7.6 -0.8 -0.2 -0.9 -0.  -0.7 -0.3 -0.1  4.8  1.4  0.3 -2.  -0.8  0.2  3.1 -1.9 -0.9  1.4 -0.   4.5  0.6  3.4 -0.4 -0.3 -0.1  2.4 -0.3  0.8 -0.1 -0.6  0.7  1.1 -0.1 -0.2  0.2  0.6  2.9 -0.1 -0.4 -0.6 -0.5  0.3 12.3 -0.5 -0.4 -0.  -0.2 -0.7 -0.8 -0.2  0.8 -0.2  0.8 -0.2  0.8 -0.7  0.9  0.3  1.1 -0.6 -0.3 -0.   3.4  0.2  0.9 -0.  -0.1  0.6  1.8 -0.3 -0.2 -2.1 -0.1 -0.3  0.5 -0.3  1.1  2.2  0.1  0.6 -0.2 -0.4  0.3  7.4 -0.3  0.8 -0.2 -0.2  2.3 10.   2.4  0.6 -0.4 -0.8 -0.5 -0.9 -2.1  4.1  0.7 -0.1  0.8 -0.5  0.8 -0.1  0.6 -0.1 -0.5 -0.  -0.  -0.4 -0.5 -0.2 -1.1 -0.2 -0.5  0.9 -0.3 -0.1 -0.4 -0.1  2.2 -0.2 -0.7 -0.5 -0.1 -0.1 -0.2 -0.3  1.8  2.4 -0.4  3.7 -1.  -0.3 -0.4 -0.4 -0.3  2.1 -0.2  2.6 -1.2  0.8 -0.9 -0.3 -0.4 -1.2 -0.3 -0.2  1.9 -0.3 -0.   5.3 -0.1  0.4 -1.3 -0.7  3.8 -0.5  3.7 -0.4 -0.2 -0.3 -0.4 -0.2 -0.2 -0.9  0.4  3.4  0.8 -0.  -1.  -0.2 -0.3  2.  -0.8  2.3 -1.3 -0.4  3.3 -0.2  0.5 -0.  -1.  -0.2 -0.1 -0.3 -0.8  0.  -1.1  1.2  0.8  2.2 -0.6 -1.2 -0.4 -0.7  1.6 -2.2 -0.4  4.5  1.9  7.1 -0.2  4.1  0.1 -0.2 -2.3 -2.3 -0.1  0.1 -0.8 -0.8 -2.9 -1.3  5.8 -0.2  5.1  1.6]
ty_50sample [[9 3 7 1 5 0 0 8 2 4]
 [5 9 1 8 6 0 2 7 3 4]
 [5 5 0 1 6 7 3 8 4 2]
 [1 3 8 9 0 7 5 2 4 6]
 [1 0 3 8 6 7 2 9 5 4]
 [4 9 7 3 8 0 5 2 1 6]
 [6 4 3 2 5 7 8 9 1 0]
 [6 1 1 5 5 9 3 8 4 2]
 [9 5 0 2 4 6 3 8 1 7]
 [4 5 8 7 1 1 3 6 2 9]]
tt_50sample [[9 3 7 1 5 0 6 8 2 4]
 [5 9 1 8 6 0 2 7 3 4]
 [5 0 1 9 6 7 3 8 4 2]
 [1 3 8 9 7 0 5 2 4 6]
 [1 0 3 8 6 7 2 9 4 5]
 [4 9 7 3 8 0 5 2 1 6]
 [6 4 3 2 5 7 8 9 1 0]
 [6 1 0 7 5 9 3 8 4 2]
 [0 9 5 2 4 6 3 8 1 7]
 [4 5 7 8 1 0 3 6 2 9]]
vm  [-0.8 -0.5  3.2  6.9 -1.8 -0.3 -0.1 -0.3  0.1 -0.3  4.7 -0.3  0.  -0.8 -0.1  2.4 -0.3 -0.4  0.4 -1.3 -0.5  0.1  1.5 -0.3 -0.6  2.3 -0.1 -0.3 -0.1  0.1  4.4 -0.4 -0.7  9.1 -0.5  0.2  1.2  2.2 11.4 -0.7 -0.   3.9  0.   3.4 -0.4 -0.1  5.1 -0.   0.3  2.1 -1.  -0.4  4.1 -1.4 -1.1  0.7 -0.5 -0.1  1.  -1.2 -0.7 -0.3  0.4  3.2 -0.1  0.3 -0.1 -0.5 -0.1  0.5 -0.  -0.6  0.6  0.6  3.3 -0.2 -0.1 -0.1  1.9  0.4 15.2 -0.2 -0.2 -0.  -0.2  4.9  0.7 -0.3 -0.4 -0.6  1.  -0.3 -0.3 -1.3  1.5  0.2 -0.  -0.6 -0.7 -0.1  0.7  7.9  0.2 -0.  -0.4  1.   3.   4.6  1.8 -1.9 -0.8 -0.4  0.6 -0.5  0.2  3.7 -0.2 -0.2 -0.1 -0.9 -0.1  7.3 -0.3  0.9  0.6 -0.1  0.4  7.9  3.7 -2.2 -0.8 -0.7 -0.4 -0.8 -4.   2.3  1.  -0.3 -0.6 -0.5 -0.  -0.1  0.8 -0.  -0.3  0.5  1.4 -0.3 -0.8  1.2 -0.1  0.3 -0.8  0.3 -0.1 -0.2 -0.3 -0.2  3.6  0.9  1.9 -0.7 -0.2 -0.8  0.  -0.7  0.1  0.9  0.4  2.1  0.6 -0.4 -0.4 -0.3 -0.1  3.   0.7  4.7 -2.2 -0.1 -0.6  0.3 -0.8 -1.1 -0.9 -0.1  2.2 -0.2 -0.3 -0.1 -0.2 -0.3 -1.3 -0.4  4.5 -0.5  5.3 -0.  -0.  -0.3 -0.1  0.2 -0.1 -0.8  1.   6.2  0.3  0.3 -1.3 -0.2 -0.   3.2 -1.1  4.3 -0.7 -0.7 -1.  -0.3  0.6 -0.3 -0.9 -0.2 -0.3 -0.3  1.1  0.1 -0.5  1.6  0.3  0.8 -0.5 -1.5 -0.3 -0.8  0.9 -0.1  0.1  5.6  2.3  9.  -0.3  4.9  0.  -0.1 -3.  -2.8 -0.4  0.2 -0.6 -0.6 -3.5 -0.1  8.8  0.9  0.9 10.8]
vy_50sample [[9 7 4 1 5 2 0 6 8 3]
 [5 8 0 6 3 1 4 9 2 7]
 [7 9 5 0 2 6 4 1 3 8]
 [8 1 7 6 5 2 3 9 0 4]
 [8 1 4 3 6 0 2 9 7 5]
 [1 5 4 0 8 7 9 3 2 6]
 [1 3 2 7 4 9 0 5 6 8]
 [6 7 0 4 9 3 2 5 1 8]
 [0 1 7 9 8 6 2 4 5 3]
 [8 2 0 7 5 3 9 9 6 1]]
vt_50sample [[9 7 4 1 5 2 0 8 6 3]
 [5 8 0 6 3 1 4 9 2 7]
 [7 9 5 0 2 6 4 1 3 8]
 [8 1 7 6 5 2 3 9 0 4]
 [8 1 4 3 0 6 2 9 7 5]
 [1 5 4 0 8 7 9 3 2 6]
 [1 3 2 7 4 9 0 5 6 8]
 [6 7 0 9 4 3 2 5 1 8]
 [0 1 7 9 8 6 2 4 5 3]
 [8 2 0 7 5 3 9 4 6 1]]
Epoch 12910: Training cost= 0.3240, Training acc= 0.7878, Validation cost= 0.4252, Validation acc= 0.7882
Epoch 12920: Training cost= 0.3423, Training acc= 0.7879, Validation cost= 0.3619, Validation acc= 0.7883
Epoch 12930: Training cost= 0.3520, Training acc= 0.7879, Validation cost= 0.4643, Validation acc= 0.7883
Epoch 12940: Training cost= 0.3564, Training acc= 0.7880, Validation cost= 0.3086, Validation acc= 0.7884
Epoch 12950: Training cost= 0.3517, Training acc= 0.7880, Validation cost= 0.3914, Validation acc= 0.7884
Epoch 12960: Training cost= 0.3448, Training acc= 0.7881, Validation cost= 0.3390, Validation acc= 0.7885
Epoch 12970: Training cost= 0.3170, Training acc= 0.7881, Validation cost= 0.3873, Validation acc= 0.7885
Epoch 12980: Training cost= 0.4593, Training acc= 0.7882, Validation cost= 0.3436, Validation acc= 0.7886
Epoch 12990: Training cost= 0.3646, Training acc= 0.7882, Validation cost= 0.4190, Validation acc= 0.7886
Epoch 13000: Training cost= 0.3451, Training acc= 0.7883, Validation cost= 0.3289, Validation acc= 0.7887
tm  [ 0.1  0.7 -0.1  7.6 -1.  -0.8 -0.4 -0.3 -0.3 -0.8 -1.7  1.1 -1.1 -0.5 -1.5 -2.  -0.3 -0.3 -0.1 -0.9 -0.6 -0.5 -0.7  1.4 -0.7  3.2 -0.2 -0.2 -1.5 -1.3  0.8 -0.  -0.3 -0.5 -0.1 -0.3  2.6 -1.1  3.5 -0.9 -0.3 -0.8  0.4 -0.7 -0.6  1.   3.2  3.   3.  -1.2 -0.5 -0.2  3.1 -2.2  2.   4.3 -0.   1.5 -0.3  1.6 -1.  -0.3 -0.1  2.9 -0.2  1.1 -0.2 -0.5  1.9  2.  -0.4  3.9 -0.2 -0.5  1.8 -0.1 -0.6 -0.4 -0.4  1.1  7.4 -0.2 -0.1 -0.  -0.8 -0.7  0.6 -0.3  0.4 -0.2  0.7 -0.6 -0.2 -0.2  0.6 -0.1  1.3 -0.8  0.1 -0.1  1.8 -1.5 -0.6 -0.6 -0.2  0.7  0.3  0.6 -0.9 -1.4 -0.5  1.4 -0.   0.2  3.5 -1.6 -0.6  0.2 -0.6  0.7 -0.2  6.2 -0.2  0.8 -0.5 -1.5  0.2 11.6  0.9  0.7  3.4 -0.6 -0.4 -0.6  7.1  5.4 -0.2 -0.2  2.  -0.4  3.7 -1.   1.7 -0.1 -0.6 -0.1 -0.1 -0.6  3.1 -0.1 -0.4  0.1  2.2  1.3 -0.3  0.3 -0.3 -0.1 -0.7 -0.5 -0.5  0.6 -0.1 -0.  -0.6 -0.3 -0.2  2.1 -0.2  2.8 -0.8 -0.1 -0.  -0.4 -0.2 -0.3 -0.4  2.2 -0.   1.5 -0.9 -0.2 -0.6 -1.4  0.9 -0.5  3.1 -0.1  1.2  4.9 -0.3  0.  -0.8 -1.   6.1  0.2  2.3 -0.5 -0.2 -0.  -0.6  0.4 -0.2 -0.6  0.1  1.7  0.1  0.3  0.8  0.1 -0.5 -0.4 -1.3  0.1 -1.  -0.8  3.2 -0.2 -0.6  0.2 -1.1 -0.4 -0.1 -0.7  0.3 -0.6 -1.5 -0.   0.8  3.7 -0.3 -1.3 -0.5 -0.   5.2  1.7  1.4  4.7  3.1  6.6 -0.6  3.  -0.1  0.7 -1.  -1.8  0.   0.5 -1.3 -0.6 -1.8 -1.4  2.4 -0.2  5.1  1.3]
ty_50sample [[0 9 3 6 5 5 4 7 7 2]
 [5 5 1 9 7 0 6 4 3 2]
 [0 5 7 9 3 8 2 2 4 1]
 [0 9 2 6 3 8 1 5 5 4]
 [0 6 9 9 2 2 3 5 7 1]
 [1 8 2 2 4 5 0 7 3 6]
 [7 4 1 2 6 8 8 0 0 5]
 [4 1 5 9 8 6 0 7 2 3]
 [2 0 9 7 5 4 8 1 3 6]
 [8 1 2 3 9 0 4 7 6 5]]
tt_50sample [[0 9 3 6 5 8 4 1 7 2]
 [5 8 9 1 0 7 6 4 3 2]
 [0 5 7 9 3 8 2 6 4 1]
 [0 9 2 6 3 8 1 7 5 4]
 [0 6 9 4 2 8 3 5 1 7]
 [1 8 2 9 5 4 0 7 3 6]
 [7 4 1 2 6 8 9 3 0 5]
 [4 1 5 9 8 6 0 7 2 3]
 [2 0 9 7 5 4 8 1 3 6]
 [8 1 2 3 9 0 4 7 6 5]]
vm  [-2.  -0.2  5.5 15.  -0.7 -0.2 -0.2 -0.5 -0.3 -0.4 -2.7 -0.1 -0.4 -0.1 -1.2  0.5 -0.6 -0.  -0.4 -1.4 -0.4 -0.9  2.1 -0.4 -0.  -0.3 -0.  -0.1  0.7 -0.8 -2.2 -0.4  0.2 -2.3 -0.8 -0.2  0.3 -0.4  4.  -0.2 -0.4 -1.9 -0.9 -1.5 -0.4 -0.5  6.7  1.5 -1.4  4.3 -0.5 -0.1 -0.  -1.5 -1.   2.9  0.6  1.5  1.1  6.   2.4 -0.2 -0.2 -0.2 -0.9  0.3 -0.3 -0.1 -0.1  0.3 -0.2 -0.4  0.4 -0.2  1.7 -0.1  1.7 -0.4 -0.1 -0.1  0.  -0.3 -0.9  0.7  1.5 -1.9 -1.6 -0.5  0.1 -0.  -0.  -0.3  0.  -0.5 -0.2 -0.3 -0.1 -0.7 -0.2 -0.5  0.5 -0.6  2.8 -0.2 -0.6 -0.1  0.  -2.4 -1.3 -2.3 -0.1 -0.3 -0.2 -0.1  2.   1.9 -0.4 -0.1 -0.7 -0.  -0.1  8.6 -0.3  0.1 -0.1 -1.4  1.1  8.7 -0.1 -0.4 -0.2 -0.5 -0.3 -0.5  5.7 -1.2 -0.4  0.3  0.6  0.6  0.9 -0.6 -0.4  0.4 -0.6 -0.3 -0.3  1.7 -0.8 -0.2 -1.3 -0.2 -0.2 -0.3 -0.1  0.  -0.4 -0.4 -0.5 -0.4 -0.6  1.5 -0.5 -0.4 -1.2  0.   1.7  4.6 -0.5  3.  -1.  -0.7 -0.3 -0.1 -0.5  3.1 -0.5  1.7 -0.2 -0.1  1.8  0.4 -0.4 -1.  -0.3  0.6 -0.5 -0.2 -0.6  4.3 -0.6 -0.4 -1.6 -0.6 -0.1 -0.1  3.1  0.4 -0.1 -0.5 -0.4  0.4 -0.4 -0.8  2.   2.4 -0.9 -0.   9.7 -0.3 -0.5  2.5 -1.1  4.9 -0.7 -0.2  5.8 -0.2  0.7 -0.2 -0.9 -0.4 -0.6 -0.9  1.3  2.6 -1.2  2.3 -0.3 -0.  -0.5 -1.  -0.3  5.7 -0.2 -1.2 -0.3  2.5  0.3 15.9 -0.3  8.1 -0.1 -0.1  1.4 -2.1  0.8  0.6 -0.6 -0.5 -0.2 -1.   2.7 -0.1  2.7  3.7]
vy_50sample [[1 8 9 6 3 7 0 2 5 4]
 [5 2 4 1 3 6 0 7 9 9]
 [4 6 7 0 9 3 5 5 1 2]
 [9 5 6 4 0 1 8 3 7 2]
 [2 4 8 6 3 0 9 1 5 7]
 [0 4 4 2 2 6 7 5 3 1]
 [3 0 1 4 5 7 9 6 2 8]
 [2 4 5 8 9 3 1 7 6 0]
 [4 0 8 7 5 2 3 9 1 6]
 [8 3 6 0 5 1 4 2 9 7]]
vt_50sample [[1 8 9 6 3 7 0 2 5 4]
 [5 2 4 1 3 6 0 7 8 9]
 [4 6 7 0 9 3 8 5 1 2]
 [9 5 6 4 0 1 8 3 7 2]
 [2 4 8 6 3 0 1 9 5 7]
 [0 9 4 2 8 6 7 5 3 1]
 [3 0 1 4 5 7 9 2 6 8]
 [2 4 5 8 9 3 1 7 6 0]
 [0 4 8 7 5 2 3 9 1 6]
 [8 3 0 6 5 1 4 2 9 7]]
Epoch 13010: Training cost= 0.3242, Training acc= 0.7883, Validation cost= 0.3430, Validation acc= 0.7887
Epoch 13020: Training cost= 0.3032, Training acc= 0.7884, Validation cost= 0.3495, Validation acc= 0.7888
Epoch 13030: Training cost= 0.3171, Training acc= 0.7884, Validation cost= 0.3502, Validation acc= 0.7888
Epoch 13040: Training cost= 0.3501, Training acc= 0.7885, Validation cost= 0.3319, Validation acc= 0.7889
Epoch 13050: Training cost= 0.3467, Training acc= 0.7886, Validation cost= 0.3677, Validation acc= 0.7889
Epoch 13060: Training cost= 0.3675, Training acc= 0.7886, Validation cost= 0.3219, Validation acc= 0.7890
Epoch 13070: Training cost= 0.3636, Training acc= 0.7887, Validation cost= 0.3340, Validation acc= 0.7890
Epoch 13080: Training cost= 0.3837, Training acc= 0.7887, Validation cost= 0.3848, Validation acc= 0.7891
Epoch 13090: Training cost= 0.3768, Training acc= 0.7888, Validation cost= 0.3459, Validation acc= 0.7891
Epoch 13100: Training cost= 0.3607, Training acc= 0.7888, Validation cost= 0.3335, Validation acc= 0.7892
tm  [-0.2 -1.1  0.8 -1.9 -1.8  0.1 -0.  -0.4  1.8  0.3  4.7  0.8 -0.7 -1.   7.8 -1.2 -0.3 -0.4  0.9  3.3 -0.8 -0.  -0.3  0.1 -0.8  2.8 -0.3 -0.5 -1.8 -1.3  5.3  0.3 -0.7  8.4  1.3 -0.4 -0.1  0.5 -0.9 -0.9  0.9  3.9 -0.3  3.6 -0.5 -0.2 -2.5 -0.1  2.3 -0.8 -0.9 -0.8 -0.1  3.3  2.  -0.8 -1.  -0.1  5.1 -1.8  4.9 -0.3  0.4  6.2 -0.4  0.  -0.   0.5  3.1  0.4 -0.3  3.1  0.   0.8 -4.7 -0.  -0.5 -0.2  1.2 -0.1  1.9  0.4  1.5  0.2 -0.8  3.8  2.4 -0.2 -0.5 -0.4  0.6 -1.1 -0.7 -1.2 -0.3  0.2  1.1 -2.2 -0.3 -0.4 -0.5  6.   0.2  0.   0.8 -0.3 -2.2  5.3  1.1  4.4 -0.6  0.6 -0.2 -0.6  6.4 -1.7  0.1  3.1  0.4 -0.   0.8 -1.1 -0.3  0.1 -0.2  7.7 -0.7 -0.1  4.8  1.1 -0.2 -0.5 -0.8 -0.5 -2.   5.9  0.2 -0.6 -0.5 -0.6  0.3 -0.3  1.  -0.3 -0.1 -0.1  0.  -0.8 -0.1 -0.4  3.3  0.  -0.8  1.6 -0.3 -0.1 -0.  -0.2  2.4  3.1  3.1 -0.8  0.7 -0.6 -0.2 -1.2 -0.9  1.2 -0.1 -0.5 -0.1 -0.1  0.4 -0.1  0.3  3.1 -0.5 -0.3  4.2  0.1 -0.6 -0.3 -0.3 -1.1  0.7 -0.4 -0.1 -0.3  0.   4.  -0.2 -0.6  0.1 -1.1 -1.  -0.9 -1.4 -1.2 -0.   1.   0.1  1.3 -0.2 -0.9 -0.3 -2.1 -0.1 -0.3 -2.   0.  -0.4 -1.  -0.7  1.6 -0.8 -0.7 -0.6 -0.7 -0.2 -0.2 -0.9 -0.1 -0.7 -1.1  1.2 -1.7 -1.   1.2 -0.2  2.  -0.2 -0.1 -0.2 -1.5  4.4  1.1  3.9 -1.6  4.5 -1.4 -0.3 -0.7 -0.3 -0.1  0.4  1.8  0.2 -0.2 -0.7 -0.3 -0.4 -0.2 -0.5 -0.1  1.8  0.1]
ty_50sample [[0 7 4 5 1 6 6 3 8 9]
 [4 1 3 5 2 0 9 6 6 7]
 [4 3 5 9 0 8 7 2 1 6]
 [6 1 1 5 8 7 4 0 2 3]
 [8 6 5 1 1 9 2 0 4 3]
 [0 2 7 7 5 6 9 8 1 4]
 [0 1 9 7 5 4 2 8 3 6]
 [1 6 0 7 8 3 4 2 5 9]
 [4 1 0 9 5 6 7 2 3 8]
 [5 9 0 4 6 3 3 8 1 1]]
tt_50sample [[0 7 4 1 5 6 2 3 9 8]
 [4 1 3 5 2 0 9 6 7 8]
 [4 3 5 9 0 8 7 1 2 6]
 [6 1 9 8 5 7 4 0 2 3]
 [8 6 5 1 7 2 9 0 4 3]
 [0 2 7 3 5 6 9 8 1 4]
 [0 1 9 7 5 4 2 8 3 6]
 [1 6 0 7 3 8 4 2 5 9]
 [4 1 0 9 5 6 7 2 3 8]
 [5 9 0 4 6 3 8 2 1 7]]
vm  [ 1.7  0.7  4.6  5.9 -1.7 -0.6 -0.4 -0.3 -1.  -1.4  5.6  0.2  1.1  1.7  0.8 -0.2  1.6 -0.6 -0.  -2.6 -0.5 -0.4 -1.6  0.7 -0.4 -0.2 -0.4  0.9 -1.8 -0.3  4.9  0.6 -0.8 11.  -0.2  3.4  2.8  2.2 14.2 -1.  -0.7 -0.8  0.7  4.  -0.6  0.  11.3  0.8  2.5 -3.4 -1.   0.2 -0.6 -1.1 -0.1  1.1 -0.   2.3 -1.1 -1.3 -2.   0.2 -1.   0.3  0.5 -0.5 -0.6 -0.2 -0.3 -0.2 -0.4  2.5 -0.3 -0.8  7.1 -0.5 -0.3 -0.9 -0.7 -0.2 19.4 -0.5 -2.  -0.2 -0.9 -1.   1.8 -0.4  1.6  0.3 -1.   0.6  0.3  3.8 -0.2 -0.3 -0.2  2.5  0.5  0.6  4.6 -0.2 -1.  -0.5 -0.1 -0.6  0.1  3.8  1.  -2.9 -0.2  0.   0.  -0.4  0.  -0.7  0.1 -0.  -0.6 -1.  -0.3 12.3 -0.1 -0.2 -1.1  1.   0.1  5.9 -0.2  3.8 -0.2 -0.4 -0.1  0.2 -4.4  1.8 -0.6 -0.2 -0.  -1.   0.1  0.5 -0.2 -0.3  0.1 -0.8 -0.5 -0.6 -0.3 -0.1 -0.7  0.1  0.5 -0.7 -0.2 -0.3  1.5 -0.5  1.4 -1.2 -1.4 -1.6 -0.9 -0.1  1.8  1.  -0.4  0.2 -0.2  1.5 -0.8  0.7  1.3 -0.3 -0.3  1.9  1.6 -0.5 -2.7 -0.4 -1.5  0.  -0.  -1.1 -0.2 -0.5  4.7 -1.   0.7  2.  -0.8  1.3 -1.  -0.7 10.6  1.7 -0.   1.1 -0.6 -0.2 -0.5 -0.8 -0.  -0.3 -0.9 -0.6 -0.1  1.3 -3.1 -0.2 -0.5 -1.  -0.4 -0.8  2.1 -0.5 -0.8  0.2 -0.1 -0.   0.3 -0.1  1.5 -0.7 -1.6 -0.8 -0.4 -0.4 -0.9  3.6 -1.7  0.3 -0.7 -2.4  3.4 -0.8  0.3  3.3 -0.   3.5 -0.5  1.5 -0.8 -0.3 -4.2 -0.9 -0.3 -1.  -0.6  1.3 -4.5 -0.8 10.8 -0.6  3.5 -0.2]
vy_50sample [[3 9 7 0 5 4 2 6 8 8]
 [1 9 2 4 7 0 6 8 3 5]
 [0 6 6 1 9 8 2 7 4 5]
 [4 0 7 1 2 8 6 3 5 9]
 [6 2 5 7 3 4 0 1 9 8]
 [6 1 4 2 0 5 3 7 9 8]
 [0 6 4 5 2 8 8 9 7 3]
 [5 8 6 1 1 7 9 3 0 2]
 [8 7 0 9 5 3 4 1 2 6]
 [3 8 1 4 7 9 5 6 2 0]]
vt_50sample [[3 9 7 0 5 4 2 6 8 1]
 [1 9 2 4 7 0 6 8 3 5]
 [0 6 3 1 9 2 8 7 4 5]
 [4 0 7 1 2 8 6 3 5 9]
 [6 2 5 7 3 4 0 1 9 8]
 [6 1 4 2 0 5 3 7 9 8]
 [0 6 4 5 2 1 8 9 7 3]
 [5 8 6 1 4 9 7 3 0 2]
 [8 0 7 9 5 3 4 1 2 6]
 [3 8 1 7 4 9 5 6 2 0]]
Epoch 13110: Training cost= 0.3497, Training acc= 0.7889, Validation cost= 0.2974, Validation acc= 0.7893
Epoch 13120: Training cost= 0.3343, Training acc= 0.7889, Validation cost= 0.3877, Validation acc= 0.7893
Epoch 13130: Training cost= 0.3609, Training acc= 0.7890, Validation cost= 0.3545, Validation acc= 0.7894
Epoch 13140: Training cost= 0.3586, Training acc= 0.7891, Validation cost= 0.3392, Validation acc= 0.7894
Epoch 13150: Training cost= 0.3939, Training acc= 0.7891, Validation cost= 0.3619, Validation acc= 0.7895
Epoch 13160: Training cost= 0.4140, Training acc= 0.7892, Validation cost= 0.3422, Validation acc= 0.7895
Epoch 13170: Training cost= 0.3358, Training acc= 0.7892, Validation cost= 0.3293, Validation acc= 0.7896
Epoch 13180: Training cost= 0.3174, Training acc= 0.7893, Validation cost= 0.3667, Validation acc= 0.7896
Epoch 13190: Training cost= 0.4284, Training acc= 0.7893, Validation cost= 0.3606, Validation acc= 0.7897
Epoch 13200: Training cost= 0.3294, Training acc= 0.7894, Validation cost= 0.3654, Validation acc= 0.7897
tm  [-0.4  0.7  3.9 -0.1 -1.3 -0.1 -0.4 -0.4 -0.8 -1.   4.1 -0.3 -0.1 -0.3  5.7  4.7 -0.3 -0.1  0.7 -0.3 -0.3 -0.5 -0.2 -0.2 -1.   1.6 -0.4 -0.3  1.2  2.1  3.4 -0.5 -0.3  8.6 -0.4  0.5  2.2 -0.  -0.5 -0.6 -0.6 -1.  -0.2  0.  -1.  -0.  -0.5 -0.4  0.6 -0.3 -0.8 -0.5  0.8  2.8 -1.6 -0.6 -0.4 -1.1 -0.2 -0.7  1.1  0.6 -0.4  1.4  0.2 -0.2 -0.1 -0.1  0.9  0.2 -0.3 -0.8 -0.   0.4 -1.4 -0.4 -0.6 -0.4  2.4  0.8  3.5 -0.1  0.   0.6 -0.5 -0.8  1.4 -0.1  0.2 -0.3 -0.   0.5  0.1 -0.7 -0.1  0.8 -0.5 -1.3 -0.6 -0.3  3.6  5.7 -0.3 -0.1 -0.   1.6 -0.4  3.7  1.8 -0.4 -1.1 -0.7 -0.   0.3 -0.7  6.4 -0.3 -0.6 -0.3 -0.6  0.6  2.4  0.1  1.  -0.1  6.1  0.2 -0.  -0.3  1.2  3.3 -0.6  1.6 -0.8 -0.6  8.7 -0.1  0.   0.2 -0.9 -0.  -0.2 -0.1  0.1 -0.4  0.2 -0.1  0.2 -2.2  0.7  1.8 -0.3 -0.  -0.4 -0.   0.3 -0.2 -0.4 -0.9 -0.5  0.8  2.3  0.9 -0.1 -0.1 -0.9  2.4  2.6  1.  -0.2 -0.6 -1.  -0.2  0.7 -0.3  5.4 -0.6  0.6  4.  -0.3  1.2 -0.1 -0.9 -1.2 -0.8 -0.1  1.3 -0.4 -0.7 -0.8 -0.2 -0.4 -0.7 -0.8  0.5  1.6  0.7  1.3 -0.3 -0.2 -0.4 -0.2 -0.7 -0.6  0.5 -1.2 -0.3  0.1  2.5 -0.4 -0.3  3.8 -1.6  2.3 -0.2 -0.6  1.8 -0.3  1.1  0.4 -1.  -0.3 -0.5 -0.5  2.6  2.  -0.1  0.7  0.7  2.   0.1 -0.6 -0.1  2.2 -0.2 -0.4  0.5 -0.1  1.9  6.1 -0.3  3.4 -0.1 -0.2 -0.2 -0.7 -0.2  1.2 -0.5 -0.7 -1.   0.3 -0.7  0.  -0.   0.7]
ty_50sample [[7 6 4 2 1 3 9 8 0 5]
 [8 0 9 7 4 6 1 2 3 5]
 [2 1 0 6 8 7 3 9 5 4]
 [0 6 1 7 3 8 4 5 2 9]
 [9 1 3 6 0 2 4 8 5 7]
 [4 7 9 8 1 6 0 2 3 5]
 [1 6 7 9 8 5 3 4 0 2]
 [7 4 0 6 5 5 9 1 3 8]
 [2 3 1 6 0 0 4 8 5 9]
 [8 5 4 9 3 2 0 6 1 7]]
tt_50sample [[7 6 4 2 1 3 9 8 5 0]
 [8 0 9 7 4 6 1 2 3 5]
 [2 1 0 6 8 7 3 9 5 4]
 [6 0 1 7 8 3 4 5 2 9]
 [9 1 3 6 0 2 4 8 5 7]
 [4 7 9 8 1 6 0 2 3 5]
 [1 6 7 9 8 5 3 4 0 2]
 [7 4 0 6 5 2 9 1 3 8]
 [2 3 1 6 7 0 4 8 5 9]
 [8 5 4 3 9 2 0 6 1 7]]
vm  [-1.2  0.4 -3.  -2.  -0.7  2.  -0.5 -0.2 -0.9 -1.4  3.7 -0.3  1.2 -0.2 -1.1  4.6 -0.2 -0.1 -0.1  0.5 -0.6 -0.5  0.1 -0.3 -1.6  2.9 -0.8 -0.7 -0.6 -0.8  3.7 -0.4 -0.4 -2.8 -0.4  1.8  4.8  1.4 -0.8 -1.1  0.  -1.4 -0.1  4.3 -1.1  1.2 -1.3 -0.6 -1.1 -0.5 -0.5 -0.9 -0.5  5.6 -1.5  1.8 -0.9 -1.4  0.1 -0.4  7.6  0.7 -0.5  0.6 -0.2  1.1  0.5  0.2 -0.3  1.8  1.1 -0.  -0.   0.4 -1.4 -0.6  1.3 -1.   3.8  1.1 -0.9 -0.3 -0.   0.7  2.1 -1.   1.  -0.6  1.  -0.5 -0.4  1.1  0.7  0.6 -0.3  1.5 -0.8 -1.4 -0.   0.4  4.3 -2.1  2.1  0.1  1.8 -0.2 -1.2  4.5  2.2 -0.6 -1.5 -0.6  0.9  1.   0.6  3.2 -0.4 -1.  -0.3 -0.4  0.6  1.8 -0.2 -0.1 -0.6 -1.3  0.9 -1.2  0.6  4.6 -0.3 -1.  -0.2 -0.4  7.1  1.5  0.7 -0.1  2.  -0.8 -0.4 -0.3 -1.2 -0.2 -0.1 -0.4 -0.3  1.9  3.  -0.1  3.1 -0.3 -0.8 -0.6  0.2 -0.2  1.5 -0.5  1.1 -0.4 -0.1 -0.  -0.6 -0.2 -1.  -0.6  3.7  2.6  1.  -0.8 -0.4 -0.5 -0.2  0.5 -0.4 -1.  -0.8 -0.5  3.7 -1.  -0.5 -0.3 -0.4 -1.6  0.3 -0.2 -1.   1.3 -0.5  3.3 -0.1 -0.2 -0.1 -1.  -1.8 -0.1 -0.2  1.5 -0.4  1.  -0.2 -0.3 -0.5 -1.1  2.5 -2.8 -0.4  1.4  3.2 -0.4 -0.3 -0.  -1.5  5.  -0.2 -0.9 -0.9 -0.4 -0.2 -0.  -0.1  0.5 -0.3 -0.8 -0.4  1.3  1.1  2.1  0.7 -0.1 -0.9 -0.2 -0.3  2.7  2.7  7.9 -0.2 -0.9  1.9 -0.  -0.3  0.3 -0.3 -0.3  4.8  1.7 -0.2  2.2 -0.6 -0.8  1.1 -0.2 -0.5 -0.2  0.3 -0.9]
vy_50sample [[1 4 2 3 8 8 0 5 9 7]
 [0 6 2 7 9 8 3 4 1 5]
 [5 8 6 3 4 7 7 0 2 2]
 [0 8 6 1 2 3 4 4 9 5]
 [3 0 9 4 1 5 8 7 2 6]
 [8 9 4 6 1 7 2 0 3 5]
 [6 9 0 0 3 5 5 4 7 2]
 [0 9 4 8 6 6 1 7 3 2]
 [7 3 8 9 5 2 6 0 4 1]
 [2 4 6 7 7 0 8 8 5 1]]
vt_50sample [[1 4 3 2 6 8 0 5 9 7]
 [0 6 2 7 9 8 3 4 1 5]
 [5 8 6 3 4 7 9 0 1 2]
 [0 8 6 1 2 3 7 4 9 5]
 [3 0 9 4 1 5 8 7 2 6]
 [8 9 4 6 1 7 2 0 3 5]
 [6 9 0 3 8 5 1 4 7 2]
 [0 9 4 8 6 5 1 7 3 2]
 [7 8 3 9 5 2 6 0 4 1]
 [4 2 6 7 3 0 8 9 5 1]]
Epoch 13210: Training cost= 0.3342, Training acc= 0.7894, Validation cost= 0.3666, Validation acc= 0.7898
Epoch 13220: Training cost= 0.3241, Training acc= 0.7895, Validation cost= 0.3939, Validation acc= 0.7898
Epoch 13230: Training cost= 0.4061, Training acc= 0.7895, Validation cost= 0.3627, Validation acc= 0.7899
Epoch 13240: Training cost= 0.4044, Training acc= 0.7896, Validation cost= 0.3329, Validation acc= 0.7899
Epoch 13250: Training cost= 0.3503, Training acc= 0.7896, Validation cost= 0.3013, Validation acc= 0.7900
Epoch 13260: Training cost= 0.3071, Training acc= 0.7897, Validation cost= 0.3573, Validation acc= 0.7900
Epoch 13270: Training cost= 0.3277, Training acc= 0.7897, Validation cost= 0.3890, Validation acc= 0.7901
Epoch 13280: Training cost= 0.3469, Training acc= 0.7898, Validation cost= 0.3640, Validation acc= 0.7901
Epoch 13290: Training cost= 0.3374, Training acc= 0.7898, Validation cost= 0.3654, Validation acc= 0.7902
Epoch 13300: Training cost= 0.3922, Training acc= 0.7899, Validation cost= 0.3634, Validation acc= 0.7902
tm  [ 0.8 -0.3 -2.8 -0.2 -0.4 -0.6 -0.3 -0.3 -0.1 -1.   5.   0.1 -0.3 -0.2 -2.7  3.1 -0.2 -0.7 -0.6 -1.9 -0.5  0.5 -0.8 -0.4 -0.8 -0.2 -0.3  0.3  0.5 -0.2  7.  -0.5  1.5  0.1 -0.  -0.   1.1 -0.4  1.1 -0.8  0.4  0.1 -0.1  1.9 -0.2  0.4  8.8 -0.2  2.4 -1.8 -0.6 -0.2 -0.4 -0.8 -1.4  5.8  0.4 -0.5  0.4 -2.1 -1.8 -0.7 -0.3 -0.2  1.  -0.8 -0.5  3.5  0.6 -0.3 -0.6 -0.9 -0.2 -0.4  1.  -0.  -0.7 -0.4 -0.  -0.3 14.4 -0.3 -1.  -0.1 -1.2  0.8  2.9 -0.2  1.  -0.4 -0.4 -0.1 -0.4 -0.2 -0.1 -0.5 -0.4 -0.1  0.3  0.5  2.5 -1.6 -1.2 -0.3 -0.2 -0.7 -0.6  6.1  1.6 -1.8 -0.6 -0.2 -0.3 -0.6  0.2  5.1 -0.  -0.1 -0.6  0.9 -0.3  7.2  0.6 -0.4 -0.6 -2.8  0.5  5.7  2.4 -0.   4.7 -0.9  0.9 -0.1 10.9 12.3 -0.3 -0.4 -0.4 -1.1 -0.1  1.3  0.2  0.7 -0.6 -0.2 -0.3 -0.6  4.9 -0.1 -0.  -0.4  2.2 -0.4 -0.1 -0.2  0.2  0.1 -1.3 -0.6 -0.2  0.  -0.5 -0.3 -0.2 -0.2 -0.   0.7 -0.1 -0.3 -0.3 -0.2 -0.3 -0.1 -0.1 -1.7 -1.6 -0.2  1.4 -0.2 -1.5 -0.2 -0.4 -1.3 -0.4 -0.3  5.1  0.7 -0.1  0.5 -0.5 -0.3 -1.3 -1.2  9.5 -0.1  0.6 -0.2 -0.2 -0.2 -0.8 -0.3 -0.4 -0.4 -1.  -0.4  0.7 -0.  -2.6 -0.2 -0.5  3.9 -0.9 -0.5  1.8  0.1 -0.1 -0.7 -0.1 -0.  -0.2 -0.3  1.  -0.8  1.5  1.4 -0.6 -0.2 -0.3  6.4 -0.8 -0.1 -0.1 -1.8 -0.3  8.1  0.8  0.6  1.1  2.8 -0.2  1.  -0.2 -0.1 -3.  -1.6 -0.2 -0.6 -1.  -0.2 -3.5 -0.2  1.5 -0.4  2.5  3.3]
ty_50sample [[4 6 9 5 3 2 0 0 1 7]
 [6 9 1 0 3 5 8 7 2 4]
 [7 4 2 8 0 9 6 1 5 5]
 [7 2 4 4 0 9 5 6 3 1]
 [5 7 1 9 0 3 4 8 2 6]
 [4 2 5 6 8 1 7 3 9 0]
 [4 2 9 1 8 8 0 0 3 7]
 [5 9 8 6 2 0 7 3 4 1]
 [3 4 9 6 1 2 5 7 8 0]
 [4 9 8 0 0 6 6 3 1 2]]
tt_50sample [[4 6 9 5 3 2 0 8 1 7]
 [6 9 1 0 3 5 8 7 2 4]
 [7 4 2 8 0 9 6 1 5 3]
 [7 2 4 8 0 9 5 6 3 1]
 [7 5 1 9 0 3 8 4 2 6]
 [4 5 2 6 8 1 7 3 9 0]
 [4 2 9 1 8 5 6 0 3 7]
 [5 9 8 6 2 0 7 3 4 1]
 [3 4 9 6 1 2 5 7 8 0]
 [4 9 8 0 7 5 6 3 1 2]]
vm  [-0.8  1.4  7.8 12.5 -1.  -0.1  0.5 -0.4 -1.  -0.7  4.6 -0.6  0.8  0.1  1.3  5.6 -0.1 -0.5 -0.1 -1.2 -0.6 -0.3  1.9  0.5 -1.4  0.6 -0.4 -0.1  0.4  1.5 -1.  -0.2  1.2  4.1 -0.7  1.   3.3  1.  -0.3 -0.2 -0.2 -0.8  0.1 -1.6 -0.5 -0.2  5.4 -0.5 -0.4  3.  -0.6 -0.2  1.4  1.6 -1.2  0.8 -0.3  1.9 -0.8  4.5 -0.3 -0.  -0.2  0.1 -0.3 -0.2 -0.1 -0.1 -0.3 -0.3 -0.3 -0.9  0.  -0.4  1.4 -0.3 -0.1 -0.3 -0.1 -0.   5.8 -0.1 -0.8 -0.  -0.3 -0.4 -0.6 -0.   0.   0.1 -0.4  1.4  0.1  1.   0.1 -0.4  0.6  0.  -0.3  0.3  2.8  3.8 -0.2  0.  -0.4 -0.2 -0.1 -0.9  2.1 -1.5 -0.6 -0.4 -0.2  1.1 -0.7  4.8 -0.1 -1.1 -0.4 -0.5 -0.3  4.9 -0.2 -0.1 -0.1  0.9  0.9  0.5 -1.  -0.7  2.4 -0.4 -0.2 -0.3  4.2  8.2 -0.2 -0.   0.5 -1.  -0.4 -0.7 -0.7 -0.3 -0.1 -0.1 -0.4  0.  -1.4  0.6 -1.3 -0.1  1.4 -0.7 -0.3 -0.1 -0.2 -0.  -1.3 -0.4 -0.2  3.6 -0.1  0.5 -0.1 -0.4  0.9  0.6 -0.2  2.6 -0.3 -0.9 -0.2  0.7 -0.2  4.  -1.2  1.6  2.6 -0.5  0.4 -0.1 -0.  -0.9 -0.9 -0.5  1.8 -0.4 -0.5 -0.2 -0.1 -0.5 -0.8 -0.8  3.4  2.3  1.3  2.  -0.3 -0.1 -0.4 -0.5 -0.3 -0.5 -0.   1.2 -0.2  0.   4.8  0.2 -0.4  2.8 -0.6  2.1 -0.5 -0.3  6.6 -0.3 -0.1  0.  -0.6 -0.3 -0.3 -0.7  2.8  2.7  0.7  2.2  0.6 -0.   0.7 -0.6 -0.3  3.  -0.5 -1.9  0.2  1.5  0.  11.9 -0.5  5.7 -0.  -0.5 -0.7 -1.8 -0.2  0.6 -0.4 -0.5 -1.4 -0.4 -0.2  0.6 -0.1  5. ]
vy_50sample [[6 2 7 7 8 1 3 0 5 4]
 [2 5 3 6 9 4 7 1 0 8]
 [7 2 6 1 8 0 3 9 4 5]
 [7 9 0 4 5 1 6 3 2 8]
 [9 4 2 5 3 0 0 1 7 8]
 [6 3 8 8 1 1 9 0 0 2]
 [2 9 7 1 3 8 6 4 5 0]
 [0 3 2 9 8 5 5 6 4 1]
 [3 6 7 1 0 0 5 8 2 4]
 [7 4 8 2 6 0 5 9 1 3]]
vt_50sample [[6 2 7 9 8 1 3 0 5 4]
 [2 5 3 6 9 4 7 1 0 8]
 [7 2 6 1 8 0 3 9 4 5]
 [7 9 0 4 5 1 6 3 2 8]
 [9 4 2 5 3 6 0 1 7 8]
 [6 3 8 5 7 1 9 0 4 2]
 [2 9 7 1 3 8 6 4 5 0]
 [0 3 2 9 8 7 5 4 6 1]
 [3 6 7 1 0 9 5 2 8 4]
 [4 7 8 2 0 6 5 9 3 1]]
Epoch 13310: Training cost= 0.3575, Training acc= 0.7899, Validation cost= 0.3570, Validation acc= 0.7903
Epoch 13320: Training cost= 0.3355, Training acc= 0.7900, Validation cost= 0.3788, Validation acc= 0.7903
Epoch 13330: Training cost= 0.4242, Training acc= 0.7900, Validation cost= 0.3992, Validation acc= 0.7904
Epoch 13340: Training cost= 0.3691, Training acc= 0.7901, Validation cost= 0.3505, Validation acc= 0.7904
Epoch 13350: Training cost= 0.3551, Training acc= 0.7901, Validation cost= 0.3881, Validation acc= 0.7905
Epoch 13360: Training cost= 0.3506, Training acc= 0.7902, Validation cost= 0.3240, Validation acc= 0.7905
Epoch 13370: Training cost= 0.3861, Training acc= 0.7902, Validation cost= 0.4130, Validation acc= 0.7906
Epoch 13380: Training cost= 0.3520, Training acc= 0.7903, Validation cost= 0.3334, Validation acc= 0.7906
Epoch 13390: Training cost= 0.4471, Training acc= 0.7903, Validation cost= 0.3387, Validation acc= 0.7907
Epoch 13400: Training cost= 0.3144, Training acc= 0.7904, Validation cost= 0.3237, Validation acc= 0.7907
tm  [ 0.9 -0.1 -2.9  0.5 -0.5 -0.4 -0.  -0.3 -1.6 -0.3 -3.3  2.1 -1.4 -0.6 -3.1 -1.8  0.5 -0.2  0.4 -1.8 -0.5 -0.2  3.   1.6 -1.2  1.6 -0.5 -0.7 -1.7  0.4  2.1  1.   0.8 -4.  -0.3  1.4  5.8 -0.8  2.6 -0.9  0.8  3.6  2.   3.3 -0.3 -0.5  7.7  2.3  1.4  6.  -0.3 -0.3 -0.5 -2.4  0.7  5.1 -1.  -0.4 -1.2 -0.2 -0.9 -0.5 -1.  -0.6 -0.5 -0.3 -0.  -0.2  2.3 -0.2 -0.3  3.4 -0.  -0.6 -0.   0.4  0.8 -0.3  1.2 -0.   1.8 -0.2 -1.   0.3 -0.6  3.6  3.5 -0.6  0.2 -0.7 -0.5  0.6 -0.6  4.6 -0.2 -0.2 -0.2  0.3 -0.4  0.1  0.8 -0.8 -0.3 -0.3  2.1 -0.4 -0.7  2.9 -1.1 -2.3 -0.5 -0.8  0.3  0.6  1.3 -1.7  0.1 -0.6  0.6  0.6 -0.4  7.  -0.8 -0.8 -0.5 -3.1  1.  11.1 -0.7 -1.   0.3  0.6  0.2  0.   8.6 -0.2  0.2 -0.5 -0.4 -0.8  2.7 -1.4  1.2 -0.5  0.  -0.4 -0.5 -1.   5.4 -0.2 -0.6  0.5  4.  -0.1 -0.3 -0.2  1.6 -0.1 -0.6 -0.7 -0.4 -0.5 -0.4 -0.5 -0.9  0.4 -0.7 -0.4 -0.5  0.2 -0.  -0.2  0.5 -0.1 -0.4 -1.3 -1.  -0.1 -0.2 -0.3 -1.6 -0.2  3.7 -1.3 -0.4  0.   3.7  1.7  1.2  0.7 -0.5 -0.5 -0.5 -2.   6.4  2.6 -0.   1.8 -0.5  0.7 -0.  -0.6  1.  -0.2 -0.8  0.2 -0.4 -0.7  1.1 -0.5 -0.2 -1.8 -0.4 -0.4  2.  -0.4 -0.8 -0.6 -0.6 -0.3 -0.5  0.5 -0.2 -0.8  1.3 -0.5 -1.9 -0.6 -0.3 -0.3 -0.7  0.3 -0.2  0.3  2.2  6.9  1.5  0.1  0.5  2.1 -0.3  0.9 -0.5 -0.1  1.  -1.7  0.2 -0.6 -0.4  0.3 -0.4 -0.1  2.7 -0.7  3.8  6.4]
ty_50sample [[0 4 5 8 9 6 3 1 7 2]
 [6 5 3 1 0 2 7 9 8 4]
 [4 3 1 8 9 6 7 5 2 0]
 [7 6 9 4 2 5 1 3 8 0]
 [3 1 5 6 6 4 7 8 0 2]
 [5 7 1 6 9 4 2 8 0 3]
 [5 1 4 6 7 8 2 0 9 3]
 [3 4 8 9 7 6 5 1 2 0]
 [4 0 8 7 9 6 3 2 1 5]
 [8 1 7 9 2 4 5 0 3 6]]
tt_50sample [[0 4 5 8 9 6 3 1 2 7]
 [6 5 1 3 0 2 7 9 8 4]
 [4 3 1 8 9 6 7 5 2 0]
 [7 6 4 9 2 5 1 3 8 0]
 [3 1 5 9 6 4 7 8 0 2]
 [5 7 1 6 9 4 2 8 0 3]
 [5 1 4 7 6 8 2 0 9 3]
 [3 4 8 9 7 6 5 1 2 0]
 [4 8 0 7 9 6 3 2 1 5]
 [8 1 7 9 2 4 5 0 3 6]]
vm  [-0.7 -0.1 -3.3 -4.6 -0.4  0.7 -0.3 -0.4 -0.7 -0.5  0.6 -0.4 -0.3 -0.3  1.5  3.2  0.1 -0.1 -0.5  3.3 -0.6 -0.6  2.8 -0.1 -1.3  0.3 -0.1 -0.2 -0.5 -0.2  3.3 -0.5 -0.3 -3.5 -0.4 -0.1  2.6  2.1 -2.1 -0.8 -0.   5.8  2.1  4.3 -0.7 -0.2 -2.8 -0.6 -0.2  6.8 -0.8 -0.6 -1.   8.6 -1.3 -0.4 -0.8  0.3  0.5 -0.9  8.4 -0.3 -0.4 -0.2 -0.6  0.5 -0.   1.7 -0.2 -0.3 -0.2 -0.7 -0.2  0.1 -5.6 -0.1  0.7 -0.2  2.5 -0.2 -4.1 -0.6  0.8  0.3 -0.1  7.   2.3 -0.4 -0.1 -0.4 -0.5  0.1 -0.4  1.5 -0.9 -0.  -0.3 -2.  -0.3 -0.   1.3 -0.4  1.9 -0.3  0.1  0.1 -3.1  4.1  0.9  2.4 -0.6 -0.7  0.3 -0.3 -0.   3.  -0.5 -0.4  0.1 -0.1 -0.3 -1.4 -0.4 -0.3 -0.4  2.7  0.9 -2.1  2.7  2.8 -0.4 -0.7  0.7  0.3  7.5 -0.4  0.  -0.3 -0.3 -1.   0.1 -0.3 -0.6 -0.2 -0.4 -0.2 -0.2 -0.3  7.1  0.7  4.7 -0.2  0.2 -0.3 -0.4 -0.3 -0.1 -0.1 -0.1 -0.5 -0.  -0.1 -0.4 -0.2 -0.7 -0.1 -0.1 -0.1  1.2 -1.3  1.1  0.9 -0.5 -0.1 -0.3 -1.9 -0.8 -1.6  7.5 -0.7 -1.7  0.4  0.2 -1.3 -0.3  0.1 -1.   1.1 -0.7  1.1 -0.3 -0.7  1.9 -1.6 -2.2 -0.2 -2.1  1.1 -0.2 -0.2 -0.  -0.1 -0.3 -0.3  0.9 -3.9 -0.2 -0.2 -0.8 -0.2 -0.4 -0.1 -0.7  3.2  1.9 -0.3 -1.  -0.6 -0.4 -0.4 -0.4  0.6 -0.3 -0.4  2.2  3.1 -0.2  0.5 -0.3  1.1 -0.9  1.8 -0.3 -0.6  0.3  8.4 -0.1 -2.5  0.6 -4.8  0.  -2.5  0.2 -0.6 13.2  6.2  0.3 -0.1 -0.3 -0.2  9.3  2.2 -1.8 -0.2  0.3 -0.6]
vy_50sample [[4 5 8 1 2 6 0 3 7 9]
 [4 9 3 3 2 7 8 6 1 5]
 [1 4 0 3 7 5 2 8 6 9]
 [3 6 9 8 4 1 0 2 5 7]
 [3 4 9 8 0 1 2 7 6 5]
 [2 3 0 8 1 7 5 4 9 6]
 [4 2 9 0 6 3 8 1 7 5]
 [9 8 4 5 3 3 6 7 2 1]
 [6 0 1 5 3 4 9 8 2 7]
 [2 7 1 4 0 6 9 3 8 5]]
vt_50sample [[4 5 8 1 2 6 0 3 7 9]
 [4 9 3 0 2 8 7 6 1 5]
 [1 4 0 7 3 5 2 8 6 9]
 [3 6 9 8 4 1 0 2 5 7]
 [3 4 9 0 8 1 7 2 6 5]
 [2 3 0 8 7 1 5 4 9 6]
 [4 2 9 6 0 8 3 1 7 5]
 [9 8 4 5 3 6 0 7 2 1]
 [6 0 1 5 3 4 9 8 2 7]
 [2 7 1 4 0 6 9 8 3 5]]
Epoch 13410: Training cost= 0.3099, Training acc= 0.7904, Validation cost= 0.3649, Validation acc= 0.7908
Epoch 13420: Training cost= 0.3726, Training acc= 0.7905, Validation cost= 0.3592, Validation acc= 0.7908
Epoch 13430: Training cost= 0.3272, Training acc= 0.7905, Validation cost= 0.4071, Validation acc= 0.7909
Epoch 13440: Training cost= 0.4144, Training acc= 0.7906, Validation cost= 0.3037, Validation acc= 0.7909
Epoch 13450: Training cost= 0.3244, Training acc= 0.7906, Validation cost= 0.3721, Validation acc= 0.7910
Epoch 13460: Training cost= 0.3472, Training acc= 0.7907, Validation cost= 0.3459, Validation acc= 0.7910
Epoch 13470: Training cost= 0.3837, Training acc= 0.7908, Validation cost= 0.3605, Validation acc= 0.7911
Epoch 13480: Training cost= 0.3579, Training acc= 0.7908, Validation cost= 0.3792, Validation acc= 0.7911
Epoch 13490: Training cost= 0.3377, Training acc= 0.7908, Validation cost= 0.3823, Validation acc= 0.7912
Epoch 13500: Training cost= 0.3146, Training acc= 0.7909, Validation cost= 0.2668, Validation acc= 0.7912
tm  [-0.4  0.2  3.6  4.6 -1.2 -0.4 -0.4 -0.4 -0.4 -0.3 -1.  -0.4 -0.4 -0.1  2.5  2.3  0.5 -0.2 -0.7  1.9 -0.4 -0.6  4.4  0.  -0.8  0.2 -0.1  0.8 -0.5 -0.8 -2.1 -0.5 -0.2 -3.   0.3 -0.2  0.5  1.  -1.4 -0.7 -0.2  5.2  1.9 -1.  -0.1 -0.2 -1.9 -0.5  1.8  7.9 -0.6 -0.6 -0.7  6.4 -0.3 -0.1 -0.2  7.1  0.7  6.7  2.9 -0.4 -0.3  2.7 -0.8 -0.2 -0.1 -0.3 -0.1 -0.  -0.4  1.1 -0.2 -0.2 -3.5 -0.  -0.4  0.4 -0.3 -0.2 -3.4 -0.1 -0.2 -0.2 -1.   6.8 -0.5 -0.1  0.   0.3  0.  -0.3 -0.3 -0.  -0.6 -0.2  2.5 -1.9  0.3 -0.3  0.8  1.4 -0.3 -0.1 -0.4  0.2 -1.8 -2.1 -0.5 -0.1 -0.5  0.3 -0.2 -0.2  0.9  0.1 -0.4 -0.2 -0.5 -0.2  0.1  0.1  0.1 -0.4 -0.1  2.5 -0.2 -1.3  2.6  1.8  1.9 -0.8 -0.4 -0.3  6.3 -1.2 -0.3 -0.4 -0.1  1.5 -0.2 -0.6 -0.4 -0.  -0.1 -0.2 -0.2 -0.2  5.4  0.3 -0.2 -0.4  3.6 -0.2 -0.2 -0.1 -0.  -0.3 -0.4 -0.7  1.1  2.  -0.2 -0.2 -0.5 -0.3 -0.2 -0.4  0.5  0.2 -0.   1.3 -0.4 -0.4 -0.4 -1.2 -0.7 -0.6  6.  -0.1 -1.7  0.  -0.7 -1.1  0.7 -0.2 -0.1 -0.3 -0.6  4.1  0.4 -0.3 -0.1 -0.3 -0.3 -0.7 -0.7 -0.6 -0.1 -0.2 -0.5 -0.2 -0.2 -0.4  0.8 -2.4 -0.1  0.3  1.5  0.  -1.   0.2 -0.5  0.2 -0.6 -0.4  5.7 -0.2 -0.5 -0.5 -0.4 -0.1 -0.5 -0.7  2.8  1.5 -0.1  2.  -0.6  2.7 -0.5 -0.1 -0.3  1.3  1.4 -0.4  1.3 -1.1  0.9 -2.8 -0.4 -1.5  0.7 -0.3 10.9  2.5 -0.4  1.2 -0.7 -0.5  7.4 -0.4 -1.  -0.1  0.6 -0.1]
ty_50sample [[8 5 6 2 0 1 7 3 9 4]
 [9 1 2 8 6 5 3 4 0 7]
 [4 1 0 2 8 7 3 6 5 9]
 [4 7 9 5 6 0 8 3 1 2]
 [4 7 3 3 2 6 0 0 5 8]
 [0 7 1 8 5 9 4 2 3 6]
 [1 3 7 7 5 2 0 8 6 9]
 [1 3 2 5 6 4 0 0 8 7]
 [6 9 0 5 1 1 3 4 4 7]
 [3 9 4 7 6 1 0 2 8 5]]
tt_50sample [[8 5 6 2 0 1 3 7 9 4]
 [9 1 2 8 6 5 3 4 0 7]
 [4 1 0 2 8 7 3 6 5 9]
 [4 7 9 5 6 0 8 3 1 2]
 [4 7 3 9 1 2 6 0 5 8]
 [0 7 1 8 5 9 4 2 3 6]
 [1 3 4 7 5 2 0 8 6 9]
 [1 2 3 5 6 4 0 9 8 7]
 [6 9 0 5 1 8 3 2 4 7]
 [3 9 4 7 6 1 0 2 8 5]]
vm  [-1.  -0.5  1.8 -0.2 -1.   0.7 -0.  -0.6 -0.  -0.1  7.6 -0.6  0.3 -0.1  3.5  3.9 -0.1 -0.6 -0.4 -0.2 -0.8 -0.2  1.  -0.5 -1.2  0.   1.  -0.1 -0.  -0.7  3.6 -0.6  0.7  6.  -0.2 -0.2  0.3  1.9 -1.6 -0.3  0.   7.3  0.7 -0.5 -0.3 -0.4 -1.1 -0.8 -0.5  1.6 -0.8 -0.4 -0.6  6.4 -0.9 -0.1 -0.4  4.4  1.9 -0.7  6.5 -0.5 -0.3  1.7  0.7 -0.2 -0.   1.4 -0.5 -0.2 -0.4 -0.7 -0.3 -0.3 -3.9 -0.1  0.5 -0.2  0.9 -0.4  4.5  0.4 -0.4 -0.1 -0.2  9.3 -0.4 -0.3 -0.5  0.1 -0.6 -0.5 -0.7 -0.6 -0.5 -0.5  0.7 -1.7 -0.4 -0.4  0.4  4.1  1.6 -0.1 -0.7 -0.1 -2.1  2.3  2.1 -0.1 -0.  -0.3 -0.4 -0.6  1.   4.2 -0.5 -0.3 -0.6 -0.1 -0.3  0.5  0.1  0.6 -0.2  3.7 -0.1 -1.3  4.2 -0.2 -0.1 -0.8 -0.6 -0.1  5.6 11.3 -0.1 -0.4 -0.5 -0.4 -0.6  2.  -0.3 -0.1 -0.4 -0.1 -0.1 -0.1  4.8  0.2  1.2 -0.5 -1.3 -0.5 -0.3 -0.2 -0.3 -0.3 -0.5 -0.2  0.4  1.6 -0.2 -0.4 -0.3 -0.2 -0.4 -0.1  0.2 -0.   0.2  1.8 -0.7 -0.2 -0.4 -1.2 -1.2 -1.   6.3 -0.5 -1.8  1.1 -0.4 -1.3 -0.3 -0.3 -0.9 -0.5 -0.8  3.2 -0.1 -0.4 -0.2 -0.7 -1.3 -0.5 -1.3  0.1  0.4 -0.3 -0.1 -0.1 -0.3 -0.5  0.8 -2.5 -0.1  0.3 -4.2 -0.1  0.2  2.4 -0.6  4.7 -0.3  0.1  2.8 -0.6 -0.3 -0.3 -0.2 -0.2 -0.2 -0.6  3.8  0.   0.4  2.2 -0.1  0.6 -0.4  0.7 -0.2 -2.9 -0.1  0.4  1.1 -1.5  0.7 -3.2 -0.1 -1.7 -0.3 -0.1 -0.5  1.7 -0.1 -0.3 -0.9  0.2 -1.1 -0.2 -1.2 -0.1  1.   3.8]
vy_50sample [[5 1 6 2 7 4 9 0 8 3]
 [5 3 0 1 2 6 7 4 8 9]
 [5 2 6 1 3 0 7 9 8 4]
 [1 1 8 2 0 5 4 6 7 9]
 [9 3 7 4 6 8 1 2 5 0]
 [1 5 4 8 6 9 3 0 2 7]
 [9 5 8 6 3 4 7 0 2 1]
 [0 8 2 5 1 6 4 3 9 7]
 [1 0 4 5 2 2 3 8 7 6]
 [3 2 0 4 8 9 6 7 1 1]]
vt_50sample [[5 1 6 2 7 4 9 0 8 3]
 [5 3 0 1 2 6 7 4 8 9]
 [5 2 6 1 3 0 7 9 8 4]
 [1 8 3 2 0 5 4 6 7 9]
 [9 3 7 4 6 1 8 2 5 0]
 [1 5 4 8 6 9 3 0 2 7]
 [9 5 8 6 3 4 7 0 2 1]
 [0 8 2 5 1 6 4 3 9 7]
 [1 0 4 5 2 9 3 8 7 6]
 [3 2 0 4 8 9 6 7 1 5]]
Epoch 13510: Training cost= 0.3360, Training acc= 0.7909, Validation cost= 0.3215, Validation acc= 0.7913
Epoch 13520: Training cost= 0.3779, Training acc= 0.7910, Validation cost= 0.3505, Validation acc= 0.7913
Epoch 13530: Training cost= 0.3345, Training acc= 0.7911, Validation cost= 0.3056, Validation acc= 0.7914
Epoch 13540: Training cost= 0.3229, Training acc= 0.7911, Validation cost= 0.3731, Validation acc= 0.7915
Epoch 13550: Training cost= 0.2966, Training acc= 0.7912, Validation cost= 0.3345, Validation acc= 0.7915
Epoch 13560: Training cost= 0.3563, Training acc= 0.7912, Validation cost= 0.3296, Validation acc= 0.7916
Epoch 13570: Training cost= 0.4400, Training acc= 0.7913, Validation cost= 0.3401, Validation acc= 0.7916
Epoch 13580: Training cost= 0.3018, Training acc= 0.7913, Validation cost= 0.3463, Validation acc= 0.7917
Epoch 13590: Training cost= 0.3909, Training acc= 0.7914, Validation cost= 0.3419, Validation acc= 0.7917
Epoch 13600: Training cost= 0.3449, Training acc= 0.7914, Validation cost= 0.3025, Validation acc= 0.7918
tm  [ 0.4 -0.3 -0.1  6.3 -1.1 -0.6 -0.1 -0.4  1.4 -0.5  5.2 -0.5 -0.2 -0.5 -1.2  5.3 -1.  -0.4  1.8 -1.  -0.7 -0.1  2.  -0.6 -0.7  1.5 -0.2 -0.3  2.3 -0.1  3.6 -0.9 -0.4  3.9  0.8 -0.3 -0.2  2.8  7.4 -1.1 -0.3 -0.9 -0.8  2.4 -0.6  0.2  4.9 -0.8  2.5  2.4 -0.6 -0.   3.8 -0.5 -1.4  3.1 -0.1 -1.3  3.6 -0.5 -1.7 -0.3  1.   3.9  0.7  0.8 -0.4  1.3  1.3  0.3 -0.  -1.   1.1  1.3  3.  -0.3 -1.5 -0.5  1.   0.8 11.2 -0.3  0.8 -0.2 -0.8 -0.5  2.  -0.2 -0.5 -0.2  1.7 -0.6 -0.4 -1.9  1.6  0.3 -0.7 -0.9 -0.3  0.6  0.8  4.8 -0.9 -0.   0.5  1.6  3.7  3.4  1.9 -1.5 -1.2 -0.4 -0.1 -0.4  0.5  6.2  0.4 -0.  -0.2 -0.   1.   5.2 -0.4  0.4  0.6 -1.5 -0.6  4.2  2.9 -1.6  3.1 -1.2  0.4 -0.8 -0.4  3.5  0.7 -0.4 -0.3 -0.5 -0.4 -0.4 -0.3  0.4 -0.5  0.9 -0.1 -0.2 -1.6  0.5 -0.1 -0.2  3.1 -0.4  1.8 -0.2 -0.1 -0.2  0.5  0.9  2.1 -0.4  0.4 -0.2 -0.2 -0.9  2.5  3.2  0.4  1.8 -0.5 -1.3 -0.1  0.4 -0.4  4.5 -0.4  5.3 -1.  -0.2  2.2 -0.4 -0.9 -1.2 -0.6 -0.1  5.6 -0.  -0.3  1.  -0.2 -0.6 -1.6 -0.7  7.9 -0.9  5.7 -0.5 -0.2 -0.3 -0.3  0.9 -0.7 -1.3 -0.6  5.8 -0.3 -0.1  4.3 -0.4  0.4  5.5 -2.   1.2 -0.7 -0.7 -0.3 -0.6  1.1  1.8 -1.2 -0.4 -0.4 -0.9  1.7  3.1  0.1  2.9  1.   5.2 -0.1 -2.   0.3  3.3 -0.4  1.9  2.2  5.2  4.5 15.5 -0.2  7.9  0.2 -0.  -2.  -2.9 -0.2  1.9 -1.4 -0.9 -2.8 -0.   6.1  0.2 -0.4  8.3]
ty_50sample [[9 2 4 7 6 8 3 1 0 5]
 [9 4 0 3 2 5 6 8 7 1]
 [6 3 7 0 9 4 8 1 2 5]
 [8 9 1 7 4 0 2 2 6 3]
 [5 1 6 7 4 3 2 0 9 8]
 [9 3 4 8 7 6 2 5 1 0]
 [2 9 3 3 4 8 7 7 0 5]
 [5 6 4 7 9 8 3 1 2 2]
 [4 5 0 8 9 7 6 3 2 1]
 [2 9 9 7 0 1 6 4 5 8]]
tt_50sample [[9 2 4 7 6 8 3 1 0 5]
 [9 4 0 3 2 5 8 6 7 1]
 [6 3 7 0 9 4 8 1 2 5]
 [8 9 1 4 7 0 5 2 6 3]
 [5 1 6 7 4 3 2 0 9 8]
 [9 3 4 8 7 6 2 5 1 0]
 [2 9 3 1 4 6 8 7 0 5]
 [5 6 4 7 9 8 3 1 2 0]
 [4 5 0 9 8 7 6 3 2 1]
 [2 3 9 7 0 6 1 4 5 8]]
vm  [ 1.2  0.8 -0.7 -1.7 -1.3 -0.2 -0.1 -0.6 -0.8 -0.2  6.  -0.9  0.  -0.2  3.7  2.6  0.6 -0.2 -0.1  1.6 -0.6 -0.3  3.4  0.5 -1.4  2.5 -0.1 -0.4 -1.1 -0.4  1.3 -0.5 -0.6 -0.6  3.  -0.   2.7  3.9 -0.8 -0.9 -0.2  3.   1.   2.2 -0.9  1.2 -2.  -1.4  3.1  7.5 -0.6 -0.7 -0.2  9.6 -0.2 -0.3 -0.6 -0.5  0.4  0.4  1.   0.6  0.3  3.8 -0.2 -0.1  0.2 -0.1 -0.5 -0.  -0.4  3.1 -0.  -0.  -3.5 -0.1 -0.6 -0.2  1.7 -0.1 -1.6 -0.2  1.5 -0.5 -1.3  3.6  3.  -0.1 -0.4 -0.1 -0.2 -0.6 -0.7 -0.2 -0.5  0.3 -0.1 -1.7 -0.  -0.  -0.1  3.4 -0.4 -0.4 -0.   1.3 -1.7  2.1  2.3  0.7 -1.1  0.6 -0.2 -0.   1.8 -1.1 -0.5 -0.6 -0.1 -0.1 -0.1 -0.4 -0.7 -0.4 -0.2  4.1 -1.  -2.6  0.4 -0.1  2.3 -0.5 -0.4  0.4  3.2 -0.2 -0.4 -0.5  0.2 -0.1 -0.6 -1.  -0.8 -0.2  0.3 -0.2 -0.3 -0.3  0.5 -0.   2.  -0.1  3.8 -0.7 -0.2 -0.1 -0.3  1.1 -0.2 -0.2  1.8 -0.2 -0.3 -0.2 -0.2 -0.5 -0.8 -0.2  1.4 -0.5  1.3 -0.6  0.1 -0.1 -0.5  0.4 -0.6 -0.2  4.  -0.8 -0.5 -0.  -0.8 -1.1  0.4 -0.7  0.8 -0.3 -0.2  1.5 -0.  -0.6  1.  -0.9  1.1 -0.2 -0.9  0.2 -0.   0.4 -0.  -0.1 -0.3 -0.7 -0.3 -2.1 -0.4  0.3  3.1 -0.1 -0.3 -0.8 -0.9  0.1 -0.2 -0.4 -0.4 -0.5 -0.7  0.1 -0.3 -0.  -0.3 -1.1  3.2  0.4  2.9  2.4 -0.3  3.  -0.7 -0.4 -0.2  2.6  3.1  4.1  3.  -1.   1.3 -0.8 -0.6 -0.4  0.1 -0.1  7.   1.6 -0.3  1.8 -1.  -0.4  3.3  0.8 -0.6  0.1 -1.   2.7]
vy_50sample [[2 0 4 8 6 5 7 1 9 3]
 [2 4 9 3 3 7 5 6 0 1]
 [0 5 3 8 7 6 1 2 4 9]
 [8 0 3 2 4 5 1 6 7 9]
 [9 5 6 0 4 2 3 3 1 7]
 [8 6 4 7 5 3 0 9 1 2]
 [4 2 5 0 3 9 1 1 6 8]
 [6 7 3 9 8 1 5 5 2 4]
 [1 8 4 7 6 6 5 3 9 2]
 [9 7 8 2 2 6 6 1 5 4]]
vt_50sample [[2 0 4 8 6 5 7 1 9 3]
 [2 4 9 8 3 7 5 6 0 1]
 [0 3 5 8 7 6 1 2 4 9]
 [8 0 3 2 4 5 1 6 7 9]
 [9 5 6 0 4 2 3 8 7 1]
 [8 6 4 7 5 3 0 9 1 2]
 [4 2 5 0 3 9 7 1 6 8]
 [6 7 3 9 8 1 0 5 4 2]
 [1 8 4 7 6 0 5 3 9 2]
 [9 7 8 2 3 0 6 1 5 4]]
Epoch 13610: Training cost= 0.3325, Training acc= 0.7915, Validation cost= 0.2895, Validation acc= 0.7918
Epoch 13620: Training cost= 0.3116, Training acc= 0.7915, Validation cost= 0.3420, Validation acc= 0.7919
Epoch 13630: Training cost= 0.3013, Training acc= 0.7916, Validation cost= 0.3416, Validation acc= 0.7919
Epoch 13640: Training cost= 0.2875, Training acc= 0.7917, Validation cost= 0.3200, Validation acc= 0.7920
Epoch 13650: Training cost= 0.4299, Training acc= 0.7917, Validation cost= 0.3733, Validation acc= 0.7920
Epoch 13660: Training cost= 0.3874, Training acc= 0.7917, Validation cost= 0.3483, Validation acc= 0.7921
Epoch 13670: Training cost= 0.3253, Training acc= 0.7918, Validation cost= 0.3414, Validation acc= 0.7921
Epoch 13680: Training cost= 0.3323, Training acc= 0.7918, Validation cost= 0.3057, Validation acc= 0.7922
Epoch 13690: Training cost= 0.3548, Training acc= 0.7919, Validation cost= 0.3832, Validation acc= 0.7922
Epoch 13700: Training cost= 0.3308, Training acc= 0.7919, Validation cost= 0.3507, Validation acc= 0.7923
tm  [-0.3 -0.8 -0.  -0.6 -1.5 -0.7 -0.  -0.3  3.3 -0.9  2.4  3.4 -1.1 -0.6  2.6 -0.8 -0.6 -0.7  0.3  1.2 -0.7  0.  -1.5 -0.4 -0.6  2.  -0.4 -0.2 -0.6 -1.9  4.7 -0.3 -0.3  6.3 -0.5 -0.7 -0.5 -0.1  1.8 -0.8  0.8 -0.1 -0.4  3.7  0.2 -0.2 -1.1  0.9  2.3 -3.1 -0.9 -0.3  0.6 -0.5 -0.6  0.4 -0.3  2.6  4.9 -1.4  1.3 -0.8  0.9  3.3 -0.  -0.2 -0.2  1.1  1.9  0.4 -0.3 -0.2 -0.1  0.  -3.5 -0.  -1.2 -0.4 -0.4 -0.1  5.2 -0.1  1.  -0.1 -0.9  0.2  1.1 -0.1  0.4 -0.3  0.3 -0.6 -0.  -1.1 -0.  -0.   0.6 -2.  -0.3 -0.4  1.5 -1.  -0.4 -0.1 -0.2 -0.  -1.6  4.5  0.3  0.4  0.3 -0.1 -0.1 -1.2  4.2  0.7 -0.2  4.   0.1  1.   0.1 -0.3  0.2  0.6 -0.6  3.2  0.1  5.   7.9  5.6  0.4 -0.9 -0.4 -0.8 -1.3  4.2  1.  -0.4  0.2 -0.4  1.6  0.4  1.7 -0.  -0.6  0.6 -0.1 -0.7  3.6 -0.3  2.1 -0.2 -0.4  2.3 -0.5 -0.2 -0.4 -0.1  2.5  1.  -0.4 -1.4 -0.  -0.4 -0.  -0.4  0.7  2.2 -0.   0.2 -0.8  1.4 -0.5 -0.4 -0.3 -0.6 -0.3 -0.6  0.3  1.7 -1.1 -0.5 -0.5 -1.2  0.7 -0.3  1.5 -0.3 -0.5  6.9 -0.1 -0.  -0.7 -1.2  0.6 -1.6 -0.6 -1.2 -0.2 -0.3 -0.4  1.1 -0.2 -0.9 -0.6 -1.6  0.4 -0.4 -3.3 -0.1 -0.1  2.4 -1.  -0.  -1.  -0.4 -0.6 -0.5  0.1 -0.2 -1.  -0.3 -0.1 -0.6 -1.4 -0.6 -1.4 -0.1  0.9  6.6 -0.4 -0.6 -0.3 -2.4  1.1  1.8  0.4 -0.9  3.5 -1.8 -0.1 -0.9 -0.1 -0.2 -0.7 -0.4 -0.2 -0.5 -0.9 -0.4 -1.4 -0.9  1.5 -0.2  6.5 -1.4]
ty_50sample [[3 5 4 0 7 1 9 6 2 8]
 [2 1 6 5 5 7 9 9 3 4]
 [8 3 6 2 7 1 5 4 0 9]
 [9 4 3 2 7 8 0 6 5 1]
 [9 3 0 5 4 7 1 8 2 6]
 [6 0 4 3 3 8 9 7 1 5]
 [3 6 8 1 0 4 5 7 9 2]
 [3 5 6 4 9 0 7 8 2 2]
 [4 7 1 6 5 8 0 9 3 2]
 [0 6 2 4 1 7 5 8 9 3]]
tt_50sample [[3 5 4 0 7 1 9 6 2 8]
 [2 1 6 8 5 7 9 0 3 4]
 [8 3 6 2 7 1 5 4 0 9]
 [9 4 3 2 7 8 0 6 5 1]
 [9 3 5 0 4 7 1 8 2 6]
 [6 0 4 3 2 8 9 7 1 5]
 [3 6 8 1 0 4 5 7 9 2]
 [3 5 6 4 9 0 7 8 2 1]
 [4 7 1 6 5 8 0 9 3 2]
 [0 6 2 4 1 7 5 8 9 3]]
vm  [-0.6 -0.5 -0.8  6.4 -1.2 -0.5 -0.1 -0.5  0.3 -0.2  1.8  0.5 -1.  -0.6 -2.4 -0.1 -0.7 -0.6  0.5 -1.8 -0.6 -0.1  2.3 -0.3 -0.7  1.5  0.1 -0.3 -0.1 -0.1  4.6 -0.6 -0.3  4.6 -0.5 -0.2  0.3  1.  12.8 -0.4 -0.3  7.6  0.8  3.4 -0.2 -0.4  9.8  0.9  0.2  4.7 -0.7  0.3  5.1 -2.6 -0.9  4.8 -0.2  2.1  0.1 -1.4 -1.1 -0.7  1.   0.5  1.2 -0.3 -0.2  0.7  1.  -0.2  0.2 -0.6  0.  -0.3  4.9  0.   0.1 -0.2  1.  -0.2 17.6 -0.3 -0.2 -0.4 -0.4  9.2  1.3 -0.5 -0.8 -0.3  1.  -0.3 -0.9 -0.7  0.9 -0.1  0.3 -0.  -0.6  0.2 -0.   5.6 -0.3 -0.2 -0.3  0.4  3.   5.5  0.5 -2.4 -0.3 -0.3 -0.2 -0.5  1.   1.9  0.2 -0.3 -0.3  1.  -0.1  7.3 -0.5  1.4 -0.2 -2.5  1.  12.6  3.4 -3.1 -0.5 -0.6 -0.2 -0.5 -1.3  3.1  0.6 -0.4 -0.5 -0.7  0.4 -0.1  0.9  0.1 -0.5  0.2 -0.2 -0.3  3.   0.5 -0.5  0.7 -0.6  1.3 -0.2 -0.5 -0.5 -0.2  2.6 -0.1  1.1 -0.7 -0.1 -0.5 -0.2 -0.6 -0.4  0.   0.1  2.3  0.9  0.5 -0.4 -0.3 -0.4 -1.1 -0.4  4.  -2.4  0.5 -1.3 -0.1 -0.  -1.1 -0.6  0.8  3.5  0.1  0.4  0.5 -0.  -0.5 -1.5 -0.9  6.5 -0.3  5.1  0.4 -0.1 -0.5 -0.   0.6 -0.3 -0.9 -0.3  8.9 -0.  -0.4 -3.8 -0.4  1.4  2.5 -1.1  4.1 -0.3 -0.4 -1.  -0.4  0.3  1.4 -0.9 -0.2 -0.1 -0.4  2.4 -0.2 -1.5  0.3  1.6  0.6 -0.5 -1.4 -0.3 -2.6 -0.3  3.2  1.4  5.7  1.5  2.9  0.   1.1 -0.1  0.7 -3.6 -3.8 -0.2 -0.1 -0.7 -0.2 -4.2 -0.3  9.6  0.4  2.2 14.5]
vy_50sample [[9 5 4 1 7 0 6 2 8 3]
 [9 4 3 0 6 5 8 7 1 2]
 [3 9 5 4 1 2 2 8 0 7]
 [5 4 3 0 9 6 8 8 7 2]
 [0 9 7 2 6 4 3 8 5 1]
 [4 6 2 7 5 8 0 9 1 3]
 [9 6 3 7 2 4 0 8 5 1]
 [4 1 5 2 2 0 3 8 7 6]
 [2 3 5 7 8 8 0 4 9 6]
 [1 7 5 9 0 6 4 8 2 3]]
vt_50sample [[9 5 4 1 7 0 2 6 8 3]
 [9 4 3 0 6 5 8 7 1 2]
 [3 9 5 4 1 2 6 8 0 7]
 [5 4 3 0 1 9 6 8 7 2]
 [0 9 7 2 6 4 3 8 5 1]
 [4 6 2 7 5 8 9 0 1 3]
 [9 6 3 7 2 4 0 8 5 1]
 [4 1 5 9 2 0 3 8 6 7]
 [2 3 5 7 8 1 0 4 9 6]
 [1 7 5 9 0 8 6 4 2 3]]
Epoch 13710: Training cost= 0.3060, Training acc= 0.7920, Validation cost= 0.3691, Validation acc= 0.7923
Epoch 13720: Training cost= 0.3919, Training acc= 0.7920, Validation cost= 0.3883, Validation acc= 0.7924
Epoch 13730: Training cost= 0.3499, Training acc= 0.7921, Validation cost= 0.3964, Validation acc= 0.7924
Epoch 13740: Training cost= 0.4297, Training acc= 0.7921, Validation cost= 0.3327, Validation acc= 0.7924
Epoch 13750: Training cost= 0.3431, Training acc= 0.7922, Validation cost= 0.3888, Validation acc= 0.7925
Epoch 13760: Training cost= 0.3184, Training acc= 0.7922, Validation cost= 0.3327, Validation acc= 0.7926
Epoch 13770: Training cost= 0.2837, Training acc= 0.7923, Validation cost= 0.3104, Validation acc= 0.7926
Epoch 13780: Training cost= 0.3285, Training acc= 0.7924, Validation cost= 0.3888, Validation acc= 0.7927
Epoch 13790: Training cost= 0.2818, Training acc= 0.7924, Validation cost= 0.3580, Validation acc= 0.7927
Epoch 13800: Training cost= 0.4063, Training acc= 0.7925, Validation cost= 0.3548, Validation acc= 0.7928
tm  [ 2.5  0.1  4.7 -1.5 -1.5 -0.7 -0.3 -0.5 -0.7 -0.3 -0.8 -0.  -1.  -0.1 10.9 -0.2 -0.4 -0.1  0.4  3.  -0.5 -0.2  2.3  0.6 -1.   1.  -0.6 -0.3 -0.6  1.   0.6 -0.4 -0.2  5.5  0.2 -0.3  1.4 -0.6 -2.7 -0.8 -0.5 -0.5 -0.  -0.3 -0.6  0.9 -2.3  0.2  4.3  3.7 -0.6 -0.3 -0.2  3.2 -0.6 -1.3 -0.5 -0.7 -0.   1.7  0.5 -0.1 -0.1  2.3 -0.1 -0.6 -0.1 -0.3  1.5  0.  -0.1  0.7  1.  -0.  -4.2 -0.2 -1.  -0.2  0.4 -0.3 -2.3 -0.1  2.   0.8 -1.3 -0.4  3.6 -0.2  0.6 -0.2 -0.3 -0.2 -0.2 -0.3 -0.6  0.2 -0.4 -1.8 -0.2  0.1  0.8  6.1 -0.9 -0.3 -0.1  0.4 -1.8  0.5 -0.5  2.6 -0.5 -0.3  0.1 -0.3  0.2  0.1 -0.5  0.3 -0.1 -0.2  0.2 -1.1 -0.1 -0.4 -0.1 11.7 -0.2 -0.3 -0.1  3.5  4.7 -0.5  1.2 -0.3 -0.4  5.2 -0.2 -0.4 -0.1 -0.6  2.4 -1.   0.9 -0.  -0.3  0.4  0.2 -0.5 -1.7  0.4  2.8 -0.3  5.1  0.4  0.1  0.2 -0.2 -0.4 -1.3 -0.5  1.2  1.9  0.6 -0.2  0.1 -0.6 -0.1  1.3  0.9 -0.3 -0.3 -0.5 -0.4  0.6 -0.5  4.9 -1.  -0.6  8.4  0.3 -0.1 -0.4 -0.6 -1.2 -0.3 -0.5  2.  -0.5 -0.2 -0.3 -0.2 -0.4 -0.  -1.1  1.4 -0.  -1.  -0.4 -0.  -0.1 -0.2 -0.  -0.4 -0.4 -0.7 -2.6 -0.3 -0.   4.7 -0.3 -0.5 -0.2 -1.2 -0.5 -0.4 -0.2  2.7 -0.3  0.3  0.4 -1.4 -0.3  0.7 -0.6  2.2  0.5 -1.  -0.2 -0.   4.2  1.3 -0.1 -0.2  3.2  0.1 -0.8  2.8 -1.3  3.2 -0.6 -0.4 -0.3 -0.1 -0.1  8.3  2.2 -0.2  0.3 -0.7 -0.3  4.7 -0.1 -2.  -0.2  1.5 -0.6]
ty_50sample [[7 6 8 0 4 3 2 5 9 9]
 [5 5 1 1 8 4 9 7 2 6]
 [8 2 6 4 5 9 7 1 0 3]
 [7 8 0 3 9 6 5 4 2 1]
 [8 5 1 2 4 6 3 3 7 0]
 [9 3 0 6 4 1 2 5 7 8]
 [4 2 2 3 1 7 8 5 6 9]
 [8 0 0 4 9 3 2 2 6 7]
 [9 4 7 0 1 6 8 5 2 3]
 [6 8 0 9 1 3 2 4 5 7]]
tt_50sample [[7 6 0 8 4 3 2 5 9 1]
 [0 3 5 1 8 4 9 7 2 6]
 [8 2 6 4 5 9 7 1 0 3]
 [7 8 0 3 9 6 5 4 2 1]
 [8 5 1 2 4 6 3 9 0 7]
 [9 3 0 6 4 1 2 5 7 8]
 [4 0 2 3 7 1 8 5 6 9]
 [5 0 8 4 9 3 6 1 2 7]
 [9 4 7 0 1 6 8 5 2 3]
 [6 8 0 9 1 3 2 4 5 7]]
vm  [-1.3 -0.4 -2.1 -0.7 -1.   0.9 -0.4 -0.2  1.1 -1.   3.7  0.5 -0.4 -0.3 -1.2 -0.6 -0.3 -0.4 -0.4 -0.1 -0.7 -0.6 -1.6 -0.3 -0.8  2.5 -0.5 -0.3 -1.1 -2.2  4.1 -0.2  0.3 -0.2  0.  -0.1  0.9 -0.3 -0.5 -0.8  0.3 -1.9 -1.   1.8 -0.7 -0.2 -0.6 -0.  -0.5 -3.3 -0.7 -0.6 -0.2  0.9 -0.4  2.5 -0.3 -0.5  4.  -1.2  5.2 -0.2 -0.2  2.8 -0.1 -0.1 -0.4  1.8  0.2  0.3 -0.2  1.6 -0.1  0.9 -2.2  0.5 -0.2 -1.   0.4 -0.3  5.2  0.  -0.1 -0.2  0.7 -1.9 -0.3 -0.2  0.5 -0.4 -0.4 -0.5  0.1 -0.5 -0.5 -0.2 -0.5 -1.7 -0.1 -0.4  2.9 -3.   1.8 -0.2 -0.2 -0.5 -1.5  4.2  0.6 -0.3 -0.7  0.4 -0.2 -0.4  5.7 -0.4 -0.7  1.3 -0.2  0.5 -0.   2.4  0.2  0.3 -0.8 -1.2  0.   2.2  3.7  6.3 -0.1 -0.9 -0.5 -0.5  8.4  8.2 -0.1 -0.3  3.1 -0.7  0.5 -0.  -0.6 -0.  -0.5 -0.3 -0.2  0.4  3.4 -0.5  1.8 -0.3 -1.5  0.7 -0.3 -0.   0.2 -0.4 -0.   0.3 -0.6 -0.4 -0.3 -0.  -0.8 -0.4  1.2  4.4 -0.1 -0.2 -1.2 -0.3 -0.3 -0.2 -0.7 -0.6 -1.  -0.9  3.3 -0.1 -0.4 -0.6 -0.4 -1.3  1.7 -0.6 -0.8  1.1 -0.4  8.1 -0.2  0.5 -0.5 -0.8 -1.  -0.5 -0.6 -0.6 -0.4  0.3 -0.2  0.4 -0.5 -1.2  0.9 -2.1 -0.3  0.1 -0.8  0.7 -0.3 -0.1 -1.4  3.  -0.4 -0.4 -0.1 -0.6 -0.4  0.3 -0.3 -0.1 -0.1 -0.9 -0.6 -0.8 -0.8  2.1  0.4  3.1 -0.6 -0.5 -0.4 -0.6  4.6  5.1  0.7 -0.8  2.9  1.7 -0.3  0.5 -0.4 -0.1 -0.6  0.6 -0.1 -0.1 -1.2 -0.7 -1.5 -1.  -0.3 -0.5  4.4 -1.3]
vy_50sample [[3 1 0 4 6 5 5 2 8 7]
 [2 9 6 8 0 1 5 7 4 3]
 [6 5 2 9 0 8 7 3 4 1]
 [8 5 6 6 9 2 4 3 7 1]
 [8 7 4 1 9 6 5 3 2 0]
 [1 4 7 5 2 6 9 8 8 0]
 [6 9 2 0 5 5 7 1 4 8]
 [8 9 4 3 2 0 5 6 1 7]
 [1 2 5 9 4 8 3 0 6 7]
 [8 9 7 3 2 1 5 0 6 4]]
vt_50sample [[3 1 0 4 6 9 5 2 8 7]
 [2 9 6 8 0 1 5 7 4 3]
 [6 5 2 9 0 8 7 3 4 1]
 [5 0 8 6 9 2 4 3 7 1]
 [8 7 4 1 9 6 5 3 2 0]
 [1 4 7 5 2 6 9 8 3 0]
 [6 9 2 3 0 5 7 1 4 8]
 [8 9 4 3 2 0 5 6 1 7]
 [2 1 5 9 4 8 3 6 7 0]
 [8 9 7 3 2 1 5 0 6 4]]
Epoch 13810: Training cost= 0.3141, Training acc= 0.7925, Validation cost= 0.3479, Validation acc= 0.7928
Epoch 13820: Training cost= 0.3786, Training acc= 0.7926, Validation cost= 0.3372, Validation acc= 0.7929
Epoch 13830: Training cost= 0.3680, Training acc= 0.7926, Validation cost= 0.3408, Validation acc= 0.7929
Epoch 13840: Training cost= 0.3820, Training acc= 0.7926, Validation cost= 0.4026, Validation acc= 0.7930
Epoch 13850: Training cost= 0.3361, Training acc= 0.7927, Validation cost= 0.3274, Validation acc= 0.7930
Epoch 13860: Training cost= 0.2758, Training acc= 0.7928, Validation cost= 0.2964, Validation acc= 0.7931
Epoch 13870: Training cost= 0.2966, Training acc= 0.7928, Validation cost= 0.3126, Validation acc= 0.7931
Epoch 13880: Training cost= 0.3333, Training acc= 0.7929, Validation cost= 0.3784, Validation acc= 0.7932
Epoch 13890: Training cost= 0.3335, Training acc= 0.7929, Validation cost= 0.3443, Validation acc= 0.7932
Epoch 13900: Training cost= 0.2944, Training acc= 0.7930, Validation cost= 0.3718, Validation acc= 0.7933
tm  [-1.3 -0.2 -0.3 -1.9 -1.1  0.1 -0.1 -0.3  1.3 -0.4  7.2 -0.3 -0.2 -0.2  6.2  5.2 -0.3 -0.5 -0.5  5.4 -0.8 -0.2 -0.5 -0.6 -1.6  1.1 -0.2  0.3  1.1 -1.2  2.5 -1.   1.   2.1 -0.5 -0.8  0.2  1.1 -3.9 -0.4 -0.4 -0.3 -0.6 -1.1 -0.7  0.2 -3.3 -0.9 -0.7 -1.3 -0.5 -0.4 -0.1 10.1 -1.2 -0.5 -0.3  2.1  3.8 -0.5  9.1 -0.5  0.9  1.9 -0.  -0.5 -0.2  1.8 -0.6 -0.4 -0.5 -1.  -0.2 -0.4 -5.8 -0.2 -0.3 -0.2 -0.1 -0.1 -1.5 -0.1  1.6 -0.1  0.2  0.5 -0.6 -0.2 -0.  -0.  -0.3 -0.2  0.3 -0.6 -0.5 -0.2  0.2 -2.4 -0.4 -0.5  1.4 -0.8  1.6 -0.3 -0.4 -0.2 -3.   2.1  1.6  6.  -0.5  0.  -0.2 -0.5  1.4  4.5 -0.2 -0.2 -0.2  0.9 -0.4 -2.  -0.1  1.  -0.1  6.5  1.1 -2.3  2.9  5.7  0.5 -0.6 -0.4 -0.2 10.8 13.2 -0.6 -0.3  0.9 -0.5 -0.7 -0.1 -0.7 -0.2 -0.3 -0.1 -0.   0.4  3.  -0.2  2.2 -0.2 -1.2 -0.3 -0.4 -0.1 -0.7 -0.1 -1.1 -0.   0.3  2.8  0.7 -0.3 -0.3 -0.5  1.4  2.3 -0.4 -0.4 -0.6 -0.4 -0.6 -0.3 -0.3 -0.3 -1.5 -0.8 12.  -0.  -0.3 -0.2 -0.6 -1.4  0.2 -0.5 -1.4 -0.3 -1.   4.6 -0.3 -0.3  1.4 -1.  -2.3 -0.6 -1.7 -0.3 -0.3 -0.3 -0.1  0.6 -0.3 -0.8  0.3 -3.3  0.  -0.1 -1.2  0.5 -0.6  2.6 -1.   5.1 -0.7 -0.2  4.8 -0.4 -0.5 -0.4 -0.6 -0.5 -0.2 -0.7  2.6  0.5 -0.1  3.9  1.6  1.6  1.9  0.1 -0.4 -0.6 -0.2  1.6  0.4 -2.5  0.6 -2.5 -0.4 -1.3 -0.3 -0.4  6.1  4.5 -0.2 -0.1 -1.  -0.5  2.9 -0.4 -3.   0.8  0.3 -1.8]
ty_50sample [[6 1 2 3 5 4 7 0 8 9]
 [7 3 6 0 1 2 9 4 8 5]
 [8 1 3 0 6 4 7 2 9 9]
 [0 3 6 8 5 4 4 7 9 1]
 [9 5 6 7 1 2 0 3 4 8]
 [1 9 6 8 0 2 5 7 4 3]
 [4 5 2 6 0 3 8 1 1 7]
 [4 7 1 9 2 0 5 3 6 8]
 [2 7 5 4 1 1 0 3 6 9]
 [0 2 1 4 7 9 5 3 8 6]]
tt_50sample [[6 1 2 3 5 4 7 0 8 9]
 [7 3 6 0 1 2 4 9 8 5]
 [8 1 3 0 6 4 7 2 5 9]
 [0 3 6 5 2 8 4 7 9 1]
 [9 5 6 7 1 2 0 3 4 8]
 [1 9 6 8 0 2 5 7 4 3]
 [4 5 2 6 0 3 8 1 9 7]
 [4 7 1 9 2 0 5 3 6 8]
 [2 7 5 4 1 8 0 3 6 9]
 [0 2 1 4 7 9 5 3 8 6]]
vm  [-1.7 -0.4 -1.2 -2.3 -0.6 -0.  -0.6 -0.5 -0.4 -0.1 -2.3  2.3 -1.3 -0.4  3.  -0.1 -0.4 -0.2 -0.3  0.7 -0.4 -0.1 -0.2 -0.9 -1.  -0.1 -0.3 -0.5  2.5 -0.7  1.2 -0.6  1.1 -1.5 -0.9 -0.8  1.3 -1.1 -3.3 -0.4 -0.3 -2.1 -1.1 -0.5 -0.6 -0.6 -1.2  0.6 -2.  -0.6 -0.5 -0.3 -1.2  0.4 -1.8 -0.2 -0.8 -1.3  3.3 -0.3  9.6 -0.3 -0.7 -1.  -0.2 -0.4 -0.3  1.9  1.  -0.3 -0.2 -1.  -0.4 -0.4 -5.4 -0.2  1.4 -0.4  0.8 -0.2 -2.6 -0.2 -0.6  0.1  2.3 -2.1 -0.5 -0.2  0.6 -0.6 -1.2  0.  -0.1 -0.2 -0.9 -0.3 -1.  -1.7 -0.8 -0.5  1.  -1.   3.5 -0.1 -0.4 -0.1 -3.2  2.6 -1.   0.3  0.3 -0.9 -0.3 -0.5  2.3  4.1  1.4  1.1 -0.1  1.6 -0.2 -0.5 -0.  -0.5 -0.3  3.   2.   2.5  0.6  7.5 -0.3 -0.6 -0.5 -0.   8.6  7.5 -0.5 -0.2 -0.1 -0.9  1.1 -0.3  0.2 -0.2 -0.8 -0.4 -0.3 -0.2 -0.4 -0.7  2.1 -0.2 -0.9 -0.1 -0.1 -0.3 -0.3 -0.  -1.6 -0.7 -0.8  1.2  1.  -0.5 -0.9 -0.1  1.4  4.7 -1.  -0.8 -1.3 -1.  -0.6 -0.  -0.1  2.  -1.8 -1.6 10.1  0.   1.5 -0.1  0.8 -1.4 -0.2  0.6 -1.5 -0.  -1.1  2.1 -0.5 -0.3 -0.3 -1.6 -2.6  1.  -1.9 -0.1 -0.4 -0.8  0.3 -0.1 -0.2 -0.6 -0.2 -3.  -0.5 -0.8  6.  -0.4 -0.3  1.  -1.2  5.  -0.1  1.1  1.3 -0.4  0.5 -0.1 -1.  -0.2 -0.1 -1.2  0.7  2.1 -1.8 -0.   0.9 -0.2  0.1  3.6 -0.2  4.  -1.2  2.8 -0.2 -3.  -0.2  2.1 -0.1  1.3 -0.6 -0.1  9.2  3.4  0.9 -0.7 -0.3 -0.3  5.9 -0.4 -2.5 -0.6  4.7 -2.1]
vy_50sample [[1 6 3 4 8 7 7 9 5 2]
 [3 8 1 9 2 0 4 5 6 7]
 [0 5 4 1 2 3 6 8 9 7]
 [4 1 8 9 0 7 5 2 3 6]
 [7 1 3 5 6 4 2 0 8 9]
 [8 5 4 0 0 9 7 7 3 6]
 [9 0 8 6 4 2 7 5 1 3]
 [2 6 9 5 0 0 8 7 4 1]
 [2 0 0 3 1 7 8 9 5 4]
 [3 2 4 9 7 5 1 0 8 6]]
vt_50sample [[1 6 3 4 8 7 0 9 5 2]
 [3 8 1 9 0 2 4 5 6 7]
 [0 4 5 1 2 3 6 8 9 7]
 [4 1 8 9 0 7 5 2 3 6]
 [7 1 3 5 6 4 2 0 8 9]
 [8 5 4 0 9 2 1 7 3 6]
 [9 8 0 6 4 2 7 1 5 3]
 [2 6 9 5 0 3 8 4 7 1]
 [2 6 0 3 1 7 8 9 5 4]
 [3 2 4 9 7 5 1 0 8 6]]
Epoch 13910: Training cost= 0.3561, Training acc= 0.7930, Validation cost= 0.4540, Validation acc= 0.7933
Epoch 13920: Training cost= 0.3171, Training acc= 0.7931, Validation cost= 0.3517, Validation acc= 0.7934
Epoch 13930: Training cost= 0.3140, Training acc= 0.7931, Validation cost= 0.3309, Validation acc= 0.7934
Epoch 13940: Training cost= 0.3637, Training acc= 0.7932, Validation cost= 0.3527, Validation acc= 0.7935
Epoch 13950: Training cost= 0.2854, Training acc= 0.7932, Validation cost= 0.3165, Validation acc= 0.7935
Epoch 13960: Training cost= 0.3178, Training acc= 0.7933, Validation cost= 0.3410, Validation acc= 0.7936
Epoch 13970: Training cost= 0.3410, Training acc= 0.7933, Validation cost= 0.3788, Validation acc= 0.7936
Epoch 13980: Training cost= 0.4196, Training acc= 0.7934, Validation cost= 0.4076, Validation acc= 0.7937
Epoch 13990: Training cost= 0.3849, Training acc= 0.7934, Validation cost= 0.4037, Validation acc= 0.7937
Epoch 14000: Training cost= 0.3170, Training acc= 0.7935, Validation cost= 0.3901, Validation acc= 0.7937
tm  [ 0.8 -0.5  6.1  0.9 -1.  -0.7 -0.4 -0.6 -0.2  0.9 -4.   0.9 -1.3 -0.4  6.5 -1.6 -0.1 -0.3 -0.   3.8 -0.4 -0.6  3.2 -0.  -0.6 -0.3 -0.1 -0.2 -1.1 -1.1 -2.4 -0.1  0.1 -3.1  1.3 -0.9 -0.2 -0.6 -2.8 -0.3 -0.4  3.4 -0.2 -1.2 -0.4 -0.4 -2.2 -0.2  1.6  8.7 -0.4 -0.3 -1.3  4.2  2.2 -0.6 -0.6  6.2  2.9  7.9  3.  -0.7 -0.4  2.3 -0.9 -0.4 -0.3 -0.2  1.9 -0.8 -0.6  3.6 -0.3 -0.3 -5.7  0.7 -0.9  0.6 -0.5 -0.3 -5.6 -0.1 -0.  -0.  -1.5  3.  -0.2 -0.  -0.2  0.1  0.1 -0.4 -0.7  0.1 -1.  -0.3  1.6 -2.4 -0.  -0.8 -0.5  2.6 -0.6 -0.5 -0.2 -0.1 -2.9 -2.4 -1.7  2.9  1.3  0.1 -0.2 -0.5  3.8 -1.7 -0.3  2.4 -0.1  2.4 -0.  -1.2 -0.1 -0.7 -0.2  7.4 -0.7 -0.4  1.4  3.5  2.9 -0.4 -0.2 -0.2  5.1 -1.9 -0.4 -0.5 -0.3  1.5  1.  -1.3  1.6 -0.2 -0.1 -0.4 -0.6 -0.6  2.  -0.4 -0.1 -0.3  6.   0.1 -0.3 -0.1  0.  -0.3 -1.  -0.2  0.3  0.5  0.4 -0.1 -0.7 -0.4 -0.7 -0.2 -0.6 -0.3 -0.6  0.2 -0.3 -0.2 -0.2 -0.2 -1.5 -1.2  8.7  1.2 -1.  -0.5 -0.2 -0.9  1.7  0.1  0.  -0.4 -0.2  4.2 -0.2 -0.4  0.8 -0.9 -0.3 -0.6 -2.  -1.  -0.1  0.2 -0.3 -0.1  0.6 -0.3 -0.6 -3.  -0.2 -0.7  4.7 -0.3 -0.7 -1.3 -0.5 -0.6 -0.5  0.6  5.8 -0.3 -0.4 -0.4 -0.9 -0.3 -0.7 -1.3  1.9 -0.2 -1.5 -0.  -0.6  3.3 -0.1  1.5 -0.3  3.6  0.9 -1.2  3.1 -2.7  1.2 -3.1 -0.2 -1.7 -0.4  0.3 17.   3.1  0.6 -0.5 -0.8  0.  13.8 -0.5 -1.9 -0.3  2.2 -1. ]
ty_50sample [[8 0 6 5 7 3 2 1 4 4]
 [8 5 9 2 3 0 6 7 1 4]
 [0 6 9 3 5 5 8 4 1 2]
 [7 6 9 3 2 1 4 5 5 0]
 [0 7 4 1 9 3 5 6 2 2]
 [6 0 2 1 3 5 8 9 4 4]
 [6 8 0 9 4 1 1 7 2 3]
 [7 4 8 9 3 0 6 1 2 5]
 [9 1 5 3 4 4 0 2 6 7]
 [1 3 4 2 6 5 9 0 8 7]]
tt_50sample [[8 0 6 5 7 3 2 1 4 9]
 [8 5 9 2 3 0 6 1 7 4]
 [0 6 9 3 5 7 8 4 1 2]
 [7 6 9 3 2 1 4 5 8 0]
 [0 7 4 9 1 3 5 6 8 2]
 [6 0 2 1 3 5 8 9 7 4]
 [8 6 0 9 1 4 5 7 2 3]
 [7 4 8 9 3 0 6 1 2 5]
 [9 1 5 3 8 4 0 2 6 7]
 [1 3 4 2 6 5 9 0 8 7]]
vm  [ 0.9  0.4 -1.8  5.6 -0.6 -1.  -0.  -0.6 -0.7 -0.7 -2.1  3.3 -1.8 -0.3 -2.9 -1.4 -0.  -0.3 -0.2 -1.7 -0.5  0.4 -0.2  0.5 -0.9  1.   0.4 -0.3 -0.6 -0.1  3.  -0.7 -0.2 -1.4 -0.4 -0.   2.6 -0.8  9.7 -0.7 -0.2  4.7  3.2  3.2 -0.1 -0.1  9.1  3.1  2.7 -0.2 -0.5 -0.4  2.6 -3.3 -0.4  5.1 -0.1  2.9 -0.9 -0.6 -2.2 -0.7 -0.  -0.4  0.4 -0.3 -0.1 -0.1  1.   0.4 -0.2  0.7 -0.1 -0.7  4.  -0.1 -0.4 -0.2 -0.1 -0.2 11.8 -0.3 -0.9 -0.1 -1.1  4.6  4.1 -0.5  0.8 -0.4 -0.1 -0.  -0.1  1.7 -0.1 -0.4  0.1  0.4 -0.3  0.1  1.7 -1.2 -0.8 -0.1 -0.2  0.8  0.9  3.2 -0.7 -2.7 -0.2 -0.3 -0.3 -0.4  0.6 -0.4 -0.3 -0.3 -0.1  0.3 -0.2  8.9 -0.1 -0.6 -0.4 -3.1  1.7 14.5  1.8 -0.8  2.  -0.5  0.1 -0.2  4.2  0.3 -0.4 -0.1 -0.1 -0.7  3.6 -0.7  2.9  0.3 -0.5 -0.2 -0.5 -0.9  6.9 -0.2 -0.4  0.   4.   0.8 -0.1 -0.  -0.7  0.  -0.2 -1.  -0.4 -0.4 -0.3 -0.5 -0.3  0.1 -0.5 -0.4  0.   0.8 -0.3  1.4 -0.4 -0.3 -0.5 -2.  -0.5  2.1 -1.5  1.  -2.2  0.6 -0.  -1.3 -0.3  0.   6.1  0.5  0.5  2.1 -0.3 -0.4 -1.2 -1.3 10.5  0.2  3.4 -0.1  0.1 -0.4 -0.1 -0.1  0.  -0.3 -0.8  5.1  0.3 -0.3 -2.6 -0.3 -0.5 -0.1 -0.6 -0.5  0.6 -0.1 -0.6 -0.3 -0.3 -0.1 -0.6 -0.2  0.3 -0.2 -0.4  0.1 -1.8 -0.9 -0.2  3.5 -0.8 -0.9 -0.2 -1.9  0.4  5.   0.6  4.5  0.4  0.9 -0.3 -0.  -0.2  0.3 -2.1 -2.8 -0.2 -0.4 -0.8  0.2 -2.7 -0.7  7.9 -0.5  5.6  5.8]
vy_50sample [[5 9 4 4 3 8 6 7 1 2]
 [2 7 8 3 5 6 9 1 0 4]
 [5 1 6 0 9 4 2 3 7 8]
 [6 4 0 2 2 1 3 9 8 5]
 [4 9 1 5 3 7 7 0 2 6]
 [0 7 3 1 4 8 9 2 5 6]
 [5 2 1 4 0 0 6 3 9 9]
 [8 0 4 4 7 5 9 1 1 2]
 [4 5 2 6 3 9 8 0 7 1]
 [6 8 3 5 4 9 7 2 1 0]]
vt_50sample [[5 9 4 3 0 8 6 7 1 2]
 [2 7 8 3 5 6 9 1 0 4]
 [5 1 6 0 9 4 2 3 7 8]
 [6 4 0 2 7 1 3 9 8 5]
 [4 9 1 3 5 7 0 8 2 6]
 [0 7 3 1 4 8 9 2 5 6]
 [5 2 1 4 7 0 3 6 8 9]
 [8 0 4 6 7 5 3 9 1 2]
 [4 5 2 6 3 9 8 0 7 1]
 [6 8 3 5 4 9 7 2 1 0]]
Epoch 14010: Training cost= 0.3122, Training acc= 0.7935, Validation cost= 0.2916, Validation acc= 0.7938
Epoch 14020: Training cost= 0.2774, Training acc= 0.7936, Validation cost= 0.3830, Validation acc= 0.7938
Epoch 14030: Training cost= 0.3229, Training acc= 0.7936, Validation cost= 0.3187, Validation acc= 0.7939
Epoch 14040: Training cost= 0.3305, Training acc= 0.7937, Validation cost= 0.3452, Validation acc= 0.7939
Epoch 14050: Training cost= 0.3366, Training acc= 0.7937, Validation cost= 0.3377, Validation acc= 0.7940
Epoch 14060: Training cost= 0.3080, Training acc= 0.7938, Validation cost= 0.3582, Validation acc= 0.7940
Epoch 14070: Training cost= 0.3983, Training acc= 0.7938, Validation cost= 0.3745, Validation acc= 0.7941
Epoch 14080: Training cost= 0.3359, Training acc= 0.7939, Validation cost= 0.3637, Validation acc= 0.7941
Epoch 14090: Training cost= 0.3790, Training acc= 0.7939, Validation cost= 0.3398, Validation acc= 0.7942
Epoch 14100: Training cost= 0.3840, Training acc= 0.7939, Validation cost= 0.3426, Validation acc= 0.7942
tm  [-1.5 -0.3  4.6 10.2 -0.9 -0.  -0.1 -0.5 -0.3  0.2 -1.5 -0.7 -0.   0.1 -0.5  3.2 -0.2 -0.1 -0.5 -0.3 -0.8 -0.6  4.2 -0.4 -0.8  0.   0.   0.3 -0.  -0.9 -2.7 -0.8 -0.1 -3.9 -0.1 -0.4  0.9  2.3  0.3  0.5 -0.4  2.8 -0.1 -1.1 -0.4 -0.7 -0.  -0.8 -1.  11.2 -0.2 -0.4 -0.7  3.3 -0.7  2.5 -0.4  5.   1.3  6.9  4.8 -0.3 -0.3  1.3 -1.1 -0.4 -0.3  0.4 -0.2 -0.6 -0.2 -0.2 -0.1  0.9 -2.5 -0.2  0.6 -0.   0.4 -0.2 -2.7 -0.2 -0.3 -0.1  0.1  3.4 -1.4 -0.1 -0.4 -0.1  1.3 -0.6 -0.5 -0.3 -0.3 -0.2  1.2 -1.5 -0.2 -0.8 -0.3  3.3  1.6 -0.4 -0.4 -0.2 -1.3 -2.6 -0.9 -1.  -0.1 -0.2 -0.3 -0.5  1.3  2.4 -0.3 -0.6 -0.2  0.8  0.3  3.6 -0.3 -0.   0.5 -0.6 -0.2 -0.2  1.3 -0.5 -0.4 -0.4 -0.5  0.3  6.1 -2.8 -0.2 -0.3 -0.1  2.8 -0.5 -0.7 -0.6 -0.2 -0.1 -0.3 -0.2  0.5  2.2 -0.3 -0.9 -0.4  1.5 -0.4  0.4  0.3 -0.3 -0.5 -0.  -0.   1.2  0.2 -0.1 -0.  -0.9 -0.4 -0.4  0.6 -0.3  1.5 -0.  -0.4 -0.3 -0.3 -0.3 -0.2 -0.8  0.4  1.6 -0.4 -0.3 -0.  -0.1 -0.8 -0.2  0.5 -0.6 -0.4 -0.7  3.9 -0.2 -0.5 -0.6 -0.3 -0.7 -0.2 -0.4 -0.  -0.5 -0.3 -0.2  0.2 -0.2 -0.8  0.8 -0.8 -0.6 -0.1  6.6 -0.4 -0.5  1.4 -0.3  5.6 -0.8 -0.1  5.2 -0.5 -0.5 -0.4 -0.3 -0.3 -0.6 -1.2  3.6  2.1 -0.3  4.2 -0.6 -0.5 -0.4 -0.3 -0.1  4.5 -0.3 -0.4  1.  -0.7  0.1  2.8 -0.1  1.4 -0.2 -0.3  8.8 -1.   0.6 -0.1 -0.8 -0.4  6.  -0.   0.5  0.6 -0.4  5.1]
ty_50sample [[8 1 2 6 9 0 5 7 3 4]
 [4 8 8 3 2 6 5 9 7 0]
 [8 1 4 0 0 5 9 3 7 6]
 [3 2 1 4 8 7 5 9 6 0]
 [5 9 9 4 1 3 7 6 0 2]
 [9 6 7 0 5 4 2 8 3 1]
 [2 0 7 9 8 6 1 5 4 3]
 [6 6 0 1 2 5 7 4 8 3]
 [2 6 4 7 3 9 5 8 0 1]
 [2 4 8 5 5 1 3 7 9 0]]
tt_50sample [[8 1 2 6 9 0 5 7 3 4]
 [4 1 8 3 6 2 5 7 9 0]
 [8 1 4 0 2 9 5 3 7 6]
 [3 2 1 4 8 7 5 9 6 0]
 [5 9 8 4 1 3 7 0 6 2]
 [9 6 0 7 4 5 2 8 3 1]
 [2 0 7 9 8 6 1 5 4 3]
 [9 0 6 1 2 5 7 4 8 3]
 [2 6 4 7 3 9 5 8 0 1]
 [2 4 8 5 6 1 3 7 9 0]]
vm  [-0.8 -0.7 -0.2  5.5 -0.9 -0.7 -0.1 -0.5  3.  -0.3  1.7  3.  -1.2 -0.  -1.  -0.7 -0.5 -0.5 -0.2 -0.6 -1.  -0.1 -1.  -0.6 -0.5  1.1  0.4 -0.5 -0.5 -2.3  1.8 -0.4 -0.4  2.  -0.5 -1.  -0.5  2.   8.4 -0.4 -0.2  3.5 -0.   3.2 -0.5  0.5  1.4  0.1 -0.1 -1.8 -0.7 -0.2  1.5 -1.2 -0.8  2.9 -0.4  5.2  4.  -0.2  1.3 -0.9  0.6  2.1  0.9 -0.8 -0.2  2.3 -0.1 -0.3  0.  -0.  -0.1 -0.1 -2.6 -0.2 -0.6 -0.5 -0.4 -0.1  8.4 -0.4 -0.1 -0.5 -0.6  3.  -0.2 -0.2 -0.3 -0.6  0.4 -0.6 -0.1 -1.  -0.4 -0.4 -0.  -1.5 -0.3 -0.4  0.8 -1.4  1.1 -0.4 -0.3  0.6 -1.1  2.   0.1 -1.3  1.  -0.1 -0.2 -1.1  4.6  0.1 -0.3  1.9 -0.2  3.5  0.3  2.9 -0.2  0.7 -0.6 -1.   1.6  7.2  8.   2.  -0.7 -0.7 -0.3 -0.4 -0.6 -0.5  0.7 -0.3  1.  -0.6  1.   0.1  0.7  0.1 -0.4  0.4 -0.3 -0.5  6.5 -0.3 -0.  -0.1 -0.8  1.6 -0.4 -0.2 -0.6 -0.   4.5  0.2 -0.4 -1.5  0.2 -0.3 -0.3 -0.3  0.1  1.7 -0.3  2.4 -0.6  1.6 -0.5 -0.2 -0.6 -1.8  0.2 -0.2 -1.3  0.1 -1.5 -0.4 -0.4 -1.3  0.7 -0.1  0.8 -0.2 -0.1  9.3 -0.1 -0.1 -1.1 -1.   1.2 -1.5 -0.3 -1.  -0.3 -0.2 -0.2  0.3 -0.4 -0.8 -0.3 -0.4  0.2 -0.6 -4.2 -0.3 -0.5  1.5 -1.   2.1 -0.8 -0.2 -0.5 -0.8 -0.2  0.7 -0.6 -0.3  0.7 -0.3 -1.2 -0.5 -1.4  1.5  0.7  3.7 -0.7 -0.7 -0.3 -3.   1.   2.4  0.7 -0.4  1.3 -2.1 -0.2 -1.1 -0.5 -0.  -1.5 -1.4 -0.4 -0.7 -1.3 -0.3 -2.2 -1.   6.8 -0.4  5.   0.3]
vy_50sample [[5 3 9 0 0 4 4 7 8 6]
 [4 6 7 9 3 8 5 0 2 1]
 [7 7 3 4 6 5 9 2 0 8]
 [9 4 5 8 1 6 3 2 0 7]
 [1 7 7 9 6 0 5 8 4 3]
 [5 0 6 3 9 2 8 1 7 4]
 [5 6 1 1 2 9 0 8 3 7]
 [2 9 5 4 4 3 6 0 8 1]
 [4 1 7 6 0 5 8 2 3 9]
 [7 8 0 5 1 6 2 4 9 3]]
vt_50sample [[5 3 9 1 0 4 7 8 2 6]
 [4 6 7 8 9 3 5 0 2 1]
 [7 1 3 4 6 5 9 2 0 8]
 [9 4 5 8 1 6 3 2 0 7]
 [1 7 2 9 6 0 5 8 4 3]
 [5 0 6 3 9 2 8 1 7 4]
 [5 6 1 4 2 9 0 8 3 7]
 [2 9 5 4 7 6 3 0 8 1]
 [4 1 7 6 0 5 8 2 3 9]
 [7 8 0 5 1 6 2 4 9 3]]
Epoch 14110: Training cost= 0.3238, Training acc= 0.7940, Validation cost= 0.3730, Validation acc= 0.7942
Epoch 14120: Training cost= 0.3286, Training acc= 0.7940, Validation cost= 0.3217, Validation acc= 0.7943
Epoch 14130: Training cost= 0.3691, Training acc= 0.7941, Validation cost= 0.3059, Validation acc= 0.7944
Epoch 14140: Training cost= 0.3356, Training acc= 0.7942, Validation cost= 0.3207, Validation acc= 0.7944
Epoch 14150: Training cost= 0.2901, Training acc= 0.7942, Validation cost= 0.3381, Validation acc= 0.7945
Epoch 14160: Training cost= 0.3210, Training acc= 0.7943, Validation cost= 0.3345, Validation acc= 0.7945
Epoch 14170: Training cost= 0.3469, Training acc= 0.7943, Validation cost= 0.3569, Validation acc= 0.7946
Epoch 14180: Training cost= 0.2973, Training acc= 0.7944, Validation cost= 0.3386, Validation acc= 0.7946
Epoch 14190: Training cost= 0.3787, Training acc= 0.7944, Validation cost= 0.3330, Validation acc= 0.7947
Epoch 14200: Training cost= 0.3356, Training acc= 0.7945, Validation cost= 0.3368, Validation acc= 0.7947
tm  [-0.3 -0.2 -0.9 -0.2 -1.1 -0.5  0.3 -0.6 -0.4 -0.3 -1.6  0.9 -1.5 -0.2 -0.1 -0.4 -0.2 -0.3 -0.4 -0.1 -0.3  1.   3.4  0.2 -1.4  0.8 -0.1 -0.5 -0.2  0.5  1.3 -0.3  2.1 -1.1 -0.6 -0.4  1.4 -0.6 -1.9 -0.3  1.2  7.3  2.4 -0.4 -0.2 -0.4 -0.5  1.2  0.9  6.7 -0.5 -0.4  0.8 -0.7 -1.   0.8 -0.3  2.8 -0.3  0.6  1.6 -0.7  0.5  0.1  0.2 -0.9  0.4  1.   0.6 -0.2 -0.1 -0.4 -0.1 -0.1 -3.6 -0.2 -0.2 -0.2  0.2 -0.6 -0.3  0.1  0.9 -0.2 -0.9  8.2  1.8 -0.1 -0.4 -0.3 -0.6 -0.2 -0.6 -0.  -0.5 -0.4 -0.  -1.4 -0.2  0.4  0.   3.3 -0.1 -0.2 -0.6  0.  -1.7  0.7 -0.8 -0.3 -0.2 -0.3 -0.3 -0.9  0.4  1.7 -0.3 -0.5 -0.2  1.1 -0.1 -0.5 -0.6 -0.4 -0.1 -0.1  1.6  5.1  2.6 -0.4  1.4 -0.4 -0.1 -0.2  8.6  7.3  0.1 -0.4 -0.4 -0.6  2.6 -0.3  1.9 -0.1 -0.4  0.2 -0.3 -0.8  5.5  0.4  0.3 -0.1  2.5  1.5 -0.3 -0.  -0.5  1.1 -0.9 -0.7  0.9  1.9  0.5 -0.2 -0.  -0.4 -0.5 -0.3  0.9  0.7  0.5  1.5 -0.5 -0.1 -0.3 -1.3 -1.6 -0.3  6.4  0.3 -1.5 -0.2 -0.1 -1.2 -0.7 -0.1  0.7 -0.3 -0.4  0.2  0.2 -0.6 -0.3 -1.3  0.9 -0.1 -0.9 -0.3 -0.1 -0.4 -0.1 -0.3 -0.1 -0.4 -0.5 -1.1 -0.2 -0.2 -2.  -0.1 -0.3  1.5 -0.4  2.7 -0.2 -0.   1.7 -0.4 -0.1  0.8 -1.  -0.1  0.6 -0.6  3.1  2.  -1.8 -0.2 -0.5  1.1  0.9  0.1 -0.2 -1.4 -0.4  3.5  1.1 -1.1  1.9 -2.8 -0.  -1.5 -0.3 -0.1  3.3 -0.7 -0.2 -0.2 -0.7  0.1  0.2 -0.4 -1.4 -0.5  3.3  4.8]
ty_50sample [[5 6 8 4 1 9 0 7 3 3]
 [7 4 2 5 9 1 3 6 0 8]
 [3 7 6 2 2 1 5 0 8 4]
 [1 3 9 0 2 6 4 7 8 5]
 [2 9 7 1 3 5 0 8 6 4]
 [2 2 1 8 0 5 7 6 3 4]
 [1 3 6 0 2 5 4 4 7 8]
 [1 8 9 2 0 4 5 3 6 7]
 [7 1 0 3 9 5 6 2 8 8]
 [0 3 5 6 4 1 7 7 2 9]]
tt_50sample [[5 6 8 4 1 0 9 7 2 3]
 [7 4 2 5 9 1 3 6 0 8]
 [3 7 6 9 2 1 0 5 8 4]
 [1 3 9 0 2 6 4 7 8 5]
 [2 9 1 7 3 5 0 8 6 4]
 [2 9 1 8 0 5 7 6 3 4]
 [1 3 6 0 2 5 4 9 7 8]
 [1 8 9 2 0 4 5 3 6 7]
 [7 1 0 3 9 5 6 4 2 8]
 [0 3 5 6 4 1 7 2 8 9]]
vm  [-0.5 -0.3  3.  -2.1 -1.8 -0.  -0.4 -0.1 -0.5 -0.2  6.3 -0.7  0.3 -0.5 10.1  0.5 -0.2 -0.2  0.6  3.8 -0.7 -0.4  2.3 -0.  -1.4  3.2 -0.6 -0.5 -1.7 -1.1  1.3 -0.1 -0.7  4.5  2.7 -0.1  2.4  3.8 -0.6 -0.8 -0.   3.2 -0.2  3.  -1.1 -0.3 -2.9 -1.3 -0.   4.8 -0.8 -0.7 -0.6 10.7  0.5 -1.2 -1.2  0.2  2.6 -0.2  7.2  0.3 -0.2  4.3 -0.2  0.1 -0.1 -0.2 -0.2 -0.4 -0.3  4.2 -0.  -0.  -4.4  0.4 -0.1 -0.2  2.1  0.2 -2.2 -0.1  1.   0.1 -0.1  3.6 -0.2 -0.2 -0.5 -0.3 -0.2 -0.7 -1.  -0.5 -0.6 -0.1  0.5 -2.2 -0.6 -0.4 -0.1  6.7  1.  -0.3  0.6  0.1 -2.7  2.3  2.5  2.7 -0.8  0.3 -0.3 -0.2  4.2 -1.7 -0.5 -0.2 -0.4 -0.3 -0.1 -1.  -0.2  0.2 -0.1 10.4 -0.8 -2.8  1.6  1.1 -0.7 -0.4 -0.6 -0.4 -2.6 -0.9 -0.1 -0.4 -0.1 -0.5 -0.4 -0.9 -0.9 -0.1  0.1 -0.7 -0.2 -0.4 -0.7 -0.3  3.1 -0.3 -0.2 -0.4 -0.2 -0.1 -0.1 -0.2  3.2 -0.4  2.  -0.9 -0.1 -0.2 -0.2 -0.8 -0.7  0.6 -0.1 -0.5  0.5 -0.3  0.1 -0.1 -0.3  2.6 -0.3 -0.9  3.3 -0.6 -0.6 -0.4 -0.3 -1.5  1.  -0.7 -1.2 -0.7 -0.1  3.8 -0.2 -0.8  1.7 -0.9 -1.6 -0.5 -1.6 -0.2 -0.1  1.7  0.4 -0.4 -0.3 -0.7  0.5 -3.5 -0.1 -0.2  0.7 -0.1 -0.3 -1.6 -0.7  3.8 -0.4 -0.5 -0.5 -0.7 -0.3 -0.1 -0.4 -0.2 -0.4 -1.   1.7 -0.7  1.6  3.5  1.4 -0.1 -0.5 -0.1 -0.3  0.8  4.5 -0.3  3.1 -1.8  0.7 -2.1 -0.4 -0.9 -0.6 -0.1  8.7  5.2 -0.1  1.1 -0.6 -0.3  5.2 -0.1 -0.5 -0.  -0.9 -0.1]
vy_50sample [[0 2 7 1 4 5 8 6 3 9]
 [0 8 9 6 4 1 7 2 3 5]
 [6 2 3 1 5 4 9 0 7 7]
 [6 0 2 7 7 8 8 9 4 3]
 [1 4 6 9 3 0 2 8 5 7]
 [3 5 1 2 7 8 4 9 6 0]
 [7 6 8 1 0 0 4 3 2 5]
 [0 4 1 8 3 7 2 5 6 6]
 [6 2 1 3 4 5 7 0 8 9]
 [9 7 7 2 1 3 6 6 0 4]]
vt_50sample [[0 2 7 1 4 5 8 6 3 9]
 [0 8 9 6 4 1 7 2 3 5]
 [6 2 3 1 5 4 9 0 7 8]
 [6 0 2 5 7 8 1 9 4 3]
 [1 4 6 9 3 0 2 8 7 5]
 [3 5 1 2 7 8 4 9 6 0]
 [7 6 8 1 0 9 4 3 2 5]
 [0 4 1 8 3 7 2 5 6 9]
 [6 2 1 3 4 5 0 7 8 9]
 [5 9 7 1 2 3 8 6 0 4]]
Epoch 14210: Training cost= 0.3362, Training acc= 0.7945, Validation cost= 0.3628, Validation acc= 0.7948
Epoch 14220: Training cost= 0.3094, Training acc= 0.7946, Validation cost= 0.4123, Validation acc= 0.7948
Epoch 14230: Training cost= 0.2853, Training acc= 0.7946, Validation cost= 0.2941, Validation acc= 0.7949
Epoch 14240: Training cost= 0.3493, Training acc= 0.7946, Validation cost= 0.3227, Validation acc= 0.7949
Epoch 14250: Training cost= 0.3325, Training acc= 0.7947, Validation cost= 0.3237, Validation acc= 0.7950
Epoch 14260: Training cost= 0.3544, Training acc= 0.7947, Validation cost= 0.3325, Validation acc= 0.7950
Epoch 14270: Training cost= 0.4562, Training acc= 0.7948, Validation cost= 0.3264, Validation acc= 0.7951
Epoch 14280: Training cost= 0.3637, Training acc= 0.7948, Validation cost= 0.3693, Validation acc= 0.7951
Epoch 14290: Training cost= 0.3657, Training acc= 0.7949, Validation cost= 0.3262, Validation acc= 0.7951
Epoch 14300: Training cost= 0.4671, Training acc= 0.7949, Validation cost= 0.4455, Validation acc= 0.7952
tm  [-0.5  0.6  0.8  6.6 -1.  -0.4 -0.4 -0.3  0.2 -0.7  5.3 -0.1 -0.2 -0.1 -1.   5.6 -0.3 -0.6 -0.4 -0.7 -0.6  0.6 -0.9 -0.7 -1.3  0.7 -0.2 -0.   3.4 -0.8  0.4 -0.8  2.3 -0.2 -0.7 -0.6  1.2  0.4 -1.6 -0.3 -0.  -1.  -0.3 -1.6 -0.4 -0.1  2.6 -0.8 -0.2 -1.9 -0.5 -0.3  0.4  2.5 -1.7  3.1  0.2  3.3  0.6  2.2 -0.2 -0.6 -0.   0.4  1.3 -0.7 -0.2  1.8 -0.2 -0.4 -0.1 -1.2 -0.4 -0.2 -2.2  0.1 -0.9 -0.5 -0.7 -0.3  5.6 -0.2 -0.2 -0.2 -0.6 -0.7 -0.5 -0.2  0.7 -0.2 -0.6  0.3  0.6 -0.1 -0.3 -0.4  0.2 -1.  -0.2 -0.2  2.8 -1.8 -0.6 -0.2 -0.4 -0.3 -1.4 -0.   1.6 -0.6  0.2 -0.5 -0.5 -0.6 -0.3  7.2  0.3 -0.4 -0.2  2.3 -0.3  1.2 -0.  -0.  -0.4 -1.   2.2 -0.   1.   4.1  2.6 -0.8 -0.  -0.2 11.7 12.8 -0.1 -0.2  0.1 -0.8 -0.5  0.  -0.3 -0.2 -0.7  0.3 -0.1 -0.4  3.6 -0.1 -0.6 -0.2  1.1 -0.3 -0.4 -0.2 -0.2  0.9 -1.7 -0.5 -0.6  2.1 -0.  -0.3 -0.2 -0.5  2.4  1.  -0.6  1.9 -0.8 -0.5 -0.6 -0.2 -0.2 -1.  -1.9 -0.5  5.9 -0.1 -0.8 -0.2 -0.3 -1.3 -0.6 -0.2  2.2 -0.3 -0.5  3.7 -0.3  0.  -1.  -1.   2.7 -0.2 -0.7 -0.  -0.1 -0.6 -0.3 -0.3 -0.6 -0.5 -0.8 -1.1  0.5 -0.3 -1.1 -0.3 -0.2  5.8 -1.   1.1 -0.7  0.2  6.2 -0.6 -0.1 -0.1 -0.5 -0.7  1.3 -0.7  1.2  2.7 -0.3  2.1  0.5  4.2  1.2  0.7 -0.3 -0.7 -1.1  1.  -0.1 -0.9 -0.2  0.5 -0.1  0.2 -0.1 -0.2 -0.7 -1.1 -0.1 -0.3 -0.9 -0.5 -1.6 -0.7 -1.2 -0.2  1.7 -0.6]
ty_50sample [[6 3 2 5 9 1 8 4 7 0]
 [4 3 5 8 0 9 9 1 2 7]
 [4 0 9 7 1 2 5 8 6 3]
 [9 1 0 8 5 7 3 6 2 4]
 [1 6 7 9 3 0 8 8 4 2]
 [0 4 8 5 7 9 2 1 3 6]
 [0 2 7 4 9 9 6 6 3 8]
 [9 1 7 4 2 2 3 6 5 0]
 [9 8 3 6 5 4 0 1 7 2]
 [4 2 3 9 7 8 8 1 5 0]]
tt_50sample [[6 3 2 5 9 1 8 4 7 0]
 [4 3 5 0 8 6 9 1 2 7]
 [4 0 9 1 7 2 5 8 6 3]
 [9 1 0 8 5 7 3 6 2 4]
 [1 6 7 0 3 9 8 5 4 2]
 [0 4 8 5 7 9 2 1 3 6]
 [0 2 5 4 7 9 6 1 3 8]
 [9 1 7 4 8 2 3 6 0 5]
 [9 8 3 6 5 4 0 1 7 2]
 [4 2 3 9 7 8 1 6 5 0]]
vm  [ 1.  -0.1 -0.5 -0.5 -1.4 -0.4 -0.1 -0.5 -0.7 -0.6  3.5  0.4 -0.8 -0.6  1.6  0.   0.6 -0.7 -0.6 -1.  -0.5  0.7 -0.3  1.1 -1.5  0.3  0.6  0.  -0.3  2.4  5.6 -0.3  2.3  7.3 -0.6  1.1  2.7 -0.5 -0.1 -0.3  0.9  4.5  3.4  1.4 -0.2 -0.2  4.6  1.1  1.8 -0.8 -0.8 -0.5  0.4 -1.1 -1.   0.1 -0.4  1.9 -1.2 -1.8 -1.3 -0.4  0.2 -0.1  2.3 -0.4 -0.1 -0.2  1.  -0.1 -0.4 -0.6 -0.4 -0.7 -1.2 -0.1 -0.4 -0.3 -0.2 -0.4 11.2  0.2 -0.3  1.4 -0.9  5.2  4.  -0.2  0.7  0.2 -0.5  1.  -0.2  1.9 -0.4 -0.3  1.  -0.4 -0.  -0.1  2.1  2.9 -1.1 -0.1 -0.5 -0.4 -1.3  5.8  1.8 -0.9 -0.1 -0.3 -0.3 -0.4 -0.2  1.1 -0.3 -0.6 -0.2 -0.  -0.3  2.4 -0.  -0.1 -0.6  2.   2.1  6.8  0.1 -0.5  3.2 -0.5 -0.2 -0.2  2.6 11.2  0.2 -0.5 -0.3 -1.1  0.8 -0.2  1.5 -0.  -0.3 -0.4 -0.1 -0.9  3.3  0.3 -0.3 -0.3  1.3  0.1 -0.5 -0.1 -0.6 -0.2 -1.2 -0.5 -0.2  0.4 -0.2 -0.4 -0.  -0.1 -0.6 -0.6 -0.  -0.  -0.2  1.2 -0.4 -0.3  0.2 -0.6 -1.3 -0.3  2.1  0.3 -1.6 -0.5 -0.1 -1.2 -0.9 -0.6  4.7 -0.5 -0.4 -0.7 -0.4 -0.3 -0.8 -1.3  7.7  1.5 -0.1  0.4 -0.1 -0.3 -0.3 -0.4 -0.3 -0.4 -1.  -0.3  0.  -0.4 -3.6 -0.1 -0.6  1.6  0.1 -0.3 -0.2 -0.3 -0.2 -0.5  0.1 -0.5 -0.8 -0.1 -0.  -0.5  1.5 -0.  -0.9 -0.8 -0.1  2.8 -0.2  0.  -0.4 -2.5 -0.6  2.7 -0.1 -0.4  0.6 -0.9 -0.2 -0.6 -0.3 -0.3 -2.2 -1.4 -0.2 -0.8 -0.1  0.4 -2.6 -0.3 -0.  -0.1  3.3  4.5]
vy_50sample [[5 4 6 7 9 0 3 2 1 8]
 [3 8 6 5 7 1 4 9 2 0]
 [9 6 7 8 3 1 2 5 0 4]
 [1 4 0 7 5 6 2 2 8 9]
 [2 0 7 4 1 5 9 8 6 3]
 [0 6 9 7 4 2 8 5 3 1]
 [6 8 1 2 0 3 7 5 5 9]
 [3 2 8 7 0 9 5 6 1 4]
 [5 9 9 4 7 0 2 8 1 3]
 [5 8 9 9 0 6 2 3 7 1]]
vt_50sample [[5 4 6 7 9 3 0 2 1 8]
 [3 8 5 6 7 1 4 9 2 0]
 [9 6 7 8 3 1 2 5 0 4]
 [1 0 4 7 5 6 3 2 8 9]
 [2 0 1 4 7 5 9 8 6 3]
 [0 6 9 7 4 8 2 5 3 1]
 [6 8 1 2 0 3 7 5 4 9]
 [3 2 8 7 0 9 5 6 1 4]
 [6 5 9 4 7 0 2 8 1 3]
 [5 8 4 9 0 6 2 3 7 1]]
Epoch 14310: Training cost= 0.3381, Training acc= 0.7949, Validation cost= 0.3960, Validation acc= 0.7952
Epoch 14320: Training cost= 0.3085, Training acc= 0.7950, Validation cost= 0.3265, Validation acc= 0.7953
Epoch 14330: Training cost= 0.3121, Training acc= 0.7950, Validation cost= 0.3163, Validation acc= 0.7953
Epoch 14340: Training cost= 0.3085, Training acc= 0.7951, Validation cost= 0.3213, Validation acc= 0.7953
Epoch 14350: Training cost= 0.3064, Training acc= 0.7951, Validation cost= 0.3203, Validation acc= 0.7954
Epoch 14360: Training cost= 0.2848, Training acc= 0.7952, Validation cost= 0.3505, Validation acc= 0.7955
Epoch 14370: Training cost= 0.3872, Training acc= 0.7952, Validation cost= 0.2775, Validation acc= 0.7955
Epoch 14380: Training cost= 0.3449, Training acc= 0.7953, Validation cost= 0.3047, Validation acc= 0.7956
Epoch 14390: Training cost= 0.3415, Training acc= 0.7953, Validation cost= 0.3481, Validation acc= 0.7956
Epoch 14400: Training cost= 0.3510, Training acc= 0.7954, Validation cost= 0.3570, Validation acc= 0.7957
tm  [ 1.8 -0.7 -0.7  0.5 -0.8 -0.7 -0.2 -0.5 -0.8  3.  -2.  -0.7 -0.5 -0.4 -0.7 -1.3 -0.5 -0.5 -0.3 -1.8 -0.4 -0.2  2.5 -0.3 -0.8  0.1 -0.3 -0.3 -1.1  0.1  1.5  0.4  1.1 -1.1  2.1 -0.6  2.8 -1.3 -1.  -0.8 -0.2  0.6 -0.9 -0.3 -0.1 -0.3  7.5  0.2  3.5  8.5 -0.5 -0.2 -0.9 -1.3  0.8  2.3 -0.4 -1.8  1.9 -0.1 -2.  -0.2 -0.9  0.4 -0.5 -0.3 -0.4 -0.1  1.3 -0.1 -0.   2.5 -0.3 -0.4 -1.1 -0.  -0.7  0.5  0.4 -0.2  0.6 -0.5 -1.  -0.3 -1.4 -0.2  3.8 -0.1 -0.3 -0.1 -1.2 -0.5 -0.8 -0.5 -0.3 -0.1 -0.7 -0.5 -0.3 -0.7 -1.3  4.6 -1.  -0.1 -0.2 -0.2 -0.7  0.7 -0.9 -2.3 -0.3 -0.2 -0.1 -0.1  3.3 -1.6 -0.1  0.8 -0.1  0.3 -0.2  7.8 -0.3 -1.1 -0.3 -0.8 -1.1  7.8 -0.3 -1.7  4.4 -0.5 -0.3 -0.2  7.6  7.  -0.4 -0.5 -1.2 -0.4 -0.1 -0.9  1.8  0.5 -0.2 -0.2 -0.2 -0.9 -1.2 -0.2 -0.2  0.3  3.8 -0.7 -0.3 -0.2 -0.  -0.1 -2.2 -0.7 -0.2  1.9 -0.4 -0.3 -0.7  0.6 -1.2  1.1 -0.6 -0.1  1.2 -1.  -0.3 -0.4 -0.1  3.8 -1.3  0.4  3.9 -0.3  0.4 -0.1  1.1 -0.3 -0.4 -0.2  6.1 -0.4  0.1 -0.4 -0.4 -0.3 -0.9 -0.8  9.9  0.5 -0.2 -0.4 -0.2 -0.3 -0.3  0.3  0.6  0.2 -1.3 -0.4 -0.3 -0.4  7.   0.2  0.  -1.1 -0.9 -0.9  1.8  0.9  1.9 -0.1 -0.4 -0.6 -0.7 -0.4 -0.1 -1.1  4.9 -0.3 -1.  -0.5 -0.1  3.9  0.3 -0.  -0.2  4.5  0.7  2.2  2.8 -0.2  0.8 15.2 -0.2  7.8 -0.2  0.7  1.1 -1.2  1.1 -0.8 -0.8  1.2 -0.3 -0.2 -0.9 -0.1 -0.1  9. ]
ty_50sample [[6 0 4 8 9 7 2 2 5 1]
 [4 3 1 2 5 0 8 7 9 6]
 [1 6 7 5 3 0 0 8 4 4]
 [9 2 2 5 0 3 1 4 8 8]
 [5 8 6 9 9 1 0 2 4 7]
 [8 7 6 5 0 0 4 3 1 2]
 [0 6 7 3 1 9 2 5 8 4]
 [8 8 9 9 2 1 4 3 5 7]
 [2 6 0 9 4 5 7 1 8 3]
 [8 2 4 0 9 5 3 1 1 6]]
tt_50sample [[6 0 4 8 9 7 2 3 1 5]
 [4 3 1 2 5 0 8 7 9 6]
 [1 6 7 5 3 0 8 2 9 4]
 [9 2 7 5 0 3 1 4 8 6]
 [5 8 3 6 9 1 0 2 4 7]
 [8 7 6 5 9 0 4 3 1 2]
 [0 6 7 3 1 9 2 5 8 4]
 [8 6 0 9 2 1 4 3 5 7]
 [2 6 0 9 4 5 7 1 8 3]
 [8 2 4 9 0 5 3 1 7 6]]
vm  [ 2.1 -0.2  7.9  1.9 -1.3 -0.7 -0.4 -0.3 -0.2  1.   2.9 -0.6 -0.6 -0.3 10.1  1.6 -0.1 -0.5 -0.4  2.1 -0.3  0.6  1.5 -0.1 -0.9 -0.  -0.3 -0.2 -0.3 -0.2 -0.5 -0.6  1.1  6.9 -0.  -0.5  0.1 -0.4 -3.1 -0.7 -0.3  3.4  0.9 -1.5  0.1  0.1 -2.1 -0.2  5.1  2.9 -0.4 -0.5 -0.1  4.7 -0.7 -1.3 -0.2  4.4  1.6  3.5 -0.6 -0.6  1.2  3.3  0.2 -0.3  0.2 -0.6 -0.1 -0.  -0.1 -0.1 -0.2  0.5 -5.  -0.  -1.4  0.8 -0.6 -0.4 -1.  -0.2  1.2 -0.5 -1.7  3.8  1.4 -0.4  0.2 -0.1 -0.7 -0.4 -0.1 -0.4 -0.5 -0.   0.5 -2.   0.4  0.6 -0.4  5.6 -1.1 -0.  -0.8  1.1 -1.7 -0.4  1.1 -0.2  0.1 -0.3 -0.2 -0.7  0.6  1.1 -0.3  2.2  0.4 -0.3  0.1 -0.5 -0.5 -0.4 -0.4 10.8 -0.3 -0.9  1.9  0.7  4.  -0.8 -0.  -0.2  2.1 11.2 -0.2 -0.3 -0.6 -0.4 -0.2 -0.3  0.  -0.3 -0.3 -0.1 -0.1 -0.9 -0.5  1.   0.7 -0.2  4.4 -0.4 -0.3 -0.2 -0.5 -0.2 -1.4 -0.4  0.1  3.6  0.3 -0.3  0.1 -0.3 -0.3 -0.5  0.4  0.4  0.  -0.3 -0.8 -0.5  0.   2.1 -1.3 -0.6  9.4 -0.3 -1.4 -0.2 -0.6 -0.6 -0.5 -0.5  3.4 -0.6 -0.4  0.8 -0.2 -0.3 -0.2 -0.4  4.  -0.8 -0.8 -0.6 -0.1 -0.3 -0.1 -0.1  1.2 -0.  -0.9 -1.8  0.1 -0.2 -0.5 -0.1 -0.5  0.  -0.4 -1.1 -0.7 -0.   6.1 -0.1 -0.2 -0.8 -0.9 -0.2 -0.  -0.6  3.3 -0.1 -0.4 -0.2  0.3  5.8  2.2 -0.1 -0.4 -0.5 -0.5 -2.   0.1 -1.6  0.7 -1.6 -0.2 -0.8 -0.  -0.4  4.4  2.2 -0.7 -0.  -0.4  0.5  1.6 -0.3 -2.4  1.1  0.3  0.4]
vy_50sample [[6 7 5 2 0 8 3 9 4 1]
 [9 4 2 2 8 3 7 6 1 5]
 [4 3 7 7 1 9 2 0 6 8]
 [9 5 8 1 6 7 4 2 3 0]
 [7 9 2 1 6 6 4 3 5 8]
 [3 7 0 6 9 4 1 8 5 2]
 [8 1 3 0 4 6 5 9 7 2]
 [5 4 1 8 6 3 0 7 2 9]
 [2 4 0 9 6 8 8 3 7 5]
 [7 5 0 6 9 2 8 3 1 4]]
vt_50sample [[6 7 5 2 0 8 3 4 9 1]
 [4 9 0 2 3 8 7 6 1 5]
 [3 4 7 5 1 9 2 0 6 8]
 [9 5 8 1 6 7 4 2 3 0]
 [7 9 2 1 0 6 4 3 5 8]
 [3 7 0 6 9 4 1 8 5 2]
 [8 1 3 0 4 6 5 9 7 2]
 [5 4 1 8 6 3 0 7 2 9]
 [2 4 0 1 9 6 8 3 5 7]
 [7 5 0 6 9 2 8 3 1 4]]
Epoch 14410: Training cost= 0.3423, Training acc= 0.7954, Validation cost= 0.3131, Validation acc= 0.7957
Epoch 14420: Training cost= 0.3735, Training acc= 0.7955, Validation cost= 0.3084, Validation acc= 0.7958
Epoch 14430: Training cost= 0.3239, Training acc= 0.7955, Validation cost= 0.3367, Validation acc= 0.7958
Epoch 14440: Training cost= 0.3261, Training acc= 0.7956, Validation cost= 0.2955, Validation acc= 0.7959
Epoch 14450: Training cost= 0.3151, Training acc= 0.7956, Validation cost= 0.3793, Validation acc= 0.7959
Epoch 14460: Training cost= 0.2986, Training acc= 0.7957, Validation cost= 0.3039, Validation acc= 0.7960
Epoch 14470: Training cost= 0.3250, Training acc= 0.7957, Validation cost= 0.3735, Validation acc= 0.7960
Epoch 14480: Training cost= 0.3148, Training acc= 0.7958, Validation cost= 0.3485, Validation acc= 0.7961
Epoch 14490: Training cost= 0.2993, Training acc= 0.7958, Validation cost= 0.3689, Validation acc= 0.7961
Epoch 14500: Training cost= 0.3380, Training acc= 0.7959, Validation cost= 0.3410, Validation acc= 0.7962
tm  [-0.7  4.2  7.7 12.8 -1.6 -0.1  0.1 -0.2 -1.5 -1.  -1.3  0.1  0.2 -0.2  1.   3.8  2.1 -0.2  0.4 -1.1 -0.5 -0.4  2.8 -0.1 -1.2 -0.2 -0.2 -0.  -0.4 -0.  -2.5 -0.3 -0.4 -1.4 -1.   1.6  4.   3.1  6.5 -0.1 -0.2  2.2  4.  -0.2 -0.1  0.9  2.9 -0.1  0.5  5.3 -0.3 -0.3 -0.3  0.9 -0.7  0.  -0.4  7.9 -1.7  8.2 -0.2 -0.3 -0.3 -0.3 -1.  -0.2 -0.3 -1.  -0.4  0.3 -0.1 -0.2 -0.1 -0.2 -0.2 -0.2 -0.2 -0.4 -0.5 -0.1 -1.3 -0.5 -0.9 -0.4 -0.7  2.8 -0.2  0.4  1.8 -0.2  0.6  2.2  0.3  5.6  0.1 -0.3  2.1 -0.5 -0.1 -0.2  4.4  2.1  0.4 -0.4 -0.  -0.1 -0.4 -2.4 -0.5 -2.  -0.3 -0.3 -0.4 -0.2 -1.3  4.3  0.4 -1.  -0.1 -0.6  0.1  6.4 -0.3 -0.4 -0.3  2.   2.2  0.4 -0.3  1.6 -0.8 -0.  -0.1 -0.  -2.3 -4.1 -0.2 -0.   0.   2.  -0.4 -0.7 -0.3 -0.3 -0.3 -0.2 -0.2 -0.3  2.7  0.4 -1.2 -0.2  3.6 -0.6 -0.2 -0.3 -0.   0.1  3.  -0.8 -0.5 -0.3 -0.6 -0.1 -0.7  0.5  0.3 -1.  -0.   1.6 -0.1  0.2 -0.4 -0.4 -0.2 -0.3  0.8 -0.2 -0.8 -0.7 -1.8 -0.1 -0.3 -0.8 -0.2  0.2  1.3 -0.6 -0.4  0.9 -0.  -0.  -0.3 -0.2  2.9  1.4  1.1  3.4 -0.3 -0.4 -0.3 -0.6  0.  -0.4 -0.  -0.3 -0.6 -0.1  3.2 -0.2 -0.6  0.9  0.8 -0.1 -0.1 -0.2  1.9 -0.4  0.5 -0.8 -0.2  1.  -0.6 -0.4 -0.6  2.7  1.3  0.2 -0.3 -0.1 -0.7 -0.4 -0.1  2.8 -0.1 -1.8 -0.7  0.9 -0.3 -0.2 -0.2 -0.4 -0.2 -0.1  5.6 -0.7 -0.5  0.7 -0.2 -0.4  2.  -0.7  5.3  0.   1.3  1.2]
ty_50sample [[8 5 5 2 3 9 1 0 6 4]
 [0 2 5 4 7 3 1 9 6 8]
 [2 1 0 0 8 5 4 6 6 3]
 [1 7 4 0 0 3 6 5 9 8]
 [4 9 3 7 0 6 1 8 5 2]
 [9 1 0 3 7 4 5 8 6 2]
 [6 8 9 2 3 0 4 1 5 7]
 [2 1 1 8 0 9 3 4 6 5]
 [9 4 6 0 7 5 2 8 1 3]
 [0 3 6 9 1 7 8 4 2 5]]
tt_50sample [[8 5 2 7 3 9 1 0 6 4]
 [0 2 5 4 3 7 1 9 6 8]
 [2 1 7 8 0 5 4 6 3 9]
 [1 7 4 2 0 3 6 5 9 8]
 [4 9 3 7 0 6 1 8 5 2]
 [9 1 0 7 3 4 5 8 6 2]
 [6 8 9 2 3 0 4 1 5 7]
 [2 7 1 8 0 9 3 4 6 5]
 [9 4 0 6 7 5 2 8 1 3]
 [0 3 6 9 1 7 4 8 2 5]]
vm  [-0.6 -0.1  8.4  0.6 -1.7 -0.1 -0.1 -0.3 -0.1 -0.4  5.3 -0.6  1.  -0.4 11.6  7.7 -0.1 -0.4 -0.3  0.9 -0.4 -0.  -0.1 -0.6 -0.9 -0.8 -0.5  0.5  2.1 -0.9 -1.4 -0.5 -0.4  4.4 -0.3 -0.6  0.1  5.1 -0.3 -0.7  0.2 -0.6 -0.6 -0.  -0.4 -0.1 -1.6 -1.2 -0.2 -0.1 -0.6 -0.3 -0.9 11.7 -1.4 -1.5 -0.6  4.3  2.6  4.5  3.4 -0.5 -0.7  0.4 -0.3 -0.3 -0.3  0.2 -0.3 -0.7 -0.1 -1.6 -0.6 -0.4 -5.1  0.6 -1.  -0.1 -0.8  0.2 -3.2 -0.  -0.5 -0.1 -0.7 -0.3 -0.4 -0.1  1.3 -0.4 -0.5  0.5  0.1  0.3 -0.6 -0.3 -0.1 -1.5 -0.3 -0.3  1.9  2.5 -0.2 -0.3 -0.3 -0.4 -3.  -1.1  2.4  1.2  1.1 -0.2 -0.4 -0.7 -0.6  7.6 -0.1  1.2 -0.2 -0.4 -0.5 -0.8 -0.3 -0.6 -0.4 13.   0.4 -3.3  2.8  6.8 -0.1 -0.6 -0.3  0.5 -3.6 -2.1 -0.4 -0.3 -0.1 -0.6 -1.5 -0.2 -0.9 -0.7 -0.6 -0.2 -0.3 -0.3 -0.6 -0.1 -0.  -0.5  2.4 -0.8 -0.3 -0.1 -0.3 -0.1  1.  -0.6 -0.8 -1.1  0.1 -0.1  0.9  0.8  0.6  0.2 -0.5 -0.1 -0.8 -0.3 -0.6 -0.2  0.1  2.5 -0.4 -1.6  2.8 -0.8 -0.9 -0.2 -0.4 -0.8 -0.2 -0.4 -0.1 -0.9 -1.   3.5 -0.3 -0.4 -0.4 -0.7 -0.5 -0.8 -1.9  0.2 -0.2 -0.6 -0.2 -0.3 -0.3 -0.2 -0.6 -3.3 -0.1 -0.5  2.8 -0.  -0.3  3.6 -0.2 -0.2 -0.3  1.1  1.5 -0.3 -0.4 -0.4 -0.5 -0.2 -0.4 -0.5 -1.   3.7  2.9  1.6  0.2  4.2 -1.1  3.5 -0.3  1.8 -1.4 -2.1 -0.3 -2.5 -0.3 -2.1 -0.3 -1.  -0.  -0.1 10.9  4.9 -0.3 -0.2 -0.4 -0.1  7.4 -0.2 -0.2 -0.3 -0.1 -1.9]
vy_50sample [[2 7 3 8 5 1 6 4 9 0]
 [3 0 1 8 7 9 6 4 5 2]
 [2 2 4 8 9 6 0 5 1 3]
 [8 6 4 7 9 3 0 2 1 5]
 [0 3 5 2 2 6 6 4 1 1]
 [3 5 1 2 4 9 7 6 0 8]
 [7 6 2 0 4 1 5 3 3 8]
 [0 8 2 2 5 7 9 1 6 4]
 [5 1 7 8 8 6 4 2 3 0]
 [1 9 3 7 6 0 4 2 8 5]]
vt_50sample [[2 7 3 8 5 1 6 4 9 0]
 [3 0 1 8 7 9 6 4 5 2]
 [7 2 4 9 8 6 5 0 1 3]
 [8 6 4 7 9 3 0 2 1 5]
 [0 3 5 9 2 7 6 4 8 1]
 [3 5 1 2 4 9 7 6 0 8]
 [7 6 2 4 0 1 5 3 9 8]
 [0 8 3 2 5 7 9 1 6 4]
 [5 1 7 9 8 6 4 3 2 0]
 [1 9 3 7 6 0 4 2 8 5]]
Epoch 14510: Training cost= 0.4058, Training acc= 0.7959, Validation cost= 0.3306, Validation acc= 0.7962
Epoch 14520: Training cost= 0.3638, Training acc= 0.7960, Validation cost= 0.3360, Validation acc= 0.7962
Epoch 14530: Training cost= 0.4010, Training acc= 0.7960, Validation cost= 0.3103, Validation acc= 0.7963
Epoch 14540: Training cost= 0.3648, Training acc= 0.7961, Validation cost= 0.3847, Validation acc= 0.7963
Epoch 14550: Training cost= 0.3200, Training acc= 0.7961, Validation cost= 0.3778, Validation acc= 0.7964
Epoch 14560: Training cost= 0.3034, Training acc= 0.7962, Validation cost= 0.4110, Validation acc= 0.7964
Epoch 14570: Training cost= 0.3121, Training acc= 0.7962, Validation cost= 0.3296, Validation acc= 0.7965
Epoch 14580: Training cost= 0.3920, Training acc= 0.7962, Validation cost= 0.3878, Validation acc= 0.7965
Epoch 14590: Training cost= 0.3710, Training acc= 0.7963, Validation cost= 0.3450, Validation acc= 0.7966
Epoch 14600: Training cost= 0.3107, Training acc= 0.7963, Validation cost= 0.3070, Validation acc= 0.7966
tm  [-0.2 -0.6 -0.2  8.  -1.1 -0.3 -0.2 -0.4  1.4 -0.1  3.2  0.6 -0.5 -0.4 -1.6 -1.2 -0.2 -0.4 -0.2 -0.2 -0.9 -0.1 -0.3 -0.3 -0.7  3.9 -0.2 -0.2 -1.5 -3.  -0.6 -0.3 -0.5 -1.7  1.2 -0.5  1.1  2.   3.5 -0.8  0.5  2.  -0.  -0.1 -0.5  0.7 -0.3 -0.4  2.1 -0.8 -0.3 -0.7  0.1  1.5  2.7  3.3 -0.4  5.8  3.7  3.4 -0.  -0.5  1.2  5.3 -0.3 -0.   0.5  0.5 -0.  -0.  -0.1  4.6 -0.4  0.1 -2.7 -0.1 -0.9 -0.2 -0.9 -0.1  2.7 -0.3  0.1 -0.3 -1.2  1.4 -0.1 -0.4 -0.2 -0.4 -0.2 -1.3 -0.4 -0.4 -0.3 -0.2  2.3 -1.6 -0.1 -0.4 -0.4 -2.  -0.4 -0.5 -0.1  1.  -1.  -0.5  1.3 -0.9 -0.4  0.4 -0.4 -0.4  6.1 -2.3 -0.3  1.8  0.6  2.  -0.1  3.2 -0.4 -0.1 -0.5 -1.6 -0.7  1.8  4.8  2.5  0.  -0.5 -0.8 -0.1  5.6 -0.3 -0.3 -0.3  0.1 -0.4 -0.1 -1.  -0.7 -0.3 -0.1 -0.3 -0.  -0.7  7.  -0.6 -0.6 -0.   1.6  0.3 -0.6 -0.4 -0.3  0.6  1.4 -0.1 -0.4 -1.2 -0.1 -0.3 -0.5 -0.6 -0.7 -0.3 -0.3  1.4 -0.3 -0.1  0.  -0.3 -0.2 -1.8 -0.3  0.4 -0.1 -0.4 -1.5  1.2 -0.5 -1.1  2.  -0.4  2.2  0.9  1.  10.3 -0.3 -0.1 -0.6 -0.7  3.1 -1.4 -0.5 -0.9 -0.1  1.3 -0.3  0.5 -0.4 -0.5 -0.3 -0.5 -0.  -0.1 -1.3  0.2 -0.5 -1.1 -0.4 -0.5 -1.  -0.2  1.8 -0.6 -0.9 -0.4 -0.1 -0.3  0.1 -0.9 -0.7 -1.2 -0.5  2.   0.3  3.7 -0.5 -0.6 -0.3 -1.1  4.6  1.3  2.  -0.5  1.3 -0.6 -0.3 -0.3 -0.1 -0.1 -0.1 -0.8 -0.3  0.2 -1.1 -0.3 -1.  -0.8  3.2  1.2  1.3 -0.1]
ty_50sample [[0 5 3 9 2 8 1 6 4 7]
 [1 2 7 3 4 5 6 9 8 0]
 [3 7 0 4 5 9 2 8 1 6]
 [2 6 5 3 9 1 9 4 7 8]
 [0 8 2 9 1 4 7 5 3 6]
 [8 0 5 9 3 4 1 7 6 2]
 [1 0 9 5 3 3 8 8 4 2]
 [7 5 6 4 1 0 2 3 9 8]
 [5 4 0 7 9 1 8 2 3 6]
 [0 5 6 3 8 1 4 9 7 2]]
tt_50sample [[0 5 3 9 2 8 1 6 4 7]
 [1 2 7 3 4 5 6 9 8 0]
 [3 7 0 4 5 9 2 1 8 6]
 [2 6 5 3 9 1 0 4 7 8]
 [0 8 2 9 1 4 7 5 3 6]
 [8 0 5 9 3 4 1 7 6 2]
 [1 0 9 5 7 3 8 6 4 2]
 [7 5 6 4 1 0 2 3 9 8]
 [5 4 0 7 9 1 8 2 3 6]
 [0 5 6 3 8 1 4 9 7 2]]
vm  [-1.3 -0.7 -1.7  1.4 -0.6 -0.2 -0.2 -0.6 -0.6  2.  -3.7 -0.2 -0.9 -0.2 -1.5 -1.   0.  -0.  -0.6 -1.1 -0.8 -0.6  4.3 -0.1 -0.8  0.6 -0.1 -0.5 -0.7 -1.1 -1.3 -0.4 -0.4 -5.5  0.4 -0.2  1.2  1.5  5.4  0.5  0.   5.  -0.   2.3 -0.7 -0.8  2.4 -0.4 -1.1 12.1 -0.4 -0.5 -1.6 -0.1 -0.1  3.5 -0.7  1.   1.6  4.   5.6 -0.5 -1.1 -0.1 -1.1 -0.6 -0.3  1.7  0.7 -0.7 -0.4  1.7 -0.3 -0.2 -3.  -0.   2.  -0.1  1.  -0.5 -3.2  0.5 -0.7 -0.   0.5  5.3 -0.4 -0.3 -0.2 -0.4  0.4 -0.5 -1.1 -0.2 -1.  -0.2 -0.1 -1.2 -0.2 -1.  -0.7  0.7  2.  -0.5 -0.5 -0.5 -1.9 -1.4 -1.6 -0.9  0.2 -0.6 -0.1 -0.7  4.2 -1.2 -0.3 -0.4 -0.   1.2 -0.2  3.1  1.2 -0.6 -0.2 -1.5 -0.3  4.4  1.5 -0.7 -0.9  0.5 -0.7  0.1  4.9 -5.5 -0.4 -0.  -0.4  0.4  1.1 -1.  -0.1 -0.2 -0.1 -0.3 -0.  -0.1  5.6 -0.4 -0.2 -0.2  1.3  0.2 -0.1 -0.  -0.  -0.5  1.6 -0.2  0.5 -1.4 -0.1 -0.2 -1.3 -0.5 -1.1  0.5 -0.5  0.2  0.4 -0.1 -0.2 -0.1 -0.3 -1.4 -0.2 -0.5 -0.6  0.4 -0.9 -0.1  0.4 -1.1  0.2  1.5 -0.7  0.1 -0.5  4.6 -0.4 -0.6 -0.7 -0.9 -1.1 -0.2 -1.1 -0.3 -0.1 -0.1 -0.1 -0.1 -0.5 -0.4 -0.  -1.3 -0.3 -0.2  4.6 -0.4 -0.2 -0.7 -0.3  4.6 -0.1 -0.1 -0.6 -0.7 -0.6 -0.3 -0.6 -0.6 -0.6 -1.2  1.8 -0.3 -1.5  1.1 -0.3 -0.7 -1.1  1.1 -0.3  2.8  1.2  4.8  3.  -1.6 -0.  -0.5 -0.4 -0.2 -0.5 -0.1 10.3 -0.8  1.  -0.8 -0.6  0.2  7.1  0.5  4.3 -0.2  1.   6.1]
vy_50sample [[8 1 0 5 4 9 2 6 3 7]
 [0 6 4 1 9 5 3 8 2 7]
 [3 2 0 5 4 9 6 1 7 7]
 [9 3 6 0 4 8 2 5 7 1]
 [4 9 8 8 0 6 1 2 7 5]
 [5 0 9 9 8 6 2 7 4 1]
 [2 8 0 6 9 7 1 5 3 4]
 [3 8 8 7 6 5 1 0 2 9]
 [1 7 5 8 3 9 2 6 4 0]
 [9 4 0 7 3 5 6 1 2 8]]
vt_50sample [[8 1 0 5 4 9 2 6 3 7]
 [0 6 4 1 9 5 3 8 2 7]
 [3 2 0 5 4 9 6 1 7 8]
 [9 3 6 0 4 8 2 5 7 1]
 [4 9 8 3 0 6 1 2 7 5]
 [5 0 9 3 8 6 2 7 4 1]
 [2 8 0 6 9 7 1 5 3 4]
 [3 8 7 4 6 5 1 0 2 9]
 [1 7 5 8 3 9 2 6 4 0]
 [9 4 0 7 3 5 6 1 2 8]]
Epoch 14610: Training cost= 0.3279, Training acc= 0.7964, Validation cost= 0.3260, Validation acc= 0.7966
Epoch 14620: Training cost= 0.2911, Training acc= 0.7964, Validation cost= 0.3014, Validation acc= 0.7967
Epoch 14630: Training cost= 0.3201, Training acc= 0.7965, Validation cost= 0.3160, Validation acc= 0.7968
Epoch 14640: Training cost= 0.2803, Training acc= 0.7965, Validation cost= 0.3872, Validation acc= 0.7968
Epoch 14650: Training cost= 0.3617, Training acc= 0.7966, Validation cost= 0.3279, Validation acc= 0.7968
Epoch 14660: Training cost= 0.3617, Training acc= 0.7966, Validation cost= 0.4494, Validation acc= 0.7969
Epoch 14670: Training cost= 0.4075, Training acc= 0.7966, Validation cost= 0.4100, Validation acc= 0.7969
Epoch 14680: Training cost= 0.4054, Training acc= 0.7967, Validation cost= 0.3965, Validation acc= 0.7969
Epoch 14690: Training cost= 0.3495, Training acc= 0.7967, Validation cost= 0.3015, Validation acc= 0.7970
Epoch 14700: Training cost= 0.3087, Training acc= 0.7967, Validation cost= 0.3247, Validation acc= 0.7970
tm  [ 1.7  3.  -0.1  3.1 -0.9 -0.5 -0.  -0.3 -1.4 -0.9 -0.5  0.1 -0.7 -0.2 -0.7  3.9  1.3 -0.5  0.3 -1.2 -0.3  0.   1.7  0.4 -1.8 -0.1  0.2 -0.2  1.9  5.4  1.9 -0.4  0.   0.7 -1.3  1.1  3.6 -0.5 -0.5 -0.6 -0.3  3.9  4.5 -0.6 -0.3 -0.   4.   0.4  2.3  3.5 -0.7  0.1  2.7 -1.1 -1.4  1.6 -0.3  2.3 -1.8 -0.1 -1.6 -0.4 -0.1 -0.7 -0.2 -0.2 -0.1 -0.3 -0.1 -0.1  0.1 -1.1 -0.1 -0.3  0.3 -0.1 -0.5 -0.3 -0.1 -0.   5.9 -0.4 -0.2 -0.3 -0.8  5.7  3.3  0.7  1.5 -0.4 -0.3  2.1  0.2  2.6 -0.  -0.4 -0.  -0.2 -0.4  0.5  3.7  3.3 -0.8 -0.2 -0.2  0.5  0.6  2.1 -0.2 -1.6 -0.6 -0.6 -0.2  0.6 -1.8  8.  -0.1 -1.4 -0.4 -0.1 -0.2  4.8 -0.6 -0.3 -0.1 -0.7  3.3  6.3 -0.5 -1.   2.9 -0.5  1.7 -0.3  6.4  8.8 -0.  -0.2 -0.7 -0.9  0.8 -0.4  2.  -0.1 -0.3 -0.1  0.3 -0.6  3.   0.7 -0.3 -0.1  3.8 -0.2 -0.4 -0.4 -0.5  0.2 -1.4 -0.5 -0.3  3.3 -0.2 -0.2 -0.4 -0.3  0.8 -0.8  0.3  0.4  0.2  0.1 -0.6 -0.3 -0.1 -0.6 -1.3  1.4  2.6 -0.6 -1.8  0.7 -0.3 -1.  -1.3 -0.1  4.6 -0.3 -0.4 -1.5  0.3 -0.4 -0.5 -1.2  8.5  2.7  2.9  3.1 -0.  -0.5 -0.  -0.5 -0.2 -0.5 -0.8  2.8 -0.1 -0.5 -1.6 -0.2 -0.4  3.4 -0.5 -0.3  0.3 -0.4  2.3 -0.1  0.7 -0.2 -0.8 -0.3  0.7 -0.1  3.1  4.2 -0.7 -0.6 -0.1  1.8  0.9 -0.8 -0.2 -1.  -0.7  1.3 -0.6  3.5  0.8 -0.2 -0.2 -0.2 -0.3 -0.2 -0.7 -1.9 -0.3 -0.1  0.  -0.4 -1.4 -0.3 -0.4  0.2  1.8  5.7]
ty_50sample [[6 5 9 4 7 7 2 3 1 0]
 [6 9 4 0 1 2 7 5 3 8]
 [2 9 7 3 4 5 6 0 8 1]
 [8 0 7 3 3 4 6 2 5 1]
 [0 5 6 9 4 3 1 8 7 2]
 [5 7 6 1 0 4 2 3 8 9]
 [0 7 8 4 3 2 9 1 6 5]
 [9 0 3 4 7 2 5 8 6 1]
 [7 9 5 4 8 3 1 1 0 6]
 [4 7 1 3 8 0 5 6 9 2]]
tt_50sample [[6 5 9 4 7 8 2 3 1 0]
 [6 9 4 0 1 2 7 5 3 8]
 [2 9 7 3 4 5 6 0 8 1]
 [8 0 7 9 3 4 2 6 5 1]
 [0 5 6 9 4 3 1 8 7 2]
 [5 7 6 1 0 4 2 3 8 9]
 [0 7 8 4 3 2 9 1 6 5]
 [9 0 3 4 7 2 5 8 6 1]
 [7 9 5 4 8 3 1 0 2 6]
 [4 7 1 3 8 0 5 6 9 2]]
vm  [-1.3 -0.8 -2.6 -1.2 -1.1  0.2 -0.1 -0.3  0.8 -0.9  5.5  1.2 -0.5 -0.3 -1.1  0.2  0.3 -0.5 -0.6 -0.8 -0.9 -0.3 -1.3 -0.3 -0.9  1.6 -0.4 -0.2 -0.6 -1.3  7.3 -0.6 -0.2  4.5 -0.5  0.5  1.   2.1  7.  -0.5  0.2 -0.2 -0.5  5.9 -0.5 -0.3  2.3  0.  -0.6 -2.7 -0.7 -0.4  0.3 -0.4 -1.   3.  -0.6 -0.8  3.3 -2.5  3.3 -0.3 -0.1  1.   0.  -0.3 -0.2  2.2 -0.1 -0.1 -0.2 -0.3 -0.1  0.1 -1.5  0.3  0.2 -0.5  1.5 -0.3 12.2 -0.1 -0.5 -0.2  0.5  0.   1.1 -0.3  0.6 -0.4 -0.2 -0.2 -0.  -0.7 -0.4 -0.1 -0.6 -1.  -0.1 -0.5  2.4 -1.4  1.6 -0.1 -0.3 -0.3 -1.2  7.9  0.9 -1.  -0.4 -0.3 -0.  -0.6  2.9  2.5 -0.1  0.4 -0.   0.2 -0.   4.6 -0.1 -0.2 -0.5 -1.2  1.4  4.5  4.3  2.2 -0.8 -0.3 -0.4 -0.1 -0.3  4.  -0.  -0.2  1.7 -0.7 -0.   1.  -0.1 -0.1 -0.1  0.1  0.1 -0.1  3.5 -0.2  1.4 -0.  -2.   0.3 -0.3 -0.1 -0.3 -0.1  3.6  1.  -0.2 -1.  -0.3 -0.3 -0.3 -0.2  0.1  2.3  0.2 -0.6 -0.5 -0.1 -0.6 -0.3 -0.2 -0.7  0.6 -0.  -1.  -0.3 -0.6 -0.3 -0.3 -1.2  0.1 -0.4 -0.3 -0.  -0.4  5.1 -0.2 -0.3 -0.8 -0.9 -0.4 -0.4 -0.  -0.4 -0.3 -0.2 -0.3  0.2 -0.3 -0.8  0.5 -0.7 -0.  -0.1 -2.7 -0.1 -0.5  1.8 -0.6  4.4  0.4 -0.3 -1.7 -0.7 -0.4 -0.2 -0.6  0.4 -0.3 -0.9 -1.  -0.5 -1.   0.5  0.6  1.6 -1.1 -0.2 -0.2 -1.8  1.6  7.2  0.6 -0.8  1.2  2.3 -0.2  1.1 -0.2 -0.2 -2.5 -1.2 -0.2 -0.4 -1.  -0.4 -2.8 -0.1  5.4 -0.3  3.3  0.3]
vy_50sample [[4 1 3 9 5 0 2 7 6 8]
 [8 2 0 4 6 1 5 7 9 3]
 [6 2 0 7 3 9 8 5 1 4]
 [1 7 3 8 8 5 4 9 2 6]
 [7 4 2 8 6 3 1 5 9 0]
 [2 8 6 6 5 4 9 1 3 7]
 [2 1 0 6 4 5 9 7 8 3]
 [8 1 0 7 3 6 2 5 5 4]
 [2 0 8 3 4 5 1 6 9 7]
 [9 4 0 0 7 6 3 5 1 2]]
vt_50sample [[4 1 3 9 5 0 2 7 6 8]
 [8 2 0 4 6 1 5 7 3 9]
 [6 2 0 7 3 9 8 5 1 4]
 [1 7 3 8 0 5 4 9 2 6]
 [7 4 2 8 6 3 1 5 9 0]
 [2 8 6 0 5 4 9 1 3 7]
 [2 1 0 6 4 5 9 7 8 3]
 [8 1 0 7 3 6 2 9 5 4]
 [2 0 8 3 4 5 1 6 9 7]
 [9 4 8 0 7 6 3 5 1 2]]
Epoch 14710: Training cost= 0.4413, Training acc= 0.7968, Validation cost= 0.3134, Validation acc= 0.7971
Epoch 14720: Training cost= 0.3753, Training acc= 0.7968, Validation cost= 0.2723, Validation acc= 0.7971
Epoch 14730: Training cost= 0.3373, Training acc= 0.7969, Validation cost= 0.3557, Validation acc= 0.7972
Epoch 14740: Training cost= 0.3407, Training acc= 0.7969, Validation cost= 0.3389, Validation acc= 0.7972
Epoch 14750: Training cost= 0.3415, Training acc= 0.7970, Validation cost= 0.3107, Validation acc= 0.7973
Epoch 14760: Training cost= 0.3898, Training acc= 0.7970, Validation cost= 0.3151, Validation acc= 0.7973
Epoch 14770: Training cost= 0.3101, Training acc= 0.7971, Validation cost= 0.3312, Validation acc= 0.7973
Epoch 14780: Training cost= 0.3676, Training acc= 0.7971, Validation cost= 0.3373, Validation acc= 0.7974
Epoch 14790: Training cost= 0.3239, Training acc= 0.7972, Validation cost= 0.3777, Validation acc= 0.7974
Epoch 14800: Training cost= 0.3767, Training acc= 0.7972, Validation cost= 0.3177, Validation acc= 0.7975
tm  [ 0.9 -0.6  3.2 -0.3 -2.1 -0.3 -0.3 -0.2 -0.4  1.2  6.7 -0.6 -0.3 -0.3  5.1 -0.4 -0.1 -0.2 -0.5 -1.7 -0.4 -0.3  2.6  0.3 -0.7  0.6 -0.5  0.5 -1.2  0.2  5.4 -0.  -0.1 12.1  2.   0.5  1.9  1.8  6.6 -0.5 -0.   3.8 -0.4  3.9 -0.4 -0.3  6.7 -0.1  2.   3.4 -0.8 -0.4 -0.2  0.2 -0.2 -0.6 -0.7 -0.8 -0.  -2.  -1.  -0.3 -0.1  1.5  2.9 -0.8 -0.1 -0.2  0.8 -0.7 -0.2  2.1 -0.3 -0.5 -1.2 -0.1 -0.2  0.5  0.2 -0.2 11.9 -0.1 -0.5  0.6 -1.1  3.7  2.5 -0.3 -0.5 -0.3 -0.5 -0.8 -0.6 -0.5 -0.2  0.2 -0.1 -0.5 -0.5 -0.1 -0.5  9.7 -1.  -0.2 -0.2 -0.4 -1.2  5.6  2.3 -1.5 -0.1 -0.3 -0.2 -0.3  2.6 -1.3 -0.2  0.8 -0.1 -0.8 -0.6  5.1 -0.3 -0.  -0.7  5.8 -0.6  2.8 -0.1 -1.6  0.8 -0.3 -0.3  0.7 -4.3  4.7 -0.  -0.5 -1.  -0.7 -0.5 -0.3 -0.3 -0.2 -0.4 -0.4  0.9 -0.6 -1.3  0.  -0.3 -0.1  0.6 -0.3 -0.2 -0.2 -0.  -0.2 -0.1 -0.5  0.1 -1.  -0.1 -0.3  2.  -0.2 -1.5 -0.1 -0.5 -0.2  1.  -0.4 -0.3 -0.   0.1  4.7 -0.5  0.1 -1.1 -0.2 -0.6 -0.1  0.4 -1.1 -0.8 -0.5  4.  -0.7  0.9 -0.5 -0.4 -0.4 -1.  -0.6  7.3  0.4 -0.5 -0.2 -0.3 -0.2 -0.  -0.4 -0.2 -0.  -0.6 -0.1  0.5 -0.3 -0.6 -0.1  0.1 -0.7  0.2 -0.2  1.5 -0.1 -1.  -0.2 -0.3 -0.5 -0.4 -0.2 -0.3 -1.1  2.9 -1.  -0.4 -0.1 -0.5  1.1 -0.8  1.2 -0.3 -0.5  0.1 -0.2  1.7 -0.7  0.5  7.9 -0.2  3.9 -0.3 -0.2 -2.5 -1.4 -0.4 -0.6 -0.3  1.6 -3.   2.1  5.  -0.3 -0.6  9.8]
ty_50sample [[7 0 4 9 2 5 6 1 8 3]
 [1 2 2 0 7 7 4 3 6 5]
 [3 9 6 4 0 5 7 2 8 1]
 [1 5 3 7 2 6 9 8 0 4]
 [6 3 8 5 4 0 0 7 1 9]
 [0 9 6 5 1 7 2 4 8 3]
 [1 3 2 6 7 8 5 0 4 9]
 [7 0 2 4 1 3 9 8 6 5]
 [8 5 7 6 1 2 9 3 4 0]
 [1 9 8 2 7 5 0 6 4 3]]
tt_50sample [[7 0 4 9 2 5 6 1 8 3]
 [1 2 9 8 0 7 4 3 6 5]
 [3 9 6 0 4 7 5 2 8 1]
 [1 5 3 7 2 6 9 8 0 4]
 [6 3 8 5 4 0 2 7 1 9]
 [0 9 6 1 5 7 2 4 8 3]
 [1 3 2 6 7 8 5 0 4 9]
 [0 7 2 4 1 3 9 8 6 5]
 [8 7 5 6 1 9 2 3 4 0]
 [1 9 2 8 7 5 0 6 4 3]]
vm  [ 0.5 -0.2  3.9  0.3 -1.8 -0.5 -0.2 -0.2 -0.4 -0.8 -1.1  2.  -0.7 -0.1  5.1  1.1  0.6 -0.3 -0.1 -0.1 -0.5  1.   0.2 -0.4 -1.2  0.1 -0.2 -0.  -0.  -0.7  0.7 -0.6 -0.4  4.1 -0.8 -0.4  1.7  2.4  7.5 -1.  -0.3  2.5  2.3  4.7 -0.2  0.3 -0.1  0.9  2.7 -0.2 -0.9 -0.2 -0.1 -0.3 -0.8 -0.4 -0.6  3.5  0.   1.5 -0.4 -0.5 -0.2  1.3 -0.2 -0.5 -0.  -0.3  0.7 -0.   0.6 -0.6 -0.1 -0.2 -2.4  0.4 -1.  -0.5 -0.5  0.2 -0.4 -0.2 -0.3  0.4 -1.   2.7  1.7  0.1  1.4 -0.3 -0.3  0.4 -0.   0.1 -0.3 -0.2  0.7 -1.3 -0.5 -0.1  2.8  2.3 -0.9 -0.  -0.1 -0.3 -1.4  0.6 -0.4 -0.6  0.2 -0.3 -0.2 -0.7 -0.4  4.1 -0.1  0.2 -0.3 -0.2 -0.2  1.1 -0.5 -0.5 -0.5  5.5  1.4  3.9  4.2  3.5 -0.3 -0.8 -0.1 -0.2 -4.7 -3.1 -0.2 -0.4 -0.1 -0.6  1.  -0.3  1.4 -0.2 -0.4  0.4 -0.1 -0.9  2.6 -0.1 -0.  -0.2  4.2  0.6 -0.3 -0.2 -0.2 -0.3  4.4 -0.6 -0.5 -1.6 -0.1 -0.4 -0.1 -0.2  0.3 -0.4 -0.3  0.1 -0.3  0.6 -0.4 -0.4 -0.3 -0.2  1.7 -0.4 -1.2 -0.1 -1.7 -0.3 -0.3 -0.9 -0.3 -0.2  2.7 -0.8 -0.5  2.5 -0.1 -0.1 -0.7 -1.1  3.7 -0.9 -0.6 -0.2 -0.  -0.3 -0.3 -0.2 -0.4 -0.6 -0.6 -1.3  0.8 -0.2 -1.4 -0.1 -0.7  2.6 -0.4 -0.4 -0.3 -0.4 -1.1 -0.3  0.5  0.  -0.9 -0.3  0.2 -0.6 -1.5  2.2 -1.  -0.3  0.1  4.5 -0.5  0.4 -0.4 -1.  -0.3 -0.4 -0.1 -0.5  1.7 -2.1 -0.  -1.  -0.3 -0.2  3.  -0.7 -0.1 -0.4 -0.6 -0.1  0.  -0.6  6.  -0.   4.  -0.4]
vy_50sample [[5 7 3 8 4 9 0 2 1 6]
 [6 9 7 2 1 4 5 0 8 3]
 [0 7 9 4 1 3 2 2 5 6]
 [9 1 7 7 6 2 8 3 4 0]
 [6 8 9 1 2 0 4 5 3 7]
 [4 2 1 5 8 7 6 3 0 9]
 [4 6 2 8 7 0 9 5 3 1]
 [9 2 0 8 4 1 7 3 6 5]
 [5 2 0 7 1 1 6 4 9 3]
 [3 8 1 4 0 7 9 6 2 5]]
vt_50sample [[5 7 3 8 4 9 0 2 1 6]
 [6 9 7 2 1 4 5 0 8 3]
 [0 7 9 4 1 3 2 8 5 6]
 [9 1 7 5 6 2 8 3 4 0]
 [6 8 9 1 2 0 4 3 5 7]
 [4 2 1 5 8 7 6 3 0 9]
 [4 6 2 8 0 7 9 5 3 1]
 [9 2 0 8 4 1 7 3 6 5]
 [5 2 0 7 8 1 6 4 9 3]
 [3 8 1 4 0 7 9 6 2 5]]
Epoch 14810: Training cost= 0.3336, Training acc= 0.7972, Validation cost= 0.3801, Validation acc= 0.7975
Epoch 14820: Training cost= 0.3709, Training acc= 0.7973, Validation cost= 0.3774, Validation acc= 0.7975
Epoch 14830: Training cost= 0.3377, Training acc= 0.7973, Validation cost= 0.3267, Validation acc= 0.7976
Epoch 14840: Training cost= 0.3583, Training acc= 0.7973, Validation cost= 0.2977, Validation acc= 0.7976
Epoch 14850: Training cost= 0.2997, Training acc= 0.7974, Validation cost= 0.3470, Validation acc= 0.7976
Epoch 14860: Training cost= 0.2791, Training acc= 0.7974, Validation cost= 0.3219, Validation acc= 0.7977
Epoch 14870: Training cost= 0.3952, Training acc= 0.7975, Validation cost= 0.3262, Validation acc= 0.7977
Epoch 14880: Training cost= 0.3401, Training acc= 0.7975, Validation cost= 0.3173, Validation acc= 0.7978
Epoch 14890: Training cost= 0.3066, Training acc= 0.7976, Validation cost= 0.3715, Validation acc= 0.7978
Epoch 14900: Training cost= 0.3412, Training acc= 0.7976, Validation cost= 0.2939, Validation acc= 0.7979
tm  [ 0.5 -0.1 -0.7 -3.2 -1.6 -0.  -0.3 -0.4 -1.4 -0.5 -0.8 -0.5  0.4 -0.4  8.2 -0.2  0.3 -0.4  0.3  1.5 -0.6 -0.4  2.8 -0.3 -0.9  1.4 -0.3 -0.3 -1.3 -0.3  1.5  0.5 -0.5 -0.6  1.3  0.6  3.7  1.9 -0.4 -1.  -0.1 -1.5 -0.3  6.  -0.8  1.  -2.  -0.5  2.2  5.6 -0.7 -0.6 -1.2  6.5  0.4 -1.  -0.9 -2.5  0.7  0.7  3.   2.5 -0.6  1.7 -1.1  0.5  0.  -0.4  0.4  2.7 -0.1  1.9  0.2 -0.1 -3.7 -0.  -0.1 -0.3  1.9 -0.  -3.7 -0.2 -0.3 -0.1 -0.9 -1.7  4.6 -0.2  0.2 -0.1 -0.5 -0.1 -0.3  1.1 -0.6 -0.2 -0.6 -1.7 -0.3  0.1  1.   3.3  0.1 -0.1  0.4 -0.3 -2.2  1.5 -0.5 -0.3 -1.1 -0.4 -0.2 -0.3  2.3 -1.1 -0.3 -0.  -0.4 -0.5  0.7  1.  -0.3 -1.  -0.4  8.8 -0.4 -1.5 -0.   5.6 -0.  -0.5 -0.4 -0.2 -2.3 -3.2 -0.3 -0.3 -0.3 -0.  -0.3 -1.1 -0.5  0.2 -0.2 -0.2 -0.4 -0.6 -1.8 -0.2  3.4 -0.2  3.3 -0.5 -0.4 -0.4 -0.1  1.5  1.4 -0.8 -0.3 -0.6 -0.4 -0.5 -0.8 -0.3 -0.5  1.5  1.1 -1.  -0.2 -0.4  0.1 -0.3  0.2  4.6  0.2 -1.1  2.7 -0.9  1.4  0.3 -0.5 -0.8  0.4 -0.2 -0.2 -0.9 -0.1  0.3 -0.2 -0.4  0.7 -1.  -0.4 -0.1 -1.4 -0.   0.1  0.3 -0.  -0.2 -0.4 -0.5 -0.1 -3.3 -0.6 -0.1  9.  -0.1 -0.5 -1.1 -0.9 -0.4  1.3 -0.4 -1.4 -0.4  0.  -0.5 -0.3  0.4 -0.1 -0.5 -0.5 -0.  -0.2 -0.3 -0.2  2.3 -1.   0.6 -0.3  6.5  3.2  3.2  1.2 -1.4  2.4  5.  -0.3  2.8 -0.2 -0.2 12.3  5.1 -0.4 -0.1 -0.4 -0.2  8.2 -0.1 -0.2 -0.5  0.4 -1.1]
ty_50sample [[4 8 0 7 2 3 1 6 9 5]
 [2 5 6 8 4 0 1 9 7 3]
 [2 7 8 3 4 9 1 0 6 5]
 [7 6 4 5 2 0 1 8 3 9]
 [3 2 4 0 5 5 9 9 6 6]
 [0 5 7 6 1 3 8 9 4 2]
 [6 2 3 5 0 4 1 8 7 9]
 [1 9 3 4 6 0 7 2 5 8]
 [6 4 5 0 9 9 8 1 3 2]
 [8 5 3 2 0 7 7 6 4 1]]
tt_50sample [[4 8 0 7 2 3 1 6 9 5]
 [2 5 6 8 4 0 1 9 7 3]
 [2 7 8 3 4 9 1 0 6 5]
 [7 6 4 5 2 0 1 8 3 9]
 [3 8 2 4 0 5 9 7 6 1]
 [0 5 7 6 1 3 8 9 4 2]
 [6 2 3 5 0 4 1 8 7 9]
 [1 9 3 4 6 0 7 2 5 8]
 [6 4 0 5 9 8 7 1 3 2]
 [8 5 3 2 9 7 0 6 4 1]]
vm  [-0.6 -0.6 -3.4 -3.5 -0.8 -0.  -0.1 -0.2  0.4 -0.8  2.2  1.1 -0.9 -0.6 -0.1 -1.1  0.1 -0.3 -0.4  2.3 -0.8 -0.3 -1.1 -0.  -1.   3.3 -0.4 -0.1 -1.5 -1.8  5.3 -0.6 -0.1 -0.9  0.4 -0.3  1.2 -0.2 -1.4 -1.  -0.2 -1.3 -0.8  3.8 -0.9 -0.1 -2.2 -0.1  0.2 -2.1 -0.4 -0.8 -0.   3.1 -0.2  0.8 -0.8 -1.1  3.6 -1.7  5.6 -0.5  1.   2.1  0.  -0.2  0.1  2.7  0.8 -0.1 -0.2  1.8 -0.1 -0.1 -4.9 -0.1 -0.5 -0.4  1.  -0.1 -0.5 -0.3  1.2 -0.3 -0.5 -1.3  2.2 -0.4 -0.  -0.6 -0.1 -0.8 -0.1 -0.1 -0.7 -0.1 -0.6 -2.  -0.2 -0.2  0.6 -2.7  0.6 -0.2 -0.1  0.4 -2.6  6.5  0.5  1.8 -0.4 -0.1 -0.3 -0.8  6.1 -1.2 -0.4  1.8  0.5  1.3  0.3 -1.  -0.2  0.4 -0.7 -0.1 -0.1 -0.1  3.   7.9  0.3 -0.4 -0.2  0.7  7.9  5.5 -0.2 -0.   1.7 -0.6  1.3 -0.7 -0.3  0.1 -0.3 -0.1 -0.3 -0.3  3.5 -0.4  3.7 -0.2 -0.4  1.5 -0.3 -0.2 -0.5  0.6 -0.1  0.2 -0.3 -0.8  0.3 -0.3 -0.3 -0.4 -0.3  2.7  0.4 -0.9 -0.6 -0.1 -0.3 -0.2 -0.3 -0.8 -0.8 -1.   5.4 -0.1 -0.4 -0.2 -0.1 -1.5  0.9 -0.2 -0.5  1.6  0.4  5.9 -0.2 -0.3  0.1 -1.4 -1.2 -0.3 -1.5 -0.8 -0.3  0.6 -0.1  0.7 -0.4 -0.8 -0.3 -2.6 -0.3 -0.4 -0.4 -0.3 -0.4 -0.7 -0.9  1.8  0.2 -0.3 -0.9 -0.8 -0.8  0.1 -0.6 -0.3 -0.1 -0.9 -0.4 -0.9 -1.3  0.6  1.1  2.5 -0.8  0.5 -0.4 -0.2  2.8  8.   1.9 -2.2  2.4 -1.1  0.1 -0.6 -0.4 -0.1  3.3  2.4 -0.3 -0.4 -1.  -0.4  0.7 -0.1 -0.9 -0.3  3.5 -2. ]
vy_50sample [[4 3 3 1 6 5 2 8 9 7]
 [1 3 4 5 6 8 9 2 7 0]
 [6 4 3 3 5 5 9 1 8 0]
 [2 0 7 1 8 4 9 5 6 3]
 [9 6 2 1 1 8 3 0 5 7]
 [4 1 6 2 9 3 8 5 0 7]
 [4 5 2 8 3 6 9 7 0 1]
 [2 3 1 0 5 6 7 8 4 9]
 [5 4 7 2 0 6 1 3 8 9]
 [3 1 4 5 7 0 9 6 2 8]]
vt_50sample [[4 3 0 1 6 5 2 8 9 7]
 [1 3 4 5 6 8 9 7 2 0]
 [6 7 4 3 5 2 9 1 8 0]
 [2 0 7 1 8 4 9 5 6 3]
 [9 6 2 4 1 8 3 0 5 7]
 [4 1 6 2 9 3 8 5 0 7]
 [4 5 2 8 3 6 9 7 0 1]
 [2 3 1 0 5 6 7 8 4 9]
 [5 4 7 2 0 6 1 3 8 9]
 [3 1 4 5 7 0 9 6 2 8]]
Epoch 14910: Training cost= 0.3294, Training acc= 0.7977, Validation cost= 0.3497, Validation acc= 0.7979
Epoch 14920: Training cost= 0.3493, Training acc= 0.7977, Validation cost= 0.3231, Validation acc= 0.7980
Epoch 14930: Training cost= 0.3316, Training acc= 0.7978, Validation cost= 0.3108, Validation acc= 0.7980
Epoch 14940: Training cost= 0.3400, Training acc= 0.7978, Validation cost= 0.2980, Validation acc= 0.7981
Epoch 14950: Training cost= 0.3204, Training acc= 0.7978, Validation cost= 0.3060, Validation acc= 0.7981
Epoch 14960: Training cost= 0.4249, Training acc= 0.7979, Validation cost= 0.3804, Validation acc= 0.7981
Epoch 14970: Training cost= 0.2986, Training acc= 0.7979, Validation cost= 0.3249, Validation acc= 0.7982
Epoch 14980: Training cost= 0.3467, Training acc= 0.7980, Validation cost= 0.3493, Validation acc= 0.7982
Epoch 14990: Training cost= 0.3624, Training acc= 0.7980, Validation cost= 0.3621, Validation acc= 0.7983
Epoch 15000: Training cost= 0.3622, Training acc= 0.7980, Validation cost= 0.3793, Validation acc= 0.7983
tm  [-1.6  0.6  5.1 11.6 -1.2 -0.  -0.  -0.4 -0.5 -0.5 -0.9 -0.4 -0.5 -0.2 -0.4  0.6 -0.2 -0.3 -0.3 -0.7 -0.5 -0.4  3.2 -0.3 -1.2  1.2 -0.1 -0.1 -0.2 -0.5 -1.4 -0.3 -0.  -0.6 -0.7 -0.   2.4 -0.7 -0.7 -0.1 -0.4  3.4  1.1 -1.7 -0.5 -0.1  1.9  0.  -0.8  5.8 -0.6 -0.2  1.  -0.5 -0.6  2.3 -0.5  5.6 -0.3  5.5  2.9 -0.2 -0.2  1.  -0.5 -0.  -0.2 -0.4  0.2 -0.2  0.  -0.2  0.2  0.4 -0.6 -0.1  0.9 -0.1  0.2  0.1  1.9 -0.3 -0.4 -0.1  0.6  5.1 -1.3  0.2 -0.2  0.4 -0.3 -0.1 -0.3 -0.1 -0.1 -0.3  1.6 -0.9 -0.2 -0.   1.3  4.   1.5 -0.1 -0.4  0.5 -0.4 -1.3 -0.4 -1.5 -0.6 -0.  -0.1 -0.1  0.2  2.2 -0.5 -0.8 -0.5 -0.1 -0.   4.9  0.4  0.3  0.2 -0.6  1.6  4.8  0.5 -1.   0.3 -0.7 -0.5 -0.4  7.2  6.5 -0.2 -0.1 -0.  -0.4  0.6 -0.4  0.3 -0.1 -0.3  0.4 -0.1 -0.1  2.3 -0.1 -0.8 -0.3 -0.1  0.4 -0.2 -0.  -0.2 -0.1 -1.  -0.4  0.2  3.9 -0.2 -0.  -0.7 -0.4  0.5  0.8 -0.3  2.2  0.2 -0.3 -0.2 -0.  -0.1 -0.3 -1.   0.7  3.6 -0.  -1.1 -0.2 -0.3 -1.  -0.2 -0.3 -0.6 -0.4 -0.1  2.  -0.  -0.6 -0.7 -0.5 -0.4  0.8  0.8  0.8 -0.1 -0.4 -0.5 -0.3 -0.2 -0.4  2.1 -0.3 -0.2  0.6  0.6  0.1 -0.6  2.  -0.4  4.9 -0.7 -0.3  7.  -0.4 -0.2 -0.2 -0.7 -0.2 -0.4 -0.7  4.7  1.9 -0.8  1.8  0.2 -0.3  1.1 -0.9 -0.3  0.5  1.3 -1.1  0.4  1.2  1.5  1.3 -0.2  0.2 -0.  -0.3  0.6 -1.1  0.2  1.7 -0.9 -0.5 -0.7 -0.6 -0.6  0.1  1.1  6.1]
ty_50sample [[6 1 5 5 8 7 0 2 3 4]
 [7 9 6 3 8 5 0 4 2 1]
 [7 6 8 2 2 9 4 5 5 3]
 [0 0 1 4 5 7 2 8 3 6]
 [3 9 7 4 1 2 6 0 0 8]
 [3 8 1 7 2 6 0 4 5 9]
 [3 3 4 2 9 9 7 8 5 6]
 [9 8 4 6 7 1 3 0 2 5]
 [8 2 6 5 3 9 0 7 4 1]
 [6 7 5 1 0 0 3 4 2 8]]
tt_50sample [[6 1 5 9 8 0 7 2 3 4]
 [7 9 6 3 8 0 5 4 2 1]
 [7 6 8 0 2 9 4 5 1 3]
 [0 9 1 4 5 7 2 3 8 6]
 [3 9 7 4 1 2 6 0 5 8]
 [3 8 1 7 2 0 6 4 5 9]
 [3 0 4 1 2 9 7 8 5 6]
 [9 4 8 6 7 1 3 0 2 5]
 [8 2 5 6 3 9 0 4 7 1]
 [6 7 5 1 0 3 9 4 2 8]]
vm  [-0.7 -0.3  4.3 -0.1 -1.  -0.1 -0.2 -0.4 -0.1 -0.   9.4 -0.9 -0.1 -0.4  7.4  5.4 -0.3 -0.2 -0.   0.8 -0.8 -0.   0.7 -0.6 -1.2  1.3 -0.4 -0.6 -0.1 -0.4  2.  -0.8  1.7  6.9  1.5 -0.4  1.   2.1 -2.4 -0.3 -0.1 -0.7 -1.1 -0.8 -0.8 -0.3 -1.2 -1.6 -0.4  1.  -0.6 -0.5 -0.4 10.2 -1.3 -0.7 -0.7 -0.9  3.2  0.1  4.7 -0.   1.1  2.   2.  -0.9  0.5  1.1 -0.3 -0.6 -0.5 -0.3  0.6 -0.2 -4.4 -0.4 -0.5 -0.2  0.6 -0.2  0.6  0.6 -0.1 -0.3 -0.6 -0.6 -0.2 -0.1 -0.2 -0.2 -0.4 -0.5 -0.2 -1.  -0.7 -0.2 -0.5 -1.9 -0.5 -0.2 -0.2  5.   0.7 -0.2 -0.5  0.  -2.1  1.7  3.3  0.4 -0.4 -0.3 -0.  -0.5  2.   1.4 -0.1 -0.3 -0.   0.2 -0.2 -0.6 -0.1  0.4 -0.3  7.  -0.5 -2.6  0.1  1.1  1.  -0.7 -0.1  0.4  3.3 10.9 -0.1 -0.2 -0.1 -0.7 -1.  -0.1 -1.  -0.4 -0.1 -0.1 -0.2 -0.1 -1.9 -0.2  0.9 -0.4 -0.6 -0.9 -0.1  0.1 -0.2  0.1 -1.  -0.4  0.6  1.5  1.  -0.3  0.1 -0.6 -0.2  2.1 -0.3 -0.1 -0.2 -0.9 -0.2  0.5 -0.3  5.  -1.6 -0.4  7.7 -0.6  2.5 -0.1 -0.3 -1.  -0.5 -0.4 -0.4 -0.4 -0.6  2.  -0.3 -0.5 -0.4 -1.  -1.  -0.2 -1.2 -0.4 -0.1 -0.1  0.3 -0.4 -0.4 -0.3 -0.2 -2.2 -0.1 -0.3  3.4 -0.5 -0.2  0.8 -0.8  3.4 -0.3 -0.1  3.1 -0.6 -0.5  0.8 -0.3 -0.5 -0.2 -0.9  3.2 -0.2  1.7  3.9  0.1  0.5  0.1  1.2 -0.3  2.6 -0.6 -0.9  1.4 -2.  -0.2  4.5 -0.4  3.2 -0.6 -0.4  1.7  0.3 -0.3 -0.1 -0.5 -0.1 -0.3  0.1 -1.8 -0.1 -1.1  0.7]
vy_50sample [[2 6 7 1 0 4 3 8 9 5]
 [2 5 4 6 8 7 0 9 3 1]
 [1 3 0 4 8 6 5 2 9 7]
 [6 2 1 3 7 0 9 5 4 8]
 [0 8 7 5 2 4 9 1 6 3]
 [6 1 4 9 0 2 3 5 8 7]
 [2 1 6 4 7 9 5 8 0 3]
 [9 2 5 3 6 7 4 0 8 1]
 [7 8 4 6 2 3 9 0 5 5]
 [9 6 0 5 7 3 2 8 1 4]]
vt_50sample [[2 6 7 1 0 4 3 8 9 5]
 [2 5 4 6 8 7 0 9 3 1]
 [1 3 0 4 8 6 5 2 9 7]
 [6 2 1 3 7 0 9 5 4 8]
 [0 8 7 5 2 4 9 1 6 3]
 [6 1 4 9 0 2 3 5 8 7]
 [2 1 6 4 7 9 5 8 0 3]
 [9 2 5 6 3 7 4 0 8 1]
 [7 8 4 6 2 3 9 5 0 1]
 [9 0 6 5 7 3 2 8 1 4]]
Epoch 15010: Training cost= 0.3615, Training acc= 0.7981, Validation cost= 0.3978, Validation acc= 0.7983
Epoch 15020: Training cost= 0.3187, Training acc= 0.7981, Validation cost= 0.2893, Validation acc= 0.7984
Epoch 15030: Training cost= 0.3249, Training acc= 0.7982, Validation cost= 0.3424, Validation acc= 0.7984
Epoch 15040: Training cost= 0.3403, Training acc= 0.7982, Validation cost= 0.3010, Validation acc= 0.7985
Epoch 15050: Training cost= 0.3121, Training acc= 0.7983, Validation cost= 0.3103, Validation acc= 0.7985
Epoch 15060: Training cost= 0.3423, Training acc= 0.7983, Validation cost= 0.3387, Validation acc= 0.7986
Epoch 15070: Training cost= 0.2852, Training acc= 0.7984, Validation cost= 0.3155, Validation acc= 0.7986
Epoch 15080: Training cost= 0.3073, Training acc= 0.7984, Validation cost= 0.3161, Validation acc= 0.7987
Epoch 15090: Training cost= 0.2655, Training acc= 0.7985, Validation cost= 0.3199, Validation acc= 0.7987
Epoch 15100: Training cost= 0.3262, Training acc= 0.7985, Validation cost= 0.4736, Validation acc= 0.7988
tm  [-0.2 -0.3 -1.4 -4.  -1.2 -0.7 -0.3 -0.3 -0.1 -0.7 -2.8  2.8 -1.6 -0.3  6.8 -1.3  0.2  0.2 -0.   2.7 -0.7 -0.1 -0.7 -0.4 -0.3  0.8 -0.4 -0.  -0.5 -1.3  2.9 -0.7 -0.3 -0.3  0.1 -0.7 -0.1 -0.2 -0.6 -0.9 -0.6 -2.6 -1.   4.3 -1.  -0.2 -2.4  0.9  1.2 -1.5 -0.6 -0.5 -0.2  1.  -0.7 -0.6 -0.4 -1.6  3.8 -0.7  4.4 -0.3  1.   0.2 -0.5 -0.5 -0.1  1.1  0.5  0.5 -0.3  0.8 -0.1 -0.2 -6.   0.4 -0.6 -0.5 -0.1 -0.  -2.8 -0.6  0.2 -0.5 -0.9 -2.8  2.6 -0.4  0.4 -0.4 -0.4 -0.6  1.2 -0.2 -0.8 -0.5 -1.1 -2.2 -0.6 -0.3  1.6 -1.6  0.  -0.5 -0.3  0.9 -3.   3.1 -1.   1.5  0.6 -0.5 -0.3 -0.9  4.8 -0.6  0.7  3.8 -0.   0.6 -0.4 -0.9 -0.4 -0.3 -0.4  7.8 -0.   1.8  2.6 10.8 -0.1 -0.7  1.2 -0.1 -1.1 -1.6 -0.6 -0.2  0.7  0.1  2.4 -0.5  1.2 -0.  -0.5 -0.2 -0.5 -0.5 -0.9 -0.6  4.  -0.2  3.   0.6 -0.2 -0.3 -0.5  1.   0.6 -0.8 -1.1 -1.2 -0.1 -0.  -0.  -0.2 -0.3  4.4  0.3 -1.1 -1.  -0.4 -0.5 -0.2 -0.5  3.2 -0.1 -1.5  3.4  1.3  0.8  1.4 -0.5 -1.4  0.7  0.1 -0.3 -0.4 -0.3  4.8 -0.2  0.3 -0.2 -1.3 -0.9 -0.4 -1.6 -1.   0.1 -0.3 -0.   1.1 -0.1 -0.5 -0.6 -3.  -0.4 -0.4  6.6 -0.5 -0.4 -0.3 -1.  -0.1  1.6  0.4 -1.1 -0.2 -0.2  0.  -1.  -0.3 -0.  -0.8 -1.3  0.5 -2.1 -0.5 -0.2  4.3 -1.   1.1 -0.3  4.3  0.4  4.6  0.7 -2.5  1.3  0.1 -0.3 -0.1 -0.4 -0.3  9.7  3.6 -0.5 -0.4 -0.7 -0.   6.  -0.4 -0.4 -0.6  6.4 -3.4]
ty_50sample [[3 4 8 0 7 1 6 5 2 9]
 [8 0 7 2 1 9 4 5 3 6]
 [5 6 9 8 0 2 3 1 7 4]
 [8 2 4 5 7 6 0 1 3 9]
 [8 4 3 1 9 0 5 7 6 2]
 [6 9 4 4 8 0 5 1 7 3]
 [1 3 2 2 6 9 0 5 4 8]
 [4 1 8 3 5 7 7 9 2 2]
 [2 3 1 9 6 6 5 4 0 7]
 [2 6 9 4 5 8 7 0 1 3]]
tt_50sample [[3 4 8 0 7 1 6 5 2 9]
 [8 0 7 2 1 4 9 5 3 6]
 [5 6 8 9 0 2 3 1 7 4]
 [8 2 4 5 7 6 0 1 3 9]
 [8 4 3 1 9 5 0 7 6 2]
 [6 9 4 2 8 0 5 1 7 3]
 [1 3 2 7 6 9 5 0 4 8]
 [4 1 8 3 5 7 0 9 6 2]
 [2 3 1 9 8 6 5 4 0 7]
 [2 6 9 4 5 8 7 0 1 3]]
vm  [-1.  -0.1  6.8 -0.9 -2.1 -0.4 -0.3 -0.1 -0.5  0.7  8.4 -0.7  0.4 -0.1 12.6  4.1  0.2 -0.1 -0.1 -0.1 -0.7 -0.4  1.9 -0.5 -1.2 -0.1 -0.4 -0.3 -0.6 -0.7  0.8  0.1 -0.6  9.2  0.2 -0.   1.5  7.   2.8 -0.2 -0.2  4.8 -0.1  2.9 -1.2 -0.3 -1.3 -1.3 -0.9  4.2 -0.7 -0.3 -0.9 11.9 -1.4 -1.7 -0.8  3.   0.8  0.8  8.3 -0.1 -0.2  0.5  1.7 -0.9 -0.2  0.9 -0.7 -1.  -0.   0.9 -0.3 -0.6 -5.3 -0.7  1.  -0.2  0.4 -0.2 -1.  -0.5 -0.3 -0.4  0.3  4.8 -0.6 -0.  -0.2 -0.3 -0.9 -0.1 -0.5  0.2 -0.9 -0.3 -0.2 -1.8 -0.4 -0.2  0.2  7.5  2.3 -0.4 -0.5 -0.3 -3.1  0.6  2.  -0.2  1.3 -0.4 -0.1 -0.7  0.5 -0.  -0.5 -0.4 -0.1 -0.4 -0.4 -0.7 -0.6 -0.3 -0.6 14.4 -0.2 -3.3  1.6  1.3 -1.2 -0.2 -0.5  1.4 -5.5 -1.5 -0.1 -0.  -0.4 -0.5 -0.7 -0.1 -0.9 -0.4  0.9 -0.6 -0.6  0.5 -0.6 -0.2  0.4 -0.2 -1.  -0.8 -0.2 -0.1 -0.3  0.8  3.1 -0.6 -0.3 -1.5 -0.3 -0.3  0.9 -0.1 -1.  -0.1 -0.3 -0.   1.2  0.4 -0.4  0.3 -0.3  2.6  0.4 -1.8 -0.2 -0.6 -1.4 -0.2  0.4 -1.  -0.3 -0.5 -1.5 -1.  -0.3  3.2 -0.3 -0.6  0.8 -0.6 -2.2  0.9 -2.1  0.5 -0.1 -0.3 -0.1 -0.7 -0.2 -0.  -0.1 -3.5 -0.3 -0.5 -1.8 -0.1 -0.3 -0.5 -0.2  4.   1.2 -0.2 -0.7 -0.6 -0.3  0.6  0.8 -0.3  1.5 -0.8 -0.1 -0.2  2.   3.2 -0.5 -0.6 -0.8  2.9 -0.5 -1.2  0.5 -1.5  0.8 -2.6 -0.6 -3.4 -0.5 -1.7 -0.4 -0.1  4.6  4.5 -0.5 -0.5 -0.4  1.2  1.8  0.6  2.  -0.6 -1.1  1.5]
vy_50sample [[2 7 1 5 0 8 4 9 3 6]
 [7 3 1 2 4 5 5 6 9 0]
 [6 4 7 5 5 9 9 2 8 3]
 [1 5 0 2 9 4 6 7 3 8]
 [1 4 3 5 8 2 0 7 7 6]
 [8 7 9 2 2 4 0 3 1 5]
 [8 1 0 7 3 9 4 2 5 6]
 [0 8 3 1 2 6 4 9 5 7]
 [5 1 7 4 2 3 8 9 6 0]
 [7 9 0 2 5 6 8 4 1 3]]
vt_50sample [[2 7 1 5 0 4 8 9 3 6]
 [7 3 1 2 4 5 8 6 9 0]
 [4 6 7 5 0 1 9 2 8 3]
 [1 5 0 2 9 4 6 7 8 3]
 [1 4 3 5 8 2 9 7 0 6]
 [8 7 9 2 6 4 0 3 1 5]
 [8 1 7 3 0 4 9 2 5 6]
 [8 0 3 1 2 6 4 9 5 7]
 [5 1 7 4 2 3 8 9 6 0]
 [7 9 0 2 5 6 4 8 1 3]]
Epoch 15110: Training cost= 0.3975, Training acc= 0.7985, Validation cost= 0.3219, Validation acc= 0.7988
Epoch 15120: Training cost= 0.3575, Training acc= 0.7986, Validation cost= 0.3335, Validation acc= 0.7988
Epoch 15130: Training cost= 0.3429, Training acc= 0.7986, Validation cost= 0.3607, Validation acc= 0.7989
Epoch 15140: Training cost= 0.3117, Training acc= 0.7987, Validation cost= 0.2808, Validation acc= 0.7989
Epoch 15150: Training cost= 0.3106, Training acc= 0.7987, Validation cost= 0.3829, Validation acc= 0.7990
Epoch 15160: Training cost= 0.3051, Training acc= 0.7988, Validation cost= 0.3363, Validation acc= 0.7990
Epoch 15170: Training cost= 0.3045, Training acc= 0.7988, Validation cost= 0.4262, Validation acc= 0.7990
Epoch 15180: Training cost= 0.3407, Training acc= 0.7988, Validation cost= 0.3350, Validation acc= 0.7991
Epoch 15190: Training cost= 0.3225, Training acc= 0.7989, Validation cost= 0.3873, Validation acc= 0.7991
Epoch 15200: Training cost= 0.3028, Training acc= 0.7989, Validation cost= 0.3713, Validation acc= 0.7992
tm  [-0.2 -0.4  5.3  1.  -1.5 -0.6  0.1 -0.3  0.5 -0.  -2.7  0.1 -1.3 -0.2  7.2 -0.2 -0.7 -0.2 -0.3  0.2 -0.5 -0.   2.7 -0.2 -1.  -0.  -0.4  0.2  1.8 -0.4 -0.4 -0.6 -0.1  4.3 -0.4 -1.  -0.4 -1.1 -1.  -0.6 -0.3  2.9  0.1 -0.3  0.1 -0.2 -0.7  1.3  2.5  6.4 -0.6 -0.1 -0.2 -0.6 -0.9 -0.8 -0.3  2.2  2.7  2.8  0.5 -0.6 -0.4  2.2 -0.1 -0.   0.2 -0.1  1.8 -0.2 -0.3 -0.9 -0.1  0.2 -3.2  0.5 -1.2  0.1 -0.1 -0.2 -1.4  1.1  0.3  1.6 -0.9  4.8  0.4 -0.1 -0.1 -0.1 -0.1 -0.3 -0.4 -1.4 -0.4 -0.1  0.5 -1.6 -0.3 -0.1 -0.2  6.5 -0.6 -0.2 -0.4  0.2 -1.3 -0.5 -1.2 -0.  -0.1 -0.  -0.3 -0.7  0.9  5.3 -0.2  1.2 -0.3 -0.2 -0.4 -0.1  0.2 -0.5 -0.1  7.7  0.4  5.1  3.7 -0.1  3.7 -1.3 -0.1 -0.4 -0.5  1.6 -0.1 -0.7 -0.4 -0.5  2.1 -0.4  3.3 -0.2 -0.7  0.8 -0.  -0.5 -0.4  0.2  1.3 -0.4  3.6  1.5  0.1  0.  -0.2 -0.4 -0.9 -0.3  1.5  0.6  0.7 -0.1 -0.1 -0.4 -0.2  1.7 -0.2  0.4 -0.1 -0.2 -0.7  0.  -0.1  1.9 -1.1 -0.4  4.8  0.9 -1.1 -0.3 -0.9 -1.4 -0.4 -0.4  1.8 -0.6 -0.6  1.5 -0.2 -0.2 -0.9 -0.9  1.7 -1.2 -0.6 -0.7  1.  -0.3 -0.4 -0.1 -0.4 -0.5 -0.2 -1.7  0.4 -0.1  2.9 -0.2  0.3  4.7 -0.8  0.2 -0.9 -0.3  2.8 -0.1 -0.1 -0.1 -1.7 -0.5 -0.3 -1.   2.8  3.2 -1.7 -0.1 -0.1  5.3 -0.4 -0.2 -0.2  1.7 -0.5 -0.8  1.3 -1.   4.  -0.7 -0.2 -0.3  0.1 -0.1  5.9 -0.3 -0.1 -0.1 -0.9 -0.2  3.1 -0.5 -0.7 -0.3  3.8  3.3]
ty_50sample [[7 8 6 5 9 4 1 3 2 2]
 [2 3 4 1 1 8 5 6 6 7]
 [6 4 9 7 0 1 2 3 5 8]
 [3 6 4 7 8 9 5 1 2 0]
 [8 5 7 1 2 6 3 0 4 4]
 [0 6 4 2 7 3 8 9 1 5]
 [4 9 6 1 2 8 7 5 3 3]
 [0 1 1 4 7 9 3 8 5 2]
 [7 4 2 9 5 3 0 6 8 1]
 [7 6 1 2 3 4 8 9 0 5]]
tt_50sample [[7 6 8 5 9 4 0 1 3 2]
 [2 3 4 8 9 1 0 5 6 7]
 [6 4 9 7 0 1 2 3 5 8]
 [3 6 4 7 8 9 5 1 2 0]
 [8 5 7 1 2 6 3 0 9 4]
 [0 6 4 2 7 3 8 9 1 5]
 [4 9 6 1 2 8 7 5 0 3]
 [0 1 6 4 7 9 3 8 5 2]
 [7 4 2 9 5 3 0 6 8 1]
 [7 6 1 2 3 4 8 9 0 5]]
vm  [ 2.2  0.3 -1.7 -3.8 -1.  -0.2 -0.1 -0.5 -1.  -0.5  2.5 -0.7 -0.1 -0.2  7.4 -0.2  2.  -0.8 -0.6  2.6 -0.5 -0.5  2.3  0.2 -1.2  1.8  1.   0.  -1.3 -0.6  3.  -0.5 -0.8 -0.8  0.8  0.4  3.5  1.  -1.8 -1.1 -0.5  5.8  3.2  3.2 -0.5  1.6 -3.8 -0.6  5.6  4.9 -0.5 -0.9 -0.6  8.8  0.8 -1.  -0.6  2.  -0.5 -0.4  0.7  0.3 -0.2  3.1 -0.9  2.9  0.1 -0.8 -0.5  2.2 -0.4  2.7 -0.6 -0.3 -5.  -0.3 -0.3  0.3  0.6  0.3 -3.5 -0.2  0.5 -0.2 -1.1  6.3  4.6 -0.1 -0.1 -0.2 -0.3 -0.4 -0.6  2.2 -0.6  1.3  0.9 -2.3  0.4  0.1  1.  -0.  -0.5 -0.3  0.3  1.8 -2.5  3.1  1.   0.2 -0.8 -0.1 -0.4 -0.5  0.1 -1.  -0.7 -0.  -0.2 -0.7 -0.  -0.2 -0.5 -0.8 -0.2  8.  -0.5 -2.3  2.7  4.5  2.7 -0.7 -0.4 -0.3  3.3 -0.3 -0.5 -0.3 -0.1 -0.2 -0.2 -0.8 -0.6 -0.2 -0.1 -0.6 -0.4 -0.6  5.9  1.1  4.5 -0.4  4.5 -1.  -0.4  0.1 -0.9  0.9 -0.2 -0.6 -0.2  0.6 -0.6 -0.4 -0.4  0.2 -0.6 -0.8  1.7 -1.1  1.4  1.9 -0.2 -0.5 -0.1 -1.1 -0.1 -1.2  6.7 -0.9 -2.4  0.1 -0.8 -1.2  2.  -0.6  0.9 -0.5 -0.2  1.3 -0.1 -0.3  3.3 -0.9  1.3 -0.5 -1.5 -0.  -0.1  0.3 -0.1  0.1 -0.1 -0.2 -0.4 -3.7 -0.1 -0.1 -1.1  0.1 -0.7 -1.2 -0.6 -1.1  0.2 -0.9 -0.7 -0.5 -0.5 -0.9 -0.1  1.1 -0.4 -0.4  2.3 -0.1  2.3 -0.5  0.6  4.5 -0.9 -0.3 -0.1 -0.7  4.1  5.3  0.8 -1.9  1.4 -4.3 -0.4 -2.3 -0.  -0.1 12.1  8.  -0.5  1.4 -0.7 -0.2  8.4 -0.2 -1.6 -0.1 -0.1 -1.1]
vy_50sample [[5 4 0 2 8 6 7 3 9 1]
 [0 5 4 8 1 6 3 2 7 9]
 [9 4 8 3 2 5 6 7 7 1]
 [5 3 0 4 2 8 6 1 9 7]
 [3 8 1 6 4 5 7 2 0 9]
 [1 4 6 2 3 9 0 8 5 7]
 [0 9 3 4 5 8 2 2 6 6]
 [8 1 2 3 7 9 6 0 4 5]
 [6 4 7 9 2 2 1 0 8 5]
 [2 6 9 5 4 3 8 1 7 0]]
vt_50sample [[5 4 0 2 8 6 3 7 9 1]
 [5 0 4 8 1 6 3 2 7 9]
 [9 4 8 3 2 5 6 7 0 1]
 [5 3 0 4 2 8 6 1 9 7]
 [3 8 1 6 4 5 7 2 0 9]
 [1 4 6 2 3 9 0 8 5 7]
 [0 9 3 4 5 8 1 2 7 6]
 [8 1 2 3 7 9 6 0 5 4]
 [6 4 7 3 2 9 1 0 8 5]
 [2 6 5 9 4 3 8 1 7 0]]
Epoch 15210: Training cost= 0.3543, Training acc= 0.7990, Validation cost= 0.3393, Validation acc= 0.7992
Epoch 15220: Training cost= 0.3171, Training acc= 0.7990, Validation cost= 0.3903, Validation acc= 0.7993
Epoch 15230: Training cost= 0.3235, Training acc= 0.7991, Validation cost= 0.3298, Validation acc= 0.7993
Epoch 15240: Training cost= 0.3483, Training acc= 0.7991, Validation cost= 0.3216, Validation acc= 0.7994
Epoch 15250: Training cost= 0.3797, Training acc= 0.7992, Validation cost= 0.4163, Validation acc= 0.7994
Epoch 15260: Training cost= 0.3360, Training acc= 0.7992, Validation cost= 0.3545, Validation acc= 0.7995
Epoch 15270: Training cost= 0.3105, Training acc= 0.7993, Validation cost= 0.3008, Validation acc= 0.7995
Epoch 15280: Training cost= 0.3710, Training acc= 0.7993, Validation cost= 0.3041, Validation acc= 0.7995
Epoch 15290: Training cost= 0.4077, Training acc= 0.7993, Validation cost= 0.3517, Validation acc= 0.7996
Epoch 15300: Training cost= 0.3991, Training acc= 0.7994, Validation cost= 0.3926, Validation acc= 0.7996
tm  [-1.4 -0.8 -1.9 -2.3 -0.8 -0.1 -0.4 -0.5 -0.4  0.8 -3.9  0.3 -0.9 -0.1  1.6 -0.8 -0.3 -0.2 -0.6  2.3 -0.7 -0.5  3.4 -0.1 -0.6  0.2 -0.3 -0.2 -0.8 -1.5 -0.9 -0.3 -0.7 -5.1  0.  -0.4  0.3  1.6  0.6 -0.2 -0.   2.8  0.   3.9 -1.  -0.6 -1.9 -0.3 -0.9  9.3 -0.2 -0.4 -1.6  4.2 -0.5  0.  -0.9  0.7  3.8  3.5  9.5 -0.1 -0.6  0.5 -1.  -0.6 -0.1  1.4  1.4 -0.6 -0.3  1.1 -0.1 -0.6 -4.8 -0.3  1.  -0.3  1.2 -0.2 -5.5  0.  -0.5  1.4  0.5  3.  -0.5 -0.2 -0.  -0.2 -0.1 -0.3 -0.8 -0.2 -0.8 -0.4 -0.1 -2.   0.1 -0.3 -0.  -0.5  2.8 -0.4 -0.3 -0.8 -3.  -1.  -1.6  1.7  0.4 -0.5  0.  -0.9  4.5 -0.7 -0.5  0.3 -0.3  0.9 -0.3 -0.8  0.1 -0.5 -0.4  2.1  0.3 -0.3  4.   3.4 -1.  -0.5 -0.3 -0.1  0.6 -5.8 -0.3 -0.3 -0.4  0.   1.9 -0.8 -0.3 -0.3 -0.5 -0.7 -0.1  0.4  5.2 -0.5  1.9 -0.6  1.9  0.1 -0.1 -0.3  1.  -0.7  2.6 -0.3 -0.2 -1.5 -0.4 -0.3 -1.  -0.3 -0.4  1.8 -0.4 -0.4  0.   1.8 -0.4 -0.1 -0.2 -1.3  0.  -1.6  1.3  0.2 -1.2 -0.4 -0.2 -1.3  1.5  0.8 -1.5 -0.2 -0.4  5.9 -0.5 -0.8 -0.2 -1.3 -2.6 -0.7 -1.9 -0.5 -0.3 -0.2 -0.3 -0.1 -0.5 -0.7  0.  -3.8 -0.3 -0.2  4.6 -0.2 -0.6 -0.7 -0.5  4.1 -0.1 -0.  -1.1 -0.7 -0.2 -0.2 -0.7 -0.4 -0.3 -1.  -0.6  1.  -1.4  0.9 -0.6  0.1 -1.1  2.5 -0.3  2.4  1.4  5.1  2.2 -2.9  0.7 -3.5 -0.3 -1.7 -0.5 -0.3 16.9  4.1  1.1 -0.6 -0.9 -0.1 13.1 -0.   0.4 -0.5  2.6 -0.8]
ty_50sample [[8 1 0 5 4 3 2 7 6 9]
 [3 1 9 5 7 6 2 0 8 4]
 [7 5 1 9 6 0 4 8 2 3]
 [3 9 8 1 6 2 2 5 7 4]
 [5 8 9 3 2 6 1 4 7 0]
 [0 3 1 1 7 9 2 4 6 5]
 [1 5 8 7 9 4 6 2 0 3]
 [9 4 0 0 2 8 7 3 5 6]
 [1 5 5 3 7 8 0 0 2 4]
 [8 2 7 4 3 5 1 6 0 9]]
tt_50sample [[8 1 0 5 4 3 2 7 6 9]
 [3 1 9 5 7 6 2 0 8 4]
 [7 5 1 9 6 0 4 8 2 3]
 [3 9 8 1 6 0 2 5 7 4]
 [5 8 9 3 2 1 6 4 7 0]
 [0 8 3 1 7 9 2 4 6 5]
 [1 5 8 7 9 4 6 2 0 3]
 [9 4 1 0 2 8 7 3 5 6]
 [1 5 3 6 7 8 0 9 2 4]
 [8 2 7 4 3 5 1 6 0 9]]
vm  [-0.7 -0.3 10.8  9.5 -2.  -0.1  0.  -0.2 -0.2  0.1  8.7 -0.2 -0.3 -0.1  8.4 -0.6  0.4 -0.1 -0.3 -0.5 -0.5 -0.5 -0.9 -0.4 -0.5  1.1 -0.5 -0.2 -1.6 -1.7 -0.2  0.2 -0.2 11.9  2.  -0.1  1.1  3.   2.2 -0.4 -0.1 -0.6 -1.  -0.7 -0.6 -0.4  0.2 -0.6 -0.3 -1.7 -0.6 -0.7 -0.6  5.4  0.6 -1.  -0.8  1.9  2.2  2.2  2.8 -0.2 -0.1  2.7  1.1 -0.7  0.  -0.1 -0.5 -0.5 -0.1  4.2 -0.4 -0.1 -3.6 -0.6 -0.4 -0.1 -0.5 -0.3  7.9  0.2 -0.6 -0.7 -0.8 -1.  -0.8 -0.2 -0.4 -0.4 -0.2 -0.9 -0.4 -0.1 -0.4 -0.  -0.3 -1.2 -0.  -0.3 -0.6  4.3  1.4 -0.4 -0.1  0.5 -2.  -0.1  0.8 -1.   1.2  0.4 -0.  -0.6  5.  -2.3 -0.5  1.7  0.  -0.6 -0.   3.7 -0.4  0.2 -0.5  9.7 -1.  -1.1 -0.1  3.3 -0.3 -0.  -0.7  1.8 -3.6  5.3 -0.5 -0.1 -0.1 -0.3 -0.7 -0.2 -1.  -0.6  0.4 -0.2 -0.4 -0.2 -2.  -0.4 -0.7  0.3 -1.  -0.3 -0.2  0.4 -0.4  0.   1.3 -0.4 -0.6 -0.9 -0.2  0.3  2.6 -0.2 -1.4  0.4 -0.5  1.3 -0.8 -0.8  0.7 -0.2 -0.2  6.7 -0.6 -0.5  0.5 -0.6 -0.3 -0.2  0.2 -1.  -0.1 -0.7 -0.  -0.9  0.5  5.6 -0.4 -0.1 -0.2 -0.2 -0.1  0.7 -1.3 -0.7 -0.3  0.2  0.7 -0.2 -0.1 -0.2 -0.2 -1.5 -0.3 -0.3  0.  -0.  -0.3 -1.5 -0.2  0.9 -0.4  0.1  3.1 -0.4 -1.  -0.3 -0.  -0.5  0.1 -0.8  0.1 -1.5  0.1  2.2 -0.8 -0.1 -0.7  1.  -0.4 -0.3  1.9 -2.9  1.1 -1.4 -0.3  5.5 -0.3  3.5 -0.4 -0.1 -1.3  0.  -0.4 -0.3 -0.5  0.2 -2.  -0.3  2.1 -0.2 -0.4 -0.1]
vy_50sample [[0 7 2 1 3 9 6 5 8 4]
 [3 5 7 1 0 6 8 8 9 2]
 [5 7 7 4 1 9 9 3 6 0]
 [3 3 1 1 4 2 7 8 5 9]
 [6 5 1 3 7 2 9 4 8 0]
 [3 6 8 7 4 2 1 9 0 5]
 [2 3 0 1 8 7 5 4 9 6]
 [0 4 5 9 8 2 3 7 1 6]
 [0 8 5 5 3 9 2 1 1 7]
 [6 7 1 1 5 8 3 2 9 9]]
vt_50sample [[0 7 2 1 3 9 6 5 8 4]
 [3 5 7 1 0 4 6 8 9 2]
 [5 7 4 2 8 1 9 3 6 0]
 [3 6 1 0 4 2 7 8 5 9]
 [6 5 1 3 2 7 9 4 8 0]
 [3 6 8 7 4 2 1 9 0 5]
 [2 0 3 1 8 7 5 4 9 6]
 [0 4 5 9 8 2 3 7 1 6]
 [0 8 5 6 3 9 4 2 1 7]
 [6 7 0 1 5 8 3 2 9 4]]
Epoch 15310: Training cost= 0.3186, Training acc= 0.7994, Validation cost= 0.3787, Validation acc= 0.7997
Epoch 15320: Training cost= 0.3860, Training acc= 0.7995, Validation cost= 0.3300, Validation acc= 0.7997
Epoch 15330: Training cost= 0.3744, Training acc= 0.7995, Validation cost= 0.3218, Validation acc= 0.7997
Epoch 15340: Training cost= 0.3556, Training acc= 0.7995, Validation cost= 0.3012, Validation acc= 0.7998
Epoch 15350: Training cost= 0.3231, Training acc= 0.7996, Validation cost= 0.3709, Validation acc= 0.7998
Epoch 15360: Training cost= 0.3347, Training acc= 0.7996, Validation cost= 0.3442, Validation acc= 0.7999
Epoch 15370: Training cost= 0.3213, Training acc= 0.7997, Validation cost= 0.3569, Validation acc= 0.7999
Epoch 15380: Training cost= 0.2995, Training acc= 0.7997, Validation cost= 0.3618, Validation acc= 0.8000
Epoch 15390: Training cost= 0.3347, Training acc= 0.7997, Validation cost= 0.3503, Validation acc= 0.8000
Epoch 15400: Training cost= 0.3341, Training acc= 0.7998, Validation cost= 0.2716, Validation acc= 0.8001
tm  [-0.8 -0.6  2.  -1.9 -1.5 -0.  -0.1 -0.4 -0.1  0.1 -0.2  1.9 -1.1 -0.2  8.8 -2.   0.1 -0.2 -0.   3.1 -0.6 -0.2 -0.9 -0.1 -1.1  1.6 -0.4 -0.5 -1.7 -1.6  2.4 -0.1  0.7  5.8 -0.  -0.3  0.8 -1.3 -4.2 -0.5 -0.2  1.4 -0.1 -1.  -0.7 -0.3 -2.7  0.2 -0.7 -1.7 -0.6 -0.8 -0.9  2.4  1.  -1.  -1.1  2.6  2.2 -0.7  9.8 -0.1  0.1  2.4 -0.4 -0.4 -0.3  0.2 -0.1 -0.3 -0.2  4.4 -0.1 -0.6 -6.2 -0.5  1.9 -0.3 -0.1 -0.2 -0.6 -0.1  0.2 -0.5 -0.1  1.7 -0.6 -0.1 -0.5  0.  -0.5 -0.7 -0.6  0.3 -0.6 -0.3  1.  -2.1 -0.1 -0.3 -0.1 -0.1  2.6 -0.4 -0.3 -0.3 -3.4  2.6 -0.3  3.4  0.8  1.  -0.4 -0.7  6.  -1.9 -0.3  1.5  0.4  0.6 -0.2 -1.  -0.1  0.4 -0.3  9.7 -0.2  0.2  1.3  6.4 -0.3 -0.1 -0.7 -0.2  7.8 14.6 -0.3 -0.4 -0.1 -0.4  1.7 -0.3 -0.1 -0.1 -0.1 -0.5  0.1 -0.1  2.5 -0.5  2.  -0.3 -1.8  0.9 -0.5 -0.2 -0.4 -0.3 -1.2 -0.  -0.3  0.8 -0.1 -0.3 -0.3 -0.6 -1.   1.7 -0.6 -0.4 -0.4 -0.  -0.2 -0.3 -0.3  0.2 -1.7 -1.5 11.6  0.6 -1.1 -0.1 -0.1 -1.2  1.2 -0.9 -1.5 -0.7 -0.2  5.2  0.1 -0.3  1.3 -0.9 -2.8  1.2 -2.5 -0.9 -0.2 -0.   0.1  0.4  0.6 -0.4  0.5 -4.  -0.3 -0.3 -2.4  0.3 -0.7 -1.5 -0.3  3.4 -0.4 -0.4  4.3 -0.6 -1.  -0.2 -0.4 -0.1  0.8 -1.   2.8 -1.7 -1.4  0.4 -0.6 -0.1 -0.   2.1 -0.5 -1.7  3.2 -0.2  1.7 -3.   0.6 -3.3 -0.3 -1.9 -0.8 -0.1  3.5  7.1 -0.3 -0.4 -0.7  0.4  0.6 -0.6 -3.  -0.2  3.5 -2. ]
ty_50sample [[0 6 1 5 3 7 4 8 2 9]
 [7 8 9 9 3 6 5 1 0 4]
 [0 4 7 2 8 3 5 6 6 1]
 [1 2 5 0 0 8 6 4 7 9]
 [2 3 0 9 5 7 6 8 1 4]
 [9 1 2 6 7 5 0 3 8 4]
 [4 8 3 6 2 0 7 9 5 1]
 [9 9 3 0 1 7 8 2 5 4]
 [1 2 8 0 7 3 4 6 5 9]
 [8 9 5 0 1 6 3 2 7 4]]
tt_50sample [[0 6 1 5 3 7 4 8 2 9]
 [7 8 2 9 3 6 5 1 0 4]
 [0 4 7 2 8 3 5 6 9 1]
 [1 2 5 3 0 8 6 4 7 9]
 [2 3 0 9 5 7 6 8 1 4]
 [9 1 2 6 7 5 0 3 8 4]
 [4 8 3 6 2 0 7 9 5 1]
 [9 6 3 0 1 7 8 2 5 4]
 [1 2 8 0 7 3 4 6 5 9]
 [8 9 5 0 1 6 3 2 7 4]]
vm  [-1.  -0.3  2.2  5.7 -1.2 -0.1 -0.1 -0.4 -0.7 -0.6  2.   2.2 -1.1 -0.2 -0.4 -0.7  0.5 -0.2 -0.1 -1.2 -0.6 -0.2 -1.4 -0.4 -1.2  0.3 -0.1 -0.3 -0.5 -0.5  2.8 -0.2  1.5  6.8 -0.9  0.5  2.2 -1.2 -1.  -0.2 -0.3  2.3  1.7 -1.2 -0.3 -0.4  4.6  0.9 -0.8 -2.5 -0.8 -0.5 -0.3 -1.5 -0.9  1.5 -0.6  4.7 -0.6 -0.7  2.4 -0.2 -0.6 -0.1 -0.1 -0.3 -0.4 -0.1 -0.  -0.3 -0.1  0.1 -0.1 -0.5 -1.2 -0.1  1.3 -0.4 -0.2 -0.4 13.  -0.2 -0.9 -0.   0.6  3.2 -0.5 -0.2  0.  -0.  -0.7  0.4 -0.1  1.8 -0.3 -0.5  1.3 -0.5 -0.3 -0.6  3.  -0.5  1.2 -0.4 -0.5 -0.4 -1.3  3.   0.5 -1.3  0.9 -0.4 -0.4 -0.3  0.6  1.6 -0.3 -0.6 -0.1  0.2 -0.3  5.7  0.7 -0.1 -0.3 -0.5  3.   8.6  0.5  1.6 -0.1 -0.3 -0.4 -0.5  8.1 15.9 -0.2 -0.4 -0.1 -0.7  0.7  0.9  1.2  0.1 -0.4 -0.4  0.5 -0.4  4.7 -0.5 -0.5 -0.3 -1.9  0.8 -0.3 -0.4 -0.2 -0.3 -1.3 -0.4 -0.5  2.2 -0.3 -0.2 -0.6 -0.2 -0.   0.9 -0.7  0.7 -0.5  0.4 -0.4 -0.4 -0.2 -1.  -1.6 -0.6  4.1  0.8 -1.6 -0.2 -0.  -1.  -0.3 -0.4 -0.3 -0.6 -0.5  2.8 -0.  -0.1 -0.8 -0.8 -0.2  1.7 -0.4 -0.1 -0.3 -0.5 -0.3 -0.5 -0.1 -0.2  0.6 -1.1  0.7 -0.3 -4.5  0.1 -0.7 -0.  -0.4  3.3 -0.3 -0.1  4.9 -0.5 -0.2 -0.4 -0.4 -0.2  0.3 -0.5  2.1 -0.7 -1.3 -0.3  0.1 -0.1 -0.1  0.1 -0.3 -2.9  0.2 -0.2 -0.2 -0.6 -0.4 -1.  -0.2 -0.6 -0.6 -0.1 -2.7 -1.1 -0.1 -0.5 -0.6 -0.2 -3.1 -0.8 -0.7 -0.5  4.9  0.1]
vy_50sample [[6 5 1 3 9 0 7 4 2 8]
 [2 8 4 0 9 7 6 6 3 1]
 [9 4 1 2 0 3 5 7 6 6]
 [0 5 7 4 1 3 8 6 6 2]
 [3 1 8 0 7 4 9 5 2 6]
 [7 1 2 6 8 5 9 4 0 3]
 [0 6 9 5 3 2 8 4 1 7]
 [4 8 8 0 2 9 5 6 1 7]
 [2 8 4 9 1 5 6 0 7 3]
 [3 0 9 2 2 6 5 1 4 8]]
vt_50sample [[6 5 1 3 9 0 7 4 2 8]
 [2 8 4 0 9 7 5 6 3 1]
 [9 4 1 2 0 3 5 7 6 8]
 [0 5 7 4 1 3 6 9 8 2]
 [3 1 8 0 7 4 9 5 6 2]
 [7 1 2 6 8 5 9 4 0 3]
 [0 6 9 5 3 2 8 4 1 7]
 [4 8 3 0 2 9 5 6 1 7]
 [2 8 9 4 1 5 6 0 7 3]
 [3 0 9 2 7 6 5 1 4 8]]
Epoch 15410: Training cost= 0.3278, Training acc= 0.7998, Validation cost= 0.3410, Validation acc= 0.8001
Epoch 15420: Training cost= 0.3434, Training acc= 0.7999, Validation cost= 0.3450, Validation acc= 0.8001
Epoch 15430: Training cost= 0.2912, Training acc= 0.7999, Validation cost= 0.3473, Validation acc= 0.8002
Epoch 15440: Training cost= 0.2796, Training acc= 0.8000, Validation cost= 0.3085, Validation acc= 0.8002
Epoch 15450: Training cost= 0.3453, Training acc= 0.8000, Validation cost= 0.3521, Validation acc= 0.8003
Epoch 15460: Training cost= 0.4063, Training acc= 0.8000, Validation cost= 0.3638, Validation acc= 0.8003
Epoch 15470: Training cost= 0.3362, Training acc= 0.8001, Validation cost= 0.3581, Validation acc= 0.8003
Epoch 15480: Training cost= 0.3575, Training acc= 0.8001, Validation cost= 0.3239, Validation acc= 0.8004
Epoch 15490: Training cost= 0.3663, Training acc= 0.8002, Validation cost= 0.3536, Validation acc= 0.8004
Epoch 15500: Training cost= 0.3538, Training acc= 0.8002, Validation cost= 0.2829, Validation acc= 0.8005
tm  [ 2.5  0.3 -0.1 -1.5 -0.7 -0.4 -0.4 -0.7 -0.7 -0.2  4.1 -0.5  0.3 -0.1  5.   3.7  1.  -0.2 -0.   3.1 -0.6 -0.4 -0.3 -0.2 -1.  -0.4 -0.7 -0.4 -0.4 -0.2 -0.9 -0.3 -0.2 -2.7 -0.2 -0.2  3.1  0.1 -4.7 -0.7 -0.5  0.2  0.8 -1.3 -0.5  0.1 -2.9 -1.   3.2 -0.2 -0.6 -0.4 -1.2 12.8 -1.2 -0.5 -0.6  3.9 -0.6  3.4  1.2 -0.3 -1.  -0.2 -0.5 -0.5 -0.1  1.1 -0.2 -0.6 -0.2 -0.4 -0.2 -0.4 -6.4 -0.3 -1.  -0.2 -0.7 -0.1 -4.9 -0.3 -0.2  1.  -1.   0.7  2.3  0.   0.9 -0.7 -1.   1.4  0.7  4.4 -0.9  0.7 -0.1 -2.1 -0.2 -0.4  1.8 -1.5 -0.8 -0.1  0.4 -0.1 -3.4 -0.7  1.2  2.8 -0.2 -0.4 -0.  -0.5 -0.5  1.7 -0.2 -0.2  0.1  0.5 -0.3 -1.6 -0.3 -0.9 -0.5  5.6  0.3 -3.6 -0.  10.6  3.5 -0.5  1.5 -0.  11.5  7.  -0.3 -0.1 -0.3 -0.9 -0.8 -0.7 -0.7 -0.3 -0.1 -0.1 -0.5 -0.6  4.6 -0.2  0.8  0.   4.7 -0.8 -0.2 -0.2 -0.1 -0.  -1.8 -0.9 -0.7  2.6 -0.3 -0.1 -0.2 -0.2  0.2 -0.3 -0.5 -0.4 -0.2  0.7 -0.5  0.5 -0.2 -1.2 -1.7 -1.9 11.8 -0.7 -1.6 -0.3  1.6 -0.9  0.1  0.6  1.4 -0.2 -0.6  1.8 -0.  -0.2  1.3 -1.2  0.6 -0.1 -2.5  0.8 -0.1 -0.2 -0.3 -0.7  0.9  0.  -0.9 -4.9 -0.1 -0.5 -0.5 -0.5 -0.5 -0.7 -0.7 -1.1 -0.  -0.3  5.4 -0.4 -0.1 -0.   1.  -0.4  1.3 -0.2  1.4  0.7  1.7 -0.1 -0.1  4.8  0.3  3.  -0.1 -0.2 -0.7  1.7  1.  -3.1 -0.2 -5.4 -0.4 -2.7 -0.3 -0.1 15.2  8.9  1.3  1.1 -0.5 -0.1 11.5 -0.2 -3.5 -0.2 -0.1 -3. ]
ty_50sample [[6 2 5 8 8 0 4 7 1 9]
 [4 7 1 0 9 8 2 5 3 6]
 [4 0 9 5 1 2 7 8 3 6]
 [8 1 6 7 2 3 9 0 4 5]
 [4 6 8 1 5 7 3 2 0 9]
 [4 1 9 0 3 8 5 2 7 6]
 [4 5 2 7 3 0 6 1 9 8]
 [2 9 7 6 0 8 5 1 3 4]
 [9 0 5 6 7 3 4 2 8 8]
 [6 3 1 5 0 7 4 8 2 9]]
tt_50sample [[6 2 3 5 8 0 4 7 1 9]
 [4 7 1 0 9 8 2 5 3 6]
 [4 9 0 5 1 2 7 8 3 6]
 [8 1 6 7 2 3 9 0 4 5]
 [4 6 8 1 5 7 3 2 0 9]
 [4 1 9 0 3 8 5 2 7 6]
 [4 5 2 7 3 0 6 1 9 8]
 [2 9 7 6 0 8 1 5 3 4]
 [9 0 5 6 7 3 4 2 8 1]
 [6 3 1 5 0 7 4 8 2 9]]
vm  [-0.8 -0.6 -2.5  4.3 -0.6 -0.6 -0.2 -0.7 -0.2  1.4 -2.1 -0.9 -0.6  0.4 -2.7  1.5 -0.5 -0.2 -0.5 -1.5 -0.6 -0.5  4.1 -0.2 -0.5  0.2 -0.3 -0.2 -0.1 -0.3  0.1 -0.4 -0.3 -3.5  0.5 -0.8  0.7 -0.2  6.7 -0.4 -0.4  2.2 -0.5  1.3 -0.5 -0.1  6.9 -0.3  0.2 11.1 -0.1 -0.3 -0.1 -1.4 -0.7  6.  -0.1 -1.6  2.3  1.2 -0.9 -0.   0.1  0.4 -1.1 -0.5 -0.   0.7  0.3  0.  -0.3 -0.6  0.6  0.2  1.5 -0.4 -0.6 -0.1  1.3 -0.2  1.7 -0.4 -0.2 -0.1 -0.9  3.   1.9 -0.  -0.6 -0.1  2.4 -0.6 -0.5 -1.3  0.4 -0.1 -0.7 -0.5 -0.  -0.3 -0.5  2.7  0.3 -0.1 -0.5  0.4  1.1 -0.1 -1.2 -2.2 -0.7  0.3 -0.1 -0.3  2.   2.4 -0.5 -0.6 -0.2 -0.1 -0.2  7.  -0.  -0.1  1.3 -2.9 -0.2  8.1  1.4 -2.5  1.9 -0.7 -0.1 -0.4  8.3 -1.5 -0.3 -0.4 -0.1  0.9  0.9 -0.6  0.1 -0.3 -0.3  0.3  0.1  0.   1.8 -0.  -0.3 -0.1  2.2 -0.2 -0.   0.9 -0.2 -0.6 -0.3  0.1  1.8  0.   0.1 -0.1 -0.5 -0.4 -0.1  2.6 -0.1  1.2  0.5 -0.7 -0.1 -0.3 -0.2  0.1 -0.4  4.4 -0.8 -0.2  1.4 -0.3 -0.3 -0.9 -0.5 -0.1  2.5  0.  -0.2 -0.  -0.3 -0.3 -1.3 -0.6  6.3 -0.3  3.8 -0.  -0.2 -0.4 -0.6  1.  -0.1 -0.7  0.   4.3 -0.5 -0.   7.5 -0.3 -0.2  3.1 -1.4  3.  -0.2 -0.5 -0.1 -0.3 -0.4 -0.  -1.  -0.6 -0.3 -0.8  4.2  2.3 -1.2  2.5 -0.4  2.  -0.5 -1.3 -0.1  5.  -0.1  6.5  2.3  3.2  2.4 14.5 -0.2  7.2 -0.1 -0.1  0.3 -3.  -0.1 -0.2 -1.4 -0.6 -0.7 -0.1  4.5 -0.1 -0.3 12.6]
vy_50sample [[9 8 4 6 1 0 0 5 7 3]
 [2 3 5 9 1 7 8 4 6 0]
 [1 6 0 4 2 5 7 3 9 8]
 [4 7 6 6 3 5 0 0 1 8]
 [2 8 1 7 5 6 3 4 9 0]
 [0 5 2 3 9 8 1 6 4 7]
 [5 9 7 2 6 3 1 1 8 4]
 [2 5 7 1 4 9 3 0 6 8]
 [5 8 0 9 7 1 3 3 6 4]
 [4 8 3 0 5 6 7 9 1 2]]
vt_50sample [[9 8 4 6 1 0 2 5 7 3]
 [2 3 5 9 1 7 8 4 6 0]
 [1 6 0 4 2 5 7 3 9 8]
 [4 7 9 6 5 3 2 0 1 8]
 [2 1 8 7 5 6 3 4 9 0]
 [0 5 2 3 9 8 1 6 4 7]
 [5 9 7 2 6 3 0 1 8 4]
 [2 5 7 1 4 9 3 0 6 8]
 [5 8 0 9 7 1 2 3 6 4]
 [4 8 3 0 5 6 7 9 1 2]]
Epoch 15510: Training cost= 0.3948, Training acc= 0.8003, Validation cost= 0.3073, Validation acc= 0.8005
Epoch 15520: Training cost= 0.2956, Training acc= 0.8003, Validation cost= 0.2887, Validation acc= 0.8006
Epoch 15530: Training cost= 0.3563, Training acc= 0.8003, Validation cost= 0.3460, Validation acc= 0.8006
Epoch 15540: Training cost= 0.3614, Training acc= 0.8004, Validation cost= 0.3980, Validation acc= 0.8007
Epoch 15550: Training cost= 0.3300, Training acc= 0.8004, Validation cost= 0.3768, Validation acc= 0.8007
Epoch 15560: Training cost= 0.3310, Training acc= 0.8005, Validation cost= 0.3260, Validation acc= 0.8007
Epoch 15570: Training cost= 0.3772, Training acc= 0.8005, Validation cost= 0.3272, Validation acc= 0.8008
Epoch 15580: Training cost= 0.3610, Training acc= 0.8005, Validation cost= 0.3362, Validation acc= 0.8008
Epoch 15590: Training cost= 0.3204, Training acc= 0.8006, Validation cost= 0.2865, Validation acc= 0.8009
Epoch 15600: Training cost= 0.3130, Training acc= 0.8006, Validation cost= 0.3078, Validation acc= 0.8009
tm  [ 0.2  0.9  4.   4.  -1.4 -0.2 -0.1 -0.  -0.8 -0.7  3.9  1.1 -0.2 -0.4  2.1  3.7 -0.  -0.6 -0.3 -2.1 -0.6  0.7 -1.3 -0.2 -0.9 -0.7 -0.3 -0.3  3.   2.9  4.9 -0.3  2.8 11.2 -0.9  1.   2.5 -0.5 -0.1 -0.5  1.6 -1.8  0.3 -0.4 -0.1 -0.4  8.4 -0.2 -0.1 -3.1 -0.8 -0.3 -0.1 -1.7 -1.7 -0.  -0.2 -0.2 -1.1 -1.6 -1.6 -0.5 -0.3 -0.6  1.7 -0.7 -0.2  0.1 -0.2 -0.4 -0.2 -1.6 -0.6 -0.5 -0.4 -0.4 -0.6 -0.5 -0.6 -0.3 16.1 -0.  -1.1 -0.2 -0.6 -1.4  2.7  0.7  1.1 -0.4 -0.5  2.1  1.4  2.4  0.  -0.4 -0.4 -0.   0.2  0.2  3.4  0.1 -0.7 -0.3 -0.5 -0.6 -0.5  4.2  0.9 -2.1  0.3 -0.7 -0.2 -0.9 -0.9  8.5  0.7 -0.3 -0.2 -0.7 -0.2  7.1 -0.1 -0.1 -0.5  2.5  3.1  7.9 -0.8  3.4  1.4 -0.3  0.6 -0.3 -0.1 14.6  0.2 -0.2 -0.6 -0.9 -0.2  1.7  0.3 -0.3 -0.3 -0.3 -0.5 -0.4 -0.9  0.2 -0.6 -0.2 -0.  -0.4 -0.4 -0.1 -0.4 -0.1 -1.6 -0.4 -1.   0.1 -0.4 -0.3  0.4  1.5  0.6  0.3 -0.5  0.5 -0.8 -0.7 -0.2 -0.4  0.   3.6 -1.8 -0.3  1.2 -0.4 -0.8  1.   0.1 -0.8 -1.4 -0.2  4.4 -0.9 -0.7 -0.8 -0.3  1.6 -1.1 -0.9  8.4  2.9 -0.   1.6 -0.4 -0.4 -0.2 -0.5  0.4 -0.4 -1.   1.  -0.1 -0.4 -1.  -0.1 -0.1  4.9 -0.4 -0.3  0.7  0.4  2.  -0.2 -0.  -0.1 -0.3 -0.3 -0.2 -0.5 -0.2  2.8 -0.6 -0.5 -0.4  2.2 -0.4  1.2 -0.1 -0.7 -1.3 -0.2 -0.7 -0.1 -0.   9.4 -0.3  4.7 -0.4 -0.2 -3.3 -1.2 -0.5 -0.4 -0.4  0.3 -4.  -0.   0.5 -0.3  3.7 -0.2]
ty_50sample [[3 7 6 9 4 5 2 1 8 0]
 [9 7 3 6 4 0 2 8 1 5]
 [7 4 9 1 0 0 6 3 5 2]
 [9 3 5 4 1 2 7 7 6 8]
 [0 0 2 7 8 5 3 9 4 4]
 [3 4 6 9 0 5 1 2 7 8]
 [3 1 5 7 8 4 9 6 0 2]
 [9 2 3 0 7 1 5 8 6 4]
 [2 0 7 1 5 4 9 6 8 3]
 [6 9 5 4 3 0 1 8 7 2]]
tt_50sample [[7 3 6 9 4 5 2 1 8 0]
 [9 7 3 4 6 0 8 2 1 5]
 [7 4 8 9 1 0 6 5 3 2]
 [9 3 5 4 1 2 7 0 6 8]
 [0 6 2 7 8 5 3 9 1 4]
 [3 4 6 9 0 5 1 2 7 8]
 [3 1 7 5 8 4 9 6 0 2]
 [9 2 3 0 7 1 5 8 6 4]
 [2 0 7 1 5 4 9 6 8 3]
 [6 9 5 3 4 0 1 8 7 2]]
vm  [-0.7  2.4  5.  10.8 -1.1 -0.3 -0.  -0.1 -0.9 -1.  -1.3  1.2 -0.8 -0.3 -0.6  2.5 -0.3 -0.4  0.3 -1.2 -0.4 -0.1 -0.3  0.1 -1.2  0.6 -0.3 -0.2  2.6  1.7 -0.2 -0.5  1.6  4.1 -1.4 -0.   1.9 -1.1  0.6 -0.3 -0.3 -1.4  1.3 -1.2 -0.1 -0.1  6.   1.  -0.1 -0.7 -0.6 -0.1  3.6 -2.3 -1.4  1.6 -0.   1.9 -1.1  2.2 -0.9 -0.4  0.2 -0.3 -0.2 -0.1  0.1 -0.4  0.5  0.5 -0.1 -1.4 -0.1 -0.1  3.8  0.3 -0.6 -0.3 -0.4  0.4  9.5 -0.1 -0.3  0.2 -0.3 -0.8 -0.3 -0.1  1.2 -0.1  0.6  1.8  1.3  0.6  0.5 -0.2  0.6  0.2 -0.5  0.1  4.   0.1 -0.3 -0.1 -0.4  0.3  2.4 -0.3 -0.6 -1.7 -0.5 -0.3 -0.3  0.  -1.   8.5  0.4 -1.  -0.3 -0.3 -0.1  6.  -0.1  0.6  0.2 -0.9  4.2 10.7 -0.8 -0.2  1.2 -0.5  0.2 -0.5  5.   9.3  0.  -0.1  0.2 -0.6  2.1 -0.4  2.  -0.1 -0.5  0.  -0.1 -0.3 -0.7 -0.1 -0.9 -0.1  1.1  0.6 -0.2 -0.1 -0.4 -0.4 -1.2 -0.4 -0.4  3.2 -0.1 -0.  -0.4 -0.4  2.7  1.5 -0.2  2.  -0.7 -0.7 -0.4 -0.4 -0.1  2.4 -1.3  3.   1.   0.2 -0.3  0.5 -0.3 -1.2 -1.2  0.1  2.7 -0.4 -0.3 -0.5 -0.2  0.5 -1.1 -0.9  5.3  2.   3.8  1.8 -0.1 -0.4 -0.1 -0.2 -0.3 -0.5 -0.1  5.3  0.1 -0.1  3.2 -0.2 -0.   5.5 -0.8  2.8 -0.6 -0.2  5.1 -0.1  0.5  0.5 -1.2 -0.4 -0.5 -0.2  1.1  4.2 -1.4 -0.   1.4  0.8  1.6 -1.1 -0.2  2.3 -0.8 -1.  -0.4  5.   1.4 11.3 -0.2  5.7 -0.2 -0.2 -1.6 -2.6 -0.1  0.2 -0.5 -0.5 -2.4 -0.5  0.5 -0.1  4.6  2.6]
vy_50sample [[9 9 3 7 1 8 5 4 2 0]
 [7 4 2 9 9 6 8 1 0 5]
 [4 3 2 6 1 0 5 9 7 8]
 [5 0 3 8 9 1 2 6 7 4]
 [6 0 3 5 1 4 4 8 2 9]
 [4 7 8 9 1 3 2 6 5 0]
 [2 7 6 5 5 9 3 1 0 4]
 [0 0 2 6 6 8 8 9 4 1]
 [5 8 7 3 9 0 6 4 1 2]
 [9 3 0 2 8 4 6 6 1 7]]
vt_50sample [[6 9 3 7 8 1 5 4 2 0]
 [7 4 2 9 3 6 8 1 0 5]
 [4 3 2 6 1 0 5 9 7 8]
 [5 0 3 8 9 1 2 6 7 4]
 [6 0 3 5 1 7 4 2 8 9]
 [4 7 8 9 1 3 2 6 5 0]
 [2 7 6 8 5 9 3 1 0 4]
 [0 5 7 2 6 3 8 9 4 1]
 [5 8 7 3 9 0 6 4 1 2]
 [3 9 0 2 8 4 5 6 1 7]]
Epoch 15610: Training cost= 0.3313, Training acc= 0.8007, Validation cost= 0.2808, Validation acc= 0.8010
Epoch 15620: Training cost= 0.3813, Training acc= 0.8007, Validation cost= 0.3626, Validation acc= 0.8010
Epoch 15630: Training cost= 0.3192, Training acc= 0.8007, Validation cost= 0.3148, Validation acc= 0.8010
Epoch 15640: Training cost= 0.3254, Training acc= 0.8008, Validation cost= 0.3710, Validation acc= 0.8011
Epoch 15650: Training cost= 0.3961, Training acc= 0.8008, Validation cost= 0.3424, Validation acc= 0.8011
Epoch 15660: Training cost= 0.4852, Training acc= 0.8008, Validation cost= 0.3354, Validation acc= 0.8011
Epoch 15670: Training cost= 0.4124, Training acc= 0.8009, Validation cost= 0.3419, Validation acc= 0.8012
Epoch 15680: Training cost= 0.3228, Training acc= 0.8009, Validation cost= 0.3509, Validation acc= 0.8012
Epoch 15690: Training cost= 0.3326, Training acc= 0.8010, Validation cost= 0.3015, Validation acc= 0.8013
Epoch 15700: Training cost= 0.2774, Training acc= 0.8010, Validation cost= 0.3699, Validation acc= 0.8013
tm  [-0.2 -0.2 -1.1 -0.2 -1.3 -0.5 -0.1 -0.3 -0.1 -1.1 -0.9  3.  -0.7 -0.1 -0.6  0.6 -0.1 -0.3 -0.2 -0.5 -0.8  0.9 -0.6 -0.3 -0.9  1.1 -0.2 -0.2  0.7 -1.2  3.1 -0.3 -0.4 -0.1 -0.6 -0.2  0.4  2.   8.9 -0.8  0.7 -0.3  0.4  5.8 -0.3 -0.   2.6  0.5  1.5 -1.4 -0.8 -0.3  1.3 -1.  -1.3  1.9 -0.2  1.   1.6 -0.4 -0.3 -0.7  0.5  0.7  0.2 -0.9 -0.1  1.   0.8 -0.3 -0.1 -0.5  0.2 -0.1 -2.   0.1 -0.8 -0.6 -0.3 -0.2  3.5 -0.2 -0.2 -0.1 -0.9 -0.2  1.5 -0.2  1.  -0.3 -0.3 -0.1 -0.  -0.3 -0.5 -0.3 -0.3 -1.2 -0.2 -0.2  3.4 -1.4 -0.5 -0.4 -0.2 -0.2 -1.2  2.6 -0.5 -0.7 -0.4 -0.3 -0.3 -1.1  0.6  3.9  0.   1.2 -0.2  1.6 -0.2  1.9 -0.3 -0.4 -0.5 -0.5  1.9  5.9  5.2  4.3 -0.4 -0.8  0.3 -0.2 -2.2 -2.4 -0.1 -0.4  0.5 -0.5  1.5 -0.3  1.3  0.2 -0.4  0.3 -0.3 -0.6  3.7 -0.3  0.6 -0.   3.3  1.1 -0.2 -0.3 -0.2  1.3  3.7 -0.4 -0.8 -1.8  0.1 -0.3 -0.2 -0.3  0.6  0.7 -0.3  0.3 -0.5  0.5 -0.4 -0.  -0.2 -0.9  0.5 -0.4 -1.4 -0.  -1.4 -0.  -0.3 -1.4 -0.2 -0.1  2.1 -0.3 -0.2  5.  -0.4 -0.1 -1.1 -1.4  3.2 -0.9 -0.3 -0.5 -0.1 -0.4 -0.4 -0.1 -0.3 -0.8 -0.6 -0.7 -0.  -0.3 -1.4 -0.  -0.4  3.7 -0.6 -0.  -0.  -0.1 -1.5 -0.6  0.7  1.3 -0.9 -0.4  0.7 -0.9 -2.   2.6 -1.4 -0.2 -0.   4.9 -0.8 -0.2 -0.2 -1.  -0.1  4.1  0.4 -0.5  1.5 -0.8 -0.1 -0.6 -0.3 -0.  -0.2 -1.4 -0.2 -0.4 -0.8 -0.2 -1.3 -0.7  7.5 -0.5  5.4 -0.8]
ty_50sample [[3 5 4 9 8 7 1 0 2 6]
 [1 8 7 2 4 0 9 3 5 6]
 [1 0 3 4 7 2 6 9 9 5]
 [7 9 4 5 8 1 0 2 6 3]
 [1 9 8 4 2 5 3 7 0 0]
 [2 8 4 3 7 5 6 0 1 9]
 [1 5 4 2 0 6 8 9 7 3]
 [9 5 4 3 7 2 0 1 1 6]
 [5 6 4 0 1 3 2 7 9 8]
 [1 5 2 9 6 0 4 7 3 8]]
tt_50sample [[3 5 4 9 8 7 1 0 2 6]
 [1 8 7 2 4 0 9 3 5 6]
 [1 0 3 4 7 2 6 9 8 5]
 [7 9 4 5 8 1 0 2 6 3]
 [1 9 8 4 2 5 3 7 6 0]
 [2 8 4 3 7 5 6 0 1 9]
 [1 5 4 2 0 6 8 9 7 3]
 [9 5 4 3 2 7 0 8 1 6]
 [5 6 4 0 1 3 2 7 9 8]
 [1 5 2 9 6 0 4 7 3 8]]
vm  [-1.1 -0.1 -0.2  6.  -1.   0.  -0.3 -0.3  0.9 -0.8  7.4 -0.2  0.7 -0.  -1.   6.7 -0.  -0.   0.4 -0.5 -0.8  0.7 -0.3 -0.4 -1.3  2.1 -0.1 -0.1  1.6 -1.9 -0.2 -0.8 -0.3 -1.  -0.2 -0.1  0.4  7.2  7.7 -0.1  0.6 -0.5 -0.6  1.9 -0.7 -0.1  2.2 -1.3 -0.8 -0.7 -0.5 -0.5  0.5  5.9 -1.5  2.7 -0.5  3.   3.   2.6  3.8 -0.5  1.2  1.1  1.  -0.5 -0.   2.2 -0.8 -0.7 -0.1 -0.6 -0.1 -0.1 -2.4  1.1 -0.2 -0.3 -0.4 -0.1  3.4 -0.1 -0.1 -0.2 -0.1 -0.2 -1.1 -0.   0.5 -0.3 -0.3 -0.5 -0.2 -0.4 -0.5 -0.3  0.1 -1.1 -0.2 -0.2  2.7 -1.5  1.  -0.4 -0.5  0.3 -1.4 -0.2  2.5 -0.6 -0.3 -0.2 -0.4 -0.6  0.7  4.4 -0.  -0.5 -0.   1.1 -0.3  1.4 -0.1 -0.  -0.  -1.   1.  -1.3  3.8  2.5 -1.1 -0.5 -0.5  0.4 -0.6 -1.8 -0.  -0.2  2.1 -0.2 -1.  -0.2 -1.  -0.2 -0.1 -0.1  0.5 -0.1  3.9 -0.3 -0.4 -0.1 -0.3 -0.5 -0.  -0.1 -0.4  0.9  3.9 -0.4 -0.3 -1.6  0.1 -0.3 -0.2 -0.6  0.3  0.5 -0.3  1.4 -0.3 -0.3 -0.7  0.2 -0.3 -0.8 -0.1 -0.  -1.1 -0.3 -0.7  0.1 -0.2 -1.3 -0.2 -0.4 -0.5 -0.3 -0.6  8.1 -0.1 -0.3 -1.  -0.6 -0.6 -0.7 -0.4 -0.3 -0.1 -0.3 -0.1 -0.3 -0.3 -0.5 -0.1 -0.8  0.  -0.3 -0.3 -0.1 -0.5  3.2 -0.4  4.4 -0.5  0.2 -0.3 -0.6 -0.5 -0.  -0.1 -0.5  0.5 -0.8 -1.3  2.3  2.1  4.4  0.2  1.1 -0.8 -0.1 -0.3 -0.1 -0.4  1.4  0.5 -0.9 -0.6  1.4 -0.4  0.8 -0.4 -0.2 -0.1 -1.4 -0.1 -0.3 -0.9 -0.4 -1.1 -0.1  5.7  0.1 -0.2 -0.2]
vy_50sample [[2 1 3 9 5 8 4 4 0 6]
 [0 9 2 8 4 3 5 1 6 7]
 [5 0 4 9 1 7 8 3 6 2]
 [9 0 1 4 8 2 3 7 6 5]
 [9 1 6 4 8 7 0 5 2 3]
 [0 5 4 7 3 1 8 2 9 6]
 [3 9 7 6 8 0 5 1 2 4]
 [9 6 7 2 5 1 3 8 0 4]
 [6 9 8 1 7 2 5 4 3 0]
 [3 6 4 7 5 0 8 1 9 2]]
vt_50sample [[2 1 3 9 5 8 0 4 7 6]
 [0 9 2 8 4 3 5 1 6 7]
 [5 0 4 9 1 7 8 3 6 2]
 [9 0 1 4 2 8 3 7 6 5]
 [9 1 6 4 8 7 0 5 2 3]
 [0 5 4 7 3 1 8 2 9 6]
 [3 9 7 6 8 0 5 1 2 4]
 [9 6 7 2 5 1 3 8 0 4]
 [6 9 8 1 7 2 5 4 3 0]
 [3 6 4 7 5 0 8 1 2 9]]
Epoch 15710: Training cost= 0.4039, Training acc= 0.8010, Validation cost= 0.3386, Validation acc= 0.8013
Epoch 15720: Training cost= 0.3661, Training acc= 0.8011, Validation cost= 0.3394, Validation acc= 0.8014
Epoch 15730: Training cost= 0.3685, Training acc= 0.8011, Validation cost= 0.2709, Validation acc= 0.8014
Epoch 15740: Training cost= 0.3081, Training acc= 0.8012, Validation cost= 0.3128, Validation acc= 0.8015
Epoch 15750: Training cost= 0.2992, Training acc= 0.8012, Validation cost= 0.3377, Validation acc= 0.8015
Epoch 15760: Training cost= 0.4000, Training acc= 0.8013, Validation cost= 0.3323, Validation acc= 0.8016
Epoch 15770: Training cost= 0.3626, Training acc= 0.8013, Validation cost= 0.3204, Validation acc= 0.8016
Epoch 15780: Training cost= 0.3544, Training acc= 0.8013, Validation cost= 0.2993, Validation acc= 0.8016
Epoch 15790: Training cost= 0.3297, Training acc= 0.8014, Validation cost= 0.3773, Validation acc= 0.8017
Epoch 15800: Training cost= 0.3523, Training acc= 0.8014, Validation cost= 0.4206, Validation acc= 0.8017
tm  [ 3.2 -0.1 -0.6 -1.1 -0.6 -0.5 -0.2 -0.2 -0.3 -0.5  4.3 -0.3 -0.1 -0.4  2.4  2.7  1.4 -0.3 -0.1  2.4 -0.9  0.2 -0.7 -0.3 -1.1  0.9 -0.4 -0.4 -0.4 -0.8 -0.2 -0.5  1.1 -2.1  0.4 -0.4  1.1 -0.1 -4.  -0.7 -0.3 -1.6 -0.5 -0.9 -0.4 -0.1 -2.2 -0.8  4.2 -1.2 -0.5 -0.5 -0.7  9.4 -0.7 -0.1 -0.5 -0.1  1.   2.3 -0.1 -0.4 -0.4  1.3 -0.4 -0.3 -0.1  1.3 -0.4 -0.2 -0.1  0.2 -0.  -0.4 -5.8  0.1 -1.2 -0.3 -0.5 -0.4 -2.7 -0.  -0.1  0.4 -1.3 -1.8  2.9 -0.2  0.4 -0.4 -0.7 -0.1  0.6  1.3 -0.6  0.  -0.3 -2.  -0.4 -0.2  1.  -2.  -1.  -0.3 -0.2  0.5 -2.9 -0.1  1.6  1.7 -0.1 -0.2 -0.4 -0.6  1.2  0.1 -0.2  0.9  0.2  1.5 -0.1 -1.1 -0.4 -0.7 -0.4  2.6 -0.3 -2.5  0.5  9.9  3.7 -0.6  1.  -0.1 12.3  9.5 -0.4 -0.1 -0.  -0.4 -0.6 -0.9 -0.6 -0.1 -0.2 -0.2 -0.1 -0.8  2.3 -0.1  1.5 -0.2  5.  -0.5 -0.1 -0.  -0.2  0.6 -1.8 -0.6 -0.4  2.7 -0.1 -0.3 -0.2 -0.3  0.6 -0.  -0.4 -0.2 -0.5 -0.4 -0.6  0.3 -0.2 -0.1 -1.8 -1.3 10.5 -0.3 -0.4 -0.1 -0.1 -0.9 -0.1  0.   2.4 -0.  -0.5  3.5 -0.2 -0.1 -0.2 -0.9  2.2 -0.4 -1.8 -0.4  0.1 -0.2  0.1 -0.5  0.4 -0.2 -1.  -3.3 -0.3 -0.5  3.7 -0.5 -0.4 -0.4 -1.1 -1.1 -0.4 -0.   4.5 -0.5 -0.4 -0.1 -0.3 -0.2  0.  -0.7  0.6 -0.1  0.1  0.3 -0.2  5.9  2.3  2.4 -0.3  3.4 -0.2  2.7  1.6 -2.5  0.1 -1.1 -0.3 -0.5 -0.3 -0.1  9.8  4.4  0.2 -0.2 -1.  -0.2  6.1 -0.5 -2.9 -0.1  1.2 -2.7]
ty_50sample [[6 3 2 0 8 4 5 7 9 1]
 [6 0 2 5 1 1 4 8 7 3]
 [9 5 4 4 0 1 6 2 3 7]
 [3 3 0 7 4 9 8 6 5 1]
 [8 3 6 1 9 0 4 5 7 2]
 [0 9 3 8 2 1 7 5 6 4]
 [0 7 9 2 3 4 1 8 5 6]
 [1 3 2 7 5 0 8 4 9 6]
 [9 0 4 4 5 3 2 8 7 7]
 [9 1 1 4 3 5 7 7 6 8]]
tt_50sample [[6 3 2 0 8 4 5 7 9 1]
 [6 0 2 5 1 9 4 8 7 3]
 [9 5 4 8 0 1 6 2 3 7]
 [3 2 0 7 9 4 8 6 5 1]
 [3 8 6 9 1 0 4 5 7 2]
 [0 9 3 8 2 7 1 5 6 4]
 [0 7 9 2 3 4 1 8 5 6]
 [1 3 2 7 5 0 8 9 4 6]
 [9 0 1 4 5 3 8 2 7 6]
 [9 2 1 4 3 5 7 6 8 0]]
vm  [-1.3  2.9  5.8  7.9 -1.5  0.6 -0.3 -0.2 -1.8 -0.5  6.4 -1.1  1.5  0.1  2.1  4.7 -0.1 -0.4  0.5 -2.2 -0.7 -0.4  4.   1.  -1.9  1.1 -0.5  0.1 -1.3  1.6 -0.8  1.7 -0.6  3.2 -0.7  2.5  7.3  3.2  2.3 -0.3 -0.1  5.   3.1 -0.2 -1.   0.3  4.8 -1.1 -1.2  9.1 -0.6 -0.2 -0.6  3.8 -1.  -0.2 -1.   4.1 -2.   3.8  2.7  0.7 -1.3 -0.4 -0.5  2.8 -0.1 -0.7 -0.5 -0.2  0.6  1.6 -0.3 -0.4  3.   0.3  3.3 -0.2  0.8  1.2  0.9 -0.5 -0.8  0.5  3.3  6.8 -0.8  0.1 -0.4  0.6 -0.7  1.2 -0.5  3.   0.1  0.8  1.3  0.2 -0.2 -0.   2.9  6.5  2.8  0.8  2.6 -0.5 -0.4 -0.3  2.8 -2.4 -0.9 -0.2  1.   1.1 -0.8  1.7 -0.3 -2.1 -0.4 -1.  -0.7  8.8 -0.9 -0.3 -0.4  3.   1.6 -0.9 -1.2 -2.  -0.5 -0.1 -0.6 -0.3 -0.7  0.6  1.3  0.1 -0.2 -0.9 -0.9 -0.4 -1.1 -0.2  0.5 -0.8 -0.5  1.   0.5  1.8 -0.9 -0.2 -0.5 -1.2 -0.3 -0.6 -0.1 -0.1  0.1 -0.6 -0.7  0.9 -1.2 -0.1 -0.9  2.2  0.6 -0.3 -0.   1.1  1.7 -0.2  0.4 -0.2 -0.   1.3 -0.6 -0.5  1.  -1.2 -1.8 -0.   1.7 -0.8 -0.1 -0.7 -0.8 -0.9 -0.4 -0.3 -0.4 -0.   0.2 -0.7 -0.4  3.2  0.   5.1 -0.5  0.5 -0.4 -0.7 -0.1 -0.6  1.9 -1.4 -0.5  0.9 -0.1  1.1  1.1 -0.7 -0.3  3.2 -0.1 -0.7  2.1 -0.6 -0.2 -0.5 -0.   2.3 -0.  -0.6  3.4  1.4  4.   2.   3.3 -1.2 -0.8 -0.7 -0.4 -0.   2.9 -1.3 -0.3  1.2 -0.2  0.5 -0.5  0.6 -0.4 -0.3  1.3 -0.  -0.1  1.1 -0.3 -0.2 -0.6 -0.1  1.5 -0.5 -1.1 11.2]
vy_50sample [[2 1 7 5 8 6 0 4 4 3]
 [9 2 5 1 0 4 8 3 6 7]
 [4 1 0 0 7 7 6 8 3 2]
 [2 1 8 5 7 3 9 0 4 6]
 [4 8 5 6 1 7 2 3 0 9]
 [3 6 9 0 1 4 8 7 2 5]
 [2 9 0 5 7 3 6 8 1 4]
 [1 9 0 6 2 8 5 7 7 3]
 [8 6 2 9 3 4 0 7 5 1]
 [8 9 6 4 5 3 1 7 0 2]]
vt_50sample [[2 1 7 5 6 0 8 9 4 3]
 [9 2 5 1 0 4 8 3 6 7]
 [4 1 0 5 9 7 6 8 3 2]
 [2 1 8 5 7 3 9 0 4 6]
 [4 8 5 6 1 7 2 3 0 9]
 [3 6 9 0 1 4 8 7 2 5]
 [2 9 5 7 0 6 3 8 1 4]
 [1 9 0 6 2 8 5 7 4 3]
 [8 6 2 9 3 4 0 7 5 1]
 [8 9 6 4 5 3 1 7 0 2]]
Epoch 15810: Training cost= 0.3732, Training acc= 0.8015, Validation cost= 0.2973, Validation acc= 0.8017
Epoch 15820: Training cost= 0.3078, Training acc= 0.8015, Validation cost= 0.2913, Validation acc= 0.8018
Epoch 15830: Training cost= 0.3900, Training acc= 0.8015, Validation cost= 0.3382, Validation acc= 0.8018
Epoch 15840: Training cost= 0.3797, Training acc= 0.8016, Validation cost= 0.3650, Validation acc= 0.8019
Epoch 15850: Training cost= 0.3277, Training acc= 0.8016, Validation cost= 0.3795, Validation acc= 0.8019
Epoch 15860: Training cost= 0.2863, Training acc= 0.8017, Validation cost= 0.3981, Validation acc= 0.8019
Epoch 15870: Training cost= 0.3211, Training acc= 0.8017, Validation cost= 0.3139, Validation acc= 0.8020
Epoch 15880: Training cost= 0.3800, Training acc= 0.8017, Validation cost= 0.3281, Validation acc= 0.8020
Epoch 15890: Training cost= 0.3235, Training acc= 0.8018, Validation cost= 0.2894, Validation acc= 0.8021
Epoch 15900: Training cost= 0.3466, Training acc= 0.8018, Validation cost= 0.2724, Validation acc= 0.8021
tm  [-1.5 -1.  -1.6 -1.1 -0.7  0.  -0.3 -0.3 -0.1  1.  -3.6  1.3 -1.2 -0.3 -0.2 -2.2 -0.2 -0.2 -0.   0.1 -0.7 -0.4  1.1 -0.5 -0.7  2.1 -0.4 -0.3 -1.4 -2.7 -0.3 -0.2 -0.9 -3.3 -0.1 -0.3  1.  -0.3  2.7 -0.5 -0.3 -0.6 -0.6  3.5 -0.9 -0.2 -1.1  1.  -1.3  1.7 -0.3 -0.5 -1.  -0.5 -0.1  1.3 -1.  -0.2  5.4  2.1  8.4  0.1 -0.2  1.7 -0.7 -0.4 -0.1  0.6  0.9 -0.1 -0.2  3.8 -0.5 -0.2 -4.3 -0.4  0.  -0.5  0.3  0.1 -2.8  0.3 -0.3 -0.2  1.5 -0.6 -0.8 -0.2 -0.1 -0.6 -0.5 -1.  -0.4 -0.6 -0.7 -0.5 -0.4 -1.8 -0.1 -0.3 -0.4 -1.6  3.4 -0.1 -0.3 -0.5 -2.5 -0.2 -1.2 -0.4  0.4 -0.2 -0.2 -0.5  7.2 -1.8 -0.3  2.3 -0.2  0.6 -0.1  0.8  0.3 -0.3 -0.3 -0.3 -0.3  5.   4.5  4.9 -1.3 -0.6 -0.5 -0.2  1.5 -3.7 -0.6 -0.1  0.1 -0.5  2.5 -0.9 -0.1 -0.3 -0.2 -0.5 -0.1 -0.1  3.3 -0.5  1.8 -0.2 -0.4  1.1 -0.2 -0.2 -0.   0.1  2.3 -0.3 -0.5 -1.6 -0.2 -0.4 -1.  -0.4 -0.8  3.2 -0.6 -0.4 -0.4 -0.1 -0.1 -0.1 -0.1 -0.6  1.2 -1.2 -0.  -0.1 -0.8  0.6 -0.1 -1.   2.  -0.3 -1.4  1.1 -0.3  8.9 -0.5 -0.3 -0.6 -1.1 -2.3 -0.6 -1.5 -0.9 -0.  -0.1 -0.   0.1 -0.1 -0.5  0.5 -2.5 -0.3 -0.2  4.4 -0.1 -0.6 -1.2 -0.6  4.1 -0.1 -0.  -1.  -0.5 -0.3 -0.5 -0.7 -0.5 -0.1 -1.1 -1.  -0.7 -1.6  0.4 -0.4  0.5 -1.   0.9 -0.3  2.4  3.4  3.6  1.6 -1.9  1.2 -0.9 -0.3 -0.4 -0.5 -0.3  9.6  2.4  0.2 -0.3 -0.7  0.   6.1 -0.5  2.2 -0.4  4.6 -1.3]
ty_50sample [[1 0 8 3 4 5 9 9 6 2]
 [6 2 0 1 3 9 8 4 4 5]
 [3 2 1 4 5 9 8 6 0 7]
 [0 3 9 5 7 2 1 1 4 8]
 [6 1 1 0 9 7 5 2 3 3]
 [2 1 4 0 6 6 8 7 5 3]
 [6 7 5 8 8 0 9 4 2 3]
 [6 5 8 1 1 9 0 7 4 3]
 [6 0 9 4 1 2 8 3 5 7]
 [8 5 2 1 1 4 6 3 0 7]]
tt_50sample [[1 0 8 3 4 5 9 7 6 2]
 [6 2 0 1 3 9 8 4 7 5]
 [2 3 1 4 5 9 8 6 0 7]
 [0 9 3 5 7 2 1 6 4 8]
 [6 1 4 0 9 7 5 2 3 8]
 [2 1 0 4 9 6 8 7 5 3]
 [6 7 5 8 1 0 9 4 2 3]
 [6 5 8 2 1 9 0 7 4 3]
 [6 0 9 4 1 2 8 3 5 7]
 [8 5 2 1 9 4 6 3 0 7]]
vm  [-0.7 -0.5 -0.8  6.9 -0.4 -0.5 -0.  -0.3 -0.6  1.3 -1.9 -1.   0.7 -0.3 -2.   3.7 -0.3  0.8 -0.1 -1.1 -0.9 -0.6  4.2 -0.4 -0.8 -0.1 -0.6 -0.4 -0.  -0.2 -1.7 -0.4  1.1 -5.4  0.2 -0.4  1.4  0.3 -1.  -0.2 -0.1  2.6 -0.3 -0.9 -0.5 -0.5  3.  -0.8 -0.2 13.6 -0.4 -0.6 -1.   1.2 -0.9  4.3 -0.6 -0.1  1.1  4.9  0.4 -0.1 -0.4  0.2 -1.5 -0.6 -0.2  0.7 -0.2 -0.5 -0.4 -0.3  0.4 -0.  -2.  -0.3 -0.1  0.   0.5 -0.4 -2.3 -0.1 -0.6 -0.1 -0.6  2.9 -0.3 -0.1 -0.6 -0.7  1.  -0.2 -0.3 -0.2 -0.2 -0.1 -0.2 -1.2 -0.5 -0.5 -0.6  2.5  0.1 -0.  -0.2 -0.3 -0.8 -1.7 -0.7 -1.7 -0.5 -0.4 -0.1 -0.5  0.7  2.5 -0.3 -0.6  0.4  0.9 -0.2  4.5 -0.4 -0.2  0.  -2.1 -0.4  1.1 -0.  -1.4  1.4 -0.4 -0.1 -0.5 12.7 -0.7 -0.  -0.2 -0.6  2.1 -0.4 -0.7 -0.7 -0.2 -0.2  0.6 -0.2 -0.2  2.3 -0.  -0.4 -0.1  1.9 -0.5  0.  -0.3 -0.3 -0.7 -1.  -0.2  1.2  1.8 -0.3 -0.3 -1.1 -0.4 -0.2  0.8 -0.3  0.6  0.9 -0.8 -0.3 -0.  -0.1 -0.4 -1.3  0.8  3.7 -0.6  0.7 -0.   0.4 -0.2 -0.5  1.8  1.3  0.3 -1.   0.5 -0.1 -0.5 -0.9 -0.5  2.1 -0.3 -0.   0.2 -0.5 -0.2 -0.4 -0.2  0.3 -0.3 -0.2 -0.6 -0.6 -0.2  8.4 -0.3 -0.   1.3 -0.9  2.9 -0.3 -0.4  4.4 -0.3 -0.5 -0.4 -0.2 -0.2 -0.6 -1.1  5.1  1.3 -0.4  3.  -0.6  0.1  0.7 -0.4 -0.4  5.5 -0.5  3.3  1.4 -0.5  0.1  8.1 -0.2  4.3 -0.3 -0.3  7.5 -1.5 -0.1 -0.4 -0.9 -0.2  4.8 -0.1 -0.7  1.5 -0.8  9.1]
vy_50sample [[8 6 2 9 1 0 4 5 7 3]
 [9 8 1 6 4 2 0 7 5 3]
 [1 4 2 3 5 7 9 8 0 6]
 [4 1 8 5 6 7 0 2 9 3]
 [9 7 7 6 2 1 5 0 4 8]
 [1 2 8 3 6 7 5 9 4 0]
 [4 9 6 5 0 1 2 3 8 7]
 [9 2 6 5 3 7 8 1 4 0]
 [1 3 2 6 5 5 8 4 7 0]
 [7 4 9 3 8 2 0 1 5 6]]
vt_50sample [[8 6 2 9 1 0 4 5 7 3]
 [9 8 1 6 4 2 0 7 5 3]
 [1 4 2 3 5 7 9 8 0 6]
 [4 1 8 5 6 7 0 2 9 3]
 [9 3 7 6 2 1 5 0 4 8]
 [1 2 8 3 6 7 5 9 4 0]
 [4 9 5 6 1 0 2 3 8 7]
 [9 2 6 5 3 7 8 1 4 0]
 [1 3 2 6 5 9 8 4 7 0]
 [7 4 3 9 8 2 0 1 5 6]]
Epoch 15910: Training cost= 0.3036, Training acc= 0.8019, Validation cost= 0.3734, Validation acc= 0.8021
Epoch 15920: Training cost= 0.3012, Training acc= 0.8019, Validation cost= 0.3360, Validation acc= 0.8022
Epoch 15930: Training cost= 0.3225, Training acc= 0.8020, Validation cost= 0.3225, Validation acc= 0.8022
Epoch 15940: Training cost= 0.3354, Training acc= 0.8020, Validation cost= 0.3780, Validation acc= 0.8023
Epoch 15950: Training cost= 0.2912, Training acc= 0.8020, Validation cost= 0.3508, Validation acc= 0.8023
Epoch 15960: Training cost= 0.4104, Training acc= 0.8021, Validation cost= 0.4140, Validation acc= 0.8023
Epoch 15970: Training cost= 0.3251, Training acc= 0.8021, Validation cost= 0.3399, Validation acc= 0.8024
Epoch 15980: Training cost= 0.3301, Training acc= 0.8022, Validation cost= 0.3215, Validation acc= 0.8024
Epoch 15990: Training cost= 0.3078, Training acc= 0.8022, Validation cost= 0.3237, Validation acc= 0.8024
Epoch 16000: Training cost= 0.3281, Training acc= 0.8022, Validation cost= 0.2633, Validation acc= 0.8025
tm  [-0.1  2.8  8.6 10.  -1.4 -0.3 -0.2 -0.3 -1.3 -1.   3.9 -0.3 -0.2 -0.3  5.   3.8  1.  -0.3 -0.3 -0.3 -0.4 -0.4 -0.5 -0.  -1.1 -0.1 -0.2 -0.4 -0.3  0.4 -1.7 -0.4 -0.1  3.3 -1.1  0.4  3.6 -0.1 -1.7 -0.4 -0.4 -1.2  1.7 -2.  -0.1  0.2 -0.7 -0.5  1.8 -1.1 -0.4 -0.5 -0.1  4.7 -1.  -0.5 -0.3  5.3 -1.5  5.4 -0.2 -0.3 -0.2 -0.2 -0.8  0.7 -0.  -0.5 -0.6 -0.1 -0.1 -0.4 -0.1 -0.  -2.6 -0.1 -0.6 -0.3 -1.  -0.1 -0.5 -0.6 -0.5 -0.1 -0.7 -1.1 -0.1  0.3  1.6  0.1 -0.5  1.7  1.1  4.4 -0.5 -0.  -0.1 -1.   0.3 -0.2  4.2 -0.2 -0.3 -0.1 -0.3  1.7 -1.2 -1.1  1.3 -1.3 -0.4 -0.3 -0.1 -0.1 -1.1  3.3 -0.1 -0.7  0.1 -0.5  0.9  3.3 -0.4 -0.4 -0.3  5.6  1.7 -0.8 -1.   7.4  1.9 -0.4  0.4  0.2  4.6  7.8 -0.3  0.4  0.9 -0.2 -0.6 -0.6 -0.5 -0.2 -0.1 -0.3 -0.3 -0.5 -0.4  0.4 -1.1 -0.   2.9 -0.5 -0.4 -0.1 -0.6  1.  -1.3 -0.4 -0.8  3.8 -0.2 -0.  -0.1  0.   1.4 -0.5 -0.1  1.1 -0.5 -0.4 -0.2 -0.2 -0.1  2.6 -1.  -0.4  5.6 -0.7 -0.7  0.2 -0.1 -0.8 -0.5 -0.4  2.2 -0.7 -0.4 -0.  -0.2  0.4 -0.  -0.8  3.4  1.8 -0.3  2.3 -0.1 -0.5  0.1 -0.5  0.6 -0.3 -0.4 -1.2 -0.6 -0.4  2.7 -0.5 -0.5  0.4 -0.5 -0.5 -0.3 -0.   7.4 -0.4 -0.1 -0.3 -0.4 -0.1 -0.4 -0.4  0.4  2.2  0.5 -0.3  0.7  1.3  0.6 -0.1 -0.   2.1 -0.3 -1.9 -0.5 -0.9 -0.1  1.3 -0.2  0.7  0.6 -0.2  3.8  0.5 -0.5  2.  -0.1 -0.5  0.7 -0.4 -1.6 -0.1  1.7 -1.6]
ty_50sample [[6 3 2 7 8 5 9 0 1 4]
 [8 6 4 0 1 2 7 5 3 9]
 [3 6 8 7 4 5 9 1 0 2]
 [8 5 6 9 0 7 3 1 4 2]
 [3 2 6 4 0 1 8 5 7 9]
 [1 0 7 4 6 2 8 3 5 9]
 [1 4 5 7 0 3 9 6 2 8]
 [5 6 0 7 9 3 4 8 1 2]
 [9 6 8 1 3 7 2 4 5 0]
 [2 6 5 4 8 8 7 3 1 1]]
tt_50sample [[6 3 2 7 8 5 9 0 1 4]
 [8 4 6 0 1 2 7 5 3 9]
 [6 3 8 7 4 5 9 1 0 2]
 [8 5 6 9 0 7 3 1 4 2]
 [3 2 6 4 0 1 8 5 7 9]
 [1 0 7 4 6 2 8 3 5 9]
 [1 4 5 7 0 3 9 6 8 2]
 [5 6 0 9 7 3 4 8 1 2]
 [9 6 1 8 3 7 2 4 5 0]
 [2 6 5 4 8 7 9 3 0 1]]
vm  [-0.7  0.7 -2.1 -0.1 -0.9  0.2 -0.4 -0.5 -1.3 -0.8 -0.9 -0.3 -0.5 -0.4 -1.6 -1.5 -0.1 -0.2 -0.1 -0.5 -0.4 -0.5  1.8  1.8 -1.6  5.4 -0.4 -0.1 -2.  -0.6  2.   0.2 -0.5 -2.1 -0.1  2.1  6.2 -0.7  1.2 -0.6 -0.3  1.1  1.4  1.7 -0.6  0.9  1.3  0.9 -0.6  2.6 -0.5 -0.5  0.2 -0.6  1.3  3.1 -1.  -0.6 -1.  -0.2  3.6  0.9 -0.5  0.5 -0.3  1.6 -0.3 -0.4  0.7  1.6 -0.2  4.6 -0.1 -0.5  0.4 -0.4  2.3 -0.3  1.9  1.6  1.2  0.  -0.3  1.7  1.7  1.3  0.6 -0.1 -0.1 -0.5 -0.2 -0.2 -0.5  2.6 -0.3  1.1 -0.  -0.4 -0.1 -0.1  1.7 -0.9  1.  -0.3  0.6  0.3 -0.9  2.9 -0.3 -1.2 -1.1 -0.1 -0.   2.5  2.3 -1.9 -0.7 -0.9 -0.3 -0.2 -0.   4.5  0.1 -0.1 -0.2 -1.7 -0.   4.3 -0.7  0.  -0.  -0.1 -0.4 -0.2  8.   2.6 -0.3 -0.5  1.1 -1.   2.2 -1.4 -0.1  0.5 -0.2 -0.4  0.3 -0.1  3.4 -0.3  0.2 -0.2 -0.2  0.9  0.1  0.1  0.2 -0.3 -0.5 -0.5  0.2  1.1 -0.3 -0.2 -0.2 -0.7 -0.4  0.  -0.1 -0.2  0.1 -0.2  1.3 -0.2  0.6 -0.6 -0.5  0.4  1.  -0.3 -0.8 -0.2 -0.1 -1.8 -0.3 -0.6 -0.7  1.   1.7  1.5 -0.5 -0.7 -0.1 -1.3 -0.4  3.6 -0.2  1.9 -0.2  0.2  0.1 -0.3 -0.4 -0.5  1.4 -0.9 -0.2 -0.2  2.7 -0.1 -0.6 -1.5 -0.8  4.6 -0.3 -0.7 -0.1 -0.5 -0.6 -0.3 -0.6 -0.1 -0.2 -0.8  1.8 -0.6 -0.7 -0.   0.2 -0.8 -0.7 -0.7 -0.2  2.2  6.2  4.9  2.   0.2  1.5  3.3 -0.5  1.4 -0.4 -0.1  1.8 -0.6  1.2  1.3 -0.6 -0.8 -0.5 -0.2  0.8 -0.5  2.   2.1]
vy_50sample [[0 1 4 6 9 9 5 2 2 7]
 [9 4 5 8 0 7 6 1 3 2]
 [6 2 7 3 9 8 4 5 0 1]
 [6 7 7 9 1 5 0 3 4 2]
 [2 9 1 0 6 7 4 5 8 3]
 [1 9 6 2 5 7 4 0 8 3]
 [0 5 7 2 4 6 8 3 9 1]
 [7 3 0 8 6 2 4 1 9 5]
 [4 0 8 8 5 2 1 7 6 9]
 [8 9 3 3 7 4 2 6 0 1]]
vt_50sample [[0 4 1 6 8 9 3 5 2 7]
 [9 4 5 8 0 7 6 1 3 2]
 [6 2 7 3 9 8 4 5 0 1]
 [6 7 9 8 1 5 0 3 4 2]
 [2 9 1 0 6 7 4 5 8 3]
 [1 9 2 6 5 7 4 0 8 3]
 [0 5 7 2 4 6 3 8 9 1]
 [7 3 0 8 6 2 4 1 9 5]
 [0 4 8 3 5 2 1 7 6 9]
 [8 9 3 5 7 4 2 6 0 1]]
Epoch 16010: Training cost= 0.3320, Training acc= 0.8023, Validation cost= 0.3423, Validation acc= 0.8025
Epoch 16020: Training cost= 0.3000, Training acc= 0.8023, Validation cost= 0.3485, Validation acc= 0.8026
Epoch 16030: Training cost= 0.3411, Training acc= 0.8024, Validation cost= 0.3365, Validation acc= 0.8026
Epoch 16040: Training cost= 0.3232, Training acc= 0.8024, Validation cost= 0.3409, Validation acc= 0.8026
Epoch 16050: Training cost= 0.3824, Training acc= 0.8024, Validation cost= 0.3076, Validation acc= 0.8027
Epoch 16060: Training cost= 0.3176, Training acc= 0.8025, Validation cost= 0.3862, Validation acc= 0.8027
Epoch 16070: Training cost= 0.3494, Training acc= 0.8025, Validation cost= 0.3968, Validation acc= 0.8028
Epoch 16080: Training cost= 0.3654, Training acc= 0.8026, Validation cost= 0.3410, Validation acc= 0.8028
Epoch 16090: Training cost= 0.4254, Training acc= 0.8026, Validation cost= 0.4054, Validation acc= 0.8028
Epoch 16100: Training cost= 0.3764, Training acc= 0.8026, Validation cost= 0.3869, Validation acc= 0.8029
tm  [ 2.7  1.  -0.7  4.1 -1.3 -0.4 -0.3 -0.2 -1.2 -1.3  6.3 -0.4  1.8 -0.2 -1.2  5.9 -0.2 -0.9 -0.  -1.7 -0.6 -0.1  0.2  0.  -1.3  0.6 -0.4 -0.5 -0.2  2.8  4.2 -0.5 -0.6  4.3 -0.6  2.6  4.6  2.4  8.4 -1.   0.6  1.1  2.6  4.3 -0.2  1.1  6.5 -0.7  4.4 -0.3 -0.5 -0.3  0.3 -0.3 -1.1  2.1 -0.6 -0.5 -1.3 -1.1 -2.6 -0.1 -0.6  0.6 -0.5  2.4 -0.3 -0.5 -0.5  1.9  0.4 -0.9 -0.2 -0.1  9.2  0.2 -0.7 -0.2  0.8  1.2 11.9  0.2 -0.8  0.8 -0.9  2.6  5.1 -0.4  0.6 -0.1  0.8  1.5 -0.2  0.   0.5  1.2 -0.1  1.3 -0.3  0.1  4.7  2.5 -1.   0.6  0.9  0.3  3.   4.6  1.9 -2.4 -1.3 -0.3 -0.1 -0.  -1.4  6.7  0.2 -1.  -0.4 -1.1  0.5  9.7 -0.3 -0.8  0.2 -1.2  1.2  2.  -0.1 -1.   1.9 -0.6 -0.2 -0.8 -0.9  2.6  0.1 -0.2 -0.2 -0.6 -0.5 -0.3 -0.4 -0.2 -0.  -0.3 -0.1 -0.3  1.4  0.5 -0.4 -0.2  3.5 -1.3 -0.1 -0.1 -0.2 -0.3  0.6 -0.4 -0.1 -0.3 -0.5 -0.2 -0.1 -0.3  0.5 -0.5  0.  -0.1 -0.2 -0.1 -0.3 -0.2  0.3 -0.  -0.4  2.8 -1.1 -0.9 -1.6 -0.4 -0.3 -1.1 -0.4 -0.1  6.2 -0.5 -0.3 -0.7 -0.  -0.3 -0.6 -0.7 11.9 -0.2  4.6  2.8 -0.1 -0.1 -0.3 -0.7 -0.1 -0.8 -0.4  2.1 -0.1  0.2 -1.1 -0.2 -0.5  2.2 -0.8 -0.9 -0.2 -0.7 -1.  -0.4  0.5 -0.5 -0.3  1.  -0.3 -0.4 -0.3  3.   3.  -0.3  2.4  3.7 -1.  -1.4 -0.1 -0.5  0.1  3.  -0.4  5.7  1.2  7.  -0.3  3.6 -0.4 -0.2 -2.2 -1.8 -0.1  0.5 -0.8 -0.5 -2.8 -0.2  5.9  0.4 -0.3  6.2]
ty_50sample [[9 2 2 5 7 3 6 8 0 1]
 [5 9 8 4 7 7 1 0 6 2]
 [7 4 0 6 8 1 5 9 9 2]
 [6 5 4 0 8 1 3 2 9 7]
 [6 3 8 2 0 4 7 1 9 5]
 [9 8 8 1 3 6 0 2 4 5]
 [7 0 5 1 4 6 2 3 9 8]
 [3 5 2 9 1 7 8 4 0 6]
 [0 3 5 6 6 9 8 2 4 1]
 [8 3 4 0 2 6 5 9 7 1]]
tt_50sample [[9 2 4 7 5 3 6 8 0 1]
 [5 9 8 4 3 7 1 0 6 2]
 [7 4 0 6 8 1 5 3 9 2]
 [6 5 0 4 8 1 3 2 9 7]
 [6 3 8 2 0 4 1 7 9 5]
 [9 7 8 1 3 6 0 2 4 5]
 [7 0 5 1 4 6 2 3 9 8]
 [3 5 2 9 1 7 8 4 0 6]
 [0 3 5 7 6 9 8 2 4 1]
 [3 8 0 4 2 6 5 9 7 1]]
vm  [ 1.4 -0.7 10.7  2.3 -2.  -0.5 -0.2  0.4  0.7  0.7 -1.   0.  -0.9 -0.6 12.9 -0.4 -0.5  0.9 -0.6  1.4 -0.6 -0.   1.2  0.3 -0.4 -0.  -0.6 -0.2 -0.7 -1.4 -1.1  0.2  0.1  7.   1.1 -0.7 -0.6  3.6  2.8 -0.6  0.5 -0.4 -0.7  2.  -0.1 -0.1 -1.1 -0.   4.2  2.7 -0.5 -0.4 -0.7  3.2 -0.2 -1.6 -0.7  2.4  4.2  4.5 -0.2 -0.6  1.7  3.1 -0.7 -0.7 -0.2  0.1 -0.2 -0.4  0.3  0.3 -0.1 -0.  -5.   0.4 -1.1 -0.  -1.1 -0.4 -2.1 -0.1  0.8 -0.3 -1.6 -0.8  0.5 -0.2  0.1 -0.7 -0.4 -0.8 -0.3 -0.5 -0.3 -0.3 -0.  -1.7 -0.3  0.1 -0.4  5.  -0.8  0.  -0.4 -0.2 -2.  -1.1 -0.4  0.1  0.9  0.3 -0.1 -0.8  3.8 -0.9  0.   4.2 -0.1 -0.5 -0.2 -0.7 -0.7 -0.6 -0.3 14.2 -0.6 -0.1  4.2  3.   0.2 -0.4 -0.3 -0.2 -6.3 -3.1  0.1 -0.4 -0.3 -0.3 -0.2 -1.  -0.5 -0.6 -0.3  0.1 -0.2 -0.7 -1.9 -0.1 -0.3 -0.3  4.4 -0.2 -0.5 -0.3 -0.6 -0.4  3.6  0.2 -0.1 -1.9 -0.1 -0.4  1.1 -0.2 -0.5  0.5 -0.3  0.6 -0.6 -0.3 -0.6  0.2 -0.1  5.4 -0.2 -0.6 -0.1 -0.1 -0.4 -0.3 -0.4 -0.6 -0.6 -0.7  2.8 -0.8 -0.4  4.   0.  -0.2 -0.6 -0.7  3.8 -1.5 -1.1 -1.1 -0.3 -0.1 -0.1 -0.3  0.  -0.2 -1.2 -1.7 -0.4 -0.4  5.   0.  -0.6 -0.3 -0.4 -1.1 -0.5 -0.2 -0.2 -0.5 -0.7 -0.5 -1.   0.1 -0.5 -0.3 -1.4  0.3 -0.9 -0.  -0.5  5.  -0.2 -0.1 -0.6  3.1 -0.3 -2.6  0.7 -1.8  1.5  0.5 -0.2 -0.  -0.2 -0.2  7.5 -0.1 -0.6 -0.6 -0.8  0.7  4.8 -0.5  2.4 -0.1  2.  -0.6]
vy_50sample [[7 8 8 3 2 5 9 4 1 6]
 [5 8 6 7 0 3 2 9 4 1]
 [8 5 9 2 0 1 4 7 3 6]
 [5 0 1 6 2 3 9 8 7 4]
 [1 6 2 9 3 8 4 5 7 0]
 [8 6 7 0 2 3 1 4 9 5]
 [8 9 4 1 3 6 0 7 2 5]
 [2 4 1 8 6 7 5 3 9 0]
 [7 9 9 6 1 4 2 2 3 0]
 [7 4 5 9 2 3 1 6 0 8]]
vt_50sample [[7 0 8 3 2 5 9 4 1 6]
 [5 8 6 7 0 3 2 9 1 4]
 [8 5 9 2 0 1 4 7 3 6]
 [5 0 1 6 2 9 3 8 7 4]
 [1 2 6 9 3 4 8 5 7 0]
 [8 6 7 0 2 3 1 4 9 5]
 [8 9 4 1 3 6 0 7 2 5]
 [2 4 1 8 6 7 5 3 9 0]
 [7 5 9 6 1 4 8 2 3 0]
 [7 4 5 9 2 3 1 6 0 8]]
Epoch 16110: Training cost= 0.3128, Training acc= 0.8027, Validation cost= 0.3384, Validation acc= 0.8029
Epoch 16120: Training cost= 0.3118, Training acc= 0.8027, Validation cost= 0.2920, Validation acc= 0.8029
Epoch 16130: Training cost= 0.3289, Training acc= 0.8027, Validation cost= 0.3231, Validation acc= 0.8030
Epoch 16140: Training cost= 0.3413, Training acc= 0.8028, Validation cost= 0.3277, Validation acc= 0.8030
Epoch 16150: Training cost= 0.3822, Training acc= 0.8028, Validation cost= 0.3766, Validation acc= 0.8031
Epoch 16160: Training cost= 0.3754, Training acc= 0.8029, Validation cost= 0.3973, Validation acc= 0.8031
Epoch 16170: Training cost= 0.3283, Training acc= 0.8029, Validation cost= 0.3411, Validation acc= 0.8031
Epoch 16180: Training cost= 0.3455, Training acc= 0.8029, Validation cost= 0.2966, Validation acc= 0.8032
Epoch 16190: Training cost= 0.3510, Training acc= 0.8030, Validation cost= 0.2978, Validation acc= 0.8032
Epoch 16200: Training cost= 0.3192, Training acc= 0.8030, Validation cost= 0.3040, Validation acc= 0.8033
tm  [-1.4 -0.3 -0.6 -0.4 -1.  -0.1 -0.3 -0.4 -0.2 -0.5  1.9  1.1 -0.9 -0.2 -0.1 -0.1 -0.3 -0.4 -0.2 -1.  -0.7 -0.2 -1.3 -0.3 -0.6  1.5 -0.2  0.1 -0.1 -0.7  4.6 -0.6  0.5  6.  -0.6  0.3  1.3 -0.4  2.2 -0.5 -0.4 -3.  -1.1  2.1 -0.9 -0.3  3.8  0.8 -1.3 -2.6 -0.4 -0.3 -0.  -1.2 -1.4  0.9 -0.4 -1.9  1.3 -1.5  4.9 -0.2 -0.1 -0.2  1.4 -0.  -0.1  1.2 -0.1  0.5 -0.1 -0.3 -0.3 -0.  -1.5 -0.3  1.4 -0.5  0.4 -0.2 10.3 -0.4 -0.3 -0.5  1.5 -2.8 -0.3 -0.1  0.4 -0.  -0.5 -0.1  0.6 -0.4 -0.6 -0.2 -0.9 -0.9 -0.2 -0.4  2.5 -1.1  2.7 -0.1 -0.3  1.1 -1.   5.3  0.3 -1.7 -0.3 -0.4  0.2 -0.6  3.4  1.9 -0.   0.5 -0.2 -0.3 -0.   5.9 -0.  -0.  -0.4 -0.2  2.1  7.1 -0.1  4.1 -0.6 -0.7 -0.1 -0.2  1.9  8.1 -0.  -0.1  1.9 -0.5  0.2  0.4 -0.2 -0.1 -0.2 -0.4 -0.1  0.2 -1.3 -0.1  0.2 -0.2 -1.7 -0.  -0.3 -0.4 -0.2 -0.2 -0.3 -0.4 -0.6 -0.1 -0.  -0.1 -0.3  0.5  0.9  4.7 -0.3 -0.4 -1.  -0.9 -0.2  0.3 -0.5  4.2 -0.7 -0.3  0.7 -0.2  2.4 -0.  -0.2 -1.1 -0.1 -0.4 -0.7 -0.4 -0.3  2.9 -0.3  0.3 -0.8 -0.7 -0.9  1.6 -0.2 -0.  -0.4 -0.3 -0.2 -0.1 -0.3 -0.6  0.7 -0.7  0.  -0.1  3.7 -0.3 -0.3  0.8 -0.8  4.9  0.9 -0.  -0.3 -0.7  0.1 -0.  -0.6 -0.  -0.1 -1.  -0.6 -0.2 -1.2  0.8  0.6 -0.1 -0.8 -0.2 -0.3  2.8  0.2  2.5 -0.3 -0.7  0.1 14.  -0.2  6.8 -0.4 -0.2 -2.  -0.9 -0.4 -0.4 -0.8 -0.2 -2.6 -0.1  1.5 -0.4  4.6 -0.5]
ty_50sample [[1 3 4 9 6 7 0 2 8 5]
 [0 1 8 7 6 2 3 4 9 5]
 [2 9 4 3 3 8 6 0 5 7]
 [4 5 7 2 0 6 6 3 8 1]
 [3 8 5 9 6 2 1 0 7 4]
 [3 7 6 9 9 5 2 1 8 4]
 [3 6 9 9 5 7 4 1 0 2]
 [1 1 9 3 8 8 0 6 4 2]
 [2 6 1 5 7 9 9 0 4 8]
 [3 9 9 8 0 0 4 6 7 5]]
tt_50sample [[1 3 4 9 6 7 0 8 2 5]
 [0 8 1 7 6 2 4 3 9 5]
 [2 9 4 1 3 8 0 6 5 7]
 [4 5 2 7 0 9 6 3 8 1]
 [3 8 5 9 6 2 1 0 7 4]
 [3 7 6 0 9 5 2 8 1 4]
 [3 6 8 9 5 7 4 1 0 2]
 [5 1 3 7 9 8 0 6 2 4]
 [2 6 1 5 7 3 9 0 4 8]
 [2 9 3 1 0 8 4 6 7 5]]
vm  [-0.9 -0.1  1.1  1.5 -1.6 -0.3 -0.2 -0.3 -0.7 -0.3  0.2 -0.3 -0.4 -0.5  1.3 -0.7 -0.2 -0.5 -0.2 -0.7 -0.6 -0.5  2.2 -0.1 -1.2  3.5  0.4  0.1 -1.2 -0.9  1.9 -0.3 -0.5  3.6 -0.3  0.3  3.   1.7  6.5 -0.2 -0.4  7.7  3.3  2.9 -0.5 -0.1 -0.1 -0.1  0.4  5.7 -0.8 -0.2  0.8 -0.4 -0.1  0.6 -0.5  4.6 -0.2 -0.1  1.7 -0.2 -0.1  2.6 -0.4  0.8 -0.2 -0.7  0.2  1.6  0.2  2.5 -0.1  0.  -1.4  0.4  1.  -0.4  0.6  0.4  3.7 -0.2 -0.1 -0.3  0.1  8.6 -0.1 -0.3 -0.5 -0.1 -0.  -0.3 -0.5 -0.3 -0.3 -0.1  1.8 -1.2 -0.5 -0.2  1.   5.3  0.8 -0.1 -0.2  1.1 -0.8  2.   0.2 -1.4 -0.5 -0.1 -0.1 -0.3  2.6 -1.  -0.3 -0.4 -0.4 -0.2  0.   4.5 -0.3  0.2 -0.4  1.1  0.1  4.6  2.6 -1.4 -0.7 -0.5 -0.6 -0.6 -2.1 -1.2  0.1 -0.2 -0.2 -0.5  0.8 -0.8  0.1  0.5 -0.3 -0.  -0.1 -0.6  4.6 -0.   0.7 -0.2 -0.2  0.5 -0.4 -0.  -0.6 -0.3  3.9 -0.3  0.  -0.7 -0.1 -0.2 -0.5 -0.5 -0.3 -0.3 -0.1  0.4  0.3  0.3 -0.1 -0.4 -0.1 -0.9  0.3  0.  -0.9 -0.1 -1.7  0.1 -0.2 -1.1 -0.  -0.2 -0.1 -0.7 -0.   2.9 -0.2 -0.2 -0.4 -0.7  0.2 -0.1 -0.1 -0.1 -0.2  0.   0.2 -0.  -0.3 -0.3  0.4 -0.4  0.3  0.1 -2.4 -0.  -0.1 -0.6 -0.5  3.8 -0.5 -0.6 -0.6 -0.6  0.5 -0.5 -0.7  0.2 -0.4 -0.4  1.5 -0.6 -0.9  0.7  1.6 -0.2 -0.5 -0.9 -0.3 -1.6  3.4  0.1  0.6  1.5  0.7 -1.5 -0.2 -0.7 -0.1 -0.2 -0.1 -0.9 -0.2 -0.1 -0.9 -0.1 -1.  -0.4  4.8 -0.   1.3  7.3]
vy_50sample [[5 0 1 9 7 4 8 2 6 3]
 [5 8 0 9 4 6 2 7 3 1]
 [2 3 8 7 5 0 9 1 4 6]
 [1 6 8 0 9 2 4 7 3 5]
 [6 0 4 8 8 3 7 7 1 2]
 [7 9 0 4 2 5 5 8 6 1]
 [8 8 4 0 3 6 7 2 5 1]
 [5 3 7 4 0 9 6 8 1 2]
 [1 4 9 3 0 8 8 7 5 6]
 [7 4 1 1 6 2 8 3 5 9]]
vt_50sample [[5 0 1 9 4 7 8 2 6 3]
 [5 8 0 9 4 6 2 7 3 1]
 [2 3 8 7 5 0 9 1 4 6]
 [1 6 8 0 9 2 4 7 3 5]
 [6 0 4 8 3 5 9 7 1 2]
 [7 9 0 4 2 3 5 8 6 1]
 [9 8 4 0 3 6 7 2 5 1]
 [5 3 7 4 0 9 6 8 1 2]
 [1 4 9 3 0 8 7 2 5 6]
 [7 4 0 1 6 8 2 3 5 9]]
Epoch 16210: Training cost= 0.2779, Training acc= 0.8031, Validation cost= 0.2823, Validation acc= 0.8033
Epoch 16220: Training cost= 0.2804, Training acc= 0.8031, Validation cost= 0.3010, Validation acc= 0.8034
Epoch 16230: Training cost= 0.3913, Training acc= 0.8031, Validation cost= 0.3223, Validation acc= 0.8034
Epoch 16240: Training cost= 0.3440, Training acc= 0.8032, Validation cost= 0.3436, Validation acc= 0.8034
Epoch 16250: Training cost= 0.2688, Training acc= 0.8032, Validation cost= 0.3420, Validation acc= 0.8035
Epoch 16260: Training cost= 0.3451, Training acc= 0.8032, Validation cost= 0.3145, Validation acc= 0.8035
Epoch 16270: Training cost= 0.3262, Training acc= 0.8033, Validation cost= 0.3997, Validation acc= 0.8035
Epoch 16280: Training cost= 0.2888, Training acc= 0.8033, Validation cost= 0.3105, Validation acc= 0.8036
Epoch 16290: Training cost= 0.3174, Training acc= 0.8034, Validation cost= 0.3452, Validation acc= 0.8036
Epoch 16300: Training cost= 0.2876, Training acc= 0.8034, Validation cost= 0.3435, Validation acc= 0.8037
tm  [ 1.1 -0.3 -1.   0.3 -1.  -0.3 -0.1 -0.2 -0.1 -0.9 10.3 -0.9  1.7 -0.1 -0.7  6.  -0.1 -0.8 -0.2 -1.1 -0.8 -0.1 -0.1 -0.2 -1.2 -0.2 -0.2 -0.1 -0.   0.2  5.7 -0.7  0.3  5.4  0.9  1.4  1.4  2.8  2.4 -0.6  0.8  3.4  1.4  2.4 -0.2 -0.1  4.4 -1.1  3.7 -0.5 -0.5 -0.5 -0.3  3.6 -1.   2.1 -0.3  0.3  0.8 -1.9 -1.4 -0.4 -0.3  2.   0.8 -0.1 -0.1  1.  -0.2 -0.1 -0.4 -0.9 -0.1 -0.2 -0.6  0.2 -0.9 -0.1 -0.  -0.1 12.5  0.7 -0.5  0.8 -1.   4.7  3.2 -0.4 -0.1 -0.  -0.3 -0.3 -0.6 -0.6 -0.2 -0.   0.3 -0.9 -0.1 -0.3  2.2  2.6 -1.3 -0.1 -0.2 -0.3 -0.7  4.8  2.1 -1.4 -0.8 -0.3 -0.1 -0.4 -0.2  5.  -0.  -0.2 -0.4 -0.2 -0.1  5.8  0.8 -0.2 -0.1 -0.6 -0.3 -0.6  3.4 -0.9  2.9 -0.8 -0.4 -0.3  3.6  9.6 -0.2 -0.2 -0.3 -0.5 -0.9  0.2 -0.6 -0.1 -0.4 -0.  -0.1 -0.3  3.4 -0.2 -0.  -0.4  1.7 -1.  -0.2 -0.1 -0.2 -0.4 -0.5 -0.   0.1 -0.1 -0.4 -0.3 -0.2 -0.3 -0.1 -0.4 -0.1 -0.2 -0.3  0.3 -0.5 -0.3 -0.2 -0.7 -1.   0.3  0.4 -0.5 -1.6 -0.2 -0.6 -1.2 -0.3 -0.3  5.3 -0.5 -0.4  0.2 -0.2 -0.6 -1.1 -0.7  8.3 -0.8  0.4 -0.  -0.2 -0.2 -0.2 -0.5 -0.3 -0.7 -0.4 -0.8 -0.1  0.7 -2.9 -0.  -0.3  3.8 -0.6 -0.6 -0.2 -0.3 -0.3 -0.6 -0.1 -0.6 -0.1 -0.4 -0.2 -0.9  2.   0.6  2.3  0.1 -0.1  5.3 -1.  -0.6 -0.4 -1.9 -0.1  3.6  1.3  0.1  0.6  0.6 -0.1  0.2 -0.  -0.1 -2.4 -1.1  0.6 -0.3 -1.  -0.2 -3.1 -0.2  2.  -0.1 -0.4  6.1]
ty_50sample [[2 4 5 9 6 7 3 3 8 1]
 [3 7 5 0 6 6 8 4 2 1]
 [0 1 8 4 3 2 5 9 7 6]
 [2 3 1 9 8 6 0 5 7 4]
 [7 9 4 5 8 2 1 6 0 3]
 [4 5 0 8 2 3 6 7 1 9]
 [9 7 8 1 6 5 0 4 2 3]
 [4 2 0 1 3 5 5 8 7 6]
 [5 0 6 2 9 3 7 8 8 1]
 [9 8 7 1 1 5 6 2 4 0]]
tt_50sample [[2 4 5 9 6 7 0 3 8 1]
 [3 7 5 0 6 8 9 4 2 1]
 [0 1 8 4 2 3 5 7 9 6]
 [2 3 1 9 8 6 0 5 7 4]
 [7 9 4 5 8 2 1 6 0 3]
 [4 5 0 8 2 3 6 7 9 1]
 [9 7 8 1 6 5 0 4 2 3]
 [4 2 1 0 3 5 9 8 7 6]
 [5 0 6 2 9 7 3 8 4 1]
 [9 8 7 1 3 5 6 2 4 0]]
vm  [ 1.2 -0.3  5.8  9.3 -1.1 -0.7  0.1 -0.7 -1.   1.3 -0.6 -0.9 -0.2 -0.2  1.6 -0.6 -0.7 -0.4 -0.4 -1.7 -0.5 -0.2  2.4  0.9 -0.9  1.4 -0.3 -0.3 -0.9  1.2 -0.4  0.7  0.3  3.1  1.2 -0.1  3.7 -0.5  1.3 -0.5 -0.1 -0.3 -0.5 -0.4 -0.2 -0.4  7.6 -0.3  2.7  7.5 -0.6 -0.1 -0.4 -0.8  0.5  0.8 -0.6 -1.3 -0.3  2.9 -1.8 -0.1 -0.9  1.3 -0.5 -0.  -0.1 -0.1  0.3 -0.1 -0.2  1.9 -0.2 -0.4  0.  -0.2 -0.6  0.2 -0.1 -0.1  3.   0.6 -0.6  0.1 -1.1 -0.5  2.3 -0.1 -0.3 -0.1 -0.4 -0.3 -0.4 -0.1 -0.2  0.1 -0.4 -0.2 -0.3 -0.4 -0.6  6.2 -0.8  0.1  0.2 -0.1 -0.1 -0.5 -0.3 -1.7 -0.6 -0.2  0.8 -0.1  2.1 -1.7 -0.6 -0.2 -0.3 -0.2 -0.1  6.1 -0.3 -0.6 -0.3  1.8 -0.8  5.2 -0.8 -1.7  3.9 -0.  -0.3 -0.1  0.1  3.8 -0.1 -0.3 -0.2 -0.8 -0.3 -1.4  0.1 -0.1  0.1 -0.  -0.4 -0.4 -2.1 -0.1 -0.8 -0.1  3.6 -0.4 -0.1 -0.  -0.1 -0.2 -1.4 -0.3  0.7  1.3 -0.2 -0.   0.1 -0.  -0.8  0.4 -0.3  1.1 -0.1 -0.8  0.7  0.3 -0.1  6.2 -0.9  0.9  0.8 -0.4  2.1 -0.4  0.5 -0.7 -0.5 -0.5  5.2 -0.8  1.  -0.4 -0.1 -0.5 -1.  -0.9  9.   1.7  0.1  0.1 -0.   0.2 -0.1 -0.3 -0.1 -0.3 -1.   0.8 -0.3 -0.1  7.4 -0.1  0.5 -0.9 -1.  -0.6 -0.4 -0.4  3.4 -0.6 -0.4 -0.  -0.7 -0.4 -0.1 -1.   3.2 -0.5 -0.4 -0.1  0.7  1.8 -0.4 -0.3 -0.2  4.4  1.3 -1.1  3.6  0.1  1.  15.2 -0.2  7.9 -0.4 -0.  -0.1 -1.9 -0.2 -0.5 -0.8 -0.2 -0.8 -0.5  1.  -0.  -0.3  8.6]
vy_50sample [[0 0 6 9 8 2 4 3 1 5]
 [8 7 3 1 9 5 4 6 2 0]
 [7 2 6 4 3 3 1 8 0 5]
 [0 8 4 1 7 9 6 5 3 2]
 [4 5 0 2 6 9 8 1 7 3]
 [6 9 3 7 1 8 0 4 2 5]
 [5 6 2 2 8 0 4 7 3 1]
 [6 3 9 7 4 1 2 5 0 8]
 [7 1 0 9 8 5 3 2 4 6]
 [5 4 4 3 9 6 6 1 0 7]]
vt_50sample [[0 7 6 9 8 2 4 3 1 5]
 [8 7 3 1 9 5 4 6 2 0]
 [7 2 4 6 3 9 1 8 0 5]
 [0 8 4 1 7 9 6 5 3 2]
 [4 5 0 6 2 9 8 7 1 3]
 [6 9 3 7 1 8 0 4 2 5]
 [5 6 9 2 8 0 4 7 3 1]
 [6 3 9 7 4 1 2 5 0 8]
 [7 1 0 9 5 8 3 2 4 6]
 [5 4 3 9 8 2 6 1 7 0]]
Epoch 16310: Training cost= 0.2740, Training acc= 0.8035, Validation cost= 0.3332, Validation acc= 0.8037
Epoch 16320: Training cost= 0.4298, Training acc= 0.8035, Validation cost= 0.3398, Validation acc= 0.8037
Epoch 16330: Training cost= 0.3633, Training acc= 0.8035, Validation cost= 0.3190, Validation acc= 0.8038
Epoch 16340: Training cost= 0.3196, Training acc= 0.8036, Validation cost= 0.3637, Validation acc= 0.8038
Epoch 16350: Training cost= 0.2908, Training acc= 0.8036, Validation cost= 0.3193, Validation acc= 0.8039
Epoch 16360: Training cost= 0.3011, Training acc= 0.8037, Validation cost= 0.3351, Validation acc= 0.8039
Epoch 16370: Training cost= 0.3307, Training acc= 0.8037, Validation cost= 0.3523, Validation acc= 0.8039
Epoch 16380: Training cost= 0.3268, Training acc= 0.8037, Validation cost= 0.3102, Validation acc= 0.8040
Epoch 16390: Training cost= 0.3110, Training acc= 0.8038, Validation cost= 0.3346, Validation acc= 0.8040
Epoch 16400: Training cost= 0.3340, Training acc= 0.8038, Validation cost= 0.3960, Validation acc= 0.8040
tm  [-1.7 -0.2 -1.4 -2.5 -0.8  1.6 -0.5 -0.3 -0.2 -0.6  7.5 -0.7  1.8 -0.2  3.3  6.6 -0.  -0.6 -0.5 -0.5 -0.8 -0.1 -0.6 -0.7 -1.2  0.2 -0.2 -0.1  2.  -0.6  4.4 -0.8  0.2  3.2 -0.3  0.8  1.9  2.1 -1.1 -0.7 -0.2 -2.1 -0.8  3.5 -0.7  0.8 -1.  -1.1 -1.4 -1.5 -0.4 -0.4 -1.2  7.8 -1.7 -0.1 -0.7 -1.9  3.1 -1.3  8.4 -0.  -0.8  0.3 -0.   1.6 -0.1  1.3 -0.8  0.6 -0.4 -1.1 -0.7 -0.1 -3.3 -0.   1.1  0.   1.1  0.8  0.9 -0.1 -0.8 -0.4  1.8 -1.6 -0.3  0.1  0.2 -0.4 -0.8 -0.  -0.  -0.5 -0.5 -0.  -0.5 -1.4 -0.1 -0.1  2.1 -1.   3.2  0.1 -0.3  0.2 -2.1  4.6  2.1 -0.9 -1.  -0.4 -0.3 -0.4  1.1  7.6 -0.2 -0.4 -0.4 -0.7 -0.2  3.9  0.4 -0.4 -0.3  3.   1.4 -1.9  1.2  5.3 -0.4 -1.1 -0.7 -0.3  4.3  6.7 -0.6 -0.3  0.1 -0.5 -1.1  1.1 -1.1 -0.3 -0.5 -0.3 -0.2  0.6 -0.4 -0.1  3.  -0.4 -1.6 -1.1 -0.3 -0.3 -0.2 -0.2 -0.3 -0.5 -0.5  0.  -0.3 -0.3 -0.7  0.1  1.3  3.1 -0.1 -1.  -0.7 -0.7 -0.4 -0.3  0.1  1.6 -1.  -0.7  5.1 -0.8 -0.   0.7 -0.5 -1.2 -0.1 -0.8 -1.3 -0.5 -1.   2.8 -0.  -0.  -0.3 -0.5 -2.3 -0.1 -1.1  0.3 -0.1 -0.4 -0.4 -0.2 -0.2 -0.8  2.1 -3.1 -0.2  0.2  3.6 -0.1 -0.2  3.4 -0.9  5.3 -0.   0.  -0.4 -0.7 -0.5 -0.7 -0.2  0.8 -0.4 -0.8 -0.2  2.5  2.2  2.1  0.7  0.1 -1.3  0.8 -0.5  2.7 -0.1  4.2 -0.4 -1.7 -0.1  6.2 -0.3  3.2 -0.2 -0.3  1.6  4.5 -0.4 -0.3 -0.9 -0.4 -0.4 -0.1 -0.7 -0.2 -0.  -1.2]
ty_50sample [[1 2 4 3 6 7 8 8 5 0]
 [4 2 1 1 3 6 8 7 7 0]
 [3 5 8 9 4 0 2 2 6 7]
 [3 7 2 9 6 1 0 4 8 5]
 [7 1 5 3 3 4 9 6 2 2]
 [1 4 5 3 0 7 2 9 6 8]
 [3 5 6 1 1 7 8 4 0 2]
 [6 7 3 4 9 8 2 5 0 1]
 [1 9 6 4 8 3 2 0 5 7]
 [6 9 1 1 5 8 0 7 4 2]]
tt_50sample [[1 2 4 3 6 7 8 9 5 0]
 [4 2 1 5 3 6 8 9 7 0]
 [3 5 8 9 4 1 2 0 6 7]
 [3 7 2 9 6 1 0 4 8 5]
 [7 1 5 0 3 4 9 6 2 8]
 [1 4 5 0 3 7 2 9 6 8]
 [3 5 6 9 1 7 8 4 0 2]
 [6 7 3 4 9 8 2 5 0 1]
 [1 9 6 8 4 3 2 0 5 7]
 [6 9 1 3 5 8 0 7 4 2]]
vm  [-1.2  0.4  6.3  1.3 -1.2 -0.2 -0.4 -0.4 -0.  -0.6  8.5 -0.3 -0.4 -0.1  6.9  4.8 -0.2 -0.   1.8  4.1 -0.7 -0.4 -0.1 -0.5 -1.5  3.  -0.3 -0.2  0.  -1.4 -0.5 -0.9 -0.5  4.4 -0.3 -0.2  0.7  4.  -1.6 -0.3 -0.9 -0.8 -0.8 -1.  -1.  -0.1 -2.4 -1.5 -0.8 -0.2 -0.5  0.  -0.1 11.7 -1.2 -0.6 -0.5  2.3  2.9  3.3  9.  -0.2  0.4  1.3  0.7 -0.2 -0.2  0.9 -0.4 -0.5 -0.4  0.2  0.9  0.8 -5.  -0.4  0.2 -0.4 -0.3  0.2 -1.  -0.5  1.3 -0.6  0.4 -0.6 -1.4 -0.1 -0.2 -0.1 -0.3 -0.8 -0.3 -0.6 -0.8 -0.1 -0.  -2.1 -0.6 -0.2  1.6  2.8  2.2 -0.4 -0.2  2.1 -2.3 -0.3  2.7  2.3 -0.3 -0.3 -0.3 -0.1  1.2  1.8  0.3 -0.3  0.   1.3 -0.1 -1.  -0.1  0.7 -0.   7.1 -0.  -3.1  0.   4.1 -0.4 -0.5 -0.3  0.4  0.3  5.6 -0.7  0.6  1.4 -0.2 -1.1 -0.7 -1.  -0.2 -0.  -0.2 -0.2  0.8 -1.2 -0.3 -0.  -0.1 -0.7 -0.4 -0.   0.2 -0.5  0.3 -0.1 -0.3  0.5  0.3  1.6 -0.1 -0.3 -0.7  1.2  1.8 -0.5 -0.  -0.6 -0.6 -0.5  0.  -0.7  3.2 -0.7 -0.3  5.4 -0.1  1.  -0.3 -0.1 -1.3 -0.  -0.1 -1.3 -0.2 -0.4  5.2 -0.3 -0.6  0.6 -0.8 -2.5  0.4 -1.1 -0.2 -0.1 -0.1 -0.  -0.3 -0.4 -0.5  0.9 -2.1 -0.1 -0.2  3.1 -0.5 -0.4  0.6 -0.7  5.3 -0.4  0.2  4.3 -0.6 -0.2  1.6 -0.4 -0.4 -0.2 -1.1  1.6 -0.2  2.1  5.3  1.7 -0.5 -0.2  0.4 -0.5  2.1  0.1 -1.7  0.9 -2.  -0.2 -0.4 -0.5 -0.1 -0.3 -0.3  5.2  1.6 -0.2  0.9 -0.6 -0.3  2.3 -0.  -1.1 -0.1 -0.8 -0.9]
vy_50sample [[2 1 7 6 3 0 8 5 4 9]
 [0 4 9 7 2 5 6 6 3 8]
 [0 8 1 4 9 6 5 5 3 2]
 [7 6 4 1 5 9 0 2 3 8]
 [1 3 4 0 7 5 8 6 2 9]
 [6 6 2 4 0 7 8 5 1 9]
 [4 5 8 0 7 6 3 9 2 1]
 [0 7 7 1 9 9 6 3 5 4]
 [7 5 6 4 3 0 9 2 8 8]
 [8 3 1 9 7 6 5 0 2 4]]
vt_50sample [[2 1 7 6 3 0 8 5 4 9]
 [0 4 9 7 5 2 6 1 8 3]
 [8 0 1 4 9 6 5 7 3 2]
 [7 6 4 5 1 9 0 2 3 8]
 [1 3 4 7 0 5 8 6 2 9]
 [3 6 2 4 7 0 8 5 1 9]
 [4 5 8 7 0 6 3 9 2 1]
 [0 8 7 1 2 9 6 3 5 4]
 [7 5 6 4 3 0 9 2 8 1]
 [8 3 1 9 7 6 5 0 2 4]]
Epoch 16410: Training cost= 0.3134, Training acc= 0.8038, Validation cost= 0.3599, Validation acc= 0.8041
Epoch 16420: Training cost= 0.3533, Training acc= 0.8039, Validation cost= 0.3065, Validation acc= 0.8041
Epoch 16430: Training cost= 0.3792, Training acc= 0.8039, Validation cost= 0.3462, Validation acc= 0.8042
Epoch 16440: Training cost= 0.4203, Training acc= 0.8040, Validation cost= 0.3177, Validation acc= 0.8042
Epoch 16450: Training cost= 0.3390, Training acc= 0.8040, Validation cost= 0.3462, Validation acc= 0.8042
Epoch 16460: Training cost= 0.4083, Training acc= 0.8040, Validation cost= 0.3523, Validation acc= 0.8043
Epoch 16470: Training cost= 0.3641, Training acc= 0.8041, Validation cost= 0.2918, Validation acc= 0.8043
Epoch 16480: Training cost= 0.3607, Training acc= 0.8041, Validation cost= 0.2942, Validation acc= 0.8043
Epoch 16490: Training cost= 0.2874, Training acc= 0.8041, Validation cost= 0.3408, Validation acc= 0.8044
Epoch 16500: Training cost= 0.2891, Training acc= 0.8042, Validation cost= 0.2972, Validation acc= 0.8044
tm  [ 1.9 -0.3  2.3 -0.8 -1.8 -0.3 -0.2 -0.1 -0.5 -0.7  3.1 -0.4 -0.3 -0.6  6.3  2.5  0.7 -0.6 -0.2  0.5 -0.3 -0.1  0.8 -0.4 -1.   1.2 -0.1 -0.1 -0.5 -0.1  2.4 -0.7 -0.9  6.7  0.1  0.3  1.6  2.   5.2 -1.2 -0.3  4.3  2.4  4.3  0.1  0.8 -1.  -0.4  6.2  1.5 -0.9 -0.3  0.1  3.  -0.5 -0.8 -0.5  1.4  1.  -0.6 -0.8 -0.4 -0.3  3.8 -0.8  1.3 -0.2 -0.7  0.2  1.7 -0.1 -0.1 -0.1  0.8 -2.2  0.5 -0.9 -0.   0.5  0.6  0.4  0.1 -0.2  0.6 -1.3  4.8  4.2 -0.2  0.5 -0.5 -0.5 -0.3 -0.4 -0.6 -0.3  0.8  1.  -1.6 -0.5 -0.1  2.2  6.2 -1.2 -0.2 -0.3  0.7 -1.   2.6  1.3 -0.8 -0.8 -0.4 -0.1 -0.5 -0.3  2.8 -0.2  0.9 -0.3 -0.8  0.8  3.2 -0.1 -0.5 -0.1  6.9 -0.3 -0.2  4.3  0.9  1.5 -0.9 -0.3 -0.8 -4.2 -1.4 -0.2 -0.5 -0.4 -0.2 -0.1 -0.4  0.7  0.3 -0.4 -0.   1.6 -0.6 -0.1 -0.   2.2 -0.2  3.7 -0.2 -0.  -0.  -0.4 -0.5  2.5 -0.4  0.6 -1.  -0.2 -0.5 -0.3 -0.6 -0.  -0.6  0.3 -0.5 -0.1 -0.  -0.5 -0.3 -0.1  1.   1.4 -0.1 -0.3 -0.4 -1.8 -0.4 -1.1 -1.1 -0.  -0.2  3.8 -0.7 -0.4 -0.  -0.1 -0.3 -0.5 -0.5  5.4 -1.2 -0.  -0.2  0.4 -0.4 -0.1 -0.3 -0.1 -0.6 -0.3 -1.5  0.3  0.2 -1.3 -0.3 -0.8  1.4 -0.7 -0.9 -0.5 -0.4 -1.1 -0.3  0.8 -0.7 -0.7 -0.1 -0.6 -0.5 -0.1  0.2 -0.1 -0.6  0.5  6.4 -0.7 -0.6 -0.4 -0.8  1.  -0.2  0.2 -0.1  1.6 -1.3 -0.  -0.6 -0.  -0.1  2.2 -0.1 -0.2  0.2 -0.6 -0.3 -0.3 -0.3  3.4  0.3  0.1  1.3]
ty_50sample [[7 5 4 2 0 0 3 3 6 1]
 [6 5 2 3 7 1 4 9 0 8]
 [0 7 2 8 1 9 4 3 6 5]
 [9 5 7 0 6 4 2 8 1 3]
 [4 8 5 3 6 1 2 9 0 7]
 [9 3 6 1 4 0 5 7 2 8]
 [0 5 7 9 6 8 4 3 1 2]
 [8 8 5 4 4 1 6 7 0 3]
 [3 9 9 0 2 5 7 8 6 4]
 [2 6 3 7 4 0 1 9 8 5]]
tt_50sample [[7 5 4 2 8 0 3 9 6 1]
 [6 5 2 3 7 1 4 9 0 8]
 [0 7 2 1 8 9 4 3 6 5]
 [9 5 7 0 6 4 2 8 1 3]
 [4 8 5 3 6 1 2 9 0 7]
 [9 3 6 1 4 0 5 7 2 8]
 [0 5 7 9 6 8 4 3 1 2]
 [2 8 5 4 9 1 6 7 0 3]
 [3 1 9 0 2 5 7 8 6 4]
 [2 6 3 7 4 0 9 1 8 5]]
vm  [-0.7 -0.8 -0.7 -1.2 -1.   0.3 -0.4 -0.2 -0.1 -0.1  3.7 -0.7 -0.2 -0.5  2.1 -0.8 -0.2 -0.6 -0.2  2.4 -0.6 -0.4  1.9 -0.1 -1.3  4.7 -0.2  0.7 -1.5 -1.9  1.  -0.1 -0.5 -0.9  1.4 -0.2  2.  -0.1 -2.  -0.7 -0.3  4.9  0.1 -0.5 -0.5 -0.2 -2.3 -0.4 -0.1  4.2 -0.7 -0.4 -0.2  6.4  2.1  0.2 -0.8  3.4  3.1  0.8  6.4 -0.   0.3  4.4 -0.2  1.8 -0.  -0.1 -0.  -0.1 -0.4  3.9 -0.5 -0.2 -3.7 -0.1 -0.1  0.4  0.5  0.7 -1.5  0.1  1.2  0.6 -0.2  5.8 -0.4 -0.  -0.6 -0.2 -0.2 -0.9 -0.9 -0.6 -0.3  0.5  2.3 -2.  -0.2 -0.5 -0.3  1.5  0.6 -0.1 -0.2  0.7 -2.1  0.7  1.2  1.6 -0.9  1.5 -0.2 -0.3  5.2 -1.8 -0.7 -0.1 -0.4 -0.1 -0.1 -0.7  0.7  1.  -0.4  2.3 -0.7 -1.2  3.3  1.1  1.3 -0.8 -1.  -0.3  8.6  5.9 -0.2 -0.3  0.2 -0.3 -0.1 -1.1 -0.6  0.5 -0.4 -0.2  0.3 -0.1  5.  -0.3  1.9 -0.4 -0.1  1.1 -0.4  0.2  0.1 -0.2 -0.4 -0.2  1.6  0.6 -0.1 -0.1 -0.4 -0.9 -0.5  0.3 -0.1 -0.4  0.3  0.6  0.1 -0.5 -0.1 -1.  -0.9 -0.6  6.5 -0.1 -1.1 -0.2 -0.6 -1.4  1.8 -0.6 -1.  -0.2 -0.   5.7 -0.2 -0.5 -0.1 -0.7 -1.4 -0.4 -1.4 -0.9 -0.1  0.  -0.6  0.1 -0.4 -0.6  1.  -2.9  0.3  0.9 -1.1  0.4 -0.3 -0.8 -0.7  3.2 -0.9 -0.6  2.7 -0.6 -0.7 -0.7 -0.6 -0.3 -0.1 -0.9  4.4 -1.  -0.3  2.7  0.6  1.3 -0.5 -0.1 -0.5 -0.9  4.9  2.6  3.2 -1.4  2.6 -2.5 -0.2 -1.2 -0.  -0.1  6.2  3.6  0.4 -0.  -1.2 -0.2  3.1 -0.3 -1.5  0.5 -0.1  1. ]
vy_50sample [[0 5 5 1 2 4 8 7 3 9]
 [6 2 0 3 8 7 5 1 4 4]
 [0 6 3 1 8 4 5 7 9 9]
 [5 9 6 3 2 1 4 8 8 7]
 [3 2 7 9 8 6 5 0 4 1]
 [8 4 9 9 5 7 6 3 2 1]
 [3 9 8 6 0 1 4 2 7 5]
 [7 9 8 4 1 6 5 3 0 2]
 [8 0 6 7 2 1 9 3 4 5]
 [0 3 1 9 8 6 7 5 2 4]]
vt_50sample [[0 5 6 1 2 4 8 7 3 9]
 [6 2 0 3 8 7 5 1 9 4]
 [6 0 3 1 8 4 5 7 9 2]
 [5 9 6 3 2 1 4 8 7 0]
 [3 2 7 9 8 6 5 0 4 1]
 [4 8 0 9 5 7 6 3 2 1]
 [3 9 8 6 0 1 4 2 7 5]
 [7 9 4 8 1 6 3 5 0 2]
 [8 0 6 7 2 1 9 3 4 5]
 [0 3 1 9 8 6 7 5 2 4]]
Epoch 16510: Training cost= 0.2936, Training acc= 0.8042, Validation cost= 0.3413, Validation acc= 0.8045
Epoch 16520: Training cost= 0.3245, Training acc= 0.8043, Validation cost= 0.2946, Validation acc= 0.8045
Epoch 16530: Training cost= 0.2874, Training acc= 0.8043, Validation cost= 0.3257, Validation acc= 0.8046
Epoch 16540: Training cost= 0.3069, Training acc= 0.8044, Validation cost= 0.3024, Validation acc= 0.8046
Epoch 16550: Training cost= 0.3098, Training acc= 0.8044, Validation cost= 0.3392, Validation acc= 0.8046
Epoch 16560: Training cost= 0.3205, Training acc= 0.8044, Validation cost= 0.3198, Validation acc= 0.8047
Epoch 16570: Training cost= 0.4269, Training acc= 0.8045, Validation cost= 0.2852, Validation acc= 0.8047
Epoch 16580: Training cost= 0.3104, Training acc= 0.8045, Validation cost= 0.3131, Validation acc= 0.8048
Epoch 16590: Training cost= 0.3072, Training acc= 0.8046, Validation cost= 0.3960, Validation acc= 0.8048
Epoch 16600: Training cost= 0.3251, Training acc= 0.8046, Validation cost= 0.3879, Validation acc= 0.8048
tm  [-1.2 -0.5 -2.2  2.5 -0.6 -0.3 -0.4 -0.3 -0.9  0.  -3.3  0.5 -0.8 -0.  -2.5  0.3 -0.2 -0.1 -0.4 -1.7 -0.8 -0.3  3.  -0.1 -0.8 -0.1 -0.1 -0.  -0.1 -0.2 -0.4 -0.2 -0.3 -4.8 -0.5  0.4  2.4  3.1 12.5 -0.2 -0.1  5.5  1.3  4.8 -0.6 -0.6  7.6 -0.2 -0.8  9.4 -0.5 -0.1 -0.7 -1.3 -0.9  5.4 -0.4  2.3 -0.1  2.2  0.6 -0.5 -0.9 -0.7 -0.6 -0.7 -0.3  1.2  0.9 -0.7 -0.3 -0.4 -0.2 -0.6 -0.7  0.2  1.3 -0.3  0.6 -0.2 -0.9 -0.3 -0.8 -0.3  0.1  6.4 -0.3 -0.2 -0.  -0.2  0.2 -0.2 -0.5  0.9 -0.5 -0.3 -0.  -0.4 -0.2 -0.3  1.6 -0.3  0.3 -0.2 -0.3 -0.6 -0.9 -0.4 -1.2 -1.9  0.2 -0.5  0.2 -0.4 -0.   1.7 -0.1 -0.7 -0.   0.4 -0.2  6.1 -0.  -0.6 -0.3 -2.7  1.1  8.   1.5 -1.4 -1.  -0.2  0.4 -0.2 -0.2 -5.4 -0.1  0.5 -0.2 -0.5  0.9 -0.6 -0.2 -0.5 -0.1 -0.2 -0.4 -0.5  7.4 -0.2 -0.6 -0.1  1.6 -0.1 -0.3 -0.2  0.1 -0.5  3.5 -0.3 -0.3 -1.6 -0.3 -0.  -0.8 -0.  -0.3 -0.2 -0.6 -0.   0.5  0.3 -0.1 -0.1 -0.3 -1.9 -0.1 -0.1 -2.2 -0.2 -1.6 -0.4  1.3 -0.9 -0.5  1.4  0.7  0.  -0.5  2.3 -0.6 -0.5 -1.2 -1.2  1.5  0.3  0.2  1.  -0.4 -0.3 -0.2 -0.5 -0.1 -0.2 -0.3  0.7 -0.  -0.3  0.7 -0.1 -0.3  0.1 -0.2  3.7  1.2 -0.1 -1.4 -0.5  0.1 -0.2 -0.6 -0.3 -0.2 -0.8 -0.4  1.5 -1.4  0.7 -0.6 -0.3 -1.2  0.1 -0.4  0.1 -0.4  5.5 -0.  -0.2 -0.3 -0.6 -0.1 -0.3 -0.4 -0.3  4.2 -2.1  0.9 -1.  -0.7  0.3  1.2 -0.1  9.2  0.   1.7  8.1]
ty_50sample [[5 8 1 4 9 0 2 3 7 6]
 [6 8 7 9 5 4 3 2 0 1]
 [0 7 4 8 2 1 3 5 9 6]
 [6 3 2 0 7 4 5 9 8 1]
 [1 4 6 8 8 3 2 0 5 7]
 [9 1 6 2 8 4 5 7 3 0]
 [2 2 5 0 0 8 4 3 6 7]
 [1 4 9 8 0 5 2 3 7 6]
 [7 4 1 6 3 2 5 5 0 8]
 [6 2 3 8 7 9 0 5 4 4]]
tt_50sample [[5 8 1 4 9 0 2 3 7 6]
 [6 8 7 9 5 4 3 2 0 1]
 [0 7 4 2 8 1 3 5 9 6]
 [6 3 0 2 7 4 5 1 9 8]
 [1 4 6 9 8 3 2 0 5 7]
 [9 1 6 2 8 4 5 7 3 0]
 [2 1 5 9 0 8 4 3 6 7]
 [1 4 9 8 0 5 2 3 7 6]
 [7 4 1 6 2 3 5 9 0 8]
 [6 2 3 8 7 9 0 5 1 4]]
vm  [-0.8 -1.4 -0.7  3.3 -0.7 -0.2 -0.5 -0.1  3.1  1.5  5.5 -0.9 -0.1 -0.3 -1.1  2.6 -0.8 -0.3 -0.1 -0.9 -1.3 -0.   2.6 -1.1 -0.5  1.6 -0.2 -0.5 -0.3 -2.5  0.2 -0.3 -0.8 -1.7  3.4 -0.7 -0.6  5.6  7.9 -0.5  0.  -0.3 -1.8  3.4 -0.6  0.2  1.9 -1.3 -0.3  6.1 -0.4 -0.2 -0.3  4.5 -0.4  3.1 -0.8 -1.   9.3  2.2  1.7 -0.1 -0.2  3.9 -0.2 -0.1 -0.2  3.6 -0.2 -0.3 -0.3  0.3 -0.   0.5 -2.3 -0.2 -0.8 -0.2  0.4 -0.2  1.1 -0.2 -0.2 -0.4 -0.1 -0.2 -0.5 -0.2 -0.8 -0.5 -0.1 -1.6 -0.9 -2.4 -0.1 -0.2 -0.4 -1.6 -0.5 -0.1 -1.1  2.2  0.7 -0.3 -0.1  1.  -0.9 -0.   2.2 -1.3 -0.7 -0.1 -0.3 -0.7  6.9 -0.5 -0.   1.6 -0.2  0.6 -0.1  4.   0.8 -0.3 -0.2 -1.2 -1.1 -1.   7.1 -0.8 -0.6 -0.9 -0.4 -0.3 -0.8 -2.7 -0.3 -0.2 -0.4 -0.4 -0.8 -0.4 -1.2 -0.2 -0.2 -0.1  0.1 -0.2 -0.3 -0.3  1.1 -0.3  0.2 -0.4 -0.  -0.  -0.1  0.3  3.7 -0.1  2.  -1.7 -0.  -0.1 -0.5 -0.9 -0.2  3.9 -0.4  0.2  0.4 -0.8 -0.2 -0.3 -0.2  1.8  0.4  0.9 -1.1 -0.6  0.8 -0.5 -0.7 -0.8  0.6 -0.2  0.2 -0.  -0.4  8.8  0.1 -0.6 -1.2 -0.4 -0.1 -1.9 -0.3 -1.2 -0.1 -0.  -0.2 -0.3 -0.4 -0.6 -0.3 -1.  -0.2 -0.4  6.2 -0.2 -0.1  0.6 -1.   2.3 -0.8 -0.4 -0.8 -0.7 -0.4 -0.1 -0.3 -0.6 -0.1 -1.  -0.  -0.   2.1  4.8 -0.2  2.8 -0.7 -0.7  0.   3.8  1.1  3.1  2.7 -0.7  2.1  9.7 -0.1  5.6 -0.3 -0.1  1.9 -1.  -0.1  0.2 -1.4 -0.6 -0.5 -0.1  6.  -0.2 -1.   6.3]
vy_50sample [[2 0 1 8 4 4 7 3 6 5]
 [7 0 8 6 2 3 9 9 1 1]
 [3 1 8 8 0 6 2 7 9 4]
 [3 0 4 7 2 2 1 6 5 8]
 [7 3 6 2 9 0 0 1 5 8]
 [6 7 9 0 5 2 8 8 4 3]
 [3 4 2 7 1 5 5 6 9 9]
 [6 7 2 9 5 4 1 8 3 0]
 [0 6 9 2 1 3 7 8 8 5]
 [9 5 2 1 3 6 7 8 4 0]]
vt_50sample [[2 0 1 9 8 4 7 3 5 6]
 [7 0 8 6 2 3 9 4 5 1]
 [3 5 1 8 0 6 2 7 9 4]
 [3 0 4 9 7 2 1 6 5 8]
 [7 3 6 2 4 0 9 1 5 8]
 [6 7 9 0 5 2 8 1 4 3]
 [3 4 2 7 1 5 0 8 6 9]
 [6 7 2 9 5 4 1 8 0 3]
 [6 0 9 2 1 3 7 4 8 5]
 [9 5 2 1 3 6 7 8 0 4]]
Epoch 16610: Training cost= 0.3194, Training acc= 0.8046, Validation cost= 0.3541, Validation acc= 0.8049
Epoch 16620: Training cost= 0.3313, Training acc= 0.8047, Validation cost= 0.3338, Validation acc= 0.8049
Epoch 16630: Training cost= 0.3647, Training acc= 0.8047, Validation cost= 0.2883, Validation acc= 0.8049
Epoch 16640: Training cost= 0.3570, Training acc= 0.8047, Validation cost= 0.3346, Validation acc= 0.8050
Epoch 16650: Training cost= 0.4308, Training acc= 0.8048, Validation cost= 0.3783, Validation acc= 0.8050
Epoch 16660: Training cost= 0.3176, Training acc= 0.8048, Validation cost= 0.3659, Validation acc= 0.8050
Epoch 16670: Training cost= 0.3537, Training acc= 0.8048, Validation cost= 0.3973, Validation acc= 0.8051
Epoch 16680: Training cost= 0.3781, Training acc= 0.8049, Validation cost= 0.3519, Validation acc= 0.8051
Epoch 16690: Training cost= 0.2999, Training acc= 0.8049, Validation cost= 0.3366, Validation acc= 0.8052
Epoch 16700: Training cost= 0.2585, Training acc= 0.8049, Validation cost= 0.3371, Validation acc= 0.8052
tm  [ 0.4 -0.1  3.1 -1.2 -1.7 -0.2 -0.6 -0.  -0.3 -0.7  7.3 -0.8  1.2 -0.2  7.1  4.4 -0.  -0.3 -0.1 -0.6 -0.6 -0.2 -0.4 -0.4 -0.8  0.1 -0.6  0.  -0.7 -0.9  2.1 -0.3 -0.7  6.4  1.5 -0.   1.8  5.8  7.3 -1.  -0.  -1.9 -0.9  5.1 -0.6  0.3  0.3 -1.   2.7 -0.9 -0.9 -0.4 -0.8  7.8 -0.6 -0.8 -0.6 -1.   3.2 -0.3 -0.4  0.5 -0.9  2.5 -0.1  0.5 -0.5 -0.2 -0.1  0.7 -0.3  0.1 -0.3 -0.4 -2.   0.8 -0.8 -0.1 -0.2  0.5 -0.1 -0.4 -0.7  0.7 -1.  -2.1  1.7 -0.3 -0.2 -0.2 -0.8 -0.1 -0.2 -0.6 -0.2 -0.1 -0.3 -1.2 -0.3 -0.2  2.9  2.5 -0.6  0.1 -0.2 -0.1 -1.6  2.4  2.8 -1.  -0.7  0.2 -0.1 -0.5  0.7  0.5 -0.1  0.9 -0.5 -0.8 -0.4  4.  -0.  -0.2 -0.4  7.6 -0.4 -1.9  2.3  4.2  0.1 -1.  -0.4 -0.5 -4.9 -2.3 -0.3 -0.2 -0.1 -0.2 -1.2 -0.4 -1.2 -0.2 -0.4 -0.2 -0.3 -0.4 -1.8 -0.1  1.  -0.4  2.6 -1.   0.  -0.4  0.  -0.3  2.7 -0.8 -0.7 -1.7 -0.1 -0.3 -0.1  0.2  0.6  1.3 -0.1 -0.5 -0.8 -0.4 -0.3 -0.2 -0.2  4.9  2.2 -0.9 -0.9 -0.5 -0.  -0.2 -0.6 -0.8  0.2 -0.3  2.2 -0.9 -0.8  3.1 -0.   0.1 -0.6 -0.5  3.5 -0.9 -0.8 -0.4 -0.2 -0.2 -0.2 -0.4 -0.7 -0.6 -0.3 -2.8 -0.   0.8  4.3  0.  -0.4  0.5 -0.9 -0.9  0.1 -0.2 -1.3 -0.3 -0.2 -0.6 -0.2 -0.2 -0.2 -0.9 -1.5  1.   2.9  0.5  0.9  5.6 -1.3  1.2 -0.5  2.9  0.7 -0.3  0.6 -0.7  0.2  6.5 -0.1  4.2 -0.2 -0.3  3.   1.6 -0.4 -0.3 -0.8 -0.1 -0.1 -0.4  5.2 -0.3 -0.1 -0.8]
ty_50sample [[2 7 3 4 0 8 9 1 5 6]
 [9 4 8 5 7 0 1 3 6 2]
 [7 6 4 8 5 1 1 2 9 9]
 [7 9 0 8 4 6 3 2 5 1]
 [2 6 4 4 3 9 9 5 1 1]
 [4 9 3 0 5 8 7 6 2 1]
 [5 5 2 1 8 7 0 9 3 6]
 [2 8 6 6 0 5 3 7 4 1]
 [2 7 4 6 5 1 0 3 8 9]
 [2 5 0 4 3 7 6 9 1 8]]
tt_50sample [[2 7 3 4 0 8 9 1 5 6]
 [9 4 8 5 7 0 1 3 6 2]
 [7 6 4 8 5 1 0 2 3 9]
 [7 9 0 8 4 6 3 2 5 1]
 [2 6 4 7 3 0 5 9 8 1]
 [4 9 3 0 5 8 7 6 2 1]
 [5 4 2 1 8 7 0 9 3 6]
 [2 8 6 9 0 5 3 7 4 1]
 [2 7 4 6 5 1 0 3 8 9]
 [2 5 0 4 3 6 7 9 1 8]]
vm  [ 0.7 -0.3  2.4  7.  -1.5 -0.7 -0.2 -0.3 -0.3 -0.  -4.5  0.1 -1.3 -0.4 -0.5 -0.6 -0.3 -0.2 -0.2 -1.4 -0.3 -0.1  3.2 -0.2 -0.6 -0.3 -0.2 -0.2 -0.   0.5 -0.6 -0.5 -0.4 -0.6  0.  -0.6 -0.1 -0.8  8.8 -0.5 -0.1  4.9  1.   1.7  0.4 -0.   6.8  1.6  4.1  8.4 -0.3 -0.3 -0.1 -2.5 -0.8  1.8 -0.2  2.2  0.4  2.7 -1.8 -0.6 -0.8  0.3 -0.6 -0.2  0.  -0.3  2.2  0.1 -0.3 -0.7 -0.1  0.6  0.4  1.  -1.  -0.   0.3 -0.2  0.7  0.4 -0.7  0.3 -1.3  5.9  2.9 -0.2 -0.  -0.3  0.7 -0.2 -0.6 -1.  -0.1 -0.1 -0.1 -0.7 -0.1 -0.1  0.3  5.5 -1.1 -0.1 -0.1 -0.3  0.4 -0.7 -1.8 -1.7 -0.  -0.2 -0.3 -0.5 -0.2  4.3 -0.1 -0.1 -0.4 -0.1 -0.3  7.2  0.4 -0.7  0.  -0.6 -0.1 12.2  3.2 -1.7  3.  -0.8  0.3 -0.4 -1.6 -2.8 -0.2 -0.5 -0.6  0.   3.5 -0.5  3.4 -0.1 -0.3 -0.   0.3 -0.5  1.2 -0.1 -0.3 -0.4  5.6  1.2  1.5 -0.1 -0.2 -0.5 -0.1 -0.3  0.7 -0.6 -0.1 -0.2 -0.3  0.5 -0.2 -0.1 -0.3  1.   0.1  0.1 -0.5 -0.   0.1 -0.  -0.5  1.5 -1.1  1.1 -1.7 -0.5 -0.7 -1.1 -0.4 -0.1  5.5 -0.4 -0.6 -0.  -0.1 -0.3 -1.6 -0.7  9.7 -1.1  3.  -0.4 -0.1 -0.4 -0.2 -0.2 -0.2 -0.4 -0.5  2.7  0.1  0.1  3.  -0.1 -0.4  4.  -0.7 -0.5 -0.4 -0.2 -0.1 -0.2  1.  -0.2 -1.6 -0.2 -0.3 -1.   2.1  2.8 -2.  -0.7 -0.5  5.7 -0.8 -1.  -0.   2.2 -0.5 -0.1  0.7  2.9  3.1  3.4 -0.4  1.1 -0.3 -0.   1.4 -2.5  0.3 -0.2 -1.  -0.3 -0.4 -0.5  6.6 -0.3  3.8  9.7]
vy_50sample [[8 9 5 7 4 6 0 3 1 2]
 [7 0 1 8 4 5 2 3 9 6]
 [9 6 7 3 1 4 0 0 2 2]
 [6 3 4 4 9 5 1 0 7 8]
 [5 9 9 8 1 3 7 4 6 0]
 [5 0 2 7 6 1 4 8 3 3]
 [4 2 7 5 8 9 6 1 3 0]
 [4 1 0 3 5 7 9 2 2 6]
 [8 0 7 9 1 3 5 4 6 2]
 [5 2 1 3 8 4 6 7 0 9]]
vt_50sample [[8 9 5 7 4 6 0 3 1 2]
 [7 0 1 8 4 5 2 3 9 6]
 [9 6 7 3 1 4 0 2 5 8]
 [6 3 4 9 2 5 1 0 7 8]
 [5 2 9 8 1 3 7 4 6 0]
 [5 0 2 7 6 1 4 8 3 9]
 [4 2 7 5 8 9 6 1 3 0]
 [4 1 0 3 5 7 9 8 2 6]
 [8 0 7 9 1 3 5 4 6 2]
 [5 2 1 3 8 4 6 7 0 9]]
Epoch 16710: Training cost= 0.2649, Training acc= 0.8050, Validation cost= 0.2719, Validation acc= 0.8052
Epoch 16720: Training cost= 0.3403, Training acc= 0.8050, Validation cost= 0.3248, Validation acc= 0.8053
Epoch 16730: Training cost= 0.3835, Training acc= 0.8051, Validation cost= 0.3771, Validation acc= 0.8053
Epoch 16740: Training cost= 0.2805, Training acc= 0.8051, Validation cost= 0.3189, Validation acc= 0.8053
Epoch 16750: Training cost= 0.3312, Training acc= 0.8052, Validation cost= 0.3813, Validation acc= 0.8054
Epoch 16760: Training cost= 0.3631, Training acc= 0.8052, Validation cost= 0.3340, Validation acc= 0.8054
Epoch 16770: Training cost= 0.2974, Training acc= 0.8052, Validation cost= 0.3318, Validation acc= 0.8055
Epoch 16780: Training cost= 0.3506, Training acc= 0.8053, Validation cost= 0.3733, Validation acc= 0.8055
Epoch 16790: Training cost= 0.2997, Training acc= 0.8053, Validation cost= 0.2789, Validation acc= 0.8055
Epoch 16800: Training cost= 0.3318, Training acc= 0.8053, Validation cost= 0.3075, Validation acc= 0.8056
tm  [-1.2 -0.3  0.6 12.3 -0.7  0.1 -0.2 -0.4 -0.4  0.6 -1.8 -0.6 -0.2 -0.3 -2.3  1.4 -0.3 -0.1 -0.3 -1.9 -0.5 -0.3  4.1  0.3 -0.6 -0.  -0.1 -0.1 -0.5 -0.6 -1.7 -0.3 -0.2 -3.9 -0.2  0.6  2.6  1.5  7.3 -0.1 -0.2  6.6  1.3 -0.1 -0.4 -0.7  7.6 -0.5 -0.7 11.9 -0.5 -0.3 -0.5 -0.8 -0.5  4.8 -0.4  6.2 -0.1  5.3 -0.1 -0.3 -0.9  0.3 -0.9 -0.1 -0.2 -0.2  0.3 -0.5  0.1 -0.1 -0.1 -0.1  2.   0.6  1.3 -0.3  0.2  0.3  0.2 -0.3 -0.8  0.8  0.7  8.5 -1.  -0.2 -0.4 -0.3  0.2 -0.1 -0.5 -0.2 -0.  -0.1  1.1 -0.4  0.1 -0.1 -0.1  2.9  0.5 -0.1 -0.2 -0.5 -0.2 -1.7 -0.5 -2.2 -0.4 -0.4  0.1 -0.2  1.5  0.8 -0.3 -0.8 -0.5 -0.2 -0.3  8.7  0.2 -0.4 -0.  -2.7 -0.1  6.   1.8 -2.4 -0.7 -0.7 -0.5 -0.4  4.6 -2.8 -0.2  0.3 -0.4 -0.1 -0.2 -0.5 -0.5 -0.2 -0.2 -0.3 -0.2 -0.2  5.7 -0.  -1.  -0.1  1.2 -0.2  0.3 -0.   0.2 -0.7  1.2 -0.3  0.3 -0.2 -0.4 -0.1 -0.8 -0.1 -0.3 -0.2 -0.3  1.1  1.1 -0.  -0.1  0.2 -0.  -1.5 -0.6  0.6 -1.2 -0.3 -1.6 -0.2 -0.2 -0.8 -0.1  1.   0.5 -0.2 -0.4  2.8  0.1 -0.3 -1.5 -0.4  2.3 -0.5  1.7  0.4 -0.4 -0.1 -0.6 -0.3 -0.4 -0.4 -0.   1.5  0.3  0.6  2.2 -0.2  0.  -0.1 -0.3  4.3 -0.5 -0.4  1.9 -0.3 -0.1 -0.4 -0.3  0.1 -0.5 -0.8  3.1  1.7 -0.6  1.7 -0.6 -0.3 -0.8 -0.7 -0.1  1.8  0.3  1.2  0.8  2.4  0.1  1.8 -0.2  0.8 -0.  -0.3  1.6 -2.1  0.9 -0.3 -0.8 -0.5 -0.3 -0.3  5.9 -0.2 -0.2 12.1]
ty_50sample [[8 8 1 1 0 2 6 4 4 3]
 [2 4 4 7 9 3 0 1 5 8]
 [7 6 1 8 4 0 3 5 9 9]
 [3 0 1 6 6 4 9 2 7 5]
 [4 6 1 9 0 8 5 5 7 3]
 [2 9 0 8 5 6 1 3 4 7]
 [1 2 2 9 3 4 8 7 0 6]
 [9 5 2 7 3 4 8 0 6 1]
 [1 4 2 2 5 7 8 3 0 6]
 [8 7 4 2 3 6 0 5 1 9]]
tt_50sample [[8 5 9 1 0 2 6 4 7 3]
 [2 4 7 6 9 3 0 1 5 8]
 [7 6 1 8 4 0 3 5 9 2]
 [3 1 0 8 6 4 9 2 7 5]
 [6 4 1 9 0 8 2 5 7 3]
 [2 0 9 8 5 6 1 3 4 7]
 [1 2 9 5 3 4 8 7 0 6]
 [9 5 2 7 3 4 0 8 6 1]
 [1 4 9 2 5 7 8 3 0 6]
 [8 7 4 2 3 0 6 5 1 9]]
vm  [-0.7  0.5 -0.5 -0.2 -1.  -0.4 -0.3 -0.3 -0.8 -0.8 -0.9  2.1 -1.1 -0.4  0.5 -0.3  1.2 -0.4 -0.5 -0.7 -0.4 -0.2 -0.7 -0.1 -1.3  0.6  0.6 -0.2  1.  -0.1  3.  -0.4  1.3  2.4 -1.1 -0.1  2.  -1.1 -1.3 -0.1 -0.2  3.2  3.4 -0.6 -0.2 -0.1 -0.1  2.  -0.1 -1.2 -0.6 -0.2 -0.  -1.2 -1.3  0.5 -0.3  4.3 -1.  -0.6  2.2 -0.7 -0.1 -0.4  0.2 -0.2 -0.2 -0.1 -0.1 -0.1 -0.2 -0.7 -0.4 -0.2 -2.8  0.2 -0.2 -0.1 -0.5  0.   4.3 -0.3 -0.3 -0.1 -0.3  4.2  0.2 -0.1  0.8 -0.3 -0.4  1.2 -0.3  2.3 -0.3 -0.1  0.2 -1.1 -0.6 -0.5  3.7 -0.7 -0.1 -0.2 -0.5  0.8 -1.6  2.9 -0.4 -0.9  0.5 -0.5 -0.4 -0.6 -0.4  5.2 -0.3 -0.6 -0.3  0.1 -0.3  1.9 -0.1  0.1 -0.3  0.7  3.6  7.   0.9  3.8  0.6 -0.6 -0.1 -0.3  7.7 10.8 -0.2  0.1  0.1 -0.7  2.7  0.1  2.3 -0.3 -0.5 -0.2 -0.2 -0.7  6.2 -0.1  0.7 -0.1 -0.4  1.  -0.4 -0.2 -0.8 -0.2 -0.9 -0.8 -0.7  2.2  0.1  0.4 -0.2  0.1  0.3 -0.3 -0.3 -0.2 -0.4  1.4 -0.5 -0.5 -0.3 -1.5 -1.3 -0.6  4.6  0.3 -1.9  0.1 -0.3 -1.3 -0.5 -0.2 -0.2 -0.5 -0.5  0.6 -0.  -0.1 -0.5 -1.2 -0.1  1.1 -0.5  0.4 -0.1 -0.5 -0.1 -0.2 -0.  -0.2  0.  -1.3  0.2 -0.4 -3.5 -0.2 -0.4  2.3 -0.3  3.2 -0.1 -0.3  2.3 -0.5 -0.1 -0.5 -0.9 -0.1  0.2 -0.3  1.2  1.4 -1.7 -0.5  0.8  0.6 -0.1 -0.1 -0.1 -2.4 -0.5  1.8 -0.5 -0.8  0.4 -2.5 -0.3 -1.3 -0.2 -0.1 -0.5 -0.6 -0.4 -0.6 -0.5 -0.3 -1.2 -0.5 -1.1 -0.1  5.7 -0.6]
vy_50sample [[5 6 3 1 4 9 7 8 0 2]
 [0 4 7 9 2 3 6 6 5 5]
 [8 6 2 5 3 3 4 9 0 0]
 [5 2 4 1 3 9 0 7 8 6]
 [4 8 7 1 9 6 2 5 3 0]
 [1 8 5 2 6 7 4 9 3 0]
 [1 0 5 7 2 8 3 4 6 9]
 [5 7 9 8 3 1 4 0 2 6]
 [1 6 8 9 2 0 5 3 4 7]
 [1 7 4 6 9 3 5 0 8 2]]
vt_50sample [[5 6 3 1 4 9 7 8 0 2]
 [0 4 7 9 2 8 3 6 1 5]
 [8 6 2 5 3 4 1 7 9 0]
 [5 2 4 1 3 9 0 7 8 6]
 [4 8 7 1 9 6 2 5 3 0]
 [1 8 5 2 6 7 4 9 3 0]
 [1 0 5 7 2 8 3 4 6 9]
 [5 7 9 8 3 1 4 0 2 6]
 [1 6 8 9 2 0 5 3 4 7]
 [1 7 4 6 9 3 5 0 8 2]]
Epoch 16810: Training cost= 0.3051, Training acc= 0.8054, Validation cost= 0.3264, Validation acc= 0.8056
Epoch 16820: Training cost= 0.3237, Training acc= 0.8054, Validation cost= 0.3115, Validation acc= 0.8057
Epoch 16830: Training cost= 0.2900, Training acc= 0.8055, Validation cost= 0.3118, Validation acc= 0.8057
Epoch 16840: Training cost= 0.3386, Training acc= 0.8055, Validation cost= 0.3067, Validation acc= 0.8058
Epoch 16850: Training cost= 0.3122, Training acc= 0.8055, Validation cost= 0.4127, Validation acc= 0.8058
Epoch 16860: Training cost= 0.3140, Training acc= 0.8056, Validation cost= 0.3697, Validation acc= 0.8058
Epoch 16870: Training cost= 0.3204, Training acc= 0.8056, Validation cost= 0.3795, Validation acc= 0.8059
Epoch 16880: Training cost= 0.3246, Training acc= 0.8056, Validation cost= 0.3474, Validation acc= 0.8059
Epoch 16890: Training cost= 0.3216, Training acc= 0.8057, Validation cost= 0.3006, Validation acc= 0.8059
Epoch 16900: Training cost= 0.2960, Training acc= 0.8057, Validation cost= 0.2799, Validation acc= 0.8060
tm  [-0.5  0.9 -2.1 -1.  -0.9  0.5  0.2 -0.3 -0.8 -0.8  2.4 -0.3 -0.1  0.2 -1.3  5.6 -0.1 -0.4 -0.2 -1.  -0.6 -0.2  2.1 -0.1 -1.3  0.2 -0.  -0.1  0.8  1.1  3.4 -0.3 -0.4 -1.2 -0.7  0.4  2.9  5.6 11.3 -0.7 -0.1  4.1  2.5  6.4 -0.5 -0.3  4.7 -0.7 -0.   4.9 -0.8  0.3  0.2  1.  -1.5  3.  -0.4 -0.1 -0.5 -0.8 -0.4 -0.6 -0.1 -0.5 -0.3 -0.7 -0.2  2.  -0.1 -0.6 -0.1 -1.2 -0.1  0.2 -0.9 -0.1  1.  -0.5  0.   0.1  3.1 -0.8 -0.4 -0.4 -0.5  5.4  1.8 -0.   0.6 -0.  -0.2  0.4 -0.3  1.3 -0.6 -0.1 -0.2 -0.5  0.2 -0.3  2.4  1.8 -0.4 -0.3 -0.2 -0.2 -0.8  3.7  1.2 -1.3 -0.4 -0.6  0.2 -0.4 -0.9  6.5 -0.1 -1.  -0.2  0.3 -0.1  3.9 -0.4 -0.2 -0.4 -1.3  1.9  1.5  0.9 -1.1 -0.6 -0.4  0.1 -0.1 -1.7 -3.1 -0.2  0.3 -0.  -0.9 -0.4 -0.3 -0.4 -0.2 -0.1 -0.2 -0.6 -0.3  4.4  0.1 -0.2 -0.   2.2 -0.3 -0.2 -0.2 -0.2 -0.1  4.  -0.1 -0.3 -1.5 -0.1 -0.1 -0.5 -0.2  0.5 -0.5 -0.  -0.4  0.7 -0.  -0.3 -0.3 -0.3 -1.1  0.3  0.  -1.8 -0.7 -1.4 -0.1 -0.  -1.1 -1.  -0.   1.8 -0.3 -0.2 -0.3 -0.2 -0.7 -0.6 -1.3  4.   0.8  0.2  2.9 -0.4 -0.4 -0.3 -0.2 -0.5 -0.6 -0.5  0.9 -0.1 -0.3 -1.3 -0.1 -0.2  2.7 -0.3  1.6  2.3 -0.2 -2.1 -0.6 -0.1 -0.  -0.3 -0.1 -0.2 -0.8 -0.5  3.8 -0.2  0.4 -0.2  0.5 -1.1 -0.2 -0.3 -1.  -0.7  5.7 -0.2  0.  -0.1 -0.9  0.  -0.5 -0.2 -0.3 -0.1 -1.8 -0.  -0.4 -0.7 -0.3 -0.9  0.2  8.3  0.1 -0.4  6.9]
ty_50sample [[4 5 2 9 8 1 7 3 0 6]
 [6 6 0 1 5 2 4 3 9 7]
 [9 2 1 1 6 4 8 0 7 7]
 [9 6 5 8 4 7 7 0 3 1]
 [9 4 5 8 1 7 6 0 0 3]
 [3 8 5 0 6 2 7 9 1 4]
 [4 8 5 5 0 2 9 3 7 6]
 [8 1 2 4 7 6 3 0 5 5]
 [4 7 9 5 0 3 1 2 6 8]
 [3 7 0 6 1 9 4 8 5 2]]
tt_50sample [[4 5 9 2 8 1 7 3 0 6]
 [6 8 0 1 5 2 4 3 9 7]
 [9 2 5 1 6 4 8 0 3 7]
 [9 6 5 8 4 7 2 0 3 1]
 [9 4 5 8 1 7 6 2 0 3]
 [3 8 5 0 6 2 7 9 1 4]
 [4 8 5 1 0 2 9 3 7 6]
 [8 1 2 7 4 6 3 0 5 9]
 [4 7 5 9 0 3 1 2 6 8]
 [3 7 0 6 1 9 4 8 5 2]]
vm  [-0.2 -0.6 -0.9  4.1 -0.9 -0.3 -0.4 -0.1  1.8 -0.5  0.7 -0.6  0.3 -0.1 -1.2  3.8 -0.2 -0.1 -0.3 -0.  -0.5 -0.2  2.  -0.2 -0.6  0.2 -0.3 -0.  -0.5 -2.3 -1.2 -0.5 -0.5 -4.1  0.4 -0.5 -0.2  3.6  3.  -1.2 -0.1 -0.1 -0.3  0.5 -0.2  0.1 -0.5 -0.9  4.8  3.1 -0.8 -0.5 -0.4  4.6 -0.5  2.7 -0.1  4.5  5.2  4.9 -0.6 -0.2  0.1  3.9 -1.   0.2  0.1 -0.1 -0.3  0.5 -0.2  0.1  0.1  0.3 -2.3 -0.1 -1.3 -0.2 -0.8  0.1 -1.7 -0.1 -0.1  0.3 -1.5  0.4 -0.  -0.1  0.2 -0.1 -0.2 -0.6 -0.1 -0.8 -0.2 -0.   1.2 -1.7 -0.  -0.1  1.2 -2.2 -0.8  0.5 -0.1 -0.2 -1.1 -1.4  0.2 -0.7 -0.6  0.5 -0.1 -0.6  2.4  2.5 -0.4  1.7 -0.2 -0.3 -0.3  2.2 -0.3 -0.3 -0.3 -1.5 -0.4 -0.8  6.5  3.1  1.6 -1.3 -0.2 -0.7  6.1 -2.7 -0.2 -0.4 -0.1  0.6 -0.6 -0.7 -1.  -0.2 -0.3 -0.1 -0.1 -0.2  5.8 -0.  -0.1 -0.4  4.9 -0.5 -0.3 -0.2 -0.2 -0.7  1.6 -0.2 -0.2 -0.7 -0.5 -0.3 -0.5 -0.5  1.   0.4 -0.3  1.  -0.3 -0.1 -0.6 -0.4 -0.3 -1.4 -0.3 -0.1  0.2 -0.5 -1.4 -0.3 -0.9 -1.2  0.5 -0.3  3.   1.  -0.5  8.   0.4 -0.2 -1.  -0.4  4.3 -2.3 -0.1 -1.  -0.3 -0.2 -0.4 -0.1 -0.6 -0.8 -0.4 -1.7 -0.1  1.   3.2  0.5 -0.7  1.9 -0.9 -0.8 -0.9 -0.5  1.  -0.2 -0.5 -0.6 -0.  -0.1 -0.3 -1.1 -0.7  2.6  1.1  2.1 -0.7  7.4 -0.9 -0.6 -0.2  2.5  0.8  3.3  0.9 -0.5  1.6 -0.5 -0.2 -0.3  0.2 -0.4  7.3 -0.4 -0.4  0.3 -1.2 -0.5  3.4 -0.6  1.8  0.1  0.3 -0.2]
vy_50sample [[8 2 3 5 9 9 6 4 1 7]
 [7 9 2 1 8 0 5 3 4 6]
 [7 4 0 3 1 5 6 9 2 8]
 [7 5 9 6 3 8 4 1 2 0]
 [8 6 6 4 2 3 9 7 5 1]
 [2 9 1 0 3 8 4 6 5 7]
 [5 1 2 9 7 3 6 8 4 0]
 [7 2 4 6 6 5 0 8 1 3]
 [8 2 9 1 7 5 5 3 6 4]
 [5 9 7 7 4 8 1 3 2 6]]
vt_50sample [[8 2 3 5 0 9 6 4 1 7]
 [7 9 2 1 8 0 5 3 4 6]
 [7 4 0 3 5 1 6 9 2 8]
 [7 5 9 6 3 8 4 1 0 2]
 [8 0 6 4 2 3 9 7 5 1]
 [2 9 1 0 3 8 4 6 5 7]
 [5 1 9 2 7 6 3 8 4 0]
 [7 2 4 6 9 5 0 8 1 3]
 [8 2 9 1 7 0 5 3 6 4]
 [5 9 7 0 4 8 1 3 2 6]]
Epoch 16910: Training cost= 0.3321, Training acc= 0.8058, Validation cost= 0.3491, Validation acc= 0.8060
Epoch 16920: Training cost= 0.3142, Training acc= 0.8058, Validation cost= 0.3247, Validation acc= 0.8061
Epoch 16930: Training cost= 0.2989, Training acc= 0.8058, Validation cost= 0.3318, Validation acc= 0.8061
Epoch 16940: Training cost= 0.4144, Training acc= 0.8059, Validation cost= 0.2836, Validation acc= 0.8061
Epoch 16950: Training cost= 0.3779, Training acc= 0.8059, Validation cost= 0.3133, Validation acc= 0.8062
Epoch 16960: Training cost= 0.3422, Training acc= 0.8059, Validation cost= 0.3243, Validation acc= 0.8062
Epoch 16970: Training cost= 0.3443, Training acc= 0.8060, Validation cost= 0.2558, Validation acc= 0.8062
Epoch 16980: Training cost= 0.3515, Training acc= 0.8060, Validation cost= 0.3031, Validation acc= 0.8063
Epoch 16990: Training cost= 0.3171, Training acc= 0.8061, Validation cost= 0.2863, Validation acc= 0.8063
Epoch 17000: Training cost= 0.3214, Training acc= 0.8061, Validation cost= 0.2907, Validation acc= 0.8064
tm  [ 0.5 -0.1  3.   8.  -1.  -0.5 -0.4 -0.6 -0.5 -0.2  1.2 -0.4 -0.4 -0.2 -0.5  2.4  0.7 -0.  -0.4 -0.6 -0.4 -0.4  2.1 -0.  -0.9  0.2  0.2  0.1 -0.7 -0.8 -1.8 -0.4 -0.4 -3.3  0.5 -0.1  2.   3.2  1.2 -0.5 -0.1  5.5  1.8 -0.8 -0.5 -0.4  1.9 -0.9  2.5  6.5 -0.7 -0.2 -0.9  5.4 -0.2  1.8 -0.3  8.5 -0.2  6.  -0.6 -0.4 -0.6  0.6 -0.6 -0.2 -0.1  0.1 -0.2 -0.8 -0.4  1.8 -0.1 -0.5 -2.8  0.4 -0.4 -0.  -0.7 -0.3 -2.1 -0.2 -0.4  1.6 -1.1  6.2 -0.1 -0.4 -0.1 -0.1 -0.5 -0.2 -0.4  1.8 -0.6 -0.2  1.6 -1.1 -0.  -0.8  0.4 -0.3 -1.1 -0.3 -0.1 -0.2 -1.7 -1.6  0.9 -0.7  0.2 -0.3 -0.1 -0.2 -0.1 -0.5 -0.4 -0.4 -0.3  0.5 -0.2  2.2 -0.3 -0.6 -0.2 -0.7 -0.5 -1.   1.   0.3  1.7 -0.6 -0.1 -0.2  5.2 -1.8 -0.3 -0.3  0.6 -0.5 -1.1 -1.1 -0.5 -0.3 -0.3 -0.1 -0.5 -0.6  6.4 -0.2 -1.  -0.1  4.4 -0.7 -0.3 -0.  -0.3 -0.5 -0.4 -0.4 -0.2 -0.3 -0.1 -0.1 -0.4 -0.1 -0.2 -0.9 -0.6  0.6 -0.3  0.7 -0.4 -0.3 -0.5 -1.7 -1.  -0.3  1.1 -0.2 -1.8 -0.3  0.3 -1.2 -0.1  0.5  3.5 -0.2 -0.1  3.4 -0.1 -0.5 -0.7 -0.8  4.8 -0.6 -1.  -0.2 -0.2 -0.3 -0.4 -0.4 -0.5 -0.1 -0.7 -1.6  0.5 -0.2 -0.8 -0.1 -0.7 -0.6 -0.4 -0.7 -0.5 -0.3  4.  -0.6 -0.3 -0.5  0.1 -0.2 -0.4 -1.1  1.5  0.3  0.3  0.9 -0.3  2.7 -0.7  1.3 -0.3 -0.4 -0.2 -0.4  1.8 -1.1 -0.4 -2.5 -0.3 -1.2 -0.2  0.2  7.3 -0.6  1.4 -0.3 -0.6 -0.2  4.7 -0.3  0.6 -0.1 -0.5  2.8]
ty_50sample [[5 2 2 0 6 9 3 7 1 4]
 [6 4 8 7 3 0 2 5 1 9]
 [0 6 9 1 8 5 4 7 2 3]
 [4 4 8 7 5 3 9 0 2 1]
 [6 4 1 7 0 8 8 3 9 5]
 [7 5 6 2 4 0 3 9 1 8]
 [5 1 9 9 7 0 0 2 4 6]
 [9 0 6 4 5 8 1 2 7 3]
 [8 6 7 9 0 5 3 4 1 2]
 [8 0 2 6 1 7 5 4 9 3]]
tt_50sample [[5 2 8 0 6 9 3 7 1 4]
 [6 4 8 7 3 0 2 5 1 9]
 [0 6 9 1 8 5 4 7 2 3]
 [4 6 8 7 5 3 9 0 2 1]
 [6 4 1 7 0 2 8 3 9 5]
 [7 5 6 2 0 4 9 3 8 1]
 [5 1 9 3 8 7 0 2 4 6]
 [9 0 6 4 5 8 1 2 7 3]
 [8 6 7 9 0 5 3 4 1 2]
 [8 0 2 6 7 1 5 4 9 3]]
vm  [ 2.4 -0.1  3.   1.6 -1.6 -0.6 -0.3 -0.3 -0.5 -0.5  9.7 -0.3 -0.1 -0.4  3.   1.2  1.1 -0.4  0.3 -0.  -0.7 -0.2 -0.7  0.6 -1.4  3.4 -0.4 -0.4 -1.5 -1.3  1.6 -0.3 -0.6  5.7  2.4  0.3  2.9  4.8  1.2 -0.8  0.4  2.5  1.6  0.9 -0.4 -0.1 -0.7 -1.3  4.9 -1.2 -0.4 -0.5 -0.4  7.7  1.4 -0.1 -0.7  3.7  0.3 -0.5 -0.6 -0.1 -0.2  3.5 -0.2 -0.2 -0.  -0.2 -0.3  0.1 -0.1  4.6 -0.1  0.2 -3.1 -0.2 -0.8 -0.2 -0.5 -0.1  5.1 -0.2 -0.2 -0.4 -1.5  2.6  2.5 -0.1 -0.2 -0.4 -0.4 -0.9 -0.5 -0.1 -0.3 -0.   1.1 -1.5 -0.5 -0.7  1.2  1.8 -1.1 -0.2 -0.   1.1 -1.3  2.4  3.1 -0.5 -0.5  0.2 -0.2  0.1  2.3 -1.6 -0.1 -0.1 -0.3  0.5  0.   2.3 -0.2 -0.  -0.1  3.2 -0.9 -1.9  1.4  2.3  1.7 -0.1 -0.4 -0.2 -1.1  4.3 -0.6 -0.3 -0.2 -0.1 -1.1 -1.  -0.7 -0.1  0.1 -0.3 -0.3 -0.5  2.5 -0.5 -0.2 -0.2  2.1 -0.9 -0.5 -0.3 -0.3 -0.1  0.7 -0.   0.1 -1.  -0.  -0.2 -0.  -0.6 -0.8 -0.8 -0.4  0.  -0.5 -0.  -0.2 -0.3 -0.3 -0.3 -0.5 -0.1  1.2 -0.5 -1.3  0.7 -0.3 -1.3  0.5 -0.3  3.5 -0.4 -0.2  4.  -0.1 -0.5 -0.1 -0.8  5.8 -0.4 -0.6 -0.4 -0.2  0.7 -0.  -0.4 -0.1 -0.6 -0.7 -1.5 -0.3 -0.2 -2.3 -0.3 -0.3 -1.3 -0.4 -0.8 -0.5 -0.4  0.4 -0.6 -0.7 -0.6  0.7 -0.2 -0.2 -1.1 -0.2 -1.3  2.9  1.1  0.4  3.6 -0.6 -0.1 -0.3 -1.5  2.6 -0.5  1.6 -0.8 -0.2 -1.2 -0.2 -0.5 -0.4 -0.  -0.6 -0.  -0.2 -0.1 -0.8 -0.3 -1.2 -0.2  1.2  0.7 -0.7 -0.2]
vy_50sample [[2 0 5 7 3 4 6 9 8 1]
 [1 0 6 7 9 2 4 5 8 3]
 [8 0 6 3 4 9 1 7 5 2]
 [1 9 5 2 8 0 6 3 7 4]
 [4 0 6 7 3 9 1 5 8 2]
 [6 7 4 0 5 2 2 3 1 1]
 [6 2 0 5 1 8 3 9 7 4]
 [7 8 2 3 6 0 1 5 4 9]
 [4 1 9 6 7 2 0 3 8 5]
 [6 1 2 5 3 8 9 0 4 7]]
vt_50sample [[2 0 5 7 3 4 6 9 8 1]
 [1 0 6 7 9 2 4 5 8 3]
 [0 8 6 3 4 9 1 7 5 2]
 [1 5 9 2 8 0 6 3 7 4]
 [4 0 6 7 3 9 1 5 8 2]
 [6 7 0 4 5 2 3 8 1 9]
 [6 2 0 5 1 8 3 9 7 4]
 [7 8 2 3 6 0 1 5 4 9]
 [4 1 9 7 6 2 0 3 8 5]
 [6 1 2 3 5 8 9 0 4 7]]
Epoch 17010: Training cost= 0.2764, Training acc= 0.8061, Validation cost= 0.3341, Validation acc= 0.8064
Epoch 17020: Training cost= 0.3265, Training acc= 0.8062, Validation cost= 0.2609, Validation acc= 0.8064
Epoch 17030: Training cost= 0.3424, Training acc= 0.8062, Validation cost= 0.3261, Validation acc= 0.8065
Epoch 17040: Training cost= 0.3509, Training acc= 0.8063, Validation cost= 0.2912, Validation acc= 0.8065
Epoch 17050: Training cost= 0.3549, Training acc= 0.8063, Validation cost= 0.2997, Validation acc= 0.8066
Epoch 17060: Training cost= 0.2739, Training acc= 0.8064, Validation cost= 0.3116, Validation acc= 0.8066
Epoch 17070: Training cost= 0.3423, Training acc= 0.8064, Validation cost= 0.3274, Validation acc= 0.8066
Epoch 17080: Training cost= 0.2936, Training acc= 0.8064, Validation cost= 0.3651, Validation acc= 0.8067
Epoch 17090: Training cost= 0.3901, Training acc= 0.8065, Validation cost= 0.2893, Validation acc= 0.8067
Epoch 17100: Training cost= 0.3504, Training acc= 0.8065, Validation cost= 0.3378, Validation acc= 0.8068
tm  [-0.8 -0.1 -3.2 -4.2 -0.4 -0.2 -0.3 -0.4 -1.3 -0.2 -4.   0.2 -0.9 -0.2  1.9 -1.8  0.1  0.5  0.2  2.7 -0.4 -0.8  2.2 -0.1 -1.3  1.2 -0.5 -0.6 -1.8 -0.7  0.1  0.8 -0.3 -5.1  0.3  0.3  3.8 -1.  -3.2 -0.9 -0.2 -0.3  0.3  1.6 -0.9 -0.  -3.2  0.4 -0.5  5.8 -0.5 -0.4 -1.3  4.2 -0.  -0.3 -1.2 -1.3 -0.   2.1  9.   0.2 -0.7 -0.1 -1.1 -0.2 -0.1 -0.   0.3 -0.2 -0.1  4.  -0.1 -0.7 -5.6 -0.6  0.9 -0.2  1.4  0.  -5.9 -0.4 -0.2  0.4 -0.2 -0.5  1.8 -0.2 -0.2 -0.5 -0.6 -0.5 -0.5  2.7 -0.8 -0.  -0.6 -2.  -0.3  0.5  0.1 -1.6  2.  -0.3 -0.1 -0.6 -3.4 -0.2 -1.4  1.  -0.6 -0.4 -0.2 -0.3  3.  -1.6 -0.6  0.3 -0.1 -0.1 -0.  -1.  -0.3 -0.3 -0.5  2.5 -0.2 -0.7 -0.   8.4 -0.2 -0.2 -0.  -0.   9.7 -1.4 -0.4 -0.2 -0.5 -0.3  2.4 -1.3 -0.1 -0.1 -0.2 -0.3 -0.2 -0.2  3.4 -0.3  3.7 -0.3  2.3  0.1 -0.4 -0.4  0.7 -0.2 -0.7 -0.6 -0.3  0.1 -0.4 -0.4 -0.9 -0.5 -0.3  1.6 -0.1 -1.  -0.4  0.2 -0.1 -0.3 -0.  -1.  -0.8 -1.8  8.8 -0.5 -0.8  0.   0.1 -1.4  0.9  1.  -1.6  1.8 -0.   2.3 -0.7 -0.6  1.6 -1.5 -2.6  1.5 -2.2 -0.3 -0.1 -0.1  0.3 -0.3 -0.  -0.7 -0.  -4.7 -0.6 -0.1  6.6 -0.5 -0.3 -2.  -0.9  2.4  1.4 -0.2 -0.5 -0.4 -0.2 -0.1 -0.5 -0.3 -0.1 -0.9  0.8 -0.4 -1.5 -0.4 -0.4  0.2 -0.7  2.6 -0.4  4.5  3.6  6.9  1.6 -2.9  0.8 -2.8 -0.1 -1.3 -0.3 -0.2 18.2  8.7 -0.2 -0.1 -0.5  0.  14.  -0.4 -2.4 -0.7  3.2 -2.3]
ty_50sample [[8 0 4 1 3 5 5 2 7 9]
 [6 6 5 7 3 2 1 0 9 4]
 [5 5 3 9 8 0 4 6 7 2]
 [2 0 3 6 7 4 1 8 5 9]
 [6 0 8 3 1 5 9 2 4 7]
 [6 0 2 1 8 4 7 3 5 9]
 [5 1 8 0 6 4 4 7 3 9]
 [9 1 6 7 8 2 3 5 4 4]
 [9 8 0 0 4 6 2 5 3 7]
 [4 9 0 3 8 8 1 7 5 6]]
tt_50sample [[8 0 4 6 1 3 5 2 7 9]
 [8 6 5 7 3 2 1 0 9 4]
 [5 1 3 9 8 0 4 6 7 2]
 [2 0 3 6 7 4 1 8 5 9]
 [0 6 8 3 1 9 5 2 4 7]
 [6 0 2 1 8 4 7 3 5 9]
 [5 1 8 0 6 2 4 7 3 9]
 [9 1 6 7 8 2 3 0 4 5]
 [9 8 0 1 4 2 6 5 3 7]
 [4 9 0 2 3 8 1 7 5 6]]
vm  [-0.9 -0.6 -0.5 -2.  -1.  -0.3 -0.1 -0.5  1.9 -0.7  9.7  0.5 -0.   0.   4.9  5.1 -0.1 -0.6 -0.2  3.4 -0.7 -0.4 -1.4 -0.7 -1.1 -0.3 -0.  -0.3  1.  -2.1  3.8 -0.8 -0.2  4.8 -0.4 -0.4 -0.4  5.  -0.8 -0.4 -0.2  3.3 -0.2  1.5 -0.7 -0.4 -2.7 -0.8 -0.4 -2.7 -0.6 -0.3 -0.6  9.8 -1.3 -0.5 -0.2  5.2  5.1 -1.4  8.3 -0.7 -0.1  0.4  0.1 -0.7 -0.2  2.8 -0.5 -0.3 -0.4 -1.  -0.3 -0.3 -6.1 -0.1 -0.3 -0.5 -0.3 -0.3  0.8 -0.1  0.3 -0.2 -0.3  5.  -0.6 -0.2 -0.2 -0.3 -0.1 -0.3 -0.1 -0.6 -0.8 -0.3 -0.3 -2.2 -0.4 -0.6  2.3 -1.1  1.4 -0.3 -0.4  0.5 -3.1  3.1  1.5  2.9  0.1 -0.3 -0.4 -0.8  1.   6.2 -0.1  2.  -0.2  1.2 -0.4 -1.  -0.1  0.  -0.1  5.6  0.8 -2.6  7.4  7.  -0.8 -0.6 -0.3 -0.2 -0.1  5.4 -0.4 -0.3 -0.2 -0.5 -0.9  1.7 -0.7 -0.3 -0.1  0.3 -0.1 -0.1  6.7 -0.5  2.4 -0.3 -1.8 -0.5 -0.3 -0.1 -0.6 -0.2  2.9 -0.  -0.4 -0.9  0.9 -0.2 -0.1 -0.4 -0.1  1.2 -0.3 -0.4 -0.7  1.3 -0.6 -0.4 -0.3 -1.8 -0.3 -1.4  4.1 -0.2 -1.8 -0.1 -0.3 -1.4  0.8 -0.  -1.2 -0.6 -0.4  7.3 -0.4 -0.2 -0.  -0.7 -2.3 -1.3 -1.8 -0.6 -0.3 -0.3  0.5  0.1  0.1 -0.6 -0.2 -3.6 -0.1 -0.3 -5.4 -0.2 -0.4  2.3 -0.6  4.  -0.3 -0.1 -0.1 -0.5 -0.4 -0.2 -0.2 -0.2 -0.  -0.7 -0.8 -0.1  0.1  2.6  0.5  2.6 -0.8  1.  -0.4 -3.7 -0.6  1.7 -0.1 -2.2 -0.2 -5.5 -0.2 -2.7 -0.3 -0.1  1.3  4.7 -0.2 -0.6 -1.  -0.1 -0.3 -0.4 -0.6 -0.2  1.3 -2.2]
vy_50sample [[5 2 1 3 4 7 6 0 8 9]
 [2 6 0 0 1 9 4 3 8 5]
 [0 5 2 4 7 3 8 9 6 1]
 [9 5 6 0 7 1 3 2 4 8]
 [7 7 6 6 4 5 2 8 3 0]
 [2 2 1 1 4 6 0 9 5 7]
 [7 7 1 3 3 2 5 6 4 9]
 [1 7 2 3 5 0 8 8 6 9]
 [6 9 0 0 1 2 3 7 4 5]
 [9 4 3 1 8 2 6 0 5 7]]
vt_50sample [[5 2 1 3 4 7 6 0 8 9]
 [2 6 0 7 1 9 4 3 5 8]
 [0 5 2 4 7 3 8 9 6 1]
 [9 5 6 0 7 1 3 2 4 8]
 [9 7 1 6 4 5 2 8 3 0]
 [8 2 3 1 4 6 0 9 5 7]
 [7 8 0 1 3 2 5 6 4 9]
 [1 7 2 3 5 0 4 8 6 9]
 [6 9 0 8 1 2 3 7 4 5]
 [9 4 3 1 8 2 6 0 5 7]]
Epoch 17110: Training cost= 0.3592, Training acc= 0.8065, Validation cost= 0.3422, Validation acc= 0.8068
Epoch 17120: Training cost= 0.3122, Training acc= 0.8066, Validation cost= 0.3694, Validation acc= 0.8068
Epoch 17130: Training cost= 0.3501, Training acc= 0.8066, Validation cost= 0.3829, Validation acc= 0.8069
Epoch 17140: Training cost= 0.3625, Training acc= 0.8066, Validation cost= 0.3292, Validation acc= 0.8069
Epoch 17150: Training cost= 0.4083, Training acc= 0.8067, Validation cost= 0.3773, Validation acc= 0.8069
Epoch 17160: Training cost= 0.3456, Training acc= 0.8067, Validation cost= 0.4499, Validation acc= 0.8069
Epoch 17170: Training cost= 0.3472, Training acc= 0.8067, Validation cost= 0.3723, Validation acc= 0.8070
Epoch 17180: Training cost= 0.3687, Training acc= 0.8068, Validation cost= 0.3177, Validation acc= 0.8070
Epoch 17190: Training cost= 0.3345, Training acc= 0.8068, Validation cost= 0.3585, Validation acc= 0.8070
Epoch 17200: Training cost= 0.3383, Training acc= 0.8068, Validation cost= 0.3256, Validation acc= 0.8071
tm  [-1.  -1.   7.9 11.9 -1.4 -0.2  0.6 -0.2 -0.2  1.9 -2.2 -0.2 -0.8 -0.2  3.  -2.3 -0.6 -0.6 -0.6 -1.  -0.6  0.4  0.8 -0.2 -0.4  1.2 -0.1 -0.4 -1.  -1.3 -0.9  0.5  1.9  5.   0.4 -0.6  1.6 -1.7 -1.3 -0.4  0.5 -0.7 -1.  -1.5  0.1 -0.3  3.7  2.  -0.2  1.9 -0.4 -0.2 -0.5 -1.9  1.8 -0.2 -0.7 -0.1  3.1  3.5  0.4 -0.2 -0.1  2.4 -0.2 -0.2  0.5 -0.1  0.6  0.6 -0.1  3.6 -0.6 -0.3 -2.1 -0.5 -0.4 -0.2 -0.3 -0.1  3.9  0.8 -0.6 -0.6 -0.4 -1.2 -0.6 -0.1 -0.3 -0.3 -0.6 -0.8 -0.4 -0.9 -0.1 -0.1 -0.  -1.1  0.4 -0.  -1.2  3.4  0.9 -0.2 -0.2 -0.  -0.9 -0.9 -0.8 -1.9 -0.   0.1 -0.2 -0.7  7.2 -2.3 -0.3  1.9 -0.2 -0.2 -0.1  5.8 -0.5 -0.2 -0.4  3.  -0.4  9.4  0.2 -0.5  1.  -0.5 -0.5  0.   3.9  9.8 -0.1 -0.1 -0.6 -0.9  1.9 -0.7  1.2 -0.4 -0.1 -0.3 -0.6 -0.4 -1.8 -0.4 -0.8 -0.2 -0.2 -0.  -0.7 -0.  -0.4  0.1 -1.5 -0.6 -0.5  1.9 -0.1 -0.2  0.  -0.  -1.1  2.4 -0.5  0.7 -0.4 -0.7  0.8 -0.3  0.5  5.3 -1.2  0.7  4.2 -0.2  1.3  0.5 -0.  -0.7 -0.  -0.6  1.  -0.7  0.   4.1 -0.2 -0.3 -1.1 -0.7  1.7 -0.2 -0.7 -0.8 -0.1  0.3 -0.  -0.   0.3 -0.3 -0.3 -0.7 -0.5 -0.3  6.1  0.8 -0.2 -0.9 -0.5  1.  -0.9 -0.5  5.8 -0.6 -0.8 -0.2 -0.8 -0.2 -0.1 -1.   2.3 -1.  -1.7 -0.  -0.2  0.4  0.3 -0.2 -0.3  3.2  2.  -1.9  1.8 -0.6  2.1 12.4 -0.3  6.4 -0.3 -0.3 -0.3 -0.9 -0.4 -0.4 -0.6  0.8 -1.2 -0.8 -0.8 -0.   3.5  4.5]
ty_50sample [[0 6 7 1 1 8 3 4 5 2]
 [5 6 4 4 9 2 7 1 0 8]
 [9 2 3 5 1 7 0 6 8 4]
 [9 6 7 4 5 1 8 3 2 0]
 [8 6 1 2 0 7 4 9 5 3]
 [6 9 0 7 8 1 4 5 3 2]
 [2 7 7 0 0 4 6 5 3 1]
 [5 6 8 1 9 3 7 4 2 0]
 [6 1 2 3 7 4 4 5 8 0]
 [5 1 3 4 8 6 7 9 0 2]]
tt_50sample [[0 6 7 9 1 8 3 4 5 2]
 [5 6 4 3 9 2 7 1 0 8]
 [2 9 3 5 1 7 0 6 8 4]
 [9 6 7 4 5 1 8 3 2 0]
 [8 6 1 2 0 7 4 9 5 3]
 [6 9 0 7 8 1 4 5 3 2]
 [2 7 9 8 0 4 6 5 3 1]
 [5 6 8 1 9 3 7 4 0 2]
 [6 1 2 3 7 4 9 5 8 0]
 [5 1 3 8 4 6 7 9 0 2]]
vm  [-1.5 -0.2  6.3 14.1 -1.7  0.4 -0.  -0.1  0.2 -0.6  4.   1.6 -0.6 -0.3 -0.6  3.4 -0.4 -0.6 -0.2 -1.4 -0.6  0.5 -0.7 -0.3 -1.4  1.6 -0.2 -0.1  2.1 -1.1  0.7 -0.6 -0.2  8.1 -1.2 -0.1  1.2  1.8 11.2 -0.1 -0.2  0.7 -0.1 -0.2 -0.4 -0.4  9.   1.  -1.5 -1.4 -0.6  1.3  2.5 -1.8 -1.5  1.8 -0.5  5.1 -0.1  1.5  1.1 -0.4  0.5 -0.   2.1 -0.1 -0.3 -0.2 -0.1 -0.2  0.  -1.2 -0.2 -0.6  3.4  0.3  1.1 -0.1 -0.3 -0.3 15.7 -0.1 -0.5  0.5  1.1  2.8 -1.4 -0.2  0.5 -0.1 -0.3  0.8 -0.  -0.5 -0.  -0.2  1.8  0.6 -0.3 -0.3  3.1  2.5  1.9 -0.  -0.6 -0.2  0.7  0.9  1.5 -1.7  0.3 -0.6 -0.  -0.3 -0.4  7.   0.2 -0.7  0.  -0.1 -0.3  6.1 -0.2 -0.2 -0.  -0.7  3.5  8.8  2.  -1.  -1.  -0.5 -0.9 -0.4 -2.9  3.3 -0.1 -0.4  0.5 -0.8 -0.2 -0.   0.5 -0.4 -0.3 -0.   1.   0.   0.7 -0.4 -1.3  0.3 -1.4  0.5 -0.1 -0.3 -0.6 -0.3  2.3 -0.1 -0.4 -0.8 -0.  -0.  -0.2 -0.6  1.   0.4 -0.7  1.8 -0.6 -0.  -0.3 -0.4  0.8  0.4 -0.5  1.8 -1.7  0.2 -1.1 -0.2 -0.2 -1.2 -0.6 -0.2 -0.2 -0.6 -0.2  3.9 -0.3 -0.3 -1.3 -0.7  0.7  0.5  2.3  0.8 -0.1 -0.5 -0.3 -0.2 -0.2 -0.5  0.   4.9  0.1 -0.4 -2.4 -0.  -0.3  4.3 -0.3  6.2 -0.9  0.7  1.2 -0.3 -0.1 -0.1 -0.7 -0.1 -0.1 -0.7 -0.7  1.5 -1.1  2.   0.9 -0.6 -0.5 -0.6 -0.1 -1.6 -0.8 -1.6 -0.4  2.8 -0.1  6.3 -0.1  3.1 -0.3 -0.2 -3.2 -3.  -0.1 -0.5 -0.7 -0.4 -3.8 -0.4  8.6  0.3  3.   5.9]
vy_50sample [[9 9 7 7 3 2 6 6 8 0]
 [6 7 0 5 4 8 3 1 9 2]
 [4 6 0 2 9 5 7 1 3 8]
 [8 1 4 2 3 5 9 0 7 6]
 [7 9 3 0 8 6 5 1 4 2]
 [8 6 4 4 2 0 1 9 3 5]
 [2 8 5 7 1 9 3 6 0 4]
 [9 9 8 6 4 3 5 0 2 7]
 [2 8 4 5 9 7 1 3 0 6]
 [9 0 4 1 7 7 5 2 3 6]]
vt_50sample [[9 1 7 5 3 2 6 0 4 8]
 [6 7 0 5 4 8 3 1 9 2]
 [4 6 0 2 9 5 1 7 3 8]
 [1 8 4 3 2 5 9 0 7 6]
 [7 9 3 0 8 6 5 1 4 2]
 [8 6 7 4 2 0 1 9 3 5]
 [2 8 5 1 7 9 3 0 6 4]
 [9 1 8 6 4 3 5 0 2 7]
 [2 8 4 5 9 7 1 3 0 6]
 [9 0 4 1 8 7 5 2 3 6]]
Epoch 17210: Training cost= 0.2764, Training acc= 0.8069, Validation cost= 0.3428, Validation acc= 0.8071
Epoch 17220: Training cost= 0.3243, Training acc= 0.8069, Validation cost= 0.3329, Validation acc= 0.8072
Epoch 17230: Training cost= 0.2981, Training acc= 0.8069, Validation cost= 0.3197, Validation acc= 0.8072
Epoch 17240: Training cost= 0.3601, Training acc= 0.8070, Validation cost= 0.2907, Validation acc= 0.8072
Epoch 17250: Training cost= 0.3188, Training acc= 0.8070, Validation cost= 0.3296, Validation acc= 0.8073
Epoch 17260: Training cost= 0.3263, Training acc= 0.8071, Validation cost= 0.2960, Validation acc= 0.8073
Epoch 17270: Training cost= 0.2842, Training acc= 0.8071, Validation cost= 0.3150, Validation acc= 0.8074
Epoch 17280: Training cost= 0.3538, Training acc= 0.8071, Validation cost= 0.3048, Validation acc= 0.8074
Epoch 17290: Training cost= 0.3207, Training acc= 0.8072, Validation cost= 0.3322, Validation acc= 0.8074
Epoch 17300: Training cost= 0.3380, Training acc= 0.8072, Validation cost= 0.4308, Validation acc= 0.8075
tm  [ 0.6  2.9  2.   6.8 -0.8 -0.4 -0.1 -0.1 -0.8 -1.3 -0.8 -0.5  0.8 -0.  -0.8  7.8  0.9 -0.3 -0.2 -0.9 -0.1 -0.2  1.5  0.2 -1.1 -0.1 -0.2 -0.1  1.5  0.  -1.3 -0.7 -0.2 -3.  -0.6  1.   2.2  3.3  3.5 -0.6 -0.1 -0.6  1.6 -0.2 -0.  -0.5  2.6 -0.6  2.8  4.4 -0.6 -0.3 -0.1  1.7 -1.3  2.2 -0.1  3.4 -0.8  5.  -1.2 -0.3 -0.2  0.3 -0.6 -0.1 -0.1 -0.5 -0.3  0.6 -0.3 -0.8 -0.  -0.1  0.7 -0.3 -0.7 -0.1 -0.5 -0.1 -1.  -0.2 -0.4 -0.2 -1.3 -0.   0.6 -0.1  1.9  0.1  0.4  1.5  0.1  2.2  0.5 -0.2  1.4 -0.8  0.5 -0.2  5.  -1.1 -0.7 -0.1  0.6 -0.3 -0.1 -1.5 -0.3 -1.1 -0.6 -0.1 -0.5 -0.2 -1.4  8.8 -0.5 -1.2 -0.3 -0.3 -0.3  4.6 -0.2 -0.2 -0.2 -1.   1.3  0.1 -0.3  1.2  2.9 -0.3 -0.  -0.5  4.  -2.4  0.4 -0.3  1.3  2.9 -0.5 -0.8 -0.4 -0.1 -0.1 -0.1 -0.3 -0.2  3.   0.6 -0.5 -0.2  4.6 -0.7 -0.3 -0.  -0.3 -0.3 -0.2 -0.2 -0.3  0.  -0.4 -0.  -0.3 -0.4  1.7 -0.3  0.6  1.1 -0.2  0.  -0.6 -0.4 -0.3 -0.2 -0.5  1.4 -0.2 -0.4 -1.  -0.2 -0.6 -1.1 -0.8  0.6  3.6 -0.4 -0.5  0.  -0.  -0.2 -0.7 -0.6  6.8 -0.1  2.2  1.7 -0.3 -0.1 -0.3 -0.3 -0.3 -0.8 -0.3 -0.1 -0.3 -0.2  4.7 -0.1 -0.4  4.2 -0.6 -0.3 -0.6 -0.8  2.8 -0.1 -0.3 -0.4 -0.3  0.2 -0.4 -0.8 -0.2  4.1  1.4  1.2 -0.5  3.5 -0.5 -0.7 -0.3  3.7 -0.6  0.9 -0.2  1.3 -0.   3.9 -0.2  1.5 -0.3 -0.   4.8 -1.5 -0.3 -0.1 -0.8 -0.6  1.4 -0.5  2.5  0.5  0.9  1.6]
ty_50sample [[8 2 9 3 5 5 7 4 1 0]
 [2 4 8 5 7 0 3 1 9 6]
 [1 4 0 7 6 5 2 3 9 8]
 [4 5 7 7 8 6 0 1 3 9]
 [2 4 3 9 8 5 1 0 7 6]
 [5 9 1 8 0 6 7 3 4 2]
 [8 3 9 1 5 7 0 6 4 2]
 [8 6 4 9 7 1 5 2 3 0]
 [2 4 9 5 7 6 1 3 0 8]
 [5 1 9 9 7 7 4 2 3 6]]
tt_50sample [[8 2 9 3 6 5 7 4 1 0]
 [2 4 8 5 7 0 3 1 9 6]
 [1 4 0 7 6 5 2 3 9 8]
 [4 5 2 7 8 6 0 1 3 9]
 [2 4 3 9 5 8 0 1 7 6]
 [5 1 9 8 0 6 7 3 4 2]
 [8 3 9 1 5 7 0 6 4 2]
 [8 6 4 9 7 1 5 2 0 3]
 [2 4 9 5 7 6 1 0 3 8]
 [5 1 9 8 0 7 4 2 3 6]]
vm  [-1.5 -0.6  1.2 11.4 -0.6 -0.3  0.2 -0.9 -0.2 -0.5 -1.5  0.9 -0.8 -0.4 -1.7  3.3 -0.3 -0.  -0.1 -1.  -0.7 -0.3 -0.3 -0.3 -0.8  0.8  0.  -0.2  3.  -1.3 -1.8 -0.8 -0.5 -3.7 -0.7 -0.4  0.3  3.4  7.8 -0.2 -0.1 -2.8 -1.4 -0.4 -1.  -1.   6.3 -0.5 -1.6  0.5 -0.5 -0.1 -0.5 -0.4 -1.5  4.4 -0.2 -0.1  1.6  4.3  3.1 -0.7 -0.2 -0.7 -0.5 -0.4 -0.3  2.8 -0.  -0.6 -0.5 -1.2 -0.1 -0.1 -1.9 -0.2  0.1 -0.7 -0.3 -0.  -1.1  0.6 -0.2 -0.4  0.8 -2.7 -1.5 -0.1  0.3 -0.2  0.4 -0.4  0.7 -0.2 -0.7 -0.1 -0.6 -0.8 -0.4 -0.9  1.6 -1.9  0.8 -0.4 -0.2 -0.2 -1.  -1.4 -0.5 -1.1  1.3 -0.6 -0.2 -0.4  0.5  3.6 -0.5 -0.3  0.1  0.8  0.5  2.2 -0.5  0.3 -0.  -1.9  1.5  5.1 -0.1  3.1 -0.5  1.1 -0.3  0.3  4.1 -3.3 -0.4  0.9  3.  -0.1 -0.5 -0.8 -0.7 -0.2 -0.2 -0.4 -0.3  0.1 -0.5 -0.4 -1.3 -0.1  0.3 -0.5 -0.2  0.1 -0.6 -0.6  0.   0.6 -0.5 -1.3  0.7 -0.2 -0.6 -0.2  0.3  3.7 -0.8  1.1 -1.  -0.8 -0.2  0.3 -0.5  2.1 -0.4  0.9 -1.   0.1  3.5 -0.2  1.6 -1.2 -0.9  2.  -0.4 -0.3 -0.8  4.7 -0.5 -0.4 -0.9 -1.6 -0.3  1.2  0.1  0.9 -0.5 -0.6 -0.1  0.7 -0.6 -0.8 -0.2  3.  -0.5 -0.7  8.9 -0.1 -0.6  3.3 -1.1  5.9 -0.8 -0.1  2.2 -0.5 -0.3  1.8 -0.9 -0.6 -0.4 -1.  -1.1  2.2 -1.1  2.4  0.2 -0.5 -0.5  0.1 -0.4  5.1 -1.5  0.1 -0.1 -0.6 -0.4 13.  -0.4  6.8 -0.5 -0.1  4.1 -2.9  1.9 -0.5 -0.6 -0.2  1.5 -0.1  5.6  1.2  2.7 -0.3]
vy_50sample [[1 3 9 9 2 6 7 4 5 5]
 [6 1 3 0 5 5 9 9 4 2]
 [9 0 6 6 4 7 8 5 2 1]
 [6 0 9 8 8 7 5 4 3 1]
 [9 7 2 5 8 6 0 0 1 3]
 [8 5 5 0 0 9 1 2 3 6]
 [0 4 6 2 7 8 9 9 5 3]
 [9 3 4 2 0 5 6 7 1 8]
 [5 4 7 3 6 1 8 2 9 9]
 [9 1 4 6 2 8 0 5 7 3]]
vt_50sample [[1 3 8 9 2 6 0 7 4 5]
 [6 1 3 0 7 5 9 4 8 2]
 [9 0 3 4 6 7 8 5 2 1]
 [6 0 2 9 8 7 5 4 3 1]
 [9 7 2 5 8 6 0 4 1 3]
 [7 8 5 9 0 4 1 2 3 6]
 [0 4 6 2 7 8 9 1 5 3]
 [3 9 4 2 5 0 6 7 1 8]
 [5 4 7 3 6 8 1 2 0 9]
 [9 1 4 2 6 8 0 5 7 3]]
Epoch 17310: Training cost= 0.4171, Training acc= 0.8072, Validation cost= 0.4598, Validation acc= 0.8075
Epoch 17320: Training cost= 0.4048, Training acc= 0.8073, Validation cost= 0.3903, Validation acc= 0.8075
Epoch 17330: Training cost= 0.4062, Training acc= 0.8073, Validation cost= 0.3852, Validation acc= 0.8075
Epoch 17340: Training cost= 0.3311, Training acc= 0.8073, Validation cost= 0.3076, Validation acc= 0.8076
Epoch 17350: Training cost= 0.2852, Training acc= 0.8074, Validation cost= 0.3676, Validation acc= 0.8076
Epoch 17360: Training cost= 0.2642, Training acc= 0.8074, Validation cost= 0.2896, Validation acc= 0.8077
Epoch 17370: Training cost= 0.3374, Training acc= 0.8074, Validation cost= 0.2882, Validation acc= 0.8077
Epoch 17380: Training cost= 0.2825, Training acc= 0.8075, Validation cost= 0.3090, Validation acc= 0.8077
Epoch 17390: Training cost= 0.3926, Training acc= 0.8075, Validation cost= 0.2824, Validation acc= 0.8078
Epoch 17400: Training cost= 0.3377, Training acc= 0.8075, Validation cost= 0.3337, Validation acc= 0.8078
tm  [-1.3  1.1  5.   6.5 -1.5  0.3 -0.2 -0.1 -0.6 -1.1  3.5 -0.   0.6 -0.1  2.   4.7 -0.1 -0.1 -0.1 -0.8 -0.7 -0.1 -0.4 -0.1 -1.   0.7 -0.4 -0.   0.2 -1.4 -0.6 -0.2 -0.6  2.3 -0.8  0.6  2.8  5.  10.8 -0.5 -0.2 -2.1 -0.4  2.9 -0.5  0.2  2.4 -0.3 -0.7 -1.1 -0.7 -0.2  0.   2.2 -1.   0.2 -0.4  1.5  0.5  3.   2.4 -0.2 -0.4  0.5 -0.4  0.2 -0.2 -0.3 -0.3  0.1 -0.  -0.5  0.3 -0.1 -0.7  0.4 -0.2 -0.4 -0.4  0.6  1.3 -0.4 -0.6  0.1  1.  -1.8 -1.  -0.1  1.1  1.3 -0.6  0.9  1.1  0.3 -0.3 -0.2 -0.1 -0.8 -0.2 -0.3  4.8 -0.7  1.  -0.  -0.  -0.2 -0.7 -0.5  1.2 -1.2 -0.5 -0.2 -0.1 -0.5 -0.2  4.7 -0.2 -0.5 -0.3 -0.6 -0.4  4.8 -0.3  0.3 -0.4  1.8  2.1  0.3  2.1  4.3 -1.1 -0.7 -0.5 -0.4 -4.  -3.5 -0.2 -0.1  1.7 -0.3 -0.5 -0.3 -0.8 -0.1 -0.3 -0.1 -0.2 -0.1 -0.5 -0.2 -0.5 -0.2 -0.1 -0.1 -0.3 -0.2 -0.1 -0.2  5.1 -0.2 -0.9 -1.6 -0.3  0.2 -0.4  0.1  2.2  1.6 -0.3  0.6 -0.5 -0.3 -0.2 -0.  -0.2  2.2  2.8 -0.3 -1.8 -0.5 -0.4 -0.1 -0.3 -0.9 -0.3 -0.2 -0.4 -0.7 -0.5  4.8 -0.2  0.3 -0.8 -0.8 -0.1 -0.4 -0.   1.6 -0.3 -0.1 -0.1 -0.3 -0.4 -0.8  1.  -0.8 -0.   0.2  3.9 -0.1 -0.3  2.3 -0.6  3.  -0.5 -0.2 -0.6 -0.4 -0.  -0.1 -0.5 -0.1 -0.3 -0.7 -2.   2.5 -0.1  2.1  1.4  1.1 -0.6 -0.4 -0.2  2.8  0.1 -0.9 -0.3  0.2 -0.1  6.3  0.1  3.2 -0.2 -0.3  1.4 -1.  -0.1 -0.1 -0.8 -0.5 -0.6 -0.6  8.1  0.2  2.5 -0.7]
ty_50sample [[3 1 2 7 9 9 5 4 0 6]
 [8 2 4 9 5 3 1 7 0 6]
 [1 6 9 0 4 7 2 3 5 8]
 [7 9 6 4 5 0 1 2 3 8]
 [0 8 6 5 3 3 9 4 7 1]
 [9 8 7 6 3 1 2 5 4 0]
 [0 5 2 9 9 6 4 3 8 7]
 [8 6 5 0 3 4 7 2 1 9]
 [0 2 3 7 7 8 5 1 9 4]
 [6 5 7 3 8 1 4 9 2 0]]
tt_50sample [[3 1 2 7 8 9 5 4 0 6]
 [8 2 4 9 5 3 1 7 6 0]
 [1 6 9 0 4 7 2 3 5 8]
 [7 9 6 4 5 0 1 2 3 8]
 [0 8 6 5 9 3 2 4 7 1]
 [9 8 7 6 3 1 2 5 4 0]
 [0 5 2 9 1 6 4 3 8 7]
 [8 6 5 0 3 7 4 2 1 9]
 [0 2 3 6 7 8 5 1 9 4]
 [6 5 7 3 8 1 4 9 2 0]]
vm  [-0.5 -0.8  5.1  8.8 -2.2 -0.4 -0.  -0.2  0.1  1.6  1.2  1.2 -1.3 -0.5  0.4 -2.  -0.2 -0.3 -0.4 -2.  -0.7 -0.  -0.4  1.2 -0.4  1.4 -0.2  0.4 -1.6 -0.8  4.7  0.2 -0.4 13.   0.4 -0.   1.1 -0.1 15.1 -0.4  0.4  1.  -0.4  3.7 -0.7 -0.1 12.1  2.4 -0.4 -1.  -0.5 -0.6  1.8 -3.4  0.9  0.5 -1.1 -0.6  0.6 -1.6 -0.8 -0.4  2.2  0.1  1.5 -0.7 -0.   0.   0.  -0.4 -0.2  3.1 -0.3 -0.9  3.3 -0.6  0.5  0.9 -0.2 -0.2 21.6  0.8 -0.8 -0.3 -0.8 -0.   0.3 -0.1 -0.3 -0.4  0.5 -0.5 -0.3 -0.4  0.6 -0.1 -0.   1.7 -0.5 -0.5 -0.7  5.8 -0.3 -0.5 -0.1 -0.4  0.5  4.9  0.  -2.2  1.4 -0.1 -0.4 -0.3  4.8 -2.5 -0.4  0.3  0.3 -1.  -0.4  8.  -0.4  0.2 -0.3  0.3 -0.2 14.4  0.7 -1.9 -0.7  0.4 -0.7  0.  -5.7  2.9 -0.3 -0.5 -0.6 -0.8  1.8 -0.4  0.2 -0.4 -0.1 -0.2  0.3 -0.4 -1.7 -0.4 -0.9  0.1 -1.4  0.5 -0.1 -0.  -0.4 -0.3  2.3 -0.1 -0.1 -2.  -0.3 -0.1  2.4 -0.2 -1.3  0.7 -0.7  0.3 -0.3 -0.5  0.  -0.3  0.2  5.1 -0.3  3.  -2.5  0.2 -0.3 -0.2  0.6 -0.9 -0.8 -0.2  1.7 -0.4  0.9  1.9 -0.  -0.4 -1.1 -0.4  5.4  2.3  1.4 -0.5 -0.2 -0.3 -0.1 -0.1 -0.2 -0.1 -0.3  7.5 -0.4 -0.6 -1.   0.5 -0.7 -1.3 -0.   2.5 -0.2 -0.3 -1.  -0.6 -1.  -0.4 -0.8 -0.4  1.  -0.7 -0.6 -1.4 -1.6  0.  -0.9 -0.7 -0.9 -0.5 -0.1 -0.8  1.2 -0.6  1.   2.1  0.1 15.8 -0.2  7.5 -0.6 -0.  -4.7 -3.3 -0.7 -0.8 -0.3  0.7 -5.1 -0.3 12.  -0.2  2.3  9.2]
vy_50sample [[0 7 7 1 4 3 5 6 2 8]
 [9 5 7 7 8 4 0 6 3 2]
 [9 2 8 0 1 3 5 4 7 6]
 [0 4 8 7 5 1 6 3 2 9]
 [4 5 9 9 1 2 7 0 0 6]
 [4 9 9 7 8 2 1 3 5 6]
 [0 7 3 9 8 1 5 6 2 4]
 [7 5 1 0 6 9 4 3 8 2]
 [7 0 4 3 6 5 5 9 2 8]
 [2 7 1 8 3 0 6 4 9 5]]
vt_50sample [[9 7 0 1 4 3 5 6 8 2]
 [9 5 7 1 8 4 0 6 3 2]
 [9 2 8 0 1 3 5 4 7 6]
 [0 4 8 7 5 1 6 3 2 9]
 [4 5 9 1 3 2 7 8 0 6]
 [0 4 9 7 8 2 1 3 5 6]
 [0 7 3 9 8 1 5 6 2 4]
 [7 1 5 0 6 9 4 3 8 2]
 [7 0 4 3 6 5 1 9 8 2]
 [2 7 1 8 3 0 6 4 9 5]]
Epoch 17410: Training cost= 0.3035, Training acc= 0.8076, Validation cost= 0.3486, Validation acc= 0.8078
Epoch 17420: Training cost= 0.3376, Training acc= 0.8076, Validation cost= 0.3016, Validation acc= 0.8079
Epoch 17430: Training cost= 0.3262, Training acc= 0.8077, Validation cost= 0.3184, Validation acc= 0.8079
Epoch 17440: Training cost= 0.2756, Training acc= 0.8077, Validation cost= 0.3093, Validation acc= 0.8080
Epoch 17450: Training cost= 0.3121, Training acc= 0.8077, Validation cost= 0.3242, Validation acc= 0.8080
Epoch 17460: Training cost= 0.2739, Training acc= 0.8078, Validation cost= 0.3731, Validation acc= 0.8080
Epoch 17470: Training cost= 0.3845, Training acc= 0.8078, Validation cost= 0.3257, Validation acc= 0.8081
Epoch 17480: Training cost= 0.3442, Training acc= 0.8078, Validation cost= 0.3389, Validation acc= 0.8081
Epoch 17490: Training cost= 0.3296, Training acc= 0.8079, Validation cost= 0.3397, Validation acc= 0.8081
Epoch 17500: Training cost= 0.3602, Training acc= 0.8079, Validation cost= 0.3486, Validation acc= 0.8082
tm  [ 0.4 -0.2  0.3 -0.8 -1.5 -0.2 -0.  -0.2 -0.6 -0.6 -2.2 -0.3 -0.3 -0.2  3.8  3.5  0.1 -0.4 -0.4 -0.  -0.5  0.1  3.8 -0.3 -1.1  0.3 -0.3 -0.2  1.4  1.2 -0.2 -0.6 -0.3 -1.  -0.3 -0.1  0.5 -0.1 -0.3 -0.8  0.2  5.1  2.5  2.3  0.2 -0.4 -0.8 -0.2  3.6 10.  -0.7 -0.2 -0.3  1.5 -0.9 -0.3 -0.3  0.8  0.5  2.2  0.4 -0.2 -0.6  1.7 -0.7  0.1  0.5 -0.5  0.7  0.8 -0.2 -0.8 -0.2 -0.  -2.4  0.7 -0.7  0.3  0.9 -0.4 -2.3  0.6 -0.1  0.2 -1.1  7.   2.6 -0.   0.1 -0.2 -0.2 -0.  -0.4 -0.8 -0.3 -0.1  1.  -1.5 -0.3 -0.1  1.6  6.1 -0.6  0.  -0.1 -0.4 -1.1 -0.4 -0.8 -0.2 -0.7 -0.1 -0.5 -0.8 -0.7  7.4 -0.5 -0.2 -0.3 -0.4 -0.1  1.1  0.  -0.7  0.5  4.2  0.1  1.1  3.  -0.2  2.4 -1.  -0.1 -0.7 -0.6 -1.8 -0.1 -0.5 -0.6  1.3  1.  -0.3  1.8  0.5 -0.4  0.6  0.3 -0.4  2.1  0.2  2.  -0.3  4.8  0.7  0.1 -0.1  0.2 -0.2 -0.1 -0.4  1.5 -0.  -0.1 -0.1 -0.3 -0.6  0.  -0.2  0.9 -0.2  0.5  1.  -0.4 -0.2 -0.1 -0.1 -0.8 -0.5  2.3 -0.3 -1.5 -0.3 -0.9 -1.2 -0.3 -0.1  1.3 -0.4 -0.5 -0.3 -0.1 -0.4 -0.7 -0.7  2.  -0.9 -0.3 -0.1  0.7 -0.4 -0.3 -0.2 -0.3 -0.7 -0.  -1.7 -0.1  0.8  3.1 -0.2 -0.1  4.4 -0.6  0.4 -0.5  0.1 -0.1 -0.3  1.1 -0.3 -0.9  0.3 -0.5 -1.   3.3  4.2 -0.7 -0.2 -0.4  4.6 -0.6 -0.2 -0.   2.2 -0.2  1.8  0.9 -0.5  3.5 -1.2 -0.1 -0.7  0.4 -0.   8.1 -0.1 -0.1  0.5 -0.8 -0.5  5.3 -0.4 -0.1 -0.1  1.   4.1]
ty_50sample [[8 5 4 7 6 2 9 1 0 3]
 [9 8 7 2 4 3 6 5 1 0]
 [2 9 6 6 7 3 8 4 1 0]
 [9 4 2 5 1 8 6 0 7 3]
 [4 6 5 0 2 1 7 3 8 9]
 [8 0 0 7 2 3 3 4 6 1]
 [6 0 7 9 9 2 3 8 4 5]
 [7 0 1 4 9 8 3 6 2 5]
 [9 0 4 8 6 5 1 2 3 7]
 [3 7 0 6 1 2 5 5 9 4]]
tt_50sample [[8 5 4 7 6 2 9 1 0 3]
 [9 8 7 2 4 3 6 5 1 0]
 [2 9 5 6 7 3 8 4 0 1]
 [9 2 4 5 8 1 6 0 7 3]
 [4 6 5 0 2 1 7 3 8 9]
 [8 0 5 7 2 9 3 4 6 1]
 [6 0 7 1 9 3 2 8 4 5]
 [7 0 1 4 9 8 3 6 2 5]
 [9 0 4 8 6 5 1 2 3 7]
 [3 7 0 6 1 8 2 5 9 4]]
vm  [-0.9  2.6  3.1 15.5 -0.8 -0.2 -0.3 -0.5 -1.1 -0.8  4.4 -0.5  0.6 -0.1 -2.1  6.3  0.5 -0.1  0.3 -1.2 -0.7 -0.3  1.7  0.7 -0.9  1.4 -0.2 -0.5 -0.9 -0.7 -2.  -0.4 -0.2 -3.  -0.3  2.1  4.9  5.9  6.6 -0.1 -0.3 -1.2  0.8 -0.6 -0.8 -0.1  5.3 -1.  -0.3  2.4 -0.4 -0.4  0.9  2.6 -0.8  4.1 -0.5  4.  -1.3  6.  -0.3 -0.  -0.3  0.2 -0.7 -0.2 -0.2 -0.4 -0.8 -0.  -0.1  1.4  0.1 -0.5  4.3 -0.4  0.9 -0.4 -0.3  0.6  2.4 -0.3 -0.5 -0.  -0.2 -1.  -0.8 -0.3  0.4 -0.1 -0.   1.1  0.2  4.1  0.   0.2 -0.1 -0.   0.2  0.3  4.  -1.7  1.  -0.2  0.9  0.   0.6 -1.5  1.9 -2.  -0.7 -0.2 -0.1  0.7 -0.5 -0.  -0.1 -1.6 -0.2 -0.5 -0.1  7.3 -0.6  0.3 -0.1 -2.3  0.9 -0.2 -0.9 -0.  -0.3  0.7 -0.  -0.2  5.  -1.7 -0.1  0.4  2.3 -0.1 -1.  -1.2 -1.6 -0.2  1.4 -0.5 -0.5  0.3  2.1  0.2 -1.9  0.1  2.2 -1.2 -0.  -0.2 -0.1 -0.3  1.3 -0.6 -0.3 -0.1 -0.7 -0.1 -0.5  0.3  0.9 -0.2 -0.1  1.9 -0.3 -0.4 -0.1  0.5 -0.2 -0.2 -0.4  1.8 -0.7 -0.6 -0.1 -0.2  0.4 -1.  -0.5 -0.1  0.3 -0.3 -0.4  3.1 -0.  -0.4 -0.3 -0.7  3.4  2.   3.   3.3 -0.  -0.   1.1 -0.4 -0.  -0.8  0.5  1.8 -0.6 -0.2  5.  -0.1 -0.5 -0.5 -0.6  2.4 -0.6 -0.8  3.5 -0.4 -0.7 -0.   1.3  0.4 -0.1 -0.7 -0.5  1.7  3.6  3.3 -0.2 -0.4 -0.6 -0.9 -0.   3.6  1.3 -0.1 -0.2  3.2 -0.7  8.6 -0.4  4.2 -0.  -0.4  0.2 -1.9 -0.2  1.5 -0.6 -0.4 -0.9 -0.2  4.9  0.5 -0.6  2.3]
vy_50sample [[2 9 8 3 1 0 6 5 7 4]
 [3 7 8 8 5 0 1 1 2 4]
 [3 8 9 0 1 5 7 6 4 2]
 [8 4 6 2 2 3 0 5 7 1]
 [1 9 3 5 7 6 8 0 4 2]
 [1 2 4 5 0 8 9 3 7 6]
 [9 5 2 3 4 8 7 0 6 1]
 [6 4 0 1 2 5 3 7 7 8]
 [6 7 9 9 3 4 5 1 8 2]
 [6 4 5 3 9 1 2 8 0 7]]
vt_50sample [[2 9 8 3 1 0 6 5 7 4]
 [3 7 8 9 5 0 6 1 2 4]
 [3 8 9 0 1 5 7 6 4 2]
 [8 4 9 6 2 3 0 5 7 1]
 [1 9 3 5 7 6 8 0 4 2]
 [1 2 4 5 0 9 8 3 7 6]
 [9 5 2 3 4 8 7 0 6 1]
 [6 4 0 1 2 5 3 7 9 8]
 [6 7 9 0 3 4 5 1 8 2]
 [6 4 5 3 9 1 8 2 0 7]]
Epoch 17510: Training cost= 0.3201, Training acc= 0.8079, Validation cost= 0.3506, Validation acc= 0.8082
Epoch 17520: Training cost= 0.3520, Training acc= 0.8079, Validation cost= 0.3378, Validation acc= 0.8082
Epoch 17530: Training cost= 0.4048, Training acc= 0.8080, Validation cost= 0.3565, Validation acc= 0.8083
Epoch 17540: Training cost= 0.3279, Training acc= 0.8080, Validation cost= 0.3549, Validation acc= 0.8083
Epoch 17550: Training cost= 0.2975, Training acc= 0.8080, Validation cost= 0.2876, Validation acc= 0.8083
Epoch 17560: Training cost= 0.2943, Training acc= 0.8081, Validation cost= 0.2828, Validation acc= 0.8084
Epoch 17570: Training cost= 0.3663, Training acc= 0.8081, Validation cost= 0.2851, Validation acc= 0.8084
Epoch 17580: Training cost= 0.3739, Training acc= 0.8082, Validation cost= 0.3598, Validation acc= 0.8084
Epoch 17590: Training cost= 0.3294, Training acc= 0.8082, Validation cost= 0.3717, Validation acc= 0.8085
Epoch 17600: Training cost= 0.3253, Training acc= 0.8082, Validation cost= 0.3123, Validation acc= 0.8085
tm  [ 0.7  1.  -2.9 -3.2 -0.4 -0.4 -0.5 -0.3 -1.1 -0.6 -2.1  0.3 -0.2  0.1  0.7  2.9  0.5 -0.  -0.6  1.5 -0.6 -0.4  0.6 -0.3 -1.3 -0.2 -0.4 -0.3  0.3 -0.4  0.4 -0.6 -0.4 -4.6 -0.7 -0.3  1.6  0.9 -1.5 -0.8 -0.1 -1.   0.5  3.  -0.5 -0.2 -1.9 -0.4  1.6  0.7 -0.5 -0.5 -1.   5.8 -1.3  0.8 -0.5 -0.  -0.2  2.1  2.  -0.3 -0.6 -0.4 -0.5 -0.3 -0.2  1.  -0.2 -0.3 -0.3 -0.9 -0.3 -0.6 -5.3 -0.4 -0.9 -0.1 -0.5 -0.1 -4.9 -0.  -0.1  0.7 -1.2 -0.7  3.5 -0.1  2.  -0.3 -0.3  1.1  0.6  3.6 -0.9  0.6 -0.5 -1.6 -0.1 -0.4  3.6 -3.  -0.4 -0.   0.3 -0.4 -2.7 -0.  -0.9  1.2  0.2 -0.4  0.3 -0.9 -0.8  4.6 -0.3 -0.2  0.1 -0.6 -0.5 -0.9 -0.4 -0.6 -0.6  1.   1.4 -1.1  0.8 11.4  1.9 -0.5  0.9 -0.1  8.  -2.3 -0.3 -0.2  0.2 -0.1 -0.  -0.7 -0.4 -0.6 -0.  -0.3 -0.4 -0.1  6.2 -0.5  1.9  0.   5.2 -0.5 -0.2 -0.2 -0.  -0.6 -0.5 -0.5 -0.6 -0.5 -0.7 -0.1 -0.2  0.3  0.5 -0.1 -0.1 -0.6 -0.4  0.4 -0.3 -0.   0.4 -1.5 -0.8 -1.6  5.2 -0.7 -1.4 -0.4  0.5 -1.2 -0.4  0.5  0.6  0.3 -0.6  2.1 -0.4 -0.3  0.7 -1.6  0.5 -0.3 -1.6  1.1 -0.2 -0.3 -0.2 -0.4 -0.2 -0.6 -0.6 -3.6 -0.4 -0.3  2.9 -0.1 -0.5  0.7 -0.5 -0.6  1.3  0.4 -0.4 -0.4 -0.4 -0.4 -0.4 -0.2 -0.2 -0.8 -1.   2.7 -0.6 -0.5 -0.2  4.1 -0.8  2.3 -0.3  2.  -0.8  6.  -0.  -2.6 -0.  -3.4 -0.3 -1.4 -0.2 -0.2 15.4  4.7  0.1 -0.5 -0.7  0.1 11.7 -0.2 -1.2 -0.2  3.3 -2.9]
ty_50sample [[3 8 4 5 6 2 0 1 9 7]
 [5 2 9 0 6 1 3 7 8 4]
 [7 8 0 3 3 5 4 2 9 6]
 [1 9 3 5 7 8 2 6 0 4]
 [7 4 5 5 1 3 3 6 2 9]
 [7 4 2 3 1 9 8 0 6 5]
 [5 9 1 8 7 3 2 4 0 6]
 [5 9 3 4 7 2 6 0 1 8]
 [9 8 7 4 1 2 3 5 0 6]
 [1 3 4 0 8 5 5 7 6 6]]
tt_50sample [[3 8 4 5 6 2 0 1 9 7]
 [5 2 9 0 6 1 7 3 8 4]
 [7 8 0 3 1 5 4 2 9 6]
 [9 1 3 5 7 2 8 6 0 4]
 [7 4 0 5 1 3 8 6 2 9]
 [7 4 2 3 1 9 8 0 6 5]
 [5 9 1 8 7 3 2 4 0 6]
 [5 9 3 4 7 2 6 0 1 8]
 [9 8 7 4 1 3 2 5 0 6]
 [1 3 4 0 8 9 5 7 6 2]]
vm  [ 0.3 -0.3  4.6 18.4 -1.1 -0.4 -0.2 -0.3 -0.6 -0.1  7.5 -0.4 -0.4 -0.  -2.4 -0.5 -0.1 -0.7 -0.  -2.  -0.6 -0.1 -1.   0.5 -0.8  1.2 -0.3 -0.1 -1.5 -1.1  0.4  0.1  1.1  5.3  0.3  0.1  3.3 -0.4  3.5 -0.2 -0.2  2.8  0.8 -1.9 -0.2 -0.3 11.2 -0.3  1.3 -2.  -0.1  0.1 -0.1 -1.   1.1  4.3 -0.1  5.8 -0.5  0.6 -1.6 -0.1 -0.6  1.4  0.8 -0.4 -0.  -0.1 -0.1 -0.4 -0.1  2.9 -0.3 -0.7  6.9 -0.2 -0.7  0.  -0.4 -0.2 21.1  0.3 -1.1  0.2 -0.7  2.6 -0.3 -0.1 -0.3 -0.1 -0.2 -0.3 -0.3  0.9  0.2 -0.5  0.3  1.7 -0.1 -0.5  0.6 -0.4 -0.6 -0.1 -0.2 -0.7  1.1 -0.   0.9 -2.2  0.4  0.5 -0.2  1.3  2.5 -1.7 -0.5 -0.5 -0.4  0.6 -0.4  9.5  0.9  0.7 -0.1 -2.9 -0.2  6.3 -0.3 -1.3  2.2  0.  -0.7 -0.4  9.  15.3 -0.2 -0.2  0.1 -0.8 -0.4 -0.5 -0.3  0.  -0.1 -0.3  0.  -0.3  4.3 -0.3 -1.9 -0.3 -0.6 -0.4 -0.1  0.4  0.2 -0.2 -1.4 -0.2 -0.2  1.8 -0.3 -0.1 -0.3 -0.3 -0.7 -0.5 -0.7  1.8 -0.4 -0.2  0.3 -0.5 -0.1 -0.9 -1.3  2.3 -0.3  0.5 -1.4 -0.2  0.4 -1.  -0.  -0.3  3.9 -0.3  1.2  3.2 -0.1 -0.2 -1.  -0.5  9.4  1.2  2.2 -0.1 -0.2 -0.2 -0.2 -0.3 -0.1 -0.2 -0.5  3.9  0.4  0.  -3.6 -0.1 -0.5 -1.1 -0.6 -0.1 -0.7 -0.   7.6 -0.6 -0.3 -0.5 -0.1 -0.6  1.4 -0.6  3.1 -1.6 -0.5  1.1 -0.1  1.4 -0.2 -0.5 -0.4 -2.5  2.2 -1.1  1.5  4.7 -0.4  6.8 -0.2  3.3 -0.3  0.3 -4.7 -2.7  0.7 -0.4 -0.8 -0.2 -5.1 -0.7  2.9 -0.1 -0.1  6.9]
vy_50sample [[9 6 0 5 2 3 1 7 8 8]
 [4 6 1 5 5 2 7 0 0 8]
 [5 4 7 1 9 8 6 0 2 3]
 [7 7 2 9 5 1 4 8 3 6]
 [8 6 9 5 0 0 1 7 2 3]
 [2 1 0 9 4 6 5 7 3 8]
 [5 9 6 7 2 3 0 0 8 8]
 [4 9 9 6 3 5 7 8 2 1]
 [5 4 3 7 6 2 9 0 1 8]
 [8 6 2 1 7 5 9 3 4 0]]
vt_50sample [[9 6 0 5 2 3 1 7 8 4]
 [4 6 1 5 3 7 2 0 9 8]
 [5 4 7 1 9 8 6 0 2 3]
 [7 0 9 2 5 1 4 8 3 6]
 [8 6 9 5 4 0 1 7 2 3]
 [2 1 0 9 4 6 5 7 3 8]
 [5 9 6 7 2 3 0 1 4 8]
 [4 0 9 6 3 5 7 8 2 1]
 [5 4 3 7 6 2 9 0 1 8]
 [8 6 2 1 7 5 9 3 4 0]]
Epoch 17610: Training cost= 0.3885, Training acc= 0.8083, Validation cost= 0.3121, Validation acc= 0.8086
Epoch 17620: Training cost= 0.3420, Training acc= 0.8083, Validation cost= 0.2986, Validation acc= 0.8086
Epoch 17630: Training cost= 0.3230, Training acc= 0.8083, Validation cost= 0.3744, Validation acc= 0.8086
Epoch 17640: Training cost= 0.3137, Training acc= 0.8084, Validation cost= 0.2762, Validation acc= 0.8087
Epoch 17650: Training cost= 0.3755, Training acc= 0.8084, Validation cost= 0.2643, Validation acc= 0.8087
Epoch 17660: Training cost= 0.2790, Training acc= 0.8084, Validation cost= 0.2879, Validation acc= 0.8087
Epoch 17670: Training cost= 0.3244, Training acc= 0.8085, Validation cost= 0.3004, Validation acc= 0.8088
Epoch 17680: Training cost= 0.3065, Training acc= 0.8085, Validation cost= 0.3409, Validation acc= 0.8088
Epoch 17690: Training cost= 0.2692, Training acc= 0.8085, Validation cost= 0.3439, Validation acc= 0.8089
Epoch 17700: Training cost= 0.3657, Training acc= 0.8086, Validation cost= 0.3063, Validation acc= 0.8089
tm  [-0.   0.1 -0.1 -0.6 -1.8 -0.1  0.  -0.2 -0.7 -0.9  3.4 -0.1 -0.1 -0.5  3.   3.9 -0.2 -0.4 -0.2 -0.4 -0.6  0.2  2.4  0.2 -1.4  1.9 -0.2 -0.3 -0.   1.4  3.6 -0.3 -0.3  5.8 -0.5  1.1  2.3  3.8  7.8 -0.6  0.8  4.2  2.5  5.8 -0.4 -0.4  2.5 -0.3  0.8  3.6 -1.  -0.3  1.   0.7 -1.3 -0.2 -0.5 -0.1 -0.6 -1.  -0.3 -0.3  0.3  1.4  1.3 -0.2  0.1 -0.2 -0.  -0.1  0.3 -0.6  0.2 -0.3 -1.1 -0.  -0.1 -0.2  0.9 -0.2  4.9 -0.2 -0.1  0.6 -0.7  5.6  2.9 -0.1 -0.1 -0.2 -0.3  0.1 -0.4 -0.2 -0.3 -0.2  0.4 -0.8 -0.4 -0.   2.9  6.3 -0.6 -0.1 -0.2 -0.5 -0.9  4.   1.6 -0.6 -0.8 -0.3 -0.  -0.5 -0.5  4.1 -0.2 -0.6 -0.4 -0.2 -0.   1.4 -0.2 -0.2 -0.3  3.7  1.1  1.8  1.5 -0.7 -0.2 -0.6 -0.4 -0.4 -3.9 -1.5  0.2 -0.3 -0.2 -0.7 -0.  -0.3  0.1 -0.1 -0.  -0.1  0.3 -0.3  0.9 -0.2 -0.  -0.2  2.1 -0.  -0.3 -0.2 -0.1  0.4  3.6 -0.3  0.5 -1.2 -0.2 -0.4 -0.2 -0.6 -0.2 -0.5  0.4 -0.1  1.1  0.4 -0.2 -0.2 -0.1  0.5 -0.3  0.3 -1.2 -0.4 -1.  -0.5 -0.4 -1.3 -0.7 -0.3  1.8 -0.8 -0.2 -0.5 -0.2 -0.7 -0.8 -1.   3.3 -0.2 -0.2  0.9 -0.  -0.3 -0.2 -0.3 -0.4 -0.6 -0.4 -0.6 -0.1  0.3 -1.5 -0.2 -0.4  2.5 -0.4  2.  -0.2 -0.3 -1.6 -0.5  0.9 -0.1 -0.5  0.1 -0.2 -1.  -0.3  2.1 -0.3 -0.  -0.   1.4 -0.6 -0.2 -0.2 -0.9 -0.1  2.   0.8 -0.2  1.  -0.5 -0.  -0.4 -0.2 -0.2 -0.5 -1.4 -0.2 -0.1 -0.4 -0.1 -1.5 -0.1  5.8 -0.  -0.   5.5]
ty_50sample [[4 5 7 9 2 8 1 0 3 6]
 [3 8 7 5 2 4 1 9 9 6]
 [9 9 4 6 7 0 3 8 5 5]
 [6 5 0 3 2 4 8 7 9 1]
 [4 8 6 0 0 3 2 7 1 5]
 [4 2 3 7 9 8 5 6 1 0]
 [9 0 8 8 4 5 7 6 1 3]
 [1 3 8 5 0 7 4 2 6 9]
 [8 8 5 9 9 4 4 2 3 6]
 [2 4 9 9 3 1 0 8 7 5]]
tt_50sample [[4 7 5 9 2 8 1 0 3 6]
 [3 8 7 5 2 4 1 0 9 6]
 [9 2 4 6 7 0 3 8 1 5]
 [6 5 0 3 2 4 7 8 9 1]
 [4 8 6 0 9 3 2 7 1 5]
 [4 2 3 7 9 8 5 6 1 0]
 [9 0 8 2 4 5 7 6 1 3]
 [1 3 8 5 0 7 4 2 6 9]
 [8 0 5 9 4 7 1 2 3 6]
 [2 4 9 3 6 1 0 8 7 5]]
vm  [ 2.1 -0.1 -1.9 -2.9 -1.1 -0.1 -0.2 -0.3 -1.5  0.2  4.  -0.8  0.3 -0.2  2.7 -0.4 -0.1 -0.7 -0.2 -1.4 -0.6 -0.5  2.8  0.3 -1.5  0.6 -0.4 -0.5 -1.8  1.6  4.2  2.6  0.4 -0.1  1.3  1.5  5.8  0.1 -1.9 -0.6  1.   6.   1.8  2.8 -0.7 -0.  -0.2 -0.7  2.1  7.9 -0.6 -0.2 -1.5  5.4  0.5 -0.1 -0.6 -0.5 -1.2 -1.2 -0.4 -0.2 -1.1  0.5 -0.1  1.1 -0.1 -0.3  0.6 -0.1 -0.1  3.5 -0.6 -0.5 -2.7 -0.3 -0.2 -0.3 -0.  -0.3 -0.8 -0.8 -0.6 -0.5 -0.8  6.4  4.9 -0.2 -0.4 -0.  -1.3 -0.3 -0.7  2.4 -0.3  0.1 -0.2 -1.   0.2 -0.  -0.1  3.2 -0.6  0.1  0.6 -0.3 -1.9  4.6  1.2 -1.2 -0.7 -0.1  0.4 -0.1  1.6 -1.9 -0.3 -0.6 -0.4 -0.3 -0.4  3.1 -0.8 -0.7 -0.6  3.4 -0.4 -1.2 -0.4 -0.9  2.  -0.3 -0.4  0.2  5.4  6.5  0.2  0.3 -0.5 -0.8 -0.5 -0.8 -0.4 -0.4 -0.1 -0.6 -0.7 -0.4  3.7  0.8  1.1 -0.4  2.6 -0.9 -0.7 -0.4  0.  -0.  -0.9 -0.3 -0.6 -0.  -0.8 -0.3 -0.5  0.9 -0.7 -0.6 -0.  -0.5  1.7  1.4  0.5 -0.3 -0.3 -0.5 -1.1 -1.2  5.2 -1.3 -1.8  0.6  1.1 -0.9  0.7 -0.4  2.2 -0.6 -0.  -0.5 -0.4 -0.3 -0.  -1.2  5.   1.1 -1.5  2.  -0.5  0.1 -0.4 -0.5  0.  -0.4 -0.7 -2.9 -0.4 -0.2 -1.4  0.2  1.5 -1.8 -0.4 -1.1  1.7 -0.5 -0.7 -0.7 -0.4 -0.7  1.3  1.5 -0.  -1.1  4.  -0.8 -0.  -0.5  0.6  1.9 -1.   1.9 -0.8 -1.   4.   5.2  2.  -1.6  1.3 -2.4 -0.1 -1.1 -0.3 -0.3  3.8  4.7 -0.3 -0.4 -0.7  1.   1.4 -0.1 -1.4 -0.4 -0.8  7.5]
vy_50sample [[4 4 5 6 2 8 7 9 1 3]
 [4 6 9 1 7 2 8 0 5 3]
 [9 2 4 8 3 0 6 1 5 7]
 [0 8 5 3 9 4 1 6 6 2]
 [8 9 2 0 4 3 7 6 5 1]
 [9 7 5 6 2 0 3 1 8 4]
 [2 6 3 5 1 0 9 7 4 8]
 [9 5 6 7 2 8 3 0 1 4]
 [1 7 4 0 9 8 3 2 6 5]
 [9 8 4 1 1 7 3 6 5 0]]
vt_50sample [[4 0 5 6 2 8 7 9 1 3]
 [6 4 1 9 7 2 8 0 5 3]
 [9 2 4 8 3 6 0 1 5 7]
 [0 8 5 3 9 4 1 7 6 2]
 [8 9 2 0 4 3 7 6 5 1]
 [9 7 5 6 2 0 3 1 8 4]
 [2 6 3 5 0 1 9 7 4 8]
 [9 5 6 7 8 2 3 0 1 4]
 [1 7 4 0 9 8 3 2 6 5]
 [9 8 4 2 1 7 3 6 5 0]]
Epoch 17710: Training cost= 0.3537, Training acc= 0.8086, Validation cost= 0.2896, Validation acc= 0.8089
Epoch 17720: Training cost= 0.2992, Training acc= 0.8087, Validation cost= 0.3099, Validation acc= 0.8090
Epoch 17730: Training cost= 0.3018, Training acc= 0.8087, Validation cost= 0.3236, Validation acc= 0.8090
Epoch 17740: Training cost= 0.2901, Training acc= 0.8087, Validation cost= 0.3159, Validation acc= 0.8090
Epoch 17750: Training cost= 0.3061, Training acc= 0.8088, Validation cost= 0.3679, Validation acc= 0.8091
Epoch 17760: Training cost= 0.3270, Training acc= 0.8088, Validation cost= 0.3138, Validation acc= 0.8091
Epoch 17770: Training cost= 0.4052, Training acc= 0.8088, Validation cost= 0.3475, Validation acc= 0.8091
Epoch 17780: Training cost= 0.3287, Training acc= 0.8089, Validation cost= 0.4357, Validation acc= 0.8092
Epoch 17790: Training cost= 0.3356, Training acc= 0.8089, Validation cost= 0.3600, Validation acc= 0.8092
Epoch 17800: Training cost= 0.3431, Training acc= 0.8089, Validation cost= 0.3319, Validation acc= 0.8092
tm  [-0.7 -0.3 -0.2 -1.  -1.5 -0.3  0.3 -0.4 -0.  -0.5 -2.   0.9 -1.2 -0.2  3.4 -2.1 -0.3 -0.1 -0.1  2.8 -0.9 -0.4 -0.3  0.6 -1.   4.2  0.3 -0.3 -1.3 -2.1  0.2 -0.2 -0.6 -0.6  0.3 -0.4  1.1 -0.4 -1.  -0.7 -0.1 -1.7 -0.5  0.3 -1.  -0.3 -2.2  0.9 -0.1 -0.8 -0.5 -0.3  1.   0.4  1.3 -0.2 -0.5 -0.3  2.2  1.9  6.  -0.5  1.6  2.4 -0.2 -0.2 -0.2  0.4  0.6 -0.2 -0.3  4.2 -0.1  0.3 -4.7 -0.4 -0.5 -0.4 -0.3 -0.1 -1.7 -0.2  1.9 -0.8 -0.5 -1.7 -0.1  0.3  0.2 -0.1  0.1 -0.9 -0.1 -0.4 -0.6 -0.4 -0.4 -2.1 -0.  -0.2  0.4 -1.5  0.1 -0.6 -0.3  1.4 -2.  -0.1 -0.9  2.4 -0.3  1.  -0.1 -0.5  6.1 -2.2 -0.5  1.6 -0.2  1.3  0.  -1.1 -0.4  0.9 -0.4  4.4 -0.3  2.4  1.9  7.8  0.3 -0.3 -0.1 -0.   3.6 -0.2 -0.3 -0.1  2.4 -0.1  3.7 -1.3  1.1 -0.  -0.2 -0.1 -0.3 -0.2  0.1 -0.2  1.2 -0.1  1.2  2.6 -0.3 -0.  -0.2  1.1 -0.1 -0.3 -0.5 -0.8  0.8  0.4  0.  -0.5 -0.5  2.6 -0.   0.4 -0.6 -0.3 -0.  -0.  -0.5  1.7 -0.5 -0.5  4.   0.4  0.2  0.3 -0.4 -1.7  0.6 -0.1 -0.6 -0.2  1.   6.9 -0.2 -0.1 -0.1 -1.1 -1.3 -0.2 -1.3 -0.8  0.1  0.4 -0.2  0.1 -0.5 -0.8 -0.  -2.1 -0.3 -0.4  5.3 -0.1 -0.2 -1.  -0.9  3.2 -0.5 -0.2  0.9 -0.6 -0.7  2.  -1.1 -0.4  0.4 -1.2 -0.5 -0.7 -1.9  0.9 -0.3  1.1 -0.5 -0.2 -0.3  2.9  3.9  2.2  2.3 -1.5  3.4 -0.2 -0.2 -0.1 -0.2 -0.1  7.1  1.4 -0.4  0.3 -1.2 -0.4  3.5 -0.6 -0.6 -0.3  5.5 -2. ]
ty_50sample [[0 3 1 8 6 4 7 5 2 9]
 [4 6 1 0 8 5 9 2 3 7]
 [4 6 8 0 2 2 7 5 3 3]
 [6 2 7 3 0 1 8 4 5 9]
 [5 4 1 9 7 0 0 6 3 2]
 [3 5 7 9 4 6 8 1 2 0]
 [1 5 3 4 8 2 6 7 0 9]
 [2 8 3 6 7 1 9 0 5 4]
 [1 2 3 0 7 8 6 4 5 9]
 [5 1 8 9 3 0 0 7 4 2]]
tt_50sample [[0 3 1 8 6 4 7 5 2 9]
 [4 6 1 0 8 5 9 2 3 7]
 [4 6 8 0 2 1 7 5 3 9]
 [6 2 7 3 0 8 1 4 5 9]
 [5 4 1 9 7 8 0 6 3 2]
 [3 5 7 9 4 6 8 1 2 0]
 [1 5 3 4 8 2 6 7 0 9]
 [2 8 3 6 7 1 9 0 5 4]
 [1 2 3 0 7 8 6 4 5 9]
 [5 1 8 9 3 6 0 7 4 2]]
vm  [ 2.9 -0.3 -1.4  2.9 -1.  -0.2 -0.1 -0.4 -0.4  0.9  4.1 -0.7 -0.5 -0.4 -1.7 -0.6  0.7 -0.3 -0.1 -0.8 -0.9 -0.2  1.9  0.7 -0.9  3.3  0.4 -0.2 -1.7 -1.1  1.5 -0.3 -0.8 -1.8  3.6 -0.1  2.3  3.5  7.1 -0.7 -0.2  3.   0.4  2.9 -0.4  0.5  2.4 -0.9  5.6  5.8 -0.3 -0.6  1.   2.1  2.8  3.6 -0.6 -0.2  0.5  0.3 -1.9 -0.3  0.1  3.7 -0.6  1.  -0.1 -0.2 -0.2  0.2 -0.1  5.4 -0.2  0.8 -1.3 -0.2 -1.  -0.3 -0.4 -0.3  4.2 -0.1 -0.  -0.7 -1.6  2.6  4.5 -0.   0.  -0.1  0.2 -1.1 -0.8 -0.4 -0.2 -0.2 -0.1 -1.2  0.2  0.5 -0.8  0.5 -1.4 -0.3 -0.1  1.4 -0.   1.   1.2 -1.5 -0.7  0.2 -0.2  0.3  3.8 -2.6 -0.3 -0.3 -0.  -0.   0.2  5.9 -0.5 -0.6 -0.2 -1.8 -1.4  0.1  1.2 -1.3  2.5 -0.1 -0.3  0.4  3.7 -1.2 -0.5 -0.1 -0.1  0.1 -0.4 -1.6 -0.5 -0.2 -0.  -0.5 -0.2 -0.5  3.1  0.2 -0.1 -0.1  5.8 -0.5 -0.2 -0.2 -0.3 -0.1  0.4  1.2  1.5 -0.9 -0.2 -0.   0.  -0.4 -0.8 -0.8 -0.4  0.1  0.1 -0.6  0.1 -0.3 -0.  -0.4 -0.1  3.  -0.9 -0.8 -1.1  0.2 -0.6 -1.1  0.7 -0.3  6.   0.3  0.2  3.2 -0.2 -0.4 -0.5 -0.7 10.8 -0.4  1.4 -0.2 -0.1  0.8  0.7  0.4  0.4 -0.4 -0.7  2.5 -0.3 -0.4  3.  -0.1 -0.1 -1.6 -0.6 -1.2 -0.4 -0.4 -0.6 -0.6 -1.  -0.6 -0.3 -0.1 -0.2 -1.1  1.6 -0.9  0.9  0.1 -0.3  3.2 -0.6 -1.1 -0.3  2.2  3.8  4.4  2.6  1.6  1.7  6.9 -0.3  3.3 -0.2  0.5 -0.3 -1.5 -0.3  0.1 -1.1 -0.5 -1.3 -0.1  5.4  0.5 -0.8  7.6]
vy_50sample [[0 2 9 4 8 5 6 3 7 1]
 [5 3 7 1 1 2 6 0 9 4]
 [3 6 1 7 5 0 9 4 4 2]
 [8 4 5 2 9 7 1 0 3 3]
 [6 2 7 8 1 3 4 5 9 0]
 [5 6 9 4 7 0 3 2 8 1]
 [3 2 1 0 6 8 9 7 5 4]
 [7 4 0 1 6 2 5 3 8 9]
 [3 8 0 6 4 2 9 7 5 1]
 [0 1 8 4 3 9 6 5 7 2]]
vt_50sample [[0 9 2 4 8 5 6 3 7 1]
 [5 3 7 1 8 2 6 0 9 4]
 [3 6 1 7 5 0 9 4 2 8]
 [8 4 5 2 9 7 1 0 3 6]
 [6 2 7 8 1 3 4 5 9 0]
 [5 6 9 4 7 0 3 2 8 1]
 [3 2 1 0 6 9 8 7 5 4]
 [7 4 0 1 6 2 5 3 8 9]
 [3 8 0 6 4 2 9 7 5 1]
 [0 1 8 4 3 9 6 5 7 2]]
Epoch 17810: Training cost= 0.3383, Training acc= 0.8089, Validation cost= 0.2845, Validation acc= 0.8093
Epoch 17820: Training cost= 0.2948, Training acc= 0.8090, Validation cost= 0.3148, Validation acc= 0.8093
Epoch 17830: Training cost= 0.3213, Training acc= 0.8090, Validation cost= 0.2961, Validation acc= 0.8093
Epoch 17840: Training cost= 0.2991, Training acc= 0.8091, Validation cost= 0.2872, Validation acc= 0.8094
Epoch 17850: Training cost= 0.3062, Training acc= 0.8091, Validation cost= 0.3157, Validation acc= 0.8094
Epoch 17860: Training cost= 0.3108, Training acc= 0.8091, Validation cost= 0.2650, Validation acc= 0.8095
Epoch 17870: Training cost= 0.3170, Training acc= 0.8092, Validation cost= 0.2923, Validation acc= 0.8095
Epoch 17880: Training cost= 0.3597, Training acc= 0.8092, Validation cost= 0.2895, Validation acc= 0.8095
Epoch 17890: Training cost= 0.2867, Training acc= 0.8092, Validation cost= 0.3209, Validation acc= 0.8096
Epoch 17900: Training cost= 0.2690, Training acc= 0.8093, Validation cost= 0.3131, Validation acc= 0.8096
tm  [-1.   0.6  3.  18.8 -0.8  0.2 -0.2 -0.2 -0.2 -0.3  9.1 -0.3  0.  -0.6 -2.7  6.9  0.1 -0.3 -0.4 -1.7 -0.6  1.  -0.2 -0.4 -1.3  0.5 -0.1 -0.5  1.3 -0.9 -0.7 -0.8  3.9 -0.5 -0.5 -0.1  2.1  2.3  0.  -0.2  0.5 -0.3 -0.5 -2.  -0.4  0.1  9.1 -1.3 -0.8 -0.7  0.2 -0.5  1.6  1.  -1.3  4.9 -0.2  4.4 -0.2  3.6 -0.4 -0.6  1.  -0.4  1.1 -0.9  0.6  1.  -1.1 -0.5 -0.3 -0.8 -0.  -0.1 -0.4 -0.  -0.   0.  -0.8 -0.2 14.6  0.  -0.4 -0.7 -0.5 -0.1 -1.2 -0.3 -0.1 -0.6 -0.3 -0.2 -0.   0.9 -0.1 -0.3 -0.3 -0.  -0.3 -0.2  0.6 -1.2  0.8 -0.3 -0.6 -0.3 -0.  -0.5  2.3 -2.4 -0.1 -0.1 -0.3 -0.4 -0.2  4.   1.  -0.9  0.4  0.8 -0.1  6.4 -0.4 -0.1 -0.  -3.1  1.1  0.3 -0.3 -1.1 -0.5  0.3 -0.6  1.3 11.4 13.1 -0.3 -0.   0.4 -0.7 -1.1  0.2 -1.2 -0.4 -0.3 -0.2  0.2 -0.4  3.5 -0.3 -1.7  0.1 -0.8 -0.9 -0.  -0.1 -0.9  0.8 -1.  -0.5 -0.3  1.5 -0.1 -0.4 -0.5 -0.1 -0.1 -0.4 -0.6  1.7 -0.3 -0.8 -0.7 -0.1 -0.1 -0.6 -2.   2.2  1.3 -0.3 -0.5  0.2  1.5 -0.9 -0.9 -0.4  0.7 -0.1 -0.5  3.7 -0.1 -0.4 -1.  -0.6  3.9  0.5  2.2  0.5 -0.1 -0.4  0.4 -0.3  1.1 -0.2 -0.4  6.1 -0.1 -0.5 -0.3 -0.1 -0.3  3.2 -0.2  3.7 -0.4  0.4  6.3 -0.6 -0.9 -0.1  0.5 -0.3  0.5 -0.8  1.5  1.   0.7  3.9  0.  -0.4  1.5 -0.3 -0.1 -0.  -1.  -0.4 -0.4  0.5 -1.1 11.8 -0.4  6.  -0.3 -0.  -2.9 -3.2 -0.3 -0.2 -0.5 -0.3 -3.6 -0.3  0.5  1.2 -0.8  6.7]
ty_50sample [[2 6 9 1 3 5 8 0 7 4]
 [7 8 3 6 5 0 4 9 9 2]
 [2 0 7 4 3 9 1 8 6 5]
 [1 8 3 6 5 2 4 0 9 7]
 [4 6 9 3 7 2 0 1 5 8]
 [5 3 7 1 2 8 8 0 9 6]
 [3 0 7 1 2 5 9 6 4 8]
 [7 6 8 4 3 1 5 2 0 9]
 [8 8 3 2 1 7 4 9 5 6]
 [6 5 2 4 0 7 3 8 9 9]]
tt_50sample [[2 6 9 1 3 5 8 0 7 4]
 [7 8 3 6 5 0 4 1 9 2]
 [2 7 0 4 3 1 9 8 6 5]
 [1 8 3 6 5 2 4 0 9 7]
 [4 6 9 3 7 2 0 1 5 8]
 [5 3 7 1 2 4 8 0 9 6]
 [3 0 1 7 2 5 9 6 4 8]
 [7 6 8 4 3 1 5 0 2 9]
 [8 0 3 2 1 7 4 9 5 6]
 [6 5 2 4 0 7 3 8 1 9]]
vm  [-1.1 -0.5  4.3 -0.4 -1.9 -0.2 -0.3 -0.1 -0.3  0.4  1.  -0.3 -0.4 -0.3  7.5  0.4 -0.5 -0.  -0.3 -1.3 -0.7 -0.4  2.4 -0.5 -0.8  0.4 -0.2 -0.3 -0.2  0.2  3.6 -0.2 -0.6 10.6 -0.3 -0.1  1.1  2.   8.3 -0.2 -0.4  4.8  0.2  3.8 -0.8 -0.1  2.9 -0.  -1.   6.1 -0.8 -0.3 -0.3 -0.5 -1.4 -0.8 -0.5 -0.1  0.6 -1.1  4.1 -0.5 -0.1  0.  -0.  -0.5 -0.2 -0.1 -0.4 -0.6  0.4 -0.3 -0.1  0.1 -2.3 -0.6  1.6 -0.3  0.9 -0.4  5.2 -0.5 -0.2 -0.4 -0.   5.7 -0.3 -0.1 -0.4 -0.5 -0.1 -0.1 -0.5 -1.  -0.3  0.1 -0.2 -1.3 -0.4 -0.3 -0.1  9.7  1.1 -0.5 -0.4  0.1 -1.2  3.4 -0.  -1.4  0.3 -0.5  0.2 -0.7  0.8  2.9 -0.6 -0.2 -0.1 -0.9 -0.3  4.1 -0.5  0.2 -0.3  8.7  0.4  4.8  2.7 -1.6 -1.1 -0.5 -0.1  0.3 -5.7 -1.2 -0.2 -0.1 -0.4 -0.6  0.9 -0.   0.6 -0.3 -0.1 -0.1 -0.1 -0.1 -1.1 -0.   1.2  0.3 -1.3 -0.2 -0.1 -0.3 -0.3 -0.3  2.9 -0.2 -0.3 -1.1 -0.2 -0.5 -0.  -0.3 -0.3  1.6  0.1 -0.2  0.7 -0.2 -0.3  0.1 -0.4  3.3  0.  -0.4 -1.2 -0.3 -0.9  0.6 -0.3 -1.  -0.6 -0.2 -0.4 -0.8 -0.5 -0.2 -0.4 -0.2 -0.9 -0.5 -0.6 -0.  -0.3  0.5 -0.1 -0.4 -0.  -0.1 -0.3 -0.   0.6 -0.9 -0.3 -0.3 -1.4 -0.1  0.5  1.  -0.7  4.9  0.  -0.3 -1.2 -0.5 -0.3 -0.2 -0.7 -0.1 -0.  -0.5  1.5  0.7 -0.9  0.7 -0.5 -0.3 -0.8 -0.3 -0.3 -0.9 -0.2 -0.3  0.2 -0.8  0.3 -0.1  0.3 -0.1 -0.3 -0.2 -0.7 -0.9 -0.7 -0.2 -0.3  0.1 -1.5 -0.   5.8 -0.3 -0.2  9.4]
vy_50sample [[7 1 4 5 9 0 8 2 6 3]
 [8 6 9 5 7 3 3 2 1 0]
 [2 1 4 9 6 0 3 7 8 5]
 [1 2 6 3 3 8 9 7 0 4]
 [6 6 1 7 2 8 0 9 5 4]
 [3 3 4 6 1 1 8 5 7 0]
 [4 4 5 5 8 9 0 0 7 1]
 [5 3 4 2 0 8 6 1 7 9]
 [4 1 9 3 7 0 6 2 8 5]
 [1 0 7 6 4 5 8 9 3 2]]
vt_50sample [[7 1 4 5 9 0 8 2 6 3]
 [8 6 9 5 7 4 3 2 1 0]
 [2 1 4 9 6 3 0 7 8 5]
 [1 2 6 3 5 8 9 7 0 4]
 [3 6 1 7 2 8 0 9 5 4]
 [3 9 4 6 2 1 8 5 7 0]
 [6 4 2 5 8 9 3 0 7 1]
 [5 3 4 2 0 8 6 1 7 9]
 [4 1 9 3 7 0 6 2 8 5]
 [1 0 7 6 4 5 8 3 2 9]]
Epoch 17910: Training cost= 0.3141, Training acc= 0.8093, Validation cost= 0.2700, Validation acc= 0.8096
Epoch 17920: Training cost= 0.3212, Training acc= 0.8094, Validation cost= 0.3084, Validation acc= 0.8097
Epoch 17930: Training cost= 0.3648, Training acc= 0.8094, Validation cost= 0.2890, Validation acc= 0.8097
Epoch 17940: Training cost= 0.3750, Training acc= 0.8094, Validation cost= 0.3448, Validation acc= 0.8097
Epoch 17950: Training cost= 0.3701, Training acc= 0.8095, Validation cost= 0.2757, Validation acc= 0.8098
Epoch 17960: Training cost= 0.3268, Training acc= 0.8095, Validation cost= 0.3497, Validation acc= 0.8098
Epoch 17970: Training cost= 0.3882, Training acc= 0.8095, Validation cost= 0.3316, Validation acc= 0.8098
Epoch 17980: Training cost= 0.3234, Training acc= 0.8095, Validation cost= 0.3349, Validation acc= 0.8099
Epoch 17990: Training cost= 0.3396, Training acc= 0.8096, Validation cost= 0.3509, Validation acc= 0.8099
Epoch 18000: Training cost= 0.3324, Training acc= 0.8096, Validation cost= 0.3870, Validation acc= 0.8099
tm  [-0.6 -0.5 -1.   2.  -1.6 -0.1 -0.3 -0.1 -0.1 -0.2  4.   0.4 -0.5 -0.8 -1.2  0.7 -0.5 -0.2 -0.1 -1.6 -0.9 -0.3  0.3 -0.2 -0.6  2.6 -0.4 -0.4 -0.5 -0.2  5.8 -0.5 -0.4  7.3 -0.   0.5  1.1  2.6 15.6 -0.6 -0.  -0.6 -0.6  6.3 -0.6 -0.4  9.1  0.3 -0.2 -0.1 -0.4 -0.3  1.8 -1.9 -0.8  2.5 -0.4 -2.1  1.9 -2.  -0.7 -0.2  1.4  0.7  0.6 -0.4 -0.3 -0.   0.9 -0.1 -0.3 -0.3 -0.   0.4  4.8  0.2 -0.1 -0.3  0.6  0.1 17.1 -0.2 -0.4 -0.3 -0.5 -0.4  2.3 -0.2 -0.3 -0.4 -0.2 -0.  -0.3 -1.2 -0.  -0.2 -0.6 -0.2 -0.5 -0.   0.6  5.2 -0.2 -0.1 -0.1 -0.   2.5  6.5  1.7 -2.3 -0.9 -0.1 -0.2 -0.2  2.8  0.4  0.7 -0.2 -0.2 -0.6  0.   8.4 -0.1 -0.  -0.1 -1.3  0.4  9.6  2.  -1.9 -0.8 -0.6 -0.2 -0.7 -3.9 -0.7 -0.1 -0.2 -0.  -0.6  0.2 -0.3 -0.   0.1 -0.2  0.2 -0.  -0.3 -1.7 -0.2 -0.1 -0.1 -0.6  0.1  0.5 -0.3  0.6 -0.2  4.3 -0.2  1.4 -1.4  0.  -0.3 -0.1 -0.5 -0.2  1.7 -0.1 -0.4 -0.3 -0.7 -0.   0.1 -0.2  4.4  0.3  3.9 -2.6 -0.1  1.6 -0.3 -0.1 -1.1 -0.7 -0.1  2.4 -0.2 -0.1  0.8  0.1 -0.5 -1.1 -0.5  6.  -0.1  5.  -0.3 -0.2 -0.2 -0.1 -0.3 -0.4 -0.6 -0.   6.7 -0.  -0.2  3.  -0.5 -0.4  0.9 -0.8  3.7  0.6 -0.4 -2.1 -0.4  0.  -0.3 -0.8 -0.2 -0.3 -0.7 -0.3 -0.3 -1.   0.8  0.5 -0.1 -0.6 -1.3  0.1  2.3  0.4  3.5  0.5  4.3  2.3 19.1 -0.1  8.9 -0.2 -0.  -3.6 -3.1 -0.4 -0.1 -0.8 -0.4 -4.1  0.1 11.6 -0.   0.7  9.5]
ty_50sample [[9 4 7 1 0 2 3 8 5 6]
 [3 4 2 8 0 6 1 9 5 7]
 [7 1 4 4 8 5 6 2 2 0]
 [1 3 6 6 5 2 4 4 7 7]
 [0 9 7 6 2 5 1 4 8 3]
 [1 6 2 5 4 8 0 9 3 7]
 [5 2 9 9 7 0 6 8 3 1]
 [6 2 9 5 7 3 8 1 4 0]
 [5 8 3 0 9 7 6 1 4 2]
 [5 8 2 0 4 1 3 9 7 6]]
tt_50sample [[9 4 7 1 0 2 3 8 5 6]
 [3 4 2 8 0 6 9 1 5 7]
 [7 1 9 4 8 5 6 3 2 0]
 [1 3 6 8 5 2 4 9 0 7]
 [0 9 7 6 2 5 1 4 8 3]
 [1 6 2 5 4 8 0 9 3 7]
 [5 2 9 7 4 0 6 8 3 1]
 [6 2 9 5 3 7 8 1 4 0]
 [5 8 3 0 9 7 6 1 4 2]
 [5 8 2 0 4 1 3 9 7 6]]
vm  [ 2.3 -0.4  5.8  4.2 -1.7 -0.4 -0.3 -0.2  0.6 -0.5  3.2  1.8 -0.9 -0.3  4.1 -0.4 -0.1 -0.2  0.3  0.7 -0.9  0.6 -1.2  0.1 -1.   2.7 -0.1 -0.3 -0.7 -2.1 -0.3 -0.4 -0.4  4.7  0.4 -0.3  0.1  3.4  3.  -0.8  0.6 -1.7 -0.4  1.2 -0.5 -0.4 -0.6 -0.4  5.2 -2.3 -0.7 -0.2  1.4  2.8 -0.  -0.2 -0.3  2.5  2.8  3.  -0.5 -0.5  1.5  3.2  0.7 -0.3 -0.1 -0.1  0.2 -0.2  0.4  3.5  0.2  0.8 -3.9  1.1 -1.5 -0.4 -1.  -0.2  1.4 -0.4  0.7 -0.5 -1.7 -1.9  1.4 -0.1  0.2 -0.3 -0.6 -0.9  0.5 -0.2 -0.4 -0.2 -0.1 -1.6 -0.2 -0.2  1.5 -1.1 -1.1 -0.2 -0.1  0.7 -1.4 -0.2  1.5 -0.2  0.3 -0.1 -0.1 -0.5  4.1 -1.3 -0.   2.9  0.4  1.7  0.2 -0.1 -0.4 -0.4 -0.4  5.  -0.3 -0.1  3.   7.8  0.8 -0.4 -0.  -0.2 -2.7 -0.7 -0.  -0.1  1.   0.2 -0.2 -1.  -0.2  0.3 -0.1  0.5 -0.2 -0.7 -0.6 -0.4 -0.3 -0.   4.3  0.4 -0.1 -0.4  0.3  0.2  2.7 -0.1 -0.5 -1.8  0.4 -0.   0.7 -0.7 -0.4 -0.1 -0.3  1.1 -0.9 -0.5 -0.3  0.1 -0.6  3.1 -0.4 -0.3 -0.2 -0.1 -0.3 -0.3 -0.5 -1.2 -0.2 -0.3  4.5 -0.5 -0.   7.7  0.6  0.4 -0.6 -0.9  4.9 -1.  -0.7 -1.  -0.   0.3 -0.1 -0.3 -0.1 -0.5 -1.1 -1.2  0.3 -0.2  1.8 -0.3 -0.2 -0.6 -0.5 -1.1 -0.6  1.4  0.1 -0.6 -0.3  0.4 -0.4 -0.1 -0.1 -1.  -1.7 -0.8 -0.6  0.   0.1  5.1 -0.3  0.5 -0.2  1.4  0.4 -1.2  1.8 -1.2  1.7  1.7 -0.2  0.7 -0.1 -0.   1.1 -0.7 -0.5 -0.1 -0.9 -0.3 -0.5 -0.5  3.  -0.   3.1 -2.1]
vy_50sample [[3 0 7 2 8 8 5 4 6 1]
 [5 9 2 7 7 4 6 1 3 0]
 [2 1 3 8 8 7 4 4 0 9]
 [1 3 6 4 0 9 8 2 7 5]
 [3 8 7 9 5 2 6 1 4 0]
 [0 5 3 9 6 2 1 7 4 8]
 [1 3 8 9 0 4 5 2 6 7]
 [2 5 7 8 6 3 4 1 9 0]
 [9 1 8 3 5 7 0 4 2 6]
 [9 2 0 6 7 1 8 8 4 3]]
vt_50sample [[3 0 7 2 9 8 5 6 4 1]
 [5 9 2 8 7 4 1 6 3 0]
 [2 1 3 8 7 5 6 4 0 9]
 [1 3 6 4 0 9 8 2 7 5]
 [3 8 7 9 5 2 6 1 4 0]
 [0 5 3 9 6 2 1 7 4 8]
 [1 3 9 8 0 4 5 2 6 7]
 [2 5 7 8 6 3 4 1 9 0]
 [9 1 8 3 7 5 0 4 2 6]
 [9 2 0 6 1 7 8 4 5 3]]
Epoch 18010: Training cost= 0.3613, Training acc= 0.8096, Validation cost= 0.3497, Validation acc= 0.8100
Epoch 18020: Training cost= 0.3452, Training acc= 0.8097, Validation cost= 0.3228, Validation acc= 0.8100
Epoch 18030: Training cost= 0.3122, Training acc= 0.8097, Validation cost= 0.2527, Validation acc= 0.8100
Epoch 18040: Training cost= 0.3840, Training acc= 0.8097, Validation cost= 0.3231, Validation acc= 0.8101
Epoch 18050: Training cost= 0.3404, Training acc= 0.8098, Validation cost= 0.3196, Validation acc= 0.8101
Epoch 18060: Training cost= 0.3094, Training acc= 0.8098, Validation cost= 0.3147, Validation acc= 0.8101
Epoch 18070: Training cost= 0.3014, Training acc= 0.8099, Validation cost= 0.3117, Validation acc= 0.8102
Epoch 18080: Training cost= 0.2940, Training acc= 0.8099, Validation cost= 0.3349, Validation acc= 0.8102
Epoch 18090: Training cost= 0.3186, Training acc= 0.8099, Validation cost= 0.3086, Validation acc= 0.8103
Epoch 18100: Training cost= 0.3643, Training acc= 0.8100, Validation cost= 0.3038, Validation acc= 0.8103
tm  [-0.8 -0.5 -2.6  1.9 -1.  -0.5 -0.1 -0.2 -0.3 -0.5 -3.9  1.7 -0.8 -0.5 -2.8 -0.1 -0.2 -0.1 -0.2 -1.7 -0.7  0.   2.3  0.2 -0.8  1.7 -0.4 -0.3  1.1 -0.6  1.9 -0.2 -0.2 -3.  -0.8 -0.5  0.2  1.3 14.9 -0.5  0.9 -0.4 -0.5  6.1 -0.3 -0.6  9.7  1.7 -0.4  4.6 -0.5 -0.4  0.4 -3.  -1.2  5.5 -0.2 -1.3  1.7 -0.1 -1.  -0.4 -0.  -0.6 -0.9 -0.5 -0.2  0.4  1.1 -0.  -0.2 -1.1  0.8 -0.1  1.3  1.7 -0.2 -0.1 -0.1 -0.1  4.1  0.2 -0.4 -0.2 -0.6 -0.1  1.  -0.3 -0.  -0.3  0.  -0.1 -0.  -0.8 -0.1 -0.4 -0.4 -0.2 -0.5 -0.2  2.3 -0.6 -0.  -0.  -0.3 -0.6  0.6  1.6 -1.5 -2.   0.3 -0.1 -0.3 -0.5  1.   4.9  0.7 -0.1 -0.2 -0.  -0.2  6.2 -0.2 -0.4  0.4 -3.   1.6 13.2  3.1 -1.4 -0.5 -0.3 -0.4 -0.7 -1.1 -4.3  0.1 -0.3  0.4 -0.   2.8 -0.6  2.5 -0.1 -0.   0.  -0.1 -0.4  2.8 -0.4 -0.1 -0.1  2.7  1.2 -0.3 -0.1 -0.3 -0.6  3.8  0.3  0.6 -1.7  0.1 -0.4 -0.5 -0.4 -0.   1.3 -0.5 -0.1 -0.1 -0.3 -0.7 -0.3  0.2 -0.2 -0.2  3.1 -2.4 -0.1 -0.2 -0.3 -0.1 -1.1 -0.9  1.1  1.9 -0.1 -0.4  2.1 -0.3 -0.5 -1.1 -1.3  6.6 -0.4  3.8 -0.2 -0.1 -0.4 -0.5 -0.  -0.1 -0.5 -0.2  6.1 -0.2 -0.3  4.5  0.4 -0.5  4.  -0.6  2.6 -0.2 -0.1 -2.  -0.3  0.5 -0.2 -1.2 -0.1 -0.3 -1.1 -1.3  2.3 -2.1 -0.1 -0.2  0.9 -0.7 -0.8 -0.4  3.3 -1.   6.  -0.1  2.1  1.1 13.  -0.2  6.3 -0.4 -0.4 -0.5 -3.6  0.3 -0.7 -1.  -0.1 -1.3 -0.2 11.  -0.2  5.   7.4]
ty_50sample [[9 4 8 1 3 5 7 0 2 6]
 [3 7 6 8 5 0 2 4 9 9]
 [6 2 0 3 1 4 5 7 9 9]
 [7 2 0 5 3 8 9 6 4 1]
 [1 3 8 5 4 2 6 6 7 0]
 [6 9 7 2 1 5 4 3 0 8]
 [2 2 3 3 1 1 7 7 0 6]
 [5 0 4 6 7 3 8 9 2 1]
 [6 1 4 5 2 8 7 0 9 9]
 [7 3 9 2 0 0 6 1 5 8]]
tt_50sample [[9 4 8 1 3 5 0 7 2 6]
 [3 7 6 8 5 0 2 4 1 9]
 [6 2 3 0 1 5 4 7 8 9]
 [7 2 0 5 3 8 9 6 4 1]
 [1 3 8 5 4 2 6 9 7 0]
 [6 9 7 2 1 5 4 3 0 8]
 [9 2 4 3 1 8 7 5 0 6]
 [5 0 4 6 7 3 8 9 2 1]
 [6 1 4 5 2 8 7 3 0 9]
 [7 3 2 9 4 0 6 1 5 8]]
vm  [-0.   3.8  3.2 -0.9 -1.3 -0.2 -0.5 -0.2 -2.1 -0.9 -2.5  1.8 -0.6 -0.2  4.8  2.   0.6  0.3 -0.  -1.3 -0.5 -0.3 -0.3  1.  -1.7 -0.2 -0.3  0.8  1.1  6.6  1.9 -0.5 -0.1  4.6 -1.3  1.2  3.9 -0.5  1.8 -0.5 -0.7 -1.6  2.8  2.4 -0.2 -0.2  4.2  1.1 -0.2 -0.7 -0.5 -0.2 -0.4 -1.2 -1.4 -0.4 -0.8 -0.7 -2.2 -0.1 -0.6  0.5 -1.1 -1.2 -0.6  0.3 -0.  -0.2 -0.1  0.2 -0.2 -1.3 -0.6 -0.4 -0.9  0.5 -0.3 -0.1 -0.3  1.1 -0.4 -0.4 -0.6  0.8 -0.5 -1.2  3.4  0.5  2.2 -0.3 -0.5  2.7  0.3  5.9  0.6 -0.2 -0.4  0.  -0.6 -0.5  5.8  2.3 -0.2 -0.2  0.7 -0.5 -0.7  2.4 -0.8 -1.4 -0.  -0.5 -0.2  0.6 -1.8  8.2  0.2 -1.3 -0.4 -0.9 -0.7  4.4 -0.2 -0.3 -0.3  5.2  3.9  6.6 -1.8  5.4  0.7 -0.1  1.3 -0.2 -1.9 -0.3 -0.2 -0.2 -0.1 -0.7  1.2 -0.5  1.3 -0.5 -0.4 -0.3 -0.1 -0.4 -1.2 -0.6 -0.5  0.   2.8 -0.4 -0.4 -0.2 -0.  -0.4 -0.8 -0.6 -0.7 -0.3 -0.4 -0.1 -0.4  0.3  1.2 -0.2 -0.2 -0.6 -0.7 -0.3 -0.5 -0.1  0.2  3.8 -0.8 -0.6  0.3 -0.5 -0.6  0.3  1.1 -1.2 -1.4 -0.3  2.3 -0.7 -0.4 -1.6 -0.1  0.6 -0.3 -1.6  5.3  5.1 -0.   4.5  0.2 -0.3 -0.  -0.3 -0.2 -0.2 -0.6 -0.7 -0.2 -0.5  4.  -0.3 -0.2  2.  -0.3 -0.   2.2  0.9 -0.2 -0.2  0.7 -0.5 -0.9 -0.1 -0.2 -0.2 -0.6  4.6 -1.2 -1.   0.9 -0.2 -1.   0.7 -0.2  2.7 -1.3 -0.2 -0.8 -0.2 -0.   5.3 -0.   2.8 -0.1 -0.5  3.  -0.6 -0.1 -0.5 -0.3 -0.6  0.8  0.6  1.3 -0.2  5.2 -0.7]
vy_50sample [[7 3 4 8 6 9 5 1 2 0]
 [6 9 4 2 7 3 0 8 1 5]
 [6 1 0 7 4 5 9 2 8 3]
 [2 3 5 6 4 9 9 8 0 1]
 [5 0 2 9 6 3 8 1 4 7]
 [3 9 5 8 8 1 6 2 0 7]
 [0 7 9 8 2 4 1 6 3 5]
 [7 8 1 4 2 6 3 9 9 5]
 [3 9 8 7 4 5 6 0 1 2]
 [6 0 9 5 2 2 4 1 7 3]]
vt_50sample [[7 3 4 8 6 9 5 1 2 0]
 [6 9 2 4 7 3 0 8 1 5]
 [6 1 7 0 4 5 9 2 8 3]
 [2 3 5 6 4 7 9 8 0 1]
 [5 0 2 9 6 3 8 1 4 7]
 [3 9 4 5 8 1 6 2 0 7]
 [0 7 9 8 2 4 1 6 3 5]
 [7 8 1 4 2 6 3 0 9 5]
 [3 9 8 7 4 5 6 0 1 2]
 [6 9 5 0 8 2 4 1 7 3]]
Epoch 18110: Training cost= 0.3465, Training acc= 0.8100, Validation cost= 0.3215, Validation acc= 0.8103
Epoch 18120: Training cost= 0.2757, Training acc= 0.8100, Validation cost= 0.3052, Validation acc= 0.8104
Epoch 18130: Training cost= 0.4049, Training acc= 0.8101, Validation cost= 0.2950, Validation acc= 0.8104
Epoch 18140: Training cost= 0.3307, Training acc= 0.8101, Validation cost= 0.2907, Validation acc= 0.8104
Epoch 18150: Training cost= 0.3512, Training acc= 0.8101, Validation cost= 0.3227, Validation acc= 0.8105
Epoch 18160: Training cost= 0.4000, Training acc= 0.8102, Validation cost= 0.3509, Validation acc= 0.8105
Epoch 18170: Training cost= 0.3558, Training acc= 0.8102, Validation cost= 0.3462, Validation acc= 0.8105
Epoch 18180: Training cost= 0.3489, Training acc= 0.8102, Validation cost= 0.3310, Validation acc= 0.8106
Epoch 18190: Training cost= 0.4136, Training acc= 0.8103, Validation cost= 0.3028, Validation acc= 0.8106
Epoch 18200: Training cost= 0.3337, Training acc= 0.8103, Validation cost= 0.3850, Validation acc= 0.8106
tm  [-0.3 -0.2 -1.4  6.1 -0.7 -0.4 -0.1 -0.4 -0.6 -0.2 -3.2 -0.5 -0.8 -0.5 -2.3  1.5  1.1  0.9 -0.6 -0.6 -0.5 -0.3  2.9  0.5 -0.6  0.9 -0.1 -0.2 -0.4 -0.2 -1.4 -0.7 -0.2 -5.8 -0.  -0.2  1.1  0.5  1.9 -0.4 -0.1  5.8  1.1 -0.2 -0.3 -0.5  1.7 -0.5  3.3 11.7 -0.3 -0.8 -0.5 -0.  -0.7  3.7 -0.1  3.8 -0.2  4.1 -0.7 -0.7 -0.3  0.2 -1.3 -0.7 -0.2 -0.2 -0.2 -0.2 -0.4  0.6  0.2  0.6 -1.6 -0.4 -0.6 -0.5  0.  -0.3 -2.1  0.1 -0.2 -0.1 -1.6  7.   2.1 -0.3 -0.1 -0.7  1.3 -0.4 -0.4 -0.1 -0.3 -0.2  0.2 -1.4 -0.3 -0.6  0.  -0.3 -0.8 -0.2 -0.2 -0.2 -0.4 -1.7 -1.2 -1.3 -0.3 -0.1 -0.2 -0.4 -0.2  1.5 -0.7 -0.5  0.3 -0.4 -0.   3.9 -0.1 -0.2  0.2 -2.5 -0.2  3.4  1.1 -1.   2.1 -0.2 -0.1 -0.6 10.4 -2.6 -0.2 -0.4 -0.4  3.3  0.2 -0.8 -0.3 -0.1  0.3 -0.1 -0.2 -0.2  7.1 -0.2 -0.4 -0.2  4.1  0.2 -0.1  0.3 -0.2 -0.7 -0.5 -0.1  1.6  0.1 -0.3 -0.3 -0.1 -0.3 -0.3 -0.5 -0.   0.9 -0.1 -0.  -0.4 -0.  -0.3 -1.8 -0.7  1.2  0.7 -0.2 -1.4 -0.4 -0.4 -1.1 -0.3  1.2  3.1  1.3 -0.3  0.8  0.1 -0.2 -0.6 -0.5  6.  -0.2  1.6 -0.1 -0.1 -0.3 -0.5  0.5 -0.1 -0.4 -0.4  0.  -0.1  0.2  3.5 -0.2 -0.6  1.1 -0.8  0.1 -0.7 -0.3  2.3 -0.2 -0.4 -0.2 -0.5 -0.3 -0.5 -0.8  3.9  0.3 -0.9  0.7 -0.9  2.  -0.4 -0.8 -0.2  2.6 -0.1  3.9  0.7  0.4  1.3 -0.3 -0.3 -0.1 -0.1 -0.1  6.9 -1.7 -0.4 -0.4 -0.8 -0.5  4.8 -0.3  1.5  0.6 -0.1  6.5]
ty_50sample [[8 5 9 6 0 2 4 1 3 7]
 [0 8 4 8 3 7 1 9 2 6]
 [5 6 7 9 4 8 1 2 3 0]
 [6 7 9 5 0 3 4 8 1 2]
 [8 3 2 1 1 5 7 7 6 4]
 [1 4 0 5 2 6 7 3 8 9]
 [5 9 0 1 2 4 7 6 3 8]
 [6 9 1 7 5 4 8 2 0 3]
 [1 3 4 5 8 9 7 2 6 0]
 [7 6 0 1 8 2 5 9 3 4]]
tt_50sample [[8 5 9 6 0 2 4 1 3 7]
 [0 8 4 5 3 1 7 9 2 6]
 [5 6 7 9 4 8 1 2 3 0]
 [6 7 9 0 5 3 4 8 2 1]
 [8 3 2 1 9 5 0 7 6 4]
 [1 4 0 5 2 6 7 3 8 9]
 [5 9 0 1 2 4 7 6 3 8]
 [6 9 7 1 5 4 8 2 0 3]
 [1 3 5 4 8 9 7 2 6 0]
 [7 6 0 1 8 2 9 5 3 4]]
vm  [-1.1 -0.9 -0.6 -3.2 -1.2  0.3 -0.1 -0.2  0.2  0.2  3.9 -0.2 -0.6 -0.2  6.4  2.2 -0.2 -0.5 -0.4 -0.5 -0.7 -0.4  2.2 -0.8 -1.1 -0.3  0.8  0.4  1.7 -0.6  5.9 -0.4 -0.3  7.3 -0.4 -0.2 -0.2  0.4 -0.8 -0.3 -0.5  6.8  0.7  2.5 -0.8 -0.5 -1.  -0.4 -1.5  3.5 -0.8 -0.1 -0.7  3.9 -1.7 -0.7 -0.8  2.5  2.3 -1.7  7.7 -0.6 -0.1 -0.4  2.1 -0.6 -0.3  1.6 -0.3 -0.7  0.2 -1.1 -0.3 -0.4 -5.1 -0.3  1.5 -0.3  0.  -0.7  1.7 -0.6 -0.3 -0.5 -0.   9.  -0.4 -0.2 -0.5 -0.1 -0.8 -0.  -0.5 -0.8 -1.  -0.3 -0.2 -1.8 -0.2 -0.3  0.5  5.6  1.9 -0.3 -0.6 -0.2 -2.8  4.7  1.  -0.3  0.2 -0.2 -0.1 -1.3  0.5  5.6 -0.3  0.7 -0.5  0.8 -0.1 -0.4 -0.3  0.1 -0.5  8.   0.7 -0.5  4.2 -0.3 -0.4 -0.7 -0.5 -0.1 -0.8  6.4 -0.2 -0.2 -0.2 -0.8 -0.2  1.5 -0.1 -0.1 -0.3 -0.  -0.1  0.9  3.6 -0.2  3.3 -0.3 -1.7 -0.2 -0.4 -0.2 -0.5 -0.1 -0.2 -0.3 -0.5 -0.4 -0.1 -0.3 -0.3 -0.2 -0.5  1.6 -0.3 -0.7  0.4  1.1 -0.5 -0.4 -0.4 -0.7 -1.1 -1.3  3.3 -0.4 -1.8  0.7 -0.2 -1.3 -0.2 -0.1 -1.2 -0.9 -0.4  1.8 -0.3 -0.5 -0.6 -0.7 -2.2 -0.2 -1.9 -0.1 -0.2 -0.5  0.7 -0.1 -0.4 -0.4  0.4 -2.9 -0.2 -0.5 -4.1 -0.1  0.6  2.7 -0.4  6.   1.  -0.1 -0.6 -0.6 -0.1 -0.2 -0.5 -0.2 -0.2 -0.9  2.9  1.4 -0.9  0.7 -0.2  0.2 -1.2  2.6 -0.2 -3.  -0.7  2.2  1.  -2.4  0.  -4.3 -0.2 -2.2 -0.2  0.2  0.2  3.3 -0.4 -0.6 -0.7  1.7 -0.6 -0.3 -0.6 -0.3  0.1  3.5]
vy_50sample [[5 1 4 7 6 2 9 8 0 3]
 [9 0 6 8 2 3 4 1 5 7]
 [5 6 0 9 8 4 3 2 7 1]
 [3 3 1 1 7 0 2 5 9 4]
 [7 0 6 5 2 4 9 8 3 1]
 [0 9 2 7 1 3 4 8 5 6]
 [2 3 8 9 1 5 4 4 6 0]
 [2 4 8 6 3 0 7 5 1 9]
 [5 6 4 2 8 8 1 0 3 7]
 [6 2 4 1 5 5 9 3 8 7]]
vt_50sample [[5 1 4 7 2 6 9 8 0 3]
 [9 0 6 8 2 3 4 1 5 7]
 [5 6 0 9 8 4 3 2 7 1]
 [8 3 6 1 7 0 2 9 5 4]
 [0 7 6 5 2 4 9 8 3 1]
 [0 9 2 7 1 3 4 8 5 6]
 [2 3 8 9 7 5 1 4 6 0]
 [2 4 8 6 3 0 7 5 1 9]
 [5 6 4 2 8 9 0 1 3 7]
 [6 2 4 1 5 0 9 3 8 7]]
Epoch 18210: Training cost= 0.3405, Training acc= 0.8103, Validation cost= 0.3204, Validation acc= 0.8106
Epoch 18220: Training cost= 0.3750, Training acc= 0.8104, Validation cost= 0.3371, Validation acc= 0.8107
Epoch 18230: Training cost= 0.3363, Training acc= 0.8104, Validation cost= 0.3668, Validation acc= 0.8107
Epoch 18240: Training cost= 0.3552, Training acc= 0.8104, Validation cost= 0.3116, Validation acc= 0.8107
Epoch 18250: Training cost= 0.3247, Training acc= 0.8104, Validation cost= 0.3521, Validation acc= 0.8108
Epoch 18260: Training cost= 0.3545, Training acc= 0.8105, Validation cost= 0.3308, Validation acc= 0.8108
Epoch 18270: Training cost= 0.2859, Training acc= 0.8105, Validation cost= 0.3032, Validation acc= 0.8108
Epoch 18280: Training cost= 0.3154, Training acc= 0.8105, Validation cost= 0.2850, Validation acc= 0.8109
Epoch 18290: Training cost= 0.2890, Training acc= 0.8106, Validation cost= 0.3554, Validation acc= 0.8109
Epoch 18300: Training cost= 0.3313, Training acc= 0.8106, Validation cost= 0.2444, Validation acc= 0.8109
tm  [ 2.1 -0.2  0.6  4.2 -0.9 -0.6 -0.2 -0.2 -0.6 -0.2 -2.  -0.5 -0.6 -0.2 -0.6 -0.3  1.1  0.1 -0.2 -0.2 -0.5 -0.3  2.2  1.6 -0.9  1.7 -0.1 -0.2 -1.3 -0.7 -1.5 -0.3 -0.2 -4.1  1.2 -0.1  2.4  0.  -1.  -0.9 -0.2  2.3  1.1 -0.8 -0.2 -0.3 -0.  -0.7  4.6  8.4 -0.5 -0.6 -0.9  2.8  1.8  1.7 -0.7  4.  -0.2  5.1 -0.8 -0.2 -0.4  2.4 -0.8 -0.4 -0.3 -0.3  0.3 -0.2 -0.2  4.9 -0.1 -0.3 -2.6  0.4 -0.8 -0.  -0.5 -0.3 -3.  -0.3 -0.2  0.3 -1.7  2.   2.1 -0.2 -0.  -0.5 -0.2 -0.4 -0.5  2.3 -0.5 -0.1  1.8 -1.5 -0.1 -0.8 -0.1 -0.5 -1.5 -0.2 -0.1 -0.4 -1.3 -1.6 -0.8 -0.5 -0.3 -0.1 -0.1 -0.   1.4 -1.7 -0.7 -0.3 -0.3  0.2 -0.1  1.9 -0.3 -0.5 -0.2 -0.6 -0.9 -0.1 -0.4  0.9  3.7 -0.3 -0.1 -0.3  8.8 -1.3 -0.  -0.4 -0.   1.4 -0.3 -1.6 -0.2 -0.1 -0.  -0.2 -0.2 -0.6  4.1  0.3 -0.6 -0.   6.  -0.6 -0.4 -0.1 -0.1 -0.7 -1.  -0.1  0.2 -0.  -0.3 -0.2 -0.4 -0.5 -0.4 -0.8 -0.5  0.8 -0.4 -0.1 -0.4 -0.3 -0.3 -0.8 -1.  -0.1  3.3 -0.2 -1.  -0.2 -0.1 -1.3 -0.1  0.6  4.7 -0.1 -0.1  1.5 -0.2 -0.1 -0.4 -0.9  6.5  0.1 -0.8 -0.3 -0.2 -0.1 -0.4 -0.2  0.9 -0.3 -0.9 -1.7 -0.1 -0.3  5.2 -0.3 -0.7 -1.2 -0.7 -1.1 -0.5 -0.2  4.5 -0.4 -0.6 -0.5 -0.2 -0.2 -0.5 -1.2  2.6 -0.3 -0.5  0.2 -0.7  3.4  0.2  0.6 -0.3  3.5  1.7  1.1  3.  -0.8  0.8 -0.2 -0.2 -0.2 -0.3 -0.   9.6 -0.5  0.6 -0.6 -0.7 -0.1  6.8 -0.3 -0.7  0.4 -0.   1.3]
ty_50sample [[8 0 6 5 2 9 3 4 7 1]
 [1 4 3 3 2 8 0 6 5 7]
 [0 4 3 1 1 6 9 2 8 5]
 [3 4 6 8 1 5 2 9 7 0]
 [9 9 5 8 3 7 4 0 6 2]
 [3 6 9 1 4 8 7 2 5 0]
 [5 0 1 7 7 9 4 6 8 3]
 [2 6 3 4 1 9 9 7 5 0]
 [0 9 9 1 6 5 8 3 4 2]
 [7 0 1 9 5 2 6 4 3 8]]
tt_50sample [[8 0 6 5 2 9 3 4 7 1]
 [1 4 9 3 8 2 0 6 5 7]
 [0 4 3 7 1 6 9 2 8 5]
 [3 4 6 8 1 5 2 9 0 7]
 [1 9 5 8 3 7 4 0 2 6]
 [3 6 9 1 4 8 7 2 5 0]
 [5 0 1 2 7 9 4 6 8 3]
 [2 6 3 4 8 1 9 7 5 0]
 [0 7 9 1 6 5 8 3 4 2]
 [7 0 1 9 5 2 6 4 3 8]]
vm  [ 0.3 -0.7  4.9  7.5 -1.3 -0.8 -0.1 -0.2  0.5 -0.2 -4.3  0.6 -1.3 -0.4 -0.2 -1.4 -0.1  0.   0.4 -0.6 -0.3 -0.1  1.8  0.5 -0.6  0.1 -0.2 -0.4 -0.4 -0.7 -1.3 -0.3  1.  -1.5 -0.3 -0.9 -0.4 -1.7 -1.5 -0.8 -0.2  1.6 -0.4 -1.3  0.3 -0.3  2.2  1.1  3.9  7.1 -0.4 -0.5 -0.4 -1.7  0.1  1.1 -0.3  3.8  2.7  4.7 -0.8 -0.6 -0.3  0.9 -0.7 -0.4 -0.1 -0.4  2.8 -0.  -0.1  1.   0.5  0.8 -2.5  2.  -1.   0.1 -0.8 -0.2 -1.  -0.3 -0.2 -0.1 -1.5  1.3  0.8 -0.2 -0.2 -0.5 -0.3 -0.5 -0.5 -0.8 -0.5 -0.3  1.2 -1.7 -0.5 -0.7 -0.2  3.5 -0.9 -0.3 -0.3 -0.1 -0.8 -1.3 -1.6 -1.1 -0.   0.4 -0.2 -0.3  3.2 -0.2  0.3  2.1 -0.2  0.9 -0.3  2.4 -0.3 -0.6  0.2 -0.1 -0.5  8.8  2.4 -0.5  3.3 -0.8 -0.2 -0.5  6.8  4.7 -0.  -0.5 -0.4  0.7  2.7 -1.   3.3 -0.1 -0.4  0.5 -0.3 -0.7 -0.2  0.2 -0.5 -0.   4.8  0.2 -0.4 -0.2 -0.2 -0.6 -1.3 -0.3  0.2  1.3  0.1 -0.1 -0.7 -0.5 -0.2 -0.1 -0.4  1.2 -0.5 -0.4 -0.6 -0.3 -0.1  1.  -1.5  1.2  4.8  1.1 -0.8 -0.3 -0.1 -1.2 -0.4  0.4  4.3 -0.2 -0.2  1.9 -0.2 -0.2 -0.9 -1.   6.5 -0.9 -0.1 -1.3 -0.1 -0.1 -0.4 -0.4  1.2 -0.3 -0.9 -0.6  0.  -0.4  5.1 -0.5 -0.6  0.6 -0.7 -0.7 -0.8  0.1  5.3 -0.2  0.5 -0.2 -1.2 -0.1 -0.5 -1.4  3.   1.  -2.2 -0.1 -0.5  4.8  2.  -0.3 -0.3  3.3 -0.3 -0.9  1.1 -0.3  2.9  5.  -0.2  2.2 -0.2 -0.4  4.7 -1.6  0.9 -0.5 -0.8 -0.2  2.2 -0.4 -1.2 -0.3  4.4  4.5]
vy_50sample [[6 8 0 9 7 5 3 4 1 2]
 [8 7 1 5 5 3 9 0 4 2]
 [7 4 3 2 5 8 9 6 1 0]
 [8 9 1 4 3 5 7 0 2 6]
 [9 3 8 1 5 4 2 0 7 6]
 [7 5 2 6 3 1 0 4 8 9]
 [5 7 8 4 9 0 3 2 1 6]
 [5 7 3 8 1 9 0 2 6 4]
 [4 0 9 3 2 1 7 8 5 6]
 [0 6 5 1 7 3 3 2 2 8]]
vt_50sample [[6 8 0 9 7 5 3 4 1 2]
 [8 7 1 5 6 3 0 9 4 2]
 [7 4 3 2 5 8 9 6 1 0]
 [8 9 1 4 3 5 7 0 2 6]
 [9 3 8 1 5 4 2 0 7 6]
 [7 5 2 6 3 1 0 4 8 9]
 [5 7 8 4 9 0 3 2 1 6]
 [5 7 3 8 1 9 0 2 6 4]
 [4 0 9 3 2 1 7 8 5 6]
 [0 6 5 1 7 4 3 2 8 9]]
Epoch 18310: Training cost= 0.2848, Training acc= 0.8107, Validation cost= 0.3162, Validation acc= 0.8110
Epoch 18320: Training cost= 0.3440, Training acc= 0.8107, Validation cost= 0.3485, Validation acc= 0.8110
Epoch 18330: Training cost= 0.3171, Training acc= 0.8107, Validation cost= 0.3404, Validation acc= 0.8110
Epoch 18340: Training cost= 0.3104, Training acc= 0.8108, Validation cost= 0.4314, Validation acc= 0.8111
Epoch 18350: Training cost= 0.3949, Training acc= 0.8108, Validation cost= 0.4740, Validation acc= 0.8111
Epoch 18360: Training cost= 0.3208, Training acc= 0.8108, Validation cost= 0.3495, Validation acc= 0.8111
Epoch 18370: Training cost= 0.3392, Training acc= 0.8108, Validation cost= 0.3648, Validation acc= 0.8112
Epoch 18380: Training cost= 0.3499, Training acc= 0.8109, Validation cost= 0.3261, Validation acc= 0.8112
Epoch 18390: Training cost= 0.2985, Training acc= 0.8109, Validation cost= 0.2770, Validation acc= 0.8112
Epoch 18400: Training cost= 0.2886, Training acc= 0.8109, Validation cost= 0.3329, Validation acc= 0.8113
tm  [-0.3 -0.4  0.2  1.4 -1.4 -0.4 -0.3 -0.5 -0.4 -0.2  5.6 -0.9 -0.1 -0.1  0.8 -0.3 -0.5 -0.3 -0.2 -0.3 -0.9 -0.4  1.9  0.5 -1.3  4.9 -0.3 -0.1 -1.5 -0.4  2.4 -0.4 -0.5  3.6  1.7  0.2  3.7  0.4 -0.4 -0.7 -0.4  1.5 -0.1 -0.2 -0.6  0.1 -0.3 -0.9  1.6  4.  -0.6 -0.4  0.2  2.8  1.4  1.4 -0.6 -0.5  0.5 -0.4  1.1  0.4 -0.1  4.5  0.4  0.3 -0.1 -0.1  0.3 -0.1 -0.3  3.9 -0.1  0.3 -1.3 -0.3 -0.5 -0.4  1.1  1.1  3.8 -0.   0.7 -0.1 -0.4  2.6  0.7  0.3 -0.4 -0.1  1.  -0.7 -0.5 -0.8 -0.4  0.4 -0.1 -1.5 -0.1 -0.5 -0.1  4.5 -0.3 -0.3  0.2  0.5 -0.7  3.1  1.4 -0.4 -1.1  0.7  0.4 -0.   3.3 -1.8 -0.9 -0.7 -0.4 -0.   0.7  1.7  0.2  1.7 -0.3  0.6 -0.7  0.  -0.2 -0.8  2.2 -0.4 -0.2 -0.4  5.6  7.8 -0.4  0.1  1.8 -0.4 -0.1 -1.2 -0.5 -0.  -0.1 -0.2 -0.1 -0.1 -0.3 -0.  -0.1 -0.1 -0.   0.  -0.1  0.4 -0.2 -0.4 -0.7  0.4  2.1  1.3  0.   0.1 -0.2 -0.8 -0.3  0.9 -0.2  0.9 -0.1 -0.6  1.3  0.  -0.5  2.  -0.4  1.1  2.7 -0.3  0.6 -0.3 -0.6 -1.3 -0.  -0.4  0.8 -0.4 -0.   1.8 -0.2 -0.5 -0.3 -0.6  1.3  0.5 -0.2 -0.1 -0.2  0.8 -0.2 -0.  -0.7 -0.8  0.5 -0.9 -0.   0.5  1.2  0.1 -0.3 -1.  -1.3  3.2 -0.7 -0.5  2.1 -0.8 -0.7  0.4 -0.6 -0.4 -0.2 -1.1  5.1 -0.8 -0.1  2.8  1.8  0.5  0.1 -0.8 -0.2  0.9  4.7  1.7  4.   0.5  2.3  4.  -0.2  2.4 -0.2 -0.1 -0.2 -0.8 -0.   1.2 -1.3 -0.5 -1.1 -0.1 -0.3  0.5 -0.8  6. ]
ty_50sample [[0 6 2 9 4 7 7 8 5 3]
 [6 3 8 8 1 2 4 7 5 9]
 [1 0 5 3 9 4 6 7 2 8]
 [6 1 5 9 8 8 7 4 2 0]
 [0 4 7 2 3 5 1 8 9 6]
 [7 2 0 6 5 4 9 1 8 3]
 [5 4 4 2 8 7 0 1 3 9]
 [9 6 1 3 2 0 5 7 4 8]
 [6 8 3 0 4 5 7 2 9 1]
 [8 4 6 1 0 0 3 7 5 5]]
tt_50sample [[0 6 2 9 4 1 7 5 8 3]
 [6 3 8 1 0 2 4 7 5 9]
 [1 0 5 3 9 4 6 7 2 8]
 [6 1 5 9 8 3 7 4 2 0]
 [0 4 7 2 3 5 1 8 9 6]
 [7 2 0 6 5 4 9 1 8 3]
 [5 6 4 2 8 7 0 1 3 9]
 [9 6 1 3 2 0 5 7 8 4]
 [6 8 3 0 4 5 7 2 9 1]
 [8 4 6 1 0 3 2 7 5 9]]
vm  [-1.1 -0.2  9.3 -0.6 -1.8 -0.3 -0.3  0.  -0.8 -0.  -3.6 -0.  -1.  -0.  14.2 -1.1 -0.3 -0.2 -0.3  2.7 -0.5 -0.5  2.5 -0.  -0.8 -0.5 -0.6 -0.3 -0.8 -0.2 -1.3 -0.3 -0.1  5.  -0.4 -0.3  0.3 -1.6 -4.2 -0.5 -0.7  3.4  0.1 -1.2 -0.3  0.1 -3.2  0.8  1.   6.  -0.3 -0.3 -1.   1.8 -0.6 -1.8 -0.8  6.1  0.7  4.8  6.1 -0.  -0.5  0.7 -0.9 -0.3 -0.2 -0.4  0.6 -0.  -0.3 -0.  -0.3  0.1 -5.5 -0.1 -0.6 -0.1 -0.2  0.3 -4.4 -0.2 -0.1 -0.1 -0.3  4.7 -0.6  0.1 -0.2 -0.3 -0.3 -0.2 -0.2 -0.  -0.4 -0.2  0.2 -2.1 -0.3  0.4  1.   6.4  1.1 -0.1  0.3  0.8 -2.7 -1.1 -1.3  0.9 -0.3 -0.1  0.2 -0.7  1.   1.6 -0.3  1.5 -0.3 -0.9 -0.3 -0.7 -0.2 -0.  -0.2 15.8  1.3  0.2  1.2  4.2  1.4 -0.6 -0.2 -0.3 -0.4  4.9 -0.4 -0.3 -0.8 -0.5  2.8 -0.4  1.4 -0.4 -0.2 -0.4 -0.7  0.3 -0.8  0.1  1.1 -0.2  1.8 -0.2 -0.3 -0.1 -0.2 -0.4 -1.1 -0.7  0.2  3.2 -0.5  0.1 -0.6 -0.   0.   1.6 -0.1 -0.5 -0.4 -0.1 -0.3 -0.  -0.1  2.3 -1.  -1.1 10.4 -0.  -1.6 -0.2 -0.4 -1.   0.8 -0.2 -0.8 -0.6 -0.5  0.3  0.4 -0.2  0.9 -0.6 -1.6 -0.4 -1.5 -0.5  0.1  0.4 -0.  -0.4 -0.1 -0.4 -0.1 -4.2 -0.1  0.4  1.7 -0.1 -0.5 -0.5 -0.5  0.6 -0.4 -0.5  6.3 -0.4  0.1 -0.3 -0.8 -0.1 -0.4 -0.7  3.5  1.4 -1.4 -0.4  0.2  3.3 -0.  -0.2 -0.2  1.2  1.3 -2.4  0.6 -2.2  2.4 -3.9 -0.3 -1.8  0.2 -0.4 13.7  8.  -0.5  1.4 -0.7 -0.1 10.6 -0.2 -3.1 -0.4  3.1 -1.1]
vy_50sample [[7 6 8 5 0 1 3 4 2 9]
 [9 3 1 2 4 7 8 5 6 0]
 [6 9 1 7 8 0 4 5 2 3]
 [5 0 2 1 8 4 6 7 9 3]
 [1 9 0 6 8 2 2 7 4 3]
 [0 4 1 7 2 8 9 6 5 3]
 [2 8 6 5 1 4 7 3 9 0]
 [4 4 0 3 1 5 8 6 2 9]
 [3 1 2 5 0 0 6 8 7 4]
 [4 5 2 7 6 8 3 3 0 1]]
vt_50sample [[7 6 8 5 0 1 3 4 2 9]
 [9 3 1 2 4 7 8 6 5 0]
 [6 9 1 7 8 0 4 5 2 3]
 [5 0 2 1 8 4 6 3 7 9]
 [1 9 0 6 8 2 7 5 4 3]
 [0 4 1 7 2 8 9 6 5 3]
 [2 8 6 5 1 4 7 3 9 0]
 [7 4 0 3 1 5 6 8 2 9]
 [3 1 2 5 9 0 6 8 7 4]
 [4 5 2 7 6 8 3 9 0 1]]
Epoch 18410: Training cost= 0.3193, Training acc= 0.8110, Validation cost= 0.3297, Validation acc= 0.8113
Epoch 18420: Training cost= 0.2987, Training acc= 0.8110, Validation cost= 0.3106, Validation acc= 0.8113
Epoch 18430: Training cost= 0.3622, Training acc= 0.8110, Validation cost= 0.3222, Validation acc= 0.8114
Epoch 18440: Training cost= 0.4008, Training acc= 0.8111, Validation cost= 0.4168, Validation acc= 0.8114
Epoch 18450: Training cost= 0.3634, Training acc= 0.8111, Validation cost= 0.3200, Validation acc= 0.8114
Epoch 18460: Training cost= 0.3067, Training acc= 0.8111, Validation cost= 0.3517, Validation acc= 0.8114
Epoch 18470: Training cost= 0.3411, Training acc= 0.8112, Validation cost= 0.3079, Validation acc= 0.8115
Epoch 18480: Training cost= 0.2903, Training acc= 0.8112, Validation cost= 0.3393, Validation acc= 0.8115
Epoch 18490: Training cost= 0.3591, Training acc= 0.8112, Validation cost= 0.3122, Validation acc= 0.8115
Epoch 18500: Training cost= 0.3177, Training acc= 0.8113, Validation cost= 0.3261, Validation acc= 0.8116
tm  [-0.9  0.3  1.6 -0.2 -1.  -0.3 -0.3 -0.1 -0.1 -1.1 -0.8 -0.5  0.5 -0.   2.7  4.9 -0.1  0.2  0.5  3.6 -0.5 -0.5  1.7 -0.2 -0.8  0.1 -0.7  0.2 -0.5 -2.  -1.9 -0.4  0.2 -4.  -0.4 -0.2  0.3  3.  -2.1 -0.7 -0.5 -2.2 -0.7 -0.7 -0.5 -0.2 -2.5 -0.7  0.5  2.3 -0.6 -0.3 -0.7  9.2 -0.6 -0.1 -0.2  3.3  3.   6.1  5.5 -0.2 -0.2  2.  -0.8 -0.3  0.  -0.3 -0.4 -0.2 -0.1  0.4  0.5 -0.2 -4.5 -0.2 -0.5 -0.3 -0.6 -0.3 -4.9 -0.5  1.  -0.1 -0.5 -2.  -1.  -0.3 -0.1 -0.2 -0.5 -0.2  0.7  1.6 -0.5 -0.3  0.4 -2.3 -0.2 -0.3  3.8 -2.5 -0.  -0.1 -0.2 -0.2 -2.3 -1.9 -0.3  2.  -0.4 -0.  -0.2 -0.4  1.5  2.2 -0.4  0.4 -0.3 -0.4 -0.3 -0.9 -0.2  1.1 -0.5  2.6  0.2 -2.2  2.2  8.6  0.5 -0.7 -0.1 -0.5  7.2 -1.9 -0.2 -0.1  1.4  1.9 -0.6 -1.1 -1.2 -0.4 -0.  -0.2 -0.5 -0.2  2.5 -0.  -0.  -0.3  2.5 -0.7 -0.3 -0.  -0.3 -0.4 -0.1 -0.5 -0.7 -0.2 -0.5 -0.2 -0.7 -0.3  1.9  2.4 -0.  -0.2 -0.5 -0.1 -0.5 -0.1 -0.5 -0.2 -0.9 -0.9  6.1 -0.4 -0.   0.  -0.3 -1.2 -0.  -0.2 -0.7 -0.2 -0.6  6.2  0.1 -0.1 -0.3 -0.7 -1.4 -1.  -1.3 -0.4 -0.4  0.1 -0.1 -0.2 -0.3 -0.8 -0.1 -3.5 -0.5  0.1  7.8  0.3 -0.5  0.8 -0.9  1.8 -0.6 -0.6  4.4 -0.3 -0.5  0.1 -0.1 -0.1 -0.3 -1.2 -0.6  1.9  0.3  2.8 -0.5  3.9 -0.5  0.2 -0.5  4.9  0.8  0.4  0.1 -1.6  0.1 -1.  -0.2 -0.5 -0.2 -0.6 15.4  4.2 -0.2  0.1 -0.9  0.  11.3 -0.4 -1.6  0.3  1.5 -2.4]
ty_50sample [[8 3 2 6 1 0 5 7 4 9]
 [6 3 7 1 8 4 9 2 5 0]
 [8 1 4 0 6 5 2 7 9 3]
 [8 1 7 6 3 4 9 5 0 2]
 [4 9 8 2 1 0 7 6 3 5]
 [1 6 8 2 4 5 9 0 3 7]
 [4 0 1 5 8 3 2 7 6 9]
 [2 2 6 9 8 1 4 5 7 3]
 [9 6 8 3 5 4 1 2 0 7]
 [7 6 9 4 2 5 1 3 0 8]]
tt_50sample [[8 3 2 6 1 0 5 7 4 9]
 [6 3 7 1 8 4 9 2 5 0]
 [8 1 4 0 6 5 2 7 9 3]
 [8 7 1 6 3 9 4 5 0 2]
 [4 9 8 2 1 0 7 6 3 5]
 [1 6 8 2 4 5 9 0 3 7]
 [4 0 1 5 8 3 7 2 6 9]
 [2 0 6 9 8 1 4 7 5 3]
 [9 6 3 8 5 4 1 2 0 7]
 [7 6 9 4 2 5 1 3 0 8]]
vm  [ 0.   0.6  5.5  7.6 -1.1 -0.3 -0.2 -0.3 -1.1 -0.  -0.5 -0.8 -0.3 -0.1  2.6  2.3  0.  -0.3 -0.6 -1.4 -0.6 -0.2  3.4  0.5 -1.1 -0.1 -0.3 -0.2 -0.4  2.6 -1.2  0.3 -0.2 -0.2 -0.4  0.   3.6 -0.4 -1.4 -0.3 -0.2  6.6  2.4 -1.1 -0.3 -0.3  3.1 -0.4  1.8 10.6 -0.5 -0.1 -0.8  2.2 -0.8 -0.  -0.4  6.1 -1.2  4.9 -0.6 -0.5 -0.9 -0.1 -0.1 -0.1 -0.1 -0.2  0.4 -0.6 -0.2 -0.4 -0.3 -0.4 -1.7  0.2 -0.6 -0.1 -0.1 -0.1 -1.1  0.2 -0.6  0.8 -0.9  8.4  0.8  0.9 -0.4 -0.3 -0.5  0.  -0.4  1.8 -0.4 -0.1  0.1 -0.7 -0.  -0.3  0.3  5.9 -0.6  1.3 -0.1 -0.1 -1.  -1.  -0.2 -1.2 -0.2 -0.1 -0.  -0.2 -0.6  2.7 -0.7 -0.9 -0.3 -0.2 -0.2  4.  -0.1 -0.4 -0.4  2.7  0.   0.3 -0.5 -1.2  3.3 -0.4 -0.3 -0.4  4.8  4.3 -0.2 -0.2 -0.  -0.6 -0.6 -0.4  0.2 -0.2 -0.3  0.  -0.4 -0.2  2.3  0.5 -0.7 -0.3  3.7 -0.4 -0.4  0.5 -0.2 -0.2 -1.5 -0.5  0.6  2.2 -0.4 -0.  -0.2  0.2 -0.1 -0.6 -0.   0.9  0.8  0.6  0.2  0.8 -0.4 -0.4 -1.2 -0.4  4.  -0.5 -1.9 -0.3 -0.1 -0.8 -0.3 -0.2  2.5 -0.6 -0.2 -0.7  0.9  0.1 -0.7 -0.4  5.1  1.1 -0.6  1.8  0.1 -0.2 -0.5 -0.4 -0.2 -0.3 -0.4 -1.4 -0.1  0.6 -0.3  0.3 -0.1  0.7 -0.3 -0.4 -0.3 -0.4  5.3 -0.4 -0.1 -0.1 -0.4 -0.2 -0.2 -0.9  4.9  2.7 -0.4 -0.2  0.6  2.1 -0.3  0.  -0.3 -0.3 -0.1 -0.9  0.8 -0.7  1.4 -1.6 -0.2 -0.8 -0.2 -0.3  4.8 -0.4  0.  -0.  -0.5 -0.1  2.6 -0.1 -1.   0.1 -0.5  8.6]
vy_50sample [[6 5 8 7 2 9 0 1 4 3]
 [3 7 1 9 5 8 0 2 4 6]
 [9 7 4 6 1 0 8 2 5 3]
 [3 9 6 5 0 2 7 4 1 8]
 [9 4 6 1 0 8 2 3 7 7]
 [7 8 3 2 4 6 0 0 1 5]
 [0 5 7 9 2 6 8 1 3 4]
 [6 9 2 0 3 4 8 1 7 5]
 [0 2 8 5 5 3 4 6 1 9]
 [4 8 3 6 7 5 9 2 1 0]]
vt_50sample [[5 6 8 7 2 9 0 4 1 3]
 [3 7 1 9 5 8 0 2 4 6]
 [9 7 4 6 1 0 8 2 5 3]
 [3 9 6 5 0 2 7 4 8 1]
 [9 4 6 1 0 8 2 3 5 7]
 [7 8 3 2 4 6 0 9 1 5]
 [0 5 7 9 2 6 8 1 3 4]
 [6 9 2 0 3 4 8 1 7 5]
 [0 2 8 7 5 3 4 1 6 9]
 [4 8 3 6 7 5 9 2 1 0]]
Epoch 18510: Training cost= 0.3337, Training acc= 0.8113, Validation cost= 0.2833, Validation acc= 0.8116
Epoch 18520: Training cost= 0.3212, Training acc= 0.8113, Validation cost= 0.3288, Validation acc= 0.8117
Epoch 18530: Training cost= 0.3195, Training acc= 0.8114, Validation cost= 0.2794, Validation acc= 0.8117
Epoch 18540: Training cost= 0.3177, Training acc= 0.8114, Validation cost= 0.2456, Validation acc= 0.8117
Epoch 18550: Training cost= 0.2992, Training acc= 0.8115, Validation cost= 0.3266, Validation acc= 0.8118
Epoch 18560: Training cost= 0.2836, Training acc= 0.8115, Validation cost= 0.2861, Validation acc= 0.8118
Epoch 18570: Training cost= 0.3401, Training acc= 0.8115, Validation cost= 0.2629, Validation acc= 0.8118
Epoch 18580: Training cost= 0.3148, Training acc= 0.8116, Validation cost= 0.2580, Validation acc= 0.8119
Epoch 18590: Training cost= 0.2736, Training acc= 0.8116, Validation cost= 0.3347, Validation acc= 0.8119
Epoch 18600: Training cost= 0.2963, Training acc= 0.8116, Validation cost= 0.3407, Validation acc= 0.8119
tm  [ 1.5 -1.3 -1.8 -0.3 -1.2 -0.4 -0.1  0.2  5.1 -0.   7.7 -0.1 -0.7 -0.7 -1.   2.2 -0.6 -0.4 -0.4 -0.5 -1.   0.5 -0.1 -0.4 -0.7  1.2 -0.  -0.3  0.8 -1.9  5.2 -1.  -0.4  4.1  1.1 -1.  -1.1  3.9  9.2 -0.7  1.2  2.5 -1.1  5.7 -0.1  0.1  2.6 -1.   5.1 -0.5 -0.3 -0.5  1.8  0.1 -1.1  3.2 -0.4 -0.5  8.2 -1.9 -1.7 -0.6  2.1  2.5  1.4 -0.2 -0.1  2.9  1.3  0.1 -0.1 -0.9 -0.1  1.7 -2.8  1.1 -1.5 -0.1 -0.6 -0.1 10.2 -0.3  1.1 -0.3 -1.6  3.   4.1 -0.1 -0.4 -0.6 -0.  -1.2 -0.5 -2.2 -0.1  0.5 -0.2 -1.8 -0.4 -0.6 -0.9  1.6 -1.6 -0.  -0.3  0.1 -0.5  5.8  1.8 -1.3 -0.4 -0.1 -0.  -1.2  4.5  2.4  2.3  4.  -0.3  1.6 -0.   2.7 -0.5 -0.2  0.1 -1.2 -0.7  2.2  8.7 -1.   1.  -0.8 -0.1 -0.3 -1.6 -0.2 -0.1 -0.3 -0.2 -0.6 -0.4 -0.2 -0.2 -0.  -0.2 -0.1  0.7 -0.6  2.7 -0.3  0.6 -0.1  3.  -0.4 -0.1 -0.3 -0.4 -0.1  4.   1.7  2.2 -2.   0.5 -0.3  0.7 -0.4 -0.4  0.9 -0.5 -0.1 -0.4 -0.5 -0.6 -0.4 -0.2 -0.3 -0.2  3.1 -1.3 -0.3 -0.7 -0.4 -0.5 -1.2 -0.4 -0.3  6.5 -0.2 -0.5  5.9 -0.2 -0.6 -1.  -0.9  9.2 -2.7  1.4 -1.5  0.5 -0.1  0.4 -0.2  0.1 -0.7 -1.   2.7  0.  -0.2 -1.3 -0.2 -0.5  3.5 -0.6 -0.7 -0.4 -0.2 -1.8 -0.8 -0.1 -0.5 -1.1 -0.2 -1.  -1.  -0.5  0.1 -0.5  0.8  2.5  7.2 -0.5 -1.  -0.1 -0.5 -1.   4.8  1.2 -0.5  2.1  5.3 -0.1  2.6  0.2 -0.1 -1.8 -2.5 -0.2 -0.1 -1.2 -0.1 -2.6  0.1  6.8  0.  -0.3  5.8]
ty_50sample [[4 9 2 5 0 7 3 8 1 6]
 [7 8 6 4 9 5 3 0 2 1]
 [4 6 6 1 0 0 7 5 2 8]
 [0 0 2 5 5 1 4 3 6 7]
 [6 0 0 9 2 8 7 5 4 3]
 [9 9 1 5 4 6 8 3 0 7]
 [6 4 8 0 3 9 5 1 1 7]
 [9 6 1 0 3 7 4 2 5 8]
 [4 9 2 5 0 8 7 6 3 1]
 [1 7 5 9 3 2 6 6 4 0]]
tt_50sample [[4 9 2 5 0 7 3 8 1 6]
 [7 8 6 4 5 9 3 0 2 1]
 [4 6 9 3 0 1 7 5 2 8]
 [0 9 2 8 5 1 4 3 6 7]
 [6 0 1 9 2 8 7 5 4 3]
 [9 2 1 4 5 6 8 0 3 7]
 [6 4 8 0 3 9 5 1 2 7]
 [9 6 1 0 3 7 4 2 5 8]
 [4 9 2 5 0 8 7 6 3 1]
 [1 7 5 9 3 2 8 6 4 0]]
vm  [-0.8 -0.1  5.6  9.3 -1.8 -0.2 -0.2 -0.  -0.7 -0.2 -2.9 -0.5 -0.1 -0.3  0.3  0.5 -0.2 -0.  -0.1 -1.2 -0.8 -0.2  4.  -0.  -0.7  1.1 -0.2  0.6 -0.7 -0.2 -1.6 -0.1 -0.1 -1.5 -0.1 -0.1  2.   2.3  9.  -0.3 -0.2  5.3  1.7  2.3  0.7 -0.6  4.4 -0.1  1.1 12.7 -0.5 -0.1 -0.5 -0.6 -0.2  0.9 -0.4  4.7 -0.3  5.1 -0.3 -0.3 -0.6  1.6 -1.2 -0.7 -0.2 -0.7  0.2 -0.  -0.   1.8  0.4  0.6  0.1  0.7 -0.1 -0.1  0.5 -0.3 -0.9 -0.2 -0.4 -0.1 -0.7  6.4 -0.4 -0.1 -0.5 -0.   0.6 -0.1 -0.7 -0.3 -0.3 -0.4  1.9 -0.9 -0.1 -0.2  0.9  7.6 -0.1 -0.   0.4 -0.6 -0.3 -1.8 -1.2 -1.7 -0.8 -0.1 -0.3 -0.4  1.1  0.4 -0.1 -0.7 -0.4 -0.4 -0.1  6.8  0.4 -0.6 -0.1  0.5 -0.2  4.7  1.1 -1.8 -0.4 -0.4 -0.4 -0.5 -2.9 -4.8  0.  -0.5 -0.5  2.8  0.3 -0.8  1.   1.  -0.3  0.1 -0.1 -0.4  0.3  0.4 -0.4 -0.4  3.5 -0.  -0.1 -0.2  0.1 -0.5  3.6 -0.4  1.4 -0.8 -0.3 -0.1 -0.5 -0.5 -0.  -0.3 -0.   0.3  0.9 -0.2 -0.2 -0.1 -0.2  1.3  0.   0.7 -1.3 -0.3 -1.3 -0.4 -0.4 -0.8 -0.2  0.2  1.3 -0.8 -0.1  1.2 -0.1 -0.3 -0.7 -0.1  3.5 -0.2  1.4 -0.1  0.4 -0.  -0.4 -0.2 -0.2 -0.5  0.3 -0.2 -0.1  1.3  5.2  0.1 -0.1  0.4 -0.2  2.2 -0.6 -0.4 -0.  -0.5  0.8 -0.1 -0.4  0.5 -0.5 -1.   2.2  1.  -0.7  1.3 -0.5  0.4 -0.3 -1.   0.1  3.4  2.1 -0.9  1.1  2.1  1.8  3.7 -0.2  1.3 -0.3 -0.3  4.2 -1.6 -0.3 -0.1 -1.  -0.6  1.8 -0.3  7.  -0.1 -0.  10.3]
vy_50sample [[8 9 7 0 5 1 2 4 6 3]
 [0 7 7 5 2 2 3 8 6 1]
 [5 9 7 6 4 3 0 2 8 1]
 [5 9 7 6 0 4 2 2 1 3]
 [5 7 3 2 4 1 9 6 6 0]
 [3 5 8 4 2 7 7 6 1 9]
 [7 8 3 5 9 6 4 1 2 0]
 [6 5 9 3 7 2 8 4 1 0]
 [7 6 3 1 5 4 4 2 0 9]
 [7 2 4 5 0 9 1 3 3 6]]
vt_50sample [[8 9 7 5 0 1 2 4 6 3]
 [0 7 9 4 5 2 3 8 6 1]
 [5 9 7 6 4 3 0 2 8 1]
 [5 9 6 7 0 4 2 8 1 3]
 [7 5 3 2 4 1 9 6 8 0]
 [3 5 8 4 2 7 0 6 1 9]
 [7 8 3 5 9 6 4 1 2 0]
 [6 5 9 3 7 2 8 4 0 1]
 [7 6 3 1 5 4 8 2 0 9]
 [7 2 4 5 0 9 1 3 8 6]]
Epoch 18610: Training cost= 0.3460, Training acc= 0.8117, Validation cost= 0.4371, Validation acc= 0.8120
Epoch 18620: Training cost= 0.3601, Training acc= 0.8117, Validation cost= 0.3369, Validation acc= 0.8120
Epoch 18630: Training cost= 0.3885, Training acc= 0.8117, Validation cost= 0.3373, Validation acc= 0.8120
Epoch 18640: Training cost= 0.3317, Training acc= 0.8117, Validation cost= 0.3385, Validation acc= 0.8120
Epoch 18650: Training cost= 0.2946, Training acc= 0.8118, Validation cost= 0.3005, Validation acc= 0.8121
Epoch 18660: Training cost= 0.3367, Training acc= 0.8118, Validation cost= 0.3120, Validation acc= 0.8121
Epoch 18670: Training cost= 0.2923, Training acc= 0.8118, Validation cost= 0.3425, Validation acc= 0.8121
Epoch 18680: Training cost= 0.3326, Training acc= 0.8119, Validation cost= 0.2829, Validation acc= 0.8122
Epoch 18690: Training cost= 0.3115, Training acc= 0.8119, Validation cost= 0.3247, Validation acc= 0.8122
Epoch 18700: Training cost= 0.2741, Training acc= 0.8120, Validation cost= 0.2529, Validation acc= 0.8123
tm  [-1.6 -0.2  3.8  9.6 -1.9  0.2 -0.4 -0.1 -0.5 -0.3 -0.4 -0.1 -0.3 -0.3 -0.9  0.4 -0.3 -0.4  0.5 -1.6 -0.9 -0.4  0.4 -0.3 -0.8  2.5 -0.3 -0.2 -0.2 -0.8  1.  -0.5 -0.6  4.8 -0.6  0.4  1.9  2.5 17.7 -0.6 -0.3 -1.8 -0.3  4.4 -0.5  0.4  8.4  1.5 -1.  -0.2 -0.6 -0.   2.3 -2.1 -0.7  2.  -0.6 -1.3  1.3  0.1  0.6  1.1 -0.3  0.1 -0.6  0.4 -0.1 -0.5  0.4  0.9 -0.2 -0.4 -0.   0.1  7.8  0.1  1.4 -0.2 -0.   0.2 12.1 -0.2 -0.6 -0.   2.9 -1.5 -0.8 -0.2 -0.  -0.1 -0.2  0.6 -0.  -0.9 -0.1 -0.1 -0.4  0.1 -0.7 -0.1  3.1  3.3  2.7 -0.1 -0.2  0.2  3.7  1.3 -0.2 -2.7 -0.7 -0.7 -0.2 -0.1  0.5  3.2  1.  -0.7 -0.3 -0.9 -0.  10.5 -0.3 -0.2 -0.1 -1.2  2.3 10.   2.  -1.2 -1.7 -0.7 -0.5 -0.7 -4.9 -3.   0.3 -0.2 -0.1 -0.5  0.9 -0.3 -0.2 -0.2 -0.3 -0.1  0.8 -0.2 -2.   0.1 -0.5 -0.1 -0.9  0.1 -0.2 -0.1 -0.  -0.4  5.7 -0.4 -0.3 -1.5 -0.2 -0.1 -0.7  0.2  1.9  2.7 -0.5 -0.  -0.6 -0.7 -0.3 -0.  -0.2  4.7  3.4  2.2 -2.9 -0.4  0.9  0.  -0.2 -0.6 -0.6 -0.  -0.7 -0.3 -0.3  3.5 -0.1 -0.3 -1.1 -0.5  1.5 -0.2  4.9  1.  -0.2 -0.2  0.1 -0.4 -0.1 -0.7  2.6  6.   0.3  0.2  5.4 -0.2 -0.2  1.  -1.   5.9 -0.3 -0.4 -1.3 -0.2  1.2 -0.  -0.6 -0.2 -0.2 -0.4 -1.6  1.  -1.2  0.8  1.7 -0.4 -0.5 -1.5 -0.1  4.1  0.6 -0.7 -0.5  6.6  1.8 19.3 -0.1  9.4 -0.4 -0.1 -2.2 -2.7 -0.2  0.3 -0.7 -0.5 -3.  -0.3 13.2 -0.1  3.5  6.2]
ty_50sample [[9 1 7 3 4 8 0 2 5 6]
 [8 6 0 5 3 9 4 2 7 7]
 [2 6 1 9 8 7 3 4 5 0]
 [5 6 1 8 9 7 2 3 4 0]
 [6 8 0 5 1 7 2 4 9 3]
 [7 5 8 3 9 6 1 2 0 0]
 [0 5 9 3 6 7 2 1 4 8]
 [1 9 6 3 2 5 0 7 4 8]
 [9 1 3 3 5 8 6 2 7 4]
 [3 6 8 1 7 2 5 4 9 0]]
tt_50sample [[9 1 7 3 4 8 0 2 5 6]
 [8 6 0 5 3 9 4 2 1 7]
 [2 6 1 9 8 7 4 3 5 0]
 [5 1 6 8 9 7 2 3 4 0]
 [6 8 0 5 1 7 2 4 9 3]
 [7 5 8 3 9 6 1 2 0 4]
 [0 5 9 3 6 7 2 1 4 8]
 [1 9 6 3 2 5 0 7 4 8]
 [9 1 3 5 0 8 6 2 7 4]
 [3 6 8 1 2 7 5 4 9 0]]
vm  [-0.2  0.2  1.8  9.1 -0.9 -0.4 -0.1 -0.4 -1.   0.4  3.5 -0.6 -0.4 -0.2 -1.3 -0.1 -0.1 -0.3 -0.  -1.4 -0.6  0.3  2.6  0.3 -1.4  2.7 -0.4 -0.2 -1.3 -0.2 -0.4  0.2  0.3 -1.   0.6  0.9  4.4 -0.2 -1.1 -0.3 -0.2  5.6  1.9 -1.3 -0.6 -0.2  4.8 -0.5  1.1  7.6 -0.3 -0.   0.6  0.6  0.3  3.  -0.4  3.7 -0.9  3.3 -0.5 -0.1 -0.2  1.  -0.1 -0.5 -0.2 -0.1 -0.1 -0.5 -0.   3.4 -0.  -0.4 -0.7 -0.2 -0.2 -0.4 -0.2 -0.1  5.5 -0.2 -0.3 -0.4 -0.8  6.   0.3 -0.  -0.5 -0.1 -0.6 -0.5 -0.4  1.2 -0.1 -0.1  0.8 -0.5 -0.2 -0.2 -0.3  3.7 -0.5 -0.  -0.2 -0.1 -0.4 -0.4  1.8 -1.4 -0.7  0.2 -0.2  0.4  1.1 -1.3 -0.3 -1.1 -0.3  1.1 -0.3  4.3 -0.3  0.  -0.2 -1.7 -0.3  2.3 -0.7 -1.9  1.2 -0.1 -0.5 -0.2 10.5  9.9 -0.2 -0.1 -0.3 -0.7 -0.3 -1.  -0.4 -0.1 -0.  -0.   0.1 -0.4  3.5 -0.1 -0.9 -0.1  1.6 -0.1 -0.2 -0.2 -0.  -0.1 -1.5 -0.5  0.2  1.8 -0.2 -0.2 -0.2 -0.7 -0.4 -0.7 -0.3  1.5  0.8 -0.2  0.3 -0.1 -0.3 -0.8 -1.3  0.8  3.1 -0.5 -1.1  0.1  0.1 -0.9 -0.4 -0.   1.7 -0.3  0.4 -0.  -0.2 -0.2 -0.6 -0.7  4.8  2.4 -0.1  1.2 -0.2  0.2 -0.2 -0.3 -0.1 -0.2 -0.5  0.4 -0.2  0.2 -0.9 -0.  -0.  -1.1 -0.4  0.7 -0.4 -0.3  5.5 -0.5 -0.7  0.2 -0.2 -0.2  0.9 -0.9  5.4 -0.6 -0.7  1.4 -0.1 -0.1  2.2 -0.3 -0.4 -0.6  2.3  0.1  1.6  1.1  0.2  1.3 -0.2  0.6 -0.4 -0.2 -0.7 -1.7 -0.   0.  -0.8 -0.2 -1.6 -0.2 -0.7  0.4 -0.9 10.7]
vy_50sample [[6 0 5 9 2 8 1 7 4 3]
 [6 1 8 0 9 5 2 4 7 3]
 [7 9 5 8 1 6 3 0 4 2]
 [9 0 0 3 1 5 6 2 7 7]
 [0 8 1 6 9 3 4 5 2 7]
 [7 5 5 0 2 2 6 6 3 3]
 [7 5 1 9 3 6 2 4 0 8]
 [5 9 7 0 8 2 3 1 4 6]
 [4 5 1 8 2 6 9 3 0 7]
 [1 0 5 3 9 6 7 2 2 4]]
vt_50sample [[6 0 5 9 2 8 1 7 4 3]
 [6 1 8 0 9 5 2 4 7 3]
 [7 9 5 8 1 6 3 4 0 2]
 [9 0 8 3 1 5 6 2 7 4]
 [0 8 1 6 9 3 4 5 2 7]
 [9 7 5 0 4 2 8 6 1 3]
 [7 5 1 9 3 6 2 4 0 8]
 [5 9 7 0 8 2 3 1 4 6]
 [4 5 1 8 2 6 9 3 0 7]
 [1 0 5 3 9 6 7 8 2 4]]
Epoch 18710: Training cost= 0.2781, Training acc= 0.8120, Validation cost= 0.2995, Validation acc= 0.8123
Epoch 18720: Training cost= 0.3314, Training acc= 0.8120, Validation cost= 0.3003, Validation acc= 0.8123
Epoch 18730: Training cost= 0.3636, Training acc= 0.8121, Validation cost= 0.3271, Validation acc= 0.8124
Epoch 18740: Training cost= 0.3713, Training acc= 0.8121, Validation cost= 0.3013, Validation acc= 0.8124
Epoch 18750: Training cost= 0.3631, Training acc= 0.8121, Validation cost= 0.3484, Validation acc= 0.8124
Epoch 18760: Training cost= 0.3406, Training acc= 0.8122, Validation cost= 0.4017, Validation acc= 0.8125
Epoch 18770: Training cost= 0.2835, Training acc= 0.8122, Validation cost= 0.3972, Validation acc= 0.8125
Epoch 18780: Training cost= 0.3100, Training acc= 0.8122, Validation cost= 0.3022, Validation acc= 0.8125
Epoch 18790: Training cost= 0.3397, Training acc= 0.8123, Validation cost= 0.3196, Validation acc= 0.8125
Epoch 18800: Training cost= 0.3132, Training acc= 0.8123, Validation cost= 0.2888, Validation acc= 0.8126
tm  [-0.1  0.6  3.5  8.1 -1.  -0.3  0.3 -0.4 -0.8 -0.1 -1.5 -0.9  0.   0.5 -0.6  5.2 -0.2 -0.5 -0.3 -2.  -0.5 -0.2  3.5 -0.3 -0.8 -0.4 -0.3 -0.2  2.   4.  -0.7 -0.4 -0.1 -1.2 -0.5 -0.3  2.  -0.4  2.5 -0.5 -0.3  2.3  1.1 -0.4 -0.1 -0.   7.3 -0.5  2.  11.4 -0.3 -0.  -0.2 -0.8 -1.   2.2 -0.1  0.3 -0.6  4.3 -1.7 -0.2 -0.9  0.1 -0.6 -0.1 -0.1 -0.3  0.8 -0.3 -0.2 -1.2 -0.  -0.1  2.9 -0.2 -0.7  0.1  0.2 -0.2  0.  -0.3 -0.7  0.5 -1.   3.7  1.3 -0.  -0.3 -0.2  0.   0.8 -0.4 -0.3 -0.1  0.2  0.3 -0.4 -0.2 -0.3  1.4  6.3 -0.5  0.4 -0.1 -0.2  1.5 -1.1 -0.7 -2.2 -0.6 -0.1 -0.4 -0.6 -1.1  8.8 -0.5 -0.9 -0.3 -0.2 -0.2  8.   0.5 -0.6 -0.3 -0.8  1.   4.9 -0.3 -2.1  3.3 -0.7 -0.2 -0.8  3.9 -0.4  0.1 -0.3 -0.3 -0.  -0.3 -0.4  0.6  0.2 -0.3  0.4 -0.2 -0.1 -0.5  1.1 -0.1 -0.2  4.2 -0.3  0.  -0.1 -0.2 -0.5 -1.1 -0.2  0.8  2.5 -0.3 -0.  -0.7 -0.1  1.6  0.2  0.7  0.6 -0.1 -0.4 -0.3  0.1 -0.2  2.  -0.7  1.  -0.2 -0.6 -0.8  0.4 -0.3 -0.8 -0.6 -0.1  3.9 -0.6 -0.3 -1.  -0.1 -0.1 -1.  -0.2  9.2 -0.   2.6  1.8 -0.3 -0.3 -0.3 -0.1 -0.1 -0.6 -0.3  0.8 -0.1  1.   6.2 -0.1  1.1  5.2 -0.9 -0.3 -0.2 -0.4  3.  -0.3 -0.   0.1 -0.6 -0.2 -0.3 -0.8  4.8  4.8 -0.3  0.2 -0.3  3.6 -0.3 -1.   0.2  4.  -0.6 -0.2  0.7  3.1  1.7  9.5 -0.2  4.1 -0.2 -0.1  1.6 -1.9 -0.2  0.3 -0.9 -0.4 -0.2 -0.4  1.6 -0.1 -0.5 11.4]
ty_50sample [[8 9 6 7 2 4 5 1 3 0]
 [4 1 8 6 2 0 5 3 7 9]
 [3 1 6 0 2 5 7 8 4 4]
 [6 3 1 8 7 2 0 9 4 5]
 [3 0 6 1 1 9 8 4 7 2]
 [6 5 8 2 1 4 0 7 3 9]
 [7 2 9 3 6 5 1 8 0 4]
 [9 4 8 2 6 0 3 7 1 5]
 [3 7 9 2 8 1 0 4 6 5]
 [8 4 7 5 2 3 1 6 9 0]]
tt_50sample [[8 9 6 7 2 4 5 1 3 0]
 [4 1 8 6 2 0 5 3 7 9]
 [3 1 0 6 2 5 7 8 9 4]
 [6 1 3 8 7 2 0 9 4 5]
 [3 0 6 1 5 9 8 4 7 2]
 [6 5 8 2 1 4 0 7 3 9]
 [7 2 9 3 6 5 1 8 0 4]
 [9 4 8 2 6 0 3 7 1 5]
 [3 7 9 2 8 1 0 4 6 5]
 [8 4 7 5 2 3 1 6 9 0]]
vm  [-1.5 -0.4 -2.8 -3.  -0.6 -0.1 -0.2 -0.3 -0.6 -0.2 -2.   0.1 -0.8 -0.4 -0.1  0.8 -0.3 -0.1 -0.8 -0.  -0.6 -0.3  0.6 -0.2 -1.6  0.8 -0.3 -0.3  0.7 -0.5  2.  -0.4  0.8 -3.3 -0.8 -0.3  1.7 -1.  -3.1 -0.5 -0.  -1.7 -0.7  0.1 -0.6 -0.6 -1.  -0.4 -1.9  1.1 -0.4 -0.2 -1.1  1.9 -1.7  1.1 -1.  -1.5  1.5 -0.3  9.1 -0.2 -0.4 -0.9 -0.2 -0.1  0.   1.4 -0.2 -0.2 -0.4 -0.8 -0.4 -0.4 -5.1  0.5  1.9  0.6 -0.1 -0.1 -3.  -0.2 -0.5  0.5  2.7 -1.4 -0.6 -0.1  0.6 -0.6 -1.  -0.1 -0.3  1.3 -0.7 -0.2 -0.2 -1.5 -0.6 -0.7  1.9 -1.8  2.8 -0.2 -0.3 -0.4 -3.1  2.  -0.7  0.  -0.1 -0.3 -0.  -0.5  0.9  3.1 -0.2  0.  -0.3 -0.2 -0.3 -0.7 -0.2 -0.4 -0.3 -0.2  1.3  0.7 -0.3  7.4 -0.6 -0.7 -0.7  0.1 12.4  5.6 -0.2 -0.3  0.4 -0.8  0.2 -0.7 -0.1 -0.2 -0.5 -0.1  0.5 -0.3  3.1 -0.3  1.  -0.1 -0.8 -0.4 -0.3 -0.1 -0.4 -0.1 -1.4 -0.3 -0.2  1.1 -0.2 -0.4 -0.6 -0.4 -0.1  2.3 -0.4 -0.6 -0.6 -0.4 -0.7 -0.3  0.1 -0.4 -1.8 -1.3  7.8 -0.3  0.1 -0.1  1.8 -1.6 -0.8  0.5 -1.4 -0.  -0.6  1.8 -0.4 -0.4 -0.2 -1.6 -2.6  2.1 -1.8 -0.1 -0.2 -0.6  0.4 -0.2 -0.  -0.3 -0.  -2.9  0.2 -0.6  5.6 -0.  -0.6  0.3 -0.7  7.2  0.9  0.1 -0.  -0.7  0.1 -0.2 -0.8 -0.4 -0.5 -1.1  1.1  2.2 -1.5  0.2  0.1 -0.6 -0.4  4.2 -0.4  3.4 -0.8  5.9 -0.1 -2.8 -0.3  1.2  0.1  0.6 -0.1 -0.3 10.3  2.3  1.3 -0.4 -0.5 -0.   7.5 -0.2 -2.3 -0.   3.2 -1.7]
vy_50sample [[1 6 4 3 8 0 0 2 7 7]
 [8 8 5 0 6 2 3 1 4 9]
 [8 5 2 1 6 0 9 4 7 3]
 [7 8 6 5 2 0 1 4 9 3]
 [5 9 3 8 1 7 6 6 2 4]
 [2 6 7 3 1 5 8 0 4 9]
 [6 0 8 1 7 4 3 5 9 2]
 [0 9 4 3 3 2 5 5 1 6]
 [5 6 3 3 9 7 1 1 2 4]
 [1 3 8 0 2 9 6 7 7 5]]
vt_50sample [[1 6 4 3 8 0 9 5 2 7]
 [7 8 5 0 6 2 3 1 4 9]
 [8 5 2 1 6 0 9 4 7 3]
 [7 6 8 5 2 0 1 4 9 3]
 [5 9 8 3 1 0 7 6 2 4]
 [2 6 7 1 3 5 8 0 4 9]
 [6 0 8 1 7 4 3 5 9 2]
 [0 9 4 7 3 8 2 5 6 1]
 [5 6 3 9 0 8 1 7 2 4]
 [3 1 8 0 2 9 6 4 7 5]]
Epoch 18810: Training cost= 0.3342, Training acc= 0.8123, Validation cost= 0.2928, Validation acc= 0.8126
Epoch 18820: Training cost= 0.3345, Training acc= 0.8124, Validation cost= 0.3377, Validation acc= 0.8126
Epoch 18830: Training cost= 0.3259, Training acc= 0.8124, Validation cost= 0.3581, Validation acc= 0.8127
Epoch 18840: Training cost= 0.2620, Training acc= 0.8124, Validation cost= 0.3165, Validation acc= 0.8127
Epoch 18850: Training cost= 0.3372, Training acc= 0.8124, Validation cost= 0.3417, Validation acc= 0.8127
Epoch 18860: Training cost= 0.3819, Training acc= 0.8125, Validation cost= 0.3678, Validation acc= 0.8128
Epoch 18870: Training cost= 0.3917, Training acc= 0.8125, Validation cost= 0.3752, Validation acc= 0.8128
Epoch 18880: Training cost= 0.3140, Training acc= 0.8125, Validation cost= 0.3294, Validation acc= 0.8128
Epoch 18890: Training cost= 0.2952, Training acc= 0.8126, Validation cost= 0.3074, Validation acc= 0.8129
Epoch 18900: Training cost= 0.2938, Training acc= 0.8126, Validation cost= 0.3013, Validation acc= 0.8129
tm  [-1.4 -0.9  7.5  4.8 -1.4  1.4 -0.1 -0.3  0.7  2.   7.8 -0.2 -0.4 -0.3  8.   2.2 -0.6 -0.2 -0.6 -0.3 -0.8  0.5 -0.5 -0.4 -1.   0.1 -0.1 -0.6 -0.4 -0.6  3.3 -0.5  3.6 12.5 -0.1 -0.4  0.8 -0.2 -1.5 -0.   1.   0.5 -1.1 -0.8 -0.3 -0.2  1.9 -0.3 -1.7 -0.5 -0.3 -0.6 -0.4  1.6 -1.2 -0.9 -0.8 -0.5  3.9 -0.8  6.1 -0.5  1.2  0.4  3.4 -1.2 -0.2  1.3 -0.1 -0.7 -0.1 -0.6 -0.2 -0.5 -3.7 -1.  -0.  -0.1 -0.1 -0.6  9.1  1.1 -0.4  1.  -0.   0.1 -0.9 -0.3 -0.3 -0.5 -0.2 -0.6 -0.4 -1.1 -0.6 -0.  -0.3 -1.3 -0.1 -0.2 -0.7  7.5  2.4 -0.3 -0.5 -0.6 -2.   2.5  1.7 -0.6  0.8 -0.4 -0.1 -1.   4.1  0.6 -0.6  0.5  1.1 -0.4 -0.2  0.9 -0.  -0.4 -0.6  8.9 -0.2  1.3  1.1 -0.6 -0.4 -0.6  0.5  0.8 -0.7 14.6 -0.1 -0.   0.  -0.9 -0.5  0.7 -0.7 -0.4  0.5 -0.1 -0.2 -0.  -2.3 -0.3 -0.7 -0.6 -2.1 -0.1 -0.1  0.9 -0.6 -0.5 -1.2  0.6  1.2  0.6  0.  -0.3 -0.  -0.3 -0.7  2.8 -0.2  0.2 -0.3 -0.6 -0.2  0.8 -0.3  5.9 -1.6 -0.6  4.7 -0.6  1.3 -0.6  0.3 -0.9 -0.8 -0.3 -0.8 -0.6 -0.5  2.3 -0.6 -0.5 -0.8 -0.6 -1.5 -0.  -0.8 -0.5 -0.4 -0.2  0.8 -0.1 -0.4 -0.5 -0.2 -1.2 -0.2 -0.6 -0.2 -0.2 -0.3  1.7 -0.4  5.8 -0.5 -0.3  3.4 -0.6 -0.7  0.9 -0.8 -0.2 -0.1 -1.2  3.2 -0.4 -0.8  2.5 -0.6 -0.5 -0.   2.1 -0.3 -0.1 -1.  -1.3  0.5 -1.8 -0.1  7.5  0.   3.7 -0.8 -0.2 -1.7 -0.8 -0.6 -0.6 -0.5  0.4 -2.3 -0.1 -1.1 -0.1 -0.4  5.3]
ty_50sample [[1 7 6 2 9 0 4 3 5 8]
 [9 6 5 1 8 0 7 2 4 3]
 [2 0 9 6 5 8 1 3 4 7]
 [8 6 7 5 0 2 4 3 9 9]
 [8 5 3 1 9 2 0 7 6 4]
 [8 2 6 1 9 3 5 7 4 0]
 [8 6 3 2 5 4 7 1 0 9]
 [1 5 4 8 9 2 6 0 3 7]
 [9 1 0 2 5 6 8 7 4 3]
 [7 9 1 8 8 5 0 3 4 2]]
tt_50sample [[1 7 6 2 9 0 4 3 5 8]
 [9 6 5 1 8 0 7 2 4 3]
 [2 0 9 6 5 8 1 3 7 4]
 [8 6 7 5 0 2 4 1 3 9]
 [8 5 3 1 9 2 0 7 6 4]
 [8 2 6 1 9 3 5 7 4 0]
 [8 6 3 2 5 4 7 1 0 9]
 [1 5 4 8 9 2 6 3 7 0]
 [9 1 0 2 5 6 8 7 4 3]
 [7 9 1 8 6 5 0 3 4 2]]
vm  [ 1.5 -0.6 -0.7  4.6 -1.3 -0.3 -0.2 -0.2  0.4 -0.3  4.8 -0.2 -0.5 -0.6 -1.7  2.5 -0.5 -0.7 -0.4 -2.  -0.3  0.1 -0.1 -0.1 -0.8  0.5 -0.2  0.4  1.4  2.6  6.1 -0.8 -0.1  8.6 -0.2 -0.4  0.  -0.4  9.9 -0.5 -0.4  2.5 -0.1  1.9  0.3 -0.3 12.   0.5  3.3 -0.2 -0.5 -0.1  2.7 -2.4 -1.1  3.1 -0.1 -0.9  0.2 -2.4 -2.9 -0.6  0.1  0.6  2.3 -0.1  0.2 -0.   1.4 -0.1 -0.2 -1.4 -0.2 -0.5  7.9  0.2 -1.   0.2 -0.2 -0.2 21.  -0.2 -0.6  1.2 -1.4  3.6  4.8 -0.4 -0.  -0.3  0.3 -0.2 -0.5 -1.   0.1  0.1 -0.1  0.8 -0.3 -0.3  0.5  5.3 -1.4  0.2 -0.4 -0.2  3.2  6.1  1.7 -2.5 -0.4 -0.1 -0.  -0.4 -0.2  5.9  1.1 -0.2 -0.3 -0.3 -0.1  9.2  0.6 -0.  -0.1 -1.8 -0.  11.1  0.8 -2.8  3.6 -0.8 -0.1 -0.9 -0.4  8.9  0.3 -0.2 -0.4 -0.6 -0.1 -0.1  0.9  0.2 -0.3 -0.   1.6 -0.1 -0.5 -0.2 -0.4 -0.2  1.9 -0.   0.3 -0.1 -0.2 -0.7 -0.7 -0.2  1.1 -0.2  0.3 -0.3 -0.1 -0.2 -0.3  0.4 -0.4 -0.2 -0.3 -0.4 -0.5 -0.3 -0.3  1.9 -0.9  3.9 -1.3 -0.2 -0.8 -0.3 -0.4 -1.5 -1.   0.2  5.9 -0.2 -0.1 -0.8 -0.6 -0.4 -1.4 -0.7 14.  -0.3  5.3 -0.1 -0.2 -0.4 -0.2 -0.  -0.3 -0.7 -0.6  8.  -0.1 -0.1 -1.3 -0.4 -0.1  4.8 -0.6 -0.5  0.3 -0.1 -0.6 -0.2  0.8 -0.5 -0.8 -0.5 -0.6 -0.5  2.8  1.3 -1.  -0.3  0.7  4.4 -0.8 -1.3 -0.2 -0.8 -1.   2.6  0.3  5.   1.8 14.9 -0.2  6.9 -0.1 -0.1 -4.6 -3.8  0.1 -0.2 -0.8 -0.2 -5.   0.4  7.   0.4  0.4 12.5]
vy_50sample [[9 4 7 6 5 2 0 0 8 1]
 [9 5 6 4 1 8 3 7 2 0]
 [6 3 1 5 7 2 8 4 9 0]
 [2 7 6 8 9 0 3 5 5 1]
 [1 7 8 5 9 4 6 0 3 2]
 [9 7 6 0 8 8 5 4 4 2]
 [1 7 7 0 5 6 2 8 9 3]
 [6 7 3 3 8 9 4 5 2 0]
 [8 0 2 3 7 1 9 5 4 6]
 [5 5 8 8 4 9 0 2 3 1]]
vt_50sample [[9 4 7 6 5 2 0 3 8 1]
 [9 5 6 4 1 8 3 7 2 0]
 [6 3 1 5 7 2 8 4 9 0]
 [2 7 6 8 9 0 3 5 4 1]
 [1 7 8 5 9 4 6 0 3 2]
 [9 7 6 0 8 1 5 3 4 2]
 [1 7 4 0 5 6 2 8 9 3]
 [6 7 1 3 8 9 4 5 2 0]
 [8 0 2 3 7 9 1 5 4 6]
 [5 6 7 8 4 9 0 2 3 1]]
Epoch 18910: Training cost= 0.2888, Training acc= 0.8126, Validation cost= 0.2586, Validation acc= 0.8129
Epoch 18920: Training cost= 0.3543, Training acc= 0.8127, Validation cost= 0.3143, Validation acc= 0.8130
Epoch 18930: Training cost= 0.3130, Training acc= 0.8127, Validation cost= 0.3139, Validation acc= 0.8130
Epoch 18940: Training cost= 0.3329, Training acc= 0.8127, Validation cost= 0.3255, Validation acc= 0.8130
Epoch 18950: Training cost= 0.2826, Training acc= 0.8128, Validation cost= 0.3193, Validation acc= 0.8130
Epoch 18960: Training cost= 0.3981, Training acc= 0.8128, Validation cost= 0.3022, Validation acc= 0.8131
Epoch 18970: Training cost= 0.3315, Training acc= 0.8128, Validation cost= 0.2758, Validation acc= 0.8131
Epoch 18980: Training cost= 0.3359, Training acc= 0.8129, Validation cost= 0.3191, Validation acc= 0.8131
Epoch 18990: Training cost= 0.3294, Training acc= 0.8129, Validation cost= 0.3503, Validation acc= 0.8132
Epoch 19000: Training cost= 0.3163, Training acc= 0.8129, Validation cost= 0.3355, Validation acc= 0.8132
tm  [-1.9 -0.1 -2.  -1.1 -0.8  0.4  0.2 -0.3 -0.1 -1.   7.7 -0.6 -0.2  0.4 -0.7  3.2  0.6  0.3 -0.2  2.  -0.9 -0.6 -1.5 -0.3 -1.1  1.  -0.7 -0.4 -0.9 -2.   3.5 -0.9  0.   0.5 -0.3  0.   2.7  1.8 -1.1 -0.6 -0.4 -1.7 -0.7  0.5 -0.9  0.4 -1.9 -0.5 -1.3 -3.5 -0.3 -0.2 -0.3  6.3 -0.9  1.1 -0.4 -0.5  3.1 -1.8  8.8 -0.2 -0.2  0.2 -0.8 -0.5 -0.2  1.7 -0.6 -0.2 -0.1 -0.2  1.6  0.5 -3.7 -0.8  0.7 -0.7  0.3 -0.3  4.8 -0.5 -0.4 -0.8  1.6 -1.5 -0.7 -0.3 -0.  -0.5 -0.2 -0.3  1.  -0.3 -0.8 -0.2 -0.8 -2.1 -0.3 -0.4  3.8 -3.   3.8 -0.5 -0.3 -0.1 -1.8  3.6  0.4 -0.4 -0.6 -0.4 -0.2  0.2  2.4  3.2 -0.7 -0.3  0.9 -0.  -0.1  1.3 -0.1 -0.  -0.7 -0.9  1.  -1.4  2.9  7.7 -0.6 -0.7  0.3  0.2  9.6 10.3 -0.6 -0.2  1.5 -0.4 -0.5 -0.1 -0.9 -0.1 -0.  -0.1 -0.3  1.5  2.8 -0.3  1.1 -0.4 -2.5 -0.2 -0.1 -0.1 -0.1 -0.1 -0.1  1.5 -0.3  0.6 -0.2 -0.1 -0.7 -0.3  1.6  4.1  0.6 -0.1 -0.8 -0.3 -0.5 -0.1 -0.6 -0.8 -0.4 -0.5  3.9 -0.6 -0.2 -0.2 -0.3 -1.4  0.8 -0.3 -1.6  2.4 -0.6  6.6 -0.3 -0.1 -0.1 -0.8 -2.5 -0.2 -0.5  0.2 -0.3 -0.1  0.   1.2 -0.3 -0.9  1.2 -2.2 -0.6  1.1 -1.9 -0.3 -0.4  0.4 -1.3  7.4 -0.2 -0.5  1.3 -0.7 -0.6  1.5 -0.1 -0.4  0.1 -0.8 -0.1 -0.7 -0.3  3.4  0.6 -0.1 -0.4 -0.5 -0.4 -1.2  3.   5.3 -0.  -1.2  0.6 -0.6 -0.2 -0.3 -0.7  0.4 -0.7  2.1 -0.5  0.2 -1.2 -0.7 -1.4 -0.4 -0.8 -0.2  1.6 -1.8]
ty_50sample [[1 3 6 6 4 0 5 9 8 7]
 [4 8 9 1 5 3 2 7 0 6]
 [5 4 2 0 8 9 7 6 1 3]
 [4 1 7 8 0 6 3 5 9 9]
 [2 1 3 7 0 5 8 4 9 6]
 [6 6 5 0 1 8 2 3 7 4]
 [8 8 3 4 2 7 1 5 6 0]
 [4 3 6 5 9 1 0 2 2 8]
 [2 3 6 5 1 0 0 9 4 4]
 [1 4 5 9 0 8 3 2 7 6]]
tt_50sample [[1 3 6 2 4 5 0 9 8 7]
 [4 8 9 1 5 3 2 7 0 6]
 [5 4 2 8 0 9 7 6 1 3]
 [4 1 7 8 6 0 3 5 9 2]
 [2 1 3 7 0 5 8 4 9 6]
 [6 9 5 0 1 8 2 3 7 4]
 [8 9 3 4 2 7 1 5 6 0]
 [4 6 3 5 9 1 0 7 2 8]
 [2 3 6 5 1 9 7 0 8 4]
 [1 4 5 9 8 0 3 2 7 6]]
vm  [ 2.6  0.2 10.5 15.  -1.7 -0.3 -0.1 -0.3 -0.3 -0.3  3.7  0.3 -1.  -0.2  2.2  2.2 -0.2  0.8 -0.4 -1.5 -0.6  0.3 -0.5 -0.1 -0.6  1.1 -0.  -0.2  0.  -0.  -0.3 -0.7 -0.2  9.5 -0.1 -0.2 -0.1  3.4 11.5 -0.5 -0.3 -1.9 -0.3 -0.1 -0.5 -0.4  9.9 -0.4  3.5 -1.1 -0.6 -0.4  3.2 -1.2 -1.2 -0.   0.2 -0.3 -0.6  3.1 -2.4 -0.6  2.8  0.4  2.4 -1.  -0.1 -0.  -0.6 -0.7  0.6 -0.5 -0.2 -0.4  0.4 -0.5 -1.  -0.3 -0.8 -0.5 13.5 -0.1 -0.2 -0.1 -2.1 -2.4  1.9 -0.  -0.1 -0.5  0.8 -0.3  0.5  1.   0.1 -0.3 -0.4 -0.1 -0.2  0.2  0.7  3.  -1.2 -0.4 -0.4  0.8  1.3 -0.3  1.3 -1.7  1.8 -0.5 -0.  -0.6  0.2  0.8 -0.3 -0.1  0.9 -0.5 -0.5  4.7 -0.4 -0.4 -0.2  2.8 -0.1  7.  -0.6 -0.3  2.8  0.   1.4  1.3 -4.4 -0.2 -0.1 -0.1  0.7 -0.3 -0.3 -0.7 -0.5 -0.4  0.3  0.1 -0.1 -0.3 -2.7 -0.2 -1.4  0.9  4.2 -0.   0.8 -0.3 -0.3 -0.4 -0.2 -0.  -0.1 -1.   0.8 -0.2  2.2 -0.1 -0.6  0.6 -0.2  2.1 -0.8 -0.9 -0.2  0.1 -0.4  7.2 -0.8  1.8 -1.7 -0.1  2.1 -0.4 -0.3 -0.9 -1.3 -0.3  5.9 -0.6 -0.3  0.4 -0.3 -0.1 -0.9 -0.6 13.   2.2  3.5 -0.1 -0.4 -0.3 -0.  -0.1 -0.5 -0.1 -1.   7.6 -0.2 -0.3  5.3 -0.2 -0.1  2.4 -0.8 -0.7 -0.2  0.1  2.2 -0.2 -0.9  1.8 -0.8 -0.4  1.2 -0.4 -1.1  1.1 -0.7 -0.  -0.9  3.2 -0.6 -0.8 -0.2  3.7 -1.2 -2.   0.3  2.9 -0.  17.9 -0.2  8.3 -0.4 -0.1 -2.6 -3.7 -0.7 -0.3 -0.8 -0.3 -3.4 -0.3  8.9  0.5  1.1  2.9]
vy_50sample [[7 9 3 2 8 0 6 4 5 5]
 [5 0 0 9 4 1 2 7 6 3]
 [9 2 0 4 5 6 8 8 7 3]
 [6 9 0 0 3 2 5 8 1 4]
 [1 3 0 2 5 9 8 7 4 6]
 [1 8 9 0 6 3 4 2 7 5]
 [1 7 0 5 4 8 9 6 2 3]
 [0 0 6 9 5 1 7 2 3 4]
 [7 0 4 1 8 9 2 6 5 3]
 [8 5 6 7 9 1 0 0 2 3]]
vt_50sample [[7 9 3 2 8 0 6 4 5 1]
 [5 8 0 9 1 4 2 7 6 3]
 [9 2 0 4 5 6 8 1 7 3]
 [6 0 9 7 3 2 5 8 1 4]
 [1 3 0 2 5 9 8 7 4 6]
 [1 8 9 6 0 3 4 2 7 5]
 [1 7 0 5 4 8 9 6 2 3]
 [8 0 6 9 5 1 7 2 3 4]
 [7 0 4 1 8 9 2 6 5 3]
 [8 5 6 7 9 1 4 0 2 3]]
Epoch 19010: Training cost= 0.3374, Training acc= 0.8130, Validation cost= 0.3377, Validation acc= 0.8132
Epoch 19020: Training cost= 0.3329, Training acc= 0.8130, Validation cost= 0.3730, Validation acc= 0.8133
Epoch 19030: Training cost= 0.3503, Training acc= 0.8130, Validation cost= 0.3588, Validation acc= 0.8133
Epoch 19040: Training cost= 0.2991, Training acc= 0.8130, Validation cost= 0.3541, Validation acc= 0.8133
Epoch 19050: Training cost= 0.2977, Training acc= 0.8131, Validation cost= 0.3407, Validation acc= 0.8133
Epoch 19060: Training cost= 0.2806, Training acc= 0.8131, Validation cost= 0.3093, Validation acc= 0.8134
Epoch 19070: Training cost= 0.2856, Training acc= 0.8131, Validation cost= 0.3126, Validation acc= 0.8134
Epoch 19080: Training cost= 0.3172, Training acc= 0.8132, Validation cost= 0.3175, Validation acc= 0.8134
Epoch 19090: Training cost= 0.2931, Training acc= 0.8132, Validation cost= 0.3209, Validation acc= 0.8135
Epoch 19100: Training cost= 0.3415, Training acc= 0.8132, Validation cost= 0.2785, Validation acc= 0.8135
tm  [-1.5 -0.7 -1.  16.2 -0.4  0.3 -0.1  0.8 -0.1  0.9  3.9 -0.7 -0.2 -0.6 -4.2 -0.  -0.3 -0.1 -0.1 -2.  -0.6 -0.2  2.   0.1 -1.2  3.1 -0.5 -0.3 -1.  -1.7 -0.5 -0.3  0.4 -2.7  0.1  0.1  3.  -0.   5.5 -0.3 -0.1  3.  -0.4 -1.  -0.3 -0.3 11.3 -0.6 -1.7  5.3 -0.2 -0.2  0.8 -1.1 -0.2  6.4 -0.8  2.2  1.   2.9  1.  -0.3 -0.2 -0.1 -0.  -0.4 -0.   0.7 -0.5 -0.5 -0.1  1.9 -0.  -0.5  6.2 -0.2  2.3  0.2  0.3 -0.2 13.  -0.1 -0.7 -0.3  1.6  3.4 -1.5 -0.1 -0.2 -0.4 -0.4 -0.7 -0.4 -0.3 -0.1 -0.2  0.5  1.4 -0.2 -0.1 -0.5 -0.7  1.9 -0.3 -0.3 -0.4  1.  -0.6  1.6 -2.6 -0.6 -0.1  0.2  0.2  3.3 -1.1 -0.1 -1.   0.1  0.1 -0.2  9.1 -0.3 -0.3 -0.1 -4.7 -0.4  6.  -0.2 -2.5 -0.8 -0.4 -0.6  0.4 12.1  6.8 -0.  -0.2 -0.2 -0.9 -0.4 -0.7 -0.8 -0.2 -0.1 -0.3  1.   0.1  4.6 -0.3 -1.3 -0.1 -1.3 -0.1 -0.1 -0.2 -0.1 -0.1 -0.7 -0.3  0.4  0.4 -0.2 -0.2 -0.4 -0.5 -0.6  0.2 -0.7  1.7  0.9 -0.5 -0.4  0.6 -0.  -1.2 -1.4  2.4 -0.7 -0.4 -0.8 -0.2  1.4 -0.8 -0.4 -0.1 -0.6  2.2 -0.1  5.3 -0.3 -0.6 -1.1 -0.6  1.3  1.2  2.8  0.2 -0.2 -0.1 -0.1 -0.2 -0.1 -0.1  0.2  5.7 -0.2 -0.2  0.9 -0.2 -0.2 -0.8 -0.1  5.6 -0.5 -0.2  3.7 -0.4 -0.7  0.3 -0.  -0.4  0.7 -1.1  3.3 -0.7 -0.4  3.9 -0.3 -1.1 -0.1 -0.6 -0.2  1.1  1.3  1.9  1.3  2.8 -0.2 13.1 -0.3  6.2 -0.6 -0.2 -2.7 -3.1 -0.  -0.3 -0.7 -0.2 -3.3 -0.2  4.4  0.2 -0.8 12.7]
ty_50sample [[9 1 0 6 2 5 8 4 3 7]
 [1 3 0 4 5 9 6 6 2 7]
 [4 7 0 8 2 3 1 9 5 6]
 [0 2 5 3 1 7 9 6 8 4]
 [3 5 8 1 9 2 6 7 4 0]
 [6 7 2 9 4 3 5 8 1 0]
 [8 7 3 4 5 6 0 1 2 9]
 [2 1 1 7 6 0 3 5 9 4]
 [9 7 6 3 8 4 1 0 5 2]
 [2 1 1 0 0 7 8 3 4 9]]
tt_50sample [[9 1 0 6 2 8 5 4 3 7]
 [1 3 0 4 9 5 6 8 2 7]
 [4 7 2 0 8 3 1 9 5 6]
 [0 2 5 3 1 7 9 8 6 4]
 [3 5 1 8 9 2 6 7 4 0]
 [6 7 2 9 4 3 5 8 1 0]
 [8 7 3 4 5 6 0 1 2 9]
 [8 2 1 7 6 0 3 5 9 4]
 [9 7 6 3 8 4 1 0 5 2]
 [2 5 6 1 0 7 8 3 9 4]]
vm  [-1.6  1.   6.7 15.4 -1.2  0.6 -0.2 -0.2 -0.6 -1.1  3.5 -0.3 -0.3 -0.1 -0.7  3.4 -0.4 -0.6 -0.1 -1.  -0.4 -0.5 -0.4 -0.2 -1.2  2.2 -0.3 -0.2 -0.1 -0.7 -0.8 -0.6 -0.3  4.5 -1.1 -0.1  2.8 -0.4  3.3 -0.3 -0.4 -1.3 -0.1 -1.5 -0.5 -0.   5.5 -0.2 -1.3 -1.1 -0.5 -0.1  2.3 -0.9 -0.9  1.9 -0.   3.6 -0.6  4.1  1.7 -0.3 -0.1 -0.  -0.1  1.1 -0.4 -0.5 -0.2 -0.1 -0.2 -0.6 -0.  -0.3  4.5 -0.3  0.1 -0.2 -0.   0.2 10.1 -0.4 -0.4  0.1  1.9 -0.7 -1.6 -0.1  0.2  0.9  0.1  0.7  0.1 -0.1 -0.3  0.2 -0.  -0.3 -0.  -0.2  4.9  0.1  1.9 -0.  -0.4  1.4  1.1 -0.6  0.9 -1.7 -0.5 -0.1  0.2  0.5 -0.4  5.5 -0.4 -1.  -0.3 -0.3 -0.   6.9  1.3  0.2 -0.3 -0.7  2.4  5.9 -0.5 -0.4 -0.1 -0.8 -0.3 -0.6  3.5  7.9 -0.1  0.1  1.7 -0.5 -0.1 -0.3 -0.2 -0.2 -0.  -0.1 -0.2  0.4 -0.6 -0.1 -1.2 -0.2 -1.   0.2 -0.1  0.3 -0.2 -0.3 -0.7 -0.3 -0.2  3.  -0.1  0.2 -0.7 -0.2  2.3  2.1 -0.1  1.4 -0.5 -0.6 -0.  -0.1 -0.3  2.  -0.6  2.  -0.1 -0.2 -0.3 -0.3 -0.3 -1.3 -0.4 -0.2 -0.7 -0.4 -0.1  2.3 -0.1 -0.2 -0.8 -0.5 -0.   2.4  3.3  1.5 -0.2 -0.2 -0.3 -0.2 -0.4 -0.8  1.3  2.9 -0.1  0.1  1.6 -0.1 -0.3  3.3 -1.   6.4 -0.8 -0.4  6.  -0.2 -0.   0.6 -0.8 -0.4 -0.2 -0.7  1.4  2.2 -0.6  2.2  2.1 -0.4 -0.  -1.3 -0.2  1.2  0.2 -1.6 -0.2  3.5  0.7 10.  -0.2  4.6 -0.2 -0.1 -1.8 -2.1  0.   1.1 -0.8 -0.9 -2.6 -0.6  2.3 -0.1  2.2  3.3]
vy_50sample [[9 1 6 3 7 2 5 8 0 4]
 [2 6 6 9 8 1 0 3 5 7]
 [9 2 3 6 7 1 8 0 4 4]
 [2 4 6 1 0 7 5 9 3 8]
 [8 2 2 3 6 4 9 1 0 5]
 [5 9 2 2 0 1 4 6 8 3]
 [0 8 1 1 6 4 9 7 2 5]
 [0 4 1 8 2 5 7 9 6 3]
 [0 3 2 5 6 4 7 9 1 8]
 [2 6 9 9 1 5 5 7 0 4]]
vt_50sample [[9 1 6 3 7 2 5 8 0 4]
 [2 6 9 4 8 1 0 3 5 7]
 [9 2 3 6 7 1 8 0 4 5]
 [2 4 6 1 0 7 5 9 3 8]
 [8 7 2 3 4 6 9 0 1 5]
 [5 9 7 2 0 1 4 6 8 3]
 [0 8 1 3 6 4 9 7 2 5]
 [4 0 1 8 2 5 7 9 6 3]
 [0 3 2 5 6 4 7 9 1 8]
 [2 6 9 1 3 8 5 7 0 4]]
Epoch 19110: Training cost= 0.3211, Training acc= 0.8133, Validation cost= 0.3246, Validation acc= 0.8135
Epoch 19120: Training cost= 0.2799, Training acc= 0.8133, Validation cost= 0.3314, Validation acc= 0.8136
Epoch 19130: Training cost= 0.3218, Training acc= 0.8133, Validation cost= 0.3154, Validation acc= 0.8136
Epoch 19140: Training cost= 0.3517, Training acc= 0.8134, Validation cost= 0.2914, Validation acc= 0.8136
Epoch 19150: Training cost= 0.3657, Training acc= 0.8134, Validation cost= 0.3123, Validation acc= 0.8137
Epoch 19160: Training cost= 0.3008, Training acc= 0.8134, Validation cost= 0.3935, Validation acc= 0.8137
Epoch 19170: Training cost= 0.2893, Training acc= 0.8135, Validation cost= 0.3172, Validation acc= 0.8137
Epoch 19180: Training cost= 0.3273, Training acc= 0.8135, Validation cost= 0.3485, Validation acc= 0.8138
Epoch 19190: Training cost= 0.3243, Training acc= 0.8135, Validation cost= 0.2938, Validation acc= 0.8138
Epoch 19200: Training cost= 0.3581, Training acc= 0.8136, Validation cost= 0.3380, Validation acc= 0.8138
tm  [-0.4 -0.5 -1.9 -0.5 -0.4 -0.4 -0.1 -0.4 -0.2 -0.2 -2.2 -0.2 -0.5 -0.  -0.8  2.3 -0.2 -0.3 -0.5 -0.8 -0.6 -0.   0.1 -0.5 -0.8 -0.3 -0.5 -0.5  1.6 -0.4 -0.2 -0.2  2.  -3.7 -0.7 -0.8 -0.1 -1.2 -3.  -0.6  0.3 -2.7 -1.3 -0.6 -0.3 -0.7  0.3 -0.2 -0.1  1.9 -0.6 -0.3 -1.1  0.4 -1.3  2.1 -0.4 -1.9  3.1  2.   1.4 -0.5 -0.5 -0.3 -0.3 -0.7 -0.2  2.7  0.4 -0.5  0.4 -1.2 -0.2  0.  -4.   0.4 -0.6 -0.3 -0.3 -0.3 -2.3  0.  -0.4  0.4 -0.5 -3.1  1.  -0.1 -0.2 -0.9 -0.7 -0.1 -0.   0.2 -0.4 -0.1 -0.5 -1.5 -0.8 -0.9  1.3 -2.1 -0.3  0.2 -0.1 -0.4 -1.9 -0.3 -0.7 -0.7  1.  -0.3 -0.1 -0.9  1.5  4.3 -0.5  1.6 -0.   0.1 -0.1  0.1 -0.5 -0.3 -0.3 -0.9  0.4  2.6 -0.1  4.7  2.1 -0.4  0.2 -0.4 14.4  7.   0.1 -0.2  0.  -0.6 -0.  -0.6 -0.2 -0.2 -0.2  0.3 -0.4 -0.2 -0.2 -0.2  0.   0.5  1.6 -0.6 -0.4  0.2 -0.4 -0.4 -1.9 -0.3 -0.4  2.7 -0.1 -0.4 -0.4 -0.4  0.1  3.4 -0.3 -0.  -0.8 -0.7 -0.2 -0.1 -0.2  2.2 -1.8 -0.6  7.3 -0.3  3.3 -0.5  0.9 -0.7 -0.9  2.   0.7 -0.2 -0.7  1.2 -0.2 -0.3 -0.7 -1.4  1.1 -0.3 -1.1 -0.3 -0.  -0.4  0.  -0.4 -0.  -0.3 -0.6 -1.9 -0.3 -0.3  9.8  0.  -0.6  2.9 -1.4  1.3  0.2 -0.5  2.6 -0.7 -0.2  0.5 -0.9 -0.4 -0.1 -0.9  0.7  2.8 -1.3  0.8 -0.2  2.9  1.8  1.9 -0.2  5.4 -1.   4.3  0.8 -1.8 -0.   9.6 -0.1  5.  -0.3 -0.2  8.2 -0.6  0.8 -0.7 -1.   0.5  5.6 -0.4 -2.3  0.   3.2 -0.9]
ty_50sample [[6 3 3 4 9 9 2 0 7 5]
 [8 5 7 0 3 2 1 4 6 9]
 [6 5 9 4 1 3 8 7 0 2]
 [6 9 2 5 8 3 4 1 0 7]
 [7 5 8 9 6 0 2 1 4 3]
 [4 2 6 3 0 7 9 5 8 1]
 [5 2 0 4 7 3 3 6 8 1]
 [7 3 5 6 4 8 0 9 1 2]
 [1 5 2 4 3 7 7 6 9 9]
 [0 8 6 7 9 3 4 2 1 5]]
tt_50sample [[6 3 8 4 9 1 2 0 7 5]
 [8 5 7 0 3 2 1 4 6 9]
 [6 5 9 4 1 3 7 8 0 2]
 [6 9 2 5 8 3 4 1 7 0]
 [7 5 8 9 6 0 2 1 4 3]
 [4 2 3 6 0 7 5 9 8 1]
 [5 2 0 4 7 3 9 6 8 1]
 [7 3 5 6 4 8 0 9 1 2]
 [1 5 2 4 3 7 8 6 0 9]
 [0 8 6 7 3 9 4 2 5 1]]
vm  [-0.8 -1.1 -2.7  3.7 -0.5 -0.1 -0.  -0.5  1.9 -0.2 -1.2 -0.9  0.1  0.5 -2.6  5.2 -0.4 -0.4 -0.8 -1.7 -0.5 -0.1  2.2 -0.5 -0.5 -0.2 -0.  -0.3  3.1 -1.3 -0.2 -0.3 -0.6 -4.3 -0.3 -0.6 -0.4  3.2 11.2 -0.5  1.5 -0.2 -1.1  4.9 -0.2 -0.4  6.9 -0.8 -0.4  8.  -0.5 -0.3 -0.5 -0.5 -1.4  5.1 -0.3 -1.4  6.4  2.1 -0.6 -0.5 -0.5  0.1 -0.8 -0.4 -0.   2.2  0.1 -0.4 -0.2 -1.7 -0.4 -0.2 -0.   0.3 -0.7 -0.2  0.1 -0.3 -0.2  0.4 -0.7  0.9 -0.3  0.2 -0.1 -0.1 -0.2 -0.5  1.3 -0.5 -0.5 -1.7 -0.1 -0.3 -0.4 -0.6  0.5 -0.5 -0.  -0.9 -0.4  0.6 -0.3 -0.8 -0.2 -0.4 -0.5 -1.8 -0.3 -0.  -0.2 -0.8  1.1  8.8 -0.4 -0.1 -0.3 -0.3 -0.2  6.2  0.8 -0.5  0.1 -2.9 -0.   4.   5.6 -1.4 -0.1 -0.8 -0.4 -0.5  3.5 -4.4  0.7 -0.4 -0.3 -0.1 -0.4 -0.3 -0.6 -0.  -0.3 -0.  -0.  -0.3  3.7 -0.1  0.5 -0.2  2.3 -0.1 -0.1  0.5  0.1 -0.7  1.8  0.8  0.4 -1.3 -0.1 -0.1 -0.5 -0.5 -0.1  3.2 -0.2  0.2 -0.2 -0.4 -0.3 -0.5  0.5 -0.5 -0.1  1.7 -1.7 -0.6 -0.3 -0.7 -0.6 -1.1 -0.7 -0.2  1.2 -0.1 -0.4  4.  -0.1 -0.8 -1.5 -0.7  4.2 -1.5  1.2 -0.5 -0.2 -0.5 -0.3 -0.3 -0.3 -0.9 -0.1  0.5 -0.3 -0.1  6.7  0.5 -0.2  6.7 -1.   1.5 -0.8 -0.5 -1.2 -0.2 -0.1 -0.1 -0.9 -0.4 -0.1 -0.8 -0.5  4.  -0.4  2.4 -0.7  3.9 -1.1 -0.9  0.7  4.3 -1.   6.6  0.8  0.4  1.5 11.9 -0.1  5.8 -0.3 -0.2  2.3 -2.5  0.3 -0.4 -1.2 -0.3 -0.3 -0.2  7.9 -0.3 -0.2  7.5]
vy_50sample [[8 9 4 2 1 3 5 6 7 0]
 [7 5 3 9 4 1 2 6 0 8]
 [7 5 2 8 3 4 1 9 0 6]
 [7 4 6 1 1 9 3 3 0 2]
 [1 7 2 5 5 0 6 6 4 3]
 [8 3 4 1 2 5 9 0 6 7]
 [6 6 3 0 0 5 7 8 1 2]
 [0 8 7 7 3 2 1 6 4 4]
 [4 2 9 6 7 1 8 0 3 5]
 [2 9 3 8 4 6 7 0 5 1]]
vt_50sample [[8 9 4 2 1 3 5 6 7 0]
 [7 5 3 9 4 1 2 6 0 8]
 [7 5 2 8 3 4 1 9 0 6]
 [7 4 6 5 1 9 3 8 0 2]
 [1 7 2 5 8 0 6 9 4 3]
 [3 8 4 1 2 5 9 0 6 7]
 [6 4 3 9 0 5 7 8 1 2]
 [0 8 7 9 3 2 1 6 4 5]
 [4 2 9 6 7 1 8 0 3 5]
 [2 9 3 8 4 6 7 0 5 1]]
Epoch 19210: Training cost= 0.3255, Training acc= 0.8136, Validation cost= 0.3177, Validation acc= 0.8139
Epoch 19220: Training cost= 0.3410, Training acc= 0.8136, Validation cost= 0.3296, Validation acc= 0.8139
Epoch 19230: Training cost= 0.4402, Training acc= 0.8136, Validation cost= 0.3204, Validation acc= 0.8139
Epoch 19240: Training cost= 0.3106, Training acc= 0.8137, Validation cost= 0.2727, Validation acc= 0.8139
Epoch 19250: Training cost= 0.3003, Training acc= 0.8137, Validation cost= 0.3066, Validation acc= 0.8140
Epoch 19260: Training cost= 0.3262, Training acc= 0.8137, Validation cost= 0.3413, Validation acc= 0.8140
Epoch 19270: Training cost= 0.3923, Training acc= 0.8138, Validation cost= 0.3627, Validation acc= 0.8140
Epoch 19280: Training cost= 0.2747, Training acc= 0.8138, Validation cost= 0.3449, Validation acc= 0.8141
Epoch 19290: Training cost= 0.3452, Training acc= 0.8138, Validation cost= 0.3406, Validation acc= 0.8141
Epoch 19300: Training cost= 0.2870, Training acc= 0.8139, Validation cost= 0.3195, Validation acc= 0.8141
tm  [-1.3 -0.   2.6 -1.5 -0.9  0.9 -0.5 -0.4 -0.3 -0.3  4.6  1.6 -0.6 -0.3  8.2  5.6 -0.1 -0.6 -0.5  2.1 -0.5  0.4 -1.  -0.7 -1.2 -0.2 -0.5 -0.9  3.6 -1.1  0.  -0.6  2.4  2.7 -1.  -0.3  0.4 -0.3 -4.3 -0.4  0.7 -3.2 -1.  -0.9 -0.6 -0.3 -2.7 -0.7 -1.9 -2.6 -0.3 -0.4 -0.5  8.9 -1.7 -0.9 -0.5 -0.7  2.8  1.2 10.2 -0.4  0.3 -0.4 -0.3 -0.5 -0.1  0.8 -0.4 -0.4 -0.2 -1.4 -0.3 -0.1 -7.  -0.1  0.  -0.3 -0.7 -0.2 -2.1 -0.3 -0.1 -0.5  0.6 -2.9 -1.1 -0.4  0.5 -0.6 -1.   0.3  0.3  0.5 -0.6 -0.2 -0.8 -2.  -0.6  0.   2.4 -1.7  2.6  0.3 -0.3  0.  -3.   0.6  1.9  1.5 -0.3 -0.5 -0.3 -0.7  0.4  8.4  1.2 -0.   0.7 -0.1 -0.2 -1.1 -0.4 -0.4 -0.2  8.4  2.  -2.2 -0.  11.6 -0.7 -0.6  0.   0.4  6.  10.9 -0.3 -0.1 -0.1 -0.9 -0.6  0.5 -0.8 -0.4 -0.2 -0.3 -0.4 -0.3 -0.9 -0.2  1.3 -0.2 -1.4 -0.5 -0.3 -0.4 -0.4 -0.2 -1.1 -0.5 -0.9  0.3  0.3 -0.3 -0.4  0.2  0.7  2.8 -0.5 -0.5 -0.9 -0.7 -0.3  0.2 -0.2  2.4 -1.8 -1.5 10.2 -0.6  0.9  2.   0.5 -1.4 -0.6 -0.2 -1.7 -0.7 -0.8  3.5 -0.3 -0.1 -0.  -1.1 -3.4  0.  -1.8  0.  -0.3 -0.3  0.6 -0.1 -0.  -0.3 -0.3 -3.2 -0.3 -0.8  4.7 -0.4  0.3  3.  -0.7  5.2 -0.3  0.5  3.5 -0.5 -0.4  0.2 -0.5  0.2  0.6 -0.8 -0.6  3.  -0.8  0.4  1.1 -0.1 -0.1  3.6 -0.2  2.6 -1.5 -0.4 -0.5 -3.1 -0.5 -0.1 -0.3 -0.1 -0.4 -0.2  7.8  5.9 -0.6 -0.5 -0.2 -0.6  4.9 -0.4 -3.  -0.2  2.7 -3.6]
ty_50sample [[3 1 6 2 7 4 8 5 0 0]
 [2 7 4 0 8 5 1 3 6 9]
 [5 7 8 6 9 2 1 4 0 3]
 [2 4 1 3 8 9 6 5 5 0]
 [1 1 4 6 6 7 9 3 5 8]
 [6 4 5 8 3 0 0 1 9 7]
 [1 3 9 6 4 2 8 0 5 7]
 [5 9 8 4 0 3 7 6 2 1]
 [2 5 3 6 7 4 8 1 9 0]
 [2 4 1 3 0 9 9 5 8 6]]
tt_50sample [[3 1 6 2 7 4 8 5 9 0]
 [2 7 4 0 8 5 1 3 6 9]
 [5 7 8 6 9 2 1 4 0 3]
 [2 4 1 3 8 9 6 5 0 7]
 [1 0 2 4 6 7 9 3 5 8]
 [6 4 5 8 2 3 0 1 9 7]
 [1 3 9 6 4 2 8 0 5 7]
 [5 9 8 4 0 3 7 6 1 2]
 [2 5 3 6 7 4 8 1 9 0]
 [2 4 1 3 0 7 9 5 8 6]]
vm  [-0.3 -0.  -2.3  0.8 -0.9 -0.3 -0.2 -0.3 -0.5 -0.9 -0.3 -0.  -0.7 -0.3 -1.8 -0.3 -0.2 -0.3 -0.6 -0.5 -0.5 -0.1 -0.6 -0.3 -1.5  0.8 -0.4 -0.2 -0.2 -0.8  2.9 -0.2  1.3 -1.9 -0.7 -0.2  2.3 -1.2 -1.4 -0.7 -0.   0.7  0.9 -0.6 -0.  -0.2  2.2 -0.2  1.  -1.5 -0.5 -0.3  0.2 -0.7 -1.1  3.4  0.3  2.5 -0.3 -0.3 -0.3 -0.6 -0.1 -0.3  0.3 -0.8 -0.3  0.7  0.  -0.3 -0.2 -0.4 -0.1 -0.2 -2.  -0.3 -0.8 -0.1 -0.7 -0.4  4.2 -0.1 -0.4  0.2 -1.   0.9  1.6 -0.1  1.2 -0.2 -0.3 -0.  -0.2  1.2 -0.4 -0.2 -0.  -0.9 -0.4 -0.1  3.1 -2.5 -0.8 -0.3 -0.1 -0.4 -1.7  1.7 -0.2 -0.7 -0.5 -0.5 -0.  -0.6  0.2  1.9 -0.3 -0.3 -0.1  0.3 -0.7  1.1 -0.2 -0.1 -0.6 -1.9  1.8  5.3  1.1  3.7  2.3 -0.9 -0.1  0.4 13.3 10.1 -0.1 -0.1 -0.1 -0.9  1.5 -0.5  0.4 -0.1 -0.3 -0.  -0.4 -0.3  7.7 -0.4 -0.2  0.1  1.7  0.8 -0.2 -0.2 -0.3  0.3 -1.6 -0.8 -0.5  1.1 -0.1 -0.3 -0.  -0.4 -0.  -0.1 -0.4 -0.  -0.1  0.2 -0.4 -0.2 -0.1 -2.  -1.8 -0.3  4.   0.3 -1.7 -0.3 -0.1 -1.5 -0.6 -0.2  1.4  1.  -0.3  2.4 -0.7 -0.3 -0.5 -1.6  3.7 -0.2 -0.5 -0.3 -0.2 -0.2 -0.5 -0.4 -0.5 -0.4 -0.6 -1.2  0.1 -0.2 -2.1  0.2 -0.5  1.3 -0.5 -0.  -0.3 -0.   2.1 -0.6 -0.1 -0.1 -0.9 -0.5  0.5 -0.8  0.3  0.1 -1.5 -0.3 -0.3  3.3 -0.3  0.6 -0.4 -1.3 -0.1  5.   0.3 -0.9  0.6 -1.3 -0.1 -0.7 -0.4 -0.1 -0.4 -1.3 -0.3 -0.3 -0.6 -0.3 -1.3 -0.5 -1.  -0.4  4.9 -0.5]
vy_50sample [[6 5 5 4 9 0 8 1 2 7]
 [3 0 7 9 2 6 5 1 8 4]
 [6 5 7 0 8 8 2 3 4 9]
 [7 5 6 3 4 8 1 0 2 9]
 [9 7 4 1 8 0 2 3 6 5]
 [7 6 8 0 4 2 5 3 9 1]
 [0 2 2 4 7 1 8 6 5 3]
 [6 9 3 1 7 0 8 4 2 5]
 [8 0 1 1 5 6 3 4 9 2]
 [9 4 8 3 0 1 7 2 5 6]]
vt_50sample [[6 3 5 4 9 8 0 1 2 7]
 [0 3 7 9 2 6 5 1 8 4]
 [6 5 7 0 1 8 2 3 4 9]
 [7 5 6 3 4 8 1 0 2 9]
 [9 7 4 1 8 0 2 3 6 5]
 [7 6 8 0 4 2 5 3 9 1]
 [0 9 2 4 7 1 8 6 5 3]
 [6 9 3 1 7 0 8 4 2 5]
 [8 0 1 7 5 6 3 4 9 2]
 [9 4 8 3 0 1 7 2 5 6]]
Epoch 19310: Training cost= 0.3933, Training acc= 0.8139, Validation cost= 0.3330, Validation acc= 0.8141
Epoch 19320: Training cost= 0.3086, Training acc= 0.8139, Validation cost= 0.2954, Validation acc= 0.8142
Epoch 19330: Training cost= 0.3131, Training acc= 0.8139, Validation cost= 0.3047, Validation acc= 0.8142
Epoch 19340: Training cost= 0.2980, Training acc= 0.8140, Validation cost= 0.2516, Validation acc= 0.8142
Epoch 19350: Training cost= 0.3176, Training acc= 0.8140, Validation cost= 0.2732, Validation acc= 0.8143
Epoch 19360: Training cost= 0.2987, Training acc= 0.8141, Validation cost= 0.2458, Validation acc= 0.8143
Epoch 19370: Training cost= 0.2940, Training acc= 0.8141, Validation cost= 0.3095, Validation acc= 0.8143
Epoch 19380: Training cost= 0.3091, Training acc= 0.8141, Validation cost= 0.3852, Validation acc= 0.8144
Epoch 19390: Training cost= 0.2769, Training acc= 0.8141, Validation cost= 0.3408, Validation acc= 0.8144
Epoch 19400: Training cost= 0.3328, Training acc= 0.8142, Validation cost= 0.3350, Validation acc= 0.8144
tm  [-0.5  0.6 -1.6 -0.5 -1.3 -0.1  0.1 -0.6 -0.7 -0.7 -0.5 -0.2 -0.8 -0.3 -0.6 -0.1  0.4 -0.4 -0.5 -0.4 -0.6 -0.4  3.   0.1 -1.4  2.8  0.3  0.5 -0.3  1.6  3.2 -0.4 -0.4 -0.3 -0.3  0.7  2.9 -0.3  1.2 -0.4 -0.2  6.9  3.3  1.7 -0.4  0.6 -0.1  0.2  1.8  6.3 -0.5 -0.2  1.9 -0.6 -0.6  1.9 -0.1  1.8 -0.7 -0.6  0.2 -0.4  0.1  0.7 -0.1  0.1 -0.1 -0.3 -0.1  0.4 -0.2 -0.3  0.  -0.  -1.5 -0.2 -0.1 -0.3  0.2  0.6  3.6 -0.2  0.7 -0.1 -0.6  8.6  2.7 -0.1 -0.1  0.2 -0.  -0.3 -0.4 -0.  -0.4 -0.1  0.2 -1.2 -0.2  0.   2.   3.4 -0.1 -0.4 -0.2  1.7 -0.7  2.9 -0.3 -0.7 -0.8 -0.1 -0.1 -0.4 -0.3  1.4 -0.7 -0.8 -0.3 -0.  -0.2  2.4 -0.2  0.5 -0.1 -0.4  0.9  5.7  0.9 -1.   2.  -0.5 -0.2 -0.2  5.5  4.  -0.2 -0.2  1.3 -0.3  1.5 -0.7  0.8 -0.1 -0.2  0.1 -0.1 -0.2  5.8  0.2  0.6 -0.1  1.6  1.4 -0.2  0.2 -0.6  0.6 -0.5 -0.5  1.1  1.3 -0.  -0.1  0.8 -0.1 -0.3 -0.3  0.8 -0.2  0.3  0.4 -0.1 -0.2 -0.3 -1.  -0.4  0.9  1.1  0.1 -1.5 -0.1 -0.6 -1.5 -0.5 -0.4  0.3 -0.1 -0.1 -0.2  0.  -0.4 -0.3 -0.9  2.7  1.5  0.5  0.5  0.3 -0.3 -0.2 -0.  -0.3 -0.6  0.8 -0.2 -0.2 -0.  -1.9  0.4 -0.2  2.  -0.7  3.4 -0.1 -0.3 -0.2 -0.5 -0.2 -0.2 -0.9 -0.2 -0.3 -0.5  4.   1.  -1.3 -0.2 -0.3  0.6 -0.5 -0.8 -0.2 -1.2  1.7  5.1  0.5  0.3  2.3 -1.3 -0.3 -0.6  0.4 -0.1 -0.1 -1.4 -0.4  0.3 -1.  -0.4 -1.  -0.1  0.7 -0.1  1.4  7.2]
ty_50sample [[5 4 6 9 8 1 1 2 2 3]
 [8 5 6 1 3 9 4 7 2 0]
 [9 0 5 6 3 2 8 7 7 4]
 [5 3 1 4 6 7 2 9 0 8]
 [9 1 3 7 6 2 0 4 8 5]
 [1 6 8 0 7 4 3 9 2 5]
 [1 4 2 3 6 0 8 8 7 5]
 [7 0 5 1 4 2 3 9 8 6]
 [1 1 8 6 2 0 4 5 7 3]
 [2 1 5 0 8 4 6 7 3 9]]
tt_50sample [[5 4 6 9 8 1 0 2 7 3]
 [8 5 6 1 3 9 4 7 2 0]
 [9 0 5 6 3 2 8 7 1 4]
 [5 3 1 4 6 2 7 9 0 8]
 [9 1 3 7 6 2 0 4 8 5]
 [1 6 8 0 7 4 3 9 2 5]
 [1 4 2 3 6 0 8 9 7 5]
 [7 0 5 1 4 2 3 8 9 6]
 [9 1 8 6 2 0 4 5 7 3]
 [2 1 5 0 8 4 6 7 3 9]]
vm  [-0.3 -0.6 -1.6  2.8 -0.9 -0.2 -0.4 -0.2 -0.2 -0.4  3.9 -0.9 -0.  -0.3 -1.9  0.1 -0.2 -0.7 -0.5 -1.3 -0.7 -0.2  2.2 -0.2 -0.9  2.8 -0.4  1.5 -0.6 -0.3  3.8 -0.2 -0.1 -0.4  0.2 -0.1  2.3 -0.5  0.3 -0.5 -0.3  5.8  0.3 -0.2 -0.1 -0.1  5.3 -0.3  2.1  4.5 -0.4 -0.1  0.5 -0.5 -0.2  4.2 -0.2  1.4  1.5 -0.8 -0.7 -0.3 -0.2  2.4  1.  -0.1 -0.2  0.4  0.5  0.  -0.3 -0.  -0.4 -0.2  0.1 -0.  -0.5  0.2 -0.1  0.   9.7 -0.1 -0.4  0.6 -0.7  6.4  1.5  0.1 -0.2 -0.1 -0.3 -0.5 -0.7 -0.8 -0.2 -0.3  0.9 -1.  -0.3 -0.3  0.8  2.3 -0.6 -0.2 -0.3 -0.2 -0.4  3.2  1.1 -1.3 -0.8  0.2 -0.2 -0.4  1.7 -0.1 -0.5 -0.5 -0.5 -0.1 -0.5  5.5  0.8  0.5 -0.3 -2.1 -0.4  5.3  2.5 -1.6  3.1 -0.9 -0.5 -0.6 10.7 10.  -0.2 -0.2  0.2 -0.5 -0.2 -0.5 -0.3  0.  -0.3 -0.2  0.6 -0.2  5.5 -0.2 -0.1 -0.1  1.1  0.1 -0.  -0.  -0.1  0.3 -1.3 -0.7  1.6  2.  -0.3 -0.1 -0.1 -0.5 -0.3 -0.  -0.1 -0.1  0.6 -0.  -0.2 -0.1 -0.2 -1.2 -1.   1.   1.7  0.1 -1.3 -0.3 -0.7 -1.3 -0.2 -0.5  2.   0.  -0.3  0.9 -0.  -0.3 -1.  -0.6  5.7 -0.4  0.9 -0.4  0.1 -0.1 -0.4 -0.2 -0.3 -0.5 -0.1 -0.4  0.3  0.4 -1.9 -0.  -0.3  1.3 -0.9  0.9 -0.4 -0.2  1.7 -0.6 -0.2 -0.4 -0.7 -0.5 -0.3 -0.7  5.6 -0.2 -0.7  0.6 -0.3  3.4 -0.3 -0.8 -0.1 -1.3  2.3  4.9  1.9  1.6  2.2  2.2 -0.1  0.8 -0.   0.1 -1.7 -1.9 -0.   0.1 -1.2 -0.3 -2.6 -0.2  0.1  0.1 -0.2 10. ]
vy_50sample [[6 6 5 4 0 2 1 8 7 3]
 [8 6 7 1 2 0 5 9 3 4]
 [6 9 2 1 4 3 5 7 0 8]
 [5 1 3 8 2 9 9 7 4 6]
 [4 0 9 7 3 5 6 2 1 8]
 [5 1 0 9 2 7 3 6 4 8]
 [9 8 8 7 0 6 2 4 1 5]
 [0 2 7 5 6 4 8 9 3 3]
 [8 6 7 2 1 4 3 0 9 5]
 [4 8 2 1 5 5 7 3 9 0]]
vt_50sample [[6 9 5 4 0 2 1 8 7 3]
 [6 8 7 1 2 0 5 3 9 4]
 [6 9 2 1 4 3 5 7 0 8]
 [5 1 3 8 2 9 0 7 4 6]
 [4 0 9 7 3 5 2 6 1 8]
 [5 1 0 9 2 7 3 6 4 8]
 [9 3 8 7 0 6 2 4 1 5]
 [0 2 7 5 6 4 8 9 3 1]
 [8 6 7 2 1 4 3 0 9 5]
 [4 8 2 1 5 6 7 3 0 9]]
Epoch 19410: Training cost= 0.2600, Training acc= 0.8142, Validation cost= 0.3280, Validation acc= 0.8145
Epoch 19420: Training cost= 0.3322, Training acc= 0.8142, Validation cost= 0.3348, Validation acc= 0.8145
Epoch 19430: Training cost= 0.2884, Training acc= 0.8143, Validation cost= 0.2918, Validation acc= 0.8145
Epoch 19440: Training cost= 0.3485, Training acc= 0.8143, Validation cost= 0.4049, Validation acc= 0.8145
Epoch 19450: Training cost= 0.3414, Training acc= 0.8143, Validation cost= 0.3339, Validation acc= 0.8146
Epoch 19460: Training cost= 0.3388, Training acc= 0.8143, Validation cost= 0.4496, Validation acc= 0.8146
Epoch 19470: Training cost= 0.2886, Training acc= 0.8144, Validation cost= 0.3464, Validation acc= 0.8146
Epoch 19480: Training cost= 0.3512, Training acc= 0.8144, Validation cost= 0.3471, Validation acc= 0.8146
Epoch 19490: Training cost= 0.3080, Training acc= 0.8144, Validation cost= 0.2845, Validation acc= 0.8147
Epoch 19500: Training cost= 0.3171, Training acc= 0.8145, Validation cost= 0.3410, Validation acc= 0.8147
tm  [-1.2  2.2  2.1  1.3 -1.5  0.1 -0.5 -0.2 -1.2 -1.6  6.5  0.1 -0.1  0.   1.9  2.6 -0.1 -0.3  1.3 -0.2 -0.8 -0.4 -0.6  1.1 -1.9  4.5 -0.3 -0.3 -1.2 -0.8  1.2 -0.1 -0.2  4.4 -0.6  2.3  5.1  2.6  1.9 -0.6 -0.1 -2.4 -0.1  1.3 -0.8  0.3 -0.2 -0.4 -1.4 -2.  -0.6 -0.   1.   4.7 -0.7  0.  -0.7 -0.3 -1.1 -0.1  6.7  0.1 -0.4 -0.1  0.1  0.5 -0.3 -0.5 -0.4 -0.2  0.2  3.   0.2 -0.2 -0.9 -0.3  2.3 -0.7  0.5 -0.1  3.6 -0.3 -0.1 -0.1  3.  -1.9 -0.8 -0.1  0.3 -0.3 -0.3  0.2  0.1  2.1 -0.3  0.6 -0.4 -0.8 -0.5 -0.2  6.  -0.8  3.  -0.1  0.3 -0.1 -1.2  2.   1.8 -0.4 -0.8 -0.3  0.1  2.7 -0.1 -0.3  0.2 -1.6 -0.5 -0.1  0.1  1.8 -0.2 -0.1 -0.4  2.3  1.2 -0.8 -0.8  5.  -0.9 -0.4 -0.1 -0.4 -0.9  3.1 -0.1 -0.1  2.9 -0.8 -0.4 -1.  -0.7 -0.  -0.1 -0.3 -0.3  0.1 -0.9 -0.1 -0.4 -0.3 -1.3 -0.4 -0.3 -0.2 -0.  -0.3  1.7 -0.2 -0.7 -0.5 -0.2  0.3 -0.6 -0.5  1.8  1.  -0.3  0.3 -0.2 -0.4 -0.2  0.1 -0.4  2.5 -0.7 -0.2  0.6 -0.6 -0.  -0.3 -0.1 -1.8 -0.4 -0.2 -1.3 -0.4 -0.1  2.8 -0.  -0.1 -0.2 -1.2 -1.5  3.8  0.3  2.7 -0.4  0.9 -0.2 -0.5 -0.5 -0.9  1.2 -1.2 -0.  -0.4  2.8 -0.2 -0.  -0.8 -0.7  7.3 -0.3 -0.5 -0.1 -0.3 -0.  -0.  -0.6  0.3  0.3 -0.8 -1.  -0.3  0.2  1.9  1.9 -1.2 -0.8 -0.5 -0.6  2.2  2.8 -0.2 -0.3 -0.2 -0.2  5.3 -0.2  2.9 -0.6 -0.2 -0.2 -0.5 -0.2  0.4 -0.4 -0.7 -0.9 -0.3  1.2 -0.5  2.3 -0.9]
ty_50sample [[1 3 2 0 0 4 6 6 8 5]
 [9 1 7 2 6 4 5 5 3 8]
 [5 5 1 0 2 7 3 8 9 9]
 [1 9 0 0 4 2 5 8 6 7]
 [3 0 1 4 8 2 7 6 9 5]
 [6 7 8 2 0 1 9 5 4 3]
 [6 8 2 5 0 1 3 7 9 4]
 [0 1 2 6 9 4 5 3 8 7]
 [5 3 2 4 0 6 6 7 8 1]
 [9 6 0 7 5 4 4 1 3 2]]
tt_50sample [[1 3 2 0 7 4 9 6 8 5]
 [9 1 7 2 6 4 5 0 3 8]
 [6 5 1 0 2 7 3 8 4 9]
 [1 9 3 0 4 2 5 8 6 7]
 [3 0 1 4 8 2 7 6 9 5]
 [6 7 8 2 0 1 9 5 4 3]
 [8 6 2 5 0 1 3 7 9 4]
 [0 1 2 6 9 4 5 3 8 7]
 [5 3 2 4 0 9 6 7 8 1]
 [9 6 0 7 8 5 4 1 3 2]]
vm  [-0.7 -0.1 -1.9 -0.6 -1.3  0.2 -0.1 -0.6 -0.7 -0.9 -0.6 -0.2 -0.  -0.2 -0.3 -0.6 -0.5 -0.5 -0.7 -0.5 -0.8 -0.6 -0.2  0.3 -0.8  3.5  0.5 -0.3 -1.1 -0.6  3.7 -0.2 -0.4 -0.2 -0.2  0.8  3.3 -0.3  3.5 -0.7  1.4 -2.6 -0.4  4.5 -0.1  1.6 -0.1  1.2  2.1 -0.6 -0.5 -0.6  1.2 -0.5 -0.1  1.5 -0.1 -2.6  0.2 -0.8 -0.1  0.6  0.   2.5 -0.7  1.7 -0.1 -0.6 -0.2  2.5 -0.3  1.8 -0.3  0.7 -0.4 -0.3 -0.5 -0.2  1.2 -0.1  2.3  0.6  0.3 -0.2 -0.6 -2.6  4.3 -0.1  0.4 -0.2 -0.1 -0.1  0.2 -0.3 -0.1  0.4 -0.5 -1.2  1.   0.3  2.3 -1.2  0.4 -0.1 -0.1  0.9 -0.3  3.5 -0.3 -1.4 -1.3 -0.2 -0.3 -0.3  2.9 -0.6 -0.6 -0.2 -0.4 -0.7  0.1  5.8 -0.3  0.1 -0.4 -0.5  0.7  4.9  1.   2.4  1.7 -0.8 -0.5 -0.6  3.4 -0.2 -0.1 -0.2  1.5 -0.1  2.1 -1.  -0.   0.1 -0.2 -0.1 -0.3 -0.2 -0.8 -0.   1.6 -0.3  1.4 -0.  -0.2 -0.  -0.5  0.5  0.3 -0.4 -0.4 -0.1 -0.4 -0.1 -0.3  0.1  1.3  2.1  1.6 -0.2 -0.4 -0.3 -0.   0.  -0.1  2.8 -0.2  0.8  0.5 -0.5  2.2  0.4 -0.8 -1.4  0.  -0.4  0.4 -0.4 -0.2  1.6 -0.2 -0.2 -0.4 -0.9  3.4 -0.3  1.6 -0.3 -0.1 -0.2 -0.4 -0.1 -0.5 -1.   1.7 -0.5 -0.4 -0.   7.1  0.5 -0.2  0.3 -1.4  2.1 -0.6 -1.  -1.1 -0.5 -0.5 -0.4 -1.   1.  -0.1 -0.7 -0.6 -0.1 -1.1 -0.2  0.3  2.7 -0.6 -1.5 -0.3  4.7  4.   5.7 -0.1  2.6  3.8 14.8 -0.3  7.  -0.2 -0.1  0.4 -1.  -0.5 -0.  -1.2 -0.6 -0.9 -0.5  2.5 -0.3  5.1  0.2]
vy_50sample [[4 3 9 9 8 6 1 7 2 5]
 [3 1 6 7 8 8 4 0 5 2]
 [9 8 4 7 3 1 6 5 2 0]
 [3 4 6 1 0 8 7 5 9 2]
 [5 3 1 4 2 8 0 9 7 6]
 [3 9 8 0 5 7 6 1 4 2]
 [7 3 2 0 8 1 1 9 5 4]
 [2 6 1 0 3 4 8 5 9 7]
 [5 0 1 4 7 9 2 8 6 3]
 [5 4 8 9 0 3 1 6 7 2]]
vt_50sample [[4 3 9 0 8 6 1 7 2 5]
 [3 1 6 7 8 9 4 0 5 2]
 [9 8 4 7 3 1 6 5 2 0]
 [3 4 6 1 0 8 7 5 9 2]
 [5 3 1 4 2 8 0 9 7 6]
 [3 9 8 0 5 7 6 1 4 2]
 [7 3 2 8 0 1 6 5 9 4]
 [2 6 1 0 3 4 8 5 9 7]
 [5 0 1 4 7 9 2 8 6 3]
 [5 4 8 9 0 3 1 6 7 2]]
Epoch 19510: Training cost= 0.3054, Training acc= 0.8145, Validation cost= 0.2991, Validation acc= 0.8147
Epoch 19520: Training cost= 0.3050, Training acc= 0.8145, Validation cost= 0.2914, Validation acc= 0.8148
Epoch 19530: Training cost= 0.2897, Training acc= 0.8146, Validation cost= 0.3231, Validation acc= 0.8148
Epoch 19540: Training cost= 0.2745, Training acc= 0.8146, Validation cost= 0.3357, Validation acc= 0.8148
Epoch 19550: Training cost= 0.3157, Training acc= 0.8146, Validation cost= 0.3482, Validation acc= 0.8149
Epoch 19560: Training cost= 0.3013, Training acc= 0.8146, Validation cost= 0.2807, Validation acc= 0.8149
Epoch 19570: Training cost= 0.3123, Training acc= 0.8147, Validation cost= 0.3077, Validation acc= 0.8149
Epoch 19580: Training cost= 0.3011, Training acc= 0.8147, Validation cost= 0.3073, Validation acc= 0.8150
Epoch 19590: Training cost= 0.3137, Training acc= 0.8147, Validation cost= 0.3430, Validation acc= 0.8150
Epoch 19600: Training cost= 0.3729, Training acc= 0.8148, Validation cost= 0.2870, Validation acc= 0.8150
tm  [-0.9 -1.  -1.2 -4.3 -1.9  0.5 -0.2 -0.3  1.  -0.5 -0.   0.9 -0.7 -0.6  8.2 -0.6 -0.2 -0.7 -0.4  5.  -0.6 -0.3 -0.2 -0.3 -1.2  3.  -0.3 -0.1 -0.4 -1.1  5.4 -0.6 -0.5  5.6 -0.5 -0.3  0.2 -0.2 -1.2 -0.6  0.4  2.9 -0.3  5.  -0.4 -0.3 -3.   1.  -0.4 -0.5 -0.8 -0.2 -0.   3.3 -0.7 -0.8 -0.7 -0.6  4.5 -2.   8.3 -0.4  0.8  1.2  0.1  0.2 -0.1  0.4  1.   0.1 -0.3 -0.5 -0.1 -0.1 -5.6  0.1 -0.1  0.3  1.  -0.2 -1.3  0.2  1.3  0.6 -0.1  4.   2.  -0.1 -0.1 -0.5 -0.2 -0.4 -0.2 -1.  -0.6  0.1  0.4 -2.5 -0.5 -0.4  1.2  3.8  1.1  0.2 -0.2  0.4 -2.6  6.   0.2  4.2 -0.5  0.5 -0.4 -0.9  3.4  1.3 -0.3  2.2 -0.  -0.1 -0.2 -1.8 -0.2  0.3 -0.1  9.5  1.2 -0.2  5.9  4.4 -0.5 -0.8 -0.4 -0.5 -1.6  3.3 -0.  -0.3 -0.1 -0.5  2.3 -0.5  1.9 -0.  -0.2 -0.1 -0.  -0.2  1.6 -0.3  3.9 -0.2 -1.2  1.9 -0.2  0.4 -0.2  0.3  2.1 -0.3  1.1 -0.6  0.6 -0.3 -0.1 -0.5 -0.3  1.5  0.1 -0.8 -0.3  0.9 -0.4 -0.2 -0.1  0.2 -0.3 -0.7  4.3  0.4 -0.7 -0.6 -0.5 -1.6 -0.1 -0.2 -1.1 -0.3 -0.4  2.8 -0.2 -0.6 -0.1 -1.1 -2.5 -1.  -1.3 -0.9  0.2 -0.2 -0.2 -0.3 -0.1 -0.9 -0.  -3.1 -0.1 -0.3 -1.9 -0.2 -0.5  1.  -0.8  5.5 -0.4 -0.3 -1.4 -0.6  0.1 -0.1 -1.2 -0.  -0.4 -0.9  0.1 -0.5 -1.7 -0.2  0.9  1.7 -0.7  0.3 -0.3 -1.   0.7  4.2  0.9 -2.3  2.8 -3.3 -0.1 -1.6 -0.4 -0.2  5.7  3.5 -0.2 -0.3 -0.9 -0.2  3.5 -0.3 -1.1 -0.2  3.7 -1.1]
ty_50sample [[4 1 5 7 0 3 6 8 2 9]
 [9 5 8 8 1 7 4 3 6 2]
 [7 3 6 1 4 8 8 0 5 9]
 [2 7 3 4 9 5 8 6 1 0]
 [2 9 1 5 8 3 4 7 6 0]
 [4 6 1 0 7 8 5 3 9 2]
 [5 2 6 1 3 7 9 4 0 0]
 [1 3 6 9 8 8 2 5 0 7]
 [5 2 8 1 0 9 7 4 6 3]
 [3 1 7 6 2 9 4 5 8 0]]
tt_50sample [[4 1 5 7 0 3 6 8 2 9]
 [9 5 0 8 1 7 4 3 6 2]
 [7 3 6 1 4 8 2 0 5 9]
 [2 7 3 4 9 5 8 6 1 0]
 [2 9 1 5 8 3 4 7 6 0]
 [4 6 1 0 7 8 5 3 9 2]
 [5 2 6 1 3 7 9 4 8 0]
 [1 3 9 6 4 8 2 5 0 7]
 [5 2 8 1 0 9 7 4 6 3]
 [3 1 7 6 2 9 4 5 8 0]]
vm  [ 0.8 -0.9 -1.8 -3.7 -1.2 -0.5 -0.1 -0.4 -0.2  0.4 -2.   0.3 -0.9 -0.1  3.3 -0.8 -0.4 -0.3 -0.   0.5 -0.3 -0.   2.9 -0.4 -1.  -0.4 -0.3 -0.2 -0.5 -0.1  4.1 -0.2  0.6 -0.8  0.  -0.6 -0.1 -0.9 -2.5 -0.7 -0.2  7.2 -0.1  1.8 -0.4 -0.3 -1.4  0.2  2.6  7.7 -0.7 -0.1 -0.6  0.7 -0.7 -0.2 -0.3  0.6  3.  -1.   0.3 -0.7 -0.5  0.1 -0.  -0.7  0.   0.9  2.2 -0.3 -0.2 -0.5 -0.1 -0.4 -5.3  0.8 -0.7 -0.3 -0.4 -0.4 -1.9 -0.7 -0.2 -0.1 -1.2  7.9  4.2 -0.1 -0.4 -0.2 -0.7 -0.5 -0.6 -0.5 -0.6 -0.4 -0.  -2.1 -0.5 -0.2 -0.3  4.7 -0.7 -0.2 -0.1 -0.2 -2.6  3.  -0.9  0.5 -0.  -0.  -0.3 -0.9  2.7  0.2 -0.1  2.3 -0.2  1.3 -0.7 -0.5 -0.3 -0.4 -0.2  3.8 -0.2  2.1  4.7 -0.2  1.9 -1.   0.3 -0.3  5.2  5.5 -0.2 -0.3 -0.6 -0.8  0.9 -0.4  1.6 -0.1 -0.3 -0.1 -0.5 -0.3  4.3 -0.1  2.7 -0.1  3.4  0.1 -0.6 -0.1 -0.   0.5 -0.9 -0.6 -0.1 -0.1 -0.2 -0.2 -0.4  0.2 -0.5  0.  -0.3 -0.9 -0.1  0.5 -0.4 -0.1 -0.6 -1.1 -1.4 -1.1  6.4 -0.2 -1.9 -0.2  0.2 -1.3 -0.1 -0.1  1.8 -0.2 -0.2 -0.  -0.2 -0.3 -0.3 -1.2  2.  -1.2 -1.5 -0.9 -0.1 -0.1 -0.  -0.5  0.  -0.6 -0.9 -2.9 -0.3 -0.2 -2.1 -0.2 -0.2 -0.3 -0.4 -0.6  1.8 -0.  -0.3 -0.4  1.3 -0.1 -0.8 -0.  -0.3 -1.1  4.   0.7 -1.7 -0.8 -0.3  4.9 -0.8  1.2 -0.2 -1.3 -0.1  4.1  1.4 -2.2  1.5 -4.3 -0.1 -2.2 -0.3 -0.2  7.5  3.  -0.1 -0.5 -0.7  1.2  4.6 -0.2 -2.  -0.5  1.4  3.5]
vy_50sample [[5 4 6 8 0 7 9 2 1 3]
 [6 9 0 1 1 2 5 8 4 3]
 [4 7 6 0 8 2 5 3 1 9]
 [5 1 1 8 9 2 6 0 0 7]
 [7 0 4 3 1 6 5 5 2 8]
 [7 4 5 3 1 2 0 6 9 8]
 [9 0 8 5 7 6 4 1 3 2]
 [7 2 5 8 9 9 1 0 4 6]
 [9 8 4 2 0 1 6 3 3 5]
 [5 8 8 9 7 3 1 2 6 4]]
vt_50sample [[5 4 6 8 0 7 9 1 2 3]
 [6 9 0 7 1 5 2 8 4 3]
 [4 7 6 0 8 2 5 3 1 9]
 [5 4 1 8 9 2 6 0 3 7]
 [7 0 4 3 1 6 9 5 2 8]
 [7 4 5 3 1 2 0 9 6 8]
 [9 0 8 5 7 6 4 1 3 2]
 [7 2 5 8 3 9 1 0 4 6]
 [9 8 4 2 0 1 7 6 3 5]
 [5 0 8 9 7 3 1 2 6 4]]
Epoch 19610: Training cost= 0.3530, Training acc= 0.8148, Validation cost= 0.3268, Validation acc= 0.8150
Epoch 19620: Training cost= 0.3597, Training acc= 0.8148, Validation cost= 0.3340, Validation acc= 0.8151
Epoch 19630: Training cost= 0.3545, Training acc= 0.8148, Validation cost= 0.3264, Validation acc= 0.8151
Epoch 19640: Training cost= 0.3699, Training acc= 0.8149, Validation cost= 0.3520, Validation acc= 0.8151
Epoch 19650: Training cost= 0.2557, Training acc= 0.8149, Validation cost= 0.3286, Validation acc= 0.8152
Epoch 19660: Training cost= 0.2813, Training acc= 0.8149, Validation cost= 0.3149, Validation acc= 0.8152
Epoch 19670: Training cost= 0.3791, Training acc= 0.8150, Validation cost= 0.3212, Validation acc= 0.8152
Epoch 19680: Training cost= 0.2673, Training acc= 0.8150, Validation cost= 0.3419, Validation acc= 0.8153
Epoch 19690: Training cost= 0.3387, Training acc= 0.8150, Validation cost= 0.2992, Validation acc= 0.8153
Epoch 19700: Training cost= 0.3255, Training acc= 0.8151, Validation cost= 0.3184, Validation acc= 0.8153
tm  [-1.  -0.8 -0.3  1.  -1.  -0.2 -0.1 -0.3 -0.2 -0.1 -2.5 -0.  -0.7 -0.4 -0.3 -2.1 -0.3 -0.3  0.5 -0.  -0.7 -0.3 -0.1 -0.1 -0.8  3.2 -0.3 -0.1 -1.5 -1.8 -0.4  0.7 -0.2 -2.2  0.4 -0.4  2.5 -1.3 -1.9 -0.9 -0.1 -1.9 -1.  -0.6 -0.3 -0.4 -0.6  0.8  0.1  0.  -0.6 -0.2 -0.4 -0.3  2.4  0.9 -0.7 -1.2  3.   2.5  4.1  0.1 -0.4  1.7 -0.7  0.8 -0.1 -0.   2.   1.1  0.3  4.5 -0.  -0.2 -3.3 -0.2 -0.6 -0.3  0.  -0.  -1.7 -0.2 -0.3 -0.  -0.3 -2.5 -0.2 -0.1 -0.2 -0.3 -0.5 -0.9 -0.2 -0.2 -0.5  0.1  0.1 -1.7 -0.6 -0.2 -0.3 -1.1 -0.1 -0.1  0.   0.6 -1.8 -0.5 -0.8 -0.6 -0.3  0.1  0.  -0.3  6.6 -2.5 -0.4  2.5 -0.1  0.5 -0.   2.  -0.5  0.4 -0.3 -0.3 -0.5  4.2  0.5  5.3  1.  -0.5 -0.3 -0.3  8.9  4.5 -0.6 -0.1 -0.1 -0.3  1.9 -1.4  0.1 -0.1 -0.2 -0.1 -0.5 -0.3 -0.6 -0.4 -0.   0.1  0.7  0.5 -0.4 -0.2  1.  -0.1 -1.1 -0.4 -0.3  0.9 -0.  -0.4 -0.6 -0.4 -0.4  2.5 -0.5  0.1 -0.8 -0.6  0.8 -0.3 -0.3  2.9 -1.  -0.6  5.6 -0.2  1.9  0.4 -0.  -1.1  0.9  0.7 -0.2  0.2  0.5  5.2 -0.4 -0.2 -0.4 -0.8 -0.6 -0.1 -1.2 -0.8 -0.1 -0.  -0.  -0.2 -0.2 -0.3 -0.2 -2.1 -0.4 -0.2  8.5 -0.  -0.5 -1.6 -1.1  1.4 -0.4 -0.5  3.2 -0.6 -0.2  0.1 -0.6 -0.3 -0.3 -1.2  1.6 -0.9 -1.6  0.2 -0.1  1.5 -0.2  0.8 -0.3  4.3  3.4  1.3  2.7 -0.9  2.1  7.7 -0.   4.2 -0.2  0.   6.8  0.8  0.7 -0.4 -0.9  0.3  4.  -0.5 -1.3 -0.2  4.2 -1.1]
ty_50sample [[0 6 3 1 1 9 9 7 2 5]
 [7 1 4 2 9 0 8 6 6 5]
 [7 5 8 8 9 4 1 0 3 2]
 [8 0 1 4 9 7 5 6 2 3]
 [1 4 7 0 9 3 8 2 6 5]
 [8 4 0 7 9 1 2 6 3 5]
 [3 9 2 5 6 7 4 8 1 0]
 [6 9 4 8 3 1 7 7 0 2]
 [2 6 1 9 9 0 4 5 7 3]
 [6 9 2 7 4 8 5 0 3 1]]
tt_50sample [[0 6 3 8 1 9 4 7 2 5]
 [7 1 4 9 2 8 3 0 6 5]
 [7 5 6 8 9 4 1 0 3 2]
 [8 0 1 4 9 7 5 6 2 3]
 [1 4 7 0 9 3 8 2 6 5]
 [8 4 0 7 9 1 2 6 3 5]
 [3 9 2 5 6 4 7 8 1 0]
 [6 9 4 8 3 1 5 7 0 2]
 [2 6 1 9 8 0 4 5 7 3]
 [6 9 7 2 4 8 5 0 3 1]]
vm  [-0.1 -0.5  6.8  1.7 -2.  -0.4 -0.3 -0.3 -0.8 -0.4  1.3  0.5 -0.2 -0.1  8.9 -0.9 -0.2 -0.5 -0.1  1.4 -0.9 -0.1 -0.8  0.2 -0.9  1.8 -0.4 -0.2 -2.  -2.  -0.9  0.1 -0.9  3.8 -0.1 -0.2  3.4  3.5  2.5 -0.8  0.  -0.6  0.5  1.8 -0.6  0.1 -1.6 -0.2  2.  -1.5 -0.8 -0.4 -0.5  5.5  1.7 -0.9 -0.7  4.2 -0.   3.4  2.1 -0.2 -0.4  3.  -0.4 -0.2 -0.1 -0.4  0.2 -0.4  0.2  4.8 -0.3 -0.4 -4.5 -0.3 -0.8 -0.3 -0.4 -0.2 -2.2 -0.3 -0.3 -0.1 -1.  -0.7  0.7  0.3  0.7 -0.2 -0.4 -0.4  0.6  2.3 -0.5  0.1  0.1 -1.9  0.5 -0.4  1.2 -0.7 -0.6 -0.2 -0.1  0.1 -2.5 -0.6  0.3  0.5  0.  -0.   0.2 -0.5  3.2 -2.2 -0.6  1.2 -0.1 -0.2  0.4 -0.3 -0.6 -0.4 -0.4 10.  -0.2 -1.   2.1 10.3 -0.3 -0.4  0.2 -0.2 -4.  -2.8 -0.3  0.1 -0.1 -0.4 -0.2 -1.2 -0.3 -0.3 -0.1 -0.2 -0.5 -0.5  1.5 -0.2 -0.4 -0.1  1.9  0.6 -0.3 -0.1  0.1  0.2  3.3 -0.5 -0.7 -1.8 -0.2 -0.2 -0.1 -0.1 -0.5 -0.4 -0.3  0.2 -0.3  0.9  0.5 -0.1 -0.1  1.1  1.5 -1.2 -0.1 -0.7 -1.4 -0.4 -0.1 -1.2  1.3 -0.4  0.1 -0.7 -0.1  6.2 -0.2 -0.1 -0.1 -0.9 -0.1 -0.4 -1.8 -0.1 -0.2 -0.3 -0.2 -0.2 -0.4 -0.6 -0.7 -3.4 -0.3 -0.3 -0.8 -0.1 -0.3 -1.7 -0.6 -0.6 -0.5 -0.3 -0.1 -0.7 -0.4 -0.2 -0.3 -0.1  0.2 -1.1 -1.9 -0.9 -0.8 -0.3  0.8  2.8 -0.8  2.2 -0.4 -0.7  2.4 -1.3  2.4 -1.8  0.8 -3.2  0.2 -1.6 -0.5 -0.2  8.3  4.7 -0.2 -0.3 -0.7 -0.2  5.3 -0.3  2.2 -0.2  2.9 -2.8]
vy_50sample [[3 0 7 5 8 2 1 9 4 6]
 [8 0 4 3 9 7 6 2 1 5]
 [9 0 7 1 3 6 4 5 8 2]
 [6 3 9 9 2 7 8 0 1 5]
 [2 4 9 5 8 0 6 7 1 3]
 [5 0 1 9 2 8 4 6 7 3]
 [1 6 5 7 4 2 0 3 9 8]
 [0 5 9 3 1 6 2 4 7 8]
 [3 1 8 7 9 4 6 5 0 2]
 [3 2 5 8 7 6 9 1 0 4]]
vt_50sample [[0 3 7 5 8 2 1 9 4 6]
 [8 0 4 3 9 7 6 2 1 5]
 [9 0 7 1 3 6 4 5 8 2]
 [6 3 9 4 7 2 8 0 1 5]
 [2 4 9 5 8 0 6 7 1 3]
 [5 0 9 1 2 8 4 6 7 3]
 [1 6 5 7 4 2 3 0 9 8]
 [0 5 9 3 1 6 2 4 7 8]
 [3 1 8 7 4 9 6 5 0 2]
 [3 5 2 8 7 6 9 1 0 4]]
Epoch 19710: Training cost= 0.2834, Training acc= 0.8151, Validation cost= 0.2849, Validation acc= 0.8154
Epoch 19720: Training cost= 0.3153, Training acc= 0.8151, Validation cost= 0.2649, Validation acc= 0.8154
Epoch 19730: Training cost= 0.2335, Training acc= 0.8152, Validation cost= 0.3082, Validation acc= 0.8154
Epoch 19740: Training cost= 0.3030, Training acc= 0.8152, Validation cost= 0.2354, Validation acc= 0.8155
Epoch 19750: Training cost= 0.3321, Training acc= 0.8153, Validation cost= 0.2744, Validation acc= 0.8155
Epoch 19760: Training cost= 0.3569, Training acc= 0.8153, Validation cost= 0.3014, Validation acc= 0.8155
Epoch 19770: Training cost= 0.2919, Training acc= 0.8153, Validation cost= 0.2991, Validation acc= 0.8156
Epoch 19780: Training cost= 0.3065, Training acc= 0.8154, Validation cost= 0.3219, Validation acc= 0.8156
Epoch 19790: Training cost= 0.3498, Training acc= 0.8154, Validation cost= 0.2708, Validation acc= 0.8156
Epoch 19800: Training cost= 0.2977, Training acc= 0.8154, Validation cost= 0.3576, Validation acc= 0.8157
tm  [ 1.3 -0.2 -1.9  2.5 -1.   0.3 -0.1 -0.3 -0.7 -1.   5.  -0.3 -0.1 -0.4 -1.6 -0.5 -0.6 -0.7 -0.3 -1.4 -0.8 -0.3 -0.7  1.  -1.1  3.1 -0.2 -0.4 -1.1 -0.2  4.5 -0.4 -0.1  3.5  1.1  2.2  3.9  0.2  6.2 -0.7  0.7 -1.9 -0.2  3.9 -0.3 -0.1  7.1 -0.3  3.2 -1.7 -0.6 -0.6  1.1 -0.8  0.6  3.3 -0.5 -2.3 -0.4 -1.7 -1.7 -0.2 -0.5  2.4  0.1  0.1 -0.2 -0.2  0.2  0.5 -0.3  2.3 -0.3 -0.5  5.9 -0.1 -1.  -0.6  1.6  0.  13.6  0.1 -0.5  0.5 -0.8 -1.7  5.4 -0.2  0.6 -0.1 -0.  -0.   0.2 -0.2 -0.2 -0.1 -0.7 -0.   0.6  0.1  2.5 -0.7 -1.1 -0.1  0.5 -0.3  0.8  5.4  1.7 -1.8 -1.3 -0.2 -0.   0.3  2.3 -1.5 -0.3 -0.7 -0.3 -0.5 -0.   7.8 -0.3 -0.1 -0.2 -1.9 -0.2  5.5 -0.5 -0.5  3.  -0.6 -0.1 -0.5  3.5  5.8  0.6 -0.   1.4 -0.8  0.3 -1.  -0.5 -0.1 -0.2 -0.3 -0.4 -0.2 -0.6 -0.2 -0.1 -0.1  1.1 -0.3  0.2  0.2 -0.  -0.6 -0.5 -0.2 -0.3 -0.3 -0.1 -0.3  0.1 -0.4 -0.2  0.8  0.  -0.3 -0.3 -0.6  0.5  0.4 -0.3  2.2 -0.8  1.8 -0.6 -0.2  0.9 -0.6 -0.6 -1.5 -0.1 -0.4  4.1 -0.3  0.1  0.2 -0.2 -0.4 -0.8 -1.   9.6  1.1  2.9  0.9 -0.2  0.2 -0.4 -0.5 -0.8 -0.8 -0.2  2.3 -0.2 -0.3  2.5 -0.1 -0.2 -0.7 -1.3 -0.4 -0.5 -0.9 -0.9 -0.8 -0.5  0.7 -0.7 -0.1 -0.3 -0.8 -0.4 -0.8 -0.6 -0.3  1.3  2.8 -0.8 -1.4  0.2  2.3  3.2  4.9  1.6  3.2  2.5 15.4 -0.1  7.1 -0.3 -0.1 -2.6 -2.4  0.2 -0.1 -1.1 -0.7 -3.4 -0.3  5.  -0.3  2.2  4.1]
ty_50sample [[9 4 0 3 2 2 7 8 1 5]
 [9 4 3 5 0 2 8 6 1 7]
 [9 7 2 1 4 3 0 6 5 8]
 [8 3 7 4 4 6 1 9 2 0]
 [5 7 1 9 6 4 2 3 0 0]
 [0 1 4 2 8 7 3 5 9 6]
 [8 9 1 6 3 2 5 7 7 0]
 [3 7 5 1 9 4 6 8 0 2]
 [2 5 0 0 4 1 8 7 3 6]
 [3 5 9 0 7 8 2 1 4 6]]
tt_50sample [[9 4 0 3 6 2 7 8 1 5]
 [9 4 3 5 0 2 8 6 1 7]
 [9 7 2 1 4 3 0 6 5 8]
 [8 3 7 4 5 6 1 2 9 0]
 [5 7 1 9 6 4 2 0 3 8]
 [0 1 4 2 8 7 3 5 9 6]
 [8 9 1 6 3 2 5 4 7 0]
 [3 7 5 1 9 4 6 8 0 2]
 [2 5 9 0 1 4 8 7 3 6]
 [3 5 9 0 7 2 8 1 4 6]]
vm  [ 1.8 -0.8  2.1  3.  -1.5 -0.6 -0.1 -0.1  1.5  0.3 10.8 -0.3  0.3 -0.2  0.5 -0.4 -0.1 -0.5  0.9 -0.5 -0.9 -0.4 -0.4 -0.2 -0.9  1.1 -0.3  0.  -1.5 -1.8  3.8  0.  -0.6  7.   2.6 -0.3  0.7  5.6  6.9 -0.5  0.1  4.5 -0.3  3.  -0.3 -0.4  2.7 -1.4  2.5 -1.2 -0.5 -0.1 -0.7  6.5  0.8  0.5 -0.7  2.9  4.2 -1.1 -0.6 -0.1 -0.3  2.9  2.8 -0.5 -0.1  1.8  1.8 -0.3 -0.3  4.1 -0.2 -0.3 -2.7 -0.3 -1.1 -0.1 -0.2 -0.1 10.8 -0.2 -0.7  0.5 -1.4  3.1  1.7 -0.  -0.4 -0.2 -0.5 -1.1 -0.4 -0.8 -0.5 -0.1  0.8 -1.6 -0.2 -0.6 -0.7  3.6 -1.2 -0.1 -0.1 -0.4 -1.6  3.   1.4 -0.8  0.2 -0.1 -0.3 -0.3  5.5 -2.2 -0.   2.  -0.4  1.8 -0.4  3.2 -0.3  0.3 -0.3  0.7 -1.  -1.4  5.1 -0.1  1.  -0.4 -0.4  1.  -2.7  2.3 -0.1 -0.1 -0.6 -0.6 -0.6 -0.7 -0.7 -0.1 -0.4 -0.1 -0.2 -0.3  3.  -0.7 -0.5 -0.1  0.3 -0.5 -0.1 -0.3  1.1  0.2  1.9 -0.1  0.  -1.9  0.7 -0.4  0.  -0.4 -0.9 -0.6 -0.6  0.3 -0.4 -0.   0.9  0.3  0.2 -0.4  0.2 -0.6 -0.9 -0.1 -1.2 -0.3  0.7 -1.4  1.2 -0.1  4.2 -0.3  0.   6.6 -0.4 -0.4 -0.6 -0.8  5.7 -1.3 -1.2 -0.9  0.3  0.4 -0.  -0.5 -0.5 -0.3 -0.7 -1.6 -0.1 -0.3 -3.6  0.1 -0.4 -1.1 -0.5 -1.  -0.3 -0.2 -0.4 -0.8 -0.2  0.6  0.5 -0.8 -0.2 -1.5 -0.4 -1.7  0.5  0.8 -0.1  3.8 -0.8  1.9 -0.3 -2.4  1.9 -0.1  3.7 -1.   0.5 -1.2 -0.  -0.5 -0.5 -0.1 -2.  -0.6  0.5 -0.7 -0.9  0.5 -2.6  0.1  5.8  0.1 -0.8  3.5]
vy_50sample [[0 2 5 9 7 4 3 1 6 8]
 [4 9 7 2 5 1 0 6 3 8]
 [5 0 2 3 9 1 8 4 7 6]
 [7 1 8 9 2 6 0 5 4 3]
 [6 4 5 5 3 8 0 7 9 9]
 [9 5 2 1 0 8 6 7 3 4]
 [1 6 0 7 5 9 4 2 8 3]
 [9 7 1 2 4 8 5 6 0 3]
 [8 5 6 0 3 1 4 2 9 7]
 [6 7 7 3 3 5 4 9 1 2]]
vt_50sample [[0 2 5 9 7 4 3 1 6 8]
 [4 9 7 2 5 1 0 6 8 3]
 [5 0 2 3 9 1 8 4 7 6]
 [7 1 8 9 2 6 0 5 4 3]
 [6 4 5 3 8 1 0 7 9 2]
 [9 5 2 1 0 8 6 7 3 4]
 [1 6 0 7 5 9 4 2 8 3]
 [9 7 1 2 4 8 5 6 0 3]
 [8 5 6 3 0 1 4 2 9 7]
 [6 0 7 3 8 5 4 9 1 2]]
Epoch 19810: Training cost= 0.2971, Training acc= 0.8154, Validation cost= 0.3581, Validation acc= 0.8157
Epoch 19820: Training cost= 0.4065, Training acc= 0.8155, Validation cost= 0.3757, Validation acc= 0.8157
Epoch 19830: Training cost= 0.3076, Training acc= 0.8155, Validation cost= 0.3716, Validation acc= 0.8157
Epoch 19840: Training cost= 0.3254, Training acc= 0.8155, Validation cost= 0.3080, Validation acc= 0.8158
Epoch 19850: Training cost= 0.3696, Training acc= 0.8155, Validation cost= 0.3385, Validation acc= 0.8158
Epoch 19860: Training cost= 0.3575, Training acc= 0.8156, Validation cost= 0.3497, Validation acc= 0.8158
Epoch 19870: Training cost= 0.2723, Training acc= 0.8156, Validation cost= 0.2977, Validation acc= 0.8159
Epoch 19880: Training cost= 0.3076, Training acc= 0.8156, Validation cost= 0.3547, Validation acc= 0.8159
Epoch 19890: Training cost= 0.3058, Training acc= 0.8157, Validation cost= 0.3482, Validation acc= 0.8159
Epoch 19900: Training cost= 0.3136, Training acc= 0.8157, Validation cost= 0.3239, Validation acc= 0.8159
tm  [-1.5 -0.6  3.4  4.2 -1.2 -0.1 -0.4 -0.3  4.9 -0.5  2.7 -0.9 -0.3 -0.   1.5  1.5 -0.8 -0.5 -0.2  2.  -0.5 -0.4  0.7 -0.6 -0.4  1.9 -0.1  1.4 -0.  -2.7 -0.6 -0.5 -0.5 -0.6 -0.5 -1.2 -0.9 -0.5 -1.7 -0.9 -0.4 -1.3 -1.5 -1.8 -0.6  0.6 -1.5 -0.5 -0.2 -0.3 -0.5 -0.   1.9  2.6 -0.9  0.5  1.   3.1  8.3  3.7  4.7 -0.4  2.4  2.8  0.1  1.  -0.3  0.6 -0.1 -0.3 -0.4 -0.8  0.4  0.5 -3.8 -0.5 -1.  -0.3 -0.6 -0.  -0.6 -0.7  1.9 -0.2 -0.3 -1.  -1.7 -0.2 -0.6  1.6 -0.1 -0.8 -0.2 -2.1 -0.5 -0.2  0.5 -2.5 -0.  -0.2  0.6 -1.1 -0.  -0.1 -0.3  0.4 -1.3 -0.7  0.1  0.5 -0.2  0.9 -0.2 -1.1  4.8  4.3 -0.3  2.7 -0.3  0.4 -0.4 -0.7  0.3  2.  -0.4  1.3 -0.   0.5  6.4  2.5  1.6 -1.7 -0.4 -0.5  9.4  7.8  0.4 -0.2  2.1 -0.2 -0.2 -0.4 -0.7 -0.2 -0.2 -0.1 -0.3 -0.   0.6  0.2 -0.1 -0.2 -0.1  1.2 -0.  -0.2 -0.2 -0.  -0.9 -0.  -0.   1.3  0.6 -0.2 -0.3 -0.4  1.6  5.7 -0.3  1.4 -0.3 -0.4 -0.2 -0.4 -0.6  0.6 -0.7 -0.1  5.3 -0.   0.4 -0.5 -1.  -1.6  0.6 -0.3 -0.7 -0.3 -0.2  7.9 -0.3 -0.2 -0.8 -0.7 -1.2 -1.9 -0.4 -1.2 -0.3 -0.1 -0.5  0.5 -0.8 -1.   0.4 -1.7 -0.1  0.9  4.4 -0.1 -0.5  4.8 -1.5  3.5 -1.4 -0.5  6.5 -0.4 -0.5  0.2 -1.3 -0.6 -0.1 -1.3  2.8  1.8 -1.2  5.  -0.2  4.7  1.2 -1.2 -0.4  2.3 -0.  -0.3  0.5 -0.7  3.5  2.2 -0.2  0.8 -0.1 -0.1  4.  -0.3 -0.1  0.5 -1.4 -0.5  0.1 -0.5 -1.4 -0.2  2.2 -0.4]
ty_50sample [[6 1 3 8 2 0 9 5 4 4]
 [6 5 4 3 8 7 1 2 0 9]
 [0 0 8 2 7 4 1 6 5 3]
 [1 8 0 4 5 2 9 9 3 6]
 [0 0 5 6 2 8 9 7 1 3]
 [6 2 2 8 4 9 7 0 5 1]
 [1 8 7 4 2 0 3 9 5 6]
 [2 5 6 1 3 0 4 8 9 7]
 [6 5 8 8 4 9 2 0 3 7]
 [3 4 1 7 2 8 9 6 0 5]]
tt_50sample [[6 1 3 8 2 0 7 9 5 4]
 [6 5 4 3 8 7 1 2 0 9]
 [0 9 8 2 7 4 1 6 5 3]
 [1 8 0 4 5 2 7 9 3 6]
 [0 4 5 6 8 2 9 7 1 3]
 [6 3 2 8 4 9 7 0 5 1]
 [1 8 7 4 2 0 3 9 5 6]
 [2 5 6 1 3 0 4 8 9 7]
 [6 5 1 8 4 9 2 0 3 7]
 [3 4 1 7 2 8 9 6 0 5]]
vm  [ 1.3  0.9 -0.9 -1.8 -1.  -0.1 -0.1 -0.4 -1.5 -0.9  7.3 -0.4  0.9 -0.1  3.8  0.3  1.2 -0.5 -0.2 -0.6 -0.9 -0.2 -0.5  1.9 -1.8  2.8 -0.1 -0.4 -1.7  1.3  3.2  0.8  0.2  2.5  1.   2.5  6.7  2.7 -0.8 -0.7  0.2 -1.7  0.9  3.8 -0.6 -0.2  0.2 -1.   1.7 -0.9 -0.4 -0.4 -0.8  7.   0.6 -0.3 -1.1 -2.  -1.3 -0.9 -0.3  0.7 -1.   0.6 -0.2  1.  -0.  -0.3 -0.4  0.9 -0.3  4.5 -0.6 -1.  -2.2 -0.2 -0.6 -0.2  0.7  0.4 -0.2 -0.2 -0.5  0.2 -0.7 -1.6  5.2 -0.1  1.3  0.1 -0.4 -0.2 -0.   4.1 -0.2 -0.  -0.2 -0.6 -0.  -0.1  2.6 -0.4 -0.6 -0.1  1.1 -0.3 -2.1  3.7  1.8 -0.5 -1.   1.   0.2  0.8  0.9 -2.3 -0.5 -1.  -0.2 -0.4 -0.4  1.4 -0.4 -0.5 -0.3  5.2 -0.4 -1.8 -1.5  5.8  2.2 -0.1 -0.3  0.6  2.2  4.  -0.1  0.3  0.4 -0.7 -0.9 -1.4 -1.1 -0.2  0.9 -0.3 -0.4 -0.1 -0.9 -0.1 -0.1 -0.   1.5 -0.8 -0.6  0.2 -0.4 -0.2 -0.8 -0.3 -0.4 -0.4 -0.3 -0.3 -0.2 -0.1 -0.7 -0.5 -0.1 -0.2  0.5 -0.3  0.6 -0.4  0.   3.5 -0.8 -0.7  3.4 -0.8  0.6 -0.2  0.7 -1.1 -0.4 -0.7  2.3 -0.7 -0.  -0.2 -0.1 -0.2 -0.  -1.3  4.1  5.2 -1.2  1.9 -0.3  0.2 -0.1 -0.2 -0.3 -0.6 -0.6 -2.5 -0.5 -0.5  3.8  0.2  0.2 -1.9 -0.4 -0.6 -0.1 -0.5 -0.7 -0.7 -0.9 -0.5 -0.1  0.5  0.9 -1.2 -0.3 -1.   1.7 -0.3  0.6 -0.1 -1.3  1.8 -0.2  2.4  2.9  4.3  1.6 -1.6 -0.   5.4 -0.   3.2 -0.3 -0.3  2.8  2.  -0.3 -0.4 -0.5 -0.4  0.1 -0.  -0.5 -0.3 -0.3 -1. ]
vy_50sample [[0 2 3 3 6 7 8 9 5 1]
 [6 1 5 2 2 3 4 0 7 9]
 [3 4 8 9 1 6 7 2 5 0]
 [5 6 4 2 9 0 8 8 3 1]
 [9 1 8 6 0 2 3 5 4 7]
 [3 2 5 9 1 4 7 6 0 8]
 [1 9 2 3 6 8 5 5 0 4]
 [4 0 5 7 2 3 9 9 1 6]
 [6 0 4 8 5 7 1 9 3 2]
 [0 3 1 9 9 7 6 6 8 4]]
vt_50sample [[0 4 2 3 6 7 8 9 5 1]
 [6 1 5 2 8 3 4 0 7 9]
 [3 4 8 9 1 6 7 2 5 0]
 [5 6 4 9 2 7 0 8 3 1]
 [9 1 8 6 0 2 3 5 4 7]
 [3 2 5 9 1 4 7 6 0 8]
 [1 9 2 3 6 8 7 5 0 4]
 [4 0 5 7 2 3 9 8 1 6]
 [6 0 4 8 5 7 1 9 3 2]
 [0 3 1 5 9 7 2 6 8 4]]
Epoch 19910: Training cost= 0.2970, Training acc= 0.8157, Validation cost= 0.3401, Validation acc= 0.8160
Epoch 19920: Training cost= 0.2867, Training acc= 0.8157, Validation cost= 0.3207, Validation acc= 0.8160
Epoch 19930: Training cost= 0.3214, Training acc= 0.8158, Validation cost= 0.3262, Validation acc= 0.8160
Epoch 19940: Training cost= 0.2817, Training acc= 0.8158, Validation cost= 0.2982, Validation acc= 0.8161
Epoch 19950: Training cost= 0.2771, Training acc= 0.8158, Validation cost= 0.3542, Validation acc= 0.8161
Epoch 19960: Training cost= 0.3151, Training acc= 0.8159, Validation cost= 0.3024, Validation acc= 0.8161
Epoch 19970: Training cost= 0.3307, Training acc= 0.8159, Validation cost= 0.3179, Validation acc= 0.8161
Epoch 19980: Training cost= 0.3662, Training acc= 0.8159, Validation cost= 0.3305, Validation acc= 0.8162
Epoch 19990: Training cost= 0.3379, Training acc= 0.8159, Validation cost= 0.2928, Validation acc= 0.8162
Epoch 20000: Training cost= 0.2688, Training acc= 0.8160, Validation cost= 0.2844, Validation acc= 0.8162
tm  [ 1.7 -0.1 -0.4  4.7 -1.2  0.5 -0.2 -0.2 -0.6 -0.3  6.7 -0.5  0.4 -0.5 -0.9  5.4  0.1 -0.5 -0.6 -2.2 -0.6 -0.2 -0.4 -0.1 -0.7 -0.2 -0.3 -0.1 -0.1 -0.1  2.2 -0.6 -0.4  3.1  0.9 -0.   1.9  6.1 16.5 -0.5  0.  -1.7 -0.4  6.2 -0.4 -0.  12.  -0.8  3.2 -0.3 -0.2 -0.4 -0.1  1.6 -0.9  1.9 -0.4 -1.8 -0.  -0.6 -2.6 -0.1 -1.  -0.  -0.1 -0.1 -0.1 -0.1 -0.3 -0.1 -0.4 -0.9 -0.5 -0.6  5.5  1.8 -0.7  1.4 -0.2  0.5  9.  -0.  -1.1  1.8 -1.  -1.8  4.7 -0.2 -0.  -0.4 -0.3  0.3 -0.3 -0.  -0.2 -0.1 -0.5  0.8 -0.5 -0.4  1.7 -0.  -1.2 -0.3 -0.2 -0.3 -0.1  2.7  2.3 -2.4 -0.4 -0.2 -0.2 -0.1 -0.4  2.7  0.3 -0.4 -0.3 -0.7 -0.6 10.2 -0.2 -0.7 -0.1 -1.1  0.1  0.9  0.  -0.7  0.8 -0.4 -0.3 -0.4 -3.6 -3.  -0.3 -0.3 -0.3 -0.7 -1.4 -0.4 -0.9 -0.3 -0.2 -0.3  0.2 -0.3 -1.2 -0.1 -0.6 -0.5  4.1 -0.9 -0.  -0.1 -0.4 -0.4  2.  -0.5 -0.6 -1.7 -0.4 -0.2 -0.2  1.8 -0.  -0.  -0.4 -0.3 -0.7 -0.7 -0.4  0.   0.   3.4  1.3  0.3 -2.6 -0.4  0.1 -0.  -0.3 -0.6 -0.3 -0.3  5.6 -0.7 -0.7  0.  -0.2 -0.3 -1.2 -0.9 13.6 -0.4  2.3  1.5 -0.1 -0.4 -0.1 -0.1 -0.2 -0.3 -0.6  2.3  0.1 -0.1  4.5  0.9 -0.4  1.7 -0.6 -1.2  0.7  0.1 -1.7 -0.3 -0.5 -0.6 -0.2 -0.2 -0.3 -0.4 -1.6  2.   2.5 -0.3  2.4  4.4 -1.3 -0.7 -0.1  3.1 -0.7  1.7  0.   2.4 -0.1 18.9 -0.3  8.9 -0.2 -0.1 -1.5 -2.4 -0.2 -0.7 -0.8 -0.2 -2.3 -0.2 11.9 -0.2 -0.5  4.9]
ty_50sample [[9 2 4 3 7 8 0 5 6 1]
 [5 9 2 6 4 1 3 8 0 7]
 [5 0 9 3 1 7 6 6 4 8]
 [1 6 4 7 8 9 2 0 5 3]
 [0 9 7 7 5 1 2 8 6 3]
 [3 6 1 0 7 2 8 4 5 9]
 [0 1 8 3 3 4 4 5 6 2]
 [5 9 7 1 4 6 8 3 2 0]
 [1 2 3 4 6 0 8 5 7 9]
 [0 1 3 8 5 7 6 4 2 9]]
tt_50sample [[9 2 4 3 7 8 0 5 1 6]
 [5 9 2 6 4 1 3 8 0 7]
 [5 0 9 3 1 7 6 2 4 8]
 [1 6 4 7 8 2 9 0 5 3]
 [0 4 9 7 5 1 2 8 6 3]
 [3 6 1 0 7 2 8 4 5 9]
 [0 1 8 9 3 4 7 5 6 2]
 [5 9 7 1 4 6 8 3 2 0]
 [1 2 3 4 6 0 8 5 7 9]
 [0 1 3 8 5 7 6 4 2 9]]
vm  [-0.7 -0.1  2.9 -1.  -1.6 -0.3 -0.2 -0.1 -0.6 -0.4  8.8 -0.5  0.5 -0.4  7.3  3.1  0.4 -0.4  0.1 -0.1 -0.7 -0.4  1.8  0.7 -1.8  2.2 -0.  -0.2 -1.1 -0.8  1.8  0.2 -0.2  5.2  0.6  0.8  4.1  5.5 -0.6 -0.2 -0.2  6.5  1.9  2.1 -0.9 -0.5 -1.3 -1.4 -0.6  4.2 -0.7 -0.3 -0.8 10.3 -0.4 -0.8 -0.8  4.  -0.1 -0.3  6.8 -0.1 -0.3  1.6  0.5 -0.2 -0.2 -0.2 -0.7 -0.3 -0.1  2.6 -0.3 -0.4 -4.1 -0.3  1.  -0.4  0.6 -0.  -0.4 -0.1 -0.  -0.1  0.4  7.5 -0.3 -0.1 -0.3 -0.1 -0.2 -0.6 -0.4 -0.1 -0.3 -0.4  1.  -1.7 -0.4 -0.4  1.1  5.7  1.1 -0.4 -0.2 -0.1 -2.6  1.9  2.1 -0.  -0.5  0.6 -0.  -0.3  1.8 -0.9 -0.5 -0.8 -0.3 -0.1 -0.4 -0.4 -0.3  0.6 -0.2  8.4 -0.4 -2.7  0.9 -0.2 -0.5 -0.2 -0.5 -0.2 -1.6  2.5 -0.3 -0.1  0.  -0.4 -0.8 -0.6 -1.  -0.   0.1 -0.1 -0.3 -0.2  3.6 -0.2  0.3 -0.2 -1.  -1.  -0.5  0.3 -0.3 -0.1  1.2 -0.6  0.5 -0.6 -0.1 -0.2 -0.4 -0.4 -0.6 -0.4 -0.  -0.2  1.   0.5 -0.3 -0.1 -0.3 -0.4 -0.7 -1.   3.2 -0.3 -1.4 -0.3 -0.  -1.2 -0.2 -0.5 -1.  -0.7 -0.4  2.9 -0.1 -0.4 -0.1 -0.7 -1.7  1.  -1.6 -0.  -0.1 -0.1  0.3 -0.4 -0.2 -0.5 -0.2 -3.2 -0.2 -0.4 -2.8  0.9 -0.1 -0.9 -0.4  4.  -0.3 -0.4 -0.1 -0.7 -0.4 -0.3  0.6 -0.1 -0.1 -1.2  2.5 -0.8  3.2  2.4 -0.2 -0.4 -0.9  1.5 -0.4 -1.8  2.  -0.2  1.3 -1.7 -0.3 -3.6 -0.2 -1.6 -0.3 -0.3  3.   3.2 -0.3 -0.5 -0.7 -0.1  0.4 -0.1 -0.4 -0.1 -1.5  2.9]
vy_50sample [[2 5 1 7 7 4 6 8 9 3]
 [1 1 2 7 6 4 3 5 5 0]
 [0 8 2 9 5 1 4 3 6 7]
 [3 7 1 6 0 4 9 8 5 2]
 [4 5 1 6 7 3 8 2 9 0]
 [7 7 8 1 2 4 5 0 3 6]
 [7 1 1 6 2 3 9 9 8 4]
 [0 4 6 2 9 1 1 8 5 3]
 [1 0 8 2 5 7 3 6 4 9]
 [4 8 3 0 1 2 9 7 5 6]]
vt_50sample [[2 5 0 1 7 4 6 8 9 3]
 [8 1 7 2 4 6 3 9 5 0]
 [0 8 2 9 5 1 4 3 6 7]
 [3 7 1 6 4 0 8 9 5 2]
 [4 5 1 6 7 3 8 2 0 9]
 [7 9 8 1 2 4 5 0 3 6]
 [7 5 1 6 2 3 9 0 8 4]
 [0 4 6 7 2 9 1 8 5 3]
 [1 0 8 5 2 7 3 6 4 9]
 [4 8 3 0 1 2 9 7 5 6]]
Epoch 20010: Training cost= 0.3248, Training acc= 0.8160, Validation cost= 0.2738, Validation acc= 0.8163
Epoch 20020: Training cost= 0.3134, Training acc= 0.8160, Validation cost= 0.3016, Validation acc= 0.8163
Epoch 20030: Training cost= 0.3405, Training acc= 0.8161, Validation cost= 0.3555, Validation acc= 0.8163
Epoch 20040: Training cost= 0.2917, Training acc= 0.8161, Validation cost= 0.2729, Validation acc= 0.8163
Epoch 20050: Training cost= 0.2822, Training acc= 0.8161, Validation cost= 0.3207, Validation acc= 0.8164
Epoch 20060: Training cost= 0.3194, Training acc= 0.8162, Validation cost= 0.3477, Validation acc= 0.8164
Epoch 20070: Training cost= 0.2957, Training acc= 0.8162, Validation cost= 0.3067, Validation acc= 0.8164
Epoch 20080: Training cost= 0.3004, Training acc= 0.8162, Validation cost= 0.3460, Validation acc= 0.8165
Epoch 20090: Training cost= 0.3167, Training acc= 0.8162, Validation cost= 0.3120, Validation acc= 0.8165
Epoch 20100: Training cost= 0.3049, Training acc= 0.8163, Validation cost= 0.3051, Validation acc= 0.8165
tm  [-1.4 -0.5  8.7  2.  -1.5  0.4 -0.4 -0.3  1.4 -0.6  4.6  0.6 -0.6 -0.  10.3 -0.3 -0.3 -0.4 -0.3  0.9 -0.8 -0.  -2.  -0.5 -0.7  0.7 -0.5 -0.1 -0.9 -2.5  1.1 -0.1  1.1 10.2 -0.7 -0.2 -0.2 -0.4 -2.4 -0.4  1.2 -2.4 -1.2 -1.  -0.5 -0.2 -1.3 -0.1 -0.8 -4.3 -0.8 -0.1 -1.   3.6 -0.3 -1.  -0.7  2.5  4.2  0.7  8.2 -0.4  0.5  1.1  0.9 -0.3 -0.2 -0.1 -0.3 -0.6 -0.2  1.1 -0.4 -0.6 -5.  -0.2 -0.2 -0.1 -0.4 -0.6  2.1 -0.2 -0.2  0.7 -0.  -2.4 -1.4 -0.1 -0.1 -0.1 -0.5 -0.2  0.5 -0.2 -0.5 -0.1 -0.  -2.  -0.2 -0.3  2.7 -1.2  2.8 -0.2 -0.3 -0.6 -3.   0.   0.4  0.6  1.7 -0.1  0.4 -1.2  4.8 -0.2 -0.4  3.6  0.4 -0.5 -0.5 -0.5 -0.3 -0.  -0.2 11.7  1.3 -0.4  2.6 11.9 -0.3 -0.8 -0.3 -0.5 -0.5 12.  -0.3 -0.3  1.2 -0.3 -0.2  0.5 -0.4 -0.1 -0.  -0.1 -0.3 -0.2 -1.1 -0.4 -0.3 -0.5 -1.8 -0.1 -0.4  0.8 -0.5 -0.4 -0.6 -0.4 -0.9 -0.1 -0.2  0.2 -0.1 -0.1 -0.2  3.2 -0.2  0.1 -0.7 -0.2 -0.  -0.3 -0.6  4.  -1.1 -1.8  6.7 -0.1 -0.3 -0.5 -0.  -1.1  0.4 -0.6 -1.2 -1.  -0.4  8.5 -0.3  0.6 -0.4 -0.5 -2.6 -0.6 -2.1 -0.9 -0.4 -0.2 -0.3 -0.2 -0.3 -0.6 -0.3 -4.  -0.  -0.2 -1.   0.1 -0.4 -0.3 -0.6  3.1 -0.7  0.7  5.  -0.8 -0.3  0.  -0.7  0.7  1.1 -0.9 -0.9 -0.9 -0.9  1.3 -0.4  2.2 -0.8  3.2 -0.5 -0.9  0.2 -1.8  0.3 -2.3  0.1 -0.7  0.3 -0.2 -0.6 -0.3  0.   5.7 -0.3 -0.7 -1.1 -0.2 -0.7 -0.6 -1.8 -0.4  5.5 -3.3]
ty_50sample [[3 1 7 0 6 5 2 9 4 8]
 [1 7 9 3 0 6 4 5 5 2]
 [9 0 1 1 7 5 6 3 2 2]
 [3 5 6 1 2 9 8 7 0 4]
 [8 4 1 2 5 3 7 9 6 0]
 [5 1 4 8 3 0 2 6 7 9]
 [4 6 0 5 8 2 9 7 3 1]
 [9 1 6 3 4 8 7 2 5 0]
 [3 9 8 6 2 1 4 4 5 0]
 [9 2 1 6 8 7 3 4 0 5]]
tt_50sample [[3 1 7 0 6 5 2 9 4 8]
 [1 7 9 3 6 0 4 5 2 8]
 [9 0 4 1 7 5 6 3 2 8]
 [3 5 6 9 1 2 7 8 0 4]
 [8 4 1 2 5 3 9 7 6 0]
 [5 4 1 8 3 0 2 6 7 9]
 [4 6 0 5 8 2 9 7 3 1]
 [9 1 6 3 4 8 7 2 5 0]
 [3 9 8 6 2 7 1 4 5 0]
 [9 2 1 6 8 7 3 4 0 5]]
vm  [-0.   0.4 -1.4 11.  -0.4 -0.2  0.6 -0.4 -1.2 -0.4 -4.6  0.6 -0.8 -0.5 -3.4  2.   0.1 -0.3 -0.5 -2.  -0.5 -0.  -0.  -0.2 -0.7 -0.4  0.6 -0.8  3.   2.5 -0.8 -0.5  1.6 -4.4 -1.  -0.1  0.9 -1.1  4.6 -0.   0.2 -1.7 -0.  -0.2 -0.2 -0.3 10.2  2.4 -0.1  1.2 -0.2 -0.3 -0.1 -3.2 -1.7  5.2 -0.3 -0.4 -1.2  3.2 -1.7 -0.8 -0.4 -0.9 -0.5 -0.6 -0.  -0.   0.9 -0.1 -0.2 -1.8 -0.5 -0.4  4.1  0.7 -0.3 -0.  -0.6 -0.1  3.   1.6 -0.9 -0.  -0.9 -1.5  2.2 -0.2  0.2 -0.9  1.2  2.1 -0.2  3.2 -0.2  0.2 -0.9  1.3 -0.6 -0.5  3.  -2.1 -0.5 -0.1  0.1 -0.1  2.2 -0.7 -1.7 -2.4  0.3 -0.6 -0.2 -0.2 -1.2  8.5 -0.2 -0.7  0.5 -0.4 -0.   8.1 -0.6 -0.6  0.5 -3.8  2.7 14.4 -0.9  0.2  0.8  0.1  0.7 -0.3 10.3 -0.3 -0.   0.3 -0.1  0.2  2.5 -0.5  2.3 -0.3 -0.1 -0.2 -0.4  0.3  3.5 -0.3 -1.   0.1  3.4 -0.3 -0.1 -0.2 -0.3 -0.7 -1.  -0.3 -0.3  0.7 -0.4 -0.1 -0.2  0.3  0.6 -0.1 -0.3  0.5 -0.8 -0.4 -0.1  0.6 -0.  -0.3 -1.6  2.1 -0.5 -0.2 -0.5 -0.   1.4 -1.  -1.2  2.6  3.9 -0.  -0.3 -0.6 -0.2 -0.1 -0.6 -1.4 10.5  2.4  3.8  2.7 -0.1 -0.5  0.4 -0.4  1.3 -0.3 -0.4  7.1 -0.5 -0.8  6.7 -0.3 -0.1  4.5 -1.   0.6  0.3 -0.2  1.7 -0.2 -0.   0.6 -0.7 -0.4 -0.5 -0.4 -0.5  4.2 -2.  -0.7 -0.5  1.  -0.  -0.6 -0.   3.5 -1.9  3.7 -0.3  3.7  0.7 13.7 -0.4  6.3 -0.1  0.2 -0.2 -3.4  0.2 -0.5 -0.5 -0.1 -0.7 -0.2  2.8  0.3  6.7  2.4]
vy_50sample [[9 3 6 4 4 5 1 7 2 0]
 [4 6 3 7 0 5 1 2 8 9]
 [8 5 6 6 7 1 2 0 9 3]
 [2 1 7 8 3 3 5 0 4 6]
 [9 9 9 8 2 6 5 3 0 7]
 [4 3 1 9 0 6 7 2 5 8]
 [0 0 9 6 8 4 5 1 2 7]
 [2 8 4 1 6 7 9 3 0 5]
 [1 2 3 9 4 7 6 5 8 0]
 [0 0 9 7 8 3 2 5 6 4]]
vt_50sample [[9 8 3 6 4 5 1 7 2 0]
 [4 6 3 7 0 5 1 2 8 9]
 [8 5 6 4 7 1 2 0 9 3]
 [2 1 7 8 3 9 5 0 4 6]
 [4 1 9 8 6 2 5 3 0 7]
 [4 3 1 9 0 6 7 2 5 8]
 [0 3 9 6 8 4 5 1 2 7]
 [2 8 4 1 6 7 9 3 0 5]
 [1 2 3 9 4 7 6 5 8 0]
 [1 0 9 7 8 3 2 5 6 4]]
Epoch 20110: Training cost= 0.3256, Training acc= 0.8163, Validation cost= 0.3583, Validation acc= 0.8166
Epoch 20120: Training cost= 0.2902, Training acc= 0.8163, Validation cost= 0.3542, Validation acc= 0.8166
Epoch 20130: Training cost= 0.2893, Training acc= 0.8164, Validation cost= 0.3160, Validation acc= 0.8166
Epoch 20140: Training cost= 0.3059, Training acc= 0.8164, Validation cost= 0.3332, Validation acc= 0.8166
Epoch 20150: Training cost= 0.3120, Training acc= 0.8164, Validation cost= 0.2920, Validation acc= 0.8167
Epoch 20160: Training cost= 0.2993, Training acc= 0.8164, Validation cost= 0.2761, Validation acc= 0.8167
Epoch 20170: Training cost= 0.3121, Training acc= 0.8165, Validation cost= 0.3101, Validation acc= 0.8167
Epoch 20180: Training cost= 0.3477, Training acc= 0.8165, Validation cost= 0.3360, Validation acc= 0.8168
Epoch 20190: Training cost= 0.3865, Training acc= 0.8165, Validation cost= 0.3133, Validation acc= 0.8168
Epoch 20200: Training cost= 0.3113, Training acc= 0.8166, Validation cost= 0.3659, Validation acc= 0.8168
tm  [-1.4 -0.2 -1.9  0.5 -0.4 -0.1 -0.3 -0.4 -0.  -0.5  5.9 -0.4 -0.1  0.6 -1.6  6.4 -0.  -0.2 -0.2 -0.2 -0.5 -0.4  1.3 -0.6 -1.2  0.9 -0.2  0.1  1.4 -1.9 -0.2 -0.7 -0.5 -3.1 -0.5 -0.3  1.2  4.7  2.8 -0.2 -0.4  3.4  0.1  0.9 -0.7 -0.3 -0.4 -1.  -1.   1.5 -0.6 -0.1 -0.4  7.  -1.6  2.3 -0.3  5.5  2.7  2.   5.6 -0.4 -0.  -0.2 -0.  -0.5 -0.1  1.8 -0.6 -0.4 -0.3 -1.   0.2  0.4 -3.6 -0.3 -0.  -0.4 -0.4 -0.1 -0.6 -0.4 -0.3 -0.4  0.3  4.5 -0.9 -0.2  0.7 -0.  -0.5 -0.5 -0.2 -0.  -0.7 -0.2 -0.1 -1.5 -0.5 -0.1  1.6 -2.2  1.2 -0.2 -0.4  1.1 -1.8 -0.2  1.8 -0.8 -0.2 -0.5 -0.2 -0.7 -0.3  7.  -0.2 -0.7 -0.1  0.2 -0.3  0.9 -0.2  0.3 -0.4 -1.8  1.4 -1.6  4.3  2.2 -0.8 -0.6 -0.5  0.6  6.7 -1.  -0.3 -0.2  0.  -0.8 -0.9 -0.2 -1.1 -0.4 -0.4 -0.  -0.   0.   8.6 -0.5 -0.  -0.1 -0.5 -0.4 -0.3 -0.2 -0.4 -0.2  2.  -0.6 -0.6 -1.   0.1 -0.2 -0.3 -0.3  0.1 -0.1 -0.5 -0.3 -0.2 -0.1 -0.6 -0.2 -0.3 -2.6 -0.5 -0.6 -0.  -0.5 -1.8  0.5 -0.1 -1.4 -0.3  0.1 -0.8  1.8 -0.4  6.4 -0.4 -0.4 -0.6 -1.  -1.4 -0.9 -1.   0.5 -0.3 -0.2  0.7 -0.1 -0.5 -0.4 -0.  -1.9 -0.1  0.3 -2.3  0.3 -0.4  2.7 -0.4  4.4 -0.1 -0.1 -0.1 -0.5 -0.5 -0.3  0.7 -0.6 -0.1 -1.  -0.5  2.4  1.   2.3 -0.1  0.7 -0.8  0.2 -0.4 -1.5 -0.7  3.  -0.  -1.3 -0.6 -3.1 -0.1 -1.3 -0.3 -0.3  4.1 -0.3 -0.1 -0.5 -0.5  0.5  0.5 -0.2  1.7  0.2 -0.3  0.1]
ty_50sample [[5 2 1 3 3 4 9 6 0 7]
 [1 8 2 9 6 0 4 7 5 3]
 [6 2 3 4 1 8 5 9 0 7]
 [5 1 6 0 4 7 9 2 3 8]
 [7 4 2 6 0 1 3 8 9 9]
 [5 0 1 3 8 4 2 9 6 7]
 [0 6 8 1 4 7 2 5 3 9]
 [6 8 9 1 3 0 5 2 4 7]
 [8 5 4 2 0 1 3 7 9 6]
 [9 2 1 6 5 4 0 8 3 7]]
tt_50sample [[5 2 1 8 3 4 9 6 0 7]
 [1 8 2 9 6 0 4 7 5 3]
 [6 2 3 4 1 8 5 9 0 7]
 [5 1 6 4 0 7 9 3 2 8]
 [7 4 2 6 0 1 8 3 9 5]
 [5 0 1 3 8 4 2 9 6 7]
 [0 6 8 1 4 2 7 5 3 9]
 [6 8 9 1 3 0 5 2 4 7]
 [8 5 4 2 0 1 3 7 9 6]
 [9 2 1 6 5 4 0 8 3 7]]
vm  [-0.2 -0.1 -2.5 -2.  -0.4 -0.3 -0.3 -0.4 -1.  -0.4 -3.2 -0.4 -0.2  0.6 -0.5  3.7  0.3 -0.1 -0.5 -0.5 -0.7 -0.4  1.6 -0.5 -0.7  0.1 -0.  -0.3  1.   2.1 -0.2 -0.6  0.3 -4.4 -0.4 -0.3  0.6 -0.3 -1.  -0.3 -0.2 -2.5 -0.3  2.2 -0.4 -0.2 -0.2 -0.2  1.5  6.8 -0.2 -0.3 -1.2  2.1 -1.4  1.3 -0.5 -2.9  0.5  2.1 -0.1  0.  -0.4 -0.  -1.1 -0.3 -0.   0.1 -0.2  1.2  0.  -0.8 -0.   0.9 -3.  -0.  -0.4 -0.1  0.4 -0.7 -3.6 -0.5 -0.7 -0.  -1.2 -2.5  4.8 -0.4  0.4 -0.3 -0.4 -0.1 -0.3  1.9 -0.4 -0.1 -0.7 -1.6 -0.5 -0.9  2.5 -1.1 -0.3 -0.1 -0.4 -0.4 -1.2 -0.4 -1.2 -1.3 -0.1 -0.5 -0.  -0.5 -0.3  5.3 -0.1 -0.2 -0.2 -0.2  0.2  2.8 -0.2 -0.6 -0.3 -0.5  0.7 -0.  -0.4  4.   2.1 -0.4 -0.3 -0.1  7.8 -2.2 -0.3 -0.3 -0.4  2.6 -0.5 -0.6 -0.3  0.1 -0.   0.4 -0.3 -0.3 -0.7 -0.6  1.7 -0.1  4.  -0.5 -0.1 -0.2 -0.2 -0.5 -0.9 -0.5 -0.2  1.4 -0.4 -0.2 -0.7 -0.3  0.4  1.5 -0.  -0.7 -0.6 -0.7 -0.5 -0.4 -0.2  2.3 -1.1 -0.3  3.9 -0.5  3.1  0.3 -0.2 -0.6 -0.4  2.4  1.7 -0.2 -0.4 -0.5 -0.3 -0.3 -0.4 -0.9  3.2 -0.1 -0.4 -0.  -0.  -0.3 -0.  -0.2 -0.2 -0.5 -0.1 -1.8 -0.4 -0.4 11.7 -0.6 -0.6  2.1 -1.  -0.1  1.1 -0.2 -0.4 -0.4  0.6 -0.5 -0.2 -0.4 -0.2 -0.6  0.3  2.3 -0.7 -0.5 -0.3  3.  -0.3 -0.  -0.   6.9 -0.6  5.4 -0.  -1.1  0.1 11.5 -0.   5.9 -0.1 -0.1 11.4 -0.5 -0.1 -0.8 -0.8 -0.1  8.8 -0.2 -0.8 -0.2  1.8 -0.5]
vy_50sample [[8 4 6 3 2 9 7 1 0 5]
 [1 4 6 3 2 8 5 7 7 0]
 [9 6 2 8 0 4 3 7 5 1]
 [1 9 5 0 3 6 2 7 4 8]
 [3 0 9 2 1 8 4 7 6 5]
 [8 5 9 1 3 2 6 0 7 4]
 [4 3 7 6 2 8 8 0 1 9]
 [9 1 2 2 8 6 7 0 4 5]
 [4 7 5 6 9 2 3 8 1 0]
 [2 1 5 7 8 9 6 4 0 3]]
vt_50sample [[8 4 6 3 2 9 1 7 0 5]
 [1 4 6 3 8 2 5 9 7 0]
 [9 6 2 8 0 4 3 7 5 1]
 [9 1 5 0 3 6 2 7 4 8]
 [3 0 9 2 1 4 8 7 6 5]
 [5 8 9 1 3 2 6 0 7 4]
 [4 3 7 6 2 8 5 0 1 9]
 [1 9 3 2 8 6 7 0 4 5]
 [4 7 6 5 9 2 3 8 1 0]
 [2 1 7 5 8 9 6 4 0 3]]
Epoch 20210: Training cost= 0.3561, Training acc= 0.8166, Validation cost= 0.3358, Validation acc= 0.8168
Epoch 20220: Training cost= 0.2980, Training acc= 0.8166, Validation cost= 0.2511, Validation acc= 0.8169
Epoch 20230: Training cost= 0.2860, Training acc= 0.8167, Validation cost= 0.3178, Validation acc= 0.8169
Epoch 20240: Training cost= 0.3629, Training acc= 0.8167, Validation cost= 0.2875, Validation acc= 0.8169
Epoch 20250: Training cost= 0.3115, Training acc= 0.8167, Validation cost= 0.3796, Validation acc= 0.8170
Epoch 20260: Training cost= 0.3208, Training acc= 0.8167, Validation cost= 0.3165, Validation acc= 0.8170
Epoch 20270: Training cost= 0.2716, Training acc= 0.8168, Validation cost= 0.3593, Validation acc= 0.8170
Epoch 20280: Training cost= 0.3203, Training acc= 0.8168, Validation cost= 0.3435, Validation acc= 0.8170
Epoch 20290: Training cost= 0.2852, Training acc= 0.8168, Validation cost= 0.3566, Validation acc= 0.8171
Epoch 20300: Training cost= 0.3025, Training acc= 0.8169, Validation cost= 0.3168, Validation acc= 0.8171
tm  [-0.8 -0.4  8.2 -1.  -1.8  0.2 -0.5  0.  -0.6 -0.5  5.7  0.3 -0.3 -0.2 12.5  1.  -0.6 -0.1  1.6  3.  -0.8 -0.3  0.6 -0.  -1.5  3.8 -0.7 -0.3 -0.9 -0.7  0.8 -0.1 -0.2 10.  -0.   0.6  2.   1.5 -2.5 -0.6 -0.2 -0.5 -0.3 -0.3 -0.7 -0.2 -2.1 -0.6 -0.9  0.1 -0.9 -0.1 -0.3  8.4 -0.6 -1.4 -1.  -0.3  1.5  0.9  9.4 -0.3 -0.1  1.2  1.7 -0.4 -0.1 -0.   0.1 -0.5  0.1  2.1  0.2 -0.3 -4.7 -0.4  0.4 -0.4  0.9 -0.1 -1.3  0.3  1.1  0.5  1.2 -0.2 -0.9 -0.1 -0.4 -0.5 -0.  -0.6 -0.4 -0.4 -0.5  0.6  1.  -2.1 -0.8 -0.1  2.5  7.6  2.3 -0.2 -0.  -0.2 -2.7  0.7  1.8  3.5 -0.3 -0.3  0.8 -0.5  3.4 -0.7 -0.3  0.  -0.  -0.2 -0.1 -1.4  0.  -0.  -0.2 14.9 -0.5 -2.  -0.2  4.2 -0.4 -0.4 -0.3 -0.4 -2.6  6.8 -0.  -0.  -0.1 -0.5 -0.4 -0.7 -0.6 -0.1  0.2 -0.1 -0.1 -0.  -2.6 -0.5  0.  -0.4 -1.  -0.2  0.1 -0.2  0.4 -0.5 -0.2 -0.4  0.4 -0.1 -0.  -0.1 -0.4 -1.2 -0.3  1.6 -0.3 -0.3 -0.1 -0.5 -0.1 -0.  -0.4  6.1 -1.3 -1.1  6.6 -0.3  0.6 -0.7 -0.1 -1.2 -0.2 -0.3 -1.1 -0.6 -0.1  2.7 -0.3 -0.5  0.  -0.8 -2.8  1.3 -1.5 -0.4 -0.2  0.7  0.1 -0.6 -0.4 -0.3 -0.2 -3.6 -0.  -0.2  3.3 -0.4 -0.3 -0.9 -0.5  5.  -0.6 -0.1  2.4 -0.6  0.2  0.3 -0.5 -0.2 -0.1 -0.9  1.9 -0.7 -0.   2.4 -0.1 -0.5 -0.2  1.2 -0.2  1.7  1.8 -1.7  2.  -1.9 -0.  -0.7  0.2 -0.1 -0.3 -0.1  5.6  4.6 -0.2  0.3 -0.8 -0.3  2.6 -0.1 -1.6 -0.1 -0.3 -1. ]
ty_50sample [[7 1 0 2 6 3 3 4 5 9]
 [5 3 4 8 9 1 2 6 7 0]
 [5 8 0 4 3 3 6 2 9 9]
 [9 5 1 1 2 4 4 0 7 3]
 [7 0 3 6 2 8 1 9 5 4]
 [2 1 3 9 7 6 8 5 0 4]
 [7 6 1 1 3 0 9 5 4 8]
 [2 2 8 6 9 4 5 0 3 7]
 [5 0 1 3 4 7 8 9 2 6]
 [0 2 9 7 4 6 6 5 3 1]]
tt_50sample [[7 1 0 2 6 3 4 8 5 9]
 [5 3 4 8 9 1 2 6 0 7]
 [5 8 0 4 3 7 2 6 1 9]
 [9 5 1 2 6 8 4 0 7 3]
 [7 0 3 6 2 8 1 5 9 4]
 [2 3 1 9 7 6 8 5 0 4]
 [7 6 1 2 3 0 9 5 4 8]
 [2 1 8 6 9 4 5 0 3 7]
 [5 0 1 3 4 8 7 9 2 6]
 [0 2 9 7 8 4 6 5 3 1]]
vm  [ 3.3  2.2  2.9 15.5 -0.7 -0.4 -0.  -0.1 -1.3 -0.4 -2.4 -0.  -0.5 -0.4 -2.4  3.6  0.4 -0.1 -0.4 -2.  -0.3 -0.   0.7  0.6 -0.9 -0.5  1.1 -0.4  1.3  4.8 -1.5 -0.8  1.1 -3.2 -0.8 -0.1  2.  -0.8  0.3 -0.3 -0.2 -0.6  2.2 -1.4 -0.2 -0.5 11.2  0.6  3.8  3.7 -0.5 -0.3 -0.1 -1.9 -1.   4.4 -0.3  4.6 -2.1  5.  -2.8 -0.8 -0.5 -0.6 -0.3 -0.6  0.4 -0.4 -0.1 -0.4 -0.6 -0.9 -0.5 -0.5  3.5  0.4 -0.6  0.2 -0.9 -0.3  3.   1.2 -0.9  0.4 -1.6 -0.4  2.9 -0.3  0.7 -1.  -0.2  2.4  0.8  5.7 -0.  -0.1 -0.2  1.4 -0.5 -0.4  2.8 -1.3 -1.5 -0.2 -0.4 -0.4  1.8 -1.2 -0.8 -2.4  0.7 -0.5 -0.3 -0.  -1.8  5.  -0.2 -1.  -0.1 -0.3 -0.   7.7 -0.6 -0.8 -0.  -2.8  1.5  8.9 -1.6 -0.2  2.3 -0.1  0.3 -0.5 10.8  4.6 -0.2 -0.3 -0.  -0.2 -0.3 -0.8  1.2 -0.1 -0.1 -0.3 -0.2 -0.3  3.8 -0.3 -1.6  0.1  5.7 -0.6 -0.3  0.4 -0.4 -0.9 -1.9 -0.5 -0.4  2.8 -0.1 -0.1  0.3  0.3 -0.2 -1.2 -0.5  0.8 -0.5 -0.5 -0.5 -0.2  0.  -0.6 -2.   1.9  0.  -0.3 -1.1 -0.2  1.4 -0.9 -1.3  1.6  6.4 -0.2 -0.5 -1.3 -0.1  0.3 -0.7 -1.1 15.4  3.8  3.5  3.3 -0.  -0.4  0.4 -0.4  1.4  0.  -0.9  5.7  0.  -0.7  4.4 -0.5 -0.3  1.7 -0.6 -1.1  0.6  0.5  6.2 -0.  -0.1 -0.5 -0.5 -0.4 -0.3 -0.5  0.8  3.9 -1.  -0.7 -0.5  2.1  1.1 -0.2 -0.5  2.8 -1.7 -0.2 -0.3  3.1 -0.4 10.3 -0.2  4.2 -0.2 -0.1 -0.2 -3.1  0.9 -0.5 -0.2 -0.1 -0.7 -0.3  0.3  0.9  2.9  3.6]
vy_50sample [[6 9 8 3 5 2 7 4 0 1]
 [1 8 2 2 9 0 0 3 6 5]
 [7 9 9 4 1 8 0 6 5 2]
 [4 7 8 9 1 5 6 3 2 0]
 [9 3 1 7 0 4 5 6 2 8]
 [4 1 7 5 9 8 2 0 3 6]
 [8 5 1 4 3 9 9 6 2 7]
 [5 4 0 3 1 9 7 2 6 8]
 [8 8 0 0 7 3 1 5 9 4]
 [9 9 8 5 6 1 2 0 7 3]]
vt_50sample [[6 9 8 3 5 2 7 4 0 1]
 [1 8 2 4 0 9 7 3 6 5]
 [7 3 9 4 1 8 0 6 5 2]
 [4 7 8 9 1 5 6 3 2 0]
 [9 3 1 7 0 4 5 6 2 8]
 [4 1 7 5 9 8 2 0 3 6]
 [8 5 1 4 3 9 0 6 2 7]
 [5 4 0 3 9 1 7 2 6 8]
 [8 6 2 0 7 3 1 5 9 4]
 [9 4 8 5 6 1 2 0 7 3]]
Epoch 20310: Training cost= 0.3526, Training acc= 0.8169, Validation cost= 0.2868, Validation acc= 0.8171
Epoch 20320: Training cost= 0.3747, Training acc= 0.8169, Validation cost= 0.2745, Validation acc= 0.8172
Epoch 20330: Training cost= 0.3702, Training acc= 0.8170, Validation cost= 0.3341, Validation acc= 0.8172
Epoch 20340: Training cost= 0.3217, Training acc= 0.8170, Validation cost= 0.3302, Validation acc= 0.8172
Epoch 20350: Training cost= 0.3900, Training acc= 0.8170, Validation cost= 0.3419, Validation acc= 0.8172
Epoch 20360: Training cost= 0.3206, Training acc= 0.8170, Validation cost= 0.3521, Validation acc= 0.8173
Epoch 20370: Training cost= 0.3163, Training acc= 0.8171, Validation cost= 0.3379, Validation acc= 0.8173
Epoch 20380: Training cost= 0.3854, Training acc= 0.8171, Validation cost= 0.2968, Validation acc= 0.8173
Epoch 20390: Training cost= 0.3417, Training acc= 0.8171, Validation cost= 0.2465, Validation acc= 0.8174
Epoch 20400: Training cost= 0.3523, Training acc= 0.8172, Validation cost= 0.3025, Validation acc= 0.8174
tm  [ 1.2 -0.9  1.6 -0.8 -1.4 -0.4 -0.1 -0.4  2.3  0.2 -2.5 -0.2 -0.9 -0.2  5.3 -0.9 -0.5 -0.7 -0.2  0.7 -0.5  0.   1.5 -0.5 -0.6  0.1 -0.2 -0.   0.1 -1.   1.2 -0.7 -0.4  2.7 -0.2 -1.  -0.9 -1.4 -1.6 -0.7 -0.5  5.2 -0.1 -0.1 -0.1  0.2 -1.7  1.3  5.5  4.3 -0.6 -0.2 -0.1 -0.4 -0.4 -0.5 -0.2  3.9  5.7  1.1 -0.2 -0.4 -0.4  3.3  0.5  1.   0.3  0.2  1.7  0.4 -0.3 -0.6 -0.3  0.3 -4.2  0.4 -1.6 -0.1 -0.1  0.1 -1.4 -0.1  0.7  0.7 -1.4  6.6  2.7 -0.3 -0.3 -0.2 -0.  -0.5 -0.5 -1.8 -0.5  0.9  0.5 -2.5 -0.4 -0.2 -0.3  4.1 -1.1 -0.1 -0.4  1.4 -1.2  0.5 -1.  -0.2 -0.1 -0.  -0.2 -1.1  3.4  3.4 -0.5  3.4 -0.4  0.5 -0.4 -0.   0.1 -0.2 -0.3  6.2 -0.1  4.9  7.4  0.6  4.3 -1.4 -0.1 -0.9  2.6  4.5 -0.1 -0.4 -0.5 -0.2  2.9 -0.4  2.9 -0.3 -0.3 -0.1  0.4 -0.4  3.3  0.4  2.5 -0.3  4.5  0.7 -0.4  0.5 -0.2 -0.5 -0.8 -0.5  0.3  0.7 -0.  -0.2 -0.2 -0.1 -0.3  0.2 -0.1 -0.2 -0.4  0.7 -0.6 -0.5 -0.3 -0.6 -1.  -0.2  4.8  0.3 -1.9 -0.4 -0.9 -1.7  0.6 -0.5  2.7 -0.6 -0.2  3.8  0.1 -0.1 -0.6 -0.6  3.7 -2.3 -0.6 -1.3  1.1 -0.3 -0.1 -0.1 -0.2 -0.6 -0.2 -2.4  0.6  0.2 -1.3 -0.2 -0.1  2.9 -0.9 -0.9 -1.  -0.2  2.  -0.3  0.5 -0.5 -1.5 -0.4  0.  -0.9  3.1  1.4 -1.9 -0.5  0.3  8.2 -0.4 -0.9 -0.1 -1.  -0.2  0.1  1.4 -0.8  4.9 -3.1 -0.1 -1.4  0.4 -0.1  6.1  1.5 -0.  -0.1 -1.3 -0.2  3.  -0.5 -1.1 -0.3  3.9  2. ]
ty_50sample [[5 6 7 8 4 0 3 9 1 2]
 [9 2 1 0 8 3 4 7 6 5]
 [6 0 7 2 9 3 8 4 1 5]
 [5 8 7 0 6 4 9 2 1 3]
 [5 7 6 2 8 0 9 4 1 3]
 [7 8 0 1 4 9 5 3 6 2]
 [6 7 5 1 9 0 2 3 4 8]
 [8 2 9 6 6 5 3 7 4 0]
 [2 1 8 9 7 5 4 3 0 6]
 [4 2 8 5 1 3 0 6 7 9]]
tt_50sample [[5 6 7 8 4 0 9 3 1 2]
 [2 9 1 0 8 3 4 7 6 5]
 [0 6 7 2 9 3 8 4 1 5]
 [5 8 7 0 6 4 9 2 1 3]
 [5 7 2 6 8 0 9 1 4 3]
 [7 8 0 1 4 9 5 3 6 2]
 [6 1 5 7 9 0 2 3 4 8]
 [8 2 9 6 1 5 7 3 4 0]
 [1 2 8 9 7 5 4 3 0 6]
 [4 2 8 5 1 3 0 6 7 9]]
vm  [-1.3 -0.3  9.9  3.4 -1.8 -0.2 -0.4 -0.1 -1.3 -0.6 -3.2  0.2 -0.3 -0.2 10.6 -1.7 -0.8 -0.3  0.8  0.9 -0.7 -0.3  1.1  0.  -1.1  2.2 -0.6 -0.3 -1.9 -0.8 -1.6  0.3 -0.4  4.3 -0.   1.1  4.  -0.6 -2.1 -0.8 -0.1 -0.8  0.3 -0.5 -0.5 -0.1 -1.4  0.8 -0.6  2.1 -0.8 -0.2 -1.3  1.2  0.8 -1.2 -1.4  3.6 -0.6  5.1  7.3  0.4 -0.9  1.5 -0.9  0.1 -0.2 -0.3  1.4  0.2 -0.1  4.8 -0.3 -0.5 -3.6 -0.1 -0.1 -0.2  0.5  1.  -3.5 -0.1 -0.4  1.3  0.6 -0.8 -1.  -0.1 -0.1 -0.4 -0.4 -0.2 -0.3  2.7 -0.1  1.1  1.7 -1.7 -0.4 -0.2  1.9  4.3  1.5 -0.3  1.1 -0.5 -2.4 -1.1 -0.9 -0.2 -0.4 -0.2 -0.  -0.2  3.2 -1.8 -0.1  0.4 -0.4 -0.5  0.3  1.  -0.7 -0.3 -0.2 12.3 -0.2  0.7 -0.5  8.6 -0.4 -0.2 -0.2 -0.2 -2.3 -0.5 -0.  -0.1 -0.2 -0.5  1.8 -1.1  0.1 -0.2 -0.1 -0.3 -0.6 -0.1 -1.6 -0.5 -0.9 -0.1  0.2 -0.2 -0.2 -0.1  1.5 -0.1 -0.2 -0.8 -0.5 -0.2 -0.2 -0.1 -0.7 -0.4 -0.4  0.3 -0.1 -0.5 -0.6 -0.1  0.2 -0.  -0.2  4.2 -0.9 -1.3  5.9 -0.4 -0.9 -0.5  0.5 -1.1  0.2 -0.1 -0.9 -0.6 -0.1  2.9 -0.5 -0.3  0.1 -0.9 -1.9  2.1 -1.8 -0.2 -0.2 -0.1  0.3 -0.6 -0.1 -0.8 -0.1 -4.  -0.2 -0.2  4.4 -0.5 -0.1 -2.2 -0.4  1.5 -0.3 -0.5  4.2 -0.7 -0.1 -0.1 -0.4  0.7 -0.3 -0.9 -0.2 -0.5 -1.  -0.3  2.  -0.3 -0.7  1.8 -0.2  2.7  4.3 -2.2  2.5 -1.7  1.2 -1.8  0.2 -0.7 -0.3 -0.  11.7  7.4  0.1  1.4 -0.5 -0.3  9.  -0.3 -1.5 -0.3  4.3 -1.8]
vy_50sample [[7 0 8 1 3 6 5 9 2 4]
 [1 3 5 9 6 0 8 7 2 4]
 [7 7 4 6 3 2 1 5 8 9]
 [4 2 0 8 7 9 5 6 1 3]
 [7 4 4 5 8 1 9 9 6 0]
 [5 0 7 8 1 2 9 6 4 3]
 [3 7 5 5 2 8 0 9 1 4]
 [2 0 6 1 7 8 4 5 3 9]
 [9 8 6 0 5 2 4 7 3 1]
 [0 3 4 6 1 2 8 7 9 5]]
vt_50sample [[7 0 1 3 8 6 5 9 2 4]
 [1 3 5 9 6 0 8 7 2 4]
 [0 7 4 6 3 2 1 5 8 9]
 [4 2 0 8 7 9 5 6 1 3]
 [7 3 4 5 8 1 9 2 6 0]
 [5 0 7 8 1 9 2 6 4 3]
 [3 7 5 6 2 8 0 9 1 4]
 [2 0 6 1 7 8 5 4 9 3]
 [9 8 6 0 5 2 4 7 3 1]
 [0 3 4 6 1 2 8 7 9 5]]
Epoch 20410: Training cost= 0.2538, Training acc= 0.8172, Validation cost= 0.2445, Validation acc= 0.8174
Epoch 20420: Training cost= 0.3010, Training acc= 0.8172, Validation cost= 0.3414, Validation acc= 0.8174
Epoch 20430: Training cost= 0.3021, Training acc= 0.8172, Validation cost= 0.3112, Validation acc= 0.8175
Epoch 20440: Training cost= 0.2715, Training acc= 0.8173, Validation cost= 0.3009, Validation acc= 0.8175
Epoch 20450: Training cost= 0.2365, Training acc= 0.8173, Validation cost= 0.2434, Validation acc= 0.8175
Epoch 20460: Training cost= 0.2864, Training acc= 0.8173, Validation cost= 0.3302, Validation acc= 0.8176
Epoch 20470: Training cost= 0.3939, Training acc= 0.8174, Validation cost= 0.3412, Validation acc= 0.8176
Epoch 20480: Training cost= 0.3260, Training acc= 0.8174, Validation cost= 0.3348, Validation acc= 0.8176
Epoch 20490: Training cost= 0.3791, Training acc= 0.8174, Validation cost= 0.3129, Validation acc= 0.8176
Epoch 20500: Training cost= 0.3627, Training acc= 0.8174, Validation cost= 0.3049, Validation acc= 0.8177
tm  [-1.  -0.3  4.6 -1.1 -1.  -0.2 -0.3 -0.4 -0.5  1.7 -2.7 -1.  -0.2  0.5  9.7 -0.4 -0.3 -0.6 -0.4  1.2 -0.8 -0.6  3.2 -0.1 -0.6 -0.1 -0.3  0.5 -1.   0.4 -1.4 -0.1 -0.5 -2.2  1.  -0.4  1.  -0.9 -3.9 -0.1 -0.4  2.  -0.4 -1.1 -0.5 -0.  -2.4 -0.3 -0.6 14.5 -0.7 -0.3 -1.3  7.7 -0.2 -1.1 -0.7 -0.2  2.1  5.6  7.   0.2 -0.2  1.2 -1.2 -0.4 -0.4 -0.1 -0.2 -0.4 -0.3  1.9 -0.3 -0.5 -5.4 -0.7  0.1  0.5  0.5 -0.2 -6.  -0.5 -0.3  1.2 -0.5  2.6 -0.5  0.9 -0.6 -0.1 -0.2 -0.3 -0.1 -0.3 -0.4 -0.2  0.5 -2.4 -0.1 -0.7 -0.8  6.6  1.5 -0.1 -0.3 -0.4 -2.6 -1.8 -1.2  0.4 -0.4  0.3 -0.4 -0.9  3.3 -0.9 -0.9  0.4 -0.3 -0.5 -0.4 -0.4 -0.  -0.2 -0.3 11.4 -0.6 -1.8 -0.1  0.7  1.5 -0.5 -0.5 -0.2  6.7 -0.5 -0.5 -0.3 -0.7  2.4 -0.2 -0.8 -0.2 -0.1 -0.1 -0.1 -0.3  0.5 -1.2  0.1  1.7 -0.3  2.4 -0.2 -0.3 -0.2 -0.2 -0.1 -1.7 -0.7 -0.1  3.9 -0.4 -0.2 -0.5 -0.1 -0.4  1.9  1.  -0.6 -0.2 -0.4 -0.1 -0.4 -0.3  3.1 -0.7 -1.3  9.5 -0.5  0.8  0.  -0.5 -0.6  0.3 -0.1 -1.  -0.9 -0.3  0.1 -0.3 -0.3 -0.1 -0.1 -2.1  0.4 -1.7 -0.4 -0.2 -0.4 -0.4  0.4 -0.5 -0.3  0.8 -4.4 -0.2  0.5 10.7  0.4 -0.1 -0.6 -0.9  2.3 -0.3 -0.5  5.7 -0.7 -0.5 -0.4 -0.3 -0.4 -0.2 -0.9  6.7  0.5 -0.5  0.9 -0.6  1.6  0.5  0.8 -0.2  5.8  2.4 -0.6  2.1 -2.1  1.8 -0.5 -0.3 -0.3  0.  -0.1 17.9  7.6 -0.5 -0.3 -0.9 -0.1 15.  -0.2 -2.7 -0.4 -0.6  1.1]
ty_50sample [[8 6 0 1 7 2 4 5 9 3]
 [8 8 1 7 0 3 4 6 9 9]
 [6 8 1 3 2 4 5 9 7 7]
 [2 9 4 6 0 8 1 3 5 5]
 [8 1 9 4 3 0 7 5 2 6]
 [7 1 5 0 3 9 8 6 2 4]
 [3 7 4 0 8 2 5 1 6 9]
 [7 3 8 1 2 5 9 0 6 4]
 [6 9 7 4 8 0 5 1 3 2]
 [8 6 7 7 0 5 2 2 9 9]]
tt_50sample [[8 6 0 1 7 2 4 5 3 9]
 [5 8 1 0 7 3 4 6 2 9]
 [6 8 1 3 2 4 5 9 0 7]
 [2 9 4 6 0 8 1 3 7 5]
 [8 1 4 9 3 0 7 5 2 6]
 [1 7 5 0 3 9 8 6 2 4]
 [3 7 4 8 0 2 5 1 6 9]
 [7 3 8 1 2 5 9 0 6 4]
 [6 9 7 4 0 8 5 1 3 2]
 [8 6 7 3 0 5 4 2 1 9]]
vm  [ 0.9  1.5  2.9 -1.4 -1.3 -0.4  0.4 -0.3 -1.2 -0.9  6.4  0.5 -0.1 -0.2  7.   2.4  1.8 -0.4 -0.1  1.4 -0.9 -0.6 -1.9 -0.5 -1.1  0.1  0.3 -0.4 -0.7  2.2  4.1 -0.3  0.5  9.3 -0.6  1.   2.4 -0.8 -3.5 -0.3 -0.4 -0.1  3.2 -1.  -0.2 -0.3 -2.2 -0.4  3.3 -4.  -0.5 -0.3 -0.5  6.1 -0.6 -0.7 -0.   4.4 -1.2 -1.7  1.4 -0.2 -0.5  0.2 -0.8 -0.3 -0.2 -0.3 -0.3  0.1 -0.5  0.4 -0.1 -0.  -4.6 -0.8 -0.8 -0.6 -0.6 -0.4  5.5 -0.4 -0.5 -0.5 -0.9  0.1  2.3 -0.1 -0.  -0.1 -0.8  0.2 -0.   3.9 -0.4 -0.2 -0.2 -1.8 -0.3 -0.4  4.7 -0.2 -0.5 -0.3 -0.6 -0.3 -2.1  2.9  0.2 -0.3 -0.3 -0.5 -0.3 -0.3 -0.7  3.5 -0.2 -0.5 -0.2 -0.2 -0.2  0.1  0.9 -0.3 -0.3  8.3  0.9 -1.2 -0.4 10.8  2.2 -0.5 -0.  -0.5  7.8 17.6 -0.4 -0.  -0.2 -0.3  0.2  1.2  0.6 -0.1 -0.2 -0.2 -0.3 -0.3  3.4  0.3  0.9 -0.3 -0.4 -0.2 -0.8 -0.1 -0.3 -0.2 -1.7  0.3 -0.4  3.3 -0.2 -0.2 -0.4 -0.3 -0.1 -0.6  0.8 -0.3 -0.3  0.6 -0.2 -0.5 -0.2 -0.3 -1.2 -1.2  8.3 -0.7 -1.9  0.3 -0.1 -1.2 -0.2 -0.2  0.9 -0.7 -0.5 -0.6 -0.3 -0.1  1.4 -0.9  0.8  2.3 -1.   1.8 -0.2 -0.2 -0.  -0.2  0.1 -0.5 -0.5 -2.9 -0.5 -0.3 -4.1 -0.3 -0.6  0.4 -0.7 -0.7  0.  -0.4  4.5 -0.6  0.4 -0.6 -0.5 -0.4 -0.1 -0.6  1.8 -0.7 -0.3 -0.6 -0.8  2.9  1.   0.7 -0.2 -2.8  0.3 -0.1 -0.6 -1.5  0.7 -3.2 -0.1 -1.6 -0.4 -0.2 -0.8  4.6 -0.7  0.3 -0.3 -0.5 -1.5 -0.4 -2.7 -0.2  3.2 -2.6]
vy_50sample [[6 3 5 7 2 4 0 9 9 8]
 [6 7 2 9 8 4 3 5 0 1]
 [5 2 4 0 1 7 6 9 8 3]
 [1 4 8 5 9 6 3 7 2 0]
 [6 3 7 8 0 9 1 4 2 5]
 [6 4 8 3 2 7 5 1 9 9]
 [5 6 1 4 4 0 8 3 9 2]
 [5 6 4 1 8 3 2 0 7 9]
 [5 1 4 0 8 6 9 2 3 7]
 [0 1 4 7 2 9 3 3 5 8]]
vt_50sample [[6 3 5 7 2 4 0 1 9 8]
 [6 7 2 9 8 4 3 5 0 1]
 [2 5 4 0 1 7 6 9 8 3]
 [1 4 8 5 9 6 3 7 2 0]
 [6 3 7 8 0 9 1 4 5 2]
 [6 4 8 3 2 7 5 1 0 9]
 [5 6 1 7 4 0 8 3 9 2]
 [6 5 4 1 8 3 2 0 7 9]
 [1 5 4 0 8 6 9 2 3 7]
 [0 1 4 7 2 6 9 3 8 5]]
Epoch 20510: Training cost= 0.2646, Training acc= 0.8175, Validation cost= 0.3517, Validation acc= 0.8177
Epoch 20520: Training cost= 0.3107, Training acc= 0.8175, Validation cost= 0.3057, Validation acc= 0.8177
Epoch 20530: Training cost= 0.3361, Training acc= 0.8175, Validation cost= 0.3365, Validation acc= 0.8178
Epoch 20540: Training cost= 0.2881, Training acc= 0.8176, Validation cost= 0.3025, Validation acc= 0.8178
Epoch 20550: Training cost= 0.2981, Training acc= 0.8176, Validation cost= 0.3508, Validation acc= 0.8178
Epoch 20560: Training cost= 0.3211, Training acc= 0.8176, Validation cost= 0.3096, Validation acc= 0.8178
Epoch 20570: Training cost= 0.3066, Training acc= 0.8176, Validation cost= 0.2605, Validation acc= 0.8179
Epoch 20580: Training cost= 0.3198, Training acc= 0.8177, Validation cost= 0.3113, Validation acc= 0.8179
Epoch 20590: Training cost= 0.2285, Training acc= 0.8177, Validation cost= 0.3665, Validation acc= 0.8179
Epoch 20600: Training cost= 0.3028, Training acc= 0.8177, Validation cost= 0.3220, Validation acc= 0.8179
tm  [-0.  -0.5  8.7  1.1 -2.1 -0.3 -0.  -0.1 -0.2 -0.4 -0.1  0.6 -1.  -0.2 10.3 -1.6 -0.1 -0.2 -0.6  2.2 -0.7 -0.3 -0.8  0.9 -1.2  3.3 -0.4  0.4 -1.6 -2.  -0.5 -0.3 -0.4  6.8 -0.  -0.5  0.9  0.1 -0.9 -0.6 -0.4 -0.6 -0.  -0.6 -0.5 -0.4 -1.9 -0.1  2.4 -1.8 -0.8  0.3  0.3  3.2  1.1 -1.2 -0.4  5.5  0.7  3.6  3.1 -0.3  1.3  1.9  0.1 -0.1  0.3 -0.1  0.1 -0.5 -0.4  4.8 -0.3 -0.4 -5.5 -0.1 -0.7  0.3 -0.7 -0.1 -1.3 -0.4  1.2 -0.2 -1.3 -0.7 -0.3 -0.1  0.3 -0.1 -0.3 -0.7  0.7  0.8 -0.4 -0.4  1.6 -1.9 -0.2 -0.4  0.6  0.  -0.7 -0.3 -0.5  0.5 -2.6 -0.3 -0.1  2.2  1.5  0.4 -0.2 -0.7  5.  -2.5 -0.6  2.5  0.8 -0.  -0.3 -1.4 -0.3  0.8 -0.  12.5 -0.4 -0.1  0.6  9.5  1.4 -0.3 -0.5  0.4 -2.2  1.5 -0.1 -0.2  1.1 -0.   0.8 -1.3  0.7 -0.  -0.2  0.6 -0.3 -0.4 -0.5 -0.3 -0.5 -0.1  2.1  1.9 -0.6 -0.1 -0.5 -0.3 -0.  -0.3 -0.4 -1.   0.8 -0.   1.  -0.5 -0.9 -0.4 -0.   0.  -0.4  0.  -0.1 -0.7 -0.1  2.7 -0.7 -0.7  3.4  0.7 -0.6 -0.2 -0.3 -1.6 -0.2 -0.5  0.6 -0.8  0.6  6.3 -0.1 -0.3 -0.1 -0.9 -0.3  0.2 -1.9 -1.  -0.2 -0.2 -0.3 -0.  -0.2 -0.3 -0.5 -2.6  0.1 -0.2 -0.2 -0.1 -0.3 -1.4 -0.2 -0.  -0.6  0.7  3.4 -0.5 -0.8 -0.5 -0.8 -0.6  0.3 -1.1 -0.6 -1.1 -1.7 -0.  -0.6  2.1 -0.7  1.6 -0.7 -0.4  1.6 -1.7  2.3 -2.1  1.5 -2.  -0.1 -0.9 -0.2 -0.3  5.7  2.4 -0.4 -0.3 -0.9 -0.3  2.5 -0.3 -0.5 -0.1  4.6 -2.7]
ty_50sample [[0 3 7 5 6 6 1 2 4 9]
 [8 1 4 3 9 7 0 0 6 2]
 [4 3 3 5 0 8 9 1 6 7]
 [3 2 7 4 5 8 0 1 9 6]
 [0 1 1 7 3 8 6 2 4 5]
 [7 9 8 5 6 3 2 0 1 4]
 [5 4 8 3 0 7 6 9 2 1]
 [2 1 9 5 6 7 4 0 3 8]
 [3 1 9 2 6 0 7 8 4 5]
 [5 7 8 1 4 6 2 9 0 3]]
tt_50sample [[0 3 7 5 6 8 1 2 4 9]
 [1 8 4 3 9 7 5 0 6 2]
 [4 2 3 5 0 8 9 6 1 7]
 [3 7 2 4 5 8 0 1 9 6]
 [0 1 9 7 3 8 6 2 4 5]
 [7 9 8 5 6 3 2 0 1 4]
 [5 4 8 3 0 7 6 9 2 1]
 [2 1 9 5 6 7 4 0 3 8]
 [3 1 9 2 6 0 7 4 8 5]
 [5 7 8 1 4 6 2 9 0 3]]
vm  [-1.6 -0.1 -3.1 -1.6 -0.4  0.6 -0.4 -0.3 -0.9 -1.   6.8 -0.3 -0.2 -0.2 -1.4  4.9  0.9 -0.1 -0.1 -0.3 -0.8 -0.4 -0.3 -0.1 -1.6  2.5 -0.2 -0.5 -0.5 -1.2  3.1 -0.3 -0.5 -2.1 -0.3  1.4  4.5  4.6  4.6 -0.5 -0.1 -0.4  0.4  4.7 -0.9  0.3 -0.2 -0.9 -1.6 -0.6 -0.4 -0.4 -0.4  6.6 -1.5  2.4 -0.8 -0.6 -0.1 -0.9  7.5 -0.1 -0.4 -0.4 -0.6 -0.2 -0.1  0.6 -0.6 -0.1 -0.1 -0.1 -0.  -0.1 -2.3 -0.3  2.7 -0.3  1.1 -0.   0.5 -0.2 -0.4 -0.3  2.7  0.3 -0.3 -0.2  1.  -0.6 -0.5 -0.1 -0.1  1.1 -0.7 -0.  -0.5 -1.2 -0.3 -0.3  3.8 -1.9  3.1 -0.1 -0.3 -0.1 -1.8  3.9  1.6 -1.2 -0.9 -0.3 -0.2 -0.  -0.2  2.7 -0.  -1.3 -0.1 -0.4 -0.   3.   0.1 -0.5 -0.4 -1.5  1.2 -1.6  0.7  3.5 -1.2 -0.4 -0.3  0.4  4.  -1.  -0.3 -0.1  0.8 -0.8 -0.7 -0.3 -1.  -0.2 -0.4 -0.3 -0.   0.5  4.7 -0.3  1.3 -0.3 -1.5 -0.5 -0.3 -0.3 -0.3 -0.2  2.8 -0.1 -0.4 -1.  -0.5 -0.  -0.7 -0.3  0.4  0.1 -0.1 -0.5 -0.  -0.3 -0.5 -0.1 -0.2 -1.4  0.2 -0.4 -0.2 -0.7 -1.1 -0.1 -0.  -1.4 -0.2 -0.3 -1.4  1.8 -0.4  4.3 -0.3 -0.4 -0.2 -1.2 -2.1  1.2 -0.4  2.1 -0.2 -0.1 -0.2 -0.3 -0.1 -0.5  0.6 -1.7 -0.3 -0.1 -0.6 -0.3 -0.4 -0.1 -0.6  7.3  0.2 -0.1 -1.5 -0.7 -0.5 -0.2  0.1 -0.  -0.2 -1.  -0.8  0.4  1.2  1.   0.1 -0.9 -1.1 -0.1 -0.3 -0.2  1.3  6.2 -0.4 -1.1 -0.5 -0.6 -0.2 -0.2 -0.5 -0.1  1.9  0.  -0.2  0.2 -0.5 -0.6 -0.5 -0.   2.9 -0.1 -0.5 -0.4]
vy_50sample [[1 2 4 3 5 0 8 9 6 7]
 [4 1 5 3 2 9 7 0 0 8]
 [3 1 4 7 6 0 2 8 9 5]
 [7 3 1 8 6 9 5 2 0 4]
 [6 4 1 7 5 0 3 3 9 2]
 [2 9 6 7 0 8 3 5 4 1]
 [0 2 6 4 8 5 3 9 1 7]
 [2 7 5 8 3 6 9 0 1 4]
 [6 8 1 3 9 7 0 4 5 2]
 [6 7 9 2 1 8 5 0 4 3]]
vt_50sample [[1 2 4 3 5 8 0 9 6 7]
 [4 1 5 3 9 2 7 0 6 8]
 [3 1 4 7 6 0 2 8 9 5]
 [7 3 1 8 6 5 9 2 0 4]
 [6 4 1 7 5 0 3 8 9 2]
 [2 9 6 7 0 8 3 5 4 1]
 [0 2 6 4 8 5 3 9 1 7]
 [2 7 5 8 3 6 0 9 1 4]
 [6 8 1 3 9 7 0 4 5 2]
 [6 7 9 2 1 8 0 5 4 3]]
Epoch 20610: Training cost= 0.4157, Training acc= 0.8177, Validation cost= 0.3239, Validation acc= 0.8180
Epoch 20620: Training cost= 0.3183, Training acc= 0.8178, Validation cost= 0.4005, Validation acc= 0.8180
Epoch 20630: Training cost= 0.3195, Training acc= 0.8178, Validation cost= 0.3178, Validation acc= 0.8180
Epoch 20640: Training cost= 0.3196, Training acc= 0.8178, Validation cost= 0.3082, Validation acc= 0.8180
Epoch 20650: Training cost= 0.2715, Training acc= 0.8178, Validation cost= 0.3315, Validation acc= 0.8181
Epoch 20660: Training cost= 0.3081, Training acc= 0.8179, Validation cost= 0.3313, Validation acc= 0.8181
Epoch 20670: Training cost= 0.3251, Training acc= 0.8179, Validation cost= 0.2677, Validation acc= 0.8181
Epoch 20680: Training cost= 0.2751, Training acc= 0.8179, Validation cost= 0.3531, Validation acc= 0.8182
Epoch 20690: Training cost= 0.2918, Training acc= 0.8180, Validation cost= 0.3273, Validation acc= 0.8182
Epoch 20700: Training cost= 0.3442, Training acc= 0.8180, Validation cost= 0.3275, Validation acc= 0.8182
tm  [-0.9 -0.1 -0.8 10.3 -0.7 -0.4 -0.2 -0.2 -0.5 -0.7 -1.1 -0.4 -0.4 -0.3 -2.6 -0.7 -0.5 -0.3 -0.3 -1.7 -0.7 -0.4 -0.4 -0.1 -0.9  1.7 -0.4 -0.  -0.8 -1.  -0.3 -0.  -0.2 -2.2 -0.2 -0.2  3.2 -1.1  1.4 -0.7 -0.2 -2.7 -0.9 -0.8 -0.4 -0.4 10.1  0.2 -0.8 -0.8 -0.8 -0.1  0.1 -1.8 -0.4  4.8 -0.4 -1.2 -0.1  2.3 -0.1 -0.2 -0.8 -0.3 -0.2  0.8 -0.3  0.5  0.6 -0.1  0.1  1.  -0.1 -0.7  4.4 -0.1 -0.2 -0.3  0.2  0.1  6.6 -0.1 -0.7  1.8  1.2 -2.8 -0.4 -0.1 -0.2 -0.2 -0.2 -0.2 -0.   0.2 -0.2 -0.1 -0.3 -0.3 -0.4 -0.4  2.  -2.1 -0.1 -0.1  0.4 -0.6 -0.4 -0.3 -0.3 -1.7 -0.4 -0.2  0.  -0.1  2.8 -0.8 -0.4 -0.2 -0.5 -0.3 -0.4  7.   0.2  0.  -0.2 -3.   0.4  9.2 -0.6  0.7  0.4 -0.5 -0.1 -0.3 11.3  6.8 -0.3  0.1  0.6 -0.9  0.8 -0.8 -0.2 -0.  -0.2 -0.3 -0.3 -0.1 -0.3 -0.5 -0.9 -0.1 -0.2 -0.1  0.7 -0.2  0.2 -0.1 -1.6 -0.7 -0.5  2.2 -0.3 -0.4 -0.3 -0.3  0.4  3.5 -0.3  0.9 -0.6 -0.5  0.5  0.  -0.4  2.  -1.2 -0.1  0.4  0.3  2.3 -0.4 -0.  -0.9 -0.1  0.8  0.6 -0.1  0.2  3.6 -0.4 -0.1 -1.3 -1.   3.3  1.7  0.6  0.1 -0.3 -0.1 -0.6 -0.3 -0.7 -0.5 -0.1 -0.1 -0.3  0.2  7.3  0.  -0.5 -0.3 -1.3  2.7 -0.6 -0.4  3.9 -0.6 -0.2  1.9 -0.9 -0.3  0.3 -0.8  0.8 -0.1 -1.1  1.4  1.1  0.5 -0.2 -0.6 -0.3  4.3  2.   1.9  1.9  2.2  1.1 17.1 -0.1  8.1 -0.2 -0.2 -0.9 -2.1  1.3 -0.2 -1.  -0.3 -1.9 -0.5  1.1 -0.5  4.6  1.8]
ty_50sample [[9 6 3 1 1 8 4 2 7 5]
 [4 7 2 6 1 0 3 9 8 5]
 [3 1 5 8 6 2 0 4 7 9]
 [4 1 5 6 0 2 3 7 9 8]
 [8 0 2 1 4 5 3 9 6 7]
 [2 6 7 3 9 5 0 4 1 8]
 [6 9 3 5 0 7 4 8 1 2]
 [8 7 2 6 0 1 3 9 4 5]
 [3 9 6 7 2 5 8 4 0 1]
 [1 2 4 0 7 8 5 3 9 6]]
tt_50sample [[9 6 3 0 1 8 4 2 7 5]
 [4 7 2 6 1 0 3 9 8 5]
 [3 1 5 8 6 2 0 4 7 9]
 [4 1 5 6 0 2 3 7 9 8]
 [8 0 2 1 4 5 3 9 6 7]
 [2 6 7 3 0 9 5 4 1 8]
 [6 9 3 5 0 7 4 8 1 2]
 [8 7 2 6 0 1 3 9 4 5]
 [3 9 6 7 2 5 8 4 0 1]
 [1 2 4 0 7 8 5 3 9 6]]
vm  [-1.1 -0.5 -0.9 -2.3 -1.9  0.2  0.2 -0.2 -0.4 -0.1  6.1 -0.6 -0.  -0.   5.5 -0.4  0.3 -0.4 -0.1 -0.8 -0.8 -0.4  1.1  0.6 -1.4  0.9 -0.3  0.9 -1.6 -1.2  4.9  0.2 -0.6  7.7  0.7  1.9  3.4  4.7  8.3 -0.4  0.1  2.8 -0.2  5.5 -0.8 -0.1  2.9 -0.3 -1.9  2.2 -1.  -0.  -1.   4.2 -0.5 -0.6 -0.7 -0.8  1.  -2.   7.  -0.1 -0.  -0.1  1.5 -0.7 -0.3 -0.  -0.2 -0.8 -0.2  4.2 -0.4 -0.7 -2.4 -0.7  3.2  0.4  0.1 -0.3  5.8 -0.5 -0.8 -0.2  0.9  2.9 -0.4 -0.1 -0.2 -0.1 -0.7 -0.5 -0.3 -0.3 -0.9 -0.4  0.9 -1.   0.3 -0.1  0.   5.1  1.6 -0.3 -0.4 -0.8 -2.4  4.1 -0.  -0.8 -0.4  0.1 -0.3 -0.3  4.2 -1.8 -0.6 -0.3 -0.1 -0.6 -0.3  2.2 -0.3 -0.3 -0.5  6.4 -0.3 -0.6  0.4 -0.5 -1.3 -0.4 -0.8  2.1 -4.3 -1.3 -0.4 -0.1  0.2 -0.9 -0.2 -0.6 -0.5 -0.1 -0.3 -0.2  0.1  0.9 -0.3 -0.5  0.3 -0.2 -1.7 -0.  -0.4 -0.3  0.4 -0.1  2.1 -0.1 -0.5 -1.7 -0.5 -0.3 -0.4 -0.2 -0.9  0.4 -0.5 -0.3  0.9 -0.1 -0.3 -0.3 -0.1  2.3  2.2 -0.8 -1.1 -0.3 -0.8 -0.2 -0.1 -1.2 -0.2 -0.8 -1.3 -0.8  0.4  3.  -0.6 -0.6 -0.5 -0.7 -1.8  3.8 -1.5 -0.4 -0.1 -0.1 -0.4 -0.3 -0.4 -0.1 -0.4 -2.1  0.2 -0.2 -1.2  0.8 -0.5 -1.4 -0.2  5.8  1.6 -0.2 -1.8 -0.6 -0.5 -0.3 -0.  -0.1 -0.1 -1.5 -0.2 -1.  -0.6  1.6 -1.  -0.7 -1.3  2.8 -0.5 -0.8  3.2  2.8  1.2 -1.4 -0.3 -0.1 -0.1 -0.1 -0.4 -0.2 -0.9  1.2 -0.5 -0.7 -0.6  0.7 -1.8 -0.4  6.1 -0.3 -0.8  4.7]
vy_50sample [[1 0 4 7 2 5 9 8 3 6]
 [2 2 1 4 7 9 3 8 0 5]
 [2 6 8 5 0 3 7 9 4 1]
 [6 2 3 4 1 9 7 0 8 5]
 [5 6 7 0 9 2 8 4 3 1]
 [6 7 3 5 8 1 0 2 9 4]
 [0 9 3 1 7 6 5 4 8 2]
 [8 7 3 0 6 2 1 1 4 5]
 [2 3 5 8 6 0 9 1 7 4]
 [8 4 9 6 2 3 0 0 5 1]]
vt_50sample [[1 0 4 2 7 5 9 8 3 6]
 [2 6 1 4 7 9 3 8 0 5]
 [2 6 8 5 0 3 7 4 9 1]
 [2 6 3 4 1 9 7 0 8 5]
 [5 6 0 7 9 2 8 4 3 1]
 [6 7 3 5 8 1 0 2 9 4]
 [0 9 3 1 7 6 5 4 8 2]
 [8 7 3 0 6 2 9 1 4 5]
 [2 3 5 8 6 0 9 1 7 4]
 [4 8 9 6 2 3 7 0 5 1]]
Epoch 20710: Training cost= 0.2649, Training acc= 0.8180, Validation cost= 0.3764, Validation acc= 0.8182
Epoch 20720: Training cost= 0.2852, Training acc= 0.8180, Validation cost= 0.3031, Validation acc= 0.8183
Epoch 20730: Training cost= 0.2501, Training acc= 0.8181, Validation cost= 0.2831, Validation acc= 0.8183
Epoch 20740: Training cost= 0.3234, Training acc= 0.8181, Validation cost= 0.2832, Validation acc= 0.8183
Epoch 20750: Training cost= 0.3051, Training acc= 0.8181, Validation cost= 0.2855, Validation acc= 0.8184
Epoch 20760: Training cost= 0.2826, Training acc= 0.8182, Validation cost= 0.2889, Validation acc= 0.8184
Epoch 20770: Training cost= 0.2850, Training acc= 0.8182, Validation cost= 0.3145, Validation acc= 0.8184
Epoch 20780: Training cost= 0.3003, Training acc= 0.8182, Validation cost= 0.3276, Validation acc= 0.8184
Epoch 20790: Training cost= 0.3459, Training acc= 0.8182, Validation cost= 0.3430, Validation acc= 0.8185
Epoch 20800: Training cost= 0.3273, Training acc= 0.8183, Validation cost= 0.2856, Validation acc= 0.8185
tm  [ 1.6  0.4 -0.4  2.5 -1.  -0.2 -0.3 -0.3 -0.9 -0.6 -4.6 -0.4 -0.6 -0.2 -0.5 -0.5 -0.1 -0.2 -0.4 -1.7 -0.7 -0.4  0.4 -0.  -0.5 -0.3 -0.1  0.9 -0.2 -0.  -0.6 -0.4 -0.2 -2.9 -0.  -0.1  1.   0.1  9.  -0.4 -0.6 -2.8 -0.5  3.2 -0.3 -0.2  7.9  1.6  4.2  4.2 -0.5 -0.1 -0.5 -1.5 -0.7  1.7 -0.3 -1.7 -0.1  3.  -1.9 -0.5 -0.7 -0.1 -0.6 -0.4 -0.3 -0.2 -0.2  0.  -0.1  0.  -0.2 -0.5 -0.4  0.9 -0.8 -0.2 -0.3 -0.2 -1.6 -0.3 -0.9  0.5 -1.7 -3.   4.5 -0.3 -0.   0.4  0.7 -0.1 -0.2  2.7 -0.2 -0.2 -0.6 -1.1 -0.2 -0.8  2.7 -1.5 -1.2 -0.3 -0.2 -0.5 -0.4 -1.  -1.6 -1.8  1.1 -0.1  0.2 -0.4  1.  -0.  -0.5  0.3 -0.5 -0.4 -0.4  7.2  0.1 -0.5 -0.3 -0.7 -0.2  8.3 -0.3  2.1  3.1 -0.4  0.1 -0.2 -1.  -4.6 -0.1 -0.3  0.6  2.6  0.2 -0.9 -0.   0.  -0.1  0.  -0.2 -0.  -1.1 -0.1 -0.4 -0.   6.4 -0.4 -0.1 -0.2 -0.3 -0.7 -0.3 -0.5 -0.4 -0.9 -0.5 -0.4 -0.2  1.5 -0.   1.2 -0.  -0.2 -0.4 -0.1 -0.4 -0.2 -0.4  3.3 -0.2 -0.3 -1.2  0.1  1.2 -0.4 -0.1 -0.5 -0.1  0.3  5.4 -0.7 -0.2  1.  -0.1  0.3 -1.2 -0.5 10.7  0.1  1.5 -0.1 -0.2 -0.2 -0.3 -0.1 -0.3 -0.3 -0.6 -0.5 -0.4 -0.2 11.1  0.1 -0.5 -0.  -0.9 -1.3  0.8 -0.1 -0.6 -0.2  0.  -0.4 -0.6 -0.3  0.1 -0.7 -1.1  1.1 -1.4 -0.6 -0.2  4.9 -1.1 -0.4 -0.3  6.2  0.   1.4  0.5  0.4  1.  15.4 -0.   7.1 -0.2  0.6  6.1 -1.7 -0.5 -1.  -0.8  0.2  3.  -0.4  6.6 -0.4  5.5 -0. ]
ty_50sample [[8 3 9 4 0 7 6 2 5 1]
 [3 2 4 8 7 9 1 6 5 0]
 [3 5 8 7 0 9 2 1 6 4]
 [4 9 6 7 3 1 5 2 8 0]
 [6 9 2 7 5 3 1 0 0 0]
 [8 3 6 9 2 7 5 1 4 0]
 [3 5 1 0 7 8 4 9 2 6]
 [1 7 4 0 6 9 9 2 3 8]
 [5 9 3 2 7 8 4 0 1 6]
 [9 5 7 4 8 0 1 3 2 6]]
tt_50sample [[8 3 9 4 0 7 6 2 5 1]
 [3 2 4 8 7 9 1 6 5 0]
 [3 5 8 7 0 9 2 1 6 4]
 [4 9 6 7 3 1 5 2 8 0]
 [6 9 2 7 5 3 1 4 0 8]
 [8 3 6 9 2 7 5 4 1 0]
 [3 5 1 0 7 8 9 4 2 6]
 [1 7 4 0 6 5 9 2 3 8]
 [5 9 3 2 7 8 4 0 1 6]
 [9 5 7 8 4 0 1 3 2 6]]
vm  [-0.1 -0.5 -1.6 -1.6 -0.2 -0.1 -0.5 -0.   0.5 -0.6 -1.1 -0.8 -0.   0.4  0.3  7.2 -0.2 -0.3 -0.3 -0.3 -0.5 -0.2  0.6 -0.4 -0.7 -0.5 -0.2 -0.1  3.4 -1.1 -1.1 -0.5 -0.2 -5.  -0.2 -0.5 -0.5  3.5 -0.4 -0.6 -0.3 -2.5 -1.2  1.8 -0.3 -0.6 -1.1 -0.8  1.4  5.1 -0.5 -0.3 -0.9  8.1 -1.6  0.8 -0.4 -1.3  5.5  3.8  1.1 -0.4 -0.2  0.8 -0.6 -0.5 -0.2  2.1 -0.3 -0.3 -0.2 -1.4 -0.3 -0.2 -4.5  0.8 -0.8 -0.2 -0.3 -0.1 -5.   0.4 -0.5  0.6 -1.2 -2.4  1.7 -0.2 -0.  -0.5  0.3 -0.4 -0.3 -0.2 -0.4 -0.2 -0.7 -2.3 -0.3 -1.   2.1 -2.1 -0.5 -0.   0.2 -0.3 -2.  -1.2 -0.3 -0.   0.5  0.4 -0.2 -0.8  0.5  8.1 -0.5  1.1 -0.2 -0.  -0.3 -0.4 -0.2 -0.4 -0.3  0.2 -0.2 -1.9  3.4  6.4  2.6 -0.6 -0.2 -0.5  4.8 -4.   0.2 -0.4 -0.1  2.7 -1.1 -0.5 -1.2 -0.1 -0.3  0.3 -0.5 -0.  -0.  -0.1  1.7 -0.2  3.3 -0.7 -0.3 -0.2 -0.5 -0.8 -0.1 -0.  -0.3 -0.9 -0.1 -0.4 -0.2 -0.4  1.   2.6  0.1 -0.4 -0.5 -0.4 -0.6 -0.3 -0.3  0.4 -0.4 -0.7  2.2 -0.4  2.  -0.5 -0.4 -0.6 -0.4  0.9  1.1 -0.1 -0.6  3.6 -0.  -0.2 -0.6 -0.6  0.4 -1.4 -1.  -0.4 -0.3 -0.2 -0.2 -0.1 -0.4 -0.5 -0.6 -3.  -0.4 -0.3 10.3 -0.  -0.5  4.8 -1.2 -0.3 -0.2 -0.3 -0.2 -0.5 -0.6 -0.1 -0.4 -0.4 -0.1 -1.  -0.7  2.8  0.2  1.6 -0.6  5.1 -0.8  1.4 -0.1  5.6 -0.9  3.6  1.  -1.8 -0.   3.7 -0.   2.3 -0.3 -0.2 15.4  0.9 -0.1 -0.7 -0.8 -0.3 12.4 -0.  -0.2 -0.1  0.1 -1.7]
vy_50sample [[8 2 3 4 6 1 9 7 5 0]
 [8 7 0 9 2 5 4 1 6 3]
 [2 4 4 0 6 1 7 8 5 9]
 [2 6 8 9 9 7 3 4 5 1]
 [3 8 2 1 0 5 7 9 4 6]
 [0 2 7 8 9 5 3 4 1 6]
 [6 5 0 9 3 1 4 8 7 2]
 [0 9 2 6 4 5 1 7 8 3]
 [9 1 8 8 7 5 2 3 6 4]
 [9 8 6 2 3 7 7 1 0 5]]
vt_50sample [[8 2 3 4 6 1 9 7 5 0]
 [8 7 0 2 9 5 4 1 6 3]
 [2 4 3 0 6 1 7 8 5 9]
 [2 6 8 0 9 7 3 4 5 1]
 [3 8 2 1 0 5 7 9 6 4]
 [0 2 7 8 9 5 3 4 1 6]
 [5 6 0 9 3 1 4 8 7 2]
 [0 2 9 6 4 5 1 7 8 3]
 [1 9 0 8 7 5 2 3 6 4]
 [9 8 6 2 3 7 4 1 0 5]]
Epoch 20810: Training cost= 0.3560, Training acc= 0.8183, Validation cost= 0.3253, Validation acc= 0.8185
Epoch 20820: Training cost= 0.3160, Training acc= 0.8183, Validation cost= 0.3495, Validation acc= 0.8185
Epoch 20830: Training cost= 0.2806, Training acc= 0.8183, Validation cost= 0.2944, Validation acc= 0.8186
Epoch 20840: Training cost= 0.2968, Training acc= 0.8184, Validation cost= 0.3449, Validation acc= 0.8186
Epoch 20850: Training cost= 0.2911, Training acc= 0.8184, Validation cost= 0.3282, Validation acc= 0.8186
Epoch 20860: Training cost= 0.3048, Training acc= 0.8184, Validation cost= 0.2988, Validation acc= 0.8187
Epoch 20870: Training cost= 0.3025, Training acc= 0.8185, Validation cost= 0.3710, Validation acc= 0.8187
Epoch 20880: Training cost= 0.3177, Training acc= 0.8185, Validation cost= 0.3225, Validation acc= 0.8187
Epoch 20890: Training cost= 0.3291, Training acc= 0.8185, Validation cost= 0.3305, Validation acc= 0.8188
Epoch 20900: Training cost= 0.2753, Training acc= 0.8185, Validation cost= 0.3266, Validation acc= 0.8188
tm  [ 0.1  0.7  2.3  2.  -2.1 -0.3  0.5 -0.3 -1.4 -0.6 -1.2 -0.  -0.4 -0.4  1.5 -1.6  0.3 -0.1 -0.  -0.8 -0.6 -0.3  1.8  1.9 -1.3  3.8 -0.4 -0.1 -2.   0.3  1.6 -0.  -0.7  4.7  0.7  2.   4.2  1.7 13.1 -0.5 -0.2  1.   3.7  5.7 -0.4  0.2  4.6  0.3  3.2  3.2 -0.8  0.1  1.6 -1.3  2.  -0.  -0.7 -0.5 -1.4 -0.4 -0.9 -0.1 -0.2  1.  -0.7 -0.1  0.4 -0.8  0.2  0.5 -0.3  5.   0.4 -0.3  1.7 -0.2  0.3 -0.2 -0.   0.4  6.2 -0.3 -0.1 -0.1 -0.7  1.2  3.6 -0.2  0.5 -0.1 -0.2 -0.2 -0.1  2.8 -0.1 -0.2  0.9 -0.3 -0.4  0.6  1.7  4.7 -0.7 -0.3 -0.2 -0.2  0.2  2.1 -0.3 -1.6 -0.9 -0.2 -0.   1.3  0.7 -2.1 -0.2 -0.8 -0.2 -0.6 -0.   6.  -0.5 -0.2 -0.2  1.1 -0.4  7.  -0.8 -0.7 -0.6  0.2 -0.3  0.1 -4.8 -3.1 -0.1 -0.3 -0.2 -0.6  2.2 -1.5  1.3 -0.  -0.1 -0.2  0.3 -0.4 -0.8 -0.1 -0.3 -0.2  3.   1.2 -0.3 -0.2 -0.1 -0.4  3.9 -0.3 -0.2 -1.6 -0.1  0.  -0.3 -0.5 -0.6 -1.  -0.2 -0.3  0.4 -0.2 -0.1 -0.2 -0.1  2.8  2.1  1.9 -2.  -0.4 -0.9 -0.3 -0.2 -1.3 -0.5 -0.4  2.1 -0.5  1.6 -0.3 -0.3 -0.5 -0.4 -1.   6.8  3.8  1.5  1.  -0.1  0.3  0.4 -0.3 -0.3 -0.1 -0.1  2.9 -0.2 -0.2  2.2 -0.4 -0.4 -1.9 -0.1  0.5 -0.2 -0.4 -1.6 -0.4 -0.3 -0.2 -0.3  0.1 -0.3 -0.7 -1.  -0.7 -1.3 -0.6 -0.1 -0.4 -0.5 -0.8 -0.1  1.9  4.  -0.   1.5  2.8  1.3  7.6 -0.1  2.8 -0.3 -0.4 -0.7 -1.9 -0.3 -0.1 -0.5 -0.4 -1.6 -0.1  9.6 -0.1  2.2  4.9]
ty_50sample [[0 7 9 4 8 5 3 1 2 6]
 [2 6 1 9 9 3 8 8 0 4]
 [3 2 0 5 4 6 8 9 7 1]
 [1 4 0 7 8 9 3 6 2 5]
 [3 0 6 4 5 2 1 7 8 9]
 [6 3 1 2 8 7 9 0 4 5]
 [6 6 4 9 9 1 0 7 5 8]
 [3 6 1 9 7 4 2 5 8 0]
 [7 4 4 0 6 8 3 2 1 5]
 [6 0 4 2 3 8 9 5 1 7]]
tt_50sample [[0 9 7 4 8 5 3 1 2 6]
 [2 6 1 9 3 7 5 8 0 4]
 [3 2 0 5 4 6 8 9 7 1]
 [1 4 0 7 8 9 3 6 2 5]
 [3 0 6 4 5 2 1 7 8 9]
 [6 3 1 2 8 7 9 0 4 5]
 [4 3 6 9 2 1 7 0 5 8]
 [3 1 6 9 7 4 2 5 8 0]
 [7 4 9 0 6 8 3 2 1 5]
 [6 0 4 2 3 8 9 5 1 7]]
vm  [-0.2  3.  -0.7 -1.1 -1.2 -0.  -0.1 -0.2 -1.7 -1.3 -2.6  0.9 -0.5 -0.2  1.8  1.8  0.1 -0.2  0.6 -0.5 -0.3 -0.1  1.3  1.5 -1.6  0.9  1.3 -0.4  0.   4.7  1.9 -0.3 -0.2 -0.4 -0.9  0.9  3.5  0.3  5.1 -0.4 -0.1  3.3  5.6  4.9 -0.3 -0.   0.7  0.8  0.8  3.5 -0.7 -0.1  0.8 -0.8 -1.2 -0.1 -0.5  2.4 -2.  -0.2  0.6 -0.4 -0.4 -0.6 -0.6 -0.3  0.3 -0.5 -0.1  0.5 -0.  -0.9  0.1 -0.2 -1.5 -0.3  0.4 -0.4 -0.2  0.8 -0.9 -0.2  0.4 -0.1 -0.3  5.   3.2 -0.1  1.3 -0.3  0.2  0.7 -0.2  4.1 -0.3 -0.2 -0.3 -0.7 -0.4 -0.1  5.5  1.7  0.3 -0.3  0.3 -0.2 -0.9  1.8 -0.9 -0.7 -0.6 -0.5 -0.1  0.3 -1.6  8.1 -0.3 -1.5 -0.1 -0.3 -0.   1.8 -0.3 -0.5 -0.2  2.3  1.6  5.2 -0.7  1.7 -0.1 -0.3  0.1 -0.2 -1.8 -2.2 -0.1 -0.2 -0.1 -0.5  2.1 -0.5  2.1 -0.1 -0.1 -0.2  0.3 -0.4  4.  -0.2 -0.  -0.1  2.7  0.5 -0.4 -0.2 -0.5 -0.1  2.1 -0.4 -0.6 -0.7 -0.4 -0.2 -0.5 -0.3  0.1 -0.9 -0.  -0.2  0.6  0.9 -0.3 -0.4 -0.  -0.6 -0.4 -0.1 -0.4 -0.5 -1.8 -0.4 -0.  -1.6 -0.9 -0.1  0.4 -0.5  0.1 -1.1 -0.3 -0.3  0.1 -1.4  1.8  3.5  0.8  3.7 -0.1 -0.3 -0.1 -0.3 -0.3 -0.4 -0.2 -0.6 -0.5 -0.4 -0.9 -0.2 -0.4  2.2 -0.1  2.1 -0.1 -0.6 -1.1 -0.3  0.3 -0.5 -0.6  0.8 -0.2 -0.6 -0.7  4.6 -1.3 -0.7 -0.1 -0.4 -0.6 -0.3 -0.1 -0.7 -0.4  2.5 -0.6 -0.   0.5 -2.  -0.1 -1.  -0.4 -0.4  4.5 -1.1 -0.5 -0.3 -0.2 -0.3  1.2 -0.1  3.2  0.3  3.7  1.3]
vy_50sample [[5 4 8 7 3 9 1 6 2 0]
 [3 4 0 7 8 5 1 2 6 9]
 [9 0 4 6 8 7 1 3 3 5]
 [3 5 6 9 7 2 4 8 0 1]
 [3 9 2 5 8 6 7 4 0 1]
 [6 9 7 5 1 4 2 8 0 3]
 [8 0 4 7 6 9 2 1 3 5]
 [3 2 4 5 1 7 0 8 9 6]
 [7 8 9 5 4 1 0 3 6 2]
 [9 1 4 8 0 6 3 2 5 7]]
vt_50sample [[5 4 8 7 3 9 1 6 2 0]
 [3 4 0 7 8 5 1 2 6 9]
 [9 4 0 6 8 7 1 2 3 5]
 [3 5 6 9 7 2 4 8 0 1]
 [3 9 2 5 8 6 7 4 0 1]
 [6 9 7 5 1 4 8 2 0 3]
 [8 0 4 6 7 9 2 1 3 5]
 [3 2 4 5 1 7 0 8 9 6]
 [7 8 9 5 4 1 0 3 6 2]
 [9 1 4 8 0 6 3 2 5 7]]
Epoch 20910: Training cost= 0.3112, Training acc= 0.8186, Validation cost= 0.3059, Validation acc= 0.8188
Epoch 20920: Training cost= 0.2562, Training acc= 0.8186, Validation cost= 0.3056, Validation acc= 0.8188
Epoch 20930: Training cost= 0.3226, Training acc= 0.8186, Validation cost= 0.2788, Validation acc= 0.8189
Epoch 20940: Training cost= 0.2964, Training acc= 0.8187, Validation cost= 0.3273, Validation acc= 0.8189
Epoch 20950: Training cost= 0.2846, Training acc= 0.8187, Validation cost= 0.2599, Validation acc= 0.8189
Epoch 20960: Training cost= 0.3315, Training acc= 0.8187, Validation cost= 0.2378, Validation acc= 0.8190
Epoch 20970: Training cost= 0.2875, Training acc= 0.8188, Validation cost= 0.3795, Validation acc= 0.8190
Epoch 20980: Training cost= 0.3139, Training acc= 0.8188, Validation cost= 0.3604, Validation acc= 0.8190
Epoch 20990: Training cost= 0.3649, Training acc= 0.8188, Validation cost= 0.2913, Validation acc= 0.8191
Epoch 21000: Training cost= 0.3380, Training acc= 0.8188, Validation cost= 0.2483, Validation acc= 0.8191
tm  [ 1.4 -0.3 -2.7 -2.8 -0.9 -0.3 -0.  -0.1 -0.1 -0.7  8.   0.  -0.3 -0.1 -0.3  4.6 -0.3 -0.2 -0.4 -0.5 -0.8 -0.2 -0.6 -0.4 -1.1 -0.2 -0.2 -0.1  1.  -1.   6.1 -0.9 -0.5  3.4 -0.  -0.2  0.1  5.1  7.5 -0.5 -0.4 -0.3 -0.2  6.6 -0.5 -0.1  1.6 -0.9  2.4 -1.9 -0.7 -0.2 -0.3  6.1 -1.7  1.2 -0.2 -1.   2.7 -2.5 -0.6 -0.7 -0.3 -0.2  1.5 -1.1 -0.1  3.1 -0.2 -0.7 -0.3 -0.9 -0.2 -0.2 -3.4  0.5 -0.8 -0.4 -0.3 -0.3  5.7 -0.4 -0.7 -0.4 -1.4 -0.2  5.4 -0.3  0.3 -0.5 -0.5 -0.4 -0.3 -0.3 -0.8 -0.3 -0.7 -1.4 -0.1 -0.3  2.3 -1.3 -1.3 -0.2 -0.2 -0.4 -2.   6.3  1.3 -1.  -0.3 -0.7 -0.1 -0.7 -0.   4.8  1.5  0.9 -0.3  1.2 -0.1  2.5 -0.3 -0.7 -0.5 -0.4 -0.1 -1.2  3.5  4.6  0.5 -0.7 -0.   0.1 -1.7 -1.1 -0.4 -0.4 -0.4 -0.8 -0.8  1.3 -0.5 -0.1 -0.3 -0.2 -0.3 -0.2  2.9 -0.7  1.6 -0.1  2.2 -0.8 -0.1 -0.2 -0.1 -0.   1.7 -0.5 -0.8 -2.1 -0.1 -0.1 -0.2 -0.3 -0.5  0.1 -0.5 -0.9 -0.2 -0.2 -0.7 -0.2  0.  -1.1  0.  -0.8 -0.9 -0.4 -1.3 -0.2 -0.2 -1.7 -0.3 -0.1  2.9 -0.3 -0.2  2.6 -0.3 -0.2 -1.  -1.3  5.3 -1.1 -0.8  0.2 -0.1 -0.3 -0.1 -0.4 -0.2 -0.2 -0.8 -1.8  0.2 -0.1 -2.2 -0.2 -0.5  2.1 -0.7 -0.7  2.6  0.9 -2.1 -0.6 -0.2 -0.1 -0.1 -0.5 -0.3 -1.1 -1.3  1.4 -0.2 -0.4  0.7  4.8 -1.4  1.2 -0.1 -1.4 -0.8  6.   0.8 -1.6 -0.4 -1.1  0.4 -0.6 -0.3 -0.3 -0.9 -0.5 -0.3 -0.5 -0.6 -0.2 -1.7  0.   6.  -0.2 -0.1 -0.9]
ty_50sample [[4 2 3 5 9 7 8 0 1 6]
 [3 2 5 9 0 7 8 4 6 1]
 [3 8 0 5 2 4 7 9 1 6]
 [8 2 5 6 4 3 0 9 7 1]
 [7 3 4 2 8 0 1 6 9 5]
 [5 3 6 2 2 0 1 8 7 4]
 [6 8 5 1 4 3 0 7 9 2]
 [2 0 8 6 1 4 9 3 5 7]
 [9 5 0 4 7 1 3 6 8 2]
 [7 2 9 3 4 5 0 1 6 6]]
tt_50sample [[4 2 3 5 9 7 8 0 1 6]
 [3 2 9 5 0 7 8 4 6 1]
 [3 8 0 5 2 4 7 1 9 6]
 [8 2 5 4 6 3 0 9 7 1]
 [7 3 4 2 8 0 1 6 9 5]
 [5 3 6 9 2 1 0 7 8 4]
 [6 8 5 1 4 3 0 7 9 2]
 [2 0 8 6 4 1 9 3 5 7]
 [9 5 0 4 7 1 3 6 8 2]
 [7 2 9 3 4 5 0 1 8 6]]
vm  [-0.4  0.1 -1.5 -0.3 -0.9 -0.4 -0.3 -0.2 -0.9 -0.4 -2.1 -0.2 -0.5 -0.2 -0.8  2.9  0.6 -0.  -0.4 -0.8 -0.6 -0.   2.5  0.8 -1.4  0.5 -0.5 -0.2  0.2  3.9 -0.3 -0.2  0.9 -3.1 -0.7 -0.   2.7 -0.7 -2.2 -0.5 -0.1  5.4  2.3 -0.5 -0.4 -0.5  0.5 -0.2  0.2 10.2 -0.6 -0.2 -0.5  0.1 -1.   2.1 -0.4  1.5 -0.9  1.8  0.9 -0.  -0.5 -0.3 -0.6 -0.4 -0.  -0.   0.5 -0.2 -0.2 -0.7 -0.3  0.  -2.6  0.3 -0.3 -0.  -0.1  0.1 -1.8  0.9  0.4  0.7 -0.5  7.2  1.9  0.9 -0.2 -0.5 -0.4 -0.  -0.   0.8 -0.1 -0.2  0.2 -1.  -0.5 -0.5  2.3  3.4 -0.3  0.3 -0.1 -0.3 -1.2 -0.2 -0.9 -0.6 -0.4 -0.  -0.1 -0.5 -0.7  5.5 -0.4 -1.  -0.1 -0.1 -0.1  0.7 -0.4 -0.3  0.4 -0.8  1.3  2.7 -0.4 -0.7  1.3 -0.5 -0.1 -0.4 12.2  6.1 -0.1 -0.1 -0.1 -0.2  0.7 -0.6  1.4 -0.3 -0.1 -0.1 -0.  -0.3  5.3 -0.1 -0.2  0.   2.5  0.3 -0.2 -0.1 -0.1 -0.4 -1.4 -0.7  0.3  3.4 -0.2 -0.   0.3 -0.4 -0.1 -0.4 -0.2 -0.   0.3 -0.1 -0.3 -0.1 -0.1 -1.  -1.5 -0.1  5.3 -0.3 -1.  -0.2  0.2 -0.9 -0.9  0.5  0.7 -0.1 -0.5 -0.9  0.5 -0.5 -0.2 -0.9  2.   1.8 -0.2  0.9 -0.1 -0.4 -0.4 -0.3 -0.1 -0.3 -0.1 -1.2  0.1 -0.1  2.1  0.2 -0.1  2.5 -0.7  2.9 -0.  -0.1  3.  -0.4 -0.1 -0.3 -0.7 -0.2 -0.3 -0.8  5.1  3.6 -1.1 -0.1 -0.5  0.4  1.2  0.8 -0.2  1.6 -0.5  3.9  0.1 -0.7  1.3 -1.1 -0.1 -0.4  0.1 -0.5  6.6 -1.  -0.1 -0.3 -0.8 -0.4  4.4 -0.3 -1.6 -0.1 -0.1  6.2]
vy_50sample [[6 8 5 4 9 1 2 0 7 3]
 [3 2 0 8 1 7 4 5 9 6]
 [3 2 9 6 4 8 7 0 1 5]
 [0 7 5 2 4 6 3 8 1 9]
 [9 7 3 0 0 6 1 4 5 2]
 [7 9 2 8 5 3 6 1 0 4]
 [0 7 9 6 5 2 8 3 1 4]
 [7 9 0 8 1 3 2 5 4 6]
 [3 6 2 7 8 1 1 9 5 0]
 [1 5 7 7 0 4 8 6 2 9]]
vt_50sample [[6 8 5 4 9 1 2 0 7 3]
 [3 2 0 8 1 7 4 5 9 6]
 [3 2 9 6 4 8 7 0 1 5]
 [0 7 5 2 4 6 3 8 1 9]
 [9 7 3 0 8 6 1 4 5 2]
 [7 9 2 8 5 3 6 1 0 4]
 [7 0 6 9 5 2 8 3 1 4]
 [7 9 0 8 1 3 2 5 4 6]
 [3 6 2 7 8 4 1 9 5 0]
 [5 1 3 7 0 4 8 6 2 9]]
Epoch 21010: Training cost= 0.3846, Training acc= 0.8189, Validation cost= 0.3719, Validation acc= 0.8191
Epoch 21020: Training cost= 0.2858, Training acc= 0.8189, Validation cost= 0.3202, Validation acc= 0.8191
Epoch 21030: Training cost= 0.3024, Training acc= 0.8189, Validation cost= 0.2807, Validation acc= 0.8192
Epoch 21040: Training cost= 0.3212, Training acc= 0.8190, Validation cost= 0.3257, Validation acc= 0.8192
Epoch 21050: Training cost= 0.2943, Training acc= 0.8190, Validation cost= 0.3028, Validation acc= 0.8192
Epoch 21060: Training cost= 0.3037, Training acc= 0.8190, Validation cost= 0.2742, Validation acc= 0.8193
Epoch 21070: Training cost= 0.3985, Training acc= 0.8190, Validation cost= 0.2901, Validation acc= 0.8193
Epoch 21080: Training cost= 0.3210, Training acc= 0.8191, Validation cost= 0.3283, Validation acc= 0.8193
Epoch 21090: Training cost= 0.3650, Training acc= 0.8191, Validation cost= 0.4026, Validation acc= 0.8193
Epoch 21100: Training cost= 0.2774, Training acc= 0.8191, Validation cost= 0.3142, Validation acc= 0.8194
tm  [-0.7 -0.  -1.3 -1.2 -1.2 -0.5 -0.5 -0.6 -1.2 -0.5 -2.1  2.5 -1.  -0.5  1.1 -2.1  1.2 -0.3 -0.4 -0.2 -0.4 -0.3 -0.8 -0.2 -1.1  2.5  0.5 -0.3 -1.2 -1.1  2.9 -0.6 -0.3  0.6 -0.1  0.3  4.4 -0.9 -0.4 -0.2 -0.3  2.9  3.5  1.6 -0.4  0.4 -1.2  1.9  1.6 -2.  -0.4 -0.4 -0.2 -1.3 -0.1 -0.1 -0.4  5.  -1.1 -0.8  2.7 -0.5 -0.1  0.3 -0.9 -0.3 -0.2 -0.5 -0.4  1.1 -0.2  4.2 -0.4 -0.1 -4.1 -0.5 -0.6 -0.5 -0.7  0.4  0.9 -0.5  0.3 -0.9 -0.7  2.6  2.2 -0.3  0.6 -0.2 -0.3 -0.3  0.   3.2 -0.4 -0.3 -0.2 -1.6 -0.4 -0.5  2.2 -1.7 -0.  -0.2 -0.5  3.3 -1.7  2.9 -0.8 -1.3 -0.4 -0.1 -0.4 -0.2  1.4 -1.4 -0.4 -0.2 -0.1 -0.3 -0.   3.  -0.3  0.8 -0.3  1.4 -0.1  7.1  0.8  7.8 -0.1 -0.1 -0.2 -0.1  4.5  4.1 -0.6  0.3  0.3 -0.4  3.2 -0.7  2.1 -0.3 -0.2 -0.1 -0.5 -0.6  7.4 -0.1  1.1  0.4 -0.2 -0.1 -0.7 -0.1 -1.   0.4 -0.1 -0.9 -0.7 -0.4  0.  -0.  -0.3  0.1 -0.7 -0.6 -0.1 -0.5 -0.4  0.9 -0.3 -0.6 -0.4 -1.8 -0.3 -0.6  2.9 -0.3 -2.2  0.5 -0.1 -1.4  0.5 -0.4 -0.1 -0.2 -0.3  3.3 -0.3 -0.1  0.4 -1.2 -0.1  2.4 -0.7  0.2 -0.5 -0.1 -0.   0.2  0.3 -0.3 -0.1 -1.6 -0.4 -0.5 -3.3 -0.4 -0.5 -1.4 -0.4  0.9  0.4 -0.3 -0.4 -0.4 -0.4 -0.7 -0.5 -0.  -0.1 -0.5 -0.7 -0.8 -1.9 -1.   0.4  0.3 -0.6  0.1 -0.3 -2.4  2.5  2.8 -0.2 -1.  -0.1 -3.5 -0.3 -1.6 -0.1 -0.   1.2  1.1 -0.7 -0.2 -0.6 -0.  -0.3 -0.4 -0.3 -0.2  6.5 -1.8]
ty_50sample [[5 3 0 4 6 1 8 7 9 2]
 [0 3 7 5 5 2 9 1 8 4]
 [5 4 2 0 8 3 6 7 9 1]
 [9 5 7 2 0 3 4 8 8 6]
 [8 4 7 5 9 2 1 3 0 6]
 [1 9 7 0 2 8 8 3 5 6]
 [4 4 1 8 6 9 2 0 5 3]
 [5 8 2 6 7 1 9 4 3 0]
 [4 8 2 7 3 6 9 1 0 5]
 [8 6 7 4 2 0 1 3 5 9]]
tt_50sample [[5 3 0 4 6 1 8 7 9 2]
 [0 3 7 5 6 2 9 1 8 4]
 [5 4 2 0 8 3 6 7 9 1]
 [9 5 7 2 3 0 4 1 8 6]
 [8 4 5 7 9 2 1 3 0 6]
 [1 9 7 0 2 4 8 3 6 5]
 [4 7 1 8 6 9 2 0 5 3]
 [5 8 2 6 7 9 1 4 3 0]
 [4 8 2 7 3 6 9 1 0 5]
 [8 6 7 4 2 0 1 3 5 9]]
vm  [ 0.2  0.2  0.1  1.3 -0.4  0.3 -0.1 -0.2 -0.6 -0.3  3.3 -0.6  0.7  0.3  0.8  7.  -0.2 -0.4  0.3 -1.1 -0.8 -0.2  1.6 -0.6 -0.8 -0.4 -0.2 -0.5  2.2  3.8  0.5 -0.3  2.1 -0.5 -0.3 -0.2  1.4 -0.3 -2.3 -0.6 -0.2 -1.4 -0.2 -0.6 -0.4 -0.   2.  -1.   1.2  5.2 -0.5 -0.4 -0.4  4.  -1.3  0.9 -0.3 -1.9  0.6  2.  -0.7 -0.1 -0.7  0.8 -0.2 -0.4 -0.1  0.5 -0.1 -0.3  0.1 -1.4 -0.   0.7 -2.1 -0.3 -0.7 -0.  -0.2 -0.  -0.5 -0.1 -0.7 -0.1 -1.  -1.5  3.  -0.  -0.  -0.7 -0.7  0.2 -0.1 -0.3 -0.2 -0.1 -0.6 -1.2 -0.2 -0.1  0.7  2.4 -0.5  0.   0.3 -0.3 -0.9  0.5  1.6 -1.3 -0.7 -0.5 -0.2 -0.6 -0.6  8.6 -0.3 -0.7  0.2 -0.  -0.1  3.7 -0.2 -0.8 -0.3  0.4  0.1 -0.9 -0.5 -0.2  2.9 -0.7 -0.1 -0.3  8.7  8.9 -0.3 -0.1 -0.5 -1.  -1.1 -0.2 -0.7 -0.2 -0.2  0.1 -0.5 -0.2 -1.6  0.1 -0.  -0.1  3.  -0.5 -0.  -0.1 -0.   0.  -1.9 -0.4 -0.2  3.4 -0.3 -0.1 -0.5 -0.1  0.7  1.4 -0.1 -0.1 -0.3 -0.7 -0.1 -0.1 -0.2  3.5 -1.3 -0.2  5.3 -0.8  1.5  0.3 -0.3 -0.4 -0.6 -0.1  2.9 -0.4 -0.4 -1.  -0.1 -0.4 -0.7 -0.8  5.5 -0.1 -0.2  0.5 -0.2 -0.  -0.1 -0.3 -0.2 -0.2 -0.4 -1.2 -0.5 -0.1  7.2 -0.1 -0.1  4.5 -1.3 -0.5 -0.1 -0.5  3.6 -0.6 -0.4 -0.  -0.5 -0.3  0.3 -0.8  3.   4.3  0.8  0.8 -0.1  3.3  2.5  0.6  0.7  4.5 -0.9  1.   0.4 -0.6  0.7 11.2 -0.2  5.4 -0.3 -0.2  3.2 -0.5 -0.3 -0.1 -0.8 -0.3  0.3 -0.3 -1.5 -0.1 -0.7  3.4]
vy_50sample [[6 2 8 8 9 7 3 1 0 5]
 [2 5 4 0 3 1 9 8 6 7]
 [6 2 3 0 7 9 8 4 1 5]
 [0 1 7 2 6 9 5 3 8 8]
 [0 8 4 9 6 3 3 2 5 7]
 [3 2 9 1 1 0 8 7 5 4]
 [0 1 4 6 7 2 5 9 8 3]
 [7 9 5 0 4 3 2 1 1 8]
 [4 7 5 3 6 2 9 9 8 8]
 [9 7 5 5 4 8 1 3 2 6]]
vt_50sample [[6 2 8 4 9 7 3 1 5 0]
 [2 5 4 0 3 1 9 8 6 7]
 [6 2 3 0 7 9 8 4 1 5]
 [0 1 7 2 6 9 5 4 3 8]
 [0 8 4 9 6 1 3 2 5 7]
 [3 2 9 6 1 0 8 7 5 4]
 [0 1 4 6 7 2 5 9 8 3]
 [7 9 5 0 4 3 2 6 1 8]
 [4 7 5 3 6 2 9 1 0 8]
 [9 7 5 0 4 8 3 1 2 6]]
Epoch 21110: Training cost= 0.2537, Training acc= 0.8191, Validation cost= 0.2915, Validation acc= 0.8194
Epoch 21120: Training cost= 0.2401, Training acc= 0.8192, Validation cost= 0.2857, Validation acc= 0.8194
Epoch 21130: Training cost= 0.3005, Training acc= 0.8192, Validation cost= 0.2618, Validation acc= 0.8195
Epoch 21140: Training cost= 0.2697, Training acc= 0.8192, Validation cost= 0.2678, Validation acc= 0.8195
Epoch 21150: Training cost= 0.2752, Training acc= 0.8193, Validation cost= 0.2402, Validation acc= 0.8195
Epoch 21160: Training cost= 0.2754, Training acc= 0.8193, Validation cost= 0.3347, Validation acc= 0.8195
Epoch 21170: Training cost= 0.3008, Training acc= 0.8193, Validation cost= 0.2951, Validation acc= 0.8196
Epoch 21180: Training cost= 0.3160, Training acc= 0.8194, Validation cost= 0.3542, Validation acc= 0.8196
Epoch 21190: Training cost= 0.3237, Training acc= 0.8194, Validation cost= 0.2840, Validation acc= 0.8196
Epoch 21200: Training cost= 0.3113, Training acc= 0.8194, Validation cost= 0.2729, Validation acc= 0.8197
tm  [-1.2 -0.8  3.5 -2.5 -1.6 -0.1 -0.5 -0.   2.7 -0.1  1.4  0.  -0.5 -0.5 10.8  0.1 -0.8 -0.2 -0.  -0.6 -0.7  0.2 -0.5 -0.4 -0.6 -0.3 -0.3 -0.2  1.  -0.6  6.2 -0.4  1.2 12.9 -0.5 -0.4 -0.4 -0.8 -1.9 -0.4  0.7 -1.4 -1.4  1.4 -0.4 -0.2 -0.   0.1 -1.5 -1.5 -1.2 -0.1 -0.9 -0.2 -1.6 -1.1 -1.  -1.6  5.  -2.   7.2 -0.3 -0.1 -0.1  4.3 -0.6 -0.1  1.2  0.3 -0.3 -0.3 -1.1 -0.6 -0.6 -4.1 -0.4  0.2  0.7 -0.1 -0.3  4.5 -0.1 -0.2  1.5  0.4 -1.  -0.3 -0.1 -0.2 -0.2 -0.5 -0.1 -0.6 -1.3 -0.4 -0.   0.3 -1.9 -0.  -0.2  1.7  5.3  2.1 -0.1  0.2 -0.6 -2.7  5.  -0.  -0.2 -0.1 -0.4 -0.2 -1.7  4.3  5.3 -0.   3.  -0.1 -0.6 -0.3 -0.2 -0.1 -0.4 -0.6 12.3  0.5  3.2  2.9  4.2 -0.3 -1.  -0.3 -0.4 -1.8 12.  -0.  -0.2 -0.3 -0.8  0.   1.8  0.4 -0.2 -0.2  0.1 -0.2 -0.3 -2.3 -0.3  1.8 -0.3 -1.7 -0.3 -0.2  0.3 -0.2 -0.5 -0.9 -0.6 -0.4 -0.2 -0.1 -0.3 -0.1 -0.1 -0.4  4.3 -0.5 -0.6 -0.4 -0.6 -0.2 -0.3 -0.3  5.6 -1.6 -1.3  5.1 -0.1  0.6 -0.3 -0.4 -1.3 -0.5 -0.3 -0.9 -0.9 -0.1  2.3 -0.5 -0.1 -0.8 -0.6 -2.  -0.6 -1.7 -1.1 -0.3 -0.1 -0.3 -0.3 -0.3 -0.5 -0.6 -3.5 -0.  -0.2  0.3 -0.4 -0.3  2.5 -0.5  3.8 -0.3 -0.1 -0.1 -0.9  0.8 -0.1 -0.6 -0.1  0.1 -1.1  1.1  0.5 -1.2  1.4 -0.7  1.9 -1.   3.3 -0.2 -0.  -0.7  0.   0.5 -2.1  1.5  3.3  0.2  1.7 -0.6 -0.2 -0.5  3.7 -0.3 -0.6 -0.9  0.3 -1.4 -0.2 -1.3 -0.5  3.3 -0.6]
ty_50sample [[7 1 4 6 3 9 0 5 2 8]
 [2 6 7 3 0 1 4 5 8 9]
 [4 3 1 7 0 2 8 6 9 5]
 [9 4 5 7 1 1 2 0 6 8]
 [2 0 9 7 4 5 6 3 1 1]
 [8 2 7 3 1 5 6 9 0 0]
 [5 2 7 7 4 3 9 1 0 8]
 [5 4 7 9 3 0 0 6 2 1]
 [1 0 5 7 4 3 9 6 8 2]
 [9 6 1 5 2 2 7 8 3 4]]
tt_50sample [[7 1 4 6 3 9 5 0 2 8]
 [2 6 7 3 0 1 4 5 8 9]
 [4 3 1 7 0 2 8 6 9 5]
 [9 4 5 7 1 3 2 0 6 8]
 [2 0 9 7 4 5 6 3 1 8]
 [8 2 7 3 1 5 6 9 4 0]
 [5 2 7 6 4 3 9 1 0 8]
 [5 4 7 9 3 0 8 6 2 1]
 [1 5 0 7 4 3 9 6 8 2]
 [9 6 1 0 5 2 7 8 3 4]]
vm  [-0.5 -0.  -2.8 -1.7 -0.7 -0.1 -0.2  0.1 -0.8 -0.1  6.3 -0.3 -0.  -0.4 -1.2  6.4  0.7  0.1 -0.1 -0.9 -0.8 -0.2  2.2  0.9 -1.5  1.1 -0.7 -0.6 -0.3  3.   2.2 -0.2  3.1 -2.4 -0.4 -0.   3.   2.6 -1.2 -0.4  0.9  3.4  0.7  1.7 -0.4 -0.6  2.4 -1.3 -0.  10.2 -0.4 -0.  -0.2  6.3 -1.1  2.4 -0.6 -1.4 -0.3 -0.8  0.  -0.1 -0.2 -0.7 -0.7 -0.6  0.1  0.2 -0.2 -0.1 -0.2 -0.6 -0.1  0.1 -2.8  1.5  0.8  0.3 -0.6 -0.4 -0.2 -0.3 -0.1 -0.6 -0.7  4.   2.6 -0.1 -0.1 -0.6 -0.9 -0.4  0.2  1.7 -0.3 -0.3 -0.2 -0.8 -0.5 -0.4 -0.1  3.1 -0.1  1.2 -0.1 -0.3 -1.4  3.7  2.3 -1.3 -0.6 -0.1 -0.1 -0.3 -0.4  2.6  2.  -1.2  0.   0.5 -0.4  1.5 -1.1 -0.4 -0.1 -1.6 -0.3 -1.4 -0.9 -2.  -0.1 -0.4 -0.5  1.4  9.5  5.9  0.3 -0.3 -0.2 -0.6 -1.3 -0.5 -1.1 -0.3 -0.3  0.1 -0.3 -0.4  2.3 -0.  -0.1 -0.1  1.6 -0.5 -0.4 -0.4 -0.5 -0.1 -0.5  0.1  0.2 -0.1 -0.  -0.1 -0.3 -0.4 -0.4 -0.5 -0.6 -0.5  0.7 -0.5 -0.4 -0.4 -0.1 -0.2 -1.7  0.2  3.3 -1.   0.2  1.   2.2 -0.8 -1.1 -0.3  0.6  0.7 -0.8 -0.7 -0.  -0.3  0.  -1.3  2.9  2.9 -0.4  1.1 -0.5 -0.2 -0.2 -0.3  0.6 -0.1 -0.8 -0.1 -0.4 -0.5  4.7  0.   2.1  0.4  0.1  2.2  2.1 -0.1 -0.4 -0.5 -0.6 -0.2  0.1  0.4 -0.7 -1.3  4.1  2.   0.7  1.  -0.1 -0.6 -0.2  2.  -0.3  3.2 -0.7  6.  -0.3 -1.3 -0.5  7.8 -0.2  3.3 -0.2 -0.1  2.5 -1.7 -0.  -0.4 -0.7  0.2 -0.  -0.1 -0.8  1.2 -1.6 10.5]
vy_50sample [[2 4 6 8 9 1 0 7 7 3]
 [6 9 8 0 2 4 7 5 3 1]
 [7 1 5 0 6 6 8 2 3 4]
 [3 2 5 5 4 7 9 8 0 1]
 [1 9 2 4 7 3 5 0 6 8]
 [2 3 7 1 8 0 9 5 6 4]
 [5 8 1 7 2 3 4 4 6 9]
 [9 2 4 5 3 7 6 8 1 0]
 [6 1 3 3 7 0 8 4 2 5]
 [8 3 4 6 2 9 9 5 7 0]]
vt_50sample [[4 2 6 8 9 1 0 5 7 3]
 [6 9 8 0 2 4 5 7 3 1]
 [7 1 5 0 9 6 8 2 3 4]
 [3 2 5 6 4 7 9 8 0 1]
 [1 9 2 4 7 3 5 0 6 8]
 [2 3 7 1 8 9 0 5 6 4]
 [5 8 7 1 2 3 4 0 6 9]
 [9 2 4 5 3 7 6 8 1 0]
 [6 1 9 3 7 0 8 4 2 5]
 [8 3 4 6 2 9 1 5 7 0]]
Epoch 21210: Training cost= 0.3139, Training acc= 0.8195, Validation cost= 0.3130, Validation acc= 0.8197
Epoch 21220: Training cost= 0.2763, Training acc= 0.8195, Validation cost= 0.2913, Validation acc= 0.8197
Epoch 21230: Training cost= 0.3645, Training acc= 0.8195, Validation cost= 0.2884, Validation acc= 0.8198
Epoch 21240: Training cost= 0.3851, Training acc= 0.8195, Validation cost= 0.2926, Validation acc= 0.8198
Epoch 21250: Training cost= 0.3648, Training acc= 0.8196, Validation cost= 0.2593, Validation acc= 0.8198
Epoch 21260: Training cost= 0.2912, Training acc= 0.8196, Validation cost= 0.3130, Validation acc= 0.8198
Epoch 21270: Training cost= 0.3045, Training acc= 0.8196, Validation cost= 0.2944, Validation acc= 0.8199
Epoch 21280: Training cost= 0.2922, Training acc= 0.8197, Validation cost= 0.2841, Validation acc= 0.8199
Epoch 21290: Training cost= 0.3092, Training acc= 0.8197, Validation cost= 0.3330, Validation acc= 0.8199
Epoch 21300: Training cost= 0.3408, Training acc= 0.8197, Validation cost= 0.2650, Validation acc= 0.8200
tm  [ 1.4  1.5  2.7  1.3 -1.1 -0.2 -0.  -0.4 -0.7 -0.9  4.5  0.2 -0.1 -0.1  2.4  7.3 -0.1 -0.4 -0.1 -0.2 -0.4 -0.1 -0.3 -0.3 -1.3  0.   0.9 -0.1  3.  -0.5 -0.1 -0.6 -0.4 -0.4 -0.7 -0.3  2.   3.7  1.4 -0.5 -0.1  1.7  2.8  0.7 -0.3 -0.3 -0.6 -0.8  2.5 -0.7 -0.7 -0.1 -0.1  7.2 -1.4 -0.1 -0.2  5.8 -0.3  2.9 -0.3 -0.5 -0.2  0.1 -0.2 -0.3  0.5 -0.1 -0.2 -0.1  0.3 -1.2 -0.1 -0.  -3.4 -0.  -1.  -0.3 -0.5 -0.1 -1.2 -0.1 -0.4 -0.2 -1.3  2.5  1.7 -0.3  1.  -0.4 -0.4 -0.1 -0.1  1.2 -0.4 -0.1 -0.2 -1.5 -0.3 -0.1  3.9 -1.  -1.1 -0.1 -0.1  0.4 -1.7 -0.2  1.4 -0.2 -0.1 -0.4 -0.4 -0.6 -1.4  9.7 -0.2 -0.6 -0.1  1.  -0.2 -0.1 -0.1 -0.6 -0.5  3.1  0.5 -1.7  1.9  6.3  1.1 -0.6 -0.2 -0.2 -0.7 -1.1 -0.3 -0.1 -0.2 -0.6 -0.9 -0.1 -0.3 -0.  -0.3  0.2 -0.3 -0.4  5.2 -0.2 -0.2 -0.2  4.1 -0.3 -0.4 -0.  -0.3  0.6  0.1 -0.7 -0.7 -1.  -0.  -0.1 -0.2 -0.  -0.1 -0.6 -0.2 -0.  -0.2  0.5 -0.4 -0.3 -0.2 -1.2 -0.4 -0.7  0.9 -0.5 -2.   0.5 -0.4 -1.6 -0.6 -0.1  2.6 -0.6 -0.1  1.8 -0.2 -0.2 -0.5 -1.   3.5 -0.6 -1.   1.3 -0.2 -0.4 -0.  -0.2 -0.6 -0.3 -0.7 -1.9 -0.3 -0.2 -1.7 -0.4 -0.3  4.6 -0.4 -0.7 -0.3 -0.   0.5 -0.5 -0.1 -0.2 -0.2 -0.5  0.7 -0.8 -0.9  4.3  1.   0.2 -0.2  3.9 -0.7  1.1 -0.2 -1.1 -1.  -0.1 -0.  -1.2 -0.  -3.2 -0.2 -1.4 -0.3 -0.1  5.1  0.2 -0.  -0.2 -0.6 -0.3  2.2 -0.3  1.  -0.   0.3 -1.4]
ty_50sample [[5 2 3 8 7 7 6 9 1 0]
 [8 8 3 4 6 7 1 2 5 9]
 [7 4 9 9 2 0 0 1 3 6]
 [3 2 8 0 6 1 1 5 4 7]
 [8 9 9 1 5 5 4 0 3 2]
 [2 4 0 1 6 3 5 8 7 9]
 [1 2 8 6 6 5 3 4 7 0]
 [3 3 4 5 0 6 2 7 9 8]
 [4 1 5 8 7 9 0 2 6 3]
 [1 7 8 8 6 0 2 3 5 4]]
tt_50sample [[5 2 3 8 7 6 4 9 1 0]
 [8 0 3 4 6 7 2 1 5 9]
 [7 4 9 8 5 2 0 1 3 6]
 [3 2 8 0 6 1 9 5 4 7]
 [8 9 6 7 1 5 0 4 3 2]
 [2 4 0 1 6 5 3 8 7 9]
 [1 2 8 9 6 5 3 4 7 0]
 [3 1 4 5 0 6 2 7 9 8]
 [4 1 5 8 7 9 0 2 6 3]
 [1 7 9 8 6 2 0 3 5 4]]
vm  [-0.8 -0.3  0.5  5.  -1.5  0.6 -0.1 -0.5  0.5 -0.8  6.6 -0.1  0.7 -0.5 -0.5  4.2 -0.6 -0.5  1.2 -1.2 -1.1 -0.1 -0.5 -0.7 -0.5  1.4 -0.5 -0.7  0.3  0.6  4.8 -0.3 -0.4 10.  -0.5  0.7  0.5  1.9  8.4 -0.8  1.2 -1.5 -0.7  4.7 -0.3 -0.   5.  -0.4  0.1 -1.6 -0.6 -0.4  0.9 -0.8 -1.1  1.4 -0.3 -2.4  3.  -2.  -0.2  0.5 -0.4  1.6 -0.3 -0.  -0.2 -0.1  0.9  1.   0.4 -1.2  0.3  1.5  3.6 -0.4 -0.2 -0.4  1.4  0.2 17.4  0.  -0.4 -0.1 -0.1 -1.1  1.7 -0.  -0.3 -0.7  0.9  0.4 -0.3 -1.5 -0.1  0.6 -0.8 -1.  -0.2 -0.   3.7  5.6  0.8  0.6  0.5 -0.   2.6  5.4  1.3 -2.  -1.4 -0.3 -0.1 -0.6  0.6  7.6  1.1 -0.2 -0.1 -0.6  0.2  8.3  0.6 -0.3  0.3 -0.6  0.5  5.7  3.  -0.9 -0.1 -0.7  0.3 -0.9 -2.4  6.3  0.  -0.2 -0.5 -0.6 -0.1  0.4 -0.3  0.4 -0.1 -0.1 -0.  -0.2 -2.5 -0.   0.2 -0.2 -1.1 -0.   1.3 -0.   1.2 -0.2  2.4 -0.1  1.  -0.4  0.3 -0.2 -0.4 -0.4  1.4  3.3 -0.  -0.2 -0.6 -0.8  0.3  0.2 -0.2  5.7 -0.1  2.1 -1.  -0.6  1.8 -0.3 -0.7 -1.2 -0.5  0.5  0.7 -0.1 -0.3  0.3 -0.1 -0.3 -0.9 -0.5  4.  -0.8  4.2 -0.  -0.1  0.2 -0.3 -0.3 -0.4 -1.   0.6  3.8 -0.5 -0.3  1.9 -0.4 -0.1  4.1 -1.5  3.7 -0.7 -0.4 -0.9 -0.6  1.3  1.2 -0.8  0.1 -0.5 -0.7 -0.1 -0.  -0.4  1.5 -0.3  1.4 -0.5 -1.9  1.4  1.9  0.3  1.4 -0.1  4.6  3.6 17.7 -0.2  8.2 -0.  -0.2 -3.6 -2.2 -0.2  1.8 -1.2 -1.  -4.3 -0.5  6.2 -0.2  0.4  6.2]
vy_50sample [[9 7 4 1 2 3 6 0 8 5]
 [2 4 3 6 9 7 8 1 5 0]
 [1 7 5 8 0 6 3 2 9 4]
 [0 4 9 8 3 1 2 7 5 6]
 [2 9 3 8 1 6 7 0 5 4]
 [6 4 3 1 2 9 8 0 5 7]
 [7 6 8 0 9 2 4 1 3 5]
 [1 3 6 8 0 4 2 7 9 5]
 [9 2 4 4 5 7 6 8 3 0]
 [8 5 9 7 0 1 2 3 4 6]]
vt_50sample [[9 7 4 1 2 3 6 0 8 5]
 [2 4 3 6 9 7 8 1 5 0]
 [1 7 5 8 0 6 3 2 9 4]
 [0 4 9 8 3 1 2 7 5 6]
 [2 9 3 8 6 1 7 0 5 4]
 [6 4 3 1 2 9 8 0 5 7]
 [7 6 8 0 9 2 4 1 3 5]
 [1 3 6 8 0 4 2 7 9 5]
 [9 2 1 4 7 5 6 8 3 0]
 [8 5 9 7 0 1 2 3 4 6]]
Epoch 21310: Training cost= 0.2790, Training acc= 0.8197, Validation cost= 0.3014, Validation acc= 0.8200
Epoch 21320: Training cost= 0.3115, Training acc= 0.8198, Validation cost= 0.2330, Validation acc= 0.8200
Epoch 21330: Training cost= 0.3066, Training acc= 0.8198, Validation cost= 0.2952, Validation acc= 0.8200
Epoch 21340: Training cost= 0.3138, Training acc= 0.8198, Validation cost= 0.3204, Validation acc= 0.8201
Epoch 21350: Training cost= 0.2926, Training acc= 0.8198, Validation cost= 0.2591, Validation acc= 0.8201
Epoch 21360: Training cost= 0.2635, Training acc= 0.8199, Validation cost= 0.3136, Validation acc= 0.8201
Epoch 21370: Training cost= 0.2380, Training acc= 0.8199, Validation cost= 0.3089, Validation acc= 0.8202
Epoch 21380: Training cost= 0.2968, Training acc= 0.8199, Validation cost= 0.3696, Validation acc= 0.8202
Epoch 21390: Training cost= 0.2862, Training acc= 0.8200, Validation cost= 0.2671, Validation acc= 0.8202
Epoch 21400: Training cost= 0.2464, Training acc= 0.8200, Validation cost= 0.2959, Validation acc= 0.8202
tm  [-0.6 -0.1  7.1  1.2 -1.3  0.4 -0.2 -0.4 -0.1 -0.1 12.  -0.8  1.6 -0.1 10.   3.   0.3 -0.3 -0.2  0.9 -1.1 -0.3 -1.  -0.1 -0.7 -0.  -0.5 -0.3 -1.5 -1.1  1.2 -0.3  1.1  9.8  1.9  0.1  1.8  2.6 -3.3 -0.2  0.6 -1.4 -0.7 -1.1 -0.4 -0.2 -1.8 -1.3  0.6 -2.1 -0.3 -0.3 -1.3 13.  -0.  -1.  -0.9 -0.4  3.4  0.   4.5  0.6 -0.1  2.7  0.7 -0.7 -0.1  0.4 -0.4 -0.3 -0.5  1.9 -0.7 -0.3 -5.1 -0.8 -0.6 -0.1 -0.1 -0.3  2.5  1.2 -0.6 -0.2 -0.8 -1.6 -0.2  0.6 -0.4  0.  -0.3 -0.5 -0.2 -0.  -0.5  0.1 -0.1 -2.1  1.1 -0.   0.3  3.3  0.3 -0.3 -0.3 -0.4 -2.8  0.9  0.8 -0.1 -0.2  0.2 -0.2 -0.8  4.7 -1.3 -0.4  1.5 -0.  -0.4 -0.1  0.1 -0.1 -0.2 -0.2 11.3 -0.6 -3.7  0.4  5.7  1.6 -0.4 -0.1  1.9  3.8 15.2 -0.6 -0.1 -0.5 -0.2 -0.9 -0.1 -1.4 -0.2 -0.1 -0.2 -0.5 -0.  -1.9 -0.3 -0.3 -0.3 -0.7 -0.9 -0.5  0.7  0.1 -0.3 -1.3 -0.6 -0.4  1.7 -0.1  0.2  0.2  0.1 -0.6  0.5  1.3 -0.4 -0.5 -0.5  0.4 -0.1 -0.   5.6 -1.3 -1.3  8.6 -0.4  0.1 -0.4 -0.3 -0.9 -0.1 -0.6 -0.1 -0.9 -0.3  3.7 -0.2 -0.5  0.3 -0.4 -1.  -0.3 -1.8 -1.  -0.  -0.1  0.2 -0.  -0.3 -0.4 -0.3 -3.8 -0.4 -0.1  1.   1.2 -0.6 -1.1 -0.5 -0.  -0.5 -0.2  5.8 -1.1 -0.7  0.2  0.3 -0.2  0.3 -1.1  2.4 -1.   4.1  2.1 -1.2  3.1 -0.5  2.4 -0.1  0.3  1.7 -1.2  2.2 -2.2 -0.1  1.4 -0.3  1.3 -0.3 -0.3  0.2  6.6 -0.4 -0.3 -0.7 -0.3 -0.8 -0.2 -2.4 -0.1 -0.9 -1.5]
ty_50sample [[2 6 0 7 3 1 4 9 5 8]
 [3 6 5 4 2 1 7 9 8 8]
 [6 3 8 5 9 7 4 0 2 1]
 [2 9 0 8 6 4 1 5 7 3]
 [9 6 3 4 8 2 1 0 7 5]
 [6 6 7 3 0 8 1 4 2 5]
 [3 2 5 1 6 8 8 7 0 4]
 [1 9 6 6 7 4 0 8 5 3]
 [7 1 9 5 5 6 4 3 8 0]
 [3 0 8 5 7 4 1 6 9 2]]
tt_50sample [[2 6 0 7 3 1 9 4 5 8]
 [3 6 5 4 2 1 7 9 0 8]
 [6 3 8 5 9 7 4 0 2 1]
 [2 9 8 0 6 4 1 5 7 3]
 [9 6 3 4 8 2 1 0 7 5]
 [9 6 7 3 0 8 1 2 4 5]
 [3 2 5 1 6 9 8 7 0 4]
 [1 9 2 6 7 4 0 8 5 3]
 [7 1 9 5 2 6 4 3 8 0]
 [3 0 8 5 7 4 1 6 9 2]]
vm  [-0.9 -1.  -0.7 -0.2 -1.1 -0.2 -0.2 -0.4  1.5  0.5 -0.2 -0.3 -0.2 -0.2 -0.  -0.4 -0.4 -0.4 -0.1  1.4 -1.  -0.2  2.3 -0.2 -0.8  2.7 -0.1 -0.2 -0.9 -2.7 -0.2 -0.3 -0.8 -2.5  0.1 -0.3  0.3  4.7  5.1 -0.5  0.3  5.9 -0.2  3.6 -0.5  0.1 -1.7 -0.5  0.7  6.8 -0.7 -0.3 -0.1  3.8  0.5  1.2 -0.6  4.9  5.6  3.   4.1 -0.3  1.4  3.4 -1.  -0.4  0.5  0.8 -0.1 -0.1  0.4  2.3  0.1  1.  -4.3 -0.3 -0.5 -0.6 -0.3  0.3 -2.1 -0.3  1.  -0.3 -0.4  6.8 -0.4 -0.2 -0.6 -0.2 -0.2 -0.9 -0.5 -1.1 -0.4 -0.4  0.6 -2.4 -0.   0.2 -0.5  0.6 -0.1 -0.3 -0.2  0.2 -1.5 -0.6  0.  -0.3 -0.6 -0.3 -0.1 -1.   5.8 -1.3 -0.1  1.5 -0.3  0.6  0.6 -0.2 -0.1 -0.3 -0.1  0.1 -0.5 -0.4  7.5  1.  -0.8 -0.5 -0.4 -0.4 -1.1 -4.1 -0.   0.1 -0.2 -0.5  0.5 -0.9 -0.4 -0.1 -0.1 -0.2 -0.2 -0.2  6.3 -0.2  1.2 -0.2  1.8  0.5 -0.3 -0.1 -0.4 -0.1  5.4  0.1  1.3 -1.7 -0.2 -0.5 -0.2 -0.6 -0.2  0.4  0.2 -0.   0.1  0.2 -0.1 -0.2 -0.3 -1.4  2.1 -0.2 -0.5 -0.5 -1.7 -0.1 -0.6 -1.   0.1 -0.2 -0.4 -0.1 -0.1  8.6 -0.2 -0.2 -0.3 -0.6 -0.8 -1.7 -1.1 -0.9  0.4  0.6 -0.1 -0.1 -0.3 -0.4 -0.4 -2.  -0.3 -0.  -1.2 -0.1 -0.4 -0.7 -0.7  2.7 -0.8 -0.6 -0.9 -0.7 -0.4 -0.1 -0.5 -0.4 -0.  -0.8 -0.5 -0.3 -0.7  2.1 -0.2  1.8 -0.3 -0.5 -0.2 -0.9  2.5  3.2  2.2 -1.   3.  -3.4 -0.1 -1.4 -0.2 -0.3  8.   0.8 -0.1 -0.  -1.3 -0.   4.6 -0.2  3.6  0.2 -0.2  2. ]
vy_50sample [[5 0 8 1 2 4 9 3 7 6]
 [1 9 5 5 8 4 7 3 2 6]
 [5 8 9 2 6 1 3 4 7 0]
 [0 6 8 4 5 3 2 9 7 1]
 [4 9 0 8 1 7 5 3 6 2]
 [1 4 0 2 3 3 7 5 6 9]
 [1 4 5 3 3 9 7 2 8 8]
 [2 5 8 6 4 9 3 7 0 1]
 [1 8 4 3 3 9 2 7 0 5]
 [5 9 7 4 1 3 8 0 2 6]]
vt_50sample [[5 0 8 1 2 4 3 9 7 6]
 [1 9 5 0 8 4 7 3 2 6]
 [5 8 9 2 6 1 3 4 7 0]
 [0 8 6 4 5 3 2 9 7 1]
 [4 9 0 1 8 7 5 3 6 2]
 [1 4 0 8 2 3 7 5 6 9]
 [1 4 5 3 6 9 7 2 8 0]
 [2 5 8 6 4 9 3 7 0 1]
 [8 1 4 6 3 9 2 7 0 5]
 [5 9 7 4 1 3 8 0 2 6]]
Epoch 21410: Training cost= 0.2766, Training acc= 0.8200, Validation cost= 0.2994, Validation acc= 0.8203
Epoch 21420: Training cost= 0.2806, Training acc= 0.8200, Validation cost= 0.2795, Validation acc= 0.8203
Epoch 21430: Training cost= 0.2859, Training acc= 0.8201, Validation cost= 0.3007, Validation acc= 0.8203
Epoch 21440: Training cost= 0.2829, Training acc= 0.8201, Validation cost= 0.3116, Validation acc= 0.8204
Epoch 21450: Training cost= 0.2949, Training acc= 0.8201, Validation cost= 0.4154, Validation acc= 0.8204
Epoch 21460: Training cost= 0.3617, Training acc= 0.8202, Validation cost= 0.2652, Validation acc= 0.8204
Epoch 21470: Training cost= 0.2781, Training acc= 0.8202, Validation cost= 0.3266, Validation acc= 0.8204
Epoch 21480: Training cost= 0.3099, Training acc= 0.8202, Validation cost= 0.3905, Validation acc= 0.8205
Epoch 21490: Training cost= 0.3689, Training acc= 0.8202, Validation cost= 0.2617, Validation acc= 0.8205
Epoch 21500: Training cost= 0.3545, Training acc= 0.8203, Validation cost= 0.2891, Validation acc= 0.8205
tm  [-0.8 -0.9  3.7 -0.6 -1.9 -0.3 -0.4 -0.3  0.4  0.9  2.2 -0.3 -0.6 -0.5  6.6 -1.3 -0.3 -0.4  0.4 -0.3 -0.6 -0.2  1.4 -0.3 -1.   1.7  0.2  0.1 -1.  -1.4  3.  -0.3 -0.4  7.9 -0.1 -0.3  1.   0.1  0.5 -0.3 -0.4  8.   0.3  1.6 -0.7 -0.3 -0.6  0.6 -0.5  3.4 -0.6 -0.1 -0.4  0.7 -0.2 -0.7 -0.8  5.3  2.5 -0.7  4.9 -0.5  0.4  1.2  2.  -0.6 -0.2  0.4  0.1 -0.4  0.2  2.4 -0.4 -0.4 -4.4 -0.5 -0.2 -0.3 -0.3 -0.4  3.3 -0.3 -0.1 -0.2 -0.4  7.8 -0.4 -0.3 -0.7 -0.2 -0.4 -0.5 -0.4 -0.7 -0.4 -0.3  0.2 -1.8 -0.2 -0.4 -0.4  6.9  0.2 -0.3 -0.4  0.3 -2.1  2.7  1.1 -0.6  0.5 -0.2 -0.2 -0.9  5.2 -1.4 -0.5  1.1 -0.4  0.4 -0.3  0.3 -0.3  0.3 -0.3  7.8 -0.6  2.3  4.3 -0.5 -0.5 -0.5 -0.5 -0.3 -2.6  3.8 -0.   0.1 -0.1 -0.7  0.6 -0.5  0.6 -0.1 -0.3 -0.  -0.3 -0.2  3.6 -0.3  0.7 -0.2 -1.2  0.  -0.4 -0.1 -0.3 -0.4  0.8 -0.4 -0.2 -1.  -0.1 -0.2 -0.1 -0.4 -0.6 -0.1 -0.2 -0.2  0.1  1.7 -0.1 -0.2 -0.3 -0.5 -0.7 -0.9  1.1 -0.  -1.9 -0.  -0.2 -1.3  0.4 -0.3 -0.4 -0.8  0.3  4.1 -0.  -0.3 -0.5 -0.5 -1.1 -0.4 -1.5 -0.8 -0.2  0.   0.3 -0.3 -0.3 -0.2 -0.2 -2.4 -0.2 -0.4 -4.5 -0.  -0.3 -1.  -0.6  3.1 -0.4 -0.4 -0.2 -0.6 -0.4 -0.4 -0.4 -0.3  0.7 -0.8  1.9 -1.1 -1.5 -0.  -0.5  0.3 -0.7  1.4 -0.3 -3.   0.8 -0.6  2.1 -1.5  0.6 -4.1  0.2 -1.9 -0.5 -0.1 -0.2  0.7 -0.2 -0.6 -0.7  1.7 -1.  -0.2  0.5 -0.2  0.5  4.8]
ty_50sample [[5 0 7 7 4 9 6 2 8 3]
 [2 3 5 4 1 0 8 6 9 7]
 [4 6 8 3 5 7 2 0 1 1]
 [2 4 8 0 9 9 1 5 6 3]
 [6 1 9 3 4 0 8 7 5 2]
 [4 1 3 2 9 0 8 6 5 7]
 [0 9 3 5 7 6 4 1 2 8]
 [9 7 2 5 3 1 4 8 6 0]
 [7 9 4 5 1 2 3 0 6 8]
 [2 5 4 9 6 0 7 3 8 1]]
tt_50sample [[5 0 7 1 4 6 9 2 8 3]
 [2 3 5 4 1 0 8 6 9 7]
 [4 6 8 3 5 7 2 0 9 1]
 [2 4 8 7 9 0 5 1 6 3]
 [6 1 9 3 4 0 8 7 5 2]
 [4 1 3 2 9 0 8 6 5 7]
 [0 9 3 5 7 6 4 1 2 8]
 [9 7 2 3 5 1 8 4 6 0]
 [7 9 4 5 1 2 3 0 6 8]
 [2 5 4 9 6 0 7 3 8 1]]
vm  [-0.7 -1.6  4.9 -1.6 -2.3 -0.4 -0.6 -0.   2.1  2.6 -0.9 -0.2 -0.6 -0.7 11.6 -1.9 -0.1 -0.1 -0.7 -0.2 -0.6  0.1  1.9 -0.  -0.8  1.4 -0.3 -0.2 -1.1 -1.7  2.7 -0.1 -0.2 10.3  0.7 -0.4 -0.2  1.5  5.3 -0.3  1.3  2.6 -1.   5.  -0.5 -0.2 -0.5  0.2 -0.4  4.5 -0.6 -0.3 -0.3 -0.1  0.8 -1.5 -1.2 -1.   6.7 -1.   4.4 -0.4  2.9  0.4 -0.1 -0.9 -0.   0.9 -0.2 -0.3 -0.2  1.8 -0.7 -0.4 -5.  -0.4 -0.   1.  -0.4 -0.6  0.1 -0.  -0.2 -0.3 -0.7  1.7 -0.1 -0.2 -0.6 -0.6 -0.5 -1.  -0.4 -1.6 -0.1 -0.4  0.7 -1.9 -0.2  0.4 -1.4  9.  -0.1 -0.3 -0.4 -0.2 -2.2  2.5 -0.2 -0.8  0.5 -0.1 -0.4 -1.   8.3 -2.2 -0.   4.3 -0.4 -0.6 -0.4  0.1 -0.5 -0.3 -0.4 12.9 -0.9  2.8  5.3 -0.5 -1.1 -0.3 -0.8  0.5 -7.1 -2.   0.1 -0.1 -0.7 -0.6  1.2 -0.5 -0.  -0.3 -0.3 -0.2 -0.2 -0.4 -2.  -0.3  1.5 -0.2 -0.7  0.1 -0.4 -0.3 -0.3 -0.3  3.8 -0.3 -0.  -2.4 -0.1 -0.3  1.5 -0.6 -1.2  0.8 -0.5 -0.6  0.6 -0.  -0.5 -0.6  0.1  4.5 -0.2 -0.4 -0.6 -0.2 -0.5 -0.1 -0.4 -1.  -0.4 -0.7 -0.4 -0.8 -0.1  3.9 -0.  -0.3 -0.5 -0.4 -0.9 -1.  -1.4 -1.9 -0.3 -0.   0.5 -0.2 -0.2  0.4 -0.4 -1.6 -0.1 -0.5  2.4 -0.  -0.6 -1.1 -0.2  1.6 -0.4 -0.3 -1.6 -0.4 -0.8 -0.8 -0.6 -0.3 -0.  -0.8 -0.3 -0.9 -1.9 -0.3 -1.1  0.  -0.7  1.4 -0.6  2.  -0.2 -0.8  1.5 -2.   0.8  3.4 -0.2  1.1 -0.4 -0.2  2.6 -0.2 -0.9 -0.3 -0.3  1.4 -0.3 -0.1  4.2 -0.2  0.9  3.4]
vy_50sample [[7 0 1 4 8 9 5 2 3 6]
 [5 5 2 0 6 3 1 4 7 8]
 [1 8 6 3 9 5 2 4 7 0]
 [2 8 5 1 4 0 6 3 9 7]
 [1 2 7 0 3 4 9 8 5 6]
 [3 9 5 8 1 0 6 4 2 7]
 [0 3 1 4 5 2 8 6 9 7]
 [3 1 7 9 8 5 0 6 4 2]
 [5 7 0 2 8 3 1 9 6 4]
 [6 1 5 2 0 9 9 7 3 8]]
vt_50sample [[7 0 1 4 8 9 5 2 3 6]
 [5 9 2 0 6 3 1 4 7 8]
 [1 8 3 6 9 5 2 4 7 0]
 [2 8 5 1 4 0 6 3 9 7]
 [1 2 7 0 3 4 9 8 5 6]
 [3 9 5 8 1 0 6 4 2 7]
 [0 3 1 4 5 2 8 6 9 7]
 [3 1 7 9 8 5 0 6 4 2]
 [5 7 0 2 3 8 9 1 6 4]
 [6 1 5 2 0 9 7 4 3 8]]
Epoch 21510: Training cost= 0.3529, Training acc= 0.8203, Validation cost= 0.2905, Validation acc= 0.8205
Epoch 21520: Training cost= 0.3387, Training acc= 0.8203, Validation cost= 0.3455, Validation acc= 0.8206
Epoch 21530: Training cost= 0.3491, Training acc= 0.8203, Validation cost= 0.3105, Validation acc= 0.8206
Epoch 21540: Training cost= 0.2844, Training acc= 0.8204, Validation cost= 0.3362, Validation acc= 0.8206
Epoch 21550: Training cost= 0.2939, Training acc= 0.8204, Validation cost= 0.2905, Validation acc= 0.8206
Epoch 21560: Training cost= 0.2879, Training acc= 0.8204, Validation cost= 0.3240, Validation acc= 0.8207
Epoch 21570: Training cost= 0.2727, Training acc= 0.8204, Validation cost= 0.3425, Validation acc= 0.8207
Epoch 21580: Training cost= 0.2660, Training acc= 0.8205, Validation cost= 0.3570, Validation acc= 0.8207
Epoch 21590: Training cost= 0.3036, Training acc= 0.8205, Validation cost= 0.3416, Validation acc= 0.8207
Epoch 21600: Training cost= 0.2809, Training acc= 0.8205, Validation cost= 0.3001, Validation acc= 0.8208
tm  [-0.6 -0.1 -1.2 -1.1 -1.6 -0.2 -0.1 -0.4 -0.5 -0.8  0.1  0.6 -0.4 -0.6 -0.2  2.5 -0.2 -0.5  0.1 -0.6 -0.6 -0.2  1.9 -0.2 -1.2  2.2 -0.2 -0.3  0.6  0.6  4.2 -0.7 -0.6  4.  -0.8  0.5  1.6  2.9 11.5 -0.4 -0.3  4.1  2.2  6.3 -0.3 -0.2  2.9 -0.   0.2  3.9 -0.8 -0.1  1.6 -0.9 -1.4  0.9 -0.4 -0.4 -0.3 -1.6 -0.  -0.3  1.  -0.1 -0.4 -0.   0.3 -0.4 -0.1  1.  -0.1 -0.9  0.   0.3 -0.9 -0.2  0.7 -0.2 -0.1 -0.1  7.1 -0.5 -0.1 -0.5 -0.5  6.2  2.3 -0.1 -0.1 -0.2 -0.2 -0.1 -0.2 -0.3 -0.3 -0.1  0.1 -1.  -0.6 -0.1  2.9  5.4 -0.4 -0.3 -0.3 -0.  -0.2  5.   0.3 -1.3 -0.8 -0.4 -0.  -0.7 -0.5  6.6  1.2 -0.5 -0.3 -0.2 -0.   3.8 -0.3 -0.2  0.  -0.1  1.1  5.9  2.  -1.2 -0.9 -0.4 -0.3 -0.6 -3.6 -1.9 -0.1 -0.  -0.3 -0.6  1.1 -0.3  1.4  0.1 -0.1 -0.1  0.2 -0.4  1.7 -0.1  0.8  0.2  0.1  0.5 -0.3 -0.3 -0.3 -0.2  5.1 -0.5  0.5 -1.3 -0.1 -0.3 -0.5 -0.5 -0.1 -0.3 -0.2 -0.6 -0.2 -0.2 -0.4 -0.3 -0.3 -0.1  1.2  1.9 -1.6 -0.3 -1.1  0.6 -0.3 -1.1 -0.7 -0.   0.2 -0.4 -0.2 -0.3 -0.2 -0.2 -0.5 -0.8  3.   0.1  1.5  0.7  0.4 -0.3  0.1 -0.1 -0.  -0.5 -0.   1.8 -0.2 -0.2 -1.3 -0.4 -0.2  3.  -0.4  3.9  0.7 -0.3 -2.1 -0.3  0.7 -0.2 -0.6 -0.3 -0.6 -0.8 -0.3  1.8 -1.3 -0.3  0.6  0.  -0.7 -0.8 -0.2 -0.8 -0.2  3.6 -0.2  0.7  0.6  1.5 -0.1  0.4  0.2 -0.2 -1.1 -2.  -0.3 -0.1 -0.7 -0.1 -2.  -0.3  8.1  0.2  0.4  7.1]
ty_50sample [[4 5 5 7 1 8 2 3 0 6]
 [7 6 2 9 5 1 3 0 4 4]
 [3 1 8 6 5 0 7 2 4 9]
 [8 2 9 5 6 4 3 0 1 1]
 [3 3 5 6 2 0 0 8 1 4]
 [5 7 9 3 4 1 2 0 8 6]
 [7 4 8 5 2 6 3 9 0 1]
 [8 4 1 0 3 9 5 7 6 2]
 [5 1 4 7 9 6 6 0 2 3]
 [4 9 0 1 8 2 5 3 6 7]]
tt_50sample [[4 9 5 7 1 8 2 3 0 6]
 [7 6 2 9 5 1 3 0 8 4]
 [3 1 8 6 5 0 7 2 4 9]
 [8 2 9 5 6 4 3 0 7 1]
 [3 9 5 6 2 0 7 8 1 4]
 [5 7 9 3 4 1 2 0 8 6]
 [7 4 8 5 2 6 3 9 0 1]
 [8 4 1 0 9 3 5 7 6 2]
 [5 1 4 7 9 6 8 0 3 2]
 [4 9 0 1 8 2 5 3 6 7]]
vm  [-0.4 -0.5  2.7  9.6 -1.1 -0.4 -0.  -0.2  0.8 -0.5 -3.6  1.7 -1.2 -0.5 -1.2 -1.2 -0.1 -0.  -0.2 -0.8 -0.5 -0.  -0.4 -0.1 -0.6 -0.  -0.4 -0.5 -0.2 -1.7 -1.3 -0.3  2.  -2.4 -0.7 -0.8 -0.4 -1.5 -1.2 -0.6  0.5 -2.3 -0.8 -1.2 -0.1 -0.5  2.8  0.8  0.7 -1.  -0.6 -0.3  0.2 -1.8 -0.9  2.7 -0.3  2.3  2.9  4.1 -0.4 -0.7  0.2 -0.1 -0.6 -0.6  0.3  0.1  2.3 -0.1  0.3 -0.2  1.  -0.  -2.9  1.9 -0.9 -0.  -0.7 -0.4 -0.3 -0.3 -0.1  0.2 -1.3 -2.4 -0.3 -0.2 -0.3 -0.7 -0.4 -0.5  0.5 -0.2 -0.3 -0.5  0.3 -1.4 -0.7 -0.6  1.  -2.1 -0.5  0.  -0.2  0.8 -1.2 -1.1 -1.2 -1.1  0.6  0.1 -0.  -0.7  3.6  0.2  0.6  3.2 -0.1  1.2 -0.1  2.7 -0.5 -0.3 -0.2 -1.2  0.1  9.9  2.1  5.1  1.  -0.6  0.1 -0.5  9.8  5.3 -0.2 -0.1  0.7  1.   1.4 -0.6  1.6 -0.1 -0.3  0.3 -0.4 -0.4  0.2 -0.4 -1.  -0.   2.4 -0.1 -0.3 -0.1 -0.3 -0.3 -1.  -0.  -0.3  0.6  0.4 -0.3 -0.4 -0.3 -0.3  1.6 -0.2  0.6 -0.8 -0.7 -0.5 -0.3 -0.   1.5 -1.8  0.1  4.1  0.2  0.6 -0.2 -0.  -1.2 -0.6  0.9  3.  -0.1 -0.1  5.9 -0.2 -0.1 -0.7 -1.1  4.1 -0.9 -0.2 -1.1 -0.1 -0.2 -0.1 -0.4 -0.1 -0.2 -0.8 -0.3 -0.3 -0.4  6.9 -0.2 -0.6  2.1 -0.8 -0.1 -0.6  0.8  5.4 -0.4  0.1  0.1 -0.7 -0.1 -0.5 -1.1 -0.4  1.5 -2.4 -0.1 -0.3  2.8  0.8  0.3 -0.   3.8 -1.  -0.1  0.4 -0.9  0.8  9.9 -0.3  4.2 -0.2 -0.4  2.8 -1.9  0.7 -0.5 -0.9  0.1  0.6 -0.3 -1.  -0.2  7.9 -1. ]
vy_50sample [[3 6 8 9 0 1 7 5 4 2]
 [5 7 9 3 4 2 8 6 0 1]
 [5 1 9 3 8 8 6 4 7 2]
 [3 4 4 1 1 5 2 7 6 9]
 [5 4 2 7 9 3 8 1 6 0]
 [1 5 8 4 2 9 7 3 0 6]
 [3 0 7 6 2 9 1 5 8 4]
 [6 1 5 4 7 9 3 2 8 0]
 [7 6 0 5 8 9 9 1 4 3]
 [8 2 3 9 4 1 0 6 5 7]]
vt_50sample [[3 6 8 9 0 1 7 4 5 2]
 [5 7 9 3 4 2 8 6 0 1]
 [5 1 3 0 9 8 6 4 7 2]
 [3 4 8 0 1 5 2 7 6 9]
 [5 4 7 2 9 3 8 6 1 0]
 [1 5 8 4 2 9 7 3 0 6]
 [3 0 7 6 2 9 1 5 8 4]
 [6 1 5 7 4 9 3 2 8 0]
 [7 6 0 5 8 9 2 1 4 3]
 [8 2 3 9 4 1 0 6 5 7]]
Epoch 21610: Training cost= 0.2899, Training acc= 0.8205, Validation cost= 0.3174, Validation acc= 0.8208
Epoch 21620: Training cost= 0.3533, Training acc= 0.8206, Validation cost= 0.3007, Validation acc= 0.8208
Epoch 21630: Training cost= 0.2908, Training acc= 0.8206, Validation cost= 0.2784, Validation acc= 0.8209
Epoch 21640: Training cost= 0.2652, Training acc= 0.8206, Validation cost= 0.2879, Validation acc= 0.8209
Epoch 21650: Training cost= 0.2553, Training acc= 0.8207, Validation cost= 0.2973, Validation acc= 0.8209
Epoch 21660: Training cost= 0.3353, Training acc= 0.8207, Validation cost= 0.3326, Validation acc= 0.8209
Epoch 21670: Training cost= 0.3314, Training acc= 0.8207, Validation cost= 0.2913, Validation acc= 0.8210
Epoch 21680: Training cost= 0.3225, Training acc= 0.8207, Validation cost= 0.3759, Validation acc= 0.8210
Epoch 21690: Training cost= 0.3239, Training acc= 0.8208, Validation cost= 0.2689, Validation acc= 0.8210
Epoch 21700: Training cost= 0.3185, Training acc= 0.8208, Validation cost= 0.3938, Validation acc= 0.8210
tm  [ 1.8 -0.2 -1.5 -0.3 -0.7 -0.3 -0.2 -0.3 -0.9 -0.5 -3.6 -0.4 -0.5  0.6 -1.1 -1.  -0.1  0.1  0.1 -0.9 -0.7 -0.5  1.4  0.5 -1.2  1.3 -0.1  0.7 -1.2 -0.7 -0.4 -0.3 -0.3 -4.1  0.5 -0.2  1.6  0.1  3.8 -0.4 -0.6 -2.  -0.2  2.2 -0.4 -0.7  4.3 -0.2  2.9  5.  -0.7 -0.  -0.7 -0.3 -0.   2.7 -0.6 -1.5  0.5  3.6 -0.9 -0.1 -0.7  0.7 -0.5 -0.3 -0.1  0.6  0.3 -0.2  0.3  3.4  1.3 -0.4 -1.5  0.8 -0.7 -0.2 -0.1 -0.1 -2.3 -0.1 -0.4  0.7 -1.5 -2.3  3.5 -0.3  0.6  0.2 -0.  -0.2 -0.4  2.8 -0.4 -0.2 -0.1 -1.  -0.5 -0.8  1.7 -1.5 -1.3 -0.1 -0.1 -0.3 -1.1 -0.9 -1.4 -0.9  0.1 -0.  -0.  -0.2  1.7 -1.8 -0.3 -0.1 -0.5 -0.  -0.2  3.3 -0.2 -0.5 -0.1 -1.1 -0.8  3.9 -0.7  3.2  2.5 -0.1  0.2 -0.2  4.6 -3.4 -0.2 -0.3  0.6  1.9 -0.2 -1.4 -0.   0.3  0.2 -0.1 -0.2 -0.  -0.4 -0.9 -0.2 -0.1  6.  -0.3 -0.2 -0.   0.6 -0.7 -0.7  0.  -0.3 -0.8 -0.1 -0.3 -0.3 -0.6 -0.4  0.3 -0.4 -0.3 -0.4 -0.5 -0.3 -0.4 -0.1  1.9 -0.8 -0.3 -0.2 -0.   1.6 -0.4 -0.1 -1.   0.1  0.6  4.6 -0.2  1.5  2.5 -0.1 -0.2 -0.5 -0.9  7.   1.9 -0.6 -0.3 -0.   0.1  0.  -0.2 -0.4 -0.2 -0.8 -1.2 -0.3  0.2 10.3 -0.1 -0.5 -1.1 -0.9 -0.8  0.5  0.5 -0.4 -0.3 -0.1 -0.1 -0.4 -0.6 -0.2 -1.1 -0.5 -0.3 -1.  -0.4 -0.4  2.7 -0.9  0.1 -0.2  6.1  1.4  3.3  2.7 -0.6  0.2 11.2 -0.1  5.3 -0.3  0.2  8.2 -1.3  1.1 -1.  -0.8  0.   4.9 -0.1  2.9 -0.2  3.9 -0.4]
ty_50sample [[8 0 3 4 9 6 2 7 5 5]
 [5 6 0 9 7 2 1 8 3 4]
 [6 8 3 1 7 5 5 9 2 4]
 [2 4 6 9 8 5 5 1 3 0]
 [6 1 5 3 4 7 2 0 8 9]
 [7 8 9 4 1 5 6 0 2 3]
 [5 4 6 0 3 1 9 9 2 8]
 [4 3 2 6 5 9 9 8 1 7]
 [0 0 1 5 2 2 8 3 6 4]
 [4 6 3 0 0 1 2 8 9 5]]
tt_50sample [[8 0 3 4 9 6 2 7 1 5]
 [5 6 0 9 7 2 8 1 3 4]
 [6 8 3 1 7 5 0 9 2 4]
 [2 4 6 9 8 7 5 1 3 0]
 [6 1 5 3 4 7 2 0 8 9]
 [7 8 9 4 1 5 6 0 2 3]
 [5 4 6 0 3 7 1 9 2 8]
 [4 3 2 6 5 9 0 8 1 7]
 [0 7 1 9 5 2 8 3 6 4]
 [4 6 3 7 0 1 2 8 9 5]]
vm  [ 2.3  0.5 -1.5 -1.6 -1.2  0.2 -0.1 -0.4 -1.5 -0.6 -1.7 -0.3 -0.4  0.   1.5 -0.9  0.  -0.4 -0.3 -0.2 -0.5 -0.2  2.2  1.4 -1.7  2.8  0.1 -0.3 -1.6  1.9  1.6 -0.1 -0.6 -1.3  0.9  1.3  5.  -0.1 -0.2 -0.5 -0.1  4.1  3.8  3.4 -0.4 -0.2 -0.5 -0.2  3.9  6.4 -0.6 -0.3 -0.2  0.7  1.7  0.1 -0.7 -0.3 -1.3 -0.3 -0.3 -0.2 -0.4  1.7 -0.4  1.   0.3 -0.4  0.  -0.  -0.2  4.5  0.5 -0.2 -2.1 -0.3 -0.4 -0.2  0.1  0.4 -1.5 -0.   0.2  0.9 -1.1  4.4  5.7  0.2 -0.  -0.1 -0.1 -0.1 -0.5  2.7 -0.4 -0.   0.1 -1.2  0.1  0.1  1.5  2.4 -1.  -0.3  0.2  0.2 -1.2  1.9 -0.8 -0.2 -1.  -0.1 -0.1  0.6 -0.1 -1.9 -0.7 -0.9 -0.1 -0.2 -0.   1.6 -0.3 -0.7  0.4  2.2 -0.7  1.6 -0.7  1.3  2.4 -0.2  0.4 -0.2  3.7 -0.8 -0.1 -0.3  0.5 -0.1  1.2 -1.5  1.3 -0.  -0.  -0.2 -0.  -0.3  3.2 -0.2  0.4 -0.2  5.   0.5 -0.4  0.6  0.  -0.1 -0.5 -0.2  0.5 -0.1 -0.1 -0.1 -0.1 -0.4 -0.5 -0.9  0.5 -0.5  0.1  0.1  0.2 -0.1 -0.1 -0.4 -0.6  0.   1.6 -0.4 -1.3 -0.4 -0.5 -1.6 -0.1 -0.5  2.6 -0.3  0.4 -0.5 -0.1 -0.5 -0.1 -1.1  4.3  3.6 -0.5  0.9 -0.  -0.2 -0.1 -0.2 -0.4 -0.3 -0.1 -1.6 -0.4 -0.1  1.1 -0.1 -0.3 -1.4 -0.5 -0.5 -0.3 -0.2 -0.7 -0.4 -0.3 -0.2 -0.5 -0.1 -0.2 -0.9  2.6 -0.1 -0.9 -0.7 -0.4  1.  -0.9 -0.2  0.   1.1  4.   4.7  2.1 -0.6  2.  -1.3 -0.  -0.7 -0.2 -0.1  6.3 -0.2 -0.  -0.1 -0.7 -0.6  3.5 -0.1 -0.1 -0.2  1.1  1.8]
vy_50sample [[0 0 8 5 6 7 7 3 3 1]
 [1 7 0 5 2 9 3 6 8 4]
 [5 2 3 1 1 0 0 8 4 4]
 [6 3 0 0 2 2 5 9 1 1]
 [9 7 2 3 5 1 6 4 0 8]
 [9 7 7 2 8 4 1 1 0 3]
 [4 1 6 7 9 5 8 2 3 3]
 [2 4 0 7 5 8 1 3 6 9]
 [6 3 0 1 5 7 4 9 8 2]
 [4 4 3 5 6 0 1 7 2 8]]
vt_50sample [[4 0 5 8 6 7 2 9 3 1]
 [1 7 0 5 2 9 3 6 8 4]
 [5 2 3 9 1 0 7 6 8 4]
 [6 3 0 8 2 4 5 1 9 7]
 [7 9 2 3 1 5 6 4 0 8]
 [9 7 5 2 4 6 8 1 0 3]
 [4 1 6 7 9 5 8 2 3 0]
 [2 4 0 7 5 8 1 3 6 9]
 [6 3 0 5 1 7 4 9 8 2]
 [4 9 3 5 6 0 1 7 2 8]]
Epoch 21710: Training cost= 0.2997, Training acc= 0.8208, Validation cost= 0.3033, Validation acc= 0.8211
Epoch 21720: Training cost= 0.3126, Training acc= 0.8208, Validation cost= 0.3383, Validation acc= 0.8211
Epoch 21730: Training cost= 0.2997, Training acc= 0.8209, Validation cost= 0.2931, Validation acc= 0.8211
Epoch 21740: Training cost= 0.2867, Training acc= 0.8209, Validation cost= 0.2725, Validation acc= 0.8211
Epoch 21750: Training cost= 0.3220, Training acc= 0.8209, Validation cost= 0.3439, Validation acc= 0.8212
Epoch 21760: Training cost= 0.3759, Training acc= 0.8209, Validation cost= 0.2988, Validation acc= 0.8212
Epoch 21770: Training cost= 0.3156, Training acc= 0.8210, Validation cost= 0.3217, Validation acc= 0.8212
Epoch 21780: Training cost= 0.3660, Training acc= 0.8210, Validation cost= 0.2903, Validation acc= 0.8212
Epoch 21790: Training cost= 0.2835, Training acc= 0.8210, Validation cost= 0.2749, Validation acc= 0.8213
Epoch 21800: Training cost= 0.3334, Training acc= 0.8211, Validation cost= 0.2519, Validation acc= 0.8213
tm  [-1.2 -0.3  7.9 14.5 -1.4  1.2 -0.  -0.1 -0.4  1.5  6.2 -0.7  0.9  1.1  2.2 -0.5 -0.1 -0.6 -0.4 -1.5 -0.9 -0.1  1.2 -0.1 -1.   1.9 -0.2 -0.3 -1.5 -1.1 -0.2  0.3  2.1  7.4  0.8  0.6  2.9 -0.4 -1.5 -0.2  1.3  2.9 -0.3 -1.8 -0.3 -0.3  6.4 -0.2 -1.2  2.7 -0.3 -0.2 -0.7  0.9  1.6  0.1 -0.7  3.7  0.6  3.1  3.1 -0.3 -0.   1.9  2.6 -0.7 -0.  -0.3 -0.2 -0.5 -0.2  3.9 -0.4 -0.5 -1.2 -0.7  0.2  0.  -0.2 -0.4 10.4  0.9 -0.7 -0.3  0.2  2.5 -1.6 -0.2 -0.3  0.6 -0.6 -0.6 -0.3 -0.1 -0.3 -0.1  0.7 -0.7  1.6 -0.2 -0.5  5.4  1.8  0.  -0.4 -0.8 -1.3 -0.5  0.1 -1.6 -0.3  0.2 -0.  -0.5  4.4 -2.2 -0.5 -0.5 -0.2 -0.4  0.1  5.4 -0.1 -0.2 -0.4  2.8 -0.4  1.5 -0.6 -1.3 -0.2 -0.1 -0.7  1.5  6.5 15.1 -0.1 -0.4 -0.2 -0.6 -0.3 -0.4 -0.7 -0.2  0.3 -0.3 -0.3  0.  -0.4 -0.4 -1.2 -0.4 -1.3 -0.3 -0.2 -0.1  0.2 -0.4 -1.6 -0.5 -0.6  1.9 -0.3 -0.2 -0.1 -0.2 -0.8 -0.2 -0.3 -0.   0.8 -0.4  0.5  0.   0.5  2.9 -1.5 -0.5  3.7 -0.3 -0.7 -0.4  0.2 -0.9 -0.  -0.7 -0.4 -1.1 -0.1  3.3 -0.3 -0.4 -0.9 -0.4 -0.5  3.  -0.8 -0.5 -0.1  0.2 -0.2 -0.1 -0.2  0.1 -0.2 -1.  -0.3 -0.2 -0.8  1.5 -0.2 -1.5  0.2  3.2 -0.6 -0.2  7.7 -0.8 -0.6 -0.1 -0.1 -0.5  0.8 -1.1  4.9 -1.3 -0.3  2.3 -0.6 -0.6  0.5  1.  -0.4 -0.5  2.9 -1.9  2.1 -0.6 -0.   5.7 -0.2  2.7 -0.5 -0.4 -2.2 -0.5 -0.4 -0.6 -0.7  0.4 -3.  -0.3 -0.9 -0.1 -0.7  8.3]
ty_50sample [[0 6 1 7 2 9 5 8 3 4]
 [2 5 1 9 4 0 3 7 8 6]
 [7 1 1 2 9 5 6 3 4 0]
 [8 4 5 2 9 6 0 3 7 1]
 [8 6 6 0 2 1 9 3 7 4]
 [0 3 4 1 7 6 9 8 2 5]
 [1 6 9 5 0 0 8 4 3 7]
 [7 3 8 6 5 4 2 1 0 9]
 [6 3 1 8 4 9 5 7 0 2]
 [8 6 1 7 3 5 0 2 9 4]]
tt_50sample [[0 6 1 2 7 9 5 8 3 4]
 [2 5 1 4 9 0 3 7 8 6]
 [7 1 8 2 9 6 5 3 4 0]
 [8 4 5 2 9 6 0 3 7 1]
 [8 5 6 0 2 1 9 3 7 4]
 [3 0 4 1 7 6 9 8 2 5]
 [1 6 9 5 2 0 8 4 3 7]
 [7 3 8 6 5 4 2 1 9 0]
 [6 3 1 8 4 9 5 7 0 2]
 [8 6 1 7 3 5 0 2 9 4]]
vm  [-0.2 -0.3 -0.4  4.9 -1.5 -0.2  0.4 -0.   0.1 -0.3  9.6 -0.4  0.9 -0.6 -1.2  5.7  0.5 -0.4  0.2 -1.7 -0.8 -0.2  1.1 -0.3 -0.8  1.6 -0.2 -0.3 -0.2 -0.   4.9 -0.6 -0.4  7.6 -0.2 -0.1  1.4  7.  17.8 -0.5  0.2  2.7 -0.   5.1 -0.2 -0.4  9.  -0.8  0.9  2.2 -0.7 -0.3  2.2  0.5 -1.2  1.9 -0.5 -0.6  0.6 -1.8 -1.3 -0.5  1.1  0.3 -0.1 -0.4  0.2 -0.3 -0.4 -0.  -0.2 -0.7  0.2 -0.2  4.2 -0.1  0.1  0.8 -0.3 -0.1 17.2 -0.2 -0.5 -0.3 -0.8  4.4  2.  -0.3 -0.1 -0.6  0.1 -0.2 -0.2 -0.6 -0.3 -0.4 -0.2 -0.2 -0.6 -0.1  1.1  6.1 -0.4 -0.3 -0.3 -0.2  1.2  4.9  2.3 -2.5 -0.6 -0.3 -0.3 -0.6 -0.3  3.9  1.2 -0.6 -0.  -0.3 -0.2  8.2 -0.3 -0.   0.  -1.1 -0.1  1.7  1.6 -2.4 -0.6 -0.3 -0.  -0.2 -4.6 -1.3 -0.2 -0.2 -0.5 -0.5 -0.7 -0.1 -0.5  0.2 -0.3 -0.3  0.7 -0.  -0.5 -0.1 -0.3 -0.2 -0.1 -0.3 -0.2 -0.2 -0.3 -0.3  5.1 -0.5 -0.1 -1.7 -0.2 -0.4 -0.1 -0.2 -0.3 -0.1 -0.3 -0.3 -0.2 -0.6 -0.6 -0.3 -0.2  1.3  2.   2.  -2.8 -0.4 -0.7  1.1 -0.1 -0.9 -0.7 -0.   2.3 -0.5 -0.3  0.2 -0.4 -0.5 -0.8 -0.6  8.1 -0.1  3.2  0.9 -0.1 -0.3 -0.1 -0.2 -0.1 -0.2 -0.2  6.1 -0.2 -0.1 -1.2 -0.5 -0.1  3.1 -0.3  1.5  0.4 -0.3 -1.8 -0.6  0.4 -0.  -0.3 -0.4 -0.4 -0.7 -0.2  0.4  0.9  1.5 -0.1  0.3 -0.9 -1.1 -0.2 -0.6 -0.2  2.5 -0.   3.1 -0.  11.6 -0.2  5.  -0.2 -0.1 -3.6 -3.2 -0.4 -0.2 -0.7 -0.2 -4.4 -0.1 12.5 -0.  -1.2 11.8]
vy_50sample [[9 2 4 7 5 1 0 8 3 6]
 [2 8 1 7 0 3 4 6 9 5]
 [3 5 7 0 6 2 2 4 1 1]
 [9 8 0 4 2 3 1 5 7 6]
 [5 9 6 6 7 8 1 0 2 4]
 [0 6 9 7 3 5 2 8 1 4]
 [8 3 5 6 2 2 4 1 0 7]
 [6 5 7 4 0 8 2 9 3 1]
 [1 6 0 3 9 2 4 7 5 8]
 [3 4 0 6 7 5 9 1 2 8]]
vt_50sample [[9 2 4 7 5 1 0 8 3 6]
 [2 8 1 7 0 3 4 6 9 5]
 [3 5 7 0 6 2 8 4 1 9]
 [9 8 0 4 2 3 1 5 7 6]
 [5 9 6 3 7 8 1 2 0 4]
 [0 6 9 7 3 5 2 8 1 4]
 [8 3 5 6 9 2 4 1 0 7]
 [6 5 7 4 0 8 2 9 3 1]
 [1 6 0 3 9 2 4 7 5 8]
 [3 4 0 6 7 5 9 1 2 8]]
Epoch 21810: Training cost= 0.3227, Training acc= 0.8211, Validation cost= 0.2892, Validation acc= 0.8213
Epoch 21820: Training cost= 0.3185, Training acc= 0.8211, Validation cost= 0.3057, Validation acc= 0.8213
Epoch 21830: Training cost= 0.2989, Training acc= 0.8211, Validation cost= 0.3048, Validation acc= 0.8214
Epoch 21840: Training cost= 0.2472, Training acc= 0.8212, Validation cost= 0.2778, Validation acc= 0.8214
Epoch 21850: Training cost= 0.3109, Training acc= 0.8212, Validation cost= 0.3090, Validation acc= 0.8214
Epoch 21860: Training cost= 0.3339, Training acc= 0.8212, Validation cost= 0.2497, Validation acc= 0.8215
Epoch 21870: Training cost= 0.3389, Training acc= 0.8213, Validation cost= 0.3130, Validation acc= 0.8215
Epoch 21880: Training cost= 0.3289, Training acc= 0.8213, Validation cost= 0.2969, Validation acc= 0.8215
Epoch 21890: Training cost= 0.2572, Training acc= 0.8213, Validation cost= 0.2565, Validation acc= 0.8215
Epoch 21900: Training cost= 0.2892, Training acc= 0.8213, Validation cost= 0.2786, Validation acc= 0.8216
tm  [-1.6 -1.1 -1.2  1.  -0.7 -0.1 -0.2 -0.2  2.1  0.9  6.5 -0.6  0.  -0.1 -0.8  2.3  0.6 -0.2 -0.3 -0.3 -1.   0.1  1.7 -0.2 -1.1  3.  -0.2 -0.2 -0.5 -3.  -0.3 -0.5 -0.5 -2.4  0.9 -0.2  0.1  5.9  5.  -0.2  0.5  2.7 -0.9  2.4 -0.4 -0.1 -0.4 -1.3 -1.4  5.7 -0.4 -0.2 -0.5  8.2 -0.5  2.  -0.7  1.6  7.   2.3  7.9 -0.3  0.2  0.7 -0.3 -0.4  0.1  1.8 -0.4 -0.4 -0.5  1.3 -0.   0.2 -3.8 -0.1  1.2  0.1 -0.4 -0.2 -0.8  0.  -0.3 -0.3  1.8  3.4 -1.5 -0.2 -0.2 -0.2 -0.5 -1.  -0.4 -1.3 -0.5 -0.4  0.6 -1.8 -0.2 -0.2 -0.5 -0.3  1.8 -0.1 -0.4 -0.2 -2.  -0.4  1.2 -0.5 -0.1 -0.1 -0.2 -0.7  5.7 -0.6  0.3 -0.  -0.1  0.  -0.2  1.2  1.1 -0.4  0.4 -0.9 -0.5 -2.   5.8 -0.1 -1.3 -0.5 -0.6  0.7  1.8 -2.7 -0.4 -0.1  0.  -0.2 -0.8 -0.7 -1.1 -0.3 -0.3 -0.1  0.9 -0.1  4.6 -0.2  0.8 -0.4 -0.8 -0.2 -0.2  0.3 -0.5 -0.2  3.3 -0.2  0.8 -1.5  0.1 -0.1 -0.3 -0.6 -0.5  1.  -0.2 -0.2  0.3 -0.3 -0.6 -0.  -0.2 -0.9  0.4 -0.3 -0.5 -0.3 -0.9 -0.  -0.2 -1.1 -0.1 -0.6 -1.1  0.4 -0.5 10.1 -0.3 -0.6 -0.6 -0.6 -2.2 -1.2 -0.8 -1.  -0.  -0.2  0.1 -0.2 -0.2 -0.2 -0.1 -1.7 -0.1 -0.3  2.5 -0.1 -0.2 -0.6 -0.1  5.6 -0.6  0.3 -0.6 -0.9 -0.5 -0.4 -0.2 -0.4 -0.1 -1.4 -0.  -0.2  2.1  4.  -0.4 -0.4 -0.7  0.1 -0.2  1.6  0.8  3.1  1.6 -1.6  0.5  0.1 -0.4 -0.  -0.4 -0.   4.2 -0.1 -0.2 -0.1 -1.1 -0.3  1.1 -0.1  3.6 -0.2 -1.3  3.6]
ty_50sample [[1 2 0 8 5 4 9 3 7 7]
 [9 3 7 5 6 0 8 2 1 4]
 [0 9 2 7 3 8 4 6 5 1]
 [4 1 0 2 8 7 9 5 3 6]
 [8 1 6 3 7 4 2 0 9 5]
 [8 1 1 5 5 7 4 2 0 6]
 [6 0 7 3 4 2 2 1 5 9]
 [1 0 8 9 2 4 5 7 3 6]
 [3 5 6 9 7 4 1 0 2 8]
 [4 9 5 3 3 0 2 6 8 7]]
tt_50sample [[1 2 0 8 5 4 9 3 6 7]
 [9 3 7 5 6 0 8 2 1 4]
 [0 2 9 7 3 4 8 6 5 1]
 [4 0 1 2 8 7 9 5 6 3]
 [8 1 6 3 7 4 2 0 9 5]
 [8 9 1 5 3 7 4 2 0 6]
 [6 0 7 3 4 8 2 1 5 9]
 [1 0 8 9 2 4 5 7 3 6]
 [3 5 6 9 7 4 1 0 2 8]
 [4 9 5 3 1 0 2 6 8 7]]
vm  [-0.7 -0.2  2.9 -0.2 -1.7 -0.1 -0.2 -0.3 -0.3 -0.4 -1.4 -0.3 -0.6  0.1  4.3 -2.  -0.5 -0.   0.3  2.5 -0.8 -0.4  0.6  0.5 -1.2  4.7 -0.3 -0.2 -1.5 -1.6 -0.3 -0.  -0.4 -0.2  0.4 -0.3  2.  -1.1 -2.3 -0.7 -0.4 -1.3 -0.4 -0.9 -0.8 -0.2 -1.9 -0.1  0.6  0.1 -0.6 -0.1  0.7  1.8  1.7 -0.2 -0.4 -0.2  1.6  2.7  5.3 -0.2  0.3  2.8  0.  -0.2 -0.2 -0.   1.9 -0.3 -0.3  5.4  1.1 -0.1 -4.1 -0.7 -0.5 -0.4 -0.3 -0.1 -1.7 -0.1  1.5 -0.4 -0.6 -1.5 -0.4 -0.1 -0.2  0.1 -0.2 -0.7 -0.3 -0.3 -0.5 -0.   0.2 -2.4 -0.1 -0.3  0.4 -0.2 -0.2 -0.4 -0.3  0.8 -1.7 -0.3 -0.6  2.1 -0.5  0.2  0.5 -0.4  5.4 -2.5 -0.6  1.  -0.1  1.7 -0.1 -1.  -0.2  1.6 -0.5  5.  -0.5  1.2  0.2  5.6  1.6 -0.3 -0.2 -0.2  6.3  5.9 -0.4 -0.1  1.7 -0.2  3.2 -1.6  0.9  0.1 -0.3  0.3 -0.3 -0.1 -0.8 -0.5  0.3 -0.1  1.4  2.1 -0.3  0.2 -0.   0.6 -0.9 -0.2 -0.2  0.6  1.4 -0.1 -0.3 -0.9 -0.2  1.8  0.4 -0.  -0.2 -0.3  0.3 -0.1 -0.5  3.  -0.8 -0.2  5.9  0.4  1.4 -0.  -0.4 -1.7 -0.   0.1 -0.2 -0.2  1.   4.7 -0.3 -0.3 -0.1 -1.1 -1.1  0.7 -1.2 -0.9 -0.1  0.3 -0.1 -0.1 -0.7 -0.5 -0.  -2.3 -0.3  0.   5.8 -0.1 -0.3 -1.4 -1.   3.2 -0.8 -0.3  4.  -0.7 -0.4  1.8 -0.8 -0.5  0.1 -1.3  2.4 -0.9 -1.7  1.4 -0.2  0.8  0.1 -0.2 -0.4  2.7  4.3 -0.1  3.1 -1.   3.2 -0.  -0.2  0.2 -0.4  0.1  7.1  1.3  0.1  0.2 -1.  -0.4  3.9 -0.1 -1.6 -0.1  4.1 -1.2]
vy_50sample [[0 6 3 1 8 7 4 2 2 9]
 [5 5 2 9 3 4 8 6 1 7]
 [2 4 0 8 5 6 1 3 7 7]
 [8 5 1 0 2 7 3 4 9 6]
 [5 7 2 1 8 3 6 0 4 9]
 [8 4 9 2 6 1 7 3 0 5]
 [0 7 5 8 3 9 4 6 1 2]
 [5 0 6 1 1 3 2 2 7 4]
 [6 8 4 3 1 0 2 9 9 7]
 [9 8 3 7 6 2 1 4 5 0]]
vt_50sample [[0 6 3 1 8 7 4 2 5 9]
 [5 0 2 9 3 4 8 6 1 7]
 [2 4 0 8 5 6 1 9 3 7]
 [8 5 1 0 2 7 3 4 9 6]
 [5 7 2 1 8 3 6 0 4 9]
 [8 4 9 2 6 1 7 3 0 5]
 [0 7 5 8 3 9 4 6 1 2]
 [5 0 6 1 8 9 3 2 7 4]
 [6 8 4 3 1 0 2 5 9 7]
 [9 8 3 7 6 2 1 4 5 0]]
Epoch 21910: Training cost= 0.3373, Training acc= 0.8214, Validation cost= 0.2678, Validation acc= 0.8216
Epoch 21920: Training cost= 0.2999, Training acc= 0.8214, Validation cost= 0.2941, Validation acc= 0.8216
Epoch 21930: Training cost= 0.2890, Training acc= 0.8214, Validation cost= 0.3258, Validation acc= 0.8217
Epoch 21940: Training cost= 0.3236, Training acc= 0.8214, Validation cost= 0.2710, Validation acc= 0.8217
Epoch 21950: Training cost= 0.2685, Training acc= 0.8215, Validation cost= 0.2806, Validation acc= 0.8217
Epoch 21960: Training cost= 0.3035, Training acc= 0.8215, Validation cost= 0.2871, Validation acc= 0.8217
Epoch 21970: Training cost= 0.3352, Training acc= 0.8215, Validation cost= 0.3031, Validation acc= 0.8218
Epoch 21980: Training cost= 0.2898, Training acc= 0.8216, Validation cost= 0.3134, Validation acc= 0.8218
Epoch 21990: Training cost= 0.2924, Training acc= 0.8216, Validation cost= 0.3330, Validation acc= 0.8218
Epoch 22000: Training cost= 0.2827, Training acc= 0.8216, Validation cost= 0.3126, Validation acc= 0.8218
tm  [-0.8 -0.1 -2.4 -3.4 -0.9  0.2 -0.2 -0.2 -0.7 -0.4 -1.7 -0.5 -0.2  0.4  1.7  4.7 -0.1 -0.3 -0.3 -0.2 -0.6 -0.6  1.9 -0.3 -1.3  0.3 -0.1 -0.5  2.4  3.3  2.1 -0.4 -0.2 -2.3 -0.7 -0.5  1.1 -0.2 -1.3 -0.3 -0.3  1.6  0.3  2.6 -0.5 -0.1 -1.1 -0.4 -0.1  9.8 -0.6 -0.  -0.6  3.2 -1.2  0.2 -0.4 -1.8  0.  -0.3  3.9 -0.2 -0.4 -0.2 -0.7 -0.2 -0.2 -0.1  0.4 -0.  -0.2 -1.4  0.1  1.1 -3.7 -0.2 -0.1  0.2  0.5 -0.2 -3.  -0.5  0.8 -0.5 -0.6  3.1  2.4 -0.4 -0.2 -0.5 -0.4 -0.2 -0.1 -0.3 -0.5 -0.3 -0.3 -1.7 -0.1 -0.3  1.9  3.9  0.8 -0.  -0.1  0.1 -1.4  2.2 -0.8 -0.5 -0.4 -0.2 -0.1 -0.6 -0.5  9.5 -0.3 -0.6  0.3  0.2 -0.2 -0.  -0.1 -0.1  0.   2.5  1.  -0.2 -0.1 -0.4  1.4 -0.7 -0.2 -0.5  5.7 -0.6 -0.  -0.3  0.3 -0.   0.  -0.4  0.3 -0.2 -0.3  0.6 -0.2 -0.1  0.3  0.1  2.9 -0.3  1.2 -0.  -0.3 -0.1 -0.2 -0.6 -0.3  0.   0.2  0.6  0.1  0.1 -0.5 -0.3  0.4  1.   0.6 -0.6 -0.2 -0.5 -0.2 -0.6 -0.2  1.  -0.7 -0.3  3.9 -0.6 -0.2  0.7 -0.3 -1.2 -0.7  0.2 -0.4 -0.2 -0.1 -0.9 -0.3 -0.3 -0.1 -1.  -0.4  0.9 -0.5  1.1 -0.3 -0.3 -0.4 -0.1 -0.2 -0.4 -0.1 -1.9 -0.2 -0.2  6.4 -0.2  0.4  4.8 -0.8  3.9  0.4 -0.2 -0.7 -0.5 -0.2 -0.1 -0.7 -0.2 -0.5 -1.   3.9  3.6 -0.8  0.  -0.4  0.4 -0.3  0.6 -0.2  4.1 -0.7  5.5 -0.1 -1.3  1.1  1.3 -0.1  1.2 -0.  -0.2  9.9 -0.1 -0.2 -0.5 -0.9 -0.4  7.3 -0.2 -0.9 -0.2 -0.3  4.3]
ty_50sample [[4 8 6 1 2 7 5 9 3 0]
 [3 9 0 1 6 4 8 5 7 2]
 [1 8 9 4 0 2 2 3 6 7]
 [5 2 3 9 7 1 0 4 8 6]
 [1 0 2 5 8 6 4 7 9 3]
 [4 0 6 3 9 5 8 7 1 2]
 [0 5 1 3 8 9 6 7 2 4]
 [4 1 0 7 5 2 3 9 6 8]
 [9 1 0 6 2 8 3 5 4 7]
 [7 5 8 0 9 6 4 2 1 3]]
tt_50sample [[4 8 6 1 2 7 5 9 3 0]
 [3 9 0 1 6 4 8 5 7 2]
 [1 8 9 4 0 2 5 3 6 7]
 [5 2 3 9 7 1 0 4 8 6]
 [1 0 2 5 8 6 4 7 9 3]
 [4 0 6 3 9 5 7 8 1 2]
 [0 5 1 3 8 9 6 7 2 4]
 [4 1 0 7 5 2 9 3 6 8]
 [9 1 0 6 2 8 3 5 4 7]
 [7 5 8 9 0 6 4 2 1 3]]
vm  [ 1.8  0.6  6.5 -1.5 -1.9 -0.3 -0.3 -0.3 -1.  -1.1  4.3  0.3 -0.3 -0.2 11.8  1.1 -0.1 -0.4  0.6  3.3 -0.7 -0.1 -0.8  0.5 -1.6  1.7 -0.3 -0.2 -1.  -1.1  0.8 -0.2 -0.5  7.1 -0.5 -0.   2.2  3.3 -0.7 -0.7 -0.1 -0.8  1.4  1.6 -0.3 -0.3 -2.3 -0.5  3.4 -2.1 -0.9 -0.1 -0.   8.3 -0.5 -1.3 -0.5  3.8 -0.1  1.5  2.2 -0.3 -0.2  1.8  0.  -0.3 -0.3 -0.5  0.8 -0.4 -0.1  2.6  0.2 -0.3 -5.  -0.3 -0.9 -0.3 -0.7 -0.4 -2.  -0.2  0.6  0.2 -1.3 -0.6  2.4 -0.2  1.1 -0.2 -0.4 -0.  -0.   2.5 -0.4 -0.2  0.4 -1.9 -0.1 -0.3  4.3  0.5 -1.  -0.2 -0.  -0.1 -2.6  0.6  1.   3.2 -0.2 -0.2 -0.3 -0.6  0.3 -0.5 -0.3 -0.1  0.1 -0.2 -0.3 -1.5 -0.5 -0.4 -0.5 13.9 -0.2 -2.   1.2 11.   0.9 -0.5 -0.  -0.5 -4.  -0.9  0.4 -0.3 -0.  -0.3 -0.2 -0.9  0.1 -0.2  0.1  0.4 -0.3 -0.3 -0.2 -0.2 -0.  -0.2  2.5 -0.  -0.6 -0.  -0.3 -0.3  2.1 -0.5 -0.5 -1.3 -0.3 -0.1 -0.3 -0.7 -0.  -0.5  0.3 -0.2 -0.2  0.6 -0.2 -0.4 -0.2  1.6 -0.5 -0.9  2.6 -0.4 -1.3 -0.5 -0.1 -1.7 -0.4 -0.2  0.9 -0.7 -0.2  2.9 -0.1 -0.2  0.4 -1.2 -0.1 -0.2 -1.5 -0.3 -0.2 -0.1 -0.4 -0.6 -0.3 -0.6 -0.8 -3.6 -0.1 -0.3 -1.3 -0.4 -0.3 -0.7 -0.3 -0.7 -0.3 -0.1 -0.3 -0.6 -0.  -0.3 -0.5 -0.   0.2 -1.  -1.6 -0.4 -0.6 -0.2 -0.2  3.7 -0.7  2.  -0.4 -0.8  0.5 -1.3  0.7 -2.   0.4 -3.6  0.  -1.5 -0.3 -0.1  7.5  4.4 -0.3 -0.3 -0.4 -0.3  4.5 -0.1 -0.4 -0.2  3.7 -3.2]
vy_50sample [[3 7 5 0 2 8 4 6 1 9]
 [8 8 2 6 4 9 3 3 1 5]
 [7 5 8 2 9 3 6 4 0 1]
 [2 8 1 9 0 5 6 3 4 7]
 [5 3 9 7 6 8 4 2 1 0]
 [1 2 9 8 5 4 3 7 0 6]
 [3 8 4 9 5 7 0 2 1 6]
 [8 2 7 3 1 0 6 9 5 4]
 [8 8 7 4 1 2 3 6 9 5]
 [9 8 1 2 3 6 5 0 4 7]]
vt_50sample [[3 7 5 0 2 8 4 6 1 9]
 [8 0 2 6 4 9 7 3 1 5]
 [7 5 8 2 9 3 6 4 0 1]
 [2 8 1 9 0 5 6 3 4 7]
 [5 3 9 7 6 8 4 2 1 0]
 [1 2 9 5 8 4 3 7 0 6]
 [3 4 8 9 5 7 0 2 1 6]
 [8 7 2 3 1 0 6 9 5 4]
 [8 0 7 4 1 2 3 6 9 5]
 [9 8 1 2 3 6 5 0 4 7]]
Epoch 22010: Training cost= 0.3149, Training acc= 0.8216, Validation cost= 0.3680, Validation acc= 0.8218
Epoch 22020: Training cost= 0.5109, Training acc= 0.8216, Validation cost= 0.3572, Validation acc= 0.8219
Epoch 22030: Training cost= 0.3023, Training acc= 0.8217, Validation cost= 0.3983, Validation acc= 0.8219
Epoch 22040: Training cost= 0.3041, Training acc= 0.8217, Validation cost= 0.3314, Validation acc= 0.8219
Epoch 22050: Training cost= 0.2626, Training acc= 0.8217, Validation cost= 0.2736, Validation acc= 0.8219
Epoch 22060: Training cost= 0.2979, Training acc= 0.8217, Validation cost= 0.3029, Validation acc= 0.8220
Epoch 22070: Training cost= 0.3224, Training acc= 0.8218, Validation cost= 0.3183, Validation acc= 0.8220
Epoch 22080: Training cost= 0.2464, Training acc= 0.8218, Validation cost= 0.3000, Validation acc= 0.8220
Epoch 22090: Training cost= 0.2518, Training acc= 0.8218, Validation cost= 0.2807, Validation acc= 0.8220
Epoch 22100: Training cost= 0.2705, Training acc= 0.8218, Validation cost= 0.3018, Validation acc= 0.8221
tm  [-0.7 -0.9 12.3 17.6 -2.  -0.4 -0.5  0.6  2.   2.6  2.3  0.5 -1.2 -0.4  4.  -2.4 -0.  -0.1 -0.9 -1.7 -1.  -0.1 -1.   0.7 -0.6  1.9 -0.4  1.  -1.5 -2.4  1.2  0.1 -0.  15.2 -0.2 -0.9 -0.4 -0.1 11.9 -0.1  1.  -0.5 -1.1 -0.5 -0.2 -0.3  9.7  0.7 -0.2 -2.1 -0.1  0.3  1.8 -2.7  0.5 -0.3 -0.7  3.5  3.6  1.1 -0.6 -0.6  4.  -0.2  1.9 -0.3  0.2  0.4 -0.4 -0.5 -0.3  1.3 -0.6 -0.5 -1.7 -1.  -0.3  0.9 -1.3 -0.4 19.4 -0.2 -0.4 -0.7 -0.7 -0.8 -1.3 -0.  -0.3 -0.3  0.7 -0.9 -0.3 -0.8  1.3 -0.1  0.8 -0.7 -0.5 -0.7 -1.2  3.9 -0.1 -0.2 -0.8  1.  -0.2  0.9  0.9 -2.   4.2 -0.1 -0.2 -0.8  7.1 -2.6 -0.9  2.4  0.2 -0.8 -0.7  5.1 -0.4  1.4 -0.6  4.7 -0.3 13.1  2.6 -1.4 -0.3 -0.1 -0.6  2.5 -5.2  5.6 -0.2 -0.4  0.7 -0.7  2.  -0.8 -0.4 -0.4 -0.4  0.2 -0.3 -0.4 -1.9 -0.3 -1.5 -0.1 -1.   2.2 -0.4 -0.4 -0.6 -0.4  1.7  2.  -0.4 -1.8 -0.1  0.2  1.4  0.4 -1.1  0.6 -0.7  0.4 -0.4 -0.7 -0.1 -0.3  0.7  4.6 -0.7  1.  -1.6  0.6 -0.2 -0.  -0.  -0.7 -0.7 -0.6  3.2 -0.5 -0.2  6.9 -0.4  0.6 -1.  -0.4  6.7 -0.   1.2 -1.5 -0.3 -0.2 -0.3  0.9 -0.1  2.2 -0.5  8.1 -0.4 -0.5 -0.8  0.5 -0.3 -0.5  0.9  0.8 -0.6 -0.1  2.7 -0.5 -1.6 -1.2 -0.9 -0.5  0.4 -0.5 -0.8 -1.5 -2.3  1.  -0.8 -0.2 -0.4 -0.9 -0.5 -0.6 -0.3 -2.6 -0.2 -0.2  0.9 15.8 -0.1  7.  -0.2 -0.1 -4.2 -3.5 -1.2 -1.  -0.6  0.7 -4.9 -0.   9.2  0.2  4.4  7.1]
ty_50sample [[7 0 9 3 3 5 6 2 4 8]
 [7 3 0 5 6 2 4 1 1 8]
 [8 6 7 9 4 5 3 1 2 0]
 [4 9 7 3 8 0 2 5 6 1]
 [3 9 8 0 2 1 6 5 7 4]
 [0 0 1 2 6 5 4 4 7 3]
 [2 7 4 5 8 3 3 1 1 0]
 [8 1 7 5 5 2 3 4 9 0]
 [0 3 4 1 2 8 9 5 7 6]
 [9 1 6 3 4 5 0 8 7 2]]
tt_50sample [[7 0 9 1 3 6 5 2 4 8]
 [7 3 0 5 6 2 4 1 9 8]
 [8 6 7 9 4 5 3 1 2 0]
 [4 9 7 3 8 0 2 5 6 1]
 [3 9 8 0 2 1 6 7 5 4]
 [0 8 1 2 6 5 4 9 7 3]
 [7 2 4 5 8 3 6 9 1 0]
 [8 1 7 6 5 2 3 4 0 9]
 [0 3 4 1 8 2 9 5 7 6]
 [9 1 6 3 4 5 0 8 7 2]]
vm  [ 1.1  0.5  4.2 12.  -1.7 -0.4 -0.  -0.1 -0.7 -0.5  6.9  0.3 -0.4 -0.5 -1.2 -0.3  0.2 -0.5  0.6 -1.5 -0.8 -0.2 -1.4  0.6 -1.   3.7 -0.4 -0.  -1.6 -1.7  1.4 -0.2 -0.8  6.6 -0.2 -0.1  2.8  5.4 18.6 -0.6 -0.2 -1.5  0.1  2.2 -0.4 -0.3  8.2 -0.5  3.8 -3.  -0.5  0.   2.4 -0.4 -0.   2.3 -0.5  2.  -0.4 -0.2 -1.8 -0.1  0.7  0.6 -0.6 -0.3  0.3 -0.3 -0.3 -0.1 -0.5  4.  -0.  -0.3  3.  -0.3 -0.5 -0.1 -0.8 -0.  16.3 -0.2 -0.4 -0.8 -1.3 -1.6  1.  -0.2  0.6 -0.2 -0.3 -0.4  0.7  1.9 -0.2 -0.3 -0.1 -0.1 -0.5 -0.5  2.4 -1.2 -1.  -0.4 -0.5  0.9  2.4  1.   2.  -2.3 -0.3  0.1 -0.  -0.1  0.9 -1.9 -0.1 -0.4 -0.  -0.4 -0.3  7.9 -0.6 -0.  -0.4 -1.3 -0.2  3.9  0.3  0.8 -0.5  0.7  0.  -0.  -4.4 -2.  -0.5 -0.3  0.9 -0.3 -0.1 -1.1 -0.4  0.3 -0.4 -0.1 -0.2 -0.5 -0.2 -0.3 -1.  -0.1  1.  -0.1 -0.6 -0.3 -0.4 -0.2  4.2 -0.2 -0.5 -2.3 -0.1  0.2 -0.2 -0.2 -0.4 -0.5 -0.5  0.2 -0.4 -0.7 -0.3 -0.1 -0.1  1.7  3.5  1.4 -3.  -0.2 -0.7  0.8  0.9 -1.  -0.3 -0.1  4.2 -0.5 -0.2  5.4 -0.5  0.3 -0.6 -1.  10.3  1.3  2.8  0.3  0.1 -0.2 -0.2  0.3 -0.1  0.3 -0.7  6.2 -0.1 -0.4 -0.8 -0.4 -0.2 -1.1 -0.4 -0.6  0.   0.1 -0.9 -0.7 -0.3 -0.5 -0.2 -0.5 -0.  -0.8 -2.3 -1.3 -0.4  0.3  1.1  1.6 -0.8 -0.9 -0.4 -0.7  2.4 -0.8 -0.1  3.5 -0.3 12.4 -0.2  5.8 -0.3 -0.1 -3.4 -2.9 -0.3 -0.3 -0.6 -0.5 -4.   0.2 13.6  1.2  2.4  0.6]
vy_50sample [[3 3 0 2 7 5 4 1 8 6]
 [1 8 6 5 4 0 9 7 2 3]
 [7 3 8 1 4 0 5 6 9 2]
 [0 4 3 1 8 2 9 5 6 7]
 [1 7 4 2 3 0 6 9 5 8]
 [9 5 0 2 6 4 1 8 8 7]
 [8 9 1 1 4 5 3 2 0 6]
 [4 1 3 5 8 2 6 0 7 9]
 [7 8 2 6 4 5 9 0 3 1]
 [7 6 6 4 1 3 2 5 9 0]]
vt_50sample [[3 9 0 2 7 5 4 1 8 6]
 [1 8 6 5 4 0 9 7 2 3]
 [7 3 8 1 4 0 5 6 9 2]
 [0 4 3 8 1 2 9 5 6 7]
 [1 7 4 0 2 3 6 9 5 8]
 [9 5 0 2 6 4 1 3 8 7]
 [8 9 1 7 4 5 3 2 0 6]
 [4 1 3 5 8 2 6 0 7 9]
 [7 8 2 6 4 5 0 9 3 1]
 [7 8 6 4 1 3 2 9 5 0]]
Epoch 22110: Training cost= 0.3507, Training acc= 0.8219, Validation cost= 0.2842, Validation acc= 0.8221
Epoch 22120: Training cost= 0.2758, Training acc= 0.8219, Validation cost= 0.2690, Validation acc= 0.8221
Epoch 22130: Training cost= 0.3134, Training acc= 0.8219, Validation cost= 0.2260, Validation acc= 0.8222
Epoch 22140: Training cost= 0.3621, Training acc= 0.8220, Validation cost= 0.3108, Validation acc= 0.8222
Epoch 22150: Training cost= 0.2260, Training acc= 0.8220, Validation cost= 0.3076, Validation acc= 0.8222
Epoch 22160: Training cost= 0.3313, Training acc= 0.8220, Validation cost= 0.2968, Validation acc= 0.8222
Epoch 22170: Training cost= 0.2718, Training acc= 0.8220, Validation cost= 0.3138, Validation acc= 0.8223
Epoch 22180: Training cost= 0.3192, Training acc= 0.8221, Validation cost= 0.2655, Validation acc= 0.8223
Epoch 22190: Training cost= 0.2797, Training acc= 0.8221, Validation cost= 0.2856, Validation acc= 0.8223
Epoch 22200: Training cost= 0.2957, Training acc= 0.8221, Validation cost= 0.2912, Validation acc= 0.8223
tm  [ 0.2 -0.4  1.6  5.3 -1.8 -0.3 -0.1 -0.2 -1.  -0.3 -1.9 -0.1 -0.7 -0.6 -0.3 -2.7 -0.4 -0.5  1.  -1.1 -0.9 -0.4 -0.4  0.3 -1.2  4.3 -0.4 -0.6 -2.2 -0.5  2.6 -0.4 -0.7  6.1  0.7  0.2  3.9 -1.   6.7 -0.6 -0.4 -0.3  1.3  2.4 -0.3 -0.2  3.9  0.8  5.2 -0.7 -0.4 -0.4  1.3 -2.7  3.1  1.4 -0.9 -0.6 -0.6 -0.6 -1.3 -0.2 -0.6  2.2 -0.4  1.   0.1 -0.4  1.5  1.8 -0.3  6.  -0.3  0.3  0.9 -0.3 -0.7 -0.4  0.5  1.3  9.8  0.2 -0.2 -0.3 -1.2 -0.2  4.9 -0.2 -0.  -0.6  0.5 -0.6 -0.4  0.1 -0.1  0.5 -0.3 -0.8 -0.4 -0.1  0.7  3.2 -0.8 -0.4 -0.2  2.   1.5  3.3 -0.4 -2.  -0.6 -0.2 -0.1  0.1  3.  -2.7 -0.2 -0.3 -0.3 -0.2  0.4  7.7 -0.6 -0.1 -0.1 -0.4 -0.3 12.2 -0.2 -0.4  1.7  0.1 -0.2 -0.4 -1.5  3.2 -0.4 -0.1 -0.1 -0.5  4.6 -1.4  1.9 -0.1 -0.3 -0.4 -0.2 -0.3 -1.  -0.3 -0.1  0.1  2.   0.3 -0.1 -0.  -0.  -0.2  0.4 -0.4  0.1 -0.8  0.4  0.4 -0.2 -0.4 -0.7 -0.4 -0.1 -0.3 -0.4 -0.4 -0.   0.1 -0.3  3.1 -0.4  2.4 -0.6  0.2 -1.  -0.1 -0.2 -1.5  0.7 -0.   4.2 -0.1  0.6  1.3 -0.2 -0.3 -0.2 -0.9  9.2  2.   1.5 -0.1  0.   0.2  0.5 -0.2 -0.2 -0.3 -0.1  3.2 -0.3 -0.3  0.4 -0.3 -0.3 -1.8 -1.  -0.4 -0.5 -0.6 -0.4 -0.5 -0.5  0.5 -0.6 -0.4 -0.2 -0.7  0.1 -1.4 -1.9 -0.8  1.5  2.  -0.7 -1.5 -0.1 -0.1  4.6 -0.1  2.   3.1  2.7  8.2 -0.1  3.8 -0.3 -0.1 -1.7 -1.8  0.3  0.8 -0.9 -0.7 -2.4 -0.1  5.   0.5  4.8  3.9]
ty_50sample [[0 9 7 4 3 6 5 8 1 2]
 [0 9 1 4 5 6 8 2 7 3]
 [8 6 9 7 5 1 4 3 2 0]
 [6 5 0 7 4 9 1 3 2 8]
 [8 4 1 7 3 9 9 2 6 0]
 [8 0 4 5 9 3 2 1 7 6]
 [0 6 3 4 2 5 8 7 9 1]
 [7 2 5 8 9 6 3 0 4 1]
 [7 0 0 5 2 1 6 3 4 8]
 [8 9 5 3 2 7 6 4 1 0]]
tt_50sample [[0 9 7 4 3 6 5 8 1 2]
 [0 9 1 4 5 6 8 2 7 3]
 [8 6 9 7 5 1 4 3 2 0]
 [6 5 0 7 4 9 1 3 2 8]
 [8 4 1 7 3 5 9 2 6 0]
 [8 0 4 5 9 3 2 1 7 6]
 [0 6 3 4 2 5 8 7 9 1]
 [7 2 5 8 9 6 3 0 4 1]
 [7 0 9 5 2 1 6 3 4 8]
 [8 5 9 3 2 7 6 4 1 0]]
vm  [-0.5  0.9  8.8 10.2 -2.1 -0.3  0.3 -0.2 -1.4 -0.7 -0.9  1.5 -0.7 -0.3  4.1 -0.4 -0.4 -0.3 -0.  -1.3 -0.9 -0.  -0.5 -0.1 -1.4  1.4 -0.2 -0.  -0.5  0.3 -0.1 -0.4 -0.2  9.1 -0.8  0.2  3.5  1.7 11.2 -0.3  0.   1.8  3.6  2.1 -0.2 -0.4  7.6  1.  -0.8 -1.1 -0.8 -0.2  0.9 -1.6 -1.3 -0.2 -0.7  5.9 -1.7  2.6  0.4 -0.3 -0.3 -0.6  0.7 -0.7 -0.2 -0.3 -0.  -0.3  0.2 -0.2 -0.1 -0.8 -0.5 -0.2  0.7 -0.4 -0.4 -0.1  8.1 -0.1 -0.6  0.6  0.2  2.5 -0.3 -0.1  0.4 -0.4 -0.1  1.5 -0.1  3.5 -0.3 -0.2  0.3 -0.1 -0.2 -0.1  4.3  4.3  0.5 -0.1 -0.3 -0.5 -1.  -0.  -0.1 -1.3  0.6 -0.4 -0.2 -0.5 -0.7  0.9  0.4 -1.  -0.1 -0.5 -0.3  4.  -0.3 -0.4 -0.3  5.   1.3  8.8 -0.5  2.  -0.8  0.2 -0.2  0.7 -6.  -1.6  0.3 -0.3 -0.1 -1.   1.2 -0.3  0.8 -0.1 -0.1 -0.1 -0.1 -0.4 -0.1 -0.4 -1.1 -0.1 -0.3  0.7  0.1 -0.3 -0.1 -0.1  3.4 -0.8 -0.7 -1.5 -0.2 -0.  -0.1 -0.4 -0.4 -0.7 -0.5  0.3 -0.2 -0.   0.2 -0.1 -0.   1.2 -0.3 -0.4 -1.6 -0.1 -1.5 -0.4  1.3 -1.3 -0.8 -0.1  0.5 -0.7 -0.2  0.8 -0.3 -0.3 -0.6 -1.1  2.6  4.1 -0.2  1.3 -0.2 -0.4 -0.2 -0.4 -0.1 -0.2 -0.4 -0.1 -0.1 -0.3 -2.2 -0.5 -0.5 -0.   0.1  3.  -0.2 -0.1 -0.4 -0.5 -0.1 -0.1 -0.5 -0.1  1.4 -0.5 -1.7  0.4 -1.5 -0.4 -0.3 -0.7 -0.7  0.4 -0.2 -1.4 -0.2 -1.8 -0.  -0.1 -0.1 -0.5 -0.1 -0.1 -0.3 -0.2 -1.4 -1.9 -0.2 -0.6 -0.6 -0.4 -2.4 -0.2  8.4 -0.2  5.8  0.6]
vy_50sample [[7 5 3 9 1 0 8 4 2 6]
 [9 5 2 4 1 8 3 0 6 7]
 [0 1 5 6 6 2 2 4 7 8]
 [9 1 5 2 0 8 4 6 7 3]
 [9 4 1 2 8 7 3 5 5 6]
 [3 5 1 8 6 0 7 4 2 9]
 [9 6 0 2 1 4 3 7 5 8]
 [2 3 0 6 1 4 7 5 9 8]
 [2 4 6 8 9 7 5 0 3 1]
 [1 1 3 2 8 8 5 0 7 9]]
vt_50sample [[7 5 3 1 9 0 8 4 2 6]
 [9 5 2 4 1 8 3 0 6 7]
 [0 1 5 6 3 9 2 4 7 8]
 [9 5 1 2 0 8 6 4 7 3]
 [9 4 1 2 8 7 3 0 5 6]
 [3 5 1 6 8 0 7 4 2 9]
 [9 6 0 2 1 4 3 7 5 8]
 [2 3 0 6 1 4 7 5 9 8]
 [2 4 6 8 9 7 0 5 3 1]
 [1 3 2 4 6 8 5 0 7 9]]
Epoch 22210: Training cost= 0.2881, Training acc= 0.8221, Validation cost= 0.3063, Validation acc= 0.8224
Epoch 22220: Training cost= 0.3087, Training acc= 0.8222, Validation cost= 0.2660, Validation acc= 0.8224
Epoch 22230: Training cost= 0.3137, Training acc= 0.8222, Validation cost= 0.3006, Validation acc= 0.8224
Epoch 22240: Training cost= 0.3035, Training acc= 0.8222, Validation cost= 0.3332, Validation acc= 0.8224
Epoch 22250: Training cost= 0.2919, Training acc= 0.8222, Validation cost= 0.2846, Validation acc= 0.8225
Epoch 22260: Training cost= 0.2569, Training acc= 0.8223, Validation cost= 0.2837, Validation acc= 0.8225
Epoch 22270: Training cost= 0.3083, Training acc= 0.8223, Validation cost= 0.3605, Validation acc= 0.8225
Epoch 22280: Training cost= 0.3170, Training acc= 0.8223, Validation cost= 0.2892, Validation acc= 0.8225
Epoch 22290: Training cost= 0.2851, Training acc= 0.8223, Validation cost= 0.2999, Validation acc= 0.8226
Epoch 22300: Training cost= 0.3580, Training acc= 0.8224, Validation cost= 0.2712, Validation acc= 0.8226
tm  [-0.8  0.1 -0.6 14.8 -0.4  0.2  0.1 -0.2 -0.5 -0.2 -0.1 -0.6 -0.2 -0.2 -3.4  5.  -0.2 -0.1 -0.1 -2.1 -0.6 -0.2  2.4  0.2 -0.7  0.1 -0.3 -0.2 -0.3 -0.1 -1.3 -0.6 -0.2 -4.1 -0.1  0.7  2.4  2.8  9.6 -0.1 -0.   6.8  1.3 -0.1 -0.1 -0.4 10.6 -0.8 -0.5 11.8 -0.5 -0.3 -0.1 -0.7 -0.9  5.6 -0.2  6.5 -0.8  4.4 -0.9 -0.2 -0.6 -0.2 -0.8 -0.3 -0.1 -0.2  0.  -0.3 -0.2 -0.5 -0.2 -0.5  6.5 -0.1  0.7 -0.4 -0.1  0.7  4.7  0.1 -0.4  1.1 -0.   8.6 -0.5 -0.2 -0.3 -0.2  0.2 -0.1 -0.2 -0.1 -0.1 -0.   0.2  1.1 -0.2 -0.2  1.   2.6 -0.2 -0.  -0.1 -0.5  1.6 -1.2 -0.  -2.4 -0.5 -0.3 -0.1 -0.2 -0.4  2.8 -0.3 -1.5 -0.2 -0.4 -0.1  9.  -0.2 -0.5  0.3 -4.  -0.   4.6  0.1 -3.  -0.5 -0.3 -0.1 -0.6  7.4 -2.  -0.  -0.  -0.2 -0.4 -0.6 -0.5 -1.  -0.4 -0.3 -0.2 -0.2 -0.2  7.1 -0.  -1.  -0.2  1.5 -0.5 -0.1  0.2 -0.1 -0.8  0.  -0.4  0.2 -0.2 -0.3 -0.  -0.3  0.1 -0.  -0.4 -0.2 -0.   0.1 -0.2 -0.2  0.3 -0.3 -1.6 -0.7  0.4 -1.4 -0.4 -1.8 -0.4 -0.1 -0.9 -0.4  0.2  0.9 -0.1 -0.   0.8 -0.1 -0.3 -1.1 -0.5  6.2  0.9  3.4  2.  -0.1 -0.2 -0.2 -0.2 -0.4 -0.3 -0.1  4.1 -0.2  0.5 -0.2 -0.1  0.2  0.1 -0.1  2.8 -0.5 -0.5  2.  -0.2 -0.1 -0.1  0.2  0.  -0.3 -0.5  3.3  2.5  1.   1.4 -0.5 -0.2 -0.9 -1.  -0.1  0.2 -0.   2.3  0.1  4.2 -0.1  3.8 -0.2  1.8  0.4 -0.3 -0.7 -2.9  1.4 -0.2 -0.7 -0.4 -1.4 -0.2  7.1  0.4 -1.2 14.4]
ty_50sample [[9 5 8 2 1 6 0 4 7 3]
 [2 1 0 6 8 9 7 4 5 3]
 [1 4 2 5 0 6 3 8 9 7]
 [3 6 8 4 1 5 9 2 7 0]
 [2 9 0 3 6 4 1 5 8 7]
 [8 3 9 2 5 7 4 6 1 0]
 [3 4 0 7 5 2 9 1 8 6]
 [3 1 7 8 5 6 6 2 9 4]
 [7 1 3 2 8 4 6 0 9 5]
 [6 0 1 1 8 3 9 4 5 7]]
tt_50sample [[9 5 8 2 1 6 0 4 7 3]
 [2 1 0 6 8 9 7 4 5 3]
 [1 4 2 5 0 6 3 8 9 7]
 [3 6 8 4 1 5 9 2 7 0]
 [2 9 0 3 6 4 1 5 8 7]
 [8 3 9 2 5 7 4 6 1 0]
 [3 4 7 0 2 5 9 1 8 6]
 [3 7 1 8 5 0 6 2 9 4]
 [7 1 3 2 8 4 6 0 9 5]
 [6 0 2 1 8 3 4 9 5 7]]
vm  [-0.2 -0.1 -1.3  6.7 -1.5  0.  -0.1 -0.1 -0.6 -0.6  4.2  0.3 -0.2 -0.2 -1.9 -1.  -0.2 -0.6 -0.3 -1.1 -1.  -0.2 -0.5  1.5 -1.2  5.5 -0.2 -0.2 -1.9 -2.   2.6 -0.1 -0.5 -0.2 -0.2  0.2  4.5  3.2 12.6 -0.5  1.4  1.8  1.8  3.8 -0.1  0.6  5.3 -0.2  2.  -1.2 -0.5 -0.3  1.5 -1.   2.2  4.1 -0.6  2.7 -0.1 -0.5 -0.7 -0.4  0.9  2.5 -0.3 -0.  -0.1 -0.2 -0.2  0.7 -0.3  4.8 -0.3 -0.   0.4 -0.3 -0.4 -0.1 -0.3  0.4 10.7  0.2 -0.  -0.4 -0.7  1.6  1.8 -0.2  0.4 -0.3 -0.1 -0.2 -0.   1.  -0.1 -0.1  0.6 -0.8  0.4 -0.4  2.1 -1.6 -0.4 -0.2 -0.2 -0.1  0.2  3.   1.3 -1.3 -0.7  0.8 -0.  -0.4  3.2 -2.4 -0.4 -0.7 -0.3 -0.  -0.1  5.3 -0.5  1.1 -0.6 -2.1 -0.   6.4  2.5 -0.4 -0.5  0.2 -0.3 -0.2 -0.6 -1.2 -0.1 -0.   1.9 -0.5  1.8 -1.4 -0.2 -0.  -0.3 -0.4 -0.3 -0.4  6.5 -0.1 -0.6 -0.1  0.4  0.5 -0.3  0.1 -0.3  1.   4.4  0.4 -0.3 -1.7 -0.3  0.2  0.2 -0.3 -0.4 -0.8  0.3  0.3  0.2  0.2 -0.1 -0.  -0.2 -1.1  0.8  1.4 -1.7 -0.1 -1.1 -0.1 -0.3 -1.3  0.1 -0.4  2.3 -0.3 -0.2  6.1 -0.4 -0.3 -0.4 -1.1  6.4 -0.1  0.8 -0.3 -0.1  0.7 -0.1  0.1 -0.2 -0.4 -0.2  2.7 -0.1 -0.3 -2.1  0.5 -0.3 -1.1 -0.4  1.1 -0.6 -0.5 -1.  -0.8 -0.7 -0.4 -0.5 -0.1  0.1 -0.9 -1.4 -1.2 -1.1  0.2  0.6  0.9 -0.6 -1.1 -0.2 -1.5  5.2  3.9  1.4  2.6  1.3  3.   0.5  1.2 -0.4  0.2 -1.9 -2.2 -0.1 -0.3 -1.2 -0.4 -2.8 -0.1  9.2  0.5  2.9  3.8]
vy_50sample [[0 9 5 3 4 2 1 8 7 6]
 [9 1 3 0 7 2 8 6 5 4]
 [6 8 4 9 1 3 2 0 5 7]
 [1 3 5 9 9 7 4 4 0 6]
 [7 6 2 3 8 5 9 1 4 0]
 [8 3 5 7 2 4 4 1 0 9]
 [8 3 4 0 1 9 6 2 7 5]
 [5 4 0 1 2 8 9 9 3 6]
 [8 0 1 4 9 6 2 5 7 3]
 [7 3 2 4 9 9 6 1 0 0]]
vt_50sample [[0 9 5 3 4 2 1 8 7 6]
 [9 1 3 0 7 2 8 5 6 4]
 [6 8 4 9 1 3 2 0 5 7]
 [1 3 5 9 7 2 4 8 0 6]
 [7 6 2 3 8 5 9 1 4 0]
 [8 3 5 7 2 4 6 1 0 9]
 [8 3 4 0 9 1 6 2 7 5]
 [5 4 0 1 2 8 7 9 3 6]
 [8 0 1 4 9 6 2 5 7 3]
 [7 3 2 4 5 9 6 1 8 0]]
Epoch 22310: Training cost= 0.2988, Training acc= 0.8224, Validation cost= 0.2741, Validation acc= 0.8226
Epoch 22320: Training cost= 0.2686, Training acc= 0.8224, Validation cost= 0.3208, Validation acc= 0.8226
Epoch 22330: Training cost= 0.3254, Training acc= 0.8224, Validation cost= 0.2643, Validation acc= 0.8227
Epoch 22340: Training cost= 0.2983, Training acc= 0.8225, Validation cost= 0.3154, Validation acc= 0.8227
Epoch 22350: Training cost= 0.2711, Training acc= 0.8225, Validation cost= 0.2801, Validation acc= 0.8227
Epoch 22360: Training cost= 0.2677, Training acc= 0.8225, Validation cost= 0.2919, Validation acc= 0.8228
Epoch 22370: Training cost= 0.2714, Training acc= 0.8226, Validation cost= 0.3044, Validation acc= 0.8228
Epoch 22380: Training cost= 0.3277, Training acc= 0.8226, Validation cost= 0.2964, Validation acc= 0.8228
Epoch 22390: Training cost= 0.3242, Training acc= 0.8226, Validation cost= 0.3015, Validation acc= 0.8228
Epoch 22400: Training cost= 0.2864, Training acc= 0.8226, Validation cost= 0.2843, Validation acc= 0.8229
tm  [-1.  -1.   0.9 -0.2 -1.7  0.7 -0.1 -0.2  0.  -0.2  0.9 -0.5 -0.6 -0.5  2.6 -1.6  0.3 -0.5  0.1 -0.1 -0.5 -0.2  1.4  0.2 -1.4  5.5 -0.2 -0.2 -1.5 -1.9  2.  -0.2 -0.7  3.9  0.1 -0.1  1.9 -0.5 -0.4 -0.4 -0.2  5.3  0.4 -0.1 -0.3 -0.4 -0.9 -0.2 -0.4  3.6 -0.6 -0.1 -0.2  0.1  2.   0.1 -0.7  3.6  3.2 -0.4  5.4 -0.1  0.   2.5 -0.   0.8 -0.  -0.2  0.8  0.2 -0.4  4.8 -0.1 -0.  -3.1  0.3  0.2  0.3 -0.   0.1  2.3  0.2  0.6 -0.2 -0.2  6.2 -0.6 -0.2 -0.3 -0.  -0.4 -0.8 -0.3 -1.  -0.3 -0.1  2.1 -2.  -0.2 -0.6 -0.3  4.5  0.2 -0.1 -0.5  0.1 -1.2  1.9  0.1 -0.3 -0.4  1.  -0.1 -0.2  5.7 -2.1 -0.6 -0.1 -0.3  0.3 -0.   0.3 -0.   0.8 -0.   2.7 -0.5  3.1  3.  -0.4 -0.2 -0.4 -0.8 -0.3  2.7  5.5 -0.4 -0.2  0.7 -0.2  1.2 -1.3  1.4  0.4 -0.3 -0.2  1.3 -0.2  3.1 -0.2  0.8 -0.2 -0.9  1.3 -0.5  0.3 -0.3 -0.2 -0.  -0.   1.  -0.3  0.5 -0.2 -0.4 -0.7 -0.7 -0.1 -0.3 -0.2 -0.  -0.1  0.4 -0.4 -0.3 -0.4 -0.7 -0.   2.4 -0.  -1.1  0.1 -0.5 -1.7  0.8 -0.7 -0.5 -0.6  0.2  5.1 -0.1 -0.4 -0.3 -0.8 -1.2 -0.3 -0.8 -0.9  0.2 -0.   0.2  0.3 -0.4 -0.4  0.7 -1.4 -0.  -0.2 -1.8  0.2 -0.  -1.3 -0.4  4.7 -1.  -0.1  1.6 -0.4 -0.5 -0.5 -0.7 -0.3 -0.2 -1.1  3.9 -1.3 -1.6  0.3  0.6 -0.1 -0.5 -0.3 -0.4 -1.4  4.1  0.2  2.2 -0.8  2.4 -1.3 -0.1 -0.6 -0.3 -0.2  0.3 -0.2 -0.  -0.3 -0.8 -0.3 -0.6 -0.1 -0.4  0.1  0.3  4.5]
ty_50sample [[0 1 5 6 7 4 9 8 2 3]
 [1 7 2 9 5 5 4 3 8 6]
 [6 9 1 2 7 3 0 8 4 5]
 [9 8 4 6 5 2 1 3 7 0]
 [2 6 1 7 3 8 9 9 0 4]
 [2 6 1 8 7 3 4 5 9 9]
 [4 8 2 6 0 9 3 5 7 1]
 [9 4 7 5 8 0 1 3 2 6]
 [5 9 6 7 2 4 4 8 1 3]
 [9 6 2 5 5 0 4 8 1 3]]
tt_50sample [[0 1 5 6 7 4 9 8 2 3]
 [1 7 2 9 5 4 0 3 8 6]
 [6 9 1 2 7 3 0 8 4 5]
 [9 8 4 6 5 2 3 1 7 0]
 [2 6 1 7 3 8 9 5 0 4]
 [2 6 1 8 7 3 4 5 9 0]
 [4 8 2 6 0 9 3 5 7 1]
 [9 4 7 5 8 1 0 3 2 6]
 [5 9 6 7 2 0 4 8 1 3]
 [9 6 2 7 5 0 4 8 1 3]]
vm  [-1.8 -0.8 -2.2  1.6 -0.3 -0.3 -0.2 -0.3 -0.4  0.6 -1.9 -0.2 -0.3 -0.2 -2.1 -0.2  2.4  0.  -0.4 -1.1 -1.3 -0.6  0.8 -0.4 -0.7  1.3 -0.2  0.4 -0.9 -2.1 -1.3 -0.3 -0.8 -6.6 -0.  -0.   1.8  3.8  8.6 -0.1 -0.4 -1.3 -0.6  2.5 -0.6 -0.2  2.4 -0.4 -1.4  7.3 -0.4 -0.2 -1.3  3.2 -0.4  3.6 -1.  -0.7  3.7  4.3  6.1  1.2 -0.8 -0.  -1.3 -0.1 -0.2  0.2 -0.1 -0.1 -0.4  2.   0.1 -0.2 -2.8 -0.2  1.7 -0.1 -0.2  0.4 -3.1  0.2 -1.1  1.5  2.  -1.4 -1.1 -0.3  0.8 -0.3 -0.6 -0.4 -0.2  0.  -0.3 -0.2 -0.3 -1.7 -0.6 -0.3  0.  -1.8  1.5  0.6 -0.6 -0.3 -1.6 -1.4 -0.8 -1.7  1.4 -0.6 -0.4 -0.5  3.9 -1.  -0.2 -0.3  0.  -0.4 -0.2  6.1  0.3 -0.1 -0.1 -2.4 -0.4 -0.1  2.2  2.8 -1.4 -0.2 -0.5  1.1  3.6 -6.2 -0.5 -0.  -0.3  0.5 -0.6 -1.2 -1.  -0.3 -0.3 -0.3  0.4 -0.2  3.1 -0.4  0.1 -0.2  1.1 -0.3 -0.2 -0.5 -0.  -0.8  2.7 -0.3 -0.4 -1.6 -0.3 -0.3 -0.8 -0.2 -0.4  1.1 -0.6 -0.4 -0.5 -0.3 -0.2 -0.5  0.1 -0.4  1.9 -0.9 -1.1 -0.5 -0.2  1.2 -0.  -0.6  0.4  1.5 -1.   0.7 -0.5  6.8 -0.4 -0.4 -0.5 -0.7 -1.7 -0.3 -0.8 -0.4 -0.2 -0.1  0.4 -0.   0.1 -0.2  0.2 -1.4 -0.3  1.  10.6  0.2 -0.5 -1.2 -0.3  4.   0.1  0.3 -0.9 -0.6 -0.3 -0.9  0.  -0.6 -0.4 -1.1 -1.1 -0.2 -0.5  0.2 -0.6 -0.6 -0.9  0.8 -0.6  6.   1.7  3.5  0.2 -1.2 -0.   9.5 -0.4  4.6 -0.3 -0.3 10.6 -0.3  1.  -0.5 -0.5  0.   6.9  0.6  6.1  0.1  0.7 -0. ]
vy_50sample [[8 1 0 2 3 4 9 5 6 7]
 [8 4 9 6 3 1 2 7 0 5]
 [4 3 6 8 8 9 7 0 0 5]
 [2 6 4 1 8 5 5 9 0 7]
 [1 9 9 3 2 4 6 0 5 7]
 [2 3 6 6 4 0 7 5 5 8]
 [9 1 2 6 3 3 5 8 0 4]
 [1 0 6 7 8 2 9 4 5 3]
 [0 4 2 3 9 5 8 6 1 7]
 [3 8 0 1 4 9 7 2 5 6]]
vt_50sample [[8 1 0 2 3 4 9 5 6 7]
 [8 4 9 6 3 1 2 0 7 5]
 [4 3 6 1 8 9 7 0 5 2]
 [2 6 4 1 8 5 3 9 0 7]
 [1 8 9 3 2 4 0 6 5 7]
 [2 3 6 9 4 0 1 7 5 8]
 [9 1 2 6 7 3 5 8 0 4]
 [1 0 6 7 8 2 9 4 5 3]
 [0 4 2 3 9 5 8 6 1 7]
 [3 8 0 1 4 9 7 2 5 6]]
Epoch 22410: Training cost= 0.2647, Training acc= 0.8227, Validation cost= 0.2922, Validation acc= 0.8229
Epoch 22420: Training cost= 0.3513, Training acc= 0.8227, Validation cost= 0.3188, Validation acc= 0.8229
Epoch 22430: Training cost= 0.3179, Training acc= 0.8227, Validation cost= 0.4183, Validation acc= 0.8229
Epoch 22440: Training cost= 0.2767, Training acc= 0.8227, Validation cost= 0.2777, Validation acc= 0.8230
Epoch 22450: Training cost= 0.3097, Training acc= 0.8228, Validation cost= 0.3441, Validation acc= 0.8230
Epoch 22460: Training cost= 0.3248, Training acc= 0.8228, Validation cost= 0.3246, Validation acc= 0.8230
Epoch 22470: Training cost= 0.3081, Training acc= 0.8228, Validation cost= 0.3680, Validation acc= 0.8230
Epoch 22480: Training cost= 0.2981, Training acc= 0.8228, Validation cost= 0.3232, Validation acc= 0.8231
Epoch 22490: Training cost= 0.2839, Training acc= 0.8229, Validation cost= 0.3423, Validation acc= 0.8231
Epoch 22500: Training cost= 0.2720, Training acc= 0.8229, Validation cost= 0.4123, Validation acc= 0.8231
tm  [-0.6  0.9 -1.8 -1.6 -0.9 -0.2 -0.1 -0.3 -1.1  0.4  3.5 -0.7  0.6 -0.  -0.3  1.9  0.9 -0.4 -0.4 -1.4 -1.1 -0.8  1.6 -0.1 -0.9  0.9 -0.4  0.7 -0.8  3.6  2.6  0.4  1.2 -1.3 -0.2 -0.   4.1 -0.5 -2.2 -0.1 -0.5 -0.1 -0.1  0.4 -0.2  0.3  2.1 -0.6  0.7  8.8 -0.5 -0.1 -0.5  4.6 -0.2  1.5 -0.6 -2.5 -0.2 -0.5  0.2  1.3 -0.9  0.1 -1.  -0.1 -0.4 -0.2 -0.2  0.1 -0.2  0.8 -0.2 -0.  -2.3 -0.   0.4  0.9 -0.3 -0.4 -0.3 -0.3 -0.6 -0.2 -0.5 -0.3  3.2 -0.1  0.1 -0.2 -1.1 -0.   0.4  1.3 -0.1 -0.2 -0.1 -1.1 -0.5 -0.1 -0.   3.8 -0.1 -0.  -0.2 -0.2 -1.4  2.7  1.  -1.8 -0.7 -0.2 -0.3 -0.3  1.  -0.2 -0.1 -1.  -0.3 -0.4 -0.3  5.5 -0.3 -0.2 -0.4 -0.3 -0.1 -0.8 -0.8 -1.5  1.  -0.6 -0.8 -0.  10.7  9.4 -0.5 -0.2 -0.4 -0.5 -0.9 -0.9 -0.5 -0.2 -0.5  0.5 -0.3 -0.3 -0.7 -0.1  1.1 -0.1  1.  -0.4 -0.3 -0.6 -0.5  0.  -1.6 -0.5 -0.2  3.4 -0.4 -0.1 -0.7  0.8  0.2  0.3 -0.2 -0.6 -0.  -0.4 -0.3 -0.5 -0.   2.8 -1.  -0.4  5.4 -0.7  1.5  0.9 -0.1 -0.2 -0.3 -0.1  0.3 -0.6 -0.3 -0.9 -0.3 -0.2 -0.3 -0.7  2.6  2.8 -0.5  0.7 -0.4 -0.1 -0.6 -0.1 -0.2  0.6 -0.1 -1.6 -0.3 -0.2  7.3  0.6 -0.1 -0.5 -0.7  0.1  1.5 -0.4  0.9 -0.6 -0.4 -0.8 -0.1  0.1 -0.3 -0.8  5.2  0.1 -0.   0.   0.2  0.7  1.5 -0.1 -0.5  4.9  2.7  4.   0.4 -0.7 -0.  13.6 -0.2  6.4 -0.  -0.2  3.  -0.5 -0.3 -0.5 -1.1  0.   0.3 -0.3 -1.5 -0.3 -1.   8.6]
ty_50sample [[6 4 2 0 8 9 7 7 3 5]
 [8 0 2 4 9 3 5 6 7 7]
 [0 9 1 5 2 7 4 6 3 8]
 [0 9 9 8 4 2 5 7 3 6]
 [3 4 0 8 6 9 7 2 5 1]
 [5 0 4 3 1 7 6 8 8 2]
 [3 8 4 5 7 6 2 0 1 9]
 [6 0 9 7 4 1 8 5 2 3]
 [5 0 3 2 4 8 8 7 7 6]
 [1 6 7 9 2 3 4 8 0 5]]
tt_50sample [[6 4 2 0 8 9 1 7 3 5]
 [8 0 2 4 9 3 5 6 1 7]
 [0 9 1 5 2 7 4 6 3 8]
 [0 1 9 8 2 4 5 7 3 6]
 [4 3 0 8 6 9 2 7 5 1]
 [5 0 4 3 1 7 6 8 9 2]
 [3 8 4 5 7 6 2 0 1 9]
 [6 0 9 7 4 1 8 5 2 3]
 [5 0 3 2 4 8 9 7 1 6]
 [1 6 7 9 2 3 4 8 0 5]]
vm  [-0.1  3.  -1.6 -3.4 -1.  -0.1 -0.3 -0.2 -1.7 -0.8 -4.   0.1 -0.6 -0.1  4.3 -0.2  0.5 -0.3 -0.2 -0.8 -0.7 -0.3  0.7  0.4 -1.5 -0.6 -0.1 -0.4 -0.2  7.3  3.2 -0.4  0.4 -0.2 -0.7 -0.   4.2 -1.6 -2.3 -0.6 -0.7  0.   2.8  1.8 -0.5  0.4 -0.5  0.5 -0.   1.2 -0.5 -0.2 -0.6 -1.3 -1.5 -0.4 -1.  -0.7 -2.  -1.   0.7 -0.3 -0.8 -0.6 -0.4  0.5  0.2 -0.3  0.2 -0.1 -0.4 -1.  -0.4 -0.2 -3.1 -0.4 -0.4 -0.1 -0.2  0.9 -1.7 -0.6 -0.3 -0.  -0.7  1.   5.4  0.4 -0.3 -0.6 -0.4  0.9 -0.2  4.2 -0.2  0.  -0.4 -1.  -0.1  0.   3.6  0.5 -0.1 -0.2  0.9  0.2 -2.   4.  -1.3 -0.8 -0.3 -0.  -0.2 -0.3 -1.2  6.4 -0.1 -1.  -0.3 -0.6 -0.3  2.3 -0.3 -0.4 -0.2  4.8  1.2  7.1 -1.2  5.2  1.4 -0.7  0.6  0.1  6.3  6.6 -0.2 -0.2 -0.2 -0.8  2.2 -0.3  2.5 -0.4 -0.2 -0.1 -0.4 -0.2  1.9 -0.1  0.8 -0.1  2.4 -0.4 -0.3 -0.2 -0.2  0.2 -1.6 -0.6 -0.3  2.4 -0.2  0.7 -0.8  1.2 -0.1 -0.3 -0.1 -0.6 -0.2  0.2 -0.3 -0.3  0.1 -0.1 -1.3 -0.7  5.6 -0.6 -1.5  0.7  0.2 -1.1 -0.7 -0.4  0.9 -0.4 -0.5 -1.9  0.3 -0.2 -0.  -1.4  2.3  4.5 -0.5  2.6 -0.1 -0.2 -0.1  0.3  0.9 -0.7 -0.2 -2.3 -0.3 -0.5  1.1 -0.2 -0.6  0.9 -0.7  0.5  1.7 -0.4 -0.2 -0.1 -0.1 -0.6 -0.7 -0.  -0.2 -0.8  2.4  4.6 -1.6 -1.  -0.   0.6 -0.2  2.2 -0.2  0.1 -0.6  4.8 -0.4 -1.3  0.4 -1.5  0.1 -0.7 -0.2 -0.4  7.   2.2 -0.4 -0.  -0.2 -0.1  4.5 -0.2 -1.9 -0.1  5.1 -0.8]
vy_50sample [[4 6 3 3 7 7 9 1 0 2]
 [6 5 1 4 7 3 2 0 0 8]
 [8 2 6 1 4 7 0 3 5 9]
 [9 7 6 8 4 3 1 2 5 0]
 [5 9 8 6 3 4 7 0 1 2]
 [6 1 8 5 0 2 3 9 4 7]
 [0 2 6 8 1 4 9 3 7 5]
 [9 5 1 1 2 7 3 0 8 6]
 [0 3 4 1 5 9 6 8 2 2]
 [6 4 3 5 5 0 1 1 9 7]]
vt_50sample [[4 6 5 8 3 7 9 1 0 2]
 [6 5 7 1 4 3 2 9 0 8]
 [8 2 6 1 4 7 0 3 5 9]
 [9 7 8 6 4 3 1 2 5 0]
 [5 9 8 6 3 4 7 0 1 2]
 [6 1 8 5 0 2 3 9 4 7]
 [0 2 6 8 1 4 9 3 7 5]
 [9 5 4 1 2 7 3 0 8 6]
 [0 3 4 1 5 9 6 8 2 7]
 [6 4 3 5 2 0 8 1 9 7]]
Epoch 22510: Training cost= 0.2783, Training acc= 0.8229, Validation cost= 0.4594, Validation acc= 0.8231
Epoch 22520: Training cost= 0.3783, Training acc= 0.8229, Validation cost= 0.3497, Validation acc= 0.8231
Epoch 22530: Training cost= 0.2752, Training acc= 0.8229, Validation cost= 0.3584, Validation acc= 0.8232
Epoch 22540: Training cost= 0.2847, Training acc= 0.8230, Validation cost= 0.2735, Validation acc= 0.8232
Epoch 22550: Training cost= 0.3720, Training acc= 0.8230, Validation cost= 0.2993, Validation acc= 0.8232
Epoch 22560: Training cost= 0.2912, Training acc= 0.8230, Validation cost= 0.2534, Validation acc= 0.8232
Epoch 22570: Training cost= 0.3297, Training acc= 0.8230, Validation cost= 0.2704, Validation acc= 0.8233
Epoch 22580: Training cost= 0.2892, Training acc= 0.8231, Validation cost= 0.3240, Validation acc= 0.8233
Epoch 22590: Training cost= 0.2678, Training acc= 0.8231, Validation cost= 0.3417, Validation acc= 0.8233
Epoch 22600: Training cost= 0.3248, Training acc= 0.8231, Validation cost= 0.3727, Validation acc= 0.8233
tm  [-1.   2.8  0.9 -0.3 -1.2  0.2 -0.2  0.6 -1.3 -1.1  3.6 -0.4 -0.1  0.1  2.8  8.8  0.7 -0.3  1.  -0.4 -0.5  0.   2.7 -0.1 -1.7  1.2 -0.1 -0.2  0.1  3.9 -0.5 -0.  -0.5 -0.9 -0.5  1.2  4.3  4.9  3.3 -0.4 -0.2  1.4  3.1  3.  -0.3 -0.1 -0.4 -1.1 -0.6  7.9 -0.3  0.3 -0.1  6.5 -1.6 -0.1 -0.8 -0.1 -1.4  2.8  4.2  0.7 -0.5 -0.1 -0.7  0.7 -0.  -0.6 -0.4  0.7  0.6 -0.7  0.7  0.8 -1.5 -0.1  1.7 -0.4  0.3  0.7 -1.7 -0.6 -0.  -0.   0.4  3.7  0.1  0.1  0.2 -0.2 -0.1 -0.2 -0.3  2.1 -0.2 -0.1  0.3 -1.2 -0.4  0.   4.4  5.1  1.9  0.5  0.7  0.6 -0.8 -0.3  1.6 -0.7 -0.8 -0.1 -0.2 -0.  -1.6  9.7  0.1 -1.8 -0.1 -0.4  0.1  3.  -0.1 -0.2  1.6  3.6  0.7 -1.5 -0.8 -0.1 -0.4 -0.2 -0.1 -0.3 -1.6 -2.4 -0.1 -0.2 -0.3  0.4 -1.1 -0.4 -0.7 -0.1 -0.1 -0.2  0.8 -0.1 -0.5  0.1 -0.1 -0.2  1.1 -0.4 -0.2 -0.2 -0.2  0.7  2.9 -0.5  0.5 -0.3 -0.3  0.1 -0.5 -0.2  0.5 -0.3 -0.1 -0.2  0.2 -0.4 -0.2 -0.3  0.1  1.7 -0.1  0.1 -0.  -0.5 -0.6  0.9 -0.1 -1.1 -0.7 -0.1 -0.5 -0.5 -0.1 -1.  -0.  -0.3  0.5 -0.8 -0.6  3.9  0.4  3.1 -0.1 -0.2  0.3  0.   0.1 -0.4  0.6 -1.2 -0.3 -0.1  4.8 -0.  -0.1  2.5  0.3  4.6 -0.3 -0.3 -0.5 -0.5  0.4 -0.3 -0.2  0.6 -0.  -0.7  1.6  4.1  3.3  1.7 -0.5 -0.8 -0.5 -0.3  0.2  3.5 -0.3  1.1 -0.4 -0.2 -0.2  1.9 -0.1  1.5 -0.  -0.4  7.1 -0.3 -0.3  1.3 -0.2 -0.7  3.5 -0.1  1.4 -0.  -1.3  3.4]
ty_50sample [[2 8 1 7 4 5 9 6 3 0]
 [6 9 5 8 1 2 7 7 3 4]
 [4 6 3 0 7 8 5 1 2 9]
 [4 3 0 2 9 7 8 8 1 6]
 [5 9 0 2 4 7 3 3 6 6]
 [4 5 0 0 7 1 3 9 6 2]
 [4 8 6 2 7 3 9 1 0 5]
 [9 3 4 6 5 7 8 1 0 2]
 [9 9 5 6 6 4 0 1 8 7]
 [1 8 6 9 5 4 3 2 0 7]]
tt_50sample [[2 8 1 4 7 5 9 6 3 0]
 [6 9 5 8 1 2 0 7 3 4]
 [4 6 3 0 7 8 5 1 2 9]
 [4 3 0 2 9 7 8 5 1 6]
 [5 9 0 2 4 7 3 8 6 1]
 [4 5 8 7 0 1 3 9 6 2]
 [4 8 6 2 7 3 9 1 0 5]
 [9 3 4 6 5 7 8 1 0 2]
 [9 2 5 6 3 4 0 1 8 7]
 [1 8 6 9 5 4 3 2 0 7]]
vm  [-0.7 -0.   8.8 12.4 -1.5 -0.3  0.1 -0.2 -1.2 -0.  10.1 -0.4 -0.   1.3  5.3  0.9  0.9 -0.4 -0.3 -0.5 -0.9 -0.4 -0.5 -0.1 -0.9  1.3 -0.3 -0.8 -1.5 -0.4 -0.7 -0.1  0.5  8.8  0.8  0.1  4.1  0.4 -2.3 -0.3 -0.3 -0.3  0.8 -2.2 -0.4 -0.2 -0.3 -1.1  0.5 -1.3 -0.2 -0.3 -0.6  7.9 -0.2 -0.5 -0.3  4.  -0.8  3.5  0.4 -0.2 -0.1  1.1 -0.6 -0.9 -0.1 -0.4 -0.5 -0.2 -0.1  3.8 -0.3  1.1 -3.4 -1.2 -0.6 -0.5 -0.1 -0.6  7.4 -0.2 -0.3 -1.1 -1.2 -0.5 -0.6 -0.1 -0.1 -0.  -0.4 -0.6 -0.1  2.1 -0.4  0.1 -0.4 -1.1  1.5 -0.5 -0.2  3.1 -0.2 -0.2 -0.4 -0.  -1.6 -0.5  0.6 -1.5 -0.2 -0.2 -0.  -0.1  0.8 -1.8 -0.4 -0.6 -0.  -0.1  1.   3.6 -0.4 -0.1 -0.2  5.8 -0.5 -1.9 -1.1  1.4  0.9  1.5 -0.1  2.6  5.9 15.3 -0.5  0.1  0.2 -0.2 -0.8 -0.4 -0.9 -0.2 -0.1 -0.1 -0.6 -0.1 -1.  -0.2 -1.3 -0.3 -0.3 -0.5 -0.5  0.1 -0.5 -0.  -1.6 -0.4 -0.4  1.6  0.6 -0.  -0.   0.2 -0.7 -0.6 -0.1  0.1 -0.  -0.5  0.6 -0.1 -0.2  3.8 -1.2 -0.3  5.4 -0.8 -0.6 -0.1  0.6 -0.7 -0.2 -0.5  0.8 -0.8 -0.2  1.2 -0.3 -0.5 -0.1 -1.   2.2  4.1 -0.7 -0.  -0.2 -0.1  0.7  0.1  0.  -0.2 -0.3 -1.2 -0.3 -0.6 -1.  -0.2 -0.6 -1.6 -0.6 -0.2 -0.5 -0.3  8.2 -0.8 -0.7  1.4 -0.2 -0.5  0.9 -0.9  3.1 -1.5  1.1  0.6 -0.8  0.5  0.8 -0.  -0.4 -0.6  1.8 -2.1  0.9 -1.  -0.4  1.9 -0.3  1.4 -0.2 -0.3 -1.2 -0.1 -0.5  0.1 -0.4 -0.3 -2.1  0.6 -1.6  0.3 -1.1  0.4]
vy_50sample [[6 2 0 7 3 3 1 5 8 4]
 [9 6 3 0 1 7 5 4 4 8]
 [0 8 2 6 7 9 1 3 5 4]
 [3 5 1 0 6 2 9 4 8 7]
 [3 3 8 1 5 7 7 9 0 2]
 [3 9 5 2 1 6 4 0 8 7]
 [0 2 4 6 8 8 3 3 1 1]
 [9 7 4 1 8 6 3 5 2 0]
 [3 5 0 4 7 7 2 1 1 8]
 [8 7 3 0 6 2 4 9 5 1]]
vt_50sample [[6 2 0 7 3 9 1 5 8 4]
 [9 6 3 0 1 7 5 4 2 8]
 [0 8 6 2 7 9 1 3 5 4]
 [3 5 1 0 6 9 2 4 8 7]
 [3 4 8 1 5 7 9 6 2 0]
 [3 5 9 2 1 6 4 0 8 7]
 [0 2 4 6 9 8 5 7 3 1]
 [9 7 4 1 8 6 3 5 2 0]
 [3 5 0 4 6 7 2 9 1 8]
 [8 7 3 0 6 2 4 9 5 1]]
Epoch 22610: Training cost= 0.3222, Training acc= 0.8231, Validation cost= 0.3378, Validation acc= 0.8233
Epoch 22620: Training cost= 0.2745, Training acc= 0.8232, Validation cost= 0.2806, Validation acc= 0.8234
Epoch 22630: Training cost= 0.2565, Training acc= 0.8232, Validation cost= 0.2704, Validation acc= 0.8234
Epoch 22640: Training cost= 0.3004, Training acc= 0.8232, Validation cost= 0.3384, Validation acc= 0.8234
Epoch 22650: Training cost= 0.3127, Training acc= 0.8232, Validation cost= 0.3078, Validation acc= 0.8234
Epoch 22660: Training cost= 0.3040, Training acc= 0.8233, Validation cost= 0.2915, Validation acc= 0.8235
Epoch 22670: Training cost= 0.2924, Training acc= 0.8233, Validation cost= 0.2440, Validation acc= 0.8235
Epoch 22680: Training cost= 0.3085, Training acc= 0.8233, Validation cost= 0.2923, Validation acc= 0.8235
Epoch 22690: Training cost= 0.2844, Training acc= 0.8234, Validation cost= 0.2652, Validation acc= 0.8236
Epoch 22700: Training cost= 0.2754, Training acc= 0.8234, Validation cost= 0.3188, Validation acc= 0.8236
tm  [-1.1 -0.3 -3.2 -1.2 -0.8 -0.2  0.5 -0.4 -0.5 -0.4  7.3 -0.2 -0.2 -0.5 -2.   1.4  0.9 -0.3 -0.7 -1.6 -1.2 -0.3 -0.6 -0.7 -0.7  1.  -0.1  0.5 -0.6 -1.1  5.4 -0.9 -0.5 -0.1  0.5  1.5  2.   3.9 10.8 -0.  -0.5 -2.2 -0.8  5.8 -0.5 -0.1  9.7 -0.7 -1.7 -1.3 -0.8 -0.  -0.5  3.4 -1.2  4.  -0.7 -3.2  2.4 -2.   4.   0.8 -0.8 -0.9  0.5 -1.1 -0.1  2.7 -0.3 -0.2 -0.4  0.2 -0.2 -0.3 -0.6  0.9  2.6 -0.2  0.8 -0.3 11.7 -0.1 -1.1 -0.5  1.1 -2.4  1.  -0.3  0.9 -0.7 -0.6 -0.  -0.3 -0.1 -1.1 -0.2 -0.8 -0.5 -0.5 -0.1  2.3 -0.7  1.2 -0.1 -0.3 -0.3 -1.7  5.5  1.  -2.1 -0.6 -0.6 -0.4 -0.3  2.3 -0.3  1.8 -0.2 -0.2  0.2 -0.1  7.8  1.5 -0.7 -0.3 -2.5 -0.2 -0.3 -0.3  1.3 -1.1 -0.4 -0.2  1.6 -0.3 -0.3 -0.8 -0.5 -0.  -1.1 -1.1  0.3 -0.6  1.5 -0.5 -0.3  0.7  0.1 -1.  -0.7  0.3 -0.5 -1.6 -0.3  0.8 -0.3  0.1  1.   0.2 -1.3 -0.5 -1.1  0.3 -0.1 -0.3  0.  -0.5  1.9 -0.5 -0.8 -0.4 -0.4 -0.6 -0.2  0.2  2.5 -0.1 -0.6 -1.4  0.1  1.6 -0.5 -0.1 -1.5 -0.1  0.6 -0.9 -0.2  0.8  3.7 -0.5 -0.5 -0.9 -0.7 -0.8  3.8 -0.2 -0.4  0.4 -0.4 -0.3 -0.3 -0.4 -0.1 -0.3 -0.5  1.3 -0.2  5.1 -0.3 -0.8 -0.9 -0.5  5.3  3.5  2.9 -2.  -0.9 -0.2  1.2  0.1 -0.5 -0.2 -1.2 -0.6 -0.2 -0.   0.4 -0.1 -0.6 -1.7  1.1 -0.1  3.5  1.2  6.4  1.1 -0.7 -0.9 18.2 -0.3  8.2 -0.2  0.  -2.4 -1.2  0.3 -0.3 -0.9 -0.8 -3.2 -0.2  8.  -0.5 -0.3  0.9]
ty_50sample [[4 1 2 0 3 0 8 7 6 5]
 [3 5 8 0 9 7 6 1 4 2]
 [2 1 9 5 7 0 3 4 6 8]
 [4 7 5 9 0 8 6 3 3 1]
 [6 1 4 3 5 8 9 0 2 7]
 [3 0 0 5 8 8 9 2 7 4]
 [9 1 7 6 8 3 2 0 4 5]
 [4 8 0 5 6 3 9 7 1 2]
 [4 1 9 2 3 5 6 8 0 0]
 [1 7 4 8 9 3 5 0 2 6]]
tt_50sample [[4 1 2 0 3 9 8 7 6 5]
 [3 5 0 8 9 7 6 1 4 2]
 [2 1 5 9 7 0 3 4 6 8]
 [4 7 5 9 0 8 6 3 2 1]
 [6 1 4 3 5 8 9 0 2 7]
 [3 0 6 5 1 8 9 2 7 4]
 [9 1 7 6 8 3 2 0 4 5]
 [4 0 8 5 6 3 9 7 1 2]
 [4 1 9 2 3 5 6 7 8 0]
 [1 7 4 8 9 3 5 0 2 6]]
vm  [-1.5  1.2  2.8 -0.4 -1.3  0.2 -0.2 -0.2 -1.1 -0.7 -0.  -0.1 -0.3  0.3  4.9  2.3 -0.1 -0.3 -0.4 -1.  -0.7 -0.3 -0.2  0.  -1.3  0.2 -0.  -0.2  1.2  3.2  2.2 -0.3 -0.2  6.9 -0.8  0.3  3.3 -1.  -1.1 -0.5 -0.4 -2.   0.4 -0.2 -0.5 -0.1  2.2 -0.2 -1.9 -0.5 -0.6 -0.1 -0.3 -0.3 -1.5 -0.5 -0.8 -1.7 -0.9 -0.7  5.7  0.6 -0.8 -0.4 -0.1  0.7 -0.2 -0.3  0.4 -0.1  0.  -1.1 -0.3 -0.2 -1.6 -0.2  1.5 -0.4  0.5 -0.1  3.3 -0.3 -0.6  1.1  2.5 -1.5 -0.3 -0.  -0.2 -0.2 -0.4  0.5 -0.2  0.  -0.3  0.1 -0.3 -0.9 -0.2 -0.2  3.6  3.7  2.8  0.4 -0.   0.4 -1.4  2.7  0.1 -1.3 -0.6 -0.4 -0.2 -0.2 -0.5  7.1 -0.2 -0.9 -0.2 -0.6 -0.1  4.4  0.6 -0.3 -0.1  5.7  1.3  3.8 -1.1  2.1 -0.2 -0.6 -0.1 -0.2  1.7  9.2 -0.3 -0.1  0.2 -0.7 -0.1 -0.1 -0.1 -0.2 -0.1 -0.3 -0.2  0.4 -2.  -0.1 -0.2 -0.3 -1.3 -0.3 -0.2 -0.  -0.2 -0.4 -1.4 -0.6 -0.5  1.8 -0.1  0.8 -0.6  0.7  0.3  2.2 -0.4 -0.3 -0.6 -0.4  0.2 -0.  -0.2  4.6 -1.  -0.4  3.9 -0.4  1.4  0.3 -0.3 -1.2 -0.7 -0.3 -1.  -0.9 -0.2 -0.8 -0.3 -0.2 -0.6 -1.1 -1.4  4.3 -0.3  1.7 -0.2 -0.2 -0.1 -0.3 -0.5 -0.5  0.7 -1.6 -0.2 -0.2  5.  -0.1 -0.3  2.1 -0.7  6.5 -0.2  0.   1.5 -0.5  0.  -0.  -0.6 -0.2 -0.3 -0.8  2.   3.6 -0.9 -0.1 -0.1 -0.7 -0.5  0.4 -0.4  3.1 -0.6 -0.3 -0.3 -0.5  0.6 10.  -0.   4.6 -0.3 -0.2 -0.1 -0.1 -0.3 -0.2 -0.3 -0.5 -0.9 -0.2 -0.9 -0.3  1.9  0.1]
vy_50sample [[1 6 7 4 3 9 8 2 5 0]
 [0 7 8 1 6 5 3 4 2 9]
 [3 0 2 6 8 5 7 1 9 4]
 [9 7 4 1 0 3 6 5 8 2]
 [7 3 5 0 2 8 4 9 6 1]
 [3 9 8 4 5 2 0 7 1 6]
 [9 5 0 1 7 2 2 8 3 6]
 [6 0 0 2 3 8 4 5 7 1]
 [7 3 1 5 6 8 8 0 4 9]
 [1 9 2 7 3 4 0 5 8 6]]
vt_50sample [[1 6 7 4 3 9 8 2 0 5]
 [0 7 8 1 6 5 3 4 2 9]
 [3 0 2 6 8 7 5 1 9 4]
 [9 7 1 4 0 3 6 5 8 2]
 [7 3 5 0 2 4 8 9 6 1]
 [3 9 8 4 5 2 0 7 1 6]
 [9 5 0 1 7 2 4 8 3 6]
 [6 0 9 2 3 8 4 5 7 1]
 [7 3 1 5 6 8 2 0 4 9]
 [1 9 2 7 3 0 4 5 8 6]]
Epoch 22710: Training cost= 0.2911, Training acc= 0.8234, Validation cost= 0.3362, Validation acc= 0.8236
Epoch 22720: Training cost= 0.3189, Training acc= 0.8234, Validation cost= 0.3866, Validation acc= 0.8236
Epoch 22730: Training cost= 0.3034, Training acc= 0.8234, Validation cost= 0.2927, Validation acc= 0.8237
Epoch 22740: Training cost= 0.2921, Training acc= 0.8235, Validation cost= 0.2709, Validation acc= 0.8237
Epoch 22750: Training cost= 0.2708, Training acc= 0.8235, Validation cost= 0.3082, Validation acc= 0.8237
Epoch 22760: Training cost= 0.3454, Training acc= 0.8235, Validation cost= 0.2794, Validation acc= 0.8237
Epoch 22770: Training cost= 0.2450, Training acc= 0.8235, Validation cost= 0.2969, Validation acc= 0.8238
Epoch 22780: Training cost= 0.2410, Training acc= 0.8236, Validation cost= 0.2717, Validation acc= 0.8238
Epoch 22790: Training cost= 0.3381, Training acc= 0.8236, Validation cost= 0.3795, Validation acc= 0.8238
Epoch 22800: Training cost= 0.2724, Training acc= 0.8236, Validation cost= 0.2666, Validation acc= 0.8238
tm  [-0.2 -0.5  4.8 13.  -1.6 -0.6 -0.4 -0.1  1.  -0.6  4.6  1.1 -0.5 -0.3 -1.1 -0.2 -0.7 -0.5  1.9 -1.1 -0.9 -0.3 -0.9 -0.3 -0.8  2.9 -0.2 -0.2 -0.7 -2.7  0.2 -0.3 -0.3  4.7 -0.6 -0.5  0.1  2.9 12.6 -0.5  0.1  1.9  0.2  1.1 -0.2  0.5  5.8 -0.1  3.  -2.  -0.6 -0.1  1.5 -1.3 -0.3  2.9 -0.   7.8  3.3  2.  -1.  -0.4  1.   1.5  1.  -0.3 -0.2 -0.3  1.4  0.4  0.4  0.6 -0.  -0.1 -0.5  0.8 -1.2 -0.4 -0.5  0.2 13.  -0.4 -0.  -0.5 -1.   2.5 -0.3 -0.2 -0.3 -0.1 -0.5 -0.4 -0.1 -0.8 -0.  -0.3  0.8 -1.4 -0.4 -0.4  2.1 -0.6 -0.7 -0.  -0.4 -0.  -0.   0.6  1.2 -1.7  0.  -0.3 -0.1 -0.5  3.2  0.4  0.4  1.1 -0.5  1.4 -0.2  5.7 -0.1  1.3 -0.5 -1.3 -0.2  7.8  6.9 -0.4 -0.2 -0.8 -0.4 -0.8 -2.8 -0.8  0.3 -0.2 -0.1 -0.6  0.1 -0.4  0.5 -0.2 -0.3 -0.1 -0.2 -0.5  4.9 -0.1 -1.   0.1  0.8 -0.  -0.2 -0.3 -0.1 -0.3  5.1  0.1 -0.5 -1.9 -0.3 -0.2 -0.5 -0.3  0.9 -0.2 -0.5  1.3 -0.3 -0.2 -0.2 -0.5 -0.2 -1.   0.   1.  -1.6  0.7 -1.7 -0.1 -0.1 -1.3 -0.1 -0.   3.3 -0.4 -0.2  8.3 -0.1 -0.1 -0.9 -0.8  7.7 -1.9  2.  -0.9 -0.2  0.5 -0.4 -0.1 -0.1 -0.4 -0.7  2.2  0.1 -0.4 -3.6 -0.3 -0.3  0.7 -0.6 -0.5 -0.9 -0.1 -0.1 -0.4  1.2 -0.6 -0.6 -0.2 -0.  -0.7 -1.6 -0.6 -1.3  0.7  1.7  4.4 -0.3 -1.1 -0.1 -2.5  0.4 -1.  -0.   3.   1.4 -0.1 -0.1  0.1 -0.1 -0.1 -2.5 -2.5 -0.1 -0.3 -1.2  0.  -3.5 -0.4  9.2  0.   3.9  3.2]
ty_50sample [[5 9 3 0 7 2 1 8 4 6]
 [8 5 3 3 2 7 4 9 6 1]
 [6 5 7 9 0 2 8 1 4 3]
 [8 2 1 1 9 6 3 4 0 7]
 [1 2 9 3 8 4 0 0 5 5]
 [0 5 4 3 2 6 1 7 8 9]
 [1 4 9 2 8 7 5 6 3 0]
 [9 2 3 1 4 6 5 7 8 0]
 [0 5 9 3 7 4 6 2 8 1]
 [7 9 9 1 3 4 2 5 5 8]]
tt_50sample [[5 9 3 0 7 2 1 8 4 6]
 [8 5 3 0 2 7 4 9 6 1]
 [6 5 7 9 0 2 8 1 4 3]
 [8 2 1 5 9 6 3 4 0 7]
 [1 2 9 3 8 4 0 6 7 5]
 [0 5 4 3 2 6 1 7 8 9]
 [1 4 9 2 8 7 5 6 3 0]
 [9 2 3 1 4 6 5 7 8 0]
 [0 5 9 3 7 4 6 2 8 1]
 [7 9 6 1 3 4 2 0 5 8]]
vm  [-1.4 -0.2  4.6  5.7 -1.2  0.5 -0.2 -0.1  1.2 -0.6  7.4 -0.4 -0.   0.2  2.5  7.3 -0.2 -0.2  0.2 -0.3 -0.8 -0.3 -0.1 -0.6 -0.8  1.4 -0.1 -0.1  2.  -1.7 -0.7 -0.7 -0.2  1.1 -0.3 -0.4 -0.   4.8  1.3 -0.4 -0.3 -2.2 -1.1 -0.3 -0.5  0.1 -0.5 -1.1 -0.6 -0.4 -0.4 -0.2 -0.2  8.4 -1.4 -0.1 -0.3 -0.2  4.6  3.6  4.6 -0.3 -0.1  1.2 -0.2 -0.1 -0.1  0.9 -0.4 -0.2  0.  -1.   0.2  0.4 -3.2 -0.1 -0.5 -0.4 -0.3 -0.  -0.5 -0.5 -0.2 -0.3 -0.3 -2.1 -1.3 -0.1 -0.2 -0.3 -0.3 -0.4  0.  -1.  -0.3 -0.2 -0.4 -1.9 -0.4 -0.4  2.  -0.4  0.2 -0.1 -0.1  1.6 -1.4 -0.6  1.7 -0.8 -0.2 -0.2 -0.3 -0.7  0.9  7.7 -0.1 -0.  -0.1 -0.1 -0.   2.  -0.1  0.5 -0.2  2.5 -0.2 -2.   3.2  3.8 -0.2 -0.6 -0.2 -0.2 -0.5 -0.4 -0.5 -0.1  0.9 -0.3 -1.1 -0.3 -1.2 -0.2 -0.3 -0.2 -0.4 -0.1 -1.3 -0.  -0.3 -0.1 -0.  -0.7  0.2 -0.  -0.2 -0.   0.8 -0.7 -0.5 -0.7  0.2  0.3 -0.2 -0.1  0.6  3.  -0.   0.2 -0.5 -0.6 -0.1  0.  -0.5  2.7 -0.3 -0.1  1.  -0.2  1.5  0.7 -0.6 -1.3 -0.5 -0.2 -0.5 -0.4 -0.3  6.1 -0.3 -0.1 -0.7 -0.7 -0.9 -1.  -0.4 -0.3 -0.2 -0.  -0.2 -0.2 -0.4 -0.6 -0.1 -1.5 -0.3 -0.3  6.4 -0.2  0.2  4.5 -0.8  4.1 -0.5 -0.3  2.6 -0.7 -0.5  0.3 -0.4 -0.3 -0.1 -1.  -0.4  3.5  2.   4.   0.4  2.  -0.5 -0.4 -0.2  3.6 -0.5 -0.8  0.2 -0.6  0.4  7.9 -0.1  3.8 -0.1 -0.4  3.5 -0.3 -0.3  0.  -1.  -0.5  0.  -0.2  1.2 -0.1 -0.5 -0.6]
vy_50sample [[2 1 3 8 7 9 9 4 0 5]
 [4 9 6 8 2 1 7 3 0 5]
 [4 0 6 9 8 5 7 1 3 2]
 [8 0 9 2 9 5 3 4 6 1]
 [6 0 8 9 4 5 7 3 1 2]
 [6 7 9 4 5 2 1 1 8 3]
 [1 3 3 9 9 4 8 5 0 2]
 [1 5 6 3 8 8 9 4 2 7]
 [7 4 3 5 1 6 8 2 2 9]
 [2 3 9 4 8 6 1 5 7 0]]
vt_50sample [[2 1 3 8 7 6 9 4 0 5]
 [4 9 6 8 2 1 7 3 0 5]
 [4 0 6 9 8 5 7 1 3 2]
 [8 0 9 7 2 5 3 4 6 1]
 [6 0 8 9 4 5 7 3 1 2]
 [6 7 9 4 5 2 0 1 8 3]
 [7 1 3 9 6 4 5 8 0 2]
 [1 5 6 3 0 8 9 4 2 7]
 [7 4 3 5 1 6 8 2 0 9]
 [2 3 9 4 8 6 1 5 7 0]]
Epoch 22810: Training cost= 0.3448, Training acc= 0.8236, Validation cost= 0.2814, Validation acc= 0.8238
Epoch 22820: Training cost= 0.3631, Training acc= 0.8237, Validation cost= 0.3362, Validation acc= 0.8239
Epoch 22830: Training cost= 0.2811, Training acc= 0.8237, Validation cost= 0.3240, Validation acc= 0.8239
Epoch 22840: Training cost= 0.2662, Training acc= 0.8237, Validation cost= 0.3198, Validation acc= 0.8239
Epoch 22850: Training cost= 0.2824, Training acc= 0.8237, Validation cost= 0.2810, Validation acc= 0.8240
Epoch 22860: Training cost= 0.3062, Training acc= 0.8238, Validation cost= 0.3310, Validation acc= 0.8240
Epoch 22870: Training cost= 0.3321, Training acc= 0.8238, Validation cost= 0.2348, Validation acc= 0.8240
Epoch 22880: Training cost= 0.2694, Training acc= 0.8238, Validation cost= 0.3124, Validation acc= 0.8240
Epoch 22890: Training cost= 0.3560, Training acc= 0.8238, Validation cost= 0.2678, Validation acc= 0.8240
Epoch 22900: Training cost= 0.2943, Training acc= 0.8239, Validation cost= 0.3206, Validation acc= 0.8241
tm  [-0.5 -0.5  1.2 -2.7 -1.5 -0.2 -0.2 -0.2  0.3 -0.9 10.2 -0.2  0.2 -0.5  8.9  5.5 -0.4 -0.1  0.4  2.2 -1.1 -0.4 -0.6 -0.4 -1.2  1.  -0.4 -0.5 -0.8 -0.5  4.9 -0.5 -0.  10.3 -0.2  0.   1.   4.9 -0.5 -0.6 -0.1 -1.  -0.6  3.4 -0.6 -0.2 -1.8 -1.4  0.1 -1.4 -0.6 -0.4 -0.3  9.1 -1.2 -0.8 -0.7 -1.7  4.1 -2.   4.8 -0.2 -0.2  2.3  0.6 -0.6 -0.1  0.6  0.1 -0.2 -0.1 -0.3  0.7  0.3 -4.1 -0.1 -0.5 -0.5  0.9 -0.   2.2 -0.1  0.1  0.3 -0.5 -0.6  1.6 -0.3 -0.2 -0.6 -0.2 -0.2 -0.1 -0.9 -0.5 -0.1 -0.4 -2.4 -0.6 -0.6  2.7  5.  -0.2 -0.  -0.  -0.1 -2.1  5.   2.   1.5 -0.7 -0.2 -0.1 -0.6  1.7  2.9 -0.1  0.1 -0.1 -0.4 -0.1 -0.6  0.5 -0.1 -0.2  9.7 -0.2 -2.3  2.7  3.9 -0.  -0.7  0.7 -0.7 -3.   5.1 -0.1 -0.1  0.1 -0.4 -0.9 -0.4 -0.8 -0.2 -0.1  0.5 -0.2 -0.2 -2.  -0.2  2.4 -0.2 -0.9 -0.7 -0.  -0.1 -0.3 -0.1  2.  -0.1  1.1 -0.7 -0.  -0.1 -0.1 -0.7 -0.1  2.5 -0.1 -0.2 -0.4 -0.5 -0.3  0.1 -0.5  4.1 -0.5 -0.5  2.7 -0.4  1.2 -0.7 -0.5 -1.5 -0.6 -0.  -0.4 -0.3 -0.4  2.   0.  -0.6 -0.2 -0.8 -1.2 -0.4 -1.1 -0.5 -0.3  0.1 -0.2 -0.4 -0.2 -0.9 -0.3 -2.7 -0.2 -0.1 -0.4 -0.3 -0.3  1.  -1.   3.7 -0.3 -0.5 -0.9 -0.8 -0.1  0.5 -0.5 -0.1 -0.4 -1.2  0.1 -0.3  2.   3.  -0.3  1.9 -0.7 -0.1 -0.  -0.1  0.1  1.   1.6 -1.3  0.2  0.  -0.   0.4 -0.3 -0.2  0.4  1.6 -0.2  0.6 -0.9 -0.6 -0.7  0.2 -0.4  0.1 -0.9 -0.8]
ty_50sample [[2 7 4 1 3 0 6 5 9 8]
 [1 6 3 9 5 8 4 2 0 7]
 [5 3 1 8 8 0 7 2 4 6]
 [2 8 4 6 0 1 7 3 5 9]
 [5 9 4 7 3 0 8 6 1 2]
 [1 4 9 9 8 0 2 6 7 3]
 [9 4 3 1 0 7 8 2 5 6]
 [6 5 4 2 9 3 8 7 1 0]
 [6 1 4 7 2 8 0 0 5 3]
 [6 4 8 2 5 3 1 7 0 9]]
tt_50sample [[2 7 4 1 3 0 6 5 9 8]
 [1 6 3 9 5 4 8 2 0 7]
 [5 3 1 8 9 0 7 2 4 6]
 [2 8 4 6 0 1 3 7 5 9]
 [5 9 4 7 3 0 8 6 1 2]
 [1 4 9 8 5 0 2 6 7 3]
 [9 4 3 1 0 7 8 5 2 6]
 [6 5 4 2 9 3 8 7 1 0]
 [6 1 4 2 7 8 0 9 3 5]
 [6 4 2 8 5 3 1 7 0 9]]
vm  [-1.5 -0.5  4.3  2.2 -1.4 -0.  -0.  -0.1 -0.3 -0.3  0.9 -0.2 -0.8 -0.3  4.9 -0.4  0.  -0.3 -0.2 -0.1 -0.5 -0.2  2.  -0.3 -1.3  3.1  0.7 -0.4 -0.5 -1.2 -0.3 -0.2 -0.4  3.4 -0.6 -0.2  2.3 -0.3 -1.2 -0.1 -0.4  7.6  1.9 -0.6 -0.8 -0.1 -1.7 -0.1 -1.1  6.9 -0.6 -0.2  0.5  2.2 -0.6 -0.5 -0.3  7.6  0.4  3.2  7.6 -0.5  0.1  0.5 -0.2  0.1 -0.2 -0.3 -0.3 -0.2  0.4  1.3 -0.3 -0.1 -4.3 -0.3  1.  -0.5 -0.1 -0.1 -0.7 -0.1  1.2 -0.6  0.7  8.7 -1.2 -0.4 -0.3 -0.  -0.1 -0.5 -0.1 -0.6 -0.3 -0.1  0.  -2.  -0.2 -0.3  0.1  5.   2.5 -0.2 -0.3  2.5 -1.7 -0.1  0.2 -0.8 -0.2 -0.1 -0.  -0.5  2.  -0.1 -0.4 -0.3 -0.1  0.5 -0.   0.7 -0.2  0.6 -0.3  6.1  0.1  0.2  2.1 -0.6 -0.4 -0.5 -0.5 -0.1  2.   4.2 -0.   0.1  0.6 -0.4 -0.1 -0.6  0.4 -0.1 -0.3 -0.  -0.  -0.2  4.8  0.4  0.6 -0.2 -1.   0.5 -0.5 -0.1 -0.8 -0.3 -0.1 -0.2 -0.2  0.6  0.6 -0.2 -0.4 -0.1 -0.  -0.1 -0.  -0.1 -0.2  0.2 -0.2 -0.5 -0.4 -0.8 -0.4 -0.6  3.5 -0.2 -1.7  0.1 -0.3 -1.2  0.8 -0.3 -1.3 -0.7  0.1  3.8 -0.3 -0.1 -0.1 -0.9 -2.3 -0.1 -0.9 -0.1 -0.2 -0.3  0.4 -0.2 -0.3 -0.3  0.  -1.9 -0.2 -0.2 -2.8 -0.3  0.9 -0.2 -0.5  6.7 -0.6 -0.4  3.1 -0.6 -0.2 -0.2 -0.5  0.6  0.1 -0.8  3.6 -0.4 -1.2  0.5  1.3 -0.6  0.2 -0.2 -0.6 -1.8  1.2 -0.9 -0.  -1.2  1.8 -3.8 -0.2 -1.6 -0.3 -0.1  4.   0.9 -0.5  0.3 -0.8 -0.1  1.2 -0.3 -0.8 -0.3 -0.1  5.8]
vy_50sample [[5 1 6 6 7 8 2 9 4 3]
 [3 5 9 8 1 6 0 4 7 2]
 [9 8 5 5 2 1 6 3 4 7]
 [7 7 9 5 6 2 8 3 4 1]
 [5 5 0 7 2 9 8 4 3 6]
 [5 6 9 3 4 1 0 2 8 7]
 [7 9 3 3 0 8 6 1 4 5]
 [7 2 0 9 1 8 5 4 3 6]
 [3 5 7 9 8 0 2 4 1 6]
 [8 8 5 6 9 4 7 1 0 2]]
vt_50sample [[5 1 6 0 7 8 2 9 4 3]
 [3 5 9 8 1 0 6 4 7 2]
 [9 0 5 8 2 1 6 3 4 7]
 [0 7 9 5 6 2 8 3 4 1]
 [5 1 0 7 2 9 8 4 3 6]
 [5 6 9 3 4 1 0 2 8 7]
 [7 9 3 2 0 8 6 1 4 5]
 [7 2 0 9 1 8 5 4 3 6]
 [3 5 7 9 8 0 2 4 1 6]
 [8 3 5 6 9 4 7 1 0 2]]
Epoch 22910: Training cost= 0.2832, Training acc= 0.8239, Validation cost= 0.3031, Validation acc= 0.8241
Epoch 22920: Training cost= 0.2754, Training acc= 0.8239, Validation cost= 0.2639, Validation acc= 0.8241
Epoch 22930: Training cost= 0.3225, Training acc= 0.8239, Validation cost= 0.3277, Validation acc= 0.8241
Epoch 22940: Training cost= 0.2863, Training acc= 0.8240, Validation cost= 0.3158, Validation acc= 0.8242
Epoch 22950: Training cost= 0.3946, Training acc= 0.8240, Validation cost= 0.3241, Validation acc= 0.8242
Epoch 22960: Training cost= 0.3027, Training acc= 0.8240, Validation cost= 0.3704, Validation acc= 0.8242
Epoch 22970: Training cost= 0.3382, Training acc= 0.8240, Validation cost= 0.3526, Validation acc= 0.8242
Epoch 22980: Training cost= 0.2979, Training acc= 0.8240, Validation cost= 0.2727, Validation acc= 0.8242
Epoch 22990: Training cost= 0.3260, Training acc= 0.8241, Validation cost= 0.3520, Validation acc= 0.8243
Epoch 23000: Training cost= 0.2539, Training acc= 0.8241, Validation cost= 0.4165, Validation acc= 0.8243
tm  [-1.3  1.7  5.4  0.9 -1.7  0.7  0.   0.1 -1.1 -0.9 -1.2 -0.2  0.3  0.4  6.4  4.3  0.6 -0.2  0.1 -0.2 -0.5 -0.3  2.5 -0.  -1.3  0.2 -0.2  0.4 -0.2 -0.1 -1.3  0.6 -0.8 -0.7 -0.6  0.3  3.6  5.4  7.4 -0.4 -0.3  2.5  2.3  2.7 -0.5  0.4 -0.6 -0.5 -1.3  6.9 -0.5 -0.1 -0.8  4.7 -1.4 -0.8 -0.7  5.7 -0.8  4.8  6.2 -0.  -0.2 -0.3 -1.   0.2 -0.2 -0.5 -0.2 -0.3 -0.  -0.6 -0.1 -0.1 -2.6 -0.5  1.1 -0.3 -0.3  0.7 -3.2 -0.4 -0.5  0.2  0.9  4.  -1.1  0.8 -0.3 -0.1 -0.6 -0.1 -0.2  2.3 -0.4 -0.2  1.1 -1.6 -0.2 -0.1  3.7  4.2  2.  -0.   0.2 -0.7 -1.8 -1.3 -0.3 -0.5 -0.2 -0.1 -0.2 -0.3 -0.8  6.5 -0.3 -1.  -0.2 -0.5 -0.1  2.2 -0.1 -0.3 -0.1  8.2  0.9 -0.9 -0.   3.2 -1.  -0.4 -0.4 -0.1 -4.9 -5.7 -0.3 -0.1 -0.3 -0.  -0.6 -0.4 -0.2 -0.3 -0.3 -0.2 -0.1 -0.1  1.6 -0.2 -0.5 -0.1  1.   0.3 -0.  -0.3 -0.1  0.8  4.  -0.4 -0.4 -1.5 -0.5 -0.1 -0.8 -0.1  0.3 -0.1 -0.4 -0.2  0.5 -0.  -0.1 -0.3 -0.   0.5  2.6 -0.7 -0.9 -0.4 -1.5 -0.  -0.1 -0.6 -0.2 -0.2 -1.1 -0.8 -0.1  0.4 -0.  -0.2 -0.3 -0.8 -1.7  1.4 -0.8  2.3 -0.2 -0.4 -0.1 -0.1 -0.1 -0.6  0.8 -2.4 -0.4 -0.   3.4  0.6 -0.3  1.2  0.4  4.3 -0.2 -0.1 -0.8 -0.4  1.3 -0.4 -0.   0.1 -0.5 -1.3 -1.   3.5 -0.   0.7 -0.4 -0.6 -0.6  1.1 -0.3  2.3 -0.1 -1.  -0.4 -1.   0.3 -2.1 -0.2 -1.  -0.3 -0.3 11.   1.9 -0.3  0.8 -0.2 -0.3  7.8 -0.3  5.1 -0.3 -0.2 -0.2]
ty_50sample [[8 1 5 2 2 3 4 9 0 6]
 [8 2 9 4 3 7 0 1 6 5]
 [5 8 0 2 7 3 4 1 9 6]
 [2 6 3 1 7 4 9 0 8 5]
 [0 7 2 1 5 9 6 3 4 8]
 [0 8 4 3 3 1 6 9 5 7]
 [1 9 6 2 4 7 3 0 8 5]
 [8 9 6 1 7 4 3 0 2 5]
 [9 2 7 8 1 6 0 5 3 4]
 [8 6 7 0 5 4 1 9 2 3]]
tt_50sample [[8 1 5 7 2 3 4 9 0 6]
 [8 2 9 4 3 7 0 1 6 5]
 [5 8 0 2 7 3 4 1 9 6]
 [2 6 3 1 7 4 9 0 8 5]
 [0 7 2 1 5 9 6 3 4 8]
 [0 8 4 2 3 1 9 6 5 7]
 [1 9 6 2 4 7 3 0 8 5]
 [8 9 6 1 7 4 3 0 2 5]
 [9 2 7 8 1 6 0 5 3 4]
 [8 6 7 0 5 4 1 9 2 3]]
vm  [-0.1 -0.2 -0.8 -1.  -1.4 -0.1 -0.2 -0.2  0.3 -0.4  5.9 -0.5  0.4 -0.4  1.2  5.5  0.3 -0.2 -0.1  0.1 -0.8  0.2  2.4 -0.5 -1.1  1.2 -0.3 -0.3 -0.1 -0.7  2.2 -0.4 -0.5  0.1  0.5 -0.2  0.9  6.9  9.2 -0.6 -0.1  3.4 -0.   5.8 -0.2  0.5 -0.5 -1.1  4.2  6.5 -0.5 -0.4 -0.2  6.5 -0.8  0.3 -0.4 -0.6  3.1 -0.3 -0.3 -0.2  0.7  1.9 -0.5 -0.4 -0.  -0.1 -0.5  0.1 -0.2 -0.5  0.5  1.4 -2.5 -0.1 -0.8 -0.  -0.4  0.3 -0.1 -0.4  0.1 -0.3 -1.1  4.1  3.2  0.2 -0.2 -0.4 -0.5 -0.3 -0.2 -0.9 -0.5 -0.2 -0.1 -1.9 -0.5 -0.1  0.3  5.1 -0.7 -0.2 -0.2  0.3 -0.8  2.2  1.5 -1.  -0.7  0.  -0.3 -0.9  0.4  4.5  0.4 -0.3 -0.  -0.3  0.1  3.  -0.1 -0.4 -0.1  1.6 -0.4 -1.5  4.3 -0.5 -0.1 -0.7  0.  -0.3 -3.5 -3.4 -0.4 -0.1 -0.5 -0.  -0.7 -0.4 -0.5 -0.2 -0.2 -0.  -0.2 -0.3  0.9 -0.1  1.3 -0.2  3.8 -0.3 -0.1 -0.1 -0.1  0.8  5.2 -0.3  0.9 -1.7 -0.1 -0.  -0.3 -0.3 -0.1 -0.1 -0.1 -0.3  0.2 -0.5 -0.4 -0.2  0.   0.2  2.2  0.8 -1.3 -0.4 -0.8 -0.1 -0.4 -1.  -0.3 -0.4  1.9 -0.3 -0.4  2.1 -0.  -0.3 -0.5 -0.5  4.5 -1.1 -0.  -0.4 -0.  -0.2  0.1 -0.1 -0.1 -0.5 -0.3 -0.8 -0.3 -0.1  2.  -0.2 -0.1  2.6 -0.6 -0.  -0.3 -0.3 -1.8 -0.6 -0.1 -0.2 -0.3 -0.2 -0.4 -1.1 -0.3  2.4  2.   1.   0.4  3.1 -0.5 -0.6  0.2  2.1 -0.1  3.3  0.6 -0.4  1.8  1.5 -0.2  0.2 -0.2 -0.3  2.7 -0.7 -0.3  1.2 -1.  -0.3 -0.1 -0.2  6.5  0.1 -1.4  5. ]
vy_50sample [[2 4 8 7 5 9 0 1 3 6]
 [7 9 5 6 4 8 1 2 3 0]
 [6 4 4 2 8 1 0 3 5 9]
 [5 3 8 0 7 1 9 4 2 6]
 [9 3 5 6 0 1 2 7 4 8]
 [7 3 2 4 8 5 9 1 0 6]
 [0 0 6 6 7 1 8 4 2 5]
 [3 7 4 0 5 9 1 2 6 8]
 [7 4 8 6 9 1 1 2 3 0]
 [7 2 8 3 5 4 0 6 1 9]]
vt_50sample [[2 4 8 5 7 9 0 1 3 6]
 [7 9 6 5 4 1 8 2 0 3]
 [6 4 7 2 8 1 0 3 5 9]
 [5 3 8 0 1 7 9 4 2 6]
 [9 3 5 6 0 1 2 7 4 8]
 [7 3 4 2 8 5 9 0 1 6]
 [0 9 3 6 7 1 8 4 2 5]
 [3 7 4 0 5 1 9 2 8 6]
 [7 4 8 6 1 5 9 2 3 0]
 [7 2 8 3 5 0 4 6 1 9]]
Epoch 23010: Training cost= 0.2984, Training acc= 0.8241, Validation cost= 0.3682, Validation acc= 0.8243
Epoch 23020: Training cost= 0.2909, Training acc= 0.8241, Validation cost= 0.3194, Validation acc= 0.8243
Epoch 23030: Training cost= 0.3406, Training acc= 0.8242, Validation cost= 0.3160, Validation acc= 0.8243
Epoch 23040: Training cost= 0.2769, Training acc= 0.8242, Validation cost= 0.3168, Validation acc= 0.8244
Epoch 23050: Training cost= 0.2394, Training acc= 0.8242, Validation cost= 0.3137, Validation acc= 0.8244
Epoch 23060: Training cost= 0.3510, Training acc= 0.8242, Validation cost= 0.2497, Validation acc= 0.8244
Epoch 23070: Training cost= 0.3484, Training acc= 0.8243, Validation cost= 0.3078, Validation acc= 0.8245
Epoch 23080: Training cost= 0.2858, Training acc= 0.8243, Validation cost= 0.3149, Validation acc= 0.8245
Epoch 23090: Training cost= 0.2592, Training acc= 0.8243, Validation cost= 0.3086, Validation acc= 0.8245
Epoch 23100: Training cost= 0.2829, Training acc= 0.8243, Validation cost= 0.3136, Validation acc= 0.8245
tm  [-1.4  1.5  6.2 12.2 -1.2  0.9 -0.3 -0.  -0.7 -1.2  2.5  1.1 -0.6 -0.1 -0.3  4.6  0.1 -0.4  1.1 -1.1 -0.5 -0.1 -0.9 -0.  -0.9  0.7 -0.2 -0.   2.8 -0.9 -0.7 -0.4  0.1  3.5 -1.   0.2  1.5  0.1  3.5 -0.3 -0.3 -3.1 -0.4 -1.1 -0.3 -0.   5.1 -0.1 -1.4 -2.3 -0.4 -0.1  1.7 -0.7 -1.4  1.6 -0.2  2.4 -0.3  3.6  2.1 -0.4 -0.1 -0.3  0.2  0.5 -0.  -0.3 -0.2 -0.   0.  -1.4 -0.1 -0.2 -0.4  0.7  0.2 -0.4 -0.4 -0.   8.2 -0.3 -0.4 -0.3  0.5 -2.5 -1.7 -0.3  0.3 -0.2 -0.4 -0.   0.1  0.9 -0.4 -0.1 -0.2 -0.5 -0.2  0.7  5.2 -1.4  1.5 -0.1 -0.3  0.5 -0.3 -0.5  1.  -1.6 -0.1 -0.4 -0.2 -0.3 -0.6  9.5  0.3 -0.6  0.2 -0.2  0.1  5.8 -0.1  0.5 -0.1 -0.5  1.8  5.2 -0.7  4.  -0.3 -0.5 -0.2 -0.4  0.8  4.6 -0.  -0.1  1.3 -0.5 -0.4 -0.2 -0.4 -0.3 -0.2 -0.1 -0.3 -0.  -1.  -0.1 -1.   0.2 -0.8 -0.1 -0.2 -0.2 -0.2 -0.3 -0.4 -0.5 -0.8 -0.2 -0.1  0.5 -0.1  0.3  1.4  2.2 -0.3 -0.1 -0.7 -0.6 -0.1 -0.1 -0.6  2.4 -0.8  0.2 -0.2 -0.2  0.2  0.9 -0.2 -1.4 -0.6 -0.1 -0.4 -0.7 -0.1  3.3 -0.2  1.1 -0.8 -0.9 -0.2  2.   1.4  2.2 -0.2 -0.1 -0.1  0.  -0.3 -0.5 -0.1  2.4 -0.1 -0.3  4.7 -0.1  0.6  4.5 -0.5  4.7 -0.2 -0.   4.1 -0.4 -0.1  0.5 -0.7 -0.2 -0.1 -0.7 -0.8  3.7 -1.1  1.   0.8 -0.4 -0.4 -0.4 -0.2  2.6 -1.  -1.3 -0.4  0.5 -0.2 12.9 -0.2  5.7 -0.1 -0.1 -1.3 -1.9 -0.2 -0.  -0.7 -0.6 -2.2 -0.2  3.  -0.1  4.8 -0.6]
ty_50sample [[3 1 9 7 6 2 8 5 4 0]
 [4 5 6 1 7 2 8 3 9 0]
 [2 6 8 7 5 3 0 9 4 1]
 [5 9 2 6 1 7 4 3 0 8]
 [1 4 9 6 0 3 7 8 2 5]
 [7 0 0 2 3 3 6 4 5 8]
 [9 7 8 6 2 5 3 4 1 0]
 [9 6 7 8 0 5 2 1 4 3]
 [2 8 6 7 1 5 5 4 3 0]
 [0 6 8 9 2 7 3 4 5 5]]
tt_50sample [[3 1 9 6 7 2 8 5 4 0]
 [4 5 6 1 7 2 3 8 9 0]
 [2 6 8 7 5 3 0 9 4 1]
 [5 9 2 6 1 7 4 0 3 8]
 [1 4 9 0 6 3 7 8 2 5]
 [9 7 0 2 3 6 1 4 5 8]
 [9 7 8 6 5 2 3 4 1 0]
 [6 9 7 8 0 5 2 1 4 3]
 [2 8 6 7 1 5 4 9 3 0]
 [0 6 8 9 2 7 3 4 1 5]]
vm  [-1.5  0.2  4.6 10.3 -1.4  0.6  0.2 -0.2 -0.1 -1.  -1.8  0.1 -0.7 -0.3 -0.4  2.3  1.5 -0.1  0.1 -0.1 -0.4 -0.5 -0.5 -0.3 -0.6  0.9 -0.2 -0.1  1.7 -1.9 -1.8 -0.5 -0.5 -2.2 -1.1 -0.6 -0.3 -0.5 -0.2 -0.3 -0.3 -2.  -0.5 -1.6 -0.7  0.  -0.7 -0.  -0.3 -1.2 -0.5 -0.1  0.5 -0.1 -0.8  1.7 -0.1  6.6  1.9  6.2  3.1 -0.3  0.6  0.6 -0.9  0.3 -0.  -0.5 -0.3 -0.1 -0.2 -1.2 -0.   1.2 -3.3 -0.1 -0.5 -0.3 -0.5 -0.1 -1.1 -0.3 -0.1 -0.6 -0.6 -1.6 -1.6 -0.3 -0.  -0.4 -0.6 -0.4  1.  -0.2 -0.4 -0.2  0.5 -2.1 -0.2  0.3  3.4 -2.3 -0.1 -0.2 -0.5  0.6 -0.9 -1.5 -0.5 -1.1 -0.1 -0.1 -0.1 -0.8  0.1  7.3 -0.3  1.3  0.2 -0.2  0.3  3.  -0.5  0.6 -0.2 -0.5  1.1  3.8  2.6  7.3  0.1 -0.6 -0.4 -0.3  6.1 -0.4 -0.2 -0.3  0.6  1.  -0.  -0.4  0.2 -0.2 -0.3  0.2 -0.1 -0.1  2.8 -0.1 -0.9 -0.1  1.2  0.9 -0.3 -0.2 -0.5 -0.1 -0.4 -0.3 -0.6 -0.1 -0.1 -0.1 -0.3  0.5  0.7  2.1 -0.2 -0.1 -0.5 -0.4 -0.4 -0.3 -0.3 -0.2 -0.5 -0.1  1.7 -0.2 -0.8  1.3 -0.6 -1.7 -0.5 -0.1 -0.3 -0.3 -0.1  5.9 -0.3  0.8 -0.6 -0.7 -0.4 -0.9  0.1 -0.1  0.3 -0.4 -0.1  0.1 -0.1 -0.3  0.7 -0.5 -0.2 -0.4  4.8  0.  -0.3  4.8 -0.5  3.4 -0.5 -0.1  5.9 -0.4 -0.2  0.1 -0.8 -0.3 -0.4 -0.9 -0.6  3.5 -1.7  0.2 -0.3  1.9 -0.2 -0.5 -0.5  2.7 -0.6 -0.6 -0.5 -0.5  1.   2.7 -0.2  1.5  0.6 -0.3  5.4 -1.  -0.3  0.8 -0.8 -0.5  2.2 -0.2 -0.1 -0.1  6.1 -1.7]
vy_50sample [[3 8 1 6 9 5 2 7 0 4]
 [0 4 9 8 7 5 1 3 2 6]
 [7 4 6 1 5 3 0 9 8 2]
 [8 2 3 7 1 9 6 0 5 4]
 [2 4 1 9 0 7 8 6 3 5]
 [7 4 5 9 9 3 2 0 8 6]
 [4 5 7 6 8 3 9 0 2 1]
 [9 6 8 0 4 1 3 5 2 7]
 [6 5 0 4 7 2 8 3 9 1]
 [1 0 5 2 7 8 4 9 3 6]]
vt_50sample [[3 8 6 1 9 5 2 7 0 4]
 [0 4 9 8 7 1 5 3 2 6]
 [7 4 6 1 5 3 0 9 8 2]
 [8 2 3 7 1 9 6 0 5 4]
 [2 4 9 1 0 7 8 6 3 5]
 [7 4 5 9 1 3 2 0 8 6]
 [4 5 7 6 8 3 9 0 2 1]
 [9 6 8 0 4 1 3 5 2 7]
 [6 5 0 4 7 2 8 3 1 9]
 [1 5 0 2 7 8 4 9 3 6]]
Epoch 23110: Training cost= 0.3502, Training acc= 0.8244, Validation cost= 0.2744, Validation acc= 0.8245
Epoch 23120: Training cost= 0.2723, Training acc= 0.8244, Validation cost= 0.3024, Validation acc= 0.8246
Epoch 23130: Training cost= 0.2510, Training acc= 0.8244, Validation cost= 0.2728, Validation acc= 0.8246
Epoch 23140: Training cost= 0.2643, Training acc= 0.8244, Validation cost= 0.2662, Validation acc= 0.8246
Epoch 23150: Training cost= 0.2492, Training acc= 0.8245, Validation cost= 0.2348, Validation acc= 0.8247
Epoch 23160: Training cost= 0.2826, Training acc= 0.8245, Validation cost= 0.3119, Validation acc= 0.8247
Epoch 23170: Training cost= 0.3157, Training acc= 0.8245, Validation cost= 0.2756, Validation acc= 0.8247
Epoch 23180: Training cost= 0.2669, Training acc= 0.8246, Validation cost= 0.3124, Validation acc= 0.8247
Epoch 23190: Training cost= 0.3218, Training acc= 0.8246, Validation cost= 0.3177, Validation acc= 0.8248
Epoch 23200: Training cost= 0.2795, Training acc= 0.8246, Validation cost= 0.2865, Validation acc= 0.8248
tm  [-1.5 -0.7  6.2  8.3 -1.9 -0.1 -0.2 -0.1 -0.3 -0.7 -0.2 -0.4 -0.2 -0.2  2.5 -0.9 -0.4 -0.3 -0.   0.  -0.6 -0.3  1.7  0.4 -1.2  4.9 -0.4 -0.1 -1.5 -1.9 -0.7 -0.  -0.5  3.6 -0.3  0.4  2.8 -0.1  1.5 -0.4 -0.1  3.6  1.2 -0.6 -0.2 -0.1 -0.5 -0.1 -0.5  4.  -0.7 -0.2  0.1 -0.1  1.6  0.2 -0.7  6.5  1.5  3.9  4.4 -0.1 -0.1  2.9 -0.2  1.6  0.2 -0.6  1.   0.4 -0.1  3.9  0.1  0.4 -1.3  1.   0.1 -0.3 -0.1  0.8  1.  -0.1  0.1 -0.1  1.4  4.9 -1.4 -0.1 -0.1 -0.  -0.1 -0.5 -0.3 -0.7 -0.4 -0.2  1.6 -1.8 -0.2 -0.1  1.8  4.7  0.7 -0.  -0.3  0.3 -0.9 -0.5 -0.2 -0.8 -0.7  0.2  0.2 -0.1  3.8 -1.3 -0.2 -0.2 -0.4 -0.2  0.8  3.  -0.   0.6 -0.1  2.5 -0.3  3.6  1.8 -0.4 -0.4 -0.7 -0.6 -0.7 -0.8  0.9 -0.  -0.3  0.4 -0.2  0.8 -1.2  0.1 -0.2 -0.1 -0.  -0.  -0.2  1.  -0.2 -0.6 -0.2 -0.3  1.1 -0.3 -0.   0.  -0.5  1.6  0.1  0.9 -0.2  0.1 -0.1 -0.5 -0.6 -0.2 -0.1 -0.2  0.2 -0.2 -0.2 -0.1 -0.5 -0.1  0.4 -0.3  0.5  0.7 -0.  -1.1 -0.2 -0.4 -1.6  1.  -0.4 -0.7 -0.5  1.2  5.4 -0.  -0.5 -0.3 -0.6 -0.8 -0.2 -0.3 -0.7 -0.   0.1 -0.  -0.2 -0.3 -0.7  0.5 -1.2 -0.1  0.2 -0.6 -0.  -0.3 -1.  -0.3  5.3 -1.2 -0.3  3.2 -0.6  0.1 -0.2 -0.5 -0.2 -0.4 -1.2  2.4 -0.5 -1.   1.9  1.7 -0.2 -0.4 -0.8 -0.1 -0.4  4.6 -1.4  1.5 -0.1  2.7 -0.5 -0.1 -0.2  0.1 -0.3  1.3 -0.4 -0.1  1.3 -1.1 -0.3 -0.4 -0.3  1.3 -0.2  0.6  3.7]
ty_50sample [[0 1 5 7 8 8 6 2 3 4]
 [1 0 3 7 5 4 8 6 2 9]
 [0 7 4 9 9 8 2 3 6 5]
 [9 7 4 3 0 1 6 5 8 2]
 [3 4 7 5 2 6 8 1 0 9]
 [1 1 8 0 0 5 2 6 9 7]
 [2 6 1 8 5 4 3 0 0 7]
 [2 9 5 3 1 7 4 8 0 6]
 [4 3 5 6 0 9 8 8 1 2]
 [9 2 4 1 5 6 3 8 7 0]]
tt_50sample [[0 1 5 7 9 8 6 2 3 4]
 [1 0 3 7 5 4 8 6 2 9]
 [0 7 1 4 9 8 2 3 6 5]
 [9 7 4 3 0 1 6 5 8 2]
 [3 4 7 5 2 6 1 8 0 9]
 [1 4 3 8 0 5 2 6 9 7]
 [2 6 1 8 5 4 3 0 9 7]
 [2 9 5 3 1 7 4 8 0 6]
 [4 3 5 6 0 9 7 8 1 2]
 [2 9 4 1 5 6 3 8 7 0]]
vm  [-1.8 -0.2  6.8  8.7 -1.6  0.  -0.2 -0.1 -0.6 -0.8 -0.5 -0.4 -0.  -0.1  2.4  0.2 -0.7 -0.2  0.2 -0.7 -1.  -0.6  0.6 -0.2 -0.8  1.5 -0.5  0.4 -0.8 -1.4 -1.  -0.1 -0.5  2.6 -0.5  0.9  2.7  2.   7.3 -0.6  0.6 -2.4 -0.5  1.1 -0.   0.8  4.1 -0.1 -1.2  1.  -0.7 -0.4 -0.3 -0.1 -0.6 -0.1 -0.6 -0.6  2.1  4.1  4.1  1.3 -0.7  0.9 -0.5  1.4 -0.3 -0.4  0.8  0.9 -0.1 -0.1 -0.  -0.2  1.5 -0.   1.3 -0.3  0.1  0.6  0.   0.5 -0.7  2.1  2.6 -2.4 -1.4 -0.  -0.2  0.2 -0.4  0.1 -0.2 -0.4 -0.6 -0.2  0.3 -1.2 -0.4  0.5  4.3  2.3  2.  -0.1 -0.2 -0.6 -0.7 -0.8 -0.1 -1.4 -0.9 -0.4 -0.1 -0.2  2.1  0.6 -0.1 -0.3 -0.6 -0.5 -0.   6.4  0.5 -0.1 -0.3  2.2  0.4  2.8  0.6  1.9 -0.6 -1.  -0.4 -0.7 -3.1 -2.5 -0.1 -0.2 -0.1 -0.6 -0.2 -0.7 -0.6 -0.1 -0.3 -0.2 -0.4  0.2 -2.4 -0.3 -0.8 -0.1 -0.  -0.1  0.3 -0.3  1.1 -0.1  1.9 -0.7 -0.4 -0.8 -0.4 -0.2 -0.7 -0.2  0.9  3.3 -0.1 -0.1 -0.6 -0.2 -0.   0.1 -0.3  4.6  0.6 -0.1 -0.8 -0.2  2.2  0.3 -0.3 -0.9 -0.1 -0.2 -0.9 -0.7 -0.1  4.8 -0.2 -0.4 -0.9 -0.7 -0.7 -0.2 -0.1 -0.3 -0.1 -0.1 -0.2 -0.2 -0.7 -0.9  1.  -1.3 -0.2  1.2  8.2  0.2 -0.4 -0.1 -0.7  5.2 -0.7 -0.4  0.4 -0.6  1.2 -0.  -0.4 -0.2 -0.2 -1.  -1.   2.1 -0.5  1.6  1.9  0.2 -0.7 -0.7 -0.   4.8  3.1 -1.5  0.9  1.7  2.4 13.8 -0.1  6.2 -0.2 -0.1  2.7 -0.7 -0.1  0.9 -0.9 -0.5 -0.3 -0.3  5.6 -0.4  3.   0.1]
vy_50sample [[1 7 8 8 9 0 2 4 6 5]
 [9 9 5 5 4 1 2 3 8 8]
 [5 6 8 4 7 2 9 0 3 1]
 [6 3 1 2 4 8 9 9 0 0]
 [0 2 8 5 3 7 1 9 6 4]
 [8 1 9 5 3 4 0 6 2 7]
 [8 5 0 2 7 3 3 4 1 6]
 [9 7 4 6 2 3 0 5 8 1]
 [3 3 2 0 5 4 9 1 8 7]
 [3 7 2 8 0 9 5 1 6 4]]
vt_50sample [[1 7 3 8 0 9 2 4 6 5]
 [9 6 7 5 4 1 2 3 8 0]
 [5 6 8 7 4 2 0 9 3 1]
 [6 3 1 2 4 8 9 5 7 0]
 [0 2 8 5 3 7 1 6 9 4]
 [1 8 9 5 3 4 0 6 2 7]
 [8 5 0 2 7 3 9 4 1 6]
 [9 7 4 6 2 3 0 5 8 1]
 [3 6 2 0 5 4 9 1 8 7]
 [3 7 2 0 8 9 5 1 6 4]]
Epoch 23210: Training cost= 0.2871, Training acc= 0.8246, Validation cost= 0.3286, Validation acc= 0.8248
Epoch 23220: Training cost= 0.2860, Training acc= 0.8247, Validation cost= 0.2857, Validation acc= 0.8248
Epoch 23230: Training cost= 0.2717, Training acc= 0.8247, Validation cost= 0.3358, Validation acc= 0.8249
Epoch 23240: Training cost= 0.2570, Training acc= 0.8247, Validation cost= 0.3131, Validation acc= 0.8249
Epoch 23250: Training cost= 0.3061, Training acc= 0.8247, Validation cost= 0.2764, Validation acc= 0.8249
Epoch 23260: Training cost= 0.3264, Training acc= 0.8248, Validation cost= 0.3114, Validation acc= 0.8249
Epoch 23270: Training cost= 0.2665, Training acc= 0.8248, Validation cost= 0.2704, Validation acc= 0.8250
Epoch 23280: Training cost= 0.3167, Training acc= 0.8248, Validation cost= 0.2746, Validation acc= 0.8250
Epoch 23290: Training cost= 0.3606, Training acc= 0.8248, Validation cost= 0.2747, Validation acc= 0.8250
Epoch 23300: Training cost= 0.3303, Training acc= 0.8249, Validation cost= 0.3232, Validation acc= 0.8250
tm  [-0.2 -0.3 -1.  -1.2 -2.1 -0.2  0.9 -0.3 -0.8 -0.1  1.7 -0.1 -0.7 -0.2  2.2 -1.9 -0.1 -0.7 -0.6 -1.1 -0.7 -0.3 -0.3 -0.1 -1.1  1.5 -0.2 -0.1 -1.7  1.7  6.5 -0.4 -0.4 11.3  0.4  0.9  2.9 -0.5  5.6 -0.3 -0.4  4.1  2.6  3.5 -0.6 -0.4  5.2  1.1 -0.2 -1.  -0.4 -0.2  0.3 -1.8 -0.2 -0.3 -0.9 -0.6 -1.2 -3.  -0.4 -0.2 -0.2 -0.3  2.  -0.4 -0.3 -0.   0.4 -0.3 -0.3  3.2 -0.1 -0.6 -1.4 -0.7  0.1 -0.1 -0.2 -0.1 15.  -0.5 -0.6 -0.2 -0.8  4.1  4.6 -0.2 -0.  -0.1 -0.2 -0.3 -0.2  2.2 -0.3 -0.1 -0.2 -0.4  0.4 -0.1 -0.2  4.7 -0.5 -0.2 -0.3 -0.3 -1.   6.8  0.5 -1.2 -0.1 -0.1 -0.2  0.4  2.2 -2.3 -0.4 -0.5  0.3 -0.2 -0.2  3.7 -0.5  0.3 -0.2  2.9 -0.1  9.1 -0.6 -0.9  0.4  0.5 -0.2  1.7 -1.9  7.9 -0.1 -0.2 -0.2 -1.   2.1 -1.   0.9 -0.3  0.5 -0.4 -0.3  0.2  0.3 -0.4 -0.2 -0.2 -0.8  1.7 -0.4 -0.4 -0.5 -0.1 -0.3  0.4 -0.4 -0.9 -0.1 -0.2 -0.2 -0.2 -1.2 -0.4 -0.2 -0.2 -0.1 -0.1  0.8 -0.2 -0.1  1.4 -0.5 -0.2 -0.7 -0.4 -1.  -0.3 -0.1 -1.2 -0.2 -0.4  1.  -0.5  0.8 -0.5 -0.3 -0.6 -0.4 -1.1  4.7  5.  -0.4  0.4 -0.   0.1  0.5  0.1 -0.3 -0.6 -0.3  0.3 -0.4 -0.3 -3.5 -0.2 -0.6 -1.6 -0.3  1.3  0.6 -0.2 -1.3 -0.6 -0.8 -0.4 -0.4 -0.4 -0.4 -1.   1.4 -1.5 -2.  -0.8 -0.7 -0.4 -1.1 -0.  -0.4 -2.5  2.   3.5  1.9 -0.7  0.4  0.1 -0.2 -0.  -0.1 -0.4 -3.3 -1.6 -0.5 -0.4 -0.7  0.1 -3.8 -0.1  4.1 -0.4  2.2  5.9]
ty_50sample [[4 0 7 5 9 6 1 3 2 8]
 [8 8 4 2 9 7 3 6 0 1]
 [6 7 0 8 2 5 3 4 9 1]
 [1 5 4 6 3 2 7 9 8 0]
 [8 2 0 4 6 6 7 9 5 3]
 [9 3 8 4 6 5 7 1 2 0]
 [6 5 1 3 2 4 8 0 9 7]
 [9 2 0 8 4 1 3 5 7 6]
 [8 7 5 2 4 1 9 0 6 3]
 [5 4 7 3 0 8 9 6 1 2]]
tt_50sample [[4 0 7 5 9 6 1 3 2 8]
 [8 5 4 2 9 7 3 6 0 1]
 [6 7 0 8 2 5 3 4 9 1]
 [1 5 4 6 3 2 7 9 8 0]
 [8 2 0 4 6 1 7 9 5 3]
 [9 3 8 4 6 5 7 1 2 0]
 [6 5 1 3 2 4 8 0 9 7]
 [9 0 2 8 4 1 3 5 7 6]
 [8 7 5 4 2 1 9 0 6 3]
 [5 4 3 7 0 8 9 6 1 2]]
vm  [ 0.6  0.5  5.9  8.1 -1.5 -0.1 -0.2 -0.5 -1.8 -0.4 -3.9  1.1 -0.4 -0.6  1.9  2.6 -0.1 -0.1 -0.4 -1.8 -0.5  0.7  0.4 -0.1 -0.9 -0.5 -0.5 -0.4  2.   4.3 -0.8 -0.6  0.3  1.3 -0.7 -0.1  1.6  4.  16.6 -0.3  0.7 -1.6  2.   5.1 -0.3 -0.5 10.3  0.6  1.   2.4 -0.1 -0.3 -0.  -2.1 -1.5  0.4 -0.5 -0.6 -1.5  2.6 -1.9 -0.6 -0.4 -0.9 -0.9 -0.6 -0.1 -0.4 -0.3 -0.2 -0.4 -1.6 -0.4 -0.3  0.8  1.5 -0.2  0.  -0.7  0.  -0.1  1.7 -0.8 -0.1 -1.1 -1.5  2.7 -0.2  0.9 -0.8 -0.   0.9 -0.1  4.3 -0.3 -0.4 -0.3  0.4 -0.3 -0.6  2.4  2.1 -0.6 -0.1 -0.4 -0.5  0.3 -0.6 -1.1 -1.9  0.9 -0.1 -0.2 -0.1 -1.6  6.9 -0.1 -0.8  0.3 -0.8 -0.2  6.5 -0.5 -0.5  0.2  1.7  0.7 10.3 -1.3  0.5 -0.4  0.4 -0.  -0.1 -6.5 -6.   0.8 -0.2 -0.1  0.1  0.4 -0.2 -0.3 -0.5  0.2  0.4  0.6 -0.1 -1.3 -0.5 -1.4 -0.1  3.6 -0.2 -0.2 -0.2 -0.5 -0.3  4.1 -0.1 -0.2 -2.4 -0.2 -0.3 -0.2  1.2 -0.4 -0.5 -0.4 -0.4 -0.3 -0.2 -0.1  0.  -0.2  3.2  0.9  1.1 -2.4 -0.5 -0.2 -0.3  1.3 -0.7 -1.2 -0.1  3.5 -0.7 -0.7 -1.4  0.2 -0.1 -0.8 -1.3 10.8  4.2  2.8  3.3 -0.5 -0.2  0.2 -0.1  0.9 -0.3 -1.   6.4 -0.1 -0.5  5.7 -0.5 -0.8  2.8 -0.3 -0.4  0.7 -0.2 -1.5 -0.1 -0.6 -0.5 -0.5 -0.3 -0.3 -0.2 -2.4  3.7 -1.6 -0.7  1.1 -0.2 -0.8 -0.  -0.4  3.6 -1.9 -0.9 -0.4  0.8 -0.4 12.7 -0.4  5.5 -0.4 -0.3  1.5 -3.3 -0.1 -0.9 -0.3 -0.  -0.1 -0.2 12.   1.7  4.5  1.9]
vy_50sample [[7 7 3 9 4 5 2 1 0 6]
 [6 9 7 1 4 0 5 3 8 8]
 [1 2 6 4 9 5 7 3 8 0]
 [9 6 8 7 4 3 2 5 0 1]
 [2 9 9 3 3 4 7 5 6 0]
 [8 2 3 1 7 0 6 5 9 4]
 [9 3 9 2 0 7 1 5 6 8]
 [3 1 4 6 0 9 7 8 5 2]
 [7 2 8 8 1 6 3 4 5 0]
 [3 7 4 1 0 2 8 9 6 5]]
vt_50sample [[7 8 3 9 4 5 2 1 0 6]
 [6 9 7 1 4 0 5 3 8 2]
 [1 2 6 4 9 7 5 3 8 0]
 [9 6 8 7 4 3 2 5 0 1]
 [2 9 1 8 3 4 7 5 6 0]
 [8 2 3 1 7 0 6 5 9 4]
 [9 3 4 2 0 7 1 5 6 8]
 [3 1 4 6 0 9 7 8 5 2]
 [7 2 8 9 1 6 3 4 5 0]
 [3 7 4 1 0 2 8 9 6 5]]
Epoch 23310: Training cost= 0.3150, Training acc= 0.8249, Validation cost= 0.3034, Validation acc= 0.8251
Epoch 23320: Training cost= 0.2731, Training acc= 0.8249, Validation cost= 0.2585, Validation acc= 0.8251
Epoch 23330: Training cost= 0.3731, Training acc= 0.8249, Validation cost= 0.3388, Validation acc= 0.8251
Epoch 23340: Training cost= 0.3041, Training acc= 0.8250, Validation cost= 0.2813, Validation acc= 0.8251
Epoch 23350: Training cost= 0.2999, Training acc= 0.8250, Validation cost= 0.2911, Validation acc= 0.8251
Epoch 23360: Training cost= 0.2972, Training acc= 0.8250, Validation cost= 0.2851, Validation acc= 0.8252
Epoch 23370: Training cost= 0.3101, Training acc= 0.8250, Validation cost= 0.3102, Validation acc= 0.8252
Epoch 23380: Training cost= 0.3860, Training acc= 0.8250, Validation cost= 0.3098, Validation acc= 0.8252
Epoch 23390: Training cost= 0.2471, Training acc= 0.8251, Validation cost= 0.2886, Validation acc= 0.8252
Epoch 23400: Training cost= 0.2810, Training acc= 0.8251, Validation cost= 0.3081, Validation acc= 0.8253
tm  [ 2.3  2.7 -1.4  3.6 -0.4 -0.3 -0.4 -0.  -1.8 -0.6 -2.6  0.2 -0.2 -0.3 -2.   3.9  0.4 -0.3  0.3 -1.7 -0.7 -0.   1.1 -0.1 -1.3 -0.5 -0.4  0.2  1.3  5.9 -0.5 -0.4  0.4 -4.1 -0.6  0.3  3.3 -0.8 -1.2 -0.7 -0.4 -0.5  2.4 -0.7 -0.1 -0.2  6.3 -0.2  2.5  3.3 -0.6 -0.1 -0.5 -1.  -1.5  3.7 -0.6  1.8 -2.1  3.1 -1.9 -0.4 -1.1 -0.7 -0.5 -0.1 -0.3 -0.2  0.5 -0.2 -0.3 -1.  -0.1 -0.6 -0.7 -0.1 -0.6 -0.1 -0.5  0.4 -0.9  0.6 -0.5  1.4 -0.9 -0.1  4.  -0.1  0.2 -0.8 -0.4  1.5 -0.3  5.6 -0.1  0.2  0.  -0.5 -0.4 -0.2  3.6 -1.5 -0.9 -0.4  0.4 -0.3 -0.7 -0.5 -1.  -1.6 -0.2 -0.2 -0.3 -0.3 -1.7  7.  -0.2 -1.2 -0.1 -0.4 -0.6  5.4 -0.3 -0.5 -0.1 -2.3  0.8  5.7 -1.6  2.8  2.  -0.4  1.3 -0.5 12.8  4.7 -0.2 -0.2 -0.3 -0.5 -0.2 -0.5  0.2 -0.4 -0.2 -0.2 -0.2 -0.3  4.6 -0.3 -0.7  0.7  4.8 -0.6  0.  -0.2 -0.1 -0.4 -2.  -0.6 -0.3  3.3 -0.6 -0.1 -0.2 -0.   0.1 -0.8 -0.4 -0.1 -0.1 -0.1 -0.1 -0.1  0.5 -1.  -1.8 -0.3  2.7 -0.3 -1.4 -0.3  1.7 -0.9 -0.9  1.1  4.3 -0.  -0.2 -1.3  0.4 -0.1 -0.3 -1.  11.3  4.   0.3  4.  -0.1 -0.4 -0.  -0.3  1.1 -0.2 -0.6 -0.4 -0.1 -0.5  3.6 -0.3 -0.4  0.8 -0.7 -0.9  0.7  0.4  3.6 -0.2  0.2 -0.2 -0.7 -0.2 -0.4 -0.6  1.5  3.7 -1.  -0.7 -0.5  1.5  0.3  0.5 -0.3  2.  -1.3  2.7 -0.2 -0.3 -0.4  2.3 -0.2  1.3 -0.2 -0.1  4.4 -1.4  1.  -0.1 -0.7 -0.2  1.8 -0.3 -0.8  0.3  3.1  0. ]
ty_50sample [[6 8 3 9 5 4 2 7 0 1]
 [6 0 9 5 3 4 2 2 8 1]
 [0 2 4 6 8 3 9 7 5 1]
 [8 4 7 3 0 1 2 5 6 9]
 [1 4 9 5 0 7 7 8 6 2]
 [5 9 4 6 0 8 2 1 7 3]
 [5 0 7 4 8 9 6 2 3 1]
 [9 2 7 0 4 8 1 6 5 3]
 [6 4 3 0 5 7 8 1 2 9]
 [2 0 7 3 1 5 8 9 4 6]]
tt_50sample [[6 8 3 9 5 4 2 7 0 1]
 [6 0 9 5 3 4 7 2 8 1]
 [0 2 4 6 8 9 3 7 5 1]
 [8 4 7 3 0 1 2 5 6 9]
 [1 4 9 5 0 3 7 8 6 2]
 [5 9 4 6 0 2 8 1 7 3]
 [5 0 7 4 8 9 6 2 3 1]
 [9 2 0 7 4 8 1 6 5 3]
 [6 4 3 0 5 7 8 1 9 2]
 [2 0 7 3 1 5 8 9 4 6]]
vm  [-1.  -0.2 -2.  -0.2 -1.  -0.1 -0.1 -0.4 -0.7 -0.3 -0.4 -0.4 -0.6 -0.3 -1.3 -0.3 -0.2 -0.3 -0.4 -0.9 -0.8 -0.2  2.1 -0.2 -1.2  2.2  0.4 -0.3 -0.7 -0.7  2.9 -0.3 -0.5 -1.5 -0.1  0.4  3.2  1.5  6.4 -0.1 -0.2  7.9  2.1  3.  -0.5 -0.1  2.8 -0.1 -0.6  8.  -0.7 -0.2  0.5 -0.5 -0.5  2.5 -0.2  2.6 -0.4 -0.5  2.2 -0.4 -0.4  0.2 -0.2 -0.2 -0.2  0.1 -0.1 -0.   0.   1.5 -0.2 -0.2 -1.3 -0.3  0.8 -0.4 -0.  -0.2  3.3 -0.1 -0.  -0.   0.3  8.8  0.5 -0.3 -0.1 -0.  -0.1 -0.2 -0.2 -0.2 -0.5 -0.3 -0.2 -1.3 -0.1 -0.2  0.9  2.5  0.8 -0.2 -0.5  0.3 -0.8  2.5 -0.2 -1.2 -0.5 -0.4 -0.1 -0.4  1.3 -0.7 -0.4 -0.9 -0.1  0.3  0.1  4.  -0.1  0.1 -0.3 -1.5 -0.1  5.2  1.8 -1.7 -0.4 -0.3 -0.  -0.2  3.2 -1.1 -0.3 -0.   1.1 -0.6  1.  -0.8 -0.   0.  -0.2 -0.1 -0.3 -0.1  7.1 -0.   0.8 -0.1 -0.4  0.7 -0.3 -0.  -0.4  0.4  1.8 -0.1 -0.1 -0.6 -0.3 -0.1 -0.3 -0.3 -0.3 -0.2  0.6 -0.3 -0.2  0.5 -0.1 -0.2 -0.5 -1.4 -0.2 -0.2 -0.7 -0.  -1.7 -0.1 -0.3 -1.3  0.2 -0.1 -0.4 -0.2 -0.   2.7 -0.3 -0.3 -0.6 -0.9 -0.2  1.2 -0.   0.1 -0.1 -0.2 -0.1 -0.2 -0.3 -0.5 -0.1 -0.5 -0.3 -0.2 -2.5 -0.3  0.5 -0.4 -0.7  5.3 -0.  -0.4 -0.9 -0.7 -0.4 -0.2 -0.6 -0.  -0.2 -0.6  2.4 -0.2 -1.1 -0.2 -0.3 -0.4 -1.  -0.6 -0.4 -1.7  2.4  4.9  0.8 -0.1  1.3 -1.9 -0.  -0.9 -0.1  0.2 -0.2 -1.4 -0.1 -0.1 -1.  -0.3 -1.2 -0.2  4.6 -0.2 -0.1  9.5]
vy_50sample [[5 1 4 9 9 8 2 6 7 3]
 [6 7 1 3 5 4 2 0 9 8]
 [2 7 9 3 0 8 5 1 4 6]
 [3 8 1 7 7 4 2 5 9 0]
 [0 6 7 5 8 2 2 3 1 9]
 [3 6 7 5 1 9 0 4 4 2]
 [7 8 2 5 1 3 9 6 0 4]
 [7 6 8 8 2 4 1 9 0 5]
 [4 5 0 2 3 8 1 9 6 7]
 [2 2 3 9 7 0 4 5 6 1]]
vt_50sample [[5 1 4 0 9 8 2 6 7 3]
 [6 7 1 3 5 4 2 0 9 8]
 [2 7 9 3 0 8 5 1 4 6]
 [3 8 1 7 6 4 2 5 0 9]
 [0 6 7 5 8 4 2 3 1 9]
 [3 6 7 1 5 9 0 8 4 2]
 [7 8 2 5 1 3 9 6 0 4]
 [7 6 8 3 4 2 1 9 0 5]
 [4 5 0 2 3 8 1 9 6 7]
 [2 3 8 9 7 0 4 5 6 1]]
Epoch 23410: Training cost= 0.3252, Training acc= 0.8251, Validation cost= 0.3243, Validation acc= 0.8253
Epoch 23420: Training cost= 0.2759, Training acc= 0.8251, Validation cost= 0.2677, Validation acc= 0.8253
Epoch 23430: Training cost= 0.2659, Training acc= 0.8252, Validation cost= 0.2712, Validation acc= 0.8253
Epoch 23440: Training cost= 0.2599, Training acc= 0.8252, Validation cost= 0.2643, Validation acc= 0.8254
Epoch 23450: Training cost= 0.3089, Training acc= 0.8252, Validation cost= 0.2910, Validation acc= 0.8254
Epoch 23460: Training cost= 0.3208, Training acc= 0.8252, Validation cost= 0.3619, Validation acc= 0.8254
Epoch 23470: Training cost= 0.2461, Training acc= 0.8252, Validation cost= 0.2582, Validation acc= 0.8254
Epoch 23480: Training cost= 0.3066, Training acc= 0.8253, Validation cost= 0.3184, Validation acc= 0.8254
Epoch 23490: Training cost= 0.3690, Training acc= 0.8253, Validation cost= 0.3079, Validation acc= 0.8255
Epoch 23500: Training cost= 0.3258, Training acc= 0.8253, Validation cost= 0.3247, Validation acc= 0.8255
tm  [ 0.5  0.8  3.6 15.8 -0.8 -0.4 -0.4 -0.5 -0.7 -0.5  3.8 -0.2 -0.2 -0.3 -1.9  4.3  0.1 -0.4  0.9 -1.4 -0.4  0.2  0.3 -0.2 -0.5 -0.2 -0.  -0.3 -0.4 -1.1 -1.7 -0.5 -0.4 -2.9 -0.3 -0.   2.8  2.9  5.3 -0.5 -0.2  3.5  3.2 -0.9 -0.4  0.1  5.5 -0.5  3.7  1.7 -0.8 -0.3 -0.2  2.1 -0.8  2.8 -0.2 10.6 -0.8  5.9 -1.7 -0.5 -0.5  0.1 -0.6 -0.4 -0.1 -0.3  0.2 -0.4  0.2 -0.3 -0.1  0.  -1.  -0.2 -0.9 -0.4 -0.5 -0.1  2.3 -0.2 -0.3 -0.2 -1.4  3.5  0.1 -0.4  0.  -0.5 -0.5  0.1  0.2  2.9 -0.3 -0.1 -0.2 -0.9 -0.1 -0.1  2.2 -1.6 -1.1 -0.1 -0.3  1.1 -0.6 -1.3  1.2 -2.2 -0.2 -0.4 -0.2 -0.3 -0.8  3.  -0.4 -0.7 -0.2  0.2 -0.2  7.8 -0.2 -0.8 -0.5 -2.3 -0.1  0.2  1.   0.3  0.9 -0.5  0.5 -0.5  5.5 -0.8 -0.1 -0.  -0.1 -0.8 -1.1 -0.4 -0.8  0.  -0.3 -0.  -0.3 -0.2  7.8 -0.3 -1.2 -0.2  3.9 -0.5 -0.2 -0.1 -0.1 -0.4 -0.2 -0.8 -0.6 -0.3 -0.2 -0.3 -0.1  0.8  0.1 -0.9 -0.1 -0.2 -0.3 -0.1 -0.5 -0.2 -0.3 -1.9 -0.7 -0.1 -0.4 -0.4 -2.4 -0.  -0.2 -1.2 -0.2  1.4  4.4  0.4 -0.   3.3 -0.3 -0.3 -0.8 -0.5 10.5 -0.2  0.9  1.5 -0.4 -0.2 -0.1 -0.4 -0.3 -0.2 -0.5  0.  -0.2 -0.2 -1.8 -0.4 -0.6  0.3 -0.4 -1.2 -0.1 -0.4  4.5 -0.6 -0.2 -0.5  0.1 -0.  -0.  -0.6 -0.5  2.1  0.9 -0.3 -0.4  3.  -0.6 -0.4 -0.1 -1.1 -0.5 -0.5 -0.2  0.7 -0.2 -1.4 -0.3 -0.7 -0.2  0.1  0.1 -1.5  0.6  0.1 -0.7 -0.3 -0.9 -0.2  3.7 -0.2  0.1  2.5]
ty_50sample [[5 2 9 8 3 6 0 7 1 4]
 [3 8 9 0 2 4 4 7 1 5]
 [7 9 3 8 6 0 5 4 1 2]
 [6 4 5 0 1 7 2 8 9 3]
 [4 3 9 2 8 1 1 5 0 6]
 [3 1 4 9 5 6 8 2 0 7]
 [3 1 0 4 7 2 9 6 8 5]
 [2 9 6 1 5 7 8 0 3 4]
 [5 8 9 9 3 1 0 6 7 4]
 [0 2 3 3 1 4 6 7 8 5]]
tt_50sample [[5 2 9 8 3 6 0 7 1 4]
 [3 8 9 0 2 6 4 7 1 5]
 [7 9 3 8 6 0 5 4 1 2]
 [6 4 5 0 1 7 2 8 9 3]
 [4 3 9 2 8 1 7 5 0 6]
 [3 1 4 9 5 6 8 2 0 7]
 [3 1 0 4 7 2 9 6 8 5]
 [2 9 1 6 5 7 8 0 3 4]
 [5 8 9 2 3 1 0 6 7 4]
 [0 2 3 9 1 4 6 7 8 5]]
vm  [-0.3  1.2 -0.5  3.5 -0.8 -0.1 -0.2 -0.1 -0.7 -1.   4.5 -0.4  0.4 -0.1 -0.5  7.7  0.9 -0.3  0.1 -0.2 -0.6  0.1  1.3  1.1 -1.3  1.6 -0.1 -0.1  1.4 -0.6 -1.1 -0.3 -0.5 -3.3 -0.6 -0.   2.4  5.3  2.3 -0.4 -0.1  0.5  1.7 -0.1 -0.6 -0.3 -0.1 -1.1  0.6  3.1 -0.8 -0.3 -0.4  7.2 -1.4  1.6 -0.   5.4 -0.6  3.8  0.6 -0.4  0.6  0.1 -0.3 -0.2 -0.2 -0.1 -0.5 -0.4 -0.3 -1.  -0.2  0.  -2.7 -0.4 -0.5 -0.2 -0.7  0.5 -2.   0.2  0.6 -0.1 -0.7  2.4 -0.2  0.4  0.8 -0.2  0.3 -0.   0.5  1.7 -0.2 -0.1  0.6 -1.4  0.3 -0.2  3.9 -1.6 -0.7 -0.1 -0.3  0.2 -1.6 -0.8  1.5 -0.3 -0.  -0.  -0.  -0.4 -1.1  7.5 -0.7 -1.1  0.1 -0.2 -0.3 -0.1 -0.2 -0.  -0.  -0.5 -0.1 -1.6 -0.2  4.   0.9 -0.5 -0.1 -0.3  5.5 -2.1  0.3 -0.   1.9 -0.2 -1.  -0.8 -1.  -0.1 -0.1  0.  -0.2 -0.   6.4 -0.2 -0.5 -0.1  2.8 -0.1 -0.4 -0.3 -0.3 -0.4  0.1 -0.2 -0.3 -0.5 -0.  -0.1  0.5 -0.   0.3 -0.4 -0.1  0.3  0.6 -0.3 -0.2 -0.2 -0.2 -1.3 -0.5 -0.   0.  -0.4 -1.1 -0.3 -0.3 -1.5 -0.7 -0.4  1.2 -0.  -0.3  2.3 -0.2 -0.5 -0.3 -1.   2.1  1.1 -0.5  2.2 -0.4 -0.3 -0.2 -0.1 -0.4 -0.5 -0.1 -1.1 -0.2 -0.1  1.4  0.3 -0.1  3.9 -0.3  1.4 -0.5 -0.4  1.6 -0.5 -0.8 -0.3 -0.5 -0.1 -0.1 -1.1 -0.4  3.6  2.   2.2 -0.6  0.6 -0.6  0.3 -0.4  1.3 -0.7  2.5  0.1 -1.   0.3 -1.4 -0.4 -0.6 -0.2 -0.2  7.3 -0.9 -0.2 -0.1 -0.7 -0.2  4.2 -0.1  1.9  0.6 -0.3 -0.4]
vy_50sample [[2 8 5 3 9 9 1 4 0 7]
 [2 1 5 8 9 4 0 3 6 7]
 [1 0 5 4 2 8 9 7 3 6]
 [5 3 9 9 4 2 2 8 0 7]
 [1 5 2 7 9 8 8 3 4 0]
 [2 5 1 8 7 6 3 9 4 0]
 [0 3 2 9 5 7 1 4 8 6]
 [3 5 8 0 6 2 4 1 7 9]
 [6 9 8 4 2 7 0 5 1 3]
 [6 4 7 2 3 5 5 8 9 1]]
vt_50sample [[2 8 5 3 9 6 1 4 7 0]
 [2 1 5 9 8 4 0 3 6 7]
 [1 0 5 4 2 8 9 7 3 6]
 [5 3 9 1 4 2 6 8 0 7]
 [1 5 2 7 9 8 6 4 3 0]
 [2 5 1 8 7 6 3 9 4 0]
 [0 3 2 9 5 7 1 4 8 6]
 [3 5 8 0 6 2 4 1 7 9]
 [6 9 8 4 2 0 7 5 1 3]
 [6 4 7 2 3 5 8 0 9 1]]
Epoch 23510: Training cost= 0.3755, Training acc= 0.8253, Validation cost= 0.3176, Validation acc= 0.8255
Epoch 23520: Training cost= 0.2880, Training acc= 0.8254, Validation cost= 0.3555, Validation acc= 0.8255
Epoch 23530: Training cost= 0.3469, Training acc= 0.8254, Validation cost= 0.2944, Validation acc= 0.8256
Epoch 23540: Training cost= 0.3203, Training acc= 0.8254, Validation cost= 0.2691, Validation acc= 0.8256
Epoch 23550: Training cost= 0.3150, Training acc= 0.8254, Validation cost= 0.2684, Validation acc= 0.8256
Epoch 23560: Training cost= 0.3196, Training acc= 0.8255, Validation cost= 0.3149, Validation acc= 0.8256
Epoch 23570: Training cost= 0.3086, Training acc= 0.8255, Validation cost= 0.3447, Validation acc= 0.8256
Epoch 23580: Training cost= 0.3494, Training acc= 0.8255, Validation cost= 0.3119, Validation acc= 0.8257
Epoch 23590: Training cost= 0.2724, Training acc= 0.8255, Validation cost= 0.3162, Validation acc= 0.8257
Epoch 23600: Training cost= 0.2670, Training acc= 0.8255, Validation cost= 0.3089, Validation acc= 0.8257
tm  [-0.1 -0.5  5.8  7.2 -1.4 -0.7 -0.1 -0.4  1.9 -0.6 -0.5  2.2 -1.6 -0.   0.8 -0.9 -0.5 -0.2  0.6  0.2 -0.5  0.3 -0.8 -0.4 -0.8  1.4 -0.3 -0.  -0.1 -2.6 -0.5 -0.3 -0.6  3.3 -0.8 -1.  -0.7 -0.5  1.9 -0.6 -0.4 -0.3 -0.1 -0.8 -0.8 -0.3 -0.4 -0.2  1.7 -2.4 -0.8  0.   1.4 -0.7 -1.1  0.6  0.2  7.6  3.5  3.5 -0.2 -0.2  1.3 -0.4  1.1 -0.5 -0.2  2.2  1.4 -0.5 -0.2 -0.4  1.  -0.1 -4.1  0.1 -1.1 -0.5 -0.7 -0.3  2.8 -0.5  0.6 -0.3 -1.5 -0.2 -0.6 -0.2 -0.2 -0.  -0.3 -0.5 -0.2 -0.8 -0.5 -0.4 -0.3 -2.  -0.6 -0.4  1.3 -1.6 -1.1 -0.2 -0.4  0.8 -1.6 -0.3 -0.1 -0.3  1.7 -0.3 -0.  -0.8  2.8  0.9  0.2  3.2  0.1  3.2 -0.5 -0.4 -0.2  0.  -0.4  0.8 -0.2  5.6  5.6  7.1  1.4 -0.6  0.1 -0.1 -0.1  2.4  0.7 -0.3 -0.1 -0.7  0.9 -0.5  1.7  0.1 -0.3 -0.  -0.2 -0.3  3.7 -0.6 -0.7 -0.2  2.7  2.3 -0.1 -0.4 -0.1 -0.1  0.5 -0.2 -0.4 -1.3  1.2 -0.1 -0.  -0.4 -0.3  1.3 -0.6  0.4 -0.4 -0.2 -0.4 -0.6 -0.4 -0.9 -0.8 -0.3  0.3  0.5 -1.2 -0.3 -0.2 -2.  -0.2  0.2  2.6 -0.3  0.8  8.5 -0.3 -0.2 -0.6 -1.3  3.6 -1.4 -0.7 -1.  -0.1 -0.3  0.1 -0.1 -0.3 -0.6 -0.5 -1.   0.3 -0.1 -2.5 -0.4 -0.2  1.7 -1.  -0.2 -0.6  1.9  3.8 -0.4  0.8  1.  -0.6 -0.7 -0.  -1.2 -0.9  0.6 -2.4 -0.1  2.2  4.6 -0.5 -0.1 -0.1 -1.6 -0.8 -1.   2.  -1.3  1.9 -2.6 -0.3 -1.1 -0.1 -0.1 -0.  -1.3 -0.1 -0.1 -1.  -0.3 -1.  -0.3  1.4 -0.1  6.7 -1.9]
ty_50sample [[3 5 9 9 0 6 8 1 2 4]
 [1 8 4 3 9 2 5 7 0 6]
 [3 2 6 0 5 1 7 9 4 8]
 [4 2 5 6 8 0 9 7 1 3]
 [9 6 5 7 8 4 3 0 2 1]
 [7 5 0 8 4 9 3 2 6 1]
 [0 8 5 1 3 7 4 2 9 6]
 [0 4 2 7 8 6 3 5 1 9]
 [7 1 9 3 6 5 8 8 2 2]
 [7 6 9 1 8 2 5 3 0 0]]
tt_50sample [[3 5 9 7 0 6 8 1 2 4]
 [1 8 4 3 9 2 5 7 0 6]
 [3 2 6 0 5 7 1 9 4 8]
 [4 2 5 6 8 0 9 7 1 3]
 [9 6 5 7 8 4 3 0 2 1]
 [7 5 0 8 4 9 3 2 6 1]
 [0 8 5 1 3 4 7 2 9 6]
 [0 4 2 7 8 6 3 5 1 9]
 [7 1 9 3 6 5 8 4 2 0]
 [7 6 9 1 8 2 5 3 4 0]]
vm  [-0.7 -0.3  3.1  9.4 -1.2 -0.2  0.1 -0.2  2.  -0.6 -1.1 -0.3 -0.8 -0.1 -0.6 -0.4 -0.7 -0.6 -0.2 -1.2 -0.8 -0.  -0.5 -0.3 -0.5  1.7 -0.2 -0.2  2.  -0.2  2.9 -0.3 -0.5  6.9 -0.5 -1.  -0.8 -1.7  3.9 -0.5 -0.5 -1.3 -0.7 -0.5 -0.4 -0.1  6.1  0.1  2.3 -0.8 -0.5 -0.1  2.7 -2.6 -0.9  1.6  0.4 -0.9  3.1 -0.6 -1.1 -0.4 -0.1  0.3  1.4  0.1 -0.1  0.9  2.4 -0.1 -0.2 -1.4  0.2  0.9 -0.1 -0.4 -1.3 -0.4 -0.1 -0.1 13.2 -0.2  0.2  0.5 -0.7 -0.9  1.5 -0.1 -0.5 -0.2  1.4 -0.3 -0.2 -1.9 -0.5  0.6 -0.8 -1.4 -0.4 -0.2  0.8  2.9 -0.6 -0.  -0.4  1.   1.8  2.6 -0.2 -1.8  0.2 -0.4 -0.2 -0.9  2.1  8.3 -0.2  1.   0.3 -0.  -0.3  6.1  0.5  0.9 -0.2 -0.8  0.1 13.2  3.8 -0.9  2.5 -0.8  0.6 -0.4  3.1  9.7  1.  -0.1  0.2 -0.5  4.  -0.1  2.3  0.4 -0.3  0.  -0.  -0.1 -1.4 -0.3 -0.3 -0.4  1.2  1.6  1.1  0.8  0.2 -0.5 -0.7 -0.1 -0.2  0.2  1.4  0.3 -0.2 -0.4  0.1  3.9 -0.1  0.7 -0.7 -0.6  0.5 -0.1 -0.1  3.8 -0.7  2.1 -0.1  0.9  0.7 -0.4 -0.7 -1.7 -0.6  0.5  3.6 -0.4 -0.   1.4 -0.4 -0.1 -1.1 -0.8  7.7 -1.1  3.3 -0.6 -0.  -0.1 -0.  -0.2 -0.7 -0.7 -0.2  3.7 -0.1 -0.2  2.2 -0.5  0.4  6.4 -1.6  1.8 -1.3 -0.4  2.5 -0.4 -0.2  1.4 -1.4 -0.5 -0.2 -0.8  2.3  2.6 -2.4  0.2  1.1  4.2 -0.1 -1.7  0.2  1.2 -0.8 -0.2  0.7  2.7  4.7 13.4 -0.2  6.  -0.1 -0.3 -2.4 -2.8  0.1 -0.2 -1.4 -0.6 -3.4 -0.2  2.5 -0.3  6.1  6.3]
vy_50sample [[9 6 7 3 4 1 8 5 0 2]
 [4 7 1 8 0 3 5 2 2 6]
 [1 4 4 9 0 0 6 2 5 3]
 [5 5 9 4 1 7 2 2 3 0]
 [1 7 8 4 6 0 0 2 2 3]
 [7 5 6 9 1 3 2 4 0 8]
 [4 5 1 8 2 7 9 3 6 6]
 [2 4 9 8 0 7 3 1 5 6]
 [4 7 2 8 8 3 0 6 1 5]
 [9 3 0 0 7 2 4 5 1 6]]
vt_50sample [[9 6 7 3 4 1 8 5 0 2]
 [4 7 1 8 0 3 5 9 2 6]
 [1 4 9 8 0 7 6 2 5 3]
 [8 5 9 4 6 7 1 2 3 0]
 [1 7 8 4 6 5 0 9 2 3]
 [7 5 6 9 1 3 2 4 0 8]
 [4 5 1 8 2 7 9 3 6 0]
 [2 4 9 8 0 7 3 5 6 1]
 [4 7 2 8 9 3 0 6 1 5]
 [9 3 8 0 7 2 4 5 1 6]]
Epoch 23610: Training cost= 0.3113, Training acc= 0.8256, Validation cost= 0.3147, Validation acc= 0.8257
Epoch 23620: Training cost= 0.2959, Training acc= 0.8256, Validation cost= 0.2811, Validation acc= 0.8258
Epoch 23630: Training cost= 0.2985, Training acc= 0.8256, Validation cost= 0.2682, Validation acc= 0.8258
Epoch 23640: Training cost= 0.3381, Training acc= 0.8256, Validation cost= 0.2799, Validation acc= 0.8258
Epoch 23650: Training cost= 0.3738, Training acc= 0.8257, Validation cost= 0.2992, Validation acc= 0.8258
Epoch 23660: Training cost= 0.3759, Training acc= 0.8257, Validation cost= 0.3439, Validation acc= 0.8259
Epoch 23670: Training cost= 0.4056, Training acc= 0.8257, Validation cost= 0.2954, Validation acc= 0.8259
Epoch 23680: Training cost= 0.2996, Training acc= 0.8257, Validation cost= 0.3393, Validation acc= 0.8259
Epoch 23690: Training cost= 0.2503, Training acc= 0.8257, Validation cost= 0.2911, Validation acc= 0.8259
Epoch 23700: Training cost= 0.2208, Training acc= 0.8258, Validation cost= 0.3250, Validation acc= 0.8259
tm  [-0.5 -0.2 -3.1 -3.7 -0.4 -0.3 -0.4 -0.1 -0.4 -0.6  3.5 -0.8  1.  -0.1  1.   5.8 -0.3 -0.2 -0.5  3.3 -0.9 -0.2  2.4 -0.4 -1.   0.2 -0.7  0.3 -0.2 -0.9  0.6 -0.4 -0.1 -4.5 -0.4  0.1  1.3  0.9 -3.8 -1.  -0.2 -1.4 -0.6  0.6 -0.1 -0.1 -2.6 -1.1  0.8  4.6 -0.6 -0.3 -0.6 11.9 -1.2 -0.1 -0.6 -1.7  4.2  1.8  4.6  0.1 -0.5  1.3 -0.5  1.1 -0.1  0.2 -0.2  0.1 -0.3 -0.8 -0.  -0.5 -5.2  0.6 -0.6  0.2 -0.1  0.7 -5.   0.9 -0.1  2.3 -0.4 -1.2  2.4 -0.1 -0.2 -0.5 -0.4 -0.3 -0.1 -0.  -0.4 -0.  -0.1 -2.4 -0.4 -0.1  2.3 -1.9 -0.5  0.2  0.4 -0.3 -3.   0.9  2.2  3.  -0.7 -0.2  0.3 -0.8 -0.   5.4 -0.5  0.6 -0.2 -0.6 -0.3 -1.6 -0.4 -0.2 -0.4  1.2 -0.2 -3.1  1.8  8.4  1.6 -0.9 -0.3 -0.3 12.5  2.3 -0.1 -0.2 -0.4 -0.6 -0.8 -0.6 -1.4 -0.2 -0.  -0.1 -0.2  0.2  3.  -0.2  2.9  0.2  2.5 -0.5  0.5 -0.2  0.6 -0.4 -1.1 -0.7  0.9  1.9 -0.2 -0.3 -0.2 -0.3  1.2  1.8 -0.  -0.3 -0.3 -0.1 -0.2 -0.2 -0.  -0.6 -1.2 -1.   8.4 -0.4 -0.1 -0.4 -0.4 -1.1 -0.3 -0.1 -0.3  1.8 -0.2  2.2 -0.1 -0.4  0.3 -1.  -1.4 -0.9 -1.7 -0.3 -0.1 -0.3 -0.1 -0.3 -0.4 -0.4 -0.  -4.5 -0.3  0.8  6.3 -0.1 -0.5  0.7 -1.1  0.2 -0.3 -0.3  1.1 -0.6 -0.5  0.5 -0.4 -0.4 -0.1 -1.   2.4  2.9  2.2  1.2 -0.2  4.  -0.4  1.5 -0.1  4.1 -0.   6.2  2.1 -2.4  0.5 -1.5 -0.1 -0.7  0.3 -0.3 16.2  6.3  0.6  0.5 -0.7 -0.3 12.7 -0.3 -2.7 -0.3 -0.4 -2.3]
ty_50sample [[2 2 4 4 3 1 0 0 7 9]
 [5 9 3 1 0 2 6 4 8 7]
 [2 6 6 1 9 4 0 7 3 5]
 [1 6 0 2 7 9 4 8 3 5]
 [9 6 3 2 1 5 4 7 0 8]
 [3 9 4 5 0 6 7 2 1 8]
 [7 1 5 3 4 8 9 2 6 0]
 [0 8 1 4 3 5 9 7 6 2]
 [1 7 0 9 2 6 8 5 3 4]
 [0 2 5 5 6 9 7 1 8 4]]
tt_50sample [[2 8 6 4 3 1 0 5 7 9]
 [5 3 9 1 2 0 6 4 8 7]
 [2 8 6 1 9 4 0 7 3 5]
 [1 6 0 2 7 9 4 8 3 5]
 [9 6 3 2 1 5 4 7 0 8]
 [3 9 4 5 0 6 7 2 1 8]
 [7 1 5 3 4 8 9 2 6 0]
 [0 8 1 4 3 5 9 7 6 2]
 [1 7 0 9 2 6 8 5 3 4]
 [0 2 5 9 6 3 7 1 8 4]]
vm  [ 0.9 -0.2 -2.7 -2.8 -1.  -0.1 -0.1 -0.  -0.3 -0.9  1.4 -0.1 -0.5 -0.  -0.2  4.  -0.3  0.4  0.4  0.7 -0.8  0.1  2.  -0.2 -1.3  1.5 -0.1 -0.   0.2 -0.4  3.1 -0.5 -0.4 -1.6 -0.3 -0.1  0.2  4.3  3.7 -0.8 -0.5 -1.8 -0.2  5.  -0.6 -0.1 -0.5 -0.8  4.2  3.4 -0.7 -0.2  0.5  3.2 -1.3  1.5 -0.2 -2.5  1.7 -0.9 -0.5 -0.2  1.3  0.4 -0.2 -0.6 -0.1  0.7 -0.  -0.2  0.  -0.4  1.6  1.4 -3.3 -0.2 -0.9 -0.4 -0.4 -0.2 -1.1 -0.4  1.2 -0.7 -1.7 -1.6  5.9 -0.1  0.2 -0.2 -0.  -0.4 -0.  -0.2 -0.2 -0.4 -0.5 -1.8 -0.2 -0.3  2.1 -0.5 -1.4 -0.3 -0.1  0.3 -1.1  3.6  0.9 -0.5 -0.5 -0.3  0.5 -0.7 -0.   3.8  0.3 -0.1 -0.1 -0.2  0.2 -0.  -0.6 -0.3 -0.4 -0.2 -0.5 -0.3  0.4  2.6  1.6 -0.5 -0.1 -0.1 -0.2 -2.1  0.3 -0.   0.8 -0.1 -0.6 -0.9 -0.5  0.3  0.  -0.1 -0.3  0.  -0.6 -0.1  1.1  0.3  5.2 -0.2  0.1 -0.1 -0.2 -0.2  2.   0.2  0.8 -1.3 -0.  -0.2 -0.3 -0.4  0.5  1.1  0.  -0.4 -0.3 -0.6 -0.5 -0.1 -0.4  2.1 -0.3  0.7 -0.1 -0.3  0.7 -0.  -0.4 -1.3 -0.6 -0.   3.4 -0.1 -0.   0.5 -0.4 -0.4 -0.1 -1.1  5.7 -0.1 -0.1 -0.4 -0.3 -0.2 -0.1 -0.3 -0.3 -0.4 -0.6 -0.6 -0.3 -0.2  6.1 -0.2 -0.4  1.7 -0.9 -0.4  1.7 -0.3 -1.6 -0.5 -0.3  0.7 -0.5 -0.3 -0.3 -1.3 -0.7  2.  -0.4 -0.1 -0.3  3.1 -0.4 -0.2 -0.2  4.6 -0.5  5.7  0.6 -1.   0.6  6.4 -0.   2.9 -0.1 -0.2  4.9 -1.2 -0.1  0.6 -0.8 -0.   1.6  0.4  2.5 -0.   0.2 -0. ]
vy_50sample [[4 8 2 3 9 7 0 6 5 1]
 [3 6 4 7 9 0 0 8 1 2]
 [1 0 4 7 8 5 9 3 6 2]
 [2 6 3 9 8 5 1 0 0 7]
 [0 9 4 8 1 3 2 6 7 5]
 [1 1 8 3 3 6 4 7 0 2]
 [0 4 1 6 9 3 5 8 7 2]
 [7 8 5 2 4 0 9 9 6 6]
 [4 1 3 8 7 8 6 9 5 0]
 [8 4 9 6 5 1 0 3 2 7]]
vt_50sample [[4 8 2 3 9 7 0 6 1 5]
 [3 6 4 7 9 5 0 8 1 2]
 [1 0 4 7 8 5 9 3 6 2]
 [2 6 3 9 8 5 1 0 4 7]
 [0 9 4 8 1 3 2 6 7 5]
 [1 5 8 3 9 6 4 7 0 2]
 [4 0 1 6 9 3 5 8 7 2]
 [7 8 5 2 4 0 3 9 1 6]
 [4 1 3 2 8 7 6 9 5 0]
 [8 4 9 6 5 1 0 3 2 7]]
Epoch 23710: Training cost= 0.2951, Training acc= 0.8258, Validation cost= 0.2703, Validation acc= 0.8260
Epoch 23720: Training cost= 0.2698, Training acc= 0.8258, Validation cost= 0.2649, Validation acc= 0.8260
Epoch 23730: Training cost= 0.2886, Training acc= 0.8259, Validation cost= 0.2859, Validation acc= 0.8260
Epoch 23740: Training cost= 0.3102, Training acc= 0.8259, Validation cost= 0.2754, Validation acc= 0.8260
Epoch 23750: Training cost= 0.2641, Training acc= 0.8259, Validation cost= 0.2565, Validation acc= 0.8261
Epoch 23760: Training cost= 0.2937, Training acc= 0.8259, Validation cost= 0.2688, Validation acc= 0.8261
Epoch 23770: Training cost= 0.2992, Training acc= 0.8260, Validation cost= 0.2624, Validation acc= 0.8261
Epoch 23780: Training cost= 0.2756, Training acc= 0.8260, Validation cost= 0.2423, Validation acc= 0.8262
Epoch 23790: Training cost= 0.2586, Training acc= 0.8260, Validation cost= 0.3051, Validation acc= 0.8262
Epoch 23800: Training cost= 0.2719, Training acc= 0.8260, Validation cost= 0.2848, Validation acc= 0.8262
tm  [-0.7 -0.  11.   6.3 -2.  -0.5 -0.3 -0.3 -0.7 -0.4  4.6  1.2 -0.7 -0.1 11.2  1.5  0.9 -0.3 -0.4  0.5 -0.9 -0.  -0.9 -0.7 -1.   1.1  0.2 -0.4 -0.3 -0.8 -0.5 -0.4 -0.5 11.9 -0.7 -0.3  1.7  2.5  0.9 -0.3 -0.1  3.3  3.  -0.2 -0.5 -0.1 -1.6 -0.3 -0.3 -2.  -0.4 -0.3 -0.1  3.9 -1.3 -1.2 -0.5  9.6 -0.7  3.6  5.1 -0.4  0.4 -0.2 -0.3 -0.8 -0.2 -0.2 -0.5 -0.3  1.2 -0.2 -0.3 -0.1 -5.4 -0.9 -0.3 -0.8 -0.5 -0.2  0.8 -0.3 -0.2 -0.7 -0.5  3.  -0.8 -0.1  0.2 -0.5 -0.5  0.2 -0.2  1.8 -0.2 -0.3 -0.4 -1.8 -0.1 -0.4  2.1  3.4  0.4 -0.1 -0.3  1.9 -2.2 -0.2  1.2 -0.6  1.1 -0.3 -0.2 -0.7 -0.5  1.7 -0.7 -0.1  0.9 -0.4  0.8 -0.3 -0.3  0.3 -0.3 13.6 -0.  -0.5  1.1  8.4 -0.5  0.2 -0.2  0.8 -5.1  0.6 -0.2 -0.2 -0.2 -0.6 -0.1 -0.1 -0.1 -0.3  0.1 -0.2 -0.6 -0.2  2.  -0.2 -0.8  0.9 -0.9 -0.  -0.2 -0.1 -0.7 -0.2  2.3 -0.3 -0.3 -1.2 -0.1 -0.2  0.2 -0.1 -0.8 -0.5  0.3 -0.1 -0.2 -0.  -0.2 -0.3  0.1  0.3 -0.2 -1.1  0.6 -0.4 -2.  -0.5 -0.1 -1.2 -0.2 -0.2 -0.4 -0.8 -0.3  2.5 -0.1 -0.3  0.4 -1.  -1.1  1.  -1.2  1.  -0.1 -0.2 -0.  -0.2 -0.1 -0.4 -0.5 -2.3 -0.3 -1.  -4.  -0.3 -0.7  0.1 -0.6  2.9 -0.4 -0.2  1.9 -0.7 -0.5 -0.1 -0.1 -0.   0.9 -0.3 -1.2 -0.6 -1.1 -0.3 -0.5 -0.2 -0.5  1.4 -0.2 -2.6 -0.4 -2.3 -0.1 -1.7  0.2 -4.7 -0.2 -2.1 -0.2 -0.1  1.2  1.1 -0.6 -0.1 -0.8 -0.5 -0.4 -0.2  0.8 -0.2  2.9 -1.9]
ty_50sample [[5 7 3 1 2 0 8 6 9 4]
 [9 3 4 8 2 1 5 0 6 7]
 [4 0 1 3 7 5 6 8 9 2]
 [2 3 6 9 7 1 0 4 8 5]
 [2 2 7 9 5 4 1 6 6 3]
 [6 9 7 3 5 1 0 4 8 2]
 [5 6 9 3 4 1 7 2 0 8]
 [5 8 3 7 1 4 6 9 0 2]
 [7 6 9 4 5 0 3 1 8 2]
 [9 3 6 0 5 1 8 4 7 2]]
tt_50sample [[7 5 3 1 2 0 6 8 9 4]
 [9 3 4 8 2 1 5 0 6 7]
 [4 1 0 7 3 5 6 8 9 2]
 [2 3 6 7 9 1 0 4 8 5]
 [2 9 7 0 5 4 1 8 6 3]
 [6 9 7 3 5 1 0 4 8 2]
 [5 6 9 3 4 1 7 2 0 8]
 [5 8 3 7 1 4 6 9 0 2]
 [7 6 9 4 5 0 3 1 8 2]
 [9 3 6 0 5 1 8 4 7 2]]
vm  [-0.9 -0.6  9.1  9.6 -1.8 -0.3 -0.5 -0.2  0.8 -0.7  3.7 -0.4 -0.2 -0.1  4.  -0.9 -0.6 -0.3  2.  -0.4 -0.7 -0.5 -0.7 -0.4 -0.6  3.7 -0.6  0.3 -1.  -1.9 -0.1  0.1 -0.4  9.5 -0.4 -0.6 -0.  -0.8 -0.1 -0.7 -0.6 -1.  -0.6 -1.1 -0.2 -0.3 -0.3 -0.1  2.6 -1.9 -0.4 -0.2 -0.  -0.2  0.5 -0.1 -0.3  3.6  4.5  2.6  1.4 -0.1 -0.5  2.  -0.2  0.1 -0.3 -0.3  2.9 -0.  -0.1  2.2  0.5  1.5 -1.9 -0.2 -1.  -0.5 -0.2 -0.3  6.8 -0.5  0.1 -0.3 -0.4 -0.9 -0.9 -0.1 -0.3 -0.1 -0.1 -0.4 -0.5 -1.1 -0.7  0.2 -0.  -2.1 -0.5 -0.5  2.4  3.2 -0.2 -0.  -0.3  0.9 -0.7 -0.2  0.9 -1.2 -0.4 -0.1 -0.  -0.4  4.2 -0.4 -0.3  1.9 -0.2 -0.2  0.4  3.9  0.9  1.4 -0.5  4.6 -0.4  4.1  4.1  2.5  1.7 -0.9 -0.2 -0.8 -1.1  8.4  0.7 -0.1  0.2 -0.4  0.7 -0.7  0.6  0.7 -0.5  0.4 -0.3 -0.2 -1.5 -0.  -0.5 -0.2 -0.4  1.1 -0.1  0.3 -0.  -0.6 -0.3 -0.4 -0.1  0.   0.1 -0.1 -0.5 -0.6  0.9  2.4 -0.1 -0.1 -0.4 -0.5  0.1 -0.3 -0.3  3.9 -0.5 -0.2  2.  -0.  -0.5 -0.4 -0.5 -1.4  0.8  0.1  1.4 -0.4  0.6  6.  -0.2 -0.2 -0.6 -0.4  0.7 -1.1 -0.2 -1.1  0.2  0.6 -0.5 -0.4 -0.7 -0.6 -0.4 -1.6 -0.1 -0.3 -0.6 -0.3 -0.2 -0.2 -1.2  0.5 -1.  -0.3  5.4 -0.7  0.8  0.7 -0.7 -0.3 -0.3 -0.9  1.3 -1.  -1.4  1.   0.1  3.9 -0.3 -1.  -0.1 -0.6  3.6 -2.3  2.  -0.2  4.   3.2 -0.1  2.  -0.1 -0.  -1.  -0.5  0.1  0.5 -1.4 -0.4 -1.9 -0.2 -0.1 -0.4  4.6 -0. ]
vy_50sample [[7 0 3 6 9 1 5 2 8 4]
 [9 5 7 4 1 3 0 2 6 8]
 [0 1 3 5 2 6 7 4 8 9]
 [9 2 4 5 8 7 6 1 3 0]
 [7 6 3 4 1 2 5 0 0 9]
 [7 5 4 6 0 2 8 9 1 3]
 [4 9 1 0 2 7 3 8 6 5]
 [2 0 9 3 1 8 5 6 7 4]
 [4 1 9 7 0 2 6 8 5 3]
 [5 3 7 8 1 6 4 2 2 0]]
vt_50sample [[7 0 3 6 1 9 5 2 8 4]
 [9 5 4 7 1 3 0 2 6 8]
 [0 1 3 5 2 6 7 4 8 9]
 [9 2 4 5 8 7 6 1 3 0]
 [7 3 6 4 1 2 5 0 8 9]
 [7 5 4 0 6 2 8 9 1 3]
 [4 9 1 0 2 7 3 8 6 5]
 [2 0 9 3 1 8 5 6 7 4]
 [4 1 9 7 0 2 6 8 5 3]
 [5 3 7 8 1 6 4 9 2 0]]
Epoch 23810: Training cost= 0.3111, Training acc= 0.8261, Validation cost= 0.2925, Validation acc= 0.8262
Epoch 23820: Training cost= 0.2919, Training acc= 0.8261, Validation cost= 0.2729, Validation acc= 0.8263
Epoch 23830: Training cost= 0.3088, Training acc= 0.8261, Validation cost= 0.3008, Validation acc= 0.8263
Epoch 23840: Training cost= 0.3217, Training acc= 0.8261, Validation cost= 0.2757, Validation acc= 0.8263
Epoch 23850: Training cost= 0.3631, Training acc= 0.8262, Validation cost= 0.3465, Validation acc= 0.8263
Epoch 23860: Training cost= 0.2602, Training acc= 0.8262, Validation cost= 0.2800, Validation acc= 0.8264
Epoch 23870: Training cost= 0.3086, Training acc= 0.8262, Validation cost= 0.2678, Validation acc= 0.8264
Epoch 23880: Training cost= 0.3528, Training acc= 0.8262, Validation cost= 0.3031, Validation acc= 0.8264
Epoch 23890: Training cost= 0.3214, Training acc= 0.8263, Validation cost= 0.2582, Validation acc= 0.8264
Epoch 23900: Training cost= 0.3335, Training acc= 0.8263, Validation cost= 0.2889, Validation acc= 0.8264
tm  [-0.3  0.1  3.4 11.1 -1.2 -0.2 -0.3 -0.1 -0.4 -0.6 -2.3 -0.5 -0.1 -0.3 -1.1 -0.3 -0.2 -0.1  0.1 -0.9 -0.6 -0.6  0.3  0.7 -0.5 -0.1 -0.4 -0.  -0.9 -1.6 -1.9 -0.1  0.4 -3.7 -0.5 -0.1  1.9 -0.4 -0.6 -0.8 -0.3 -1.  -0.1 -1.2 -0.5 -0.2  3.6 -0.4  1.   0.1 -0.9 -0.4 -0.5 -0.1 -0.2  2.6 -0.5  7.5  0.4  6.9 -0.3 -0.3 -0.8  0.4 -0.4  0.2 -0.  -0.2  0.6 -0.5 -0.3  0.7 -0.1 -0.5 -1.5  0.7 -0.8 -0.3 -0.6 -0.  -1.8 -0.4 -0.5  1.9 -0.8 -0.8 -0.6 -0.3 -0.2 -0.4 -0.4  0.7 -0.1  1.6 -0.3 -0.3  0.9 -1.5 -0.1 -0.2  3.4 -2.5 -0.8 -0.1  0.5 -0.5 -1.5 -1.5 -0.7 -0.9 -0.3 -0.1  0.5 -0.3  0.9 -0.4 -0.5 -0.  -0.5 -0.3 -0.5  4.3 -0.1 -0.3 -0.5 -1.3 -0.1  3.6  1.1  5.5  1.7 -0.9  0.2 -0.5  9.5 -0.5 -0.1 -0.1  1.1 -0.2 -0.3 -0.8 -0.4 -0.2 -0.4 -0.1 -0.5 -0.1  4.4 -0.2 -1.3 -0.1  3.9 -0.4 -0.2 -0.1  1.  -0.5 -1.1 -0.5 -0.7  0.6 -0.4 -0.2 -0.4 -0.1  0.9  0.1 -0.4 -0.  -0.2 -0.  -0.4 -0.1 -0.4 -1.1 -1.3 -0.5  2.1 -0.1 -1.4 -0.6 -0.4 -1.4 -0.2  0.2  2.6 -0.1 -0.2  5.5 -0.3 -0.  -0.9 -0.8  4.2 -0.7 -0.8 -0.4 -0.2  0.1 -0.4 -0.5 -0.5 -0.4 -0.5 -1.9 -0.  -0.   4.  -0.2 -0.6 -0.4 -0.7 -0.9 -0.4 -0.4  6.3 -0.4 -0.1 -0.3 -0.4 -0.3 -0.5 -1.2 -0.3  1.9 -0.8 -0.1 -0.5  4.5 -0.8  0.4 -0.4  2.8  1.1 -0.3  1.9 -0.6  1.4 -0.3  0.2 -0.3 -0.1 -0.1  6.8 -0.5  1.4  0.3 -1.  -0.2  3.8 -0.2 -0.4 -0.4  5.6 -0.9]
ty_50sample [[3 8 6 0 5 9 2 1 7 4]
 [8 9 5 3 7 2 1 4 0 6]
 [4 0 8 2 1 3 6 5 9 7]
 [9 3 6 7 1 8 0 2 5 4]
 [9 5 8 7 1 6 4 2 3 0]
 [2 1 6 3 9 8 8 7 4 5]
 [9 4 6 0 7 5 8 3 1 2]
 [9 6 5 7 1 3 4 0 2 8]
 [7 3 4 0 2 5 6 6 1 9]
 [1 8 3 5 6 0 9 7 9 4]]
tt_50sample [[3 8 6 0 5 9 2 1 7 4]
 [8 9 5 3 7 2 4 1 6 0]
 [4 0 8 2 1 3 6 5 9 7]
 [9 3 6 7 1 0 8 2 5 4]
 [5 9 8 7 6 1 4 2 3 0]
 [2 6 1 3 9 0 8 7 4 5]
 [9 4 6 0 7 5 3 8 1 2]
 [9 6 5 7 1 3 4 0 2 8]
 [7 3 4 0 2 5 6 1 8 9]
 [1 8 3 5 6 0 2 9 7 4]]
vm  [-0.4 -0.2 -1.7 -2.2 -0.5 -0.2 -0.5 -0.2 -1.  -0.4 -2.1  0.9 -0.3 -0.4  1.2  3.8 -0.  -0.2 -0.  -0.2 -0.9 -0.1 -0.6 -0.6 -1.1 -0.5 -0.5 -0.6  3.7  0.1 -0.1 -0.2  1.7 -3.3 -0.9 -0.3 -0.  -1.  -3.8 -0.6  0.9 -3.8 -0.8 -0.2 -0.  -0.3 -1.2 -0.5 -0.4 -0.8 -0.7 -0.2 -1.   4.  -1.8  0.9 -0.8 -2.2  1.3  1.9  2.7 -0.4 -0.7 -0.5 -1.2 -0.1 -0.2  0.9  0.3 -0.2 -0.3 -1.8 -0.4 -0.1 -5.4  1.  -0.4 -0.2 -0.6 -0.2 -3.9  0.4 -0.4 -0.  -0.4 -3.7  2.  -0.1 -0.  -1.  -0.7  0.2 -0.   2.1 -0.4 -0.1 -0.2 -2.  -0.5 -0.6  2.5 -2.1 -0.2 -0.   0.7 -0.  -2.5 -0.2 -0.6 -0.3 -0.1 -0.4 -0.2 -1.  -0.5  8.9 -0.   1.1 -0.2 -0.3  0.3 -0.2 -0.4 -0.4 -0.2  1.5  0.6 -0.5 -0.4 12.3  0.  -0.4 -0.1 -0.2 10.4  4.6 -0.3 -0.  -0.4 -0.4 -0.3 -0.2 -0.3 -0.4 -0.1 -0.2 -0.5 -0.1 -0.8 -0.4  1.6 -0.   1.7 -0.6 -0.6 -0.2 -0.3 -0.5 -1.4 -0.5 -0.4  1.1 -0.2 -0.2 -0.3 -0.3 -0.2  1.4 -0.3 -0.5 -0.6 -0.6  0.4 -0.2  0.1  2.4 -1.9 -1.   7.5 -0.5  2.4 -0.   0.6 -1.1 -0.9  0.9 -0.  -0.2 -0.4  0.2 -0.2  0.2 -0.3 -1.5 -0.5 -0.2 -1.6 -0.   0.5 -0.4  0.2 -0.4  0.9 -0.5 -0.7 -2.8 -0.5 -0.5  9.4 -0.4 -0.1  3.3 -1.1  1.   0.2 -0.   1.5 -0.4 -0.1  0.9 -0.8 -0.3 -0.3 -0.8 -0.6  3.8 -1.3 -0.5 -0.2  1.4 -0.1  4.  -0.1  4.6 -1.7  3.2  0.4 -2.4 -0.3  6.  -0.1  3.1 -0.1 -0.2 12.8  2.9  0.4 -0.4 -0.9 -0.3 10.9 -0.2 -2.5 -0.2  5.1 -3.2]
vy_50sample [[3 6 8 4 1 2 7 9 5 0]
 [4 5 3 2 0 7 6 9 8 1]
 [3 1 5 8 4 9 7 0 6 2]
 [2 5 3 1 4 8 6 9 7 7]
 [2 0 3 1 7 6 4 9 8 5]
 [9 2 8 5 6 3 0 7 1 4]
 [3 6 0 9 1 1 4 8 8 5]
 [2 0 3 7 9 6 4 1 8 5]
 [6 8 2 5 0 7 4 9 3 1]
 [4 0 3 6 2 9 7 8 1 1]]
vt_50sample [[3 6 8 4 1 2 7 9 5 0]
 [4 5 3 2 0 7 6 9 8 1]
 [3 1 5 8 4 9 7 0 6 2]
 [2 5 3 1 4 8 6 0 9 7]
 [2 0 3 1 7 6 4 9 8 5]
 [9 2 8 5 6 3 0 7 1 4]
 [3 6 0 9 7 1 4 2 8 5]
 [2 0 3 7 9 6 4 1 8 5]
 [6 8 2 5 0 7 4 9 3 1]
 [4 0 3 6 2 9 7 8 5 1]]
Epoch 23910: Training cost= 0.3255, Training acc= 0.8263, Validation cost= 0.3102, Validation acc= 0.8265
Epoch 23920: Training cost= 0.2916, Training acc= 0.8263, Validation cost= 0.3550, Validation acc= 0.8265
Epoch 23930: Training cost= 0.2898, Training acc= 0.8263, Validation cost= 0.3368, Validation acc= 0.8265
Epoch 23940: Training cost= 0.3385, Training acc= 0.8264, Validation cost= 0.3750, Validation acc= 0.8265
Epoch 23950: Training cost= 0.3842, Training acc= 0.8264, Validation cost= 0.3567, Validation acc= 0.8266
Epoch 23960: Training cost= 0.2927, Training acc= 0.8264, Validation cost= 0.3088, Validation acc= 0.8266
Epoch 23970: Training cost= 0.3143, Training acc= 0.8264, Validation cost= 0.2959, Validation acc= 0.8266
Epoch 23980: Training cost= 0.3216, Training acc= 0.8264, Validation cost= 0.3401, Validation acc= 0.8266
Epoch 23990: Training cost= 0.2697, Training acc= 0.8265, Validation cost= 0.4082, Validation acc= 0.8266
Epoch 24000: Training cost= 0.2583, Training acc= 0.8265, Validation cost= 0.3504, Validation acc= 0.8267
tm  [-1.4 -1.1 -2.8 -1.4 -0.3 -0.2 -0.3 -0.   1.4 -0.  -5.2 -0.4 -0.2 -0.2 -0.8 -0.5 -0.5 -0.2 -0.8 -0.4 -0.5 -0.3  1.6 -0.4 -0.7 -0.2 -0.4 -0.3  0.3 -1.4 -0.4 -0.4 -0.  -5.  -0.7 -0.9 -0.4 -1.3 -1.4 -0.4  0.1 -1.  -1.3  0.2 -0.3 -0.5 -0.1  0.1 -1.3  7.6 -0.6 -0.  -0.9 -0.6 -1.3  1.4 -0.6 -1.6  6.1  2.   5.7 -0.5 -0.4 -0.4 -0.8 -0.1  0.   1.2  0.6 -0.2 -0.1 -1.1 -0.1 -0.5 -3.7 -0.2 -0.2  0.1 -0.1 -0.4 -3.8 -0.1 -0.3  2.6  0.8 -1.2 -0.6 -0.2 -0.3 -0.8 -0.3 -0.2 -0.2 -1.3 -0.7 -0.1 -0.4 -2.  -0.2 -0.7 -0.1 -1.4  2.  -0.  -0.3 -0.4 -2.2 -0.5 -1.8 -0.6  1.4  0.4 -0.1 -0.9  4.7  4.5 -0.6  2.6 -0.3 -0.3 -0.2  1.2 -0.2 -0.2 -0.2 -1.   0.   5.3  4.6  2.2 -0.2 -1.  -0.4 -0.3 11.4 -1.3 -0.3 -0.2 -0.  -0.3  2.6 -0.5  0.1 -0.  -0.  -0.1 -0.1  0.   2.8 -0.5  1.3 -0.2  1.3 -0.2 -0.2 -0.1 -0.  -0.6 -0.8 -0.2 -0.2  0.1 -0.2 -0.3 -0.3 -0.5 -0.3  4.5 -0.2 -0.2 -0.5 -0.1 -0.3 -0.2  0.  -0.2 -1.2 -0.7  3.8  0.   0.9 -0.4 -0.4 -1.5 -0.4  0.1 -0.8  0.7 -0.3  3.9 -0.5 -0.5 -0.9 -0.9 -1.5 -1.4 -1.  -1.  -0.2 -0.3 -0.3 -0.4 -0.3 -0.6 -0.2 -2.6 -0.3 -0.1  9.  -0.1 -0.6  3.2 -0.8  3.9 -0.5 -0.7  0.2 -0.4 -0.  -0.1 -0.8 -0.4 -0.1 -1.3  1.7  3.4 -1.9  1.1 -0.4  2.2 -0.3  0.6 -0.3  4.7 -0.6  4.8  0.7 -1.6  1.3  4.2 -0.1  1.7 -0.3 -0.3 12.3 -0.1  0.1 -0.4 -1.   0.6  9.6 -0.2 -1.1 -0.4  4.   0.2]
ty_50sample [[8 1 6 4 3 9 0 5 2 7]
 [9 0 6 3 5 8 1 7 4 2]
 [2 3 7 8 0 5 1 4 6 9]
 [6 5 3 7 0 4 9 2 1 8]
 [6 2 3 9 1 8 5 4 7 0]
 [1 4 5 8 3 6 2 7 0 9]
 [9 5 2 4 3 8 6 1 7 0]
 [9 4 3 8 0 0 1 5 7 6]
 [0 2 9 6 3 8 5 4 7 1]
 [0 5 9 3 6 8 8 2 4 1]]
tt_50sample [[8 1 6 4 3 9 0 5 2 7]
 [9 0 6 3 5 8 1 7 4 2]
 [2 3 7 8 0 5 1 4 6 9]
 [6 5 3 7 0 4 9 2 1 8]
 [6 2 3 9 1 8 5 4 7 0]
 [1 4 5 8 3 6 2 0 7 9]
 [9 5 2 4 3 8 6 1 7 0]
 [9 4 3 8 0 2 1 5 7 6]
 [0 2 9 6 3 5 8 4 7 1]
 [0 5 9 3 6 8 7 2 4 1]]
vm  [ 3.2 -0.1 -1.4 -1.1 -1.5 -0.  -0.  -0.3 -1.2 -0.1  3.7 -0.3 -0.5 -0.1  1.4 -1.  -0.  -0.5 -0.4 -1.6 -0.7  0.1  0.9  0.5 -1.2  0.7 -0.1 -0.4 -1.8  3.2  4.6 -0.1  0.8  6.6  0.7  1.5  5.  -0.5 -0.2 -0.5 -0.2  3.   2.1  1.6 -0.6 -0.2  5.  -0.3  3.1  1.9 -0.5 -0.2 -0.2 -1.2  0.3 -0.  -0.6 -1.3 -1.5 -2.3 -1.9 -0.4 -0.2  0.2  1.2 -0.8 -0.3 -0.5 -0.  -0.4 -0.   4.7 -0.5 -0.4 -1.3 -0.6 -0.3 -0.2 -0.2 -0.1 10.9 -0.3 -0.2 -0.2 -1.7  3.1  7.4 -0.2 -0.1  0.6 -0.5 -0.5 -0.4  2.8 -0.1 -0.2 -0.  -0.4  0.8  0.9 -0.5  4.6 -1.3 -0.3  0.3 -0.3 -0.9  5.3  1.1 -1.8 -0.5 -0.1 -0.1  0.1  2.1 -2.4 -0.2 -0.7 -0.   0.1  0.1  5.2 -0.8 -0.6 -0.1  2.  -0.1  6.3 -1.3 -1.4  1.9  0.6 -0.1  0.4  3.2 10.2  0.6 -0.2 -0.5 -0.8 -0.2 -1.1  0.1 -0.3 -0.1 -0.5 -0.4 -0.2 -0.2  0.2 -0.3 -0.2  2.5 -0.3 -0.6 -0.1 -0.6 -0.3 -1.3 -0.4 -0.3 -0.3 -0.  -0.1 -0.3  0.  -1.1 -0.9 -0.3 -0.3  0.1 -0.2 -0.1 -0.1 -0.3  1.7 -1.2  0.2  1.1 -0.5 -1.1  0.1 -0.  -0.8 -0.2 -0.5  4.8 -1.  -0.1 -1.2 -0.3 -0.5 -0.4 -1.  11.8  5.4 -0.3  0.3 -0.4 -0.   0.4 -0.3  0.5 -0.4 -0.5  0.4 -0.3 -0.3 -1.2  0.2 -0.4 -2.1 -0.2 -1.1  1.  -0.3 -0.7 -0.4 -0.4 -0.4 -0.4 -0.2 -0.2 -1.1  2.7 -1.2 -1.2 -1.  -0.8  0.7 -0.6  0.3 -0.4 -0.7  0.8  4.   0.7 -0.4 -0.1  4.4 -0.1  1.9 -0.4 -0.2 -2.1 -1.3 -0.6 -0.3 -0.4  0.9 -2.8  0.1 -0.  -0.  -0.4  7.3]
vy_50sample [[4 0 6 7 9 5 2 8 3 1]
 [0 4 6 2 7 5 9 1 8 3]
 [5 8 9 6 2 0 1 3 4 7]
 [2 6 6 9 1 4 8 5 3 0]
 [3 8 7 5 6 1 4 0 2 9]
 [6 7 2 2 3 1 1 5 9 9]
 [7 6 2 0 5 5 9 3 4 4]
 [1 3 6 6 7 5 2 0 9 4]
 [5 3 4 4 2 0 6 6 8 7]
 [0 8 1 9 6 3 2 4 7 5]]
vt_50sample [[4 0 6 7 9 5 2 3 8 1]
 [0 4 6 2 7 5 9 1 8 3]
 [5 8 9 6 2 0 1 3 4 7]
 [2 7 6 9 1 4 8 5 0 3]
 [3 8 7 6 5 1 4 0 2 9]
 [6 7 2 8 3 4 1 5 9 0]
 [7 6 2 0 5 1 9 3 8 4]
 [1 6 8 3 7 5 2 0 9 4]
 [5 3 4 0 1 2 9 6 8 7]
 [0 8 1 9 6 3 2 4 7 5]]
Epoch 24010: Training cost= 0.3236, Training acc= 0.8265, Validation cost= 0.3826, Validation acc= 0.8267
Epoch 24020: Training cost= 0.3056, Training acc= 0.8265, Validation cost= 0.2807, Validation acc= 0.8267
Epoch 24030: Training cost= 0.2903, Training acc= 0.8265, Validation cost= 0.3269, Validation acc= 0.8267
Epoch 24040: Training cost= 0.2930, Training acc= 0.8266, Validation cost= 0.3476, Validation acc= 0.8267
Epoch 24050: Training cost= 0.2620, Training acc= 0.8266, Validation cost= 0.3044, Validation acc= 0.8268
Epoch 24060: Training cost= 0.3244, Training acc= 0.8266, Validation cost= 0.3230, Validation acc= 0.8268
Epoch 24070: Training cost= 0.2900, Training acc= 0.8266, Validation cost= 0.2947, Validation acc= 0.8268
Epoch 24080: Training cost= 0.2456, Training acc= 0.8267, Validation cost= 0.2916, Validation acc= 0.8268
Epoch 24090: Training cost= 0.3099, Training acc= 0.8267, Validation cost= 0.3043, Validation acc= 0.8269
Epoch 24100: Training cost= 0.2773, Training acc= 0.8267, Validation cost= 0.2695, Validation acc= 0.8269
tm  [ 1.9 -0.2  4.1 -1.7 -1.9 -0.3 -0.4 -0.3 -0.9 -0.5 -1.7  0.2 -0.2 -0.3  9.5 -0.2 -0.4  1.3 -0.1  0.9 -0.7 -0.2  2.   0.9 -1.6  1.3 -0.2 -0.3 -0.6  1.6  0.2 -0.1  0.1  4.9 -0.2  0.8  1.6  2.9  1.8 -0.6  0.6 -0.4  2.4  4.9 -0.1 -0.4 -0.6 -0.3  3.7  5.  -0.8 -0.  -0.6  2.9 -0.4 -1.  -0.7 -1.3 -0.3  0.9 -0.  -0.2 -0.4  0.8 -0.3 -0.3  0.2 -0.2  1.1 -0.2  0.4  1.3  1.   0.4 -3.3  1.4 -0.7  0.  -0.2 -0.3 -2.4  0.6 -0.2  1.4 -1.4 -0.3  5.3 -0.3  0.7 -0.3 -0.5 -0.3 -0.2  1.1 -0.3 -0.3 -0.  -1.5 -0.3 -0.2  1.6  5.9 -1.2  0.4 -0.1 -0.5 -1.6  0.6 -0.6  0.3 -0.3 -0.4 -0.  -0.2  0.1 -0.5 -0.3 -0.4 -0.1 -0.3 -0.2 -0.4 -0.3 -0.6 -0.2 11.3 -0.4 -0.2 -0.4  2.5  1.6 -0.2 -0.2 -0.3 -5.  -3.1  0.4 -0.2 -0.4  0.1  0.4 -1.1  0.5 -0.1 -0.2  0.6  0.1 -0.2 -1.9 -0.4 -0.  -0.1  4.9 -0.2 -0.2 -0.1  0.5 -0.5  2.3 -0.  -0.1 -1.4 -0.1 -0.2 -0.4 -0.8 -0.3 -0.6 -0.2 -0.2 -0.1 -0.2 -0.3 -0.1 -0.3  3.7 -0.6 -0.2  0.1 -0.4 -0.2 -0.5 -0.1 -1.3 -0.8 -0.2  3.6 -0.7 -0.2 -0.5  0.1 -0.4 -0.3 -1.1  3.6  0.5 -0.9 -0.3 -0.  -0.  -0.3 -0.5 -0.3 -0.3 -0.3 -2.1 -0.1 -0.1  4.9 -0.2 -0.6 -0.6 -0.5 -0.8 -0.4 -0.3 -1.2 -0.3 -0.1 -0.1 -0.4 -0.1 -0.2 -0.9 -0.8  0.5 -0.8 -0.5  0.5  1.9 -0.6  1.2 -0.   3.7  0.1 -0.5  1.8 -1.2  1.6  1.5 -0.1  0.5 -0.3 -0.2  8.5 -0.4 -0.1 -0.5 -0.7 -0.   5.8  0.5  1.8 -0.2  1.7 -0.1]
ty_50sample [[7 8 4 0 3 2 9 9 6 1]
 [7 3 9 2 4 0 8 8 5 1]
 [1 2 3 5 4 0 0 8 6 7]
 [5 4 6 8 0 1 9 2 7 3]
 [3 5 7 1 6 4 0 2 8 9]
 [3 1 0 4 7 7 5 9 2 6]
 [4 7 2 3 9 1 5 6 8 0]
 [1 0 4 2 9 5 8 6 7 3]
 [6 3 1 7 4 2 0 9 5 5]
 [3 7 5 4 9 6 0 8 2 1]]
tt_50sample [[7 8 4 0 3 2 5 9 6 1]
 [7 3 9 2 4 0 8 6 5 1]
 [1 2 3 5 4 9 0 8 6 7]
 [5 4 6 8 0 1 9 2 7 3]
 [3 5 7 1 6 4 0 2 8 9]
 [1 3 0 4 8 7 5 9 2 6]
 [4 7 2 3 9 1 5 6 8 0]
 [1 0 4 2 9 5 8 6 7 3]
 [6 3 1 7 4 2 0 9 5 8]
 [3 7 5 4 9 6 0 8 2 1]]
vm  [-1.   0.5 -1.4  3.7 -0.9 -0.1 -0.1 -0.4 -1.4 -0.8 -1.7  0.2 -1.  -0.1 -1.5 -1.9 -0.   0.2 -0.2 -0.8 -0.5 -0.2 -1.   0.3 -1.3  3.2 -0.1 -0.6 -1.5 -1.6  1.5 -0.2 -0.4 -1.2 -0.3  0.7  5.1 -0.7  3.4 -0.4 -0.3 -1.   1.9  0.2 -0.6 -0.2  2.9  0.8 -1.4 -2.2 -0.6 -0.3  0.7 -1.5 -0.1  2.2 -0.7  2.7 -1.2  0.3  4.  -0.3 -0.6 -0.5 -0.2 -0.2 -0.4 -0.2 -0.  -0.4 -0.2  4.7 -0.2 -0.7 -1.7 -0.4  1.2 -0.2 -0.4 -0.3  4.8 -0.2 -0.3 -0.4  0.2 -0.8 -0.6 -0.2  1.3 -0.3 -0.2 -0.1 -0.1  4.  -0.4 -0.1 -0.6 -0.7 -0.2 -0.4  2.7 -2.7  2.1 -0.1 -0.3  0.4 -1.3  1.2 -0.7 -1.3 -0.3 -0.3 -0.3  0.8  0.8 -1.9 -0.5 -0.9 -0.   0.2 -0.   4.1 -0.1  0.5 -0.3 -1.7  0.2  8.  -0.5  5.7 -0.5 -0.  -0.1  1.2  5.4  2.2 -0.  -0.1  1.2 -0.7  2.2 -1.3  0.6 -0.1 -0.3 -0.1 -0.3 -0.   5.2 -0.3 -0.4 -0.1 -0.9  1.5 -0.3 -0.1 -0.3  0.2 -0.1 -0.3 -0.9 -0.8 -0.1 -0.  -0.2 -0.4 -0.2 -0.3 -0.3 -0.  -0.1 -0.  -0.1 -0.2 -0.3 -1.2 -0.7 -0.7 -0.2 -0.4 -1.2 -0.4  0.3 -1.7 -0.1  0.1 -0.8 -0.  -0.1  4.8 -0.3 -0.2 -0.4 -1.5 -0.7  4.8 -0.4  1.5 -0.2 -0.2 -0.1 -0.2 -0.2 -0.5 -0.  -0.6 -0.4 -0.2 -1.5 -0.5  0.2 -1.7 -0.4  5.5 -0.1 -0.2 -0.  -0.5 -0.7 -0.1 -0.6  0.2  1.  -1.  -1.1 -0.8 -2.1 -0.5 -0.  -1.  -1.  -0.  -0.4 -1.   2.2  2.2  0.3 -0.6 -0.1 -0.6 -0.2 -0.2 -0.6  0.3 -0.5 -0.9 -0.3 -0.1 -0.7 -0.4 -1.5 -0.2  2.7 -0.2  7.1 -1. ]
vy_50sample [[3 1 0 5 9 4 4 8 7 2]
 [6 8 8 9 2 4 3 5 5 7]
 [0 9 4 4 3 2 7 8 5 6]
 [8 0 7 4 4 2 1 5 3 9]
 [1 4 8 2 9 7 0 3 6 5]
 [0 6 1 8 3 2 7 9 5 4]
 [4 0 1 5 7 3 2 2 6 8]
 [5 2 9 1 3 4 0 7 6 8]
 [7 6 6 3 8 2 0 9 1 5]
 [1 2 4 5 3 8 6 9 0 7]]
vt_50sample [[3 1 0 5 9 4 6 8 7 2]
 [6 0 8 9 2 4 3 1 5 7]
 [0 9 4 1 2 3 7 8 5 6]
 [8 0 7 4 2 6 1 5 3 9]
 [1 4 8 2 9 7 0 3 6 5]
 [0 6 1 8 3 2 7 9 5 4]
 [4 0 1 5 7 3 9 2 6 8]
 [5 2 9 1 3 4 0 7 6 8]
 [7 4 6 3 8 2 0 9 1 5]
 [1 2 4 5 3 8 6 9 0 7]]
Epoch 24110: Training cost= 0.3099, Training acc= 0.8267, Validation cost= 0.2593, Validation acc= 0.8269
Epoch 24120: Training cost= 0.2580, Training acc= 0.8268, Validation cost= 0.2517, Validation acc= 0.8269
Epoch 24130: Training cost= 0.2979, Training acc= 0.8268, Validation cost= 0.3571, Validation acc= 0.8270
Epoch 24140: Training cost= 0.3653, Training acc= 0.8268, Validation cost= 0.3181, Validation acc= 0.8270
Epoch 24150: Training cost= 0.2622, Training acc= 0.8268, Validation cost= 0.2958, Validation acc= 0.8270
Epoch 24160: Training cost= 0.2895, Training acc= 0.8269, Validation cost= 0.2643, Validation acc= 0.8270
Epoch 24170: Training cost= 0.2608, Training acc= 0.8269, Validation cost= 0.2260, Validation acc= 0.8271
Epoch 24180: Training cost= 0.3293, Training acc= 0.8269, Validation cost= 0.2420, Validation acc= 0.8271
Epoch 24190: Training cost= 0.2682, Training acc= 0.8269, Validation cost= 0.2818, Validation acc= 0.8271
Epoch 24200: Training cost= 0.2770, Training acc= 0.8270, Validation cost= 0.3204, Validation acc= 0.8271
tm  [-1.2 -0.1  6.6  7.4 -1.7 -0.3 -0.2 -0.1 -0.6 -0.9 10.6 -0.3  0.3  0.6  3.3  5.5  0.9 -0.1  1.3 -0.4 -0.8 -0.4 -0.6 -0.4 -1.2  1.3 -0.6 -0.3 -0.8 -1.5  0.2 -0.4 -0.7  8.1 -0.3 -0.   2.9  8.2 12.  -0.5 -0.6 -0.4  0.2  1.7 -0.3 -0.1  0.4 -0.9 -0.6 -1.4 -0.2 -0.2 -0.3  7.7 -1.1 -0.2 -0.6  3.9  0.3  0.8  3.3  0.5 -0.6  0.5 -0.6 -0.3 -0.3 -0.2 -0.3  0.  -0.2  0.5  0.1  0.7 -1.7 -0.6  0.4 -0.6 -0.2  0.1  7.7 -0.3 -0.7 -0.8  0.6 -0.1 -1.   0.1 -0.1 -0.1 -0.4 -0.4 -0.2 -0.1 -0.2 -0.2 -0.3 -1.3 -0.5 -0.6  3.4  3.7  1.5 -0.1 -0.3  1.  -1.   0.5  1.4 -1.7 -0.3 -0.5 -0.  -0.3 -0.4  3.  -0.1 -0.6  0.2 -0.6 -0.1  6.1 -0.1 -0.  -0.   3.8 -0.2 -1.8  1.9  2.  -0.9 -0.2 -0.2 -0.  -5.4 -1.7 -0.2 -0.  -0.1 -0.3 -0.9 -0.2 -0.9 -0.2  0.  -0.2 -0.2 -0.1 -0.6 -0.3 -0.6 -0.1 -1.1 -0.6 -0.1 -0.1  0.1 -0.3  5.  -0.5 -0.  -1.7  0.2 -0.1 -0.4  0.2 -0.2  0.  -0.2 -0.1 -0.3 -0.4 -0.5 -0.2 -0.2  2.   4.3 -0.4 -1.6 -0.3 -1.1 -0.  -0.1 -0.6 -0.2 -0.  -0.6 -0.5 -0.1  5.   0.3 -0.6 -0.2 -0.7 -0.5  0.2 -0.1  0.9 -0.1 -0.4 -0.  -0.2  0.2 -0.3  0.2 -1.  -0.1 -0.1 -1.5 -0.4 -0.8 -0.1 -0.6  4.6  0.1 -0.3 -0.4 -0.8 -0.1 -0.1  0.6 -0.3  0.4 -0.9 -1.3 -0.4  3.2  3.1 -0.3 -0.2 -0.7 -0.6 -0.1 -0.9  1.  -1.4 -0.1 -0.4 -0.3  1.  -0.2  0.5 -0.3 -0.3 -1.2 -0.4 -0.3  0.3 -0.8 -0.5 -2.  -0.1  8.1 -0.1 -0.7 -0. ]
ty_50sample [[2 7 7 3 5 0 0 4 8 6]
 [6 3 8 7 5 2 9 9 1 0]
 [6 2 1 4 0 8 3 9 7 5]
 [4 3 1 5 6 8 7 7 0 0]
 [5 7 2 6 1 0 8 9 3 4]
 [6 0 9 2 1 3 8 7 5 4]
 [7 0 6 2 9 8 1 4 3 5]
 [4 2 7 8 9 1 3 0 6 5]
 [0 1 4 8 5 2 7 3 6 9]
 [9 2 1 7 5 0 4 3 6 8]]
tt_50sample [[2 7 1 3 5 9 0 8 4 6]
 [6 3 8 7 5 2 9 4 1 0]
 [6 2 1 4 0 8 3 9 7 5]
 [4 3 1 5 6 8 7 9 2 0]
 [5 7 2 6 0 1 8 9 3 4]
 [6 0 2 9 1 3 8 7 5 4]
 [7 0 6 2 9 1 8 4 3 5]
 [4 2 7 8 9 1 3 0 6 5]
 [0 1 4 8 5 2 7 3 6 9]
 [9 2 1 7 5 4 0 3 6 8]]
vm  [ 1.9 -0.1 -0.4  4.9 -0.5 -0.2 -0.1 -0.3 -1.  -0.5 -4.1  1.4 -0.9 -0.7 -1.   2.4 -0.1 -0.  -0.1 -0.8 -0.7 -0.  -0.7 -0.2 -0.8 -0.7 -0.  -0.8  3.5  1.2 -1.2 -0.9 -0.1 -3.8 -0.6 -0.4 -0.4 -0.5  0.6 -0.1 -0.  -3.4 -0.  -0.2 -0.3 -0.5  3.3 -0.1  3.8 -0.1 -0.8 -0.2 -0.4 -0.8 -1.8  2.1  0.  -0.9 -0.5  3.1 -1.3 -0.9 -0.2 -0.6 -0.8 -0.5  0.   0.2  0.8 -0.2 -0.4 -1.5 -0.1  0.2 -2.9 -0.1 -1.  -0.2 -0.5 -0.2 -2.4  1.  -0.3 -0.3 -2.  -3.1  4.2 -0.3  0.8 -1.2  0.5 -0.2  0.3  2.9 -0.7  0.1 -0.4 -1.5 -0.4 -1.   2.5 -2.  -1.4 -0.2 -0.2  0.9 -0.7 -1.2 -1.3 -1.3  1.  -0.6 -0.2 -0.4 -1.   8.3 -0.5  0.1  0.2 -0.1  1.1  2.7 -0.4 -0.6  0.6 -1.1 -0.3  6.3 -0.7  7.5  3.4  0.3  0.8 -0.   5.4 -2.  -0.3 -0.  -0.1  2.1 -0.  -0.5  1.4 -0.1 -0.1 -0.3 -0.1 -0.1 -0.4 -0.6 -0.4  0.1  4.4 -0.3 -0.3 -0.3 -0.5 -0.8 -0.7  0.1 -0.2 -0.4  1.2 -0.1 -0.2 -0.1 -0.1 -0.  -0.3 -0.1 -0.7 -0.8 -0.  -0.1 -0.2  2.3 -1.2  0.5  1.1 -0.2  1.  -0.2  0.5 -1.2 -1.3  1.8  5.3 -0.1 -0.  -0.6 -0.3  0.4 -0.6 -1.4  9.6  1.3  0.8  1.  -0.1 -0.5  0.5  0.2  0.4 -0.3 -0.9  1.2 -0.3 -0.5  9.3 -0.4 -0.3  4.8 -1.2 -0.7  0.1  0.1  1.8 -0.1 -0.2 -0.  -1.1 -0.4 -0.6 -0.5 -1.   3.  -1.8 -0.8 -0.1  2.4 -0.3  0.4 -0.1  4.9 -2.1  0.9 -0.1 -0.6 -0.2 11.  -0.1  5.2 -0.5  0.2  7.6 -2.4  0.9 -0.6 -0.5 -0.4  5.9 -0.2  0.3  1.1  5.9 -1.5]
vy_50sample [[3 8 6 9 4 7 2 5 0 1]
 [3 8 8 4 2 6 7 0 1 9]
 [6 8 1 7 0 5 9 4 3 2]
 [8 5 6 1 4 7 9 2 3 0]
 [4 6 2 0 5 7 3 8 1 9]
 [5 2 0 6 3 1 7 8 4 9]
 [3 1 9 4 5 0 8 7 2 6]
 [6 2 7 7 4 8 3 5 1 1]
 [6 7 1 2 3 8 5 4 9 0]
 [2 6 4 9 8 0 1 5 7 3]]
vt_50sample [[3 8 6 9 4 7 2 5 0 1]
 [3 8 5 4 2 6 7 0 1 9]
 [6 8 1 7 0 5 9 4 3 2]
 [8 5 6 1 4 9 7 2 3 0]
 [4 6 2 0 5 7 3 8 1 9]
 [5 2 0 3 6 1 7 8 4 9]
 [3 1 9 4 5 0 8 7 2 6]
 [6 9 2 7 4 8 3 5 1 0]
 [6 7 1 2 3 8 5 4 9 0]
 [2 6 4 9 8 0 1 5 7 3]]
Epoch 24210: Training cost= 0.3319, Training acc= 0.8270, Validation cost= 0.2563, Validation acc= 0.8271
Epoch 24220: Training cost= 0.3834, Training acc= 0.8270, Validation cost= 0.2881, Validation acc= 0.8272
Epoch 24230: Training cost= 0.3491, Training acc= 0.8270, Validation cost= 0.2624, Validation acc= 0.8272
Epoch 24240: Training cost= 0.3102, Training acc= 0.8270, Validation cost= 0.2980, Validation acc= 0.8272
Epoch 24250: Training cost= 0.3062, Training acc= 0.8271, Validation cost= 0.3161, Validation acc= 0.8272
Epoch 24260: Training cost= 0.2840, Training acc= 0.8271, Validation cost= 0.2820, Validation acc= 0.8273
Epoch 24270: Training cost= 0.2767, Training acc= 0.8271, Validation cost= 0.3081, Validation acc= 0.8273
Epoch 24280: Training cost= 0.2718, Training acc= 0.8271, Validation cost= 0.2774, Validation acc= 0.8273
Epoch 24290: Training cost= 0.2899, Training acc= 0.8272, Validation cost= 0.2820, Validation acc= 0.8273
Epoch 24300: Training cost= 0.2682, Training acc= 0.8272, Validation cost= 0.3037, Validation acc= 0.8274
tm  [-1.3 -0.5 -0.5 -0.8 -0.8  0.8 -0.3 -0.2 -0.2 -0.4  4.4 -0.4  0.4 -0.   2.9  6.3 -0.  -0.3 -0.4  0.1 -0.9 -0.3  1.4 -0.4 -1.   0.2 -0.2 -0.3 -0.1 -1.6 -0.7 -0.2 -0.3 -2.2 -0.4 -0.1  1.2  6.2  3.8 -0.5 -0.2 -2.5 -0.7  3.2 -0.4 -0.  -1.  -0.8 -0.5  3.9 -0.5 -0.1 -0.7  8.9 -1.2 -0.2 -0.3 -1.7  5.3  3.1  5.6  0.2 -0.5  1.3 -0.9  0.5 -0.   0.2 -0.2  0.3 -0.3 -0.7 -0.1  0.4 -3.7 -0.1 -0.2 -0.1 -0.2 -0.1 -3.2 -0.1 -0.2 -0.   0.  -2.4 -0.6  0.3  0.  -0.2 -0.3 -0.3  0.1 -0.7 -0.4 -0.2 -0.4 -2.1 -0.1 -0.4  1.3 -0.6  0.8  0.  -0.3 -0.1 -1.9 -0.6  1.3 -0.7 -0.2 -0.2 -0.2 -0.7  2.   4.9 -0.4 -0.1 -0.  -0.4 -0.3  1.6 -0.  -0.1 -0.2  3.1 -0.2 -2.2  3.7  4.6 -0.4 -1.  -0.4 -0.4 -1.3 -4.1 -0.2 -0.3  0.8 -0.2 -0.9 -0.5 -1.3 -0.3 -0.  -0.1 -0.1 -0.1 -1.1 -0.1  0.6 -0.3  1.2 -0.4 -0.2 -0.2 -0.5 -0.3  3.2 -0.3 -0.4 -1.3 -0.  -0.1 -0.4  0.5  0.6  2.7  0.3 -0.1 -0.1 -0.2 -0.1 -0.1 -0.2  2.2  1.9 -0.6 -0.2 -0.5  3.1 -0.2 -0.5 -0.8 -0.3 -0.3 -0.6 -0.4 -0.6  5.   0.2 -0.4 -0.5 -0.6 -1.3 -1.1 -0.9 -0.3 -0.3 -0.2 -0.  -0.1 -0.3 -0.7 -0.  -2.4 -0.4  0.7  9.3  0.8 -0.5  3.1 -0.8  3.5 -0.4 -0.5 -0.9 -0.5 -0.5 -0.3 -0.4 -0.1 -0.2 -1.1 -1.2  2.7  1.8  2.7 -0.1  1.6 -0.5 -0.1 -0.4  5.3 -0.2  1.8  0.3 -1.   1.3  7.9 -0.1  4.1 -0.2 -0.4 10.8  1.  -0.4 -0.1 -0.9 -0.3  7.5 -0.1  2.7 -0.1 -0.5 -0.7]
ty_50sample [[2 8 1 3 4 7 9 0 6 5]
 [1 4 0 0 8 5 3 2 6 9]
 [4 6 2 2 0 3 9 5 1 7]
 [9 7 6 2 3 4 5 1 8 0]
 [9 5 7 6 3 2 8 0 4 1]
 [3 4 7 9 5 2 1 0 6 8]
 [7 1 8 2 3 5 9 4 0 6]
 [6 8 1 9 2 3 7 4 0 5]
 [1 2 8 9 6 6 7 0 5 4]
 [6 8 5 7 9 0 1 4 2 3]]
tt_50sample [[2 8 1 3 4 7 0 9 6 5]
 [1 4 7 0 8 5 3 2 6 9]
 [4 6 8 2 0 3 9 5 1 7]
 [9 7 6 2 3 5 4 1 8 0]
 [9 5 7 6 3 2 8 0 4 1]
 [3 4 7 9 5 2 1 6 0 8]
 [7 1 8 2 3 5 9 4 0 6]
 [6 8 1 9 2 3 7 4 0 5]
 [1 2 8 9 6 0 3 7 5 4]
 [6 8 5 7 9 0 1 4 2 3]]
vm  [ 1.7 -0.6 -2.  -0.8 -0.6 -0.  -0.4 -0.2 -0.2 -0.2  3.1 -0.3 -0.4 -0.3 -0.7 -0.1 -0.  -0.4 -0.2 -0.1 -1.  -0.  -0.5 -0.1 -0.9  1.4 -0.1 -0.3 -1.2 -2.7 -0.3 -0.3 -0.5 -3.7  0.3 -0.1  1.7  3.4  1.3 -0.8 -0.2 -1.8 -0.4  2.4 -0.5 -0.1 -0.8 -0.7  4.4 -1.1 -0.7 -0.1 -0.4  6.7 -0.   1.6 -0.7 -0.2  4.1  2.6 -0.4 -0.2 -0.4  2.2 -0.7  0.6  0.3  0.5 -0.  -0.1 -0.2  3.  -0.3 -0.2 -4.   0.8 -1.2 -0.4 -0.3 -0.3 -2.3  0.2 -0.2  0.  -1.4 -1.9  3.8 -0.2  0.4 -0.5 -0.4 -0.6  0.3 -0.  -0.4  0.1 -0.2 -2.1 -0.1 -0.2  0.2 -3.1 -1.2 -0.1 -0.1  0.2 -1.9 -0.3  0.9 -0.5 -0.1 -0.3 -0.1 -0.4  3.7 -1.6 -0.4  1.4 -0.1 -0.1 -0.1  1.2 -0.2 -0.6 -0.4 -0.9 -0.6 -1.5  4.   9.2  2.  -0.6  0.2 -0.3  5.4 -2.3 -0.2 -0.1  0.8 -0.2 -0.7 -1.2 -0.7 -0.3 -0.1 -0.2 -0.2 -0.2  4.4 -0.3  0.3 -0.3  4.4 -0.4 -0.2 -0.2 -0.3 -0.3  0.8 -0.1 -0.4 -1.3 -0.  -0.1 -0.1 -0.4 -0.3 -0.1 -0.1 -0.1 -0.3 -0.1 -0.3 -0.2 -0.2 -0.8 -0.1 -0.8  0.8 -0.3 -0.8 -0.2 -0.6 -1.1  0.7 -0.2  4.   1.4 -0.5  8.3 -0.   0.1 -0.4 -0.8  5.  -1.1 -1.2 -0.6 -0.1 -0.1 -0.   0.2 -0.2 -0.3 -0.5 -2.5 -0.3 -0.1  4.3  0.1 -0.5 -1.  -0.7 -1.4 -0.3 -0.  -0.5 -0.8 -0.6 -0.3 -0.3 -0.3 -0.1 -0.9 -1.5 -0.5  0.3 -0.2 -0.2  5.3 -0.8  0.5 -0.2  2.5  1.9  4.2  2.3 -1.5  1.5 -0.2 -0.1  0.  -0.3 -0.1  8.5  1.4  0.2 -0.4 -1.  -0.3  5.4 -0.2  1.2 -0.3  2.  -2.2]
vy_50sample [[3 0 2 8 4 5 6 6 7 7]
 [4 6 8 3 1 5 0 9 2 7]
 [7 1 5 9 6 2 8 0 4 3]
 [5 6 0 2 8 3 1 7 9 4]
 [0 2 1 1 3 8 5 9 6 6]
 [6 9 4 1 7 0 8 5 3 2]
 [7 4 8 3 2 6 5 1 9 0]
 [6 5 3 7 9 2 1 4 0 8]
 [7 9 6 2 5 4 3 8 1 0]
 [4 6 8 9 1 3 0 7 5 2]]
vt_50sample [[3 0 2 8 4 5 6 9 7 1]
 [4 6 8 3 1 5 0 9 2 7]
 [7 1 5 6 9 2 8 0 4 3]
 [5 6 0 2 3 8 1 7 9 4]
 [0 2 4 1 3 8 5 9 6 7]
 [6 9 4 1 7 0 5 8 3 2]
 [7 4 8 3 2 6 5 1 9 0]
 [6 5 3 7 9 2 1 0 4 8]
 [7 9 6 2 5 4 3 8 1 0]
 [4 6 8 9 1 3 0 7 5 2]]
Epoch 24310: Training cost= 0.2523, Training acc= 0.8272, Validation cost= 0.2850, Validation acc= 0.8274
Epoch 24320: Training cost= 0.2583, Training acc= 0.8272, Validation cost= 0.3198, Validation acc= 0.8274
Epoch 24330: Training cost= 0.3122, Training acc= 0.8273, Validation cost= 0.3218, Validation acc= 0.8274
Epoch 24340: Training cost= 0.2993, Training acc= 0.8273, Validation cost= 0.2650, Validation acc= 0.8275
Epoch 24350: Training cost= 0.3009, Training acc= 0.8273, Validation cost= 0.2675, Validation acc= 0.8275
Epoch 24360: Training cost= 0.3115, Training acc= 0.8273, Validation cost= 0.3180, Validation acc= 0.8275
Epoch 24370: Training cost= 0.3270, Training acc= 0.8274, Validation cost= 0.2902, Validation acc= 0.8275
Epoch 24380: Training cost= 0.2401, Training acc= 0.8274, Validation cost= 0.2806, Validation acc= 0.8275
Epoch 24390: Training cost= 0.2935, Training acc= 0.8274, Validation cost= 0.3408, Validation acc= 0.8276
Epoch 24400: Training cost= 0.2458, Training acc= 0.8274, Validation cost= 0.3569, Validation acc= 0.8276
tm  [-1.3 -0.3  8.4  0.1 -1.3 -0.2 -0.2 -0.2 -0.5 -0.   7.4 -0.4 -0.  -0.2 11.9  4.8 -0.3 -0.1 -0.3  0.3 -0.4 -0.4  2.6 -0.2 -0.9  1.6 -0.4 -0.4 -0.4  1.2 -0.5  0.3 -0.1  7.6 -0.3 -0.2  2.3  2.6 -2.1 -0.3 -0.4  1.3 -0.2 -0.7 -0.2  0.1 -2.  -1.1 -0.6  9.  -0.1 -0.1 -0.4 12.3 -1.2 -1.4 -0.7 -0.5  1.6  2.7  6.   0.2 -0.5  0.4 -0.8 -0.3 -0.2 -0.2 -0.2 -0.1 -0.1 -0.3 -0.2  0.5 -5.1 -0.7 -0.1 -0.2  0.  -0.2 -2.1 -0.1  0.2 -0.7 -0.3  1.8 -0.8 -0.  -0.3 -0.5 -0.5 -0.4 -0.  -0.5 -0.3  0.1 -0.1 -2.1 -0.3 -0.2 -0.4  9.6  2.   0.1 -0.2  1.  -2.  -0.5  1.3 -0.9 -0.4 -0.3  0.3 -0.5  0.6  2.  -0.4 -0.3 -0.1 -0.6  0.5  0.5 -0.7 -0.1 -0.5 14.3 -0.4 -3.5 -0.3 -0.3 -0.1 -0.3 -0.5  0.4 -2.1  3.8 -0.3 -0.1 -0.4 -0.5 -0.8 -0.5 -1.2 -0.4 -0.1 -0.1 -0.3 -0.1 -2.6  0.6 -0.1 -0.  -0.1 -0.4 -0.2 -0.  -0.5  0.3 -0.3 -0.5 -0.1  0.3 -0.  -0.  -0.2  0.  -0.4  0.8 -0.1 -0.3 -0.  -0.4 -0.4 -0.1 -0.1  4.3 -0.5 -0.9  5.2 -0.8  0.3 -0.  -0.1 -0.9 -0.6 -0.3 -0.7 -0.5 -0.5 -0.2 -0.1 -0.4  0.5 -0.8 -1.8  0.7 -1.   0.3 -0.1 -0.2  0.2 -0.3 -0.1 -0.1 -0.1 -2.7 -0.3 -0.4  5.6 -0.3  0.7 -0.  -0.5  3.1 -0.4 -0.2  3.5 -0.8 -0.2 -0.1 -0.1  0.4 -0.3 -1.   4.1  0.5  2.7  1.7 -0.1 -0.3 -0.3  0.2 -0.2  3.1 -0.1 -1.8 -0.1 -1.8 -0.1  1.5 -0.2  1.  -0.  -0.1  7.9  3.5 -0.8  1.2 -0.6 -0.4  5.4 -0.1 -1.5 -0.4 -2.1  4. ]
ty_50sample [[2 7 1 6 8 0 4 9 5 3]
 [3 4 2 5 7 6 8 0 1 9]
 [7 0 2 6 9 1 8 4 3 5]
 [7 2 6 6 3 0 1 4 9 5]
 [5 7 8 6 4 2 9 1 3 0]
 [0 7 5 2 1 3 3 4 9 6]
 [2 6 7 4 0 9 1 5 3 8]
 [3 6 1 4 0 0 7 5 9 2]
 [0 7 3 1 2 9 8 6 4 5]
 [9 5 7 0 6 1 2 3 8 8]]
tt_50sample [[2 7 1 6 8 0 4 9 5 3]
 [3 4 2 5 7 6 8 0 1 9]
 [7 0 2 6 9 1 8 4 3 5]
 [2 7 8 6 3 0 1 4 9 5]
 [5 7 8 6 4 2 9 1 3 0]
 [0 7 2 5 1 3 8 4 9 6]
 [2 6 7 4 0 9 1 5 3 8]
 [3 6 1 4 8 0 7 5 9 2]
 [0 7 3 1 9 2 8 6 4 5]
 [9 5 7 0 1 6 2 3 8 4]]
vm  [-0.8 -0.4 -0.2  8.5 -1.  -0.  -0.1 -0.  -0.4 -0.4  4.3 -0.5 -0.3 -0.4 -1.8  0.1 -0.1 -0.3  0.2 -1.4 -1.  -0.   1.8 -0.1 -1.1  2.9 -0.2 -0.3 -0.5 -0.6  2.3  0.1  1.4  0.5 -0.2 -0.1  2.7 -0.5 -0.1 -0.1 -0.1  7.5  1.6 -0.7 -0.5 -0.3  5.3 -0.3 -0.1  5.3 -0.5 -0.2  0.5 -0.7 -0.2  3.3 -0.4  6.1 -0.3 -0.  -0.1 -0.3 -0.1  0.6 -0.1 -0.7 -0.3 -0.  -0.2 -0.3 -0.2  0.4 -0.2  0.1 -0.6 -0.1 -0.1 -0.3 -0.3 -0.1 11.9 -0.1  0.  -0.6 -0.   8.5 -0.4 -0.1 -0.4 -0.2 -0.2 -0.3 -0.2 -0.4 -0.1 -0.6 -0.3 -1.  -0.3 -0.4  1.5  3.5 -0.1 -0.1 -0.3 -0.2 -0.3  1.6  1.5 -2.  -0.6 -0.2 -0.2 -0.6  1.2  0.6 -0.2 -1.  -0.2  0.2 -0.4  5.8 -0.2  0.5 -0.3 -2.1  0.3  5.5  1.7 -2.4 -0.3 -0.4 -0.3 -0.6  9.7 11.5  0.2 -0.  -0.  -0.7 -0.1 -0.3 -0.3 -0.1 -0.1 -0.1  0.  -0.1  6.2 -0.1 -0.4 -0.2 -0.6 -0.  -0.4 -0.3 -0.3  0.1 -0.7 -0.3 -0.3  1.  -0.1 -0.1 -0.4 -0.3  0.  -0.2 -0.1 -0.2  0.   0.3 -0.3 -0.1 -0.1 -1.4 -1.4 -0.   1.3 -0.1 -1.7  0.5 -0.3 -1.  -0.1 -0.1 -0.  -0.3 -0.2  2.4  0.4 -0.1 -0.7 -0.9  3.2  0.   0.7 -0.1 -0.1  0.4 -0.2 -0.1 -0.2 -0.4 -0.3  0.6 -0.1  0.  -3.8  0.4  0.7  0.1 -0.5  3.  -0.3 -0.4  3.5 -0.7 -0.2 -0.3 -0.4 -0.1  0.2 -0.5  4.8 -0.6 -0.9  0.2  0.7 -0.   0.7 -0.8 -0.2 -2.3  1.   0.7  0.3  1.7  1.4 -0.6 -0.1 -0.3 -0.3 -0.1 -2.3 -2.  -0.2 -0.2 -1.1 -0.1 -3.3 -0.2  0.  -0.  -0.3 12.1]
vy_50sample [[5 6 9 1 0 2 4 7 8 3]
 [7 3 5 2 9 8 1 6 0 4]
 [7 0 5 1 9 2 4 3 6 8]
 [4 2 6 8 1 9 5 3 0 7]
 [1 5 0 8 6 9 2 7 3 4]
 [6 0 4 3 9 7 8 5 1 2]
 [9 8 6 1 0 5 7 2 3 4]
 [8 5 4 9 7 2 6 3 0 1]
 [5 8 6 2 4 7 1 9 3 0]
 [0 9 5 4 1 7 8 2 3 6]]
vt_50sample [[5 6 9 1 0 2 4 8 7 3]
 [7 3 2 5 9 1 8 6 0 4]
 [7 0 5 1 9 2 4 3 6 8]
 [4 2 6 1 8 9 5 3 7 0]
 [1 5 0 8 6 9 2 7 3 4]
 [6 0 4 3 9 7 8 5 1 2]
 [9 8 6 1 0 5 7 2 3 4]
 [8 5 4 9 7 2 6 3 0 1]
 [5 8 6 2 4 7 1 9 3 0]
 [0 9 4 5 1 7 8 2 3 6]]
Epoch 24410: Training cost= 0.3047, Training acc= 0.8274, Validation cost= 0.3322, Validation acc= 0.8276
Epoch 24420: Training cost= 0.2771, Training acc= 0.8275, Validation cost= 0.2801, Validation acc= 0.8276
Epoch 24430: Training cost= 0.2991, Training acc= 0.8275, Validation cost= 0.2838, Validation acc= 0.8277
Epoch 24440: Training cost= 0.2888, Training acc= 0.8275, Validation cost= 0.3124, Validation acc= 0.8277
Epoch 24450: Training cost= 0.2690, Training acc= 0.8275, Validation cost= 0.2345, Validation acc= 0.8277
Epoch 24460: Training cost= 0.3388, Training acc= 0.8276, Validation cost= 0.2776, Validation acc= 0.8277
Epoch 24470: Training cost= 0.3981, Training acc= 0.8276, Validation cost= 0.3111, Validation acc= 0.8277
Epoch 24480: Training cost= 0.3727, Training acc= 0.8276, Validation cost= 0.3138, Validation acc= 0.8278
Epoch 24490: Training cost= 0.3273, Training acc= 0.8276, Validation cost= 0.3169, Validation acc= 0.8278
Epoch 24500: Training cost= 0.2711, Training acc= 0.8276, Validation cost= 0.2948, Validation acc= 0.8278
tm  [-1.6 -0.8 -1.2 -0.  -0.9  0.6 -0.2 -0.2 -0.1 -0.5  3.8 -0.4 -0.1  0.  -0.6  1.  -0.4 -0.2 -0.1  0.2 -1.2 -0.3  1.1 -0.3 -1.3  3.5 -0.3 -0.2 -1.2 -2.7 -0.3 -0.3 -0.5 -2.7 -0.2  0.8  2.9  3.3  0.7 -0.5  0.  -1.7 -0.6  1.7 -0.4 -0.  -0.7 -0.5 -1.4  2.2 -0.6 -0.2 -0.4  5.5 -0.4  1.8 -0.7 -1.   4.6  2.7  7.3  0.2 -0.1  1.9 -0.2  0.5 -0.1  0.3 -0.1  0.3  0.3  2.5  0.2  0.2 -2.6 -0.3  0.5 -0.4  0.8 -0.1 -1.4  0.2 -0.3  0.6  2.2 -1.6 -1.2 -0.2  0.2 -0.3 -0.3 -0.4 -0.1 -0.8 -0.2 -0.1 -0.2 -2.1 -0.1  0.4  1.3 -1.4  1.2  0.1 -0.1 -0.  -1.5 -0.2  1.4 -0.4 -0.8 -0.3 -0.  -0.3  4.6 -1.  -0.4 -0.3 -0.3 -0.1 -0.   1.5  0.1 -0.1 -0.5 -0.8 -0.2 -1.   3.1  4.  -0.9 -0.7 -0.4 -0.5  5.2 -1.4 -0.3 -0.1  1.1 -0.3 -0.4 -1.1 -1.  -0.2 -0.2 -0.3 -0.2  0.1  0.3 -0.4  0.5 -0.2 -0.5 -0.3  0.3 -0.1 -0.1 -0.2  1.6 -0.3  0.1 -0.6 -0.3 -0.2 -0.4 -0.5 -0.1  2.5 -0.  -0.1 -0.1 -0.2 -0.2 -0.2 -0.3  0.5 -0.2 -0.3  1.1 -0.4  1.1 -0.1 -0.5 -1.2  0.  -0.2 -1.1  0.5 -0.2  8.3 -0.1 -0.4 -0.3 -0.7 -1.9 -0.4 -0.6 -0.6 -0.2  0.  -0.1 -0.1 -0.4 -0.8 -0.1 -2.2 -0.2  0.7  7.3 -0.1 -0.3 -0.6 -0.8  6.9 -0.7 -0.3  0.  -0.7 -0.6 -0.1 -0.3 -0.1 -0.2 -1.1 -0.3 -0.3  0.7  2.7 -0.2 -0.1 -0.4 -0.4 -0.2  4.1  3.6  2.8  1.7 -0.6  2.2  6.2 -0.1  3.2 -0.3  0.4  6.4  0.7 -0.2  0.3 -1.2 -0.2  2.6 -0.1  0.7  0.  -0.1 -0.5]
ty_50sample [[1 0 2 8 3 4 6 9 7 5]
 [4 5 1 1 2 8 0 9 6 3]
 [9 0 7 2 1 8 4 5 3 6]
 [5 8 4 6 0 3 9 2 1 7]
 [0 8 2 6 1 1 7 3 5 4]
 [3 6 2 4 7 1 0 8 5 9]
 [7 0 6 9 3 2 4 1 5 8]
 [6 2 4 9 8 1 1 0 3 7]
 [4 0 3 5 9 8 6 2 1 7]
 [8 1 3 4 5 0 6 7 2 9]]
tt_50sample [[1 0 2 8 3 4 6 9 7 5]
 [4 5 7 1 2 8 0 9 6 3]
 [9 0 7 2 1 8 4 5 3 6]
 [5 8 6 4 0 3 9 2 1 7]
 [0 8 2 6 9 1 7 3 5 4]
 [3 6 2 4 7 1 0 8 5 9]
 [7 0 6 9 3 2 4 1 5 8]
 [6 2 4 9 8 5 1 0 7 3]
 [4 0 3 5 9 8 6 2 1 7]
 [8 1 3 5 4 0 6 7 2 9]]
vm  [-1.5 -0.6 -0.7 -1.3 -1.6  0.4 -0.1 -0.   0.5 -0.9 -0.8  0.4 -0.4 -0.1  3.4  2.  -0.4 -0.6 -0.8 -0.5 -0.7 -0.1 -0.4 -0.4 -1.4  1.5 -0.2 -0.4  3.  -0.8  3.8 -0.2  0.   5.  -0.7 -0.1  0.3 -0.7 -0.4 -0.4  1.1 -1.4 -0.5  3.2  0.2  0.1 -0.4  0.4 -1.1 -1.2 -0.7 -0.1 -0.4 -0.6 -1.5 -0.  -0.7 -1.5  3.7 -1.2  6.4 -0.4 -0.3  0.3  0.8  0.2 -0.1  0.3  0.5 -0.1 -0.1 -1.5 -0.5  0.4 -2.5 -0.1 -0.2 -0.3  0.5 -0.1  2.   0.2 -0.2  0.3  1.2 -0.8 -0.1 -0.  -0.1 -0.7 -0.2  0.5 -0.3 -1.5 -0.4  0.  -0.3 -2.  -0.   0.3  3.1 -0.1  1.5  0.4  0.   0.1 -1.4  3.6 -0.3 -0.6 -0.8 -0.4 -0.1 -1.2  1.  10.7 -0.2  0.4 -0.2 -0.6  0.2  3.5 -0.  -0.3 -0.   4.2  0.8  5.   3.7  4.9 -0.5 -0.8 -0.3 -0.6 -0.4  4.7 -0.2 -0.2 -0.3 -0.4  1.9  0.4  1.1 -0.1 -0.2 -0.2 -0.2 -0.  -0.7 -0.1  1.9 -0.2 -1.1 -0.1  0.2  0.2 -0.1 -0.4  0.1 -0.5 -0.1 -0.2  0.2 -0.  -0.2 -0.1 -0.2  3.3 -0.2 -0.4 -0.6 -0.3 -0.1 -0.1 -0.1  2.1 -0.7 -0.2  2.2 -0.2 -0.4 -0.1 -0.5 -1.7 -0.5 -0.3 -0.9 -0.7 -0.2  2.4 -0.3 -0.1 -0.7 -0.9 -1.6 -0.9 -0.4 -0.3 -0.3 -0.4 -0.  -0.1 -0.3 -0.8  0.4 -2.2 -0.1 -0.2  2.3 -0.1 -0.2  6.4 -1.   5.7 -0.8 -0.2 -0.6 -0.7 -0.2 -0.1 -0.8  0.2 -0.4 -0.9 -0.3  3.3 -1.4 -0.1  0.3  1.3 -0.6 -0.2 -0.1  1.9 -0.5  2.4  0.2 -0.8  3.3  4.  -0.2  1.8 -0.1 -0.2  0.5  0.8 -0.5  0.3 -1.4 -0.4 -0.7 -0.2 -0.2 -0.3  4.3 -0.7]
vy_50sample [[1 4 3 7 6 9 8 5 2 0]
 [2 1 7 5 8 3 6 0 4 9]
 [1 5 6 3 0 9 2 4 7 8]
 [9 1 7 0 4 5 3 6 8 2]
 [3 6 7 4 9 0 8 5 2 1]
 [7 2 3 0 4 5 8 8 9 6]
 [0 9 1 7 2 2 3 3 8 4]
 [4 0 2 6 5 1 3 7 9 8]
 [2 1 9 4 5 0 0 8 6 7]
 [6 7 2 0 3 8 5 9 4 4]]
vt_50sample [[1 4 3 7 6 9 8 5 2 0]
 [2 1 7 5 8 3 6 0 4 9]
 [1 5 6 3 0 9 2 4 7 8]
 [9 1 7 0 4 5 3 6 8 2]
 [3 6 7 4 0 9 8 5 2 1]
 [7 2 3 4 0 5 1 8 6 9]
 [0 9 7 1 2 6 5 3 8 4]
 [4 0 2 6 5 1 3 9 7 8]
 [2 1 9 4 5 3 0 8 6 7]
 [6 7 2 0 3 8 5 9 1 4]]
Epoch 24510: Training cost= 0.3016, Training acc= 0.8277, Validation cost= 0.2876, Validation acc= 0.8278
Epoch 24520: Training cost= 0.2654, Training acc= 0.8277, Validation cost= 0.2670, Validation acc= 0.8279
Epoch 24530: Training cost= 0.2623, Training acc= 0.8277, Validation cost= 0.2277, Validation acc= 0.8279
Epoch 24540: Training cost= 0.2622, Training acc= 0.8277, Validation cost= 0.2478, Validation acc= 0.8279
Epoch 24550: Training cost= 0.2620, Training acc= 0.8278, Validation cost= 0.3538, Validation acc= 0.8279
Epoch 24560: Training cost= 0.2845, Training acc= 0.8278, Validation cost= 0.2639, Validation acc= 0.8280
Epoch 24570: Training cost= 0.2977, Training acc= 0.8278, Validation cost= 0.2811, Validation acc= 0.8280
Epoch 24580: Training cost= 0.2553, Training acc= 0.8278, Validation cost= 0.2662, Validation acc= 0.8280
Epoch 24590: Training cost= 0.3829, Training acc= 0.8279, Validation cost= 0.2416, Validation acc= 0.8280
Epoch 24600: Training cost= 0.2779, Training acc= 0.8279, Validation cost= 0.2834, Validation acc= 0.8280
tm  [-0.1 -0.1 -0.9 10.  -0.9 -0.3  0.3 -0.3 -1.  -0.2 -3.  -0.  -0.6 -0.4 -2.8 -1.9 -0.2 -0.3  0.1 -1.6 -0.9 -0.2 -0.  -0.1 -0.6  2.2 -0.4 -0.2 -1.3 -0.2 -0.3  0.   0.9 -2.2 -0.1 -0.2  4.  -1.7  1.6 -0.6 -0.  -2.3 -0.1 -0.8 -0.1 -0.4  9.4  0.6  1.2  0.6 -0.6 -0.1  1.1 -2.9  1.   4.3 -0.6 -1.9 -0.8  2.  -1.7 -0.2 -0.4 -0.2 -0.8 -0.1  0.  -0.3  1.1  1.5 -0.   4.2 -0.2 -0.4  3.5 -0.2 -0.3 -0.2 -0.3 -0.1  8.   0.1 -0.5 -0.4 -0.9 -2.8  2.4 -0.3 -0.2 -0.4 -0.3 -0.3  0.1  3.1 -0.1 -0.2 -0.1  0.6 -0.7 -0.3 -0.  -1.1 -0.4 -0.2  0.  -0.1  1.6 -0.3 -1.  -2.5 -0.8  0.2  0.   0.5  2.4 -2.3  0.  -0.3 -0.1  0.  -0.2  8.5 -0.5 -0.1 -0.1 -3.2 -0.  13.  -1.4 -0.6  1.  -0.1 -0.1 -0.4 10.9  7.1 -0.3 -0.1 -0.2 -0.3  1.9 -1.2  1.2  0.   0.1 -0.2 -0.3 -0.2 -0.8 -0.6 -0.8 -0.   2.5 -0.  -0.3 -0.1 -0.2 -0.1 -1.4 -0.8 -0.3  2.  -0.  -0.2 -0.2 -0.4 -0.6 -0.1 -0.3 -0.1 -0.4 -0.7  0.7 -0.2  0.2  3.4 -1.1  1.9  0.5 -0.2  2.6  1.   0.5 -0.7 -0.3  1.   2.6 -0.1  0.6  0.2 -0.2 -0.1 -0.6 -0.8 10.5  5.   2.  -0.3  0.9 -0.1 -0.   0.1  1.2 -0.  -0.4  5.6 -0.6 -0.2  9.1 -0.1 -0.6 -1.5 -0.7 -0.  -0.  -0.4  3.6 -0.4 -0.2 -0.  -0.4 -0.4 -0.2 -0.6  1.5 -1.  -1.9 -0.4 -0.  -0.   1.3 -0.6 -0.1  4.3  2.4  2.2  1.7  3.3  0.7 22.8 -0.2 10.   0.1 -0.1 -1.3 -2.8 -0.  -0.6 -0.8 -0.1 -2.1 -0.3  0.8 -0.1  5.   4. ]
ty_50sample [[9 6 6 3 8 4 1 7 2 5]
 [8 0 9 1 3 7 6 4 5 2]
 [7 2 5 1 8 9 0 6 4 3]
 [4 1 3 0 9 6 8 5 2 7]
 [4 9 3 5 7 2 1 0 6 8]
 [6 8 7 3 0 2 9 1 5 4]
 [7 7 1 1 5 4 6 8 0 2]
 [9 7 6 8 8 4 2 5 0 1]
 [1 0 8 2 4 6 9 7 5 3]
 [3 5 2 0 4 9 1 6 8 7]]
tt_50sample [[0 9 6 3 8 4 1 7 2 5]
 [8 0 1 9 3 7 6 4 5 2]
 [7 2 5 1 8 9 0 6 4 3]
 [4 1 3 0 9 6 8 5 2 7]
 [4 9 3 5 7 2 1 6 0 8]
 [6 8 7 3 0 2 9 1 5 4]
 [7 9 3 1 5 4 6 8 0 2]
 [9 7 6 8 3 4 2 5 0 1]
 [1 0 8 2 4 6 9 7 5 3]
 [3 5 2 0 4 9 1 6 7 8]]
vm  [ 0.4 -0.3  2.5 -3.  -1.6 -0.  -0.5 -0.3 -0.5  0.4 -4.7 -0.9 -0.4 -0.1 10.3 -0.5 -0.3 -0.2 -0.4 -0.5 -0.5 -0.4  2.3 -0.2 -0.9 -1.  -0.6  0.7 -0.1  1.7 -0.2 -0.4 -0.3 -0.4  0.3 -0.8 -0.  -0.4 -0.2 -0.7 -1.   5.8 -0.1  2.4 -0.8 -0.3 -0.7 -0.3  2.5 11.8 -0.7 -0.1 -1.2  0.6 -0.8 -1.  -0.2  2.2  1.   2.1 -0.1 -0.1 -0.9  0.  -0.4 -0.2 -0.3 -0.2  0.4 -0.6 -0.4 -0.7 -0.3 -0.6 -4.5  0.2 -1.2 -0.2 -0.2 -0.1 -5.  -0.5 -0.5  1.  -1.4  7.8  4.  -0.3 -0.4  0.4 -0.4 -0.2 -0.3 -0.4 -0.5 -0.3 -0.1 -2.2 -0.2 -0.4 -0.1  5.7 -0.9 -0.4  0.1 -0.4 -2.6 -0.4 -1.7  0.4  1.4  1.8 -0.2 -0.7  0.8  2.  -0.8  0.5 -0.1 -0.3 -1.1 -0.2  0.2 -0.3 -0.7 11.9 -0.2  2.3  1.7 -0.3  3.1 -1.   0.  -0.4 -2.8 -3.7 -0.4 -0.3  0.3 -0.2  0.8 -0.4  1.5 -0.3 -0.3 -0.1 -0.3 -0.   1.  -0.1  1.6  0.1  5.3 -0.1 -0.6 -0.   0.3 -0.1 -0.5 -0.4 -0.3 -0.9 -0.2  0.  -0.4  1.7  0.2  0.7 -0.5 -0.2  0.2  1.  -0.3 -0.1 -0.6 -0.1 -0.6 -1.   1.5 -0.1 -1.9 -0.4 -0.4 -1.3 -0.  -0.4  2.2 -0.8 -0.3 -0.5 -0.3 -0.1 -0.7 -0.7  3.6 -0.7 -1.5 -0.5 -0.3  0.2 -0.6 -0.2 -0.3 -0.7 -0.4 -3.6  1.2  0.5  2.8 -0.2 -0.3 -0.  -0.9 -1.2  0.2  0.9 -0.4 -0.2 -0.1 -0.6 -0.5 -0.5 -0.4 -1.2  3.1  2.4 -1.2 -0.3 -0.   5.8 -1.7  1.4 -0.4  1.6 -0.4 -0.1  1.4 -2.   1.5 -3.9 -0.3 -1.8 -0.2 -0.  15.   3.   0.4 -0.7 -0.9  0.2 12.5 -0.4 -0.  -0.2 -0.1  3. ]
vy_50sample [[8 5 7 4 0 0 9 2 3 1]
 [2 1 9 3 5 7 8 0 4 6]
 [8 4 7 6 5 2 2 0 9 3]
 [2 7 0 3 5 4 9 6 8 1]
 [2 8 5 1 4 0 9 6 3 7]
 [2 6 3 4 5 7 0 8 1 9]
 [5 0 8 7 2 4 6 1 9 3]
 [4 6 7 1 8 3 2 0 9 5]
 [6 9 4 0 5 3 2 7 1 8]
 [7 2 5 8 1 0 3 4 9 6]]
vt_50sample [[8 5 7 4 0 6 9 2 1 3]
 [2 1 9 3 5 7 8 0 4 6]
 [4 8 7 6 5 1 2 9 0 3]
 [2 7 0 3 5 4 9 6 8 1]
 [2 8 5 1 4 0 9 6 3 7]
 [2 6 3 4 5 7 0 8 1 9]
 [0 5 8 7 2 4 6 1 9 3]
 [4 6 7 8 1 3 2 0 9 5]
 [6 4 9 0 5 3 2 7 1 8]
 [7 2 5 1 8 0 3 4 9 6]]
Epoch 24610: Training cost= 0.3264, Training acc= 0.8279, Validation cost= 0.2762, Validation acc= 0.8281
Epoch 24620: Training cost= 0.2941, Training acc= 0.8279, Validation cost= 0.2637, Validation acc= 0.8281
Epoch 24630: Training cost= 0.3004, Training acc= 0.8280, Validation cost= 0.3263, Validation acc= 0.8281
Epoch 24640: Training cost= 0.3145, Training acc= 0.8280, Validation cost= 0.3317, Validation acc= 0.8281
Epoch 24650: Training cost= 0.3752, Training acc= 0.8280, Validation cost= 0.3504, Validation acc= 0.8282
Epoch 24660: Training cost= 0.2706, Training acc= 0.8280, Validation cost= 0.2602, Validation acc= 0.8282
Epoch 24670: Training cost= 0.3165, Training acc= 0.8280, Validation cost= 0.2650, Validation acc= 0.8282
Epoch 24680: Training cost= 0.2183, Training acc= 0.8281, Validation cost= 0.2699, Validation acc= 0.8282
Epoch 24690: Training cost= 0.2972, Training acc= 0.8281, Validation cost= 0.2633, Validation acc= 0.8283
Epoch 24700: Training cost= 0.3413, Training acc= 0.8281, Validation cost= 0.2645, Validation acc= 0.8283
tm  [-1.1 -0.4 -2.5 -2.6 -1.5  0.1  0.1 -0.1 -0.2 -0.7 -0.6 -0.1 -0.7 -0.4  1.5 -1.  -0.  -0.7 -0.8  0.4 -0.6 -0.3 -0.3  0.1 -1.5  4.1 -0.1 -0.5 -0.9 -0.9  5.  -0.4 -0.3  3.1 -0.3  0.5  2.7 -0.6 -0.2 -0.2  0.8  2.8  1.3  3.9 -0.3 -0.1 -1.3  0.5 -0.3 -0.6 -0.5 -0.4 -0.  -0.9 -0.6  0.2 -0.5 -0.7  0.7 -2.2  4.3 -0.5  1.6  0.6 -0.3  0.1 -0.1 -0.2 -0.3  0.6 -0.2  0.6 -0.4  1.2 -3.3 -0.3  0.9 -0.   1.1 -0.   3.4  0.3  0.7 -0.2 -0.2  4.3  2.5 -0.2 -0.  -0.4  0.  -0.4 -0.  -0.6 -0.4 -0.1 -0.1 -1.9  0.  -0.3  1.5 -0.1  0.3 -0.2 -0.3  1.3 -1.5  5.6 -0.3 -0.3 -0.9  0.6 -0.2 -0.4  3.5 -0.4 -0.5 -0.1 -0.3 -0.3 -0.1  0.9 -0.2  0.4 -0.1  2.   1.2  6.1  2.5  1.1 -0.3 -0.3 -0.5 -0.4  3.7  5.3 -0.2 -0.   1.2 -0.2  3.2 -1.   2.4  0.  -0.2 -0.1  0.4 -0.2  4.4  0.1  2.2 -0.3 -0.9  0.9 -0.4  0.9 -0.8 -0.2  1.  -0.2  1.6 -0.2 -0.  -0.  -0.  -0.2 -0.6  0.1  0.9 -0.3 -0.4 -0.1 -0.4 -0.5 -0.2 -0.5 -0.5  0.4  2.1  0.1 -1.  -0.3 -0.6 -1.8 -0.3 -0.7 -0.6 -0.4 -0.4  2.2 -0.1 -0.3 -0.2 -0.9 -0.9 -0.1 -0.1 -0.6 -0.1 -0.3 -0.2  0.3 -0.1 -0.8  0.8 -1.2 -0.2 -0.3 -1.9 -0.  -0.5  0.6 -0.7  6.3 -0.6 -0.6 -1.1 -0.7 -0.4 -0.7 -0.9  0.3 -0.4 -0.9  1.7 -0.7 -1.8 -0.3  0.4 -0.  -0.3 -0.5 -0.4 -1.1  1.7  5.9 -0.1 -0.9  2.2 -1.   0.1 -0.4 -0.2  0.1 -0.1 -0.4 -0.7 -0.1 -1.  -0.3 -0.9 -0.1 -0.3 -0.3  3.2  0.6]
ty_50sample [[4 1 5 0 6 3 7 9 8 2]
 [0 2 5 7 9 4 8 1 6 3]
 [2 2 0 0 4 6 3 3 5 9]
 [3 3 4 4 6 0 9 2 1 7]
 [7 4 0 3 6 6 9 2 1 5]
 [9 6 3 8 1 7 4 0 2 5]
 [2 5 6 9 7 8 3 0 1 4]
 [1 0 6 9 7 3 8 2 5 4]
 [4 9 5 2 6 7 3 8 0 1]
 [5 8 4 7 6 2 3 1 9 0]]
tt_50sample [[4 1 5 0 6 3 7 9 8 2]
 [0 2 5 7 4 9 1 8 6 3]
 [2 8 0 7 4 6 3 1 9 5]
 [3 5 4 8 6 0 9 2 1 7]
 [7 4 0 3 8 6 9 2 1 5]
 [9 6 3 8 1 7 4 0 2 5]
 [2 5 6 9 7 8 3 0 1 4]
 [1 0 6 9 7 3 8 2 5 4]
 [4 9 5 2 7 6 3 8 0 1]
 [5 8 4 7 6 2 3 1 9 0]]
vm  [-1.5 -0.3 -1.   3.6 -0.6 -0.5 -0.4 -0.3 -0.5 -0.6 -1.3 -0.2 -0.1 -0.5 -1.1  3.2  1.1  0.3 -0.1  0.4 -0.8 -0.3 -0.2 -0.  -0.8 -0.  -0.6 -0.1 -0.5 -2.5 -2.2 -0.5 -0.2 -6.  -0.7  0.6  1.4  4.2  1.2 -0.3  0.3 -2.1 -0.5 -0.2 -0.7 -0.5 -0.9 -0.5 -0.8  0.1 -0.7 -0.2 -1.   6.6 -1.1  1.4 -0.4  4.9  2.   6.   6.  -0.2 -0.5 -0.1 -1.4 -0.4 -0.2 -0.  -0.2 -0.2 -0.4 -0.3  0.1  0.  -4.2  0.3  0.3 -0.4 -0.5 -0.2 -4.3 -0.1 -0.4  0.3 -0.2 -2.  -1.6 -0.3  0.5 -0.4 -0.5 -0.1  0.5  2.  -0.3 -0.  -0.1 -1.8 -0.6 -0.4  2.9 -3.9  0.8 -0.2 -0.4 -0.3 -2.1 -1.7 -0.5 -0.7  0.3 -0.4 -0.4 -0.4  0.2  1.6 -0.1 -0.1 -0.  -0.5 -0.1  0.4 -0.3 -0.1 -0.  -1.4 -0.  -1.5  2.6 10.4 -0.9 -0.3 -0.2 -0.3  6.5 -4.3 -0.2 -0.1  0.6  1.3 -1.  -0.8 -1.3 -0.4 -0.3 -0.2 -0.1 -0.3  5.2 -0.2 -0.7 -0.2  1.1 -0.6 -0.2 -0.2 -0.4 -1.   1.8 -0.7 -0.6 -1.3 -0.3 -0.2 -0.2 -0.1 -0.1  0.9 -0.3 -0.4 -0.1  0.1 -0.5 -0.  -0.1 -1.2 -0.1 -0.8  0.7 -0.5 -0.6 -0.   0.1 -0.9 -0.4 -0.1 -0.6  1.3 -0.7  7.9 -0.  -0.4 -0.5 -1.  -1.6 -0.7 -1.1  0.6 -0.3 -0.3 -0.1 -0.1 -0.1 -0.5 -0.2 -2.4 -0.2  0.4  5.9 -0.  -0.5 -0.2 -0.4  3.5 -0.1 -0.2  1.5 -0.6 -0.7 -0.4 -0.2 -0.4 -0.5 -1.1 -1.8  2.  -0.3  0.7 -0.4  0.3 -0.8  1.5 -0.5  3.6 -0.4  1.9  0.5 -1.4 -0.2 -0.7 -0.4 -0.2 -0.2 -0.4 13.6  1.  -0.  -0.2 -0.5 -0.1 10.8 -0.1  0.8 -0.1  2.8 -2.7]
vy_50sample [[3 8 1 2 5 0 9 6 4 7]
 [5 8 4 9 7 6 0 2 3 1]
 [5 9 3 0 8 1 4 2 7 6]
 [8 5 1 3 7 2 6 9 4 0]
 [6 2 8 4 0 0 5 7 1 9]
 [9 4 2 7 5 0 1 3 8 6]
 [0 2 7 8 1 1 9 5 6 4]
 [4 0 0 5 6 8 3 2 7 1]
 [0 2 8 9 6 4 5 3 1 7]
 [6 3 9 0 4 8 5 7 1 2]]
vt_50sample [[3 8 1 2 5 0 9 6 4 7]
 [5 8 4 9 7 6 0 2 3 1]
 [5 9 3 0 8 1 4 2 7 6]
 [8 5 1 3 7 2 6 9 4 0]
 [6 2 8 4 3 0 5 7 1 9]
 [9 2 4 7 5 0 3 1 8 6]
 [0 2 7 8 1 3 9 5 6 4]
 [4 0 9 5 6 8 3 2 7 1]
 [2 0 8 9 6 4 5 3 1 7]
 [6 3 9 0 4 5 8 7 1 2]]
Epoch 24710: Training cost= 0.2723, Training acc= 0.8281, Validation cost= 0.2857, Validation acc= 0.8283
Epoch 24720: Training cost= 0.3762, Training acc= 0.8282, Validation cost= 0.3170, Validation acc= 0.8283
Epoch 24730: Training cost= 0.3705, Training acc= 0.8282, Validation cost= 0.2860, Validation acc= 0.8283
Epoch 24740: Training cost= 0.2981, Training acc= 0.8282, Validation cost= 0.3011, Validation acc= 0.8284
Epoch 24750: Training cost= 0.3266, Training acc= 0.8282, Validation cost= 0.3236, Validation acc= 0.8284
Epoch 24760: Training cost= 0.2680, Training acc= 0.8282, Validation cost= 0.3226, Validation acc= 0.8284
Epoch 24770: Training cost= 0.2630, Training acc= 0.8283, Validation cost= 0.2981, Validation acc= 0.8284
Epoch 24780: Training cost= 0.2992, Training acc= 0.8283, Validation cost= 0.2941, Validation acc= 0.8284
Epoch 24790: Training cost= 0.2582, Training acc= 0.8283, Validation cost= 0.2292, Validation acc= 0.8285
Epoch 24800: Training cost= 0.2931, Training acc= 0.8283, Validation cost= 0.2634, Validation acc= 0.8285
tm  [-0.3  1.   6.6 -1.6 -1.3 -0.4 -0.1 -0.2 -1.1 -0.1  5.3 -0.5 -0.5  0.  12.9  4.   0.9 -0.2 -0.2  2.  -0.5 -0.3  2.6  1.5 -1.4  1.1 -0.4 -0.3 -1.2  4.3 -1.2  0.6 -0.3  1.5 -0.3 -0.1  3.   1.3 -4.1 -0.3 -1.   3.5  1.5 -1.  -0.4 -0.3 -3.  -1.   1.4 11.4 -0.3 -0.1 -0.5 14.4 -0.8 -1.5 -0.4  3.2 -1.   4.3  4.6  0.3 -0.8 -0.1 -1.  -0.  -0.  -0.   0.  -0.4 -0.5  2.5 -0.2 -0.2 -6.2 -0.1 -0.2  0.  -0.5  0.1 -5.2  0.1  0.9 -0.2 -1.   5.4 -0.1  0.2 -0.3 -0.1 -0.3 -0.4 -0.3  2.8 -0.3 -0.2 -0.  -2.1 -0.3 -0.6 -0.   7.1 -0.3  0.2 -0.   0.  -2.9 -0.7  1.2  1.9  0.2  0.4 -0.2 -0.1 -0.5 -0.4 -0.5 -0.8  0.6 -0.2 -0.3 -1.4 -0.5  0.  -0.3 15.7 -0.2 -4.  -1.4  2.2  2.2 -0.2 -0.2 -0.1  3.2  3.8 -0.3 -0.3  0.3 -0.4 -1.2 -1.  -0.8 -0.2 -0.1  0.1 -0.2 -0.  -0.9  0.5 -0.  -0.2  2.9 -0.3 -0.5 -0.2 -0.7 -0.2 -1.4 -0.2 -0.2  2.5  0.  -0.2 -0.3  1.4 -0.1 -0.6 -0.1 -0.3  0.4 -0.2 -0.3 -0.2 -0.2  2.1 -0.8 -1.   8.8 -0.4 -0.5 -0.3  0.9 -0.9 -0.3 -0.5 -0.2 -0.7 -0.3 -1.1  0.1 -0.3  2.6 -1.1 -1.2  4.7 -1.7  1.5 -0.  -0.2 -0.2 -0.   1.  -0.3 -0.1 -3.6 -0.1  0.1  4.5  0.1  0.8 -0.9 -0.2  0.1  0.2 -0.1  5.2 -0.4 -0.4 -0.2 -0.1 -0.2 -0.1 -1.2  5.9  0.3  2.5  0.5  1.7 -0.2 -0.2  2.6 -0.4  1.7  0.2 -1.3  0.6 -2.3 -0.1 -2.9 -0.1 -1.2 -0.  -0.2 16.2  6.4 -0.4 -0.3 -0.1 -0.5 14.2  0.1 -3.  -0.2 -1.9 -0. ]
ty_50sample [[2 6 7 8 0 5 1 4 3 9]
 [2 5 0 9 1 3 8 4 6 7]
 [9 2 5 1 6 3 8 0 7 7]
 [9 0 4 3 5 2 2 6 8 7]
 [0 4 7 7 8 9 2 2 5 3]
 [4 9 6 8 1 7 2 2 3 3]
 [3 0 0 7 4 9 5 1 2 8]
 [6 7 5 1 3 4 0 8 9 2]
 [8 5 4 1 9 7 2 3 6 0]
 [2 4 0 9 7 6 8 3 1 5]]
tt_50sample [[2 6 7 8 0 5 1 4 3 9]
 [2 5 9 0 1 3 8 4 6 7]
 [9 2 5 1 6 3 8 0 4 7]
 [9 0 4 3 2 1 5 6 8 7]
 [0 4 1 7 8 9 6 2 5 3]
 [4 9 6 8 1 7 5 2 3 0]
 [3 6 0 7 4 9 5 2 1 8]
 [6 7 5 1 3 4 0 8 9 2]
 [8 5 4 1 9 7 2 3 6 0]
 [2 4 0 9 7 6 8 3 1 5]]
vm  [-1.3 -0.2  4.6  5.5 -2.1 -0.4  0.3 -0.  -1.2 -0.5 -3.   0.9 -0.7 -0.5  3.3 -0.1 -0.2  0.2 -0.3 -0.3 -0.6 -0.2  1.5  0.  -1.2  3.  -0.2 -0.6 -0.4  2.7 -0.8 -0.5 -0.6  2.1 -0.9  0.4  3.3  3.  12.9 -0.3 -0.2  2.3  2.7  3.8 -0.7 -0.5  1.5 -0.2 -0.8  8.2 -0.4 -0.1  0.4 -1.  -1.2 -0.3 -0.6 -0.3 -1.1  2.2  2.6 -0.2  0.3 -0.5 -1.6 -0.5  0.  -0.5 -0.2  0.1 -0.1 -0.4  1.   1.4 -1.3 -0.1  2.6 -0.4  0.9  0.9 -0.7 -0.   0.6 -0.5  0.8  4.2 -0.4 -0.3 -0.  -0.6  0.7 -0.5 -0.   0.6 -0.3 -0.2 -0.1 -0.9 -0.4 -0.4  1.   7.3  1.2 -0.3 -0.3 -0.1 -0.  -0.5 -0.9 -1.6 -0.5 -0.4  0.2  0.1 -0.6  1.7 -0.  -1.   0.1 -0.5  0.9  4.1 -0.5  0.   0.8  4.3  0.3  6.5 -0.7 -1.2 -1.1  0.8 -0.4 -0.2 -5.8 -5.3  0.4 -0.2 -0.4 -0.   2.4 -0.8  1.3 -0.1 -0.1 -0.2  1.1 -0.3 -1.1 -0.4 -0.6 -0.2  0.2  0.9 -0.4 -0.3 -0.5 -0.5  4.8 -0.1  1.1 -1.7 -0.1 -0.2 -0.3 -0.4 -0.5 -0.2 -0.4 -0.2 -0.3 -0.4 -0.1 -0.4 -0.1  2.2  2.2  2.2 -1.8 -0.3 -0.3 -0.4  0.7 -0.8 -0.9 -0.  -0.6 -0.2 -0.2 -0.8 -0.2 -0.6 -0.1 -1.  -0.3  4.2  1.9  2.2 -0.1 -0.4 -0.1 -0.1 -0.1 -0.2  0.1  3.6  0.6 -0.3  5.1 -0.4 -0.5  0.5 -0.3  7.3 -0.5 -0.  -1.5 -0.5  0.4  0.2 -0.3 -0.2 -0.2 -0.5 -0.5  0.6 -1.6 -0.2  2.1 -1.5 -0.2 -0.7 -0.1  3.  -0.3 -0.6 -0.3 -0.1  0.8  6.7 -0.1  3.4 -0.1 -0.5  3.5 -2.2 -0.4 -0.1 -0.3 -1.   1.1 -0.2  9.1  0.1  0.3  6.4]
vy_50sample [[7 1 8 9 4 0 5 2 3 6]
 [3 9 2 1 1 8 5 0 6 4]
 [5 7 2 9 1 6 0 4 3 8]
 [5 7 1 0 8 3 2 9 9 6]
 [7 0 0 8 9 3 1 6 5 4]
 [1 0 3 9 2 6 6 4 5 7]
 [5 9 1 8 2 3 7 6 0 4]
 [5 6 3 1 0 8 2 9 7 4]
 [6 7 9 4 1 3 0 5 8 2]
 [4 4 9 2 7 6 3 8 1 5]]
vt_50sample [[7 1 8 9 0 4 5 2 3 6]
 [3 9 2 7 1 8 5 0 6 4]
 [5 7 2 9 1 6 0 4 3 8]
 [5 7 1 0 8 3 2 9 4 6]
 [7 0 2 8 9 3 1 6 5 4]
 [1 3 0 9 8 2 6 4 5 7]
 [5 9 1 8 2 3 7 6 0 4]
 [5 6 3 1 0 8 2 9 7 4]
 [6 7 9 4 1 3 0 5 8 2]
 [4 0 2 9 7 6 3 8 1 5]]
Epoch 24810: Training cost= 0.2990, Training acc= 0.8283, Validation cost= 0.2996, Validation acc= 0.8285
Epoch 24820: Training cost= 0.2806, Training acc= 0.8284, Validation cost= 0.3113, Validation acc= 0.8285
Epoch 24830: Training cost= 0.3018, Training acc= 0.8284, Validation cost= 0.3575, Validation acc= 0.8285
Epoch 24840: Training cost= 0.3250, Training acc= 0.8284, Validation cost= 0.2604, Validation acc= 0.8286
Epoch 24850: Training cost= 0.3042, Training acc= 0.8284, Validation cost= 0.3420, Validation acc= 0.8286
Epoch 24860: Training cost= 0.2735, Training acc= 0.8285, Validation cost= 0.2530, Validation acc= 0.8286
Epoch 24870: Training cost= 0.3181, Training acc= 0.8285, Validation cost= 0.2786, Validation acc= 0.8286
Epoch 24880: Training cost= 0.2964, Training acc= 0.8285, Validation cost= 0.2667, Validation acc= 0.8287
Epoch 24890: Training cost= 0.3165, Training acc= 0.8285, Validation cost= 0.2533, Validation acc= 0.8287
Epoch 24900: Training cost= 0.3199, Training acc= 0.8285, Validation cost= 0.3175, Validation acc= 0.8287
tm  [-0.8 -0.8 -3.3 -3.6 -0.9 -0.2 -0.1 -0.2  1.  -0.4  9.2 -0.1 -0.1 -0.3 -0.   1.9 -0.1 -0.5 -0.1  3.3 -1.  -0.5 -0.6 -0.4 -0.9  0.4 -0.5 -0.4 -1.2 -2.2  5.7 -0.6  0.4  1.  -0.2 -0.1  0.4  3.8 -1.  -0.4  0.6  5.3 -0.1  4.8 -0.5 -0.4 -2.7 -0.5  1.4 -1.9 -0.3 -0.5 -0.4  8.6 -1.1  0.2 -0.6  2.6  5.3 -2.5  5.2 -0.7  0.3  1.7 -0.8 -0.8 -0.1  2.3 -0.  -0.1  0.4  0.1  0.9  0.2 -5.7 -0.1 -0.4 -0.5  0.1 -0.3  2.8 -0.1 -0.2 -0.4 -0.8  5.9  3.  -0.4 -0.3 -0.3 -0.2 -0.5 -0.2 -0.5 -0.8 -0.3 -0.4 -2.6 -0.2 -0.5  0.5 -1.2 -0.  -0.1 -0.3 -0.1 -2.5  5.1  0.4  0.  -0.5 -0.1 -0.3 -0.8  3.7 -0.2  0.6  1.6  0.5  0.4 -0.2 -0.7  0.6 -0.1 -0.3  0.1 -0.1 -1.9  7.5  5.3 -0.3 -0.5  0.3 -0.5  5.1  5.8 -0.3 -0.4 -0.3 -0.7 -0.2 -0.1 -0.8 -0.2 -0.  -0.1 -0.4  0.3  8.1 -0.1  2.4 -0.  -1.2 -0.7 -0.4 -0.2 -0.5  0.8  3.1  0.4  0.7 -1.  -0.5 -0.2 -0.2 -0.2 -0.3  0.   0.4 -0.4 -0.3  1.1 -0.1 -0.  -0.5 -2.  -0.4 -0.8  3.5 -0.4 -1.6 -0.1 -0.1 -1.5  0.5 -0.1 -0.1  0.8 -0.4  6.9  0.1 -0.6  0.7 -1.  -1.3 -1.7 -1.4 -0.7 -0.2  0.1 -0.1  0.9 -0.1 -1.1 -0.4 -3.2 -0.6  0.  -5.7 -0.5 -0.8 -0.3 -0.8  1.5  0.5 -0.2 -1.2 -0.8 -0.3  0.8  0.4 -0.2 -0.  -1.  -0.1 -1.1 -0.3 -0.1  1.   2.6 -0.8  0.1 -0.  -3.6  1.1  7.   1.5 -1.9  0.9 -5.3 -0.1 -2.3 -0.4 -0.2 -0.2  4.4 -0.5 -0.3 -1.3  0.1 -0.9 -0.3 -0.7 -0.2 -0.3 -1. ]
ty_50sample [[5 4 2 0 1 3 6 9 7 7]
 [2 5 9 1 8 0 4 3 6 7]
 [2 6 4 3 7 8 5 1 0 9]
 [5 4 6 7 0 1 8 3 2 9]
 [6 2 9 1 3 7 4 0 5 8]
 [0 7 4 8 3 9 1 6 2 5]
 [5 4 9 9 1 1 7 6 3 2]
 [9 9 3 8 8 7 0 1 6 4]
 [8 0 1 5 2 4 6 3 7 9]
 [6 0 4 5 7 2 1 3 8 9]]
tt_50sample [[5 4 2 0 1 3 6 9 7 8]
 [2 5 9 1 8 0 4 3 6 7]
 [2 4 6 3 7 8 5 1 0 9]
 [5 4 6 0 7 1 8 3 2 9]
 [6 9 2 1 3 7 4 0 8 5]
 [0 7 4 8 3 1 9 6 2 5]
 [5 4 9 0 8 1 7 6 3 2]
 [9 2 3 5 8 7 0 1 6 4]
 [8 0 1 5 2 4 6 3 7 9]
 [6 0 4 5 7 2 1 3 8 9]]
vm  [-0.1  1.2  4.7  6.4 -1.5 -0.4 -0.1 -0.2 -0.8 -1.  -5.6 -0.3 -0.6 -0.1  0.9 -1.2 -0.4  0.4  0.5 -0.8 -0.8 -0.2  1.  -0.  -0.9  0.2 -0.3 -0.2 -0.8 -0.2 -1.  -0.2 -0.2 -1.5 -0.2 -0.2  0.5 -0.5  5.5 -0.6 -0.7 -1.9  0.4 -0.1 -0.4 -0.3  4.   0.9  3.3  4.1 -0.8 -0.3 -0.4 -1.9 -0.5 -0.  -0.2 -0.1 -0.3  4.1 -0.7 -0.4 -0.4 -0.1 -0.6 -0.8 -0.2 -0.3  0.8 -0.1 -0.1  1.9  2.1  0.1 -0.8 -0.1 -0.8 -0.3 -0.3 -0.2 -1.4 -0.2 -0.1 -0.  -1.6 -1.8  2.2 -0.3 -0.1 -0.1  0.8 -0.1 -0.2  0.8 -0.6 -0.2 -0.1 -1.4 -0.5 -0.5  3.8 -0.3 -0.8 -0.3  0.1 -0.3 -0.5 -1.2 -2.  -0.9 -0.3 -0.1 -0.2 -0.2  0.7 -0.3 -0.4 -0.1 -0.1 -0.3 -0.3  4.4 -0.2 -0.1 -0.3  0.8 -0.3  9.6 -0.2  2.   2.2 -0.4  1.5 -0.6 -1.5 -3.3 -0.1 -0.1  0.2  2.3  2.5 -1.1  1.6  0.4 -0.1 -0.1 -0.3 -0.2 -1.3 -0.2 -0.5 -0.1  4.5 -0.1 -0.1 -0.1 -0.  -0.3 -0.1 -0.2 -0.2 -0.6  0.  -0.2 -0.4 -0.5 -0.1  0.6  0.9  0.1 -0.5 -0.3 -0.3  0.7 -0.5  3.1 -0.4  0.7 -0.4  0.9 -0.3 -0.5 -0.4 -1.3 -0.2  0.5  3.7 -0.3 -0.2  1.  -0.2 -0.2 -0.8 -0.7  6.5  0.8  1.  -0.4 -0.  -0.1 -0.2 -0.3 -0.5 -0.5 -0.4 -0.5 -0.2 -0.2  8.4 -0.3 -0.5 -0.3 -1.2 -0.3 -0.5 -0.6  1.6 -0.4 -0.   0.1 -0.7 -0.3 -0.4 -1.1 -0.7  1.  -1.8 -0.  -0.5  3.4 -0.7 -0.8 -0.2  4.3  1.5 -0.7  2.   1.   2.   8.6 -0.1  3.5 -0.2  0.2  5.8 -1.8 -0.1 -0.3 -0.8 -0.3  3.1 -0.1  4.  -0.   7.   0.6]
vy_50sample [[8 3 3 0 0 6 4 5 1 2]
 [0 4 5 8 6 3 7 9 2 1]
 [1 3 6 0 5 9 8 4 7 2]
 [5 4 8 7 9 2 0 3 6 1]
 [0 9 6 2 3 8 4 1 5 7]
 [8 2 3 5 9 4 6 0 0 1]
 [0 6 1 5 9 2 4 8 3 7]
 [8 4 9 3 7 7 6 6 0 2]
 [6 9 9 8 4 1 7 3 5 0]
 [7 8 9 4 1 2 6 5 3 0]]
vt_50sample [[8 3 9 7 0 6 4 1 5 2]
 [0 4 5 8 6 3 7 2 9 1]
 [3 1 6 5 0 9 8 4 7 2]
 [5 4 7 8 9 2 0 3 6 1]
 [0 9 6 2 3 8 4 1 5 7]
 [8 2 3 5 9 4 6 7 0 1]
 [0 6 1 5 9 2 4 8 3 7]
 [8 4 9 5 3 7 1 6 0 2]
 [6 2 9 8 4 1 7 3 5 0]
 [7 8 9 4 1 2 6 5 3 0]]
Epoch 24910: Training cost= 0.3266, Training acc= 0.8286, Validation cost= 0.3140, Validation acc= 0.8287
Epoch 24920: Training cost= 0.3634, Training acc= 0.8286, Validation cost= 0.3098, Validation acc= 0.8287
Epoch 24930: Training cost= 0.2937, Training acc= 0.8286, Validation cost= 0.3265, Validation acc= 0.8288
Epoch 24940: Training cost= 0.3340, Training acc= 0.8286, Validation cost= 0.2947, Validation acc= 0.8288
Epoch 24950: Training cost= 0.2546, Training acc= 0.8286, Validation cost= 0.2474, Validation acc= 0.8288
Epoch 24960: Training cost= 0.3356, Training acc= 0.8287, Validation cost= 0.2894, Validation acc= 0.8288
Epoch 24970: Training cost= 0.3291, Training acc= 0.8287, Validation cost= 0.3221, Validation acc= 0.8289
Epoch 24980: Training cost= 0.2760, Training acc= 0.8287, Validation cost= 0.3660, Validation acc= 0.8289
Epoch 24990: Training cost= 0.2881, Training acc= 0.8287, Validation cost= 0.2943, Validation acc= 0.8289
Epoch 25000: Training cost= 0.3041, Training acc= 0.8288, Validation cost= 0.2568, Validation acc= 0.8289
tm  [-1.5  1.9  6.2 12.9 -1.2 -0.1 -0.3  0.5 -1.1 -1.2  5.9 -0.3 -0.2 -0.   0.   3.7  0.2 -0.4 -0.2 -0.6 -0.4 -0.3 -1.1 -0.  -1.1  2.  -0.1 -0.5 -0.3 -0.8 -0.8 -0.4  0.6  4.4 -0.7  0.4  4.4 -0.2 -0.6 -0.  -0.3 -1.9  0.9 -1.8 -0.4 -0.1  0.7 -0.3 -0.9 -2.6 -0.4 -0.1  0.3  2.  -1.1  0.6 -0.3  6.  -1.1  3.7  3.2 -0.5 -0.3 -0.2 -0.2  0.4  0.1 -0.5 -0.5 -0.1  0.2 -0.2 -0.1 -0.1 -1.1 -0.3  0.1 -0.6 -0.4 -0.3  6.8 -0.4 -0.2 -0.8  1.3 -1.2 -1.9 -0.3  0.4 -0.1 -0.   0.1  0.9  2.  -0.2 -0.  -0.3 -0.8  1.2 -0.1  5.6 -1.5  2.  -0.2 -0.3  0.4 -0.6 -0.5  1.  -1.5 -0.3 -0.1  0.2 -0.1 -0.8  4.2 -0.4 -1.3 -0.2 -0.6  0.8  4.7 -0.   0.7 -0.1  0.2  1.4  0.5 -0.9  5.3 -0.2 -0.4 -0.1 -0.2  6.1  9.7  0.  -0.1  2.3 -0.3 -0.4 -0.1 -0.5 -0.2 -0.  -0.1 -0.3  0.1  1.4 -0.  -1.1 -0.2 -1.3 -0.3 -0.2 -0.1 -0.4 -0.2 -0.6 -0.5 -0.8  2.  -0.2 -0.  -0.4  0.3  0.7  0.5  0.6 -0.1 -0.1 -0.2 -0.2 -0.2 -0.2  0.3 -0.8 -0.1  2.3 -0.2 -0.8 -0.2 -0.1 -1.4 -0.2 -0.4 -0.9 -0.7 -0.3  2.8 -0.1  0.5 -0.3 -0.9 -0.7  3.2  0.3  3.2 -0.2 -0.2 -0.3 -0.1 -0.2 -0.5 -0.1 -0.6 -0.1 -0.3 -0.7 -0.2 -0.2  0.6 -0.5  5.8 -0.5 -0.4  7.1 -0.5 -0.5  0.1 -0.4 -0.1 -0.1 -0.5 -0.2  0.4 -0.3  1.1  1.1 -0.6 -0.2 -0.6 -0.5 -0.5  0.2 -1.3 -0.6 -0.1 -0.1  2.5 -0.   1.7 -0.2  0.  -1.1 -0.8 -0.4  0.4 -0.6 -0.4 -1.8 -0.2 -0.7 -0.2  3.1 -0.8]
ty_50sample [[3 1 6 2 9 5 7 0 8 4]
 [6 7 3 1 2 4 5 9 8 8]
 [9 0 7 8 3 6 2 5 4 1]
 [1 8 2 6 4 0 5 9 3 7]
 [7 4 8 9 2 0 1 3 6 5]
 [5 9 2 6 3 8 0 1 7 4]
 [6 0 2 7 8 8 5 5 3 4]
 [3 0 6 5 4 1 9 8 2 7]
 [8 3 1 4 6 9 2 5 0 7]
 [5 6 9 7 2 8 3 1 0 4]]
tt_50sample [[3 1 6 2 9 5 7 0 8 4]
 [6 7 3 1 2 4 5 9 8 0]
 [9 0 7 3 8 6 2 5 4 1]
 [1 2 8 6 4 0 5 9 3 7]
 [7 4 8 9 2 0 1 3 6 5]
 [5 9 2 6 3 8 0 1 7 4]
 [6 0 2 7 8 1 9 5 3 4]
 [3 0 6 5 4 1 9 8 2 7]
 [8 3 1 4 6 9 2 5 0 7]
 [6 5 9 7 8 2 3 1 0 4]]
vm  [-0.8 -0.4 -1.9 13.4 -0.3 -0.1  0.8  0.1 -0.1  0.2  9.6 -0.  -0.3 -0.5 -4.3  0.7  0.4 -0.1 -0.2 -1.6 -0.8 -0.3 -0.8 -0.  -1.   2.8 -0.3  0.2 -1.1 -2.5  1.  -0.9 -0.3 -1.7  0.6  0.   3.1  4.1 11.3 -0.1 -0.3 -1.5 -1.1 -0.3 -0.7 -0.5 11.8 -1.1 -1.3 -1.8 -0.2 -0.3  0.7  1.  -0.8  5.7 -0.7 -0.3  1.  -0.3 -0.1 -0.2 -0.  -0.8  0.3 -0.6  0.4  2.2 -0.7 -0.6 -0.4  2.9 -0.3 -1.   3.7 -0.1  0.7 -0.1 -0.2 -0.1 17.9  1.2 -0.7 -0.8 -0.2 -1.5 -1.3 -0.3  0.  -0.5 -0.1 -0.4  0.4 -0.1 -0.3 -0.5 -0.3  2.  -0.4 -0.2 -0.3 -2.5  0.1 -0.3 -0.2 -0.1 -0.1  0.8  1.4 -2.3 -0.  -0.1 -0.2  1.1  2.5 -2.  -0.1 -0.9  0.4 -0.  -0.4  7.2 -0.2 -0.1 -0.  -5.1 -0.3  0.7 -0.3 -0.7 -0.6  0.4 -0.2  2.1  9.   4.7 -0.8 -0.2  1.  -0.8 -1.1 -0.8 -1.4 -0.1 -0.2 -0.3 -0.   0.1  3.1 -0.6 -1.   0.4 -1.6 -0.6  0.5 -0.3 -0.4  0.2 -0.4 -0.6 -0.2 -1.1 -0.2 -0.3  0.7 -0.2 -0.9  0.7 -0.5 -0.3 -0.1 -0.4 -0.4  0.2 -0.  -0.7 -0.6  0.2 -1.5  0.2  0.1 -0.3  1.8 -1.2 -0.5 -0.3 -0.6  2.4 -0.1  8.  -0.1 -0.4 -0.6 -0.9  2.4  2.7  1.6 -0.  -0.1 -0.1 -0.1  0.6 -0.4 -0.2 -0.1  6.7  0.4 -0.1  1.7 -0.2 -0.3 -1.4 -0.1  4.2  0.7  1.2  1.7 -0.7 -0.9  1.1  0.5 -0.5  0.  -1.1 -0.2 -1.1  1.5  2.  -0.2 -0.9 -1.  -0.3 -0.2  1.5  0.7  2.4  0.8  1.  -0.9 17.5 -0.2  7.5 -0.5 -0.2 -3.9 -3.2 -0.2 -0.5 -0.6 -0.1 -4.5 -0.1  8.5  0.1 -0.8  4.5]
vy_50sample [[9 2 1 1 3 6 4 8 5 7]
 [6 2 0 1 4 3 7 8 5 9]
 [7 7 1 5 5 2 8 6 4 3]
 [5 6 2 4 3 1 9 8 7 0]
 [5 2 0 1 8 3 4 6 7 9]
 [6 5 3 8 9 2 7 1 4 4]
 [2 8 5 1 0 4 4 9 6 3]
 [6 7 8 3 1 0 4 2 2 5]
 [1 9 2 7 5 6 4 8 3 0]
 [8 5 3 6 0 2 2 1 9 4]]
vt_50sample [[2 9 0 1 3 6 4 8 5 7]
 [6 2 0 1 4 3 7 8 5 9]
 [7 0 1 9 5 2 8 6 4 3]
 [5 6 2 4 3 1 9 8 7 0]
 [5 2 0 1 8 3 4 6 7 9]
 [6 5 3 8 9 2 7 1 4 0]
 [2 8 5 1 0 7 4 9 6 3]
 [6 7 8 3 1 0 4 9 2 5]
 [1 9 2 7 5 6 4 8 3 0]
 [8 5 3 6 0 7 2 1 9 4]]
Epoch 25010: Training cost= 0.2802, Training acc= 0.8288, Validation cost= 0.2506, Validation acc= 0.8289
Epoch 25020: Training cost= 0.2755, Training acc= 0.8288, Validation cost= 0.3150, Validation acc= 0.8290
Epoch 25030: Training cost= 0.2847, Training acc= 0.8288, Validation cost= 0.2573, Validation acc= 0.8290
Epoch 25040: Training cost= 0.2771, Training acc= 0.8289, Validation cost= 0.2498, Validation acc= 0.8290
Epoch 25050: Training cost= 0.2639, Training acc= 0.8289, Validation cost= 0.3200, Validation acc= 0.8290
Epoch 25060: Training cost= 0.2452, Training acc= 0.8289, Validation cost= 0.2772, Validation acc= 0.8291
Epoch 25070: Training cost= 0.2384, Training acc= 0.8289, Validation cost= 0.3153, Validation acc= 0.8291
Epoch 25080: Training cost= 0.3327, Training acc= 0.8289, Validation cost= 0.2577, Validation acc= 0.8291
Epoch 25090: Training cost= 0.2563, Training acc= 0.8290, Validation cost= 0.2380, Validation acc= 0.8291
Epoch 25100: Training cost= 0.2903, Training acc= 0.8290, Validation cost= 0.2629, Validation acc= 0.8292
tm  [-0.  -0.7  4.2 -0.5 -1.9 -0.1  0.3 -0.3 -0.5 -0.1 -4.1  0.3 -0.5 -0.6  7.3 -0.5  0.6 -0.2 -0.8 -1.2 -0.9 -0.1 -0.6 -0.1 -1.  -0.8 -0.5 -0.2  0.4 -0.6  0.4 -0.6 -0.2  4.6 -0.5 -0.7 -0.   0.7 10.2 -0.4  1.5 -1.8 -0.2  5.7 -0.2 -0.2  5.7  1.2 -0.1 -1.2 -0.6 -0.2 -0.9 -1.7 -1.2 -0.7 -0.4 -0.8  1.7  0.  -0.7 -0.2 -0.6 -0.5 -0.5 -0.2 -0.2 -0.2 -0.1 -0.2 -0.3 -1.5 -0.6 -0.5 -2.6  1.8 -1.1  1.  -0.3  0.4 -1.1  0.7 -1.1  2.9 -1.  -1.8  4.  -0.2 -0.1 -0.5 -0.2 -0.   0.2 -0.1 -0.2 -0.3  1.1 -1.2 -0.5 -0.6  1.2 -0.1 -0.7  0.1 -0.3 -0.6 -2.2  1.  -1.1 -1.1  1.8 -0.1 -0.4 -0.7  0.4  5.2 -0.3  1.8 -0.1 -1.  -0.8  3.3 -0.2 -0.6  0.6  7.6  0.5  9.6  2.8  6.4 -0.2 -0.7 -0.4 -0.  -6.1 -4.3 -0.4 -0.4 -0.2 -0.5  0.9 -0.1  1.6 -0.4  0.2 -0.  -0.  -0.2 -1.3 -0.5 -0.5 -0.3  2.7 -0.1 -0.1 -0.2 -0.2 -0.2  2.  -0.3 -0.4 -2.3 -0.3 -0.1 -0.4  1.2 -0.8  0.7 -0.3 -0.1 -0.5  0.8 -0.4  1.1  0.9  3.  -0.  -0.8 -1.1 -0.2 -0.3  0.3 -0.2 -1.1 -0.8 -0.6  3.4 -0.9 -0.7  1.4 -0.1 -0.2 -1.3 -0.9  6.1 -1.  -0.8 -0.5 -0.1 -0.3 -0.2  0.1  0.4 -0.3 -0.3 -1.4 -0.1 -0.   3.7  0.1 -0.9  3.7 -0.5 -0.6 -0.3  0.5 -1.6 -0.2 -0.4 -0.8 -0.6 -0.2 -0.3 -0.5 -2.4  4.2 -1.9 -0.7 -0.   3.9 -1.5  2.4 -0.3  2.2 -1.7 -0.3 -0.1 -1.3  0.6  6.5 -0.3  2.8 -0.1 -0.3  5.  -1.  -0.3 -1.1 -0.8 -0.1  2.4 -0.4  7.   0.2  7.6 -1.5]
ty_50sample [[3 7 4 8 9 5 1 0 2 6]
 [6 3 0 5 2 9 1 4 7 8]
 [3 7 9 2 0 8 4 6 1 5]
 [2 6 9 5 3 8 0 1 7 4]
 [5 7 6 3 4 1 9 0 8 2]
 [7 6 4 9 8 5 0 3 2 2]
 [6 3 7 8 1 5 9 4 0 2]
 [7 9 0 0 1 1 6 5 4 4]
 [7 2 5 1 4 8 3 9 0 6]
 [2 0 5 1 7 4 8 6 3 9]]
tt_50sample [[3 7 4 8 9 5 1 0 2 6]
 [6 3 0 5 2 9 1 4 7 8]
 [3 7 9 2 0 8 4 6 1 5]
 [2 6 9 5 3 8 0 1 7 4]
 [5 7 6 3 4 1 0 9 8 2]
 [7 6 4 9 8 5 0 3 2 1]
 [6 3 7 8 1 5 9 4 0 2]
 [7 2 0 9 1 5 6 3 8 4]
 [7 2 5 1 4 8 3 9 0 6]
 [2 0 5 1 7 4 8 6 3 9]]
vm  [ 2.3 -0.   5.5 -0.5 -1.6 -0.2  0.3 -0.4 -0.4 -0.2  2.9 -0.1 -0.7 -0.2  9.6  3.4 -0.1 -0.1 -0.3  1.2 -0.7  0.2  2.5 -0.3 -1.3 -0.1 -0.  -0.3 -0.1  1.  -0.1 -0.4 -0.4  5.  -0.1 -0.3  0.2  3.4 -0.1 -0.6 -0.4  7.1  2.8  1.8 -0.5 -0.1 -1.3 -0.6  4.3  6.7 -0.7 -0.2 -0.   6.3 -1.1 -1.2 -0.4  5.2 -0.4  2.5 -0.1 -0.4  0.3  0.7  0.5 -0.7 -0.1  0.7 -0.  -0.4  0.6 -0.5  0.4 -0.3 -5.  -0.5 -1.  -0.6 -0.2 -0.3 -1.8  0.5  0.5  0.  -1.8  7.8  3.9 -0.3 -0.2 -0.2 -0.2 -0.3 -0.1 -0.  -0.5 -0.3 -0.4 -2.  -0.3  0.3 -0.1  6.2 -1.4 -0.1 -0.2  0.8 -2.  -0.2  0.7  0.6  0.9 -0.2 -0.  -0.7 -0.4  2.6 -0.9 -0.2 -0.   0.5 -0.4 -1.  -0.5 -0.6 -0.5 11.3 -0.5 -1.3  0.7  0.9  2.8 -0.3  0.3 -0.1 -3.2 -1.4 -0.1 -0.1 -0.2 -0.9 -0.4 -0.6 -0.2 -0.   0.7 -0.1 -0.2 -0.1  2.1 -0.3 -0.1 -0.1  4.3 -0.2  0.  -0.1 -0.3 -0.1  0.1 -0.3  0.9 -0.8  0.  -0.3  0.3 -0.4 -0.4 -0.5 -0.   0.2 -0.2  0.9 -0.2 -0.  -0.1 -0.3 -0.8 -0.5  1.3 -0.3 -1.9 -0.4 -0.4 -1.6 -0.5 -0.3  2.8 -0.8 -0.1 -0.3 -0.2 -0.5 -0.2 -0.8  3.2 -0.  -1.   0.8  0.1 -0.2  0.5 -0.2 -0.4 -0.3 -0.4 -2.2 -0.2 -0.  -2.4 -0.2 -0.4  1.  -1.  -0.8 -0.3 -0.2 -0.1 -0.5 -0.3  0.8 -0.4 -0.3  1.  -0.9  1.8  1.6 -0.4 -0.3 -0.4  3.5 -0.6  0.7 -0.1 -1.3 -1.  -0.8  1.4 -1.6  1.3 -4.8 -0.4 -2.2 -0.  -0.   7.2  0.3 -0.3 -0.3 -0.7 -0.1  4.3 -0.2  0.  -0.1 -0.9  1.3]
vy_50sample [[5 7 2 8 4 0 6 9 3 1]
 [4 8 2 1 9 0 7 5 6 3]
 [0 9 2 3 4 8 5 6 1 7]
 [9 4 8 2 1 6 5 0 7 3]
 [4 9 7 8 6 1 2 3 0 5]
 [8 4 0 0 7 1 5 3 6 2]
 [2 0 6 1 8 7 9 9 5 3]
 [5 6 3 2 4 9 8 1 7 0]
 [5 7 3 4 8 0 9 2 1 6]
 [6 0 7 1 8 5 3 2 9 4]]
vt_50sample [[5 7 8 2 4 6 0 3 9 1]
 [4 8 2 1 9 0 7 5 6 3]
 [9 0 2 3 4 8 5 6 1 7]
 [9 4 8 1 2 6 5 0 7 3]
 [4 9 7 8 6 1 2 3 0 5]
 [8 4 9 0 7 1 5 6 3 2]
 [2 0 6 1 8 7 9 4 5 3]
 [5 6 3 2 4 9 8 1 0 7]
 [5 7 3 4 8 9 0 2 1 6]
 [6 0 7 1 8 5 3 2 9 4]]
Epoch 25110: Training cost= 0.3009, Training acc= 0.8290, Validation cost= 0.3081, Validation acc= 0.8292
Epoch 25120: Training cost= 0.2864, Training acc= 0.8290, Validation cost= 0.3178, Validation acc= 0.8292
Epoch 25130: Training cost= 0.2871, Training acc= 0.8291, Validation cost= 0.3255, Validation acc= 0.8292
Epoch 25140: Training cost= 0.2995, Training acc= 0.8291, Validation cost= 0.3669, Validation acc= 0.8292
Epoch 25150: Training cost= 0.3292, Training acc= 0.8291, Validation cost= 0.3539, Validation acc= 0.8293
Epoch 25160: Training cost= 0.2504, Training acc= 0.8291, Validation cost= 0.3283, Validation acc= 0.8293
Epoch 25170: Training cost= 0.2709, Training acc= 0.8291, Validation cost= 0.3282, Validation acc= 0.8293
Epoch 25180: Training cost= 0.2623, Training acc= 0.8292, Validation cost= 0.3190, Validation acc= 0.8293
Epoch 25190: Training cost= 0.2810, Training acc= 0.8292, Validation cost= 0.2972, Validation acc= 0.8294
Epoch 25200: Training cost= 0.3348, Training acc= 0.8292, Validation cost= 0.2774, Validation acc= 0.8294
tm  [ 1.8 -1.3 -0.2  8.9 -1.  -0.2 -0.1 -0.4  2.7  1.2 -3.1 -0.1 -0.4 -0.7 -1.5 -1.8  0.7 -0.2 -0.3 -0.9 -0.6 -0.1  0.1  0.4 -0.7  1.2 -0.2  0.5 -1.  -3.3 -1.4 -0.4 -0.8 -4.2  0.4 -0.8 -0.6  0.2  5.8 -0.3  1.1 -0.7 -0.9 -0.3 -0.7 -0.5  4.6 -0.4  4.1  2.3 -0.5 -0.1 -0.5 -0.9  1.   3.  -0.2  3.9  6.4  4.2 -1.2 -0.1  0.5  0.8 -0.6  0.1 -0.1  0.4  0.  -0.2 -0.7  1.9 -0.6 -0.3 -2.7  0.4 -1.5  1.8 -0.5 -0.2 -1.4  1.6 -0.2  0.3 -1.8 -0.7  2.2 -0.1 -0.  -0.2  0.1 -0.4 -0.1 -1.1 -0.5 -0.5  1.7 -1.9 -0.  -0.9 -1.  -2.4 -1.9 -0.3  0.4 -0.4 -1.1 -1.2 -1.  -0.9  1.2  0.6 -0.1 -0.1  7.  -2.4 -0.7  3.8 -0.2 -0.  -0.5  2.4 -0.2 -0.6  0.5 -2.  -0.8  6.7  5.2  2.7  2.9 -0.5 -0.4 -0.2  7.1 -2.9 -0.4 -0.   1.3  0.  -0.4 -1.6 -0.1 -0.1 -0.2 -0.5  0.9 -0.1  5.3 -0.4 -1.  -0.3  4.7  0.  -0.4 -0.4 -0.1 -0.5 -0.5  1.  -0.  -1.4  0.7 -0.1 -0.1 -0.3 -0.9 -0.1 -0.6  0.4 -0.4 -0.3 -0.7 -0.2  0.4 -1.1 -0.7 -0.2 -0.3  0.2 -1.  -0.3 -0.5 -1.4 -0.5 -0.5  6.   0.2 -0.2  8.8 -0.1 -0.  -0.9 -0.7  9.  -1.7 -0.3 -1.8 -0.2 -0.3 -0.3  0.2 -0.1 -0.2 -0.6 -0.1  0.5 -0.4  4.4  0.7 -0.9 -0.7 -0.9 -1.8 -1.  -0.1  2.6 -0.3 -0.5 -0.8 -1.3 -0.4 -0.6 -1.3 -0.5 -0.9 -1.7 -0.1 -0.6  5.6 -0.8 -0.1 -0.3  2.4 -0.2  1.7  2.2 -1.   2.3  5.4 -0.   2.  -0.1  1.1  5.6 -2.1  1.4 -1.  -0.9 -0.   3.  -0.1  3.6 -0.   4.1 -0.1]
ty_50sample [[0 8 3 9 5 6 2 4 7 7]
 [9 8 1 5 3 6 0 4 7 2]
 [6 1 2 4 9 7 0 5 3 8]
 [6 8 4 5 1 2 3 9 7 0]
 [0 8 7 3 1 9 2 5 4 6]
 [0 8 6 4 3 9 7 2 1 5]
 [3 5 2 4 0 7 6 6 8 1]
 [7 1 2 6 4 9 5 0 8 3]
 [3 4 1 7 6 8 9 2 0 5]
 [1 7 0 5 8 2 9 6 3 4]]
tt_50sample [[0 8 3 9 5 6 2 4 7 1]
 [9 8 1 5 3 6 0 4 7 2]
 [6 1 2 4 9 7 0 5 3 8]
 [6 8 4 5 1 2 3 9 7 0]
 [0 8 7 3 1 9 2 5 4 6]
 [0 8 6 4 3 9 7 2 1 5]
 [3 5 4 2 0 7 9 6 8 1]
 [7 1 2 6 4 9 5 0 8 3]
 [3 4 1 7 6 8 9 2 5 0]
 [7 1 0 5 8 2 9 6 3 4]]
vm  [ 1.6 -0.7 -2.8 -3.7 -0.9 -0.4 -0.3 -0.   5.9 -0.2  3.2  1.  -1.4 -0.1 -0.3 -0.5 -0.4  0.1  1.5 -0.3 -0.9 -0.  -0.1 -0.4 -1.   0.5 -0.3  1.3  1.2 -2.5  6.4 -0.6 -0.6  3.9 -0.4 -1.4 -1.9  1.4  4.7 -0.6 -0.8 -2.3 -2.3  3.7 -0.9 -0.1 -0.1 -0.4  4.8 -1.5 -0.4  0.3  2.6 -0.5 -1.5  1.7 -0.2 -2.5  9.6 -2.2 -0.7 -0.2  4.1 -0.3  2.7 -1.  -0.5  4.2  3.5 -0.9 -0.  -1.   1.9  1.3 -5.  -0.  -1.7  0.1 -0.8 -0.5  5.9 -1.   2.2 -1.  -2.4 -2.3  5.2 -0.2 -0.5 -0.1 -0.3 -0.9 -0.3 -2.2 -0.5 -0.5 -0.4 -2.6 -0.8 -0.4 -0.4 -0.6 -1.8 -0.3  1.1  0.2 -1.3  6.1  1.2 -0.3  2.2 -0.   0.1 -1.1  6.8  3.3  3.   5.8 -0.4  2.8 -0.3 -0.4 -0.5  1.4 -0.5 -0.4 -0.6  4.2  6.8  0.7  3.1 -1.  -0.2 -0.1 -0.6  2.3  0.8 -0.2  2.  -0.9 -0.3 -0.6 -0.1 -0.  -0.3  0.3 -0.4 -0.  -1.  -0.   0.7  0.3  4.8  1.   0.2 -0.3 -0.2 -0.2  0.7  2.  -0.3 -2.   2.1 -0.  -0.2 -0.3  1.2  4.9 -0.7 -0.4 -0.8 -0.9 -0.9 -0.3 -0.4  3.4 -0.7  0.7 -0.4  0.6  1.3  0.3 -0.  -1.8 -0.7 -0.1  6.2 -0.2  1.5  6.3 -0.4 -0.1 -0.4 -1.4  7.1 -2.   0.  -2.  -0.3 -0.3 -0.5 -0.3 -0.5 -0.3 -1.   0.8 -0.4 -0.2  3.9 -0.2 -0.5  3.4 -1.1 -1.8  3.1 -0.3 -1.4 -0.6  0.5  1.6 -1.2 -0.4 -0.9 -1.4 -0.9 -0.  -2.4  0.4  1.9  6.3 -0.1 -0.3 -0.3  2.7 -1.5  4.4  0.8 -1.7  1.8  8.6 -0.1  3.4 -0.4  1.2 -0.8 -1.9 -0.2  0.4 -1.   2.3 -1.7  1.5  3.7 -0.1  4.2  0.8]
vy_50sample [[4 9 9 7 0 2 6 8 5 5]
 [0 4 3 9 7 8 2 5 6 1]
 [5 0 6 7 7 2 8 3 1 9]
 [3 6 5 2 4 0 9 1 7 8]
 [5 6 4 8 0 9 2 3 1 7]
 [4 0 6 8 2 7 1 9 3 5]
 [5 1 0 3 8 9 6 2 7 4]
 [3 9 7 1 0 8 8 4 6 2]
 [2 3 9 9 7 6 4 0 1 8]
 [8 5 4 1 6 2 0 3 7 9]]
vt_50sample [[4 9 3 7 0 2 6 8 1 5]
 [0 4 3 9 7 8 2 5 6 1]
 [5 0 6 4 7 2 8 3 1 9]
 [3 6 2 5 4 0 9 7 1 8]
 [5 6 4 8 9 0 2 3 1 7]
 [4 0 6 8 2 7 1 9 3 5]
 [5 1 0 3 9 8 6 2 7 4]
 [3 9 7 1 5 0 8 4 6 2]
 [2 3 9 5 7 6 4 0 1 8]
 [8 5 4 1 6 2 0 3 7 9]]
Epoch 25210: Training cost= 0.2703, Training acc= 0.8292, Validation cost= 0.2795, Validation acc= 0.8294
Epoch 25220: Training cost= 0.3279, Training acc= 0.8293, Validation cost= 0.2234, Validation acc= 0.8294
Epoch 25230: Training cost= 0.3453, Training acc= 0.8293, Validation cost= 0.2587, Validation acc= 0.8294
Epoch 25240: Training cost= 0.2929, Training acc= 0.8293, Validation cost= 0.2719, Validation acc= 0.8295
Epoch 25250: Training cost= 0.2555, Training acc= 0.8293, Validation cost= 0.2511, Validation acc= 0.8295
Epoch 25260: Training cost= 0.2739, Training acc= 0.8293, Validation cost= 0.2695, Validation acc= 0.8295
Epoch 25270: Training cost= 0.2812, Training acc= 0.8294, Validation cost= 0.2777, Validation acc= 0.8295
Epoch 25280: Training cost= 0.3056, Training acc= 0.8294, Validation cost= 0.2984, Validation acc= 0.8295
Epoch 25290: Training cost= 0.2600, Training acc= 0.8294, Validation cost= 0.3368, Validation acc= 0.8296
Epoch 25300: Training cost= 0.2763, Training acc= 0.8294, Validation cost= 0.3229, Validation acc= 0.8296
tm  [ 0.8 -0.1  2.6 -2.3 -1.8 -0.2 -0.3 -0.2  0.1 -0.5  8.8  0.2 -0.4 -0.3  8.6  4.2  0.1 -0.3  0.5  4.4 -0.7  0.1 -0.8 -0.1 -1.5  2.2 -0.4 -0.1 -0.7 -2.4  1.1 -0.5 -0.3  3.5 -0.4 -0.3 -0.   7.2 -0.2 -0.7 -0.2 -0.5 -0.   2.3 -0.4 -0.3 -3.1 -1.2  5.2 -1.9 -0.7 -0.1 -0.1 13.9 -0.8 -0.8 -0.4  3.7  4.1  0.4  2.6 -0.1  0.9  2.  -0.3 -0.2  0.4 -0.1 -0.3 -0.3 -0.3  0.2  0.2 -0.  -6.3  0.2 -1.1 -0.3 -0.4 -0.3 -2.4 -0.1  0.7 -0.5 -1.5 -0.2  2.  -0.2  0.5 -0.3 -0.6 -0.3  0.5 -0.3 -0.3 -0.4 -0.  -2.8 -0.4 -0.3  2.3 -1.  -1.  -0.3 -0.3  0.2 -2.6  1.   1.9  3.6  0.   0.6 -0.2 -0.7  0.7  0.7  0.3  1.   0.1  0.2 -0.3 -1.7 -0.4 -0.1 -0.4  9.5 -0.3 -3.7  5.  10.4 -0.1 -0.5 -0.2 -0.5 -3.  -1.9 -0.2 -0.1 -0.  -0.4 -0.8 -0.7 -0.7  0.6  0.4 -0.2 -0.  -0.2  2.7 -0.1  0.9 -0.2  2.4 -0.6 -0.2  0.2 -0.4 -0.2  4.5 -0.2 -0.3 -2.  -0.1 -0.1 -0.1 -0.4 -0.1 -0.2 -0.2 -0.1 -0.3 -0.1 -0.6 -0.1 -0.3 -0.4  0.9 -0.6  1.4 -0.2 -1.2  0.  -0.3 -1.5 -0.3 -0.2  1.9 -0.6 -0.6  6.9 -0.1 -0.3  0.3 -1.1 -0.4 -1.6 -1.3 -0.5 -0.1 -0.2 -0.1 -0.2 -0.1 -0.5 -0.4 -3.3  0.3  0.1 -1.5 -0.2 -0.5 -0.2 -0.7 -0.7 -0.3  0.2 -0.7 -0.7 -0.5 -0.2 -0.3 -0.4  0.2 -1.1 -1.7 -0.3  1.7  0.8  1.6  5.  -0.5  0.5 -0.3 -0.7 -0.1 -0.3  0.2 -1.9 -0.1 -3.9 -0.1 -1.7 -0.3 -0.1  9.1  4.6 -0.3 -0.1 -0.8 -0.2  5.9 -0.2 -0.   0.5 -0.3 -3.2]
ty_50sample [[2 3 5 7 0 4 8 1 6 9]
 [0 9 8 2 6 3 7 4 5 1]
 [3 3 2 1 1 5 0 6 9 4]
 [2 0 1 8 7 3 4 6 9 5]
 [5 4 0 7 2 9 3 6 8 1]
 [4 5 5 8 0 1 2 2 6 7]
 [6 6 2 2 1 5 8 7 0 4]
 [6 4 8 1 9 3 0 2 2 5]
 [1 4 4 6 3 8 7 2 2 9]
 [4 5 2 2 1 6 0 3 9 7]]
tt_50sample [[2 3 5 7 0 4 8 1 6 9]
 [0 9 8 2 6 3 7 4 5 1]
 [7 3 2 1 8 5 0 6 9 4]
 [2 0 1 8 7 3 4 6 9 5]
 [5 4 0 2 7 9 3 6 8 1]
 [4 5 9 0 8 1 2 3 6 7]
 [6 3 9 2 1 8 5 7 0 4]
 [6 4 8 1 9 3 7 0 2 5]
 [1 4 0 3 6 8 7 5 2 9]
 [4 5 2 8 1 6 0 3 9 7]]
vm  [-0.8 -0.2 -3.   0.4 -0.7 -0.4 -0.4  0.  -1.  -0.3 -0.5 -0.6 -0.2 -0.2 -2.8 -0.9 -0.3 -0.4 -0.2 -1.3 -0.9 -0.5  1.6 -0.1 -1.   2.3 -0.7  0.2 -1.4 -0.1  3.1 -0.  -0.1 -3.1 -0.3 -0.1  4.5 -1.3 -1.3 -0.4 -0.4  5.5  1.1 -0.4 -0.4 -0.   3.2 -0.1  1.8  6.9 -0.6 -0.1 -0.  -0.8  0.2  3.7 -0.7  0.8 -0.5 -0.5 -0.5  0.1 -0.8 -0.  -0.9  0.  -0.3 -0.3  1.1 -0.  -0.1  2.2 -0.1 -0.2 -1.  -0.1 -0.3 -0.1 -0.2 -0.   4.6 -0.4 -0.4  0.  -0.3  5.8  2.7 -0.3 -0.4 -0.6 -0.7 -0.3 -0.3  1.2 -0.2  0.8 -0.1 -1.  -0.8 -0.3  0.7 -0.2 -0.3 -0.  -0.1 -0.  -0.6  3.3 -0.  -2.3 -0.7 -0.5 -0.3 -0.4  1.4 -0.9  0.1 -0.9 -0.2 -0.3 -0.3  7.  -0.4  0.3 -0.4 -3.2 -0.   5.7  0.1 -1.8 -0.  -0.6 -0.2 -0.5 15.7 11.6 -0.3 -0.1 -0.4 -0.9  1.  -0.9 -0.3 -0.3 -0.4 -0.2 -0.5 -0.2  6.1 -0.1  0.4 -0.2  1.8  0.2 -0.2 -0.4 -0.1 -0.4 -1.2 -0.6 -0.4  2.7 -0.5 -0.2 -0.4 -0.2  0.4 -0.4 -0.3 -0.4 -0.2 -0.3 -0.1 -0.1 -0.2 -1.6 -1.2 -0.   3.6 -0.4 -1.7  0.   0.1 -0.5 -0.2  1.   1.3  1.6  0.1  0.6 -0.2  0.1 -0.3 -1.   5.7  0.9  0.   0.1 -0.3 -0.1 -0.3 -0.2 -0.1 -0.3 -0.  -0.7 -0.4  0.  -1.1 -0.1 -0.2 -1.  -0.6  0.2 -0.  -0.5  2.4 -0.6 -0.5 -0.3 -0.2 -0.3 -0.4 -0.7  5.6 -0.5 -1.1 -0.4  0.7  1.1  0.7 -0.5 -0.5 -0.8  3.3  4.4  0.3  0.8  1.3  0.2  0.5  0.  -0.2 -0.1 -0.4 -1.2  0.2 -0.3 -1.  -0.1 -1.3  0.1 -0.9 -0.  -0.1  9.7]
vy_50sample [[6 0 5 9 9 8 8 2 3 7]
 [1 5 3 0 8 6 7 2 9 4]
 [6 9 4 7 0 3 5 2 1 8]
 [7 2 3 5 1 9 0 4 6 8]
 [4 8 8 6 2 1 7 0 5 3]
 [7 4 0 6 3 8 5 5 2 1]
 [7 9 1 5 5 6 2 8 4 3]
 [5 7 0 4 2 3 1 8 6 9]
 [6 5 7 0 4 2 9 3 1 8]
 [2 3 6 5 8 1 4 7 9 0]]
vt_50sample [[6 0 5 4 9 8 1 2 3 7]
 [1 5 0 3 8 6 7 2 9 4]
 [6 9 4 7 0 3 5 2 1 8]
 [7 2 3 5 1 9 4 0 6 8]
 [4 8 6 9 2 1 7 0 5 3]
 [7 4 6 0 3 8 9 5 2 1]
 [7 9 1 0 5 6 2 8 4 3]
 [5 7 4 0 2 3 1 6 8 9]
 [6 5 7 0 4 2 9 3 8 1]
 [2 3 6 5 8 1 4 7 9 0]]
Epoch 25310: Training cost= 0.3121, Training acc= 0.8295, Validation cost= 0.3121, Validation acc= 0.8296
Epoch 25320: Training cost= 0.3327, Training acc= 0.8295, Validation cost= 0.2449, Validation acc= 0.8296
Epoch 25330: Training cost= 0.3010, Training acc= 0.8295, Validation cost= 0.2581, Validation acc= 0.8297
Epoch 25340: Training cost= 0.2626, Training acc= 0.8295, Validation cost= 0.2531, Validation acc= 0.8297
Epoch 25350: Training cost= 0.3374, Training acc= 0.8295, Validation cost= 0.2878, Validation acc= 0.8297
Epoch 25360: Training cost= 0.3357, Training acc= 0.8296, Validation cost= 0.2815, Validation acc= 0.8297
Epoch 25370: Training cost= 0.3032, Training acc= 0.8296, Validation cost= 0.3060, Validation acc= 0.8298
Epoch 25380: Training cost= 0.3097, Training acc= 0.8296, Validation cost= 0.3011, Validation acc= 0.8298
Epoch 25390: Training cost= 0.2763, Training acc= 0.8296, Validation cost= 0.3225, Validation acc= 0.8298
Epoch 25400: Training cost= 0.2409, Training acc= 0.8296, Validation cost= 0.2788, Validation acc= 0.8298
tm  [ 0.4 -0.5  3.4 -1.  -1.3 -0.1 -0.3 -0.3 -0.3  1.3  3.6 -1.   0.4 -0.2  6.9  6.2 -0.1 -0.3 -0.3 -0.7 -0.6 -0.4  1.9 -0.4 -0.7 -0.7 -0.4 -0.2 -0.   0.6 -1.  -0.1 -0.7 -1.1  0.1 -0.9 -0.1  4.6  1.2 -0.5 -0.3  5.3 -0.3  2.1 -0.4 -0.2 -0.5 -0.9  2.2 13.4 -0.1 -0.1 -1.  11.8 -0.8 -0.7 -0.3  2.7  1.7  3.9 -0.4 -0.1 -1.2  0.5 -0.6 -0.2 -0.1  0.9  0.9 -0.4 -0.5 -1.3 -0.5 -0.2 -4.3  0.6 -0.9  0.4 -0.5 -0.3 -4.3 -0.3 -0.3 -0.1 -1.4  6.8  2.4 -0.1 -0.5 -0.3 -0.3 -0.2 -0.2 -0.4 -0.7  0.   0.3 -2.  -0.3 -0.7 -0.6  6.2 -0.6  0.  -0.2 -0.4 -2.4 -0.8  0.9 -0.6  1.5  0.8 -0.2 -0.9 -0.3  6.2 -0.4 -0.1 -0.  -0.2 -0.6  0.7 -0.4 -0.6 -0.5  8.2 -0.5 -3.   1.8 -0.6  1.9 -0.9 -0.3 -0.2 -2.4 -3.8 -0.5 -0.2 -0.2 -0.3 -1.4 -0.4 -0.8  0.1 -0.4  0.  -0.2 -0.1  1.2 -0.   0.4 -0.4  4.7 -0.  -0.3 -0.2  0.1  0.5 -0.  -0.2 -0.2 -1.1 -0.2 -0.2 -0.3  1.6  0.7 -0.1 -0.4 -0.3  0.1 -0.   0.1 -0.1  0.3 -0.  -0.3 -1.1  0.3 -0.5 -1.7  0.3 -0.1 -0.8 -0.3 -0.1  2.2 -0.7 -0.3 -0.2 -0.2 -0.3 -0.5 -0.5  4.5 -1.  -1.3  0.4 -0.1 -0.2 -0.3  0.2 -0.2 -0.7 -0.2 -2.8 -0.   0.1  3.6 -0.   0.7  2.3 -0.6 -1.3 -0.3 -0.3 -0.2 -0.7 -0.4 -0.5 -0.2 -0.3 -0.3 -1.3  2.8  3.2  2.7  0.1 -0.1  4.5 -1.5  1.6 -0.4  1.5 -0.8 -0.5  1.1 -1.9  0.5 -2.3 -0.2 -1.2 -0.2  0.6 13.4  2.8  0.2 -0.5 -0.5 -0.1 11.3 -0.2  0.7 -0.4 -2.   5.7]
ty_50sample [[2 8 5 7 4 9 6 0 1 3]
 [3 0 9 1 8 4 2 5 6 7]
 [6 4 9 1 3 5 8 7 2 0]
 [3 4 2 5 8 0 7 1 9 6]
 [2 7 6 8 3 0 1 9 5 4]
 [6 9 2 7 4 0 8 5 3 1]
 [7 6 2 4 0 8 3 3 1 1]
 [8 2 6 5 0 1 7 9 4 4]
 [1 3 6 9 4 7 5 2 8 0]
 [0 6 2 3 7 4 8 9 5 1]]
tt_50sample [[2 8 7 5 4 9 6 0 1 3]
 [3 0 9 1 8 4 2 5 6 7]
 [6 4 9 1 3 5 8 7 2 0]
 [3 4 2 5 8 0 1 7 9 6]
 [2 7 6 8 3 0 1 9 5 4]
 [6 9 2 7 4 8 0 5 3 1]
 [7 6 2 4 0 8 9 3 5 1]
 [8 2 6 5 0 1 7 9 4 3]
 [1 3 6 9 4 7 5 2 8 0]
 [0 6 2 3 7 4 8 9 5 1]]
vm  [-0.5 -0.5 -2.9 -3.8 -1.1  0.6 -0.3 -0.1 -0.2 -0.5  3.  -0.1 -0.3 -0.4  3.  -0.5 -0.5 -0.6 -0.5  4.4 -1.2 -0.2 -0.3  0.2 -1.4  3.5 -0.2 -0.4 -1.3 -2.3  4.  -0.2 -0.3 -1.6 -0.5 -0.   2.   1.8 -1.9 -0.6  1.4  4.   0.9  4.8 -0.4 -0.3 -3.4 -0.2  2.2 -0.9 -0.9 -0.2  0.2  8.7 -0.5 -0.2 -0.8  3.   3.  -1.   6.7 -0.3  0.4  1.4 -0.5 -0.1 -0.2  0.9  1.2 -0.1 -0.2  0.9 -0.4 -0.2 -6.4 -0.7 -0.5 -0.2  0.2 -0.1 -2.6  1.   0.7  0.6 -0.6  4.4  3.4 -0.4  0.2 -0.6 -0.1 -0.2 -0.   0.  -0.4  0.3 -0.2 -2.8 -0.2 -0.4  1.7 -1.8 -0.3 -0.2 -0.1  0.5 -2.8  3.8  1.4  3.6 -0.6 -0.1 -0.2 -0.9  3.2 -0.9 -0.4  0.7 -0.1  0.1 -0.  -1.8 -0.2  0.3 -0.5  3.6 -0.  -1.6  6.6  8.3 -0.2 -0.3 -0.2 -0.4  5.1  0.3 -0.3  0.1  0.4 -0.8  1.9 -0.8 -0.3  0.4 -0.3 -0.2 -0.3 -0.1  8.4 -0.4  3.1 -0.2  0.3  0.6 -0.2  0.5 -0.5 -0.   2.8 -0.4 -0.3 -1.  -0.4 -0.1 -0.1 -0.6 -0.3 -0.2  0.6 -0.3 -0.2  0.8  0.3  0.3 -0.2 -2.  -0.7 -0.7  5.4 -0.5 -1.7 -0.4 -0.3 -1.6  0.3  0.2 -0.1  0.3 -0.3  6.8 -0.3 -0.3  0.5 -1.4 -1.7 -1.4 -1.7 -0.5 -0.2  0.5 -0.3 -0.2 -0.5 -0.8 -0.2 -3.8 -0.2 -0.3 -3.6 -0.  -0.5 -0.6 -1.   1.1 -0.6 -0.6 -1.2 -1.  -0.5 -0.1 -0.6  0.1  0.  -0.7 -1.  -0.8 -1.1 -0.4  0.2  3.  -0.6 -0.1 -0.4 -2.3  2.3  5.6  0.6 -1.8  2.8 -6.3 -0.1 -2.6 -0.3  0.   9.8  5.5 -0.3 -0.5 -1.2 -0.1  6.6 -0.2 -1.1 -0.2  3.7 -2.3]
vy_50sample [[5 4 0 3 1 2 8 6 7 9]
 [1 7 8 6 0 5 4 3 9 2]
 [1 3 0 7 9 8 4 6 2 5]
 [5 7 8 9 2 1 6 4 4 0]
 [0 5 7 1 8 4 6 6 3 2]
 [0 0 0 2 7 1 8 6 5 3]
 [7 9 8 2 3 6 0 1 5 4]
 [1 8 6 4 0 2 3 5 9 7]
 [2 5 0 1 7 8 9 3 6 4]
 [3 2 5 4 4 0 7 6 9 8]]
vt_50sample [[5 4 0 3 1 2 8 6 7 9]
 [1 7 8 6 0 5 4 3 9 2]
 [3 1 0 7 9 8 4 6 2 5]
 [5 7 8 9 2 1 6 3 4 0]
 [0 5 7 1 8 4 9 6 3 2]
 [9 0 4 2 7 1 8 6 5 3]
 [7 9 8 2 3 6 0 1 5 4]
 [1 8 6 4 0 2 3 5 9 7]
 [2 5 0 1 7 8 9 3 6 4]
 [3 2 5 4 1 0 7 6 9 8]]
Epoch 25410: Training cost= 0.3099, Training acc= 0.8297, Validation cost= 0.3161, Validation acc= 0.8298
Epoch 25420: Training cost= 0.3256, Training acc= 0.8297, Validation cost= 0.3323, Validation acc= 0.8299
Epoch 25430: Training cost= 0.3142, Training acc= 0.8297, Validation cost= 0.2564, Validation acc= 0.8299
Epoch 25440: Training cost= 0.3079, Training acc= 0.8297, Validation cost= 0.2790, Validation acc= 0.8299
Epoch 25450: Training cost= 0.2996, Training acc= 0.8298, Validation cost= 0.3698, Validation acc= 0.8299
Epoch 25460: Training cost= 0.3432, Training acc= 0.8298, Validation cost= 0.3111, Validation acc= 0.8299
Epoch 25470: Training cost= 0.3228, Training acc= 0.8298, Validation cost= 0.2901, Validation acc= 0.8300
Epoch 25480: Training cost= 0.3288, Training acc= 0.8298, Validation cost= 0.4140, Validation acc= 0.8300
Epoch 25490: Training cost= 0.3137, Training acc= 0.8298, Validation cost= 0.3088, Validation acc= 0.8300
Epoch 25500: Training cost= 0.2956, Training acc= 0.8299, Validation cost= 0.2650, Validation acc= 0.8300
tm  [-1.5 -1.6  7.4  6.3 -2.1 -0.  -0.4  0.4  1.9  1.6 -1.2 -0.6 -0.1 -0.2  6.2 -1.8 -0.8 -0.3 -0.1 -0.  -0.9 -0.2  2.  -0.1 -0.7  3.4 -0.4  0.1 -1.7 -3.  -1.2 -0.1 -0.8  2.5  1.  -0.6  0.   2.1  4.4 -0.3 -0.1  3.9 -0.8  0.2 -0.2 -0.1 -0.6 -0.3 -0.7  8.  -0.3 -0.1 -0.6  1.9  3.2 -0.5 -0.9  5.8  6.7  4.9  5.5 -0.2 -0.2  1.9 -0.4  0.5 -0.  -0.   0.8 -0.3 -0.2  4.3 -0.3 -0.1 -3.6 -0.1 -0.4 -0.1 -0.1  0.4 -1.9 -0.2 -0.2 -0.1  1.3  4.8 -1.8 -0.1 -0.4 -0.2  0.1 -0.6 -0.5 -1.6 -0.2 -0.2  0.4 -2.6 -0.1 -0.4 -0.9  6.5  0.3 -0.1 -0.2 -0.4 -1.6 -0.9 -0.4 -0.4 -0.2  0.8 -0.  -0.7  8.6 -2.8 -0.2  2.5 -0.2 -0.3 -0.2  0.9  0.2  0.4 -0.2  7.5 -0.6  0.8  5.5 -0.4 -0.6 -0.6 -0.6 -0.4 -3.6 -3.1  0.3 -0.1 -0.3 -0.4  0.5 -1.3 -0.3 -0.2 -0.1 -0.1 -0.2 -0.2 -0.3 -0.3 -0.5 -0.1 -0.1  0.6 -0.2 -0.2  0.4 -0.2  3.1 -0.1  0.5 -1.7 -0.2 -0.2 -0.3 -0.5 -0.3  1.9 -0.4 -0.2 -0.1 -0.2 -0.  -0.1 -0.1  1.3  0.9 -0.5 -0.4 -0.3 -1.  -0.4 -0.2 -1.3 -0.1 -0.5 -0.6 -0.6  0.2  8.4 -0.2 -0.2 -0.5 -0.4 -1.4 -1.3 -1.2 -1.4  0.   0.1 -0.3  0.  -0.3 -0.5 -0.  -2.2 -0.3 -0.2  1.9  0.2 -0.2 -1.4 -0.5  3.3 -1.2 -0.3  1.4 -0.9 -0.3 -0.3 -0.6 -0.4 -0.4 -1.2  0.9 -1.2 -1.1  2.   1.1  0.6 -0.6 -0.3 -0.   0.5  4.2 -1.8  3.1 -1.2  3.4 -1.3 -0.2 -0.6 -0.1 -0.2  7.   1.1 -0.  -0.2 -1.2 -0.2  4.2 -0.1  3.4 -0.2 -0.2  3.8]
ty_50sample [[0 1 7 8 5 2 9 6 6 4]
 [9 4 8 6 7 0 2 1 3 5]
 [9 9 9 8 1 2 7 6 4 3]
 [6 1 0 9 2 3 7 8 4 5]
 [7 6 9 4 3 5 1 8 0 2]
 [3 2 8 7 6 0 1 4 9 5]
 [7 2 2 3 4 5 1 6 9 8]
 [8 0 5 2 1 1 9 4 6 3]
 [0 5 6 1 8 4 3 2 9 7]
 [4 0 8 1 9 2 5 7 3 6]]
tt_50sample [[0 1 7 8 5 2 9 3 6 4]
 [9 8 4 6 7 0 2 1 3 5]
 [9 0 5 8 1 2 7 6 4 3]
 [6 1 9 0 2 3 8 7 4 5]
 [7 6 9 4 3 5 1 8 2 0]
 [3 2 8 7 6 1 0 4 9 5]
 [7 2 0 3 4 5 1 6 9 8]
 [8 0 5 2 1 7 9 4 6 3]
 [0 5 6 1 8 4 3 2 9 7]
 [4 1 0 8 9 2 5 7 3 6]]
vm  [-1.2 -1.5  7.4  2.2 -2.2  0.  -0.3  0.2  1.3  0.4  0.2 -0.1 -0.6 -0.5  8.7 -2.3 -0.4 -0.4  0.3  2.9 -0.6 -0.  -0.2  0.2 -1.2  5.2 -0.3 -0.2 -1.9 -3.5 -0.6 -0.1 -0.6  5.9 -0.  -0.5  0.8 -0.3 -1.4 -0.5 -0.2  2.3 -0.4 -0.8 -0.3 -0.3 -2.4 -0.1 -0.8 -0.5 -0.3 -0.1 -0.3  3.5  2.8 -0.8 -1.1  7.1  5.2  3.4  8.7 -0.1  1.   0.9 -0.2  0.9  0.3 -0.2  0.9 -0.2 -0.2  5.5 -0.3 -0.  -5.7 -0.  -0.2  0.9 -0.3 -0.2 -1.4 -0.2  0.5 -0.5  0.6  2.6 -1.9 -0.2 -0.2 -0.3 -0.3 -0.7 -0.3 -0.9 -0.2 -0.1  0.5 -2.7 -0.2 -0.5 -0.4  3.5  0.6 -0.  -0.4  0.6 -2.3 -0.3  0.2  2.1 -0.2  1.  -0.1 -0.3  7.5 -3.  -0.3  2.7  0.3  0.1 -0.3 -1.2 -0.2  0.9 -0.2 10.3 -0.5 -0.2  4.3  4.4 -0.6 -0.2 -0.9 -0.2 -1.7  3.1 -0.1 -0.2  0.2 -0.4  1.3 -1.4  0.2 -0.2 -0.2  0.7 -0.2 -0.3  0.8 -0.4 -0.4 -0.1 -1.2  1.2 -0.6 -0.2 -0.4 -0.4  1.4 -0.2  0.1 -1.1  0.3 -0.2 -0.3 -0.9 -0.6  0.2 -0.3 -0.2 -0.4 -0.1 -0.3 -0.5 -0.1  0.5 -0.6 -0.5  4.2 -0.1 -1.  -0.4 -0.  -1.6  0.4 -0.3 -1.  -0.5  0.6  9.  -0.1 -0.2  0.3 -0.7 -2.8 -0.8 -1.7 -1.5 -0.2  0.1 -0.2 -0.1 -0.1 -0.3 -0.1 -2.6 -0.1 -0.5 -1.5 -0.3 -0.4 -1.9 -0.1  4.5 -1.  -0.3  3.4 -0.7 -0.3 -0.4 -0.5 -0.3 -0.2 -1.1  0.3 -1.9 -1.7  0.9 -0.  -0.2 -0.4  0.7 -0.4 -1.1  3.5 -1.9  1.9 -1.9  2.1 -3.  -0.  -1.3 -0.2 -0.2  5.5  3.2 -0.2 -0.3 -0.8 -0.1  3.2 -0.1 -0.9 -0.1  2.6 -1.1]
vy_50sample [[0 1 7 5 3 6 8 2 9 4]
 [5 9 1 8 8 4 3 7 2 6]
 [4 2 3 9 6 1 0 8 7 5]
 [2 8 3 5 0 9 7 7 6 4]
 [5 2 0 6 8 7 7 3 1 4]
 [9 3 6 5 1 4 0 2 7 8]
 [8 2 5 7 0 6 6 3 1 4]
 [6 3 1 7 9 8 4 0 2 5]
 [5 3 0 1 9 8 4 4 7 7]
 [8 3 6 1 4 5 9 9 7 2]]
vt_50sample [[0 1 7 5 3 6 8 2 9 4]
 [5 9 1 8 0 4 3 7 2 6]
 [4 2 3 6 9 1 0 8 7 5]
 [2 8 3 5 0 9 7 1 6 4]
 [5 2 6 0 9 8 7 3 1 4]
 [9 3 6 5 1 4 0 2 7 8]
 [8 2 5 7 6 9 0 3 1 4]
 [6 3 1 7 9 8 4 0 2 5]
 [5 3 0 1 9 8 2 4 7 6]
 [8 3 6 1 4 5 9 7 0 2]]
Epoch 25510: Training cost= 0.2678, Training acc= 0.8299, Validation cost= 0.2444, Validation acc= 0.8300
Epoch 25520: Training cost= 0.2782, Training acc= 0.8299, Validation cost= 0.2496, Validation acc= 0.8301
Epoch 25530: Training cost= 0.2869, Training acc= 0.8299, Validation cost= 0.3216, Validation acc= 0.8301
Epoch 25540: Training cost= 0.2653, Training acc= 0.8299, Validation cost= 0.2615, Validation acc= 0.8301
Epoch 25550: Training cost= 0.3168, Training acc= 0.8300, Validation cost= 0.3060, Validation acc= 0.8301
Epoch 25560: Training cost= 0.2926, Training acc= 0.8300, Validation cost= 0.3107, Validation acc= 0.8302
Epoch 25570: Training cost= 0.3151, Training acc= 0.8300, Validation cost= 0.2624, Validation acc= 0.8302
Epoch 25580: Training cost= 0.3041, Training acc= 0.8300, Validation cost= 0.2619, Validation acc= 0.8302
Epoch 25590: Training cost= 0.2579, Training acc= 0.8301, Validation cost= 0.2547, Validation acc= 0.8302
Epoch 25600: Training cost= 0.2368, Training acc= 0.8301, Validation cost= 0.3139, Validation acc= 0.8303
tm  [-0.8  2.6  4.9 -2.  -1.5 -0.  -0.1 -0.2 -0.9 -1.2  6.5 -0.1 -0.1 -0.2 11.7  6.7 -0.  -0.5  0.5  2.9 -0.4 -0.3 -0.4  1.1 -1.6  0.5  0.3  0.   0.2 -0.6 -0.3 -0.1 -0.1  3.4 -0.7  0.2  2.8  4.4 -2.4 -0.4 -0.1  1.6  3.  -0.2 -0.3 -0.3 -3.1 -0.6 -0.5 -1.1 -0.7 -0.  -0.5 13.6 -1.4 -1.3 -0.7  8.6 -0.7  2.8  8.1 -0.4 -0.3  0.4 -0.1  1.6  0.6 -0.4 -0.1 -0.2  0.3 -1.1 -0.4 -0.7 -5.8  0.3 -0.4 -0.4 -0.5  0.4 -4.  -0.1  0.  -0.   0.3  4.  -0.6 -0.3 -0.  -0.2 -0.5 -0.1 -0.3  3.1 -0.2 -0.3  1.3 -2.3 -0.1 -0.4  5.6 -0.3  0.1 -0.3  0.3 -0.2 -3.4 -0.   1.8  4.8 -0.   0.4 -0.1 -0.5 -1.2  7.8 -0.2 -0.9 -0.2 -0.2 -0.3 -1.8 -0.   0.4 -0.2 14.  -0.  -3.6 -0.1 11.6 -0.4 -0.6 -0.4 -0.4 -1.2 -0.1 -0.2 -0.2 -0.1 -0.5 -0.9 -0.4 -0.7 -0.2  0.   0.5 -0.2 -0.2  5.5 -0.1 -0.1 -0.1 -0.  -0.3 -0.6 -0.1 -0.5 -0.   1.3 -0.6 -0.7 -0.5 -0.1 -0.1 -0.3 -0.4 -0.1 -0.4 -0.1 -0.1 -0.1  0.8 -0.2 -0.4 -0.2 -0.9 -0.7 -1.1  5.7 -0.3 -2.   0.6 -0.2 -1.7 -0.3 -0.3 -0.8 -1.  -0.2  1.6  0.1 -0.1  0.8 -1.3 -2.7  0.6 -1.9  2.2 -0.2 -0.4 -0.3  0.1  0.1 -0.5 -0.2 -4.7  0.2 -0.2 -2.2  0.  -0.3  1.4 -0.1  2.6 -0.5 -0.3  1.8 -0.5 -0.2 -0.6 -0.2 -0.2  0.4 -0.8 -0.7  3.2  2.5  0.5  1.1 -0.  -0.9  3.2 -0.4 -1.4 -0.5 -0.9 -0.3 -2.3 -0.2 -6.3 -0.  -2.7 -0.2 -0.  12.7  7.9 -0.3 -0.1 -0.4 -0.5 10.2 -0.1 -1.9 -0.2 -0.1 -3.2]
ty_50sample [[5 2 3 1 7 8 6 4 0 9]
 [8 1 7 3 6 5 5 0 4 4]
 [5 5 3 7 6 1 4 0 8 2]
 [7 8 9 2 1 4 3 0 6 5]
 [9 7 8 3 2 6 5 0 1 1]
 [1 6 4 0 5 7 7 2 8 3]
 [7 2 9 5 0 3 4 1 6 8]
 [7 2 9 0 4 5 1 6 8 3]
 [0 1 5 8 8 7 4 2 6 6]
 [2 4 3 0 1 7 5 9 8 6]]
tt_50sample [[5 2 3 7 1 8 6 4 0 9]
 [8 1 7 3 6 5 2 0 9 4]
 [5 9 7 3 6 1 4 0 8 2]
 [7 8 9 2 1 4 3 0 6 5]
 [9 7 8 3 2 6 5 0 1 4]
 [1 6 4 0 5 9 7 2 8 3]
 [7 2 9 5 0 3 4 1 6 8]
 [7 2 9 0 4 5 1 6 8 3]
 [0 1 5 8 3 7 4 2 9 6]
 [2 4 3 0 1 7 5 9 8 6]]
vm  [-0.8 -0.8 -1.3  5.5 -0.8 -0.2  0.2 -0.2 -0.4  0.6 -3.4 -0.1 -0.5 -0.2 -1.8 -2.3 -0.4 -0.3 -0.5 -0.5 -1.1 -0.5  0.1  0.3 -0.7  2.4 -0.4 -0.1 -1.8 -2.9 -1.2 -0.4 -0.9 -4.7  0.1 -0.2  2.8 -0.3  3.3 -0.5 -0.1 -0.1 -0.2 -0.1 -0.6 -0.2  1.5 -0.1 -0.6 -0.  -0.5 -0.1 -0.8 -0.7  1.3  3.1 -0.8  5.   1.9  3.7  2.8 -0.2 -0.8 -0.  -0.4 -0.  -0.3  0.2  1.4 -0.4 -0.4  4.6 -0.4 -0.4 -2.9 -0.5 -0.3 -0.3 -0.2 -0.  -2.   0.7 -0.4  1.2 -0.1 -0.3 -0.5 -0.   0.3 -0.5 -0.1 -0.5 -0.2 -0.  -0.3 -0.2 -0.2 -1.9  0.  -0.4 -0.1 -2.8 -0.5 -0.2  0.1 -0.1 -1.7 -0.7 -1.1 -0.9  0.2 -0.2 -0.1 -0.   5.5 -2.9 -0.9  0.9 -0.2 -0.  -0.4  2.6 -0.2 -0.3 -0.2 -1.9 -0.3  5.6  3.6  6.5  0.2 -0.2 -0.1  0.5  8.7 -2.4 -0.3  0.1  0.6 -0.5  1.6 -1.6  0.5 -0.5 -0.3 -0.4 -0.5 -0.1  6.4 -0.8 -0.6  0.2  2.3  0.7 -0.1 -0.2  0.9 -0.5 -0.2 -0.5 -0.3 -1.1  0.2 -0.1 -0.2 -0.4 -0.4  0.3 -0.6  0.3 -0.4 -0.1 -0.2  0.3 -0.3 -1.7 -0.3 -0.6  0.1 -0.3 -1.4 -0.3 -0.3 -1.3  0.4  0.  -0.1  2.   0.3  8.6 -0.2 -0.1 -0.7 -1.3 -0.2 -0.6 -1.4 -0.7 -0.3 -0.1 -0.2 -0.1 -0.4 -0.3 -0.1 -2.  -0.2 -0.2  1.8  0.3 -0.7 -1.9 -0.6  0.5 -0.8  0.5  1.2 -0.7 -0.6  0.2 -0.5 -0.5 -0.3 -1.4 -0.7 -0.7 -1.5 -0.  -0.3  1.6 -1.   0.8 -0.3  0.7  3.1  3.   3.5 -1.   2.7 -1.6 -0.1 -0.7 -0.4 -0.3  7.7 -0.3  1.5 -0.4 -0.9 -0.3  4.8  0.1  2.3 -0.1  5.6 -1.2]
vy_50sample [[0 3 8 5 1 9 6 4 2 7]
 [4 7 1 3 2 5 6 9 8 0]
 [4 7 0 1 5 6 2 8 3 9]
 [5 1 1 8 0 2 7 7 3 6]
 [7 9 3 4 6 5 0 0 8 8]
 [5 7 8 4 3 9 0 6 6 1]
 [9 2 1 6 8 0 7 5 4 3]
 [4 7 9 2 3 1 8 0 6 5]
 [2 1 7 3 6 5 8 8 0 9]
 [8 9 6 3 5 0 1 7 4 2]]
vt_50sample [[0 3 8 5 1 9 6 4 2 7]
 [7 4 1 2 3 5 6 9 8 0]
 [7 4 0 1 5 6 2 8 3 9]
 [5 1 9 8 0 2 7 4 3 6]
 [7 9 3 6 4 5 0 1 2 8]
 [5 7 8 4 3 9 0 2 1 6]
 [9 2 1 6 0 8 7 5 4 3]
 [4 9 7 2 3 1 0 8 6 5]
 [2 1 7 3 6 5 8 4 0 9]
 [8 9 6 3 5 0 1 7 4 2]]
Epoch 25610: Training cost= 0.2901, Training acc= 0.8301, Validation cost= 0.3349, Validation acc= 0.8303
Epoch 25620: Training cost= 0.2993, Training acc= 0.8301, Validation cost= 0.2986, Validation acc= 0.8303
Epoch 25630: Training cost= 0.2956, Training acc= 0.8301, Validation cost= 0.3132, Validation acc= 0.8303
Epoch 25640: Training cost= 0.3301, Training acc= 0.8302, Validation cost= 0.3091, Validation acc= 0.8303
Epoch 25650: Training cost= 0.3092, Training acc= 0.8302, Validation cost= 0.2443, Validation acc= 0.8304
Epoch 25660: Training cost= 0.2884, Training acc= 0.8302, Validation cost= 0.2810, Validation acc= 0.8304
Epoch 25670: Training cost= 0.2861, Training acc= 0.8302, Validation cost= 0.2475, Validation acc= 0.8304
Epoch 25680: Training cost= 0.2823, Training acc= 0.8303, Validation cost= 0.2574, Validation acc= 0.8304
Epoch 25690: Training cost= 0.2322, Training acc= 0.8303, Validation cost= 0.2707, Validation acc= 0.8304
Epoch 25700: Training cost= 0.2923, Training acc= 0.8303, Validation cost= 0.2779, Validation acc= 0.8305
tm  [-1.  -0.1  3.9 -2.4 -1.6 -0.2 -0.2 -0.3 -0.1 -0.5  8.  -0.3 -0.2 -0.3 12.   7.4  0.7 -0.5 -0.2  2.1 -0.7 -0.1 -0.6 -0.2 -1.3 -0.1 -0.2 -0.1  1.5 -1.7  0.5 -0.3  0.1  4.9 -0.4 -0.2 -0.1  6.9 -0.7 -0.4  0.9 -2.5 -1.   2.2 -0.4 -0.4 -2.3 -1.2 -1.  -1.9 -0.7 -0.2 -0.6 14.3 -1.8 -1.3 -0.6 -0.5  4.9  0.6  7.7 -0.4 -0.1 -0.1  0.7 -0.4 -0.2  0.3 -0.7 -0.6 -0.2 -1.4 -0.4 -0.5 -6.3  0.6 -0.3 -0.2 -0.5 -0.  -3.   0.3 -0.2 -0.1 -0.1 -1.9 -0.9 -0.2 -0.  -0.4 -0.6 -0.2 -0.1 -0.5 -0.5 -0.5 -0.3 -2.5 -0.2 -0.2  3.  -0.6 -0.  -0.  -0.2 -0.3 -3.5  0.6  2.4  3.9  0.8 -0.2 -0.2 -1.1 -0.   7.2  0.2  0.   0.  -0.3 -0.5 -1.7 -0.  -0.3 -0.2 13.4 -0.1 -3.9  2.9 11.6 -0.9 -0.5 -0.2 -0.  -3.5 -1.5 -0.2 -0.2  0.6 -0.6 -1.2 -0.2 -1.2 -0.3  0.2 -0.2 -0.1 -0.1 -1.3 -0.1  0.9 -0.3 -0.6 -0.6 -0.2  0.  -0.6 -0.   2.2 -0.6 -0.7 -1.8 -0.  -0.1  0.3 -0.2 -0.5  2.4 -0.3 -0.4 -0.3 -0.  -0.3 -0.  -0.3  2.1 -0.3 -1.3  2.5 -0.2 -0.1 -0.  -0.3 -1.4 -0.7 -0.4 -0.9 -0.9 -0.6  5.  -0.1 -0.3 -0.3 -1.1 -2.9 -0.7 -1.9 -0.2 -0.4 -0.2 -0.1 -0.2 -0.2 -0.5 -0.3 -3.8  0.8 -0.1  3.3 -0.1 -0.2  3.2 -0.6  3.7 -0.4  0.3 -0.6 -0.8 -0.9 -0.1 -0.4 -0.3 -0.1 -0.8 -1.7  3.2  1.6  1.8 -0.1  1.1 -0.9  2.5 -0.3  2.3 -1.2 -0.6 -0.  -2.6 -0.5 -1.3 -0.3 -0.6 -0.3 -0.3 10.1  5.1 -0.4 -0.5 -0.7 -0.2  7.1  0.3 -0.4 -0.2 -0.4 -3.5]
ty_50sample [[2 3 1 7 4 8 5 6 0 9]
 [2 0 0 8 6 5 4 3 1 7]
 [3 5 2 4 9 7 6 1 8 0]
 [9 6 4 0 7 3 8 1 5 2]
 [9 3 4 1 0 0 8 5 2 7]
 [5 4 1 9 2 0 6 3 8 7]
 [1 5 9 8 8 7 3 4 0 6]
 [5 9 8 6 4 1 0 2 3 7]
 [4 0 1 9 5 6 6 7 8 3]
 [3 2 9 0 1 5 8 4 6 7]]
tt_50sample [[2 3 1 7 4 8 5 6 0 9]
 [2 9 0 8 6 5 4 3 1 7]
 [3 5 2 4 9 7 6 1 8 0]
 [9 6 4 7 0 3 8 1 5 2]
 [9 3 4 1 6 0 8 5 7 2]
 [5 1 4 9 2 6 0 3 8 7]
 [1 5 9 8 7 2 3 4 0 6]
 [5 9 8 6 4 1 0 2 3 7]
 [4 0 1 9 5 6 2 7 8 3]
 [3 2 9 0 1 5 8 4 6 7]]
vm  [-1.2 -1.2  2.4 11.8 -1.2 -0.2 -0.2 -0.2  0.8  0.8 -0.9 -0.  -1.  -0.1 -1.5 -2.2 -0.8 -0.2  1.1 -1.1 -0.6  0.4  1.8 -0.2 -0.9  2.4 -0.  -0.3 -0.9 -2.8  0.   0.3  0.6  2.  -0.  -0.4  0.4 -0.8  2.7 -0.3 -0.1  4.8 -0.3 -0.7 -0.5 -0.2  7.2 -0.1 -1.9  2.3 -0.4 -0.   0.6 -2.1 -0.4  3.6 -0.7  6.   3.5  2.9  3.7 -0.3 -0.  -0.5  3.9 -0.9 -0.2  2.   1.9 -0.3 -0.1  3.8  0.5 -0.5 -1.5 -0.2  0.7 -0.5 -0.4 -0.3 11.  -0.3 -0.1 -0.3  1.   4.2 -1.8 -0.2 -0.4  0.4 -0.2 -0.5 -0.5 -1.1 -0.4 -0.4 -0.5 -1.2 -0.1 -0.4 -0.3  2.6  0.9 -0.1  0.  -0.2 -1.1  0.3 -0.2 -1.1 -0.1 -0.2 -0.1 -0.2  6.1 -1.8 -0.   0.5 -0.2  3.3 -0.4  4.6 -0.1 -0.3 -0.3 -1.8 -0.2 10.8  3.7 -1.5 -0.6 -0.4 -0.6  0.2  5.4  7.2  0.6 -0.  -0.2 -1.   1.5 -0.7  0.7 -0.2 -0.2 -0.3 -0.3 -0.1  4.3 -0.6 -1.  -0.1 -1.1  0.3 -0.2 -0.5  0.9  0.3 -0.5 -0.2 -0.4 -0.7  0.5 -0.1 -0.6 -0.6 -0.4  0.7 -0.5  0.  -0.5 -0.2 -0.1 -0.2 -0.2 -1.  -1.2 -0.3 -0.   0.9 -1.2 -0.6 -0.  -1.4  0.9 -0.3 -0.5 -0.4  2.   8.6 -0.3 -0.6 -0.9 -1.1 -0.7 -0.4 -0.6 -1.2 -0.3  0.3 -0.  -0.5 -0.4 -0.3 -0.7 -0.2 -0.1 -0.1 -3.  -0.2 -0.3 -1.  -0.3  3.9 -0.5 -0.2  3.2 -0.8 -0.1  1.2 -0.3 -0.3  1.2 -1.3  2.  -1.2 -2.1  0.5  0.3 -0.5 -0.4  0.2  0.1 -1.7  0.9 -0.4  2.6 -0.7  1.1 -0.7 -0.2 -0.4 -0.3 -0.3 -2.1 -1.9 -0.  -0.3 -1.2  0.3 -3.2 -0.3  2.5 -0.4  3.2  8.8]
vy_50sample [[0 0 5 9 6 8 7 3 4 2]
 [4 3 7 6 0 1 2 8 9 5]
 [0 2 5 3 6 7 8 1 4 9]
 [4 2 9 1 3 5 8 0 7 6]
 [8 9 6 2 0 1 5 3 4 7]
 [2 3 6 7 4 5 9 8 1 0]
 [2 5 7 1 3 4 0 8 6 9]
 [4 0 1 2 9 7 6 5 3 8]
 [6 1 5 4 9 9 7 3 0 8]
 [5 1 3 6 0 4 7 8 9 2]]
vt_50sample [[1 0 5 9 6 7 8 3 4 2]
 [4 3 7 6 0 1 2 8 9 5]
 [0 2 5 3 6 7 8 1 4 9]
 [4 2 9 1 3 5 8 0 7 6]
 [8 9 6 2 0 1 5 3 7 4]
 [2 3 6 7 4 5 9 8 1 0]
 [2 5 7 1 3 4 0 8 6 9]
 [4 0 1 9 2 7 6 5 3 8]
 [6 1 5 4 2 9 7 3 0 8]
 [5 1 3 6 0 4 7 8 9 2]]
Epoch 25710: Training cost= 0.2586, Training acc= 0.8303, Validation cost= 0.2846, Validation acc= 0.8305
Epoch 25720: Training cost= 0.3047, Training acc= 0.8303, Validation cost= 0.2928, Validation acc= 0.8305
Epoch 25730: Training cost= 0.2777, Training acc= 0.8304, Validation cost= 0.2801, Validation acc= 0.8305
Epoch 25740: Training cost= 0.2153, Training acc= 0.8304, Validation cost= 0.2977, Validation acc= 0.8306
Epoch 25750: Training cost= 0.3202, Training acc= 0.8304, Validation cost= 0.3274, Validation acc= 0.8306
Epoch 25760: Training cost= 0.2589, Training acc= 0.8304, Validation cost= 0.2818, Validation acc= 0.8306
Epoch 25770: Training cost= 0.3010, Training acc= 0.8305, Validation cost= 0.3022, Validation acc= 0.8306
Epoch 25780: Training cost= 0.2982, Training acc= 0.8305, Validation cost= 0.2538, Validation acc= 0.8306
Epoch 25790: Training cost= 0.2973, Training acc= 0.8305, Validation cost= 0.3187, Validation acc= 0.8307
Epoch 25800: Training cost= 0.3706, Training acc= 0.8305, Validation cost= 0.2985, Validation acc= 0.8307
tm  [-1.1  1.3  4.6 18.3 -1.6 -0.   0.  -0.1 -0.9 -0.8 -2.5 -0.2 -0.4 -0.2 -1.8 -0.6  0.2 -0.3 -0.3 -0.9 -0.3 -0.6  2.3 -0.1 -0.6  2.2 -0.1 -0.2 -0.8 -0.3 -1.6 -0.3 -0.5 -2.  -0.4  0.2  3.3 -0.8  3.9  0.5 -0.2  4.8  3.3 -1.5 -0.3  0.9  5.2  1.2  0.1  5.4 -0.5 -0.2  1.1 -2.  -0.2  2.7 -0.2 10.4 -1.3  6.2 -0.7 -0.1 -0.5 -0.1 -0.9  0.1 -0.2 -0.6  0.2 -0.2 -0.1  0.6 -0.  -0.1  2.3 -0.3 -0.  -0.2 -0.2  0.3  4.9 -0.2 -0.2 -0.  -0.4  5.8 -1.2 -0.2 -0.1 -0.1 -0.1 -0.  -0.   1.6 -0.3 -0.1  0.4 -0.6 -0.   0.4  2.6 -0.  -0.2 -0.1 -0.3  0.8  1.4 -1.4 -0.9 -2.  -0.6 -0.1 -0.  -0.1 -0.3 -0.1 -0.6 -1.  -0.3 -0.3  0.   7.9 -0.   0.9 -0.1 -2.   0.6 10.2 -0.3 -1.5  0.6 -0.5 -0.5 -0.5  7.2  1.7 -0.3 -0.1  0.7 -0.3  2.  -0.9  1.3  0.  -0.   0.2 -0.1 -0.1  5.7 -0.  -1.3 -0.2  2.1  1.3 -0.1 -0.  -0.4 -0.2 -0.6 -0.7 -0.   2.  -0.1 -0.2 -0.1  0.2 -0.  -0.4  0.6 -0.2 -0.5 -0.1 -0.1 -0.3  0.3 -1.1 -0.6  1.  -0.1  0.7 -1.9 -0.  -0.6 -1.6 -0.   0.   0.2 -0.4  0.9  1.2 -0.1 -0.5 -0.6 -0.4  5.6  1.9  3.1  0.7  0.2 -0.2 -0.4 -0.1 -0.2 -0.2  1.   3.9 -0.2 -0.2 -1.   0.1 -0.5 -0.1 -0.4  3.  -0.5 -0.6  5.9 -0.3 -0.3 -0.3 -0.6 -0.1 -0.1 -0.7  2.5  1.5 -1.7 -0.1 -0.4 -0.1 -0.3 -1.3 -0.4 -0.7  1.6 -0.9 -0.2  3.6  1.8  0.6 -0.3 -0.  -0.  -0.1 -0.5 -2.2 -0.4  0.7 -0.9 -0.5 -1.4 -0.3  2.7 -0.4  3.7  7.1]
ty_50sample [[5 9 8 8 0 1 3 7 2 4]
 [7 5 4 3 9 0 2 6 1 8]
 [9 3 7 4 6 8 0 1 2 5]
 [9 3 4 1 7 2 8 0 6 5]
 [0 7 1 3 9 8 5 2 6 4]
 [6 9 1 0 3 5 7 8 4 2]
 [2 8 1 7 7 0 3 5 9 6]
 [0 9 5 2 4 1 8 3 7 6]
 [1 2 3 4 8 7 5 0 6 9]
 [0 3 4 6 9 5 1 2 7 8]]
tt_50sample [[5 9 6 8 0 1 3 7 2 4]
 [7 5 4 3 9 0 2 6 1 8]
 [9 3 7 4 6 8 0 1 2 5]
 [9 3 4 1 7 2 8 0 6 5]
 [0 7 1 3 9 8 5 2 6 4]
 [6 1 9 0 5 3 7 4 8 2]
 [2 8 1 4 7 0 3 5 9 6]
 [0 9 5 2 4 1 3 8 7 6]
 [1 2 3 4 8 7 5 0 9 6]
 [0 3 4 6 9 5 1 2 7 8]]
vm  [-0.9 -0.4 -1.4 -0.2 -1.  -0.2 -0.3 -0.2 -0.7  0.7 -3.7 -0.6 -0.3 -0.2 -0.8 -0.7 -0.1  0.4 -0.1 -1.1 -0.7 -0.6  1.4 -0.1 -0.8  0.9 -0.4 -0.1 -1.  -0.9 -0.9 -0.3 -0.5 -4.4  0.  -0.   1.5  2.2  6.7 -0.1 -0.4  7.3  0.4  2.4 -0.5 -0.4  2.7 -0.4 -1.  15.  -0.7  0.  -1.1 -0.2 -0.3  2.1 -0.5  4.3  0.6  3.7  3.9  0.4 -1.  -0.4 -1.  -0.6 -0.1  0.3  1.6 -0.4 -0.2  2.7 -0.1 -0.1 -2.4 -0.2  0.4 -0.4 -0.5 -0.3 -2.9 -0.7 -0.3  0.2 -0.1  8.3 -0.6 -0.3 -0.4 -0.  -0.3 -0.3 -0.3 -0.3 -0.3 -0.1  1.1 -1.4 -0.2 -0.5 -0.3  4.7  0.6 -0.2 -0.1 -0.5 -1.4 -0.9 -1.3 -1.3 -0.2 -0.3 -0.1 -0.3  3.7 -1.2 -0.1 -0.5  0.   0.3 -0.3  4.6  0.7 -0.1 -0.3 -0.9 -0.4  3.6  1.3 -1.7 -0.5 -0.5 -0.4 -0.5 -0.3 -5.2 -0.2  0.2  0.3  0.8  0.2 -0.9 -0.2 -0.3 -0.2 -0.  -0.5 -0.3  5.4 -0.1 -0.1 -0.1  2.4  0.4 -0.3 -0.2  0.3 -0.7  1.7 -0.3  0.6 -1.3 -0.2 -0.2 -0.2 -0.4 -0.   0.2 -0.5 -0.1 -0.2 -0.3 -0.2 -0.3 -0.3 -1.2 -0.  -0.7 -0.8 -0.  -1.6  0.3 -0.1 -0.9 -0.2 -0.1 -0.3 -0.3  0.4  3.3 -0.4 -0.2 -0.8 -0.6 -0.6  0.4 -0.7 -0.3 -0.2 -0.1 -0.5 -0.  -0.2 -0.2 -0.3 -1.6 -0.1 -0.   2.9 -0.2  0.8 -1.3 -0.3  3.2 -0.1 -0.1 -0.6 -0.4 -0.  -0.5 -0.3 -0.3 -0.4 -1.2  2.7 -0.  -1.2  0.3 -0.5 -0.3 -1.2  1.1 -0.5  2.   2.5  2.2  1.6 -0.9 -0.1 -1.8 -0.3 -0.7  0.1 -0.6  9.4 -0.5  1.  -0.6 -0.9 -0.3  7.4 -0.2  4.8 -0.1 -0.6  9.4]
vy_50sample [[8 5 0 1 4 9 2 7 6 3]
 [6 5 3 2 9 0 0 4 8 1]
 [9 7 6 0 4 2 2 8 8 3]
 [2 1 3 7 0 5 5 4 6 9]
 [5 6 1 1 3 3 0 8 7 2]
 [3 1 6 2 0 4 7 5 9 8]
 [0 8 4 4 7 6 5 2 9 3]
 [2 9 9 3 7 5 5 4 0 6]
 [9 0 8 6 6 7 2 4 1 3]
 [0 7 4 3 1 6 8 2 9 5]]
vt_50sample [[8 5 0 1 4 9 2 7 6 3]
 [6 5 3 2 9 0 7 4 8 1]
 [9 7 6 0 4 1 2 8 5 3]
 [2 1 3 7 0 5 8 4 6 9]
 [5 6 4 1 3 9 0 8 7 2]
 [3 1 6 2 0 4 7 5 9 8]
 [0 8 7 4 6 1 5 2 9 3]
 [2 9 8 1 7 3 5 4 0 6]
 [9 8 0 5 6 7 2 4 1 3]
 [0 7 4 3 1 6 8 2 5 9]]
Epoch 25810: Training cost= 0.4055, Training acc= 0.8305, Validation cost= 0.3467, Validation acc= 0.8307
Epoch 25820: Training cost= 0.3323, Training acc= 0.8305, Validation cost= 0.2783, Validation acc= 0.8307
Epoch 25830: Training cost= 0.3190, Training acc= 0.8306, Validation cost= 0.3505, Validation acc= 0.8307
Epoch 25840: Training cost= 0.3029, Training acc= 0.8306, Validation cost= 0.2810, Validation acc= 0.8308
Epoch 25850: Training cost= 0.2663, Training acc= 0.8306, Validation cost= 0.2621, Validation acc= 0.8308
Epoch 25860: Training cost= 0.2597, Training acc= 0.8306, Validation cost= 0.2880, Validation acc= 0.8308
Epoch 25870: Training cost= 0.2536, Training acc= 0.8307, Validation cost= 0.3008, Validation acc= 0.8308
Epoch 25880: Training cost= 0.3030, Training acc= 0.8307, Validation cost= 0.2554, Validation acc= 0.8308
Epoch 25890: Training cost= 0.3024, Training acc= 0.8307, Validation cost= 0.2985, Validation acc= 0.8309
Epoch 25900: Training cost= 0.2965, Training acc= 0.8307, Validation cost= 0.3373, Validation acc= 0.8309
tm  [-0.5 -0.2  9.   1.9 -1.5  0.3 -0.  -0.2 -0.3 -0.5 -0.6 -0.4 -0.2 -0.2 11.9  3.9 -0.  -0.8 -0.4  2.5 -0.4 -0.3  1.5  0.9 -1.  -0.5 -0.2 -0.3  0.2  0.4 -1.4 -0.2  1.3  3.1 -0.7 -0.5 -0.1 -0.4 -4.3 -0.3  0.5  3.4  0.6 -1.5 -0.4 -0.2 -2.3 -0.4  1.6  5.1 -0.6 -0.2 -0.6  7.1 -1.1 -1.3 -0.6  8.7  0.4  6.2  2.5 -0.4 -0.2  0.8 -0.4  0.9  0.3 -0.2  0.7 -0.6 -0.4 -1.6 -0.5 -0.6 -5.5 -0.1 -1.1 -0.1 -0.1 -0.1 -4.2 -0.  -0.   0.8 -0.9  5.2 -0.6 -0.1 -0.3  0.  -0.1  0.5 -0.   0.2 -0.3 -0.2  0.5 -2.3  1.   0.1  1.7  3.6 -0.7 -0.  -0.2 -0.4 -2.6 -1.  -0.1  2.3  0.5  1.2 -0.1 -1.  -0.6  7.5 -0.6  0.3 -0.  -0.4 -0.  -1.4 -0.1 -0.2 -0.3 13.8  0.5 -1.5  1.3  4.6  1.6 -0.9 -0.4 -0.4  3.8  5.8 -0.  -0.2  1.  -0.7 -0.3 -0.4 -0.1 -0.3  0.2 -0.  -0.3  0.   2.  -0.2 -0.7 -0.2  2.6 -0.2 -0.4  0.1 -0.5 -0.1 -1.2  0.2 -0.3  2.2 -0.4 -0.1 -0.3  0.6  0.1 -0.1 -0.2 -0.4 -0.3  0.4 -0.3 -0.2 -0.2 -0.  -1.5 -0.8  8.5 -0.5 -1.6 -0.3 -0.2 -1.3 -0.4 -0.4  0.7 -1.  -0.2 -0.2  0.2 -0.5 -0.1 -0.8 -0.3 -0.8 -1.7 -0.1 -0.1 -0.3 -0.2 -0.4  0.2 -0.7 -0.3 -3.6 -0.2 -0.3 -0.8  0.5 -0.4  3.7 -0.3 -0.5 -0.5 -0.6  7.2 -0.6 -0.5 -0.3 -0.4 -0.2 -0.4 -1.3  2.7  3.8 -0.5 -0.4  0.9  4.6 -0.3  1.3 -0.3 -0.5 -0.9 -2.   1.  -2.1  1.9 -4.8 -0.1 -2.1 -0.2 -0.1 13.2  4.7 -0.3 -0.  -0.7 -0.2 11.2 -0.2 -3.  -0.  -0.  -1. ]
ty_50sample [[6 5 7 8 2 3 1 0 9 4]
 [0 1 4 4 9 2 6 8 3 7]
 [9 0 2 5 4 1 7 6 8 3]
 [9 8 6 5 7 4 2 1 3 0]
 [0 7 8 9 5 1 3 2 6 4]
 [6 1 3 4 5 7 0 9 2 8]
 [8 2 9 6 5 1 7 4 0 3]
 [4 4 2 7 7 3 6 1 5 8]
 [4 8 3 2 1 0 6 5 9 7]
 [2 1 4 6 6 9 8 3 5 0]]
tt_50sample [[6 5 7 8 2 3 1 0 4 9]
 [0 1 5 4 9 2 6 8 3 7]
 [9 0 2 5 4 1 7 6 8 3]
 [9 8 6 5 7 4 2 1 3 0]
 [0 7 8 5 9 1 2 3 6 4]
 [6 1 3 4 5 7 0 9 2 8]
 [8 2 9 6 5 1 7 4 0 3]
 [9 4 2 0 7 3 6 1 5 8]
 [4 8 2 3 1 0 6 5 9 7]
 [2 1 4 7 6 9 8 3 5 0]]
vm  [-1.2 -0.8 -1.6 -5.  -1.6 -0.1 -0.1 -0.1  0.9 -0.3 -0.8 -0.1 -0.6 -0.1  7.9 -0.2 -0.1 -0.3  0.2  4.  -1.1 -0.4  2.3 -0.3 -1.2  1.7 -0.4 -0.5 -0.5 -1.5  3.3 -0.3 -0.3 -0.1 -0.3 -0.3 -0.1  3.9  2.  -0.7 -0.4 -0.  -0.8  6.4 -0.6 -0.3 -3.1 -0.6 -0.6  5.3 -0.8 -0.1 -0.4  5.4 -1.  -0.9 -0.7 -2.1  6.3 -0.9  8.8 -0.   2.   0.6 -0.5 -0.4 -0.2  0.1  0.5 -0.4 -0.2 -0.1  1.3  0.4 -5.7 -0.4  0.5 -0.6  0.2 -0.1 -3.4 -0.4  1.4 -0.3  0.7  1.   0.6 -0.3 -0.2 -0.1 -0.5 -0.5 -0.2 -1.4 -0.7 -0.4 -0.4 -3.  -0.4  0.1  0.2  4.7  0.6 -0.3 -0.3  0.  -2.4  3.6 -0.2  2.3 -0.6 -0.1 -0.3 -1.   3.8  0.2  0.2  1.8  0.6 -0.1 -0.1 -1.2 -0.2 -0.3 -0.1  9.4 -0.2 -1.1  5.1  4.7 -1.  -0.8 -0.1 -0.4 -3.9 -3.8 -0.2 -0.1 -0.2 -0.3  1.5 -0.5 -0.1 -0.  -0.1  0.1 -0.3 -0.1 -0.8 -0.1  3.7 -0.2 -0.3  0.6 -0.2 -0.1 -0.3  0.8  4.5 -0.2  2.  -1.7  0.3 -0.2 -0.3 -0.6 -0.   3.1 -0.2 -0.4 -0.4 -0.3 -0.3 -0.2 -0.6  2.   3.5 -0.3 -0.1 -0.3 -0.2 -0.3 -0.3 -1.2 -0.2 -0.2 -1.1 -0.2 -0.2  4.3 -0.2 -0.3 -0.1 -0.9 -2.9 -0.8 -1.3 -0.8  0.3 -0.1 -0.3 -0.2 -0.2 -0.5 -0.1 -3.  -0.2 -0.1  4.9 -0.5 -0.6 -0.1 -0.9  6.5 -0.1 -0.3 -2.4 -0.7  0.7  1.1 -0.4 -0.4 -0.2 -1.3 -0.5  0.4 -1.3  1.  -0.2  0.2 -0.2  0.4 -0.1  3.2  1.4  4.   0.6 -2.1  2.9 -1.4 -0.1 -0.7 -0.3  0.3 11.4  4.  -0.1  1.  -1.1 -0.5  8.4 -0.1  2.3 -0.1  0.5 -0.9]
vy_50sample [[4 1 8 7 0 2 3 5 9 6]
 [1 2 4 8 5 0 3 3 7 6]
 [0 4 6 6 2 5 7 8 9 3]
 [7 0 3 9 4 1 6 2 8 5]
 [6 3 8 4 1 2 0 7 9 5]
 [7 7 1 6 2 4 8 9 5 3]
 [3 7 5 2 9 8 1 6 0 4]
 [4 7 1 5 3 0 0 6 2 8]
 [2 4 1 0 8 6 7 9 3 5]
 [6 4 1 0 5 9 8 3 2 7]]
vt_50sample [[4 1 8 7 0 2 3 5 9 6]
 [1 2 4 8 5 0 9 3 7 6]
 [0 4 6 1 2 5 7 8 9 3]
 [7 0 9 3 4 1 6 2 8 5]
 [6 3 4 8 1 2 0 7 9 5]
 [7 1 0 6 2 4 8 9 5 3]
 [3 7 5 2 9 8 1 6 0 4]
 [4 7 5 1 3 9 0 6 2 8]
 [2 4 1 0 8 6 7 9 3 5]
 [6 4 1 0 5 9 8 3 7 2]]
Epoch 25910: Training cost= 0.2730, Training acc= 0.8307, Validation cost= 0.3322, Validation acc= 0.8309
Epoch 25920: Training cost= 0.2678, Training acc= 0.8308, Validation cost= 0.3110, Validation acc= 0.8309
Epoch 25930: Training cost= 0.2628, Training acc= 0.8308, Validation cost= 0.3405, Validation acc= 0.8309
Epoch 25940: Training cost= 0.2975, Training acc= 0.8308, Validation cost= 0.2577, Validation acc= 0.8310
Epoch 25950: Training cost= 0.3414, Training acc= 0.8308, Validation cost= 0.2641, Validation acc= 0.8310
Epoch 25960: Training cost= 0.3178, Training acc= 0.8309, Validation cost= 0.3061, Validation acc= 0.8310
Epoch 25970: Training cost= 0.2913, Training acc= 0.8309, Validation cost= 0.2543, Validation acc= 0.8310
Epoch 25980: Training cost= 0.2981, Training acc= 0.8309, Validation cost= 0.2861, Validation acc= 0.8310
Epoch 25990: Training cost= 0.3390, Training acc= 0.8309, Validation cost= 0.3704, Validation acc= 0.8311
Epoch 26000: Training cost= 0.3160, Training acc= 0.8309, Validation cost= 0.2988, Validation acc= 0.8311
tm  [-0.8 -0.3 -4.1  0.5 -0.5 -0.1 -0.4 -0.2 -0.9 -0.6  2.4 -0.2 -0.5 -0.8 -3.5 -0.7 -0.2 -0.2 -0.4 -1.2 -0.7 -0.3  1.  -0.3 -1.   3.  -0.3 -0.2 -1.1 -0.7  4.5 -0.4 -0.6 -2.6 -0.3  1.9  4.5 -0.2  5.9 -0.6 -0.1  6.7  3.   3.4 -0.1 -0.2  5.5  0.5 -0.2  2.1 -0.6 -0.3  1.  -1.1 -0.6  4.3 -0.7  2.3 -0.9 -1.6 -0.  -0.5 -0.2 -0.2 -0.5 -0.1 -0.2  0.3  0.1  0.6 -0.2  1.6 -0.2 -0.2 -0.3 -0.2  1.5 -0.2  0.1 -0.2 10.5 -0.2 -0.3 -0.   0.3  6.8  2.6 -0.5 -0.1 -0.6 -0.4 -0.3 -0.4  3.  -0.4  0.3 -0.3 -0.3 -0.5 -0.4  1.9 -1.1  0.2 -0.3 -0.2  1.4 -0.3  4.   1.2 -2.2 -0.8 -0.5 -0.1 -0.1  0.4 -0.8 -0.  -0.9 -0.1 -0.2  0.1  7.3 -0.1  0.2 -0.  -4.1  0.2  7.  -0.1 -1.3 -0.2 -0.1 -0.1 -0.3  9.5  4.5 -0.3 -0.  -0.3 -1.   0.4 -0.7 -0.3  0.5 -0.5 -0.2 -0.1 -0.1  9.5 -0.4  0.6 -0.1 -0.8 -0.  -0.3 -0.2 -0.4 -0.4  0.3 -0.7  0.5 -0.2 -0.1 -0.3 -0.  -0.6 -0.5 -0.5 -0.1 -0.6 -0.4 -0.1 -0.1 -0.2 -0.2 -2.5 -0.5 -0.2 -0.5 -0.1 -2.  -0.1 -0.2 -1.1 -0.1  0.3 -0.2  2.5 -0.1  2.  -0.3 -0.4 -0.5 -1.2  2.4  2.8  0.6  1.2 -0.2 -0.1  0.2 -0.1 -0.2 -0.3 -0.1  0.8 -0.2 -0.3 -3.7 -0.2 -0.4 -1.  -0.4  3.4  0.7 -0.4 -1.  -0.9 -0.4 -0.2 -0.4 -0.1 -0.4 -0.3  1.5 -0.8 -1.  -0.5 -0.  -0.5 -0.8 -0.5 -0.2 -2.2  2.7  6.8 -0.   1.2 -0.1 -0.7 -0.2 -0.3  0.   0.1 -1.9 -1.9 -0.3 -0.1 -0.8 -0.3 -2.9 -0.1  3.9 -0.   0.8  7.3]
ty_50sample [[5 4 9 0 1 6 2 8 3 7]
 [2 5 0 0 6 3 4 4 9 8]
 [4 0 9 2 1 5 7 6 3 8]
 [6 5 3 0 9 7 4 1 2 8]
 [8 1 2 7 9 3 6 0 5 4]
 [3 8 6 0 1 7 4 5 2 9]
 [5 7 6 1 0 9 2 4 8 3]
 [4 1 8 0 7 6 2 9 5 3]
 [4 8 7 2 5 0 1 9 6 3]
 [6 0 9 7 5 3 4 2 8 1]]
tt_50sample [[5 4 0 9 1 6 2 8 3 7]
 [7 2 5 0 6 3 4 1 9 8]
 [4 0 9 2 1 5 7 6 3 8]
 [5 6 3 0 9 7 4 1 2 8]
 [8 1 2 7 9 3 6 0 5 4]
 [3 8 6 0 1 7 4 5 2 9]
 [5 7 6 1 0 9 2 4 8 3]
 [4 1 8 0 7 6 2 9 5 3]
 [4 8 7 2 5 0 1 9 6 3]
 [6 0 9 7 5 3 4 2 8 1]]
vm  [-0.9 -0.3  8.2 -0.3 -2.  -0.4 -0.1 -0.2 -0.6 -0.5 -1.9  0.6 -0.6  0.9 11.4 -1.1 -0.4 -0.4  0.3 -0.1 -0.9 -0.3 -0.9 -0.3 -0.9  0.6 -0.5 -0.1 -0.7 -1.8 -0.2 -0.4 -0.1  8.5 -0.5 -0.3  1.4  0.6  1.7 -0.3 -0.3 -1.3 -0.2  1.4 -0.5 -0.3 -1.1  1.2 -0.8 -2.5 -0.9 -0.  -0.8  0.4 -0.9 -1.3 -0.9  4.4  1.1  2.5  6.7 -0.1 -0.4 -0.5  0.5 -0.5 -0.2 -0.3 -0.  -0.5 -0.   1.  -0.2 -0.6 -4.8 -0.2 -0.4 -0.2 -0.2 -0.2 -1.6 -0.2 -0.   0.5 -0.2 -1.1 -0.8 -0.4  0.2 -0.3 -0.2 -0.1  0.7  0.2 -0.6 -0.  -0.2 -1.9 -0.2 -0.3  2.7 -0.2  1.1 -0.3 -0.3 -0.1 -2.8 -0.1 -0.7  0.4  1.1 -0.3 -0.2 -0.9  1.7 -0.2 -0.4  1.   0.2 -0.5 -0.3 -0.3 -0.1 -0.  -0.2 13.4  0.5  2.2  2.3 12.7 -0.5 -0.5 -0.3 -0.4 -5.3 -1.7 -0.2 -0.1  0.3 -0.6  2.1 -0.4  1.7 -0.2  0.  -0.3 -0.  -0.2 -0.6 -0.1 -0.1 -0.  -0.6  0.3 -0.1 -0.1 -0.4 -0.3  2.9 -0.7 -0.9 -1.6 -0.1 -0.1  0.1 -0.  -0.2  1.2 -0.1 -0.3 -0.3 -0.1 -0.2 -0.2 -0.1  1.9  0.2 -1.3  0.3 -0.1 -1.2 -0.3 -0.2 -1.5 -0.2  0.  -0.6 -0.8 -0.3  5.5 -0.2  0.2 -0.5 -1.  -2.  -0.5 -1.6 -0.3 -0.  -0.4 -0.2 -0.4 -0.2 -0.2 -0.5 -3.7 -0.2 -0.3 -1.1 -0.3 -0.5 -0.5 -0.4  2.9 -0.3 -0.1 -0.2 -0.7 -0.   0.3 -0.4 -0.3  0.7 -0.8 -2.2 -0.2 -1.8 -0.2 -0.2  0.8 -0.7  2.5 -0.4 -0.7 -0.  -1.6  0.8 -2.   0.8 -3.  -0.  -1.1 -0.4 -0.1  6.2  4.2 -0.4 -0.4 -0.7 -0.1  3.5 -0.3  1.4 -0.2  8.  -3.3]
vy_50sample [[3 7 1 5 0 8 4 9 6 2]
 [7 2 4 3 6 1 9 9 5 5]
 [5 4 6 2 3 1 0 8 7 9]
 [9 7 2 1 8 5 6 4 3 0]
 [8 3 1 6 4 2 7 0 9 5]
 [5 2 2 6 7 1 4 8 3 9]
 [2 6 0 8 9 3 5 1 7 4]
 [3 4 6 1 2 7 9 8 5 0]
 [1 3 0 5 7 4 6 2 8 9]
 [4 8 3 6 0 9 5 2 7 1]]
vt_50sample [[3 7 1 5 0 8 4 9 6 2]
 [7 2 4 3 6 1 9 8 0 5]
 [5 4 6 2 3 1 0 8 7 9]
 [9 7 2 1 8 5 6 4 3 0]
 [8 3 1 6 4 2 7 0 9 5]
 [0 5 2 6 7 1 4 8 3 9]
 [2 6 0 8 3 9 5 1 7 4]
 [3 4 6 1 2 9 7 8 5 0]
 [1 0 3 5 7 4 6 2 8 9]
 [4 8 3 6 0 9 5 2 7 1]]
Epoch 26010: Training cost= 0.3133, Training acc= 0.8309, Validation cost= 0.3085, Validation acc= 0.8311
Epoch 26020: Training cost= 0.3059, Training acc= 0.8310, Validation cost= 0.3642, Validation acc= 0.8311
Epoch 26030: Training cost= 0.2862, Training acc= 0.8310, Validation cost= 0.2782, Validation acc= 0.8311
Epoch 26040: Training cost= 0.3071, Training acc= 0.8310, Validation cost= 0.2724, Validation acc= 0.8312
Epoch 26050: Training cost= 0.3368, Training acc= 0.8310, Validation cost= 0.2562, Validation acc= 0.8312
Epoch 26060: Training cost= 0.3229, Training acc= 0.8310, Validation cost= 0.3120, Validation acc= 0.8312
Epoch 26070: Training cost= 0.2691, Training acc= 0.8311, Validation cost= 0.2685, Validation acc= 0.8312
Epoch 26080: Training cost= 0.3029, Training acc= 0.8311, Validation cost= 0.2801, Validation acc= 0.8312
Epoch 26090: Training cost= 0.2822, Training acc= 0.8311, Validation cost= 0.2717, Validation acc= 0.8313
Epoch 26100: Training cost= 0.2858, Training acc= 0.8311, Validation cost= 0.2795, Validation acc= 0.8313
tm  [-1.  -0.   5.2  3.5 -1.5 -0.3 -0.  -0.3  0.7 -0.3 -2.8  0.7 -1.2 -0.3  4.5 -0.6  1.4 -0.5 -0.4  3.1 -0.5 -0.4 -0.5 -0.4 -0.3  0.4 -0.4 -0.2 -0.1 -2.2 -1.7 -0.6 -0.5 -1.7 -0.9 -0.7 -0.5 -1.3 -3.1 -0.2 -0.7 -1.5 -0.5 -1.8 -0.6  0.4 -3.   0.9  1.4 -1.9 -0.5 -0.  -0.1  2.1 -1.  -0.5 -0.3  8.6  3.   6.3  5.  -0.2 -0.  -0.4 -0.9 -0.  -0.  -0.4 -0.  -0.2 -0.  -0.9 -0.3 -0.  -6.8 -0.3 -0.8 -0.3 -0.5 -0.1 -3.3 -0.5  0.5 -0.4 -1.1 -1.2 -1.2 -0.2 -0.2 -0.2 -0.6 -0.2  0.9 -0.3 -0.6 -0.1 -0.2 -2.7 -0.3  0.5  1.2 -2.7 -0.2 -0.1 -0.5  1.9 -2.2 -1.1 -0.8  0.6  0.8 -0.2 -0.1 -1.1  1.8  3.8 -0.2  4.   0.4 -0.1 -0.  -0.9 -0.6 -0.  -0.2  5.5  0.4  1.4  4.4 13.6  0.8 -0.7 -0.1 -0.1  7.8  4.1 -0.5 -0.2  0.1  0.5  1.4 -0.5  1.8 -0.1 -0.2  0.1 -0.3 -0.2  3.9 -0.1 -0.6  0.2  2.3  1.9 -0.3 -0.1 -0.5 -0.1 -0.7 -0.9 -0.5  1.1  0.8 -0.1  0.2  1.4 -0.3  1.4 -0.2 -0.5 -0.5 -0.2 -0.4 -0.5 -0.1 -0.7 -0.7 -0.7  6.6  0.1 -1.4  0.7 -0.4 -1.9 -0.3 -0.  -0.2 -0.3 -0.1  6.7 -0.1  1.3 -0.1 -0.7 -1.2 -1.3 -0.8 -0.7  0.2 -0.4  0.5 -0.  -0.1  0.2  0.1 -2.5 -0.1 -0.5  2.3 -0.3 -0.6  2.6 -0.5  0.9 -0.2  0.5  7.1 -0.5 -0.2 -0.2 -0.7 -0.4 -0.2 -0.9 -0.5  2.1 -2.7 -0.5 -0.4  3.6 -0.1  0.2 -0.3  1.1 -0.6 -0.8 -0.3 -1.9  2.5 -3.1 -0.1 -1.3  0.4 -0.3 11.7  3.8 -0.6  0.7 -0.8 -0.5  8.9 -0.4 -2.1 -0.4  9.  -4. ]
ty_50sample [[3 6 8 5 1 0 7 2 9 4]
 [4 6 8 0 9 7 1 2 5 3]
 [2 9 3 4 0 6 8 1 7 5]
 [8 9 0 7 5 1 3 6 2 4]
 [6 2 1 7 3 5 0 8 9 4]
 [6 1 8 7 4 2 9 0 5 3]
 [8 4 6 3 3 2 9 1 0 5]
 [7 2 1 6 4 0 8 9 5 3]
 [2 0 8 3 1 4 7 6 9 5]
 [2 4 6 1 8 7 9 0 5 3]]
tt_50sample [[3 6 8 5 1 0 7 2 9 4]
 [4 6 0 8 9 7 1 2 5 3]
 [2 9 3 0 4 6 8 1 7 5]
 [8 9 0 7 5 1 3 6 2 4]
 [6 2 1 7 3 5 0 8 9 4]
 [1 6 8 7 4 2 9 0 5 3]
 [8 4 6 3 2 7 9 1 0 5]
 [7 2 1 6 4 0 8 9 5 3]
 [2 0 8 3 1 4 7 6 9 5]
 [2 4 6 1 8 7 9 0 5 3]]
vm  [ 0.2 -0.1  3.6  8.6 -0.5 -0.2 -0.2 -0.3 -0.6  2.8  4.8 -0.6  0.6 -0.4 -0.   5.1 -0.3 -0.1 -0.5 -2.  -0.9  0.2  1.6 -0.  -0.4 -0.5 -0.3 -0.7  0.6  6.  -0.6  0.2  2.9  0.5 -0.2 -0.8  1.3 -0.4 -1.7 -0.2  1.2  1.7 -0.1 -1.  -0.1 -0.3  8.2 -0.6  1.7 12.  -0.2 -0.5 -0.3  3.1 -1.   0.9 -0.5 -1.6 -0.2  3.  -1.6 -0.5 -0.8 -0.2 -0.2 -0.8 -0.   0.8 -0.1 -0.3 -0.3 -1.4 -0.1 -0.  -1.5 -0.1 -0.6  0.9 -0.5 -0.5  2.1  0.9 -0.9 -0.4 -1.2  0.7  2.8  0.4 -0.4 -0.9 -0.6  0.3  0.8  0.1 -0.3 -0.2 -0.7 -0.7 -0.1 -0.5 -1.   6.1 -0.4  0.6 -0.5 -0.5 -0.7 -0.3  1.6 -2.1 -0.1  0.3 -0.2 -0.7 -0.4  4.7 -0.1 -0.8  0.1 -0.1 -0.1  5.8 -0.4 -0.6 -0.6 -0.2 -0.3 -0.3 -0.9 -2.7  1.  -0.4 -0.4  1.3  8.2  9.6 -0.2 -0.2 -0.3 -0.8 -1.3  0.  -1.  -0.4 -0.1 -0.  -0.3 -0.  -1.7 -0.2 -0.8 -0.2  2.6 -0.3 -0.3 -0.2 -0.5  0.8 -2.  -0.2 -0.3  2.4 -0.3 -0.1 -0.2  1.3 -0.2 -0.2 -0.2  0.6  0.2 -0.3 -0.   0.1 -0.2  4.  -1.8 -0.3  3.1 -0.9  2.1 -0.   1.1  0.6 -0.8 -0.3  3.4 -0.8 -0.6 -1.4 -0.1 -0.2 -0.8 -0.7 10.5  2.4 -0.  -0.  -0.2  0.   0.3 -0.2  0.9 -0.  -0.4  1.3 -0.2 -0.3  8.4  0.3  0.9  2.6 -0.6 -0.9 -0.1 -0.4  5.1 -0.5 -1.  -0.6 -0.1 -0.2  0.4 -0.9  6.   2.6  0.9  0.1  0.2  1.7  1.8  1.  -0.2  3.8 -1.4 -0.3  0.8 -0.7 -0.2 17.4 -0.3  7.1 -0.3  0.1  0.1 -1.8 -0.3 -0.8 -0.7 -0.  -0.7 -0.4 -0.9 -0.1 -1.7 13.4]
vy_50sample [[6 2 9 8 7 4 0 1 5 3]
 [2 4 0 6 5 7 8 9 1 3]
 [0 5 4 8 6 9 7 1 2 3]
 [8 8 4 7 0 2 5 9 6 1]
 [1 6 8 9 7 7 0 4 5 3]
 [0 1 9 7 8 2 6 4 3 5]
 [9 2 3 1 6 8 7 0 4 5]
 [9 3 8 6 5 4 0 1 7 2]
 [7 9 3 8 6 1 5 4 2 0]
 [6 2 4 5 8 1 3 7 0 9]]
vt_50sample [[6 2 9 8 7 4 0 1 5 3]
 [2 4 0 6 5 7 8 1 3 9]
 [0 5 4 8 6 9 7 1 2 3]
 [3 8 4 7 0 2 5 9 6 1]
 [1 6 8 9 7 2 0 4 5 3]
 [0 1 9 7 8 2 6 4 3 5]
 [9 2 3 1 6 8 7 0 4 5]
 [9 3 8 6 5 4 0 1 7 2]
 [7 9 3 8 6 5 1 4 2 0]
 [2 6 4 5 8 1 3 7 0 9]]
Epoch 26110: Training cost= 0.2491, Training acc= 0.8311, Validation cost= 0.2891, Validation acc= 0.8313
Epoch 26120: Training cost= 0.2904, Training acc= 0.8312, Validation cost= 0.2582, Validation acc= 0.8313
Epoch 26130: Training cost= 0.2861, Training acc= 0.8312, Validation cost= 0.2630, Validation acc= 0.8313
Epoch 26140: Training cost= 0.3155, Training acc= 0.8312, Validation cost= 0.2722, Validation acc= 0.8314
Epoch 26150: Training cost= 0.2707, Training acc= 0.8312, Validation cost= 0.3418, Validation acc= 0.8314
Epoch 26160: Training cost= 0.2759, Training acc= 0.8313, Validation cost= 0.2893, Validation acc= 0.8314
Epoch 26170: Training cost= 0.3253, Training acc= 0.8313, Validation cost= 0.2744, Validation acc= 0.8314
Epoch 26180: Training cost= 0.3268, Training acc= 0.8313, Validation cost= 0.3138, Validation acc= 0.8314
Epoch 26190: Training cost= 0.2663, Training acc= 0.8313, Validation cost= 0.3429, Validation acc= 0.8315
Epoch 26200: Training cost= 0.2984, Training acc= 0.8313, Validation cost= 0.3301, Validation acc= 0.8315
tm  [-1.7  0.9  6.3  8.6 -2.1 -0.2 -0.3 -0.2 -1.2 -0.2 -2.2 -0.1 -0.6  0.3  2.5 -0.4 -0.7 -0.1  0.2 -1.3 -0.5 -0.4  1.   0.3 -1.1  0.3 -0.4 -0.3 -0.6  1.8 -0.7 -0.2 -0.7  4.3 -0.8 -0.   4.3  3.  15.9 -0.2 -0.5  3.9  2.1  2.7 -0.8 -0.2  6.2  0.2 -1.7  8.4 -0.4  0.3  0.1 -1.6 -1.2 -0.4 -0.5  3.3 -1.3  2.4  2.9 -0.4 -0.6 -0.9 -1.  -0.5 -0.  -0.3 -0.2 -0.4 -0.   0.2  0.8 -0.2 -0.2 -0.2  1.9 -0.6  0.3 -0.1  1.8 -0.2 -0.1 -0.6  2.3  6.2 -1.3 -0.2  0.1 -0.3  0.6 -0.1  0.1  0.7 -0.4 -0.2 -0.5 -0.2 -0.  -0.3  0.9  7.3  2.2 -0.1  0.3 -0.6 -0.4 -0.4 -0.8 -2.  -0.2 -0.4  0.2  0.  -0.6  0.  -0.3 -1.3  0.2 -0.6 -0.   6.9 -0.5 -0.1 -0.1  3.5  1.1  7.9 -1.  -2.4 -1.2 -0.1 -0.4 -0.1 -6.3 -4.7  0.6 -0.1 -0.2 -1.   1.7 -0.7  0.3 -0.4 -0.1 -0.  -0.1 -0.1 -0.5 -0.1 -0.7 -0.2 -0.8  0.4 -0.2 -0.2 -0.2 -0.6  3.9 -0.  -0.5 -1.8 -0.4 -0.2 -0.5 -0.1 -0.  -0.1 -0.5 -0.1 -0.1 -0.3 -0.2 -0.2 -0.2  1.4  1.8 -0.  -2.2 -0.3 -1.4 -0.1  0.8 -0.8 -0.4  0.2 -1.2 -0.6 -0.3 -0.6 -0.3 -0.3 -0.2 -1.1 -0.6  5.5  1.1  3.4 -0.4 -0.1 -0.1 -0.1 -0.2 -0.3 -0.3  2.3 -0.3 -0.  -0.1 -0.3 -0.  -0.5 -0.3  7.6 -0.3 -0.4 -1.1 -0.4 -0.  -0.1 -0.2 -0.1 -0.1 -0.8 -0.5  0.6 -1.5 -0.2  1.1 -1.4 -0.7 -0.3 -0.3 -0.1 -0.2 -1.4 -0.6  0.  -0.1  1.1 -0.1  0.6 -0.1 -0.4  0.1 -2.1 -0.2 -0.4 -0.3 -0.3 -0.8  0.1 10.7 -0.3 -0.1 10.7]
ty_50sample [[1 7 5 9 8 0 4 2 3 6]
 [7 4 3 9 0 2 5 6 8 1]
 [4 4 0 1 5 2 7 3 8 9]
 [7 7 6 2 8 3 5 1 9 4]
 [6 8 3 4 0 5 1 2 9 7]
 [6 5 3 4 7 9 0 1 8 2]
 [3 1 4 5 5 0 0 6 7 8]
 [4 3 7 7 1 0 9 8 6 5]
 [3 1 7 8 5 9 6 4 2 0]
 [4 0 1 3 5 6 7 9 8 2]]
tt_50sample [[1 7 5 9 8 0 4 2 3 6]
 [7 4 3 9 0 2 5 6 8 1]
 [4 6 0 1 5 2 7 3 8 9]
 [0 7 6 2 8 3 5 1 9 4]
 [6 8 3 4 0 5 1 2 9 7]
 [6 5 3 4 7 9 0 1 8 2]
 [3 1 4 5 2 0 9 7 6 8]
 [3 4 2 7 1 0 9 8 6 5]
 [3 1 7 8 5 9 6 4 2 0]
 [4 0 1 3 5 6 7 9 8 2]]
vm  [-0.2 -0.1 -3.5 -2.9 -0.5 -0.3 -0.3 -0.1 -0.9 -0.8  5.4 -0.2 -0.3 -0.2 -0.8  3.4  0.1 -0.4 -0.4  0.4 -0.9 -0.5 -0.2 -0.4 -1.4  1.2 -0.1 -0.1 -0.6 -1.4  3.  -0.7 -0.5 -3.6 -0.3 -0.   2.4  3.5  0.1 -0.6 -0.2  3.7  2.2  3.5  0.1 -0.2 -1.3 -0.6  3.2 -0.4 -0.8 -0.2 -0.7  9.7 -1.1  0.7 -0.3  4.1  0.3 -0.5  0.8 -0.6 -0.6 -0.1 -0.6 -0.2 -0.2  0.2 -0.2 -0.  -0.2 -0.  -0.3 -0.4 -4.6 -0.1 -0.6 -0.4 -0.1 -0.1 -2.2  0.2 -0.4  1.5 -1.   5.   4.9 -0.4  0.5 -0.4 -0.7 -0.3 -0.2  3.  -0.6  0.4  0.5 -1.9 -0.6 -0.4  2.4 -2.4 -0.8 -0.2 -0.3 -0.1 -2.7  2.   1.5 -0.5 -0.1 -0.6 -0.5 -0.7 -0.3  0.9 -0.  -0.4 -0.3 -0.3 -0.2  0.3  0.3 -0.4 -0.4 -0.9 -0.2 -2.4  3.   8.3  0.3 -0.9 -0.1 -0.5  6.  -1.7 -0.5 -0.2 -0.2 -0.7 -0.8 -0.5 -0.7  0.3 -0.3  0.1 -0.2 -0.3 10.1 -0.4  2.2 -0.2  2.6 -0.5 -0.3  0.2 -0.6 -0.4  1.  -1.2 -0.2 -1.  -0.2 -0.1 -0.2 -0.3 -0.5 -0.8 -0.2 -0.6 -0.1  0.4 -0.5 -0.3 -0.2 -2.9 -0.2 -1.   1.6 -0.3 -2.6 -0.1 -0.4 -1.4 -0.1  0.2  1.3  1.6 -0.3  4.1 -0.5 -0.2 -0.5 -1.3  1.6 -0.7 -1.1 -0.  -0.1 -0.4 -0.1 -0.2 -0.3 -0.1 -0.1 -3.5 -0.   0.1 -2.5 -0.3 -0.7 -0.4 -0.3 -0.7  0.5  0.7 -1.2 -0.7 -0.3 -0.5 -0.1 -0.4 -0.3 -0.6 -1.   0.3  1.8 -0.5 -0.   3.3 -1.4  1.3 -0.3 -1.4  0.6  5.6  0.2 -1.5 -0.4 -4.7  0.2 -2.  -0.3  0.3  8.4  3.2  0.1 -0.5 -0.8 -0.4  4.9 -0.2 -0.  -0.3 -0.1 -2. ]
vy_50sample [[5 2 4 3 0 0 6 9 1 7]
 [2 1 9 5 8 4 3 0 6 7]
 [5 1 7 3 4 0 6 9 8 2]
 [8 0 1 5 3 9 4 6 7 2]
 [4 2 1 6 5 7 9 3 8 0]
 [5 0 3 3 9 1 4 6 2 7]
 [7 5 4 0 6 1 9 2 2 8]
 [3 9 8 0 1 6 5 4 7 2]
 [9 8 3 5 6 4 2 7 0 1]
 [6 8 2 1 0 7 4 3 5 9]]
vt_50sample [[5 2 4 3 0 8 6 1 9 7]
 [2 1 9 5 8 4 3 0 6 7]
 [5 1 7 3 4 0 6 9 8 2]
 [8 0 1 5 3 4 9 6 7 2]
 [2 4 1 6 5 7 9 3 8 0]
 [5 0 3 8 1 9 4 6 2 7]
 [7 5 4 0 6 1 9 3 2 8]
 [3 9 8 1 0 6 5 4 7 2]
 [9 3 8 5 6 4 2 7 0 1]
 [6 8 2 1 0 4 7 3 5 9]]
Epoch 26210: Training cost= 0.2925, Training acc= 0.8314, Validation cost= 0.2909, Validation acc= 0.8315
Epoch 26220: Training cost= 0.3048, Training acc= 0.8314, Validation cost= 0.3570, Validation acc= 0.8315
Epoch 26230: Training cost= 0.2485, Training acc= 0.8314, Validation cost= 0.3080, Validation acc= 0.8315
Epoch 26240: Training cost= 0.2385, Training acc= 0.8314, Validation cost= 0.3465, Validation acc= 0.8316
Epoch 26250: Training cost= 0.2953, Training acc= 0.8314, Validation cost= 0.3186, Validation acc= 0.8316
Epoch 26260: Training cost= 0.2696, Training acc= 0.8315, Validation cost= 0.2861, Validation acc= 0.8316
Epoch 26270: Training cost= 0.2860, Training acc= 0.8315, Validation cost= 0.2798, Validation acc= 0.8316
Epoch 26280: Training cost= 0.2659, Training acc= 0.8315, Validation cost= 0.2817, Validation acc= 0.8316
Epoch 26290: Training cost= 0.2996, Training acc= 0.8315, Validation cost= 0.2630, Validation acc= 0.8317
Epoch 26300: Training cost= 0.2843, Training acc= 0.8315, Validation cost= 0.3261, Validation acc= 0.8317
tm  [ 1.3 -0.4 -2.2  2.4 -1.1  0.1 -0.1 -0.2 -0.3 -0.8 -1.2 -0.1 -0.4 -0.2 -1.9 -0.7 -0.3 -0.6 -0.5 -1.  -0.8 -0.1 -0.5  0.2 -1.3  2.2 -0.  -0.4 -0.8 -1.1  4.  -0.3 -0.2 -0.7 -0.2 -0.1  2.3 -0.6  5.9 -0.5  0.9  1.   1.   3.4  0.6  0.6  4.9  0.4  5.5 -1.3 -0.6 -0.2  1.1 -2.2 -0.4  3.2 -0.4  0.1  1.  -1.2 -1.7 -0.6 -0.2  0.9 -0.2  0.5 -0.1 -0.3  1.3  0.6 -0.1  0.1 -0.3  0.3  0.  -0.  -0.9 -0.1  0.3  0.6  9.2  0.2 -0.3  1.1 -1.1  2.   6.3 -0.1  0.5 -0.6 -0.  -0.2 -0.3 -0.6 -0.4 -0.  -0.2 -1.1  0.2 -0.2  2.2 -1.4 -1.1 -0.1 -0.1  1.3 -0.2  3.5 -0.5 -1.8 -0.7 -0.1 -0.2 -0.5  1.8  0.2 -0.3 -0.2 -0.3 -0.4 -0.3  7.1  0.4 -0.2 -0.3 -2.3 -0.1 10.6  4.2 -0.   2.3 -0.9 -0.1 -0.7  4.9  3.2 -0.2 -0.3  0.4 -0.3  2.  -0.7  2.   0.1 -0.1 -0.2 -0.1 -0.2  5.3 -0.   0.2 -0.1  3.1 -0.3 -0.   0.3 -0.5  0.3  0.3 -0.3  0.3 -0.4 -0.3  0.  -0.2 -0.  -0.1 -0.3  0.7 -0.3 -0.2 -0.1 -0.2 -0.1 -0.2 -1.1 -0.7 -0.  -0.4 -0.  -1.7 -0.4 -0.6 -1.5  0.  -0.   4.4  0.2 -0.4  3.3 -0.2 -0.2 -0.6 -1.  11.3 -1.   2.3 -0.5 -0.2 -0.1 -0.4 -0.1 -0.1 -0.7 -0.3  0.2 -0.2 -0.2 -1.6  0.3 -0.6  1.3 -0.8 -1.1 -0.7 -0.3 -0.9 -0.7 -0.2 -0.4 -0.8 -0.  -0.2 -0.9 -0.6 -0.2 -1.4 -0.6 -0.   5.6 -0.7 -1.2  0.7 -0.9  1.9  5.   0.3  1.7  3.6  2.8  0.1  1.1 -0.2  0.2 -1.5 -1.9 -0.3  0.  -1.3 -0.5 -2.6 -0.3  4.3 -0.3  5.   2.6]
ty_50sample [[9 4 5 3 0 6 8 7 2 1]
 [4 4 1 3 8 6 9 7 0 2]
 [1 6 5 2 4 9 0 3 7 8]
 [2 8 8 0 9 4 7 7 6 5]
 [0 6 7 7 5 5 3 1 2 9]
 [4 0 1 2 9 5 6 3 8 7]
 [5 5 2 1 3 4 6 8 7 9]
 [4 1 0 5 7 8 9 2 6 3]
 [0 5 3 2 6 8 1 4 7 9]
 [8 2 2 1 6 7 5 0 9 3]]
tt_50sample [[9 4 5 3 0 6 8 7 2 1]
 [4 5 1 3 8 6 9 7 0 2]
 [1 6 5 2 4 9 0 3 7 8]
 [2 1 8 0 9 4 3 7 6 5]
 [0 6 7 8 5 4 3 1 2 9]
 [4 0 1 2 9 5 6 3 8 7]
 [0 5 1 2 3 4 6 8 7 9]
 [4 1 0 5 7 8 9 2 6 3]
 [0 5 3 2 6 8 1 4 7 9]
 [8 4 2 6 1 7 5 0 9 3]]
vm  [-0.3 -0.4 -0.3  6.5 -1.7 -0.2 -0.  -0.3 -0.3 -0.6 -0.8  1.5 -0.7 -0.3 -1.3 -1.3 -0.3 -0.4 -0.1 -1.2 -1.1  0.1 -1.  -0.1 -0.9  3.9 -0.3 -0.5 -0.9 -2.   2.7 -0.4 -0.6  3.9 -0.3 -0.1  2.3  1.9 15.8 -0.6 -0.2 -1.9 -0.1  4.5 -0.3 -0.   5.5 -0.2  3.6 -2.7 -0.6 -0.2  2.2 -2.3 -0.2  2.8 -0.6 -0.7  1.5 -0.8 -1.2 -0.4  0.7  0.1 -0.6 -0.2 -0.1 -0.2  0.2  0.6 -0.1  2.2 -0.1  0.6 -0.3  0.3 -0.6 -0.6 -0.2  0.6 12.  -0.1 -0.1 -0.6 -0.7 -1.7  2.9 -0.2  0.  -0.6 -0.1 -0.4  0.4 -0.6 -0.3 -0.1 -0.5 -1.  -0.4 -0.2  1.1 -1.4 -0.6 -0.2 -0.1  0.9  1.1  2.8 -0.1 -2.  -0.5 -0.2 -0.1 -0.4  3.3 -1.2  0.9  0.5 -0.1 -0.   0.7  7.  -0.3  0.5 -0.1 -1.5 -0.  11.4  3.   2.7 -0.4 -0.2  0.6 -0.3 -3.4 -2.1 -0.2 -0.2  0.5 -0.4  2.6 -1.   2.  -0.1 -0.1 -0.2 -0.3 -0.2 -0.2 -0.1 -0.3 -0.   1.   0.1 -0.1 -0.1 -0.3 -0.   5.  -0.3 -0.3 -2.2  0.1 -0.  -0.1 -0.4 -0.   0.8 -0.  -0.2 -0.2 -0.5 -0.1  0.1 -0.2  1.9  2.2  0.7 -2.1  0.1 -0.4 -0.1 -0.4 -1.2 -0.1  0.5  2.9 -0.2 -0.4  6.3 -0.1  0.5 -0.5 -1.2  8.  -0.5  2.3 -0.4 -0.  -0.1 -0.1  0.1 -0.2 -0.5 -0.2  4.2 -0.3 -0.2  1.  -0.2 -0.4 -0.3 -0.9  0.1 -0.4 -0.1 -1.7 -0.9 -0.1  0.8 -0.6 -0.1 -0.3 -0.8 -2.4 -0.8 -2.1 -0.3  2.2  2.1 -0.2 -1.1  0.5  0.7  1.9  1.8  0.3  1.5  2.6 11.8 -0.2  4.6 -0.3 -0.2 -2.3 -2.5 -0.1  0.3 -1.1 -0.7 -3.2 -0.3 11.5 -0.1  6.8 -0.1]
vy_50sample [[3 9 0 4 7 7 5 8 2 6]
 [1 2 5 9 7 3 8 4 0 6]
 [7 8 5 1 3 0 2 4 9 6]
 [9 2 3 5 8 0 7 6 4 1]
 [0 3 2 7 7 5 4 4 1 8]
 [8 5 4 3 2 9 6 1 7 0]
 [1 8 6 9 3 2 5 4 7 0]
 [5 4 6 2 1 3 0 7 9 8]
 [5 1 9 3 0 0 8 8 6 4]
 [8 7 5 4 3 1 2 2 0 9]]
vt_50sample [[3 9 0 4 7 5 1 8 2 6]
 [1 2 5 9 7 3 8 4 0 6]
 [7 8 5 3 1 0 2 4 9 6]
 [9 2 3 5 8 0 7 6 4 1]
 [0 3 2 7 5 6 4 9 1 8]
 [8 5 4 3 2 9 6 1 7 0]
 [1 8 6 9 3 2 5 4 7 0]
 [5 4 6 2 1 3 0 7 9 8]
 [5 1 9 3 0 2 7 8 6 4]
 [8 7 5 4 3 1 2 6 0 9]]
Epoch 26310: Training cost= 0.2615, Training acc= 0.8316, Validation cost= 0.3052, Validation acc= 0.8317
Epoch 26320: Training cost= 0.2829, Training acc= 0.8316, Validation cost= 0.2980, Validation acc= 0.8317
Epoch 26330: Training cost= 0.2832, Training acc= 0.8316, Validation cost= 0.3570, Validation acc= 0.8317
Epoch 26340: Training cost= 0.2751, Training acc= 0.8316, Validation cost= 0.2492, Validation acc= 0.8318
Epoch 26350: Training cost= 0.2732, Training acc= 0.8316, Validation cost= 0.2989, Validation acc= 0.8318
Epoch 26360: Training cost= 0.2583, Training acc= 0.8317, Validation cost= 0.3318, Validation acc= 0.8318
Epoch 26370: Training cost= 0.3248, Training acc= 0.8317, Validation cost= 0.2757, Validation acc= 0.8318
Epoch 26380: Training cost= 0.2621, Training acc= 0.8317, Validation cost= 0.2993, Validation acc= 0.8318
Epoch 26390: Training cost= 0.2734, Training acc= 0.8317, Validation cost= 0.3142, Validation acc= 0.8319
Epoch 26400: Training cost= 0.3971, Training acc= 0.8317, Validation cost= 0.2832, Validation acc= 0.8319
tm  [-0.3  2.1  7.3 -0.3 -1.2 -0.2 -0.2 -0.4 -1.3 -1.1  4.9  0.5 -0.4 -0.   9.9  5.  -0.2 -0.1 -0.   1.1 -0.6 -0.1 -0.3  0.5 -1.5  1.3 -0.3 -0.5  0.2  4.5 -0.2  0.4  0.7  7.  -0.4  0.2  2.7 -0.2 -3.2 -0.5 -0.2 -2.2  2.  -0.8 -0.2 -0.3 -1.2 -0.7 -0.1 -0.8 -0.7 -0.  -0.3  7.9 -1.4 -0.9 -0.7 -0.6 -1.2  2.7  3.5  0.3 -0.6 -0.1  0.2 -0.5 -0.2 -0.1  1.6 -0.1 -0.2 -0.8  0.2 -0.4 -3.8 -0.2 -0.4 -0.6 -0.2 -0.  -1.8 -0.2  0.5  0.9 -0.5 -1.8  0.4  0.3 -0.2 -0.1 -0.2 -0.2 -0.3  2.1 -0.3 -0.2 -0.2 -1.5 -0.4 -0.2  4.3  3.8 -0.4  0.1  0.1 -0.2 -2.3 -0.1  1.8  1.4 -0.4 -0.3 -0.1 -0.2 -1.   5.8 -0.3 -1.1 -0.   0.1 -0.1 -0.8 -0.2 -0.1 -0.2 12.1 -0.1 -2.  -1.6  8.9  1.4 -0.3 -0.1 -0.1 -0.1  8.6  0.1 -0.1 -0.2 -0.7 -0.7 -0.6 -0.3 -0.1 -0.   0.4 -0.3 -0.3 -2.4 -0.2 -0.4  0.1  1.5 -0.1 -0.3 -0.2 -0.3 -0.2 -1.3 -0.4 -0.3  2.4  0.1 -0.  -0.2 -0.8 -0.2  0.7 -0.   0.7 -0.3 -0.1  1.  -0.1 -0.3  4.9 -1.3 -0.6  6.3 -0.4  1.5 -0.4 -0.2 -1.3 -0.7 -0.2  0.1 -0.7 -0.1 -1.1 -0.3 -0.2 -0.3 -1.4 -0.7  4.9 -1.   2.1  0.  -0.1 -0.  -0.5 -0.5 -0.3 -0.3 -3.  -0.2 -0.4  5.3 -0.3 -0.4  0.9 -0.7  1.9 -0.6 -0.2  4.5 -0.4  0.1  0.6 -0.6 -0.3 -0.1 -0.8  1.   2.8  0.1 -0.   0.7 -0.1  0.4  2.7 -0.1  2.7 -0.6 -1.4  0.4 -1.3  0.3  0.9  0.   0.7 -0.3 -0.2  7.   1.9 -0.   0.4 -0.2 -0.7  4.6  0.  -2.3 -0.3  0.7 -2. ]
ty_50sample [[7 6 3 2 8 1 4 0 5 9]
 [7 8 8 9 3 4 0 5 2 6]
 [8 9 2 7 5 1 0 4 6 3]
 [9 2 3 1 0 8 4 7 6 5]
 [1 8 4 6 2 9 5 0 3 7]
 [3 4 0 1 8 6 6 7 9 2]
 [3 7 9 0 4 4 5 6 2 1]
 [7 9 4 5 2 3 6 8 1 0]
 [7 4 5 8 3 9 2 1 6 0]
 [8 4 0 7 2 3 1 6 9 5]]
tt_50sample [[7 6 3 2 8 1 4 5 0 9]
 [7 8 9 1 3 4 0 5 6 2]
 [8 9 2 7 5 1 0 4 6 3]
 [9 2 3 1 0 8 4 7 6 5]
 [1 8 4 6 2 9 5 0 3 7]
 [3 4 0 8 1 6 5 7 9 2]
 [3 7 9 0 8 4 6 5 2 1]
 [7 9 4 5 3 2 6 8 1 0]
 [7 4 5 8 3 9 2 1 6 0]
 [8 4 0 7 2 3 1 6 9 5]]
vm  [-1.1 -1.  -2.1  5.7 -0.7 -0.  -0.2 -0.1  1.2  0.2  8.6 -0.7  0.2 -0.3 -2.7 -0.2  0.6 -0.1 -0.2 -1.2 -1.1 -0.1  1.4 -0.3 -1.2  3.1 -0.2  0.1 -1.  -2.6  3.  -0.4  0.3 -1.   0.6  0.3  1.8  3.8  5.8 -0.3  0.5  4.9 -0.7  1.1 -0.2 -0.4  5.9 -0.9 -0.9  3.6 -0.4 -0.3 -0.2  2.9 -0.2  3.8 -0.5  2.1  4.4 -0.9  2.1 -0.6  0.2 -0.   0.3 -0.2  0.2  1.2 -0.3 -0.2 -0.1  3.6 -0.2 -0.1 -1.2  0.3  0.6  0.5 -0.3 -0.2 12.7  0.8 -0.3 -0.6  0.4  4.4 -0.8 -0.1 -0.1 -0.4 -0.3 -0.6 -0.2 -0.9 -0.4 -0.3  0.1 -1.2 -0.4 -0.5 -0.4 -0.2  0.7 -0.  -0.3 -0.1 -0.8  1.9  0.8 -1.8 -0.4  0.1 -0.2 -0.3  5.8 -1.7  0.6 -0.2 -0.  -0.1 -0.1  6.  -0.2 -0.  -0.1 -3.1 -0.6 -0.1  3.8 -2.2 -0.9 -0.4 -0.5  0.4  7.5  5.6 -0.4 -0.2 -0.1 -0.4 -0.7 -0.7 -1.2 -0.1 -0.4 -0.3  0.5 -0.2  5.3 -0.1 -0.3 -0.2 -1.2 -0.4 -0.4 -0.3 -0.2  0.5  0.8 -0.2  0.3 -1.  -0.2 -0.2 -0.3 -0.6 -0.5 -0.1 -0.3 -0.4  0.1 -0.2 -0.5 -0.1  0.  -1.1 -0.8  0.4 -0.5 -0.  -0.9 -0.1  0.2 -1.1  0.1 -0.4 -0.4  0.8 -0.2  8.2 -0.1 -0.4 -0.8 -0.7  0.4 -0.6 -0.2 -1.1 -0.2  0.3 -0.  -0.1 -0.2 -0.4 -0.3  0.6 -0.3 -0.  -1.6 -0.   0.5 -0.8 -0.1  3.9 -0.2 -0.2 -0.3 -0.9 -0.7 -0.2 -0.1 -0.1 -0.2 -1.3  2.6 -1.2  0.5  2.2 -0.2 -0.4 -0.6 -0.4 -0.3 -1.   2.6  3.6  1.  -0.4 -0.1  6.  -0.2  2.6 -0.2 -0.1 -2.6 -1.8 -0.4 -0.5 -1.   0.2 -3.5 -0.1  4.3  0.1 -1.4 11.1]
vy_50sample [[0 0 2 9 5 4 6 8 3 7]
 [9 4 3 1 7 2 8 8 5 6]
 [8 8 1 4 6 5 7 9 2 3]
 [8 2 6 3 0 9 5 4 7 1]
 [2 1 9 5 7 6 3 0 8 4]
 [7 6 1 0 8 3 2 4 9 5]
 [6 5 2 1 8 7 4 0 3 9]
 [3 5 2 4 1 6 8 0 7 7]
 [5 0 3 7 8 4 1 9 6 2]
 [9 1 5 3 6 4 8 7 2 0]]
vt_50sample [[0 1 2 9 5 4 6 8 3 7]
 [9 4 3 1 7 2 8 0 5 6]
 [0 8 1 4 6 5 7 9 2 3]
 [8 2 6 3 0 9 5 4 7 1]
 [2 1 9 5 7 6 3 0 8 4]
 [7 6 1 0 8 3 2 4 9 5]
 [6 5 2 1 8 7 4 0 3 9]
 [3 5 2 4 1 6 8 0 7 9]
 [5 0 3 7 8 4 9 1 6 2]
 [9 1 5 3 6 4 8 7 2 0]]
Epoch 26410: Training cost= 0.3350, Training acc= 0.8318, Validation cost= 0.3383, Validation acc= 0.8319
Epoch 26420: Training cost= 0.2726, Training acc= 0.8318, Validation cost= 0.2648, Validation acc= 0.8319
Epoch 26430: Training cost= 0.2439, Training acc= 0.8318, Validation cost= 0.3027, Validation acc= 0.8319
Epoch 26440: Training cost= 0.2746, Training acc= 0.8318, Validation cost= 0.2539, Validation acc= 0.8320
Epoch 26450: Training cost= 0.2419, Training acc= 0.8319, Validation cost= 0.2620, Validation acc= 0.8320
Epoch 26460: Training cost= 0.2727, Training acc= 0.8319, Validation cost= 0.2947, Validation acc= 0.8320
Epoch 26470: Training cost= 0.2897, Training acc= 0.8319, Validation cost= 0.3323, Validation acc= 0.8320
Epoch 26480: Training cost= 0.3389, Training acc= 0.8319, Validation cost= 0.3246, Validation acc= 0.8320
Epoch 26490: Training cost= 0.2640, Training acc= 0.8319, Validation cost= 0.3055, Validation acc= 0.8321
Epoch 26500: Training cost= 0.2823, Training acc= 0.8320, Validation cost= 0.2484, Validation acc= 0.8321
tm  [-1.   0.9  6.  10.3 -1.6 -0.1 -0.1 -0.3 -0.5 -0.8 -4.8 -0.  -0.1 -0.2  0.5  1.9 -0.   0.  -0.1 -0.8 -0.6 -0.3  0.9 -0.2 -0.7 -0.  -0.1 -0.1  0.8 -1.  -2.4 -0.3  0.6 -3.4 -0.7 -0.   0.6  2.5  7.1 -0.3  0.1 -0.3  1.   0.1 -0.4 -0.3  2.8  0.  -0.3  5.1 -0.8 -0.2 -0.9 -0.7 -1.2  0.6 -0.3  8.7 -0.2  7.3  2.  -0.3 -0.4 -0.1 -0.6 -0.6 -0.2 -0.6 -0.  -0.3 -0.2 -0.7  0.4  0.2 -2.  -0.  -0.4 -0.3 -0.4 -0.3 -3.1 -0.3 -0.6 -0.1 -0.8 -0.  -1.5  0.  -0.1 -0.3 -0.2  0.2  0.1  1.6 -0.2 -0.3  0.8 -1.9  0.3 -0.3  3.7 -1.1 -0.1 -0.1 -0.3 -0.3 -1.2 -2.  -1.4 -1.  -0.  -0.2 -0.1 -0.4 -0.4  6.6 -0.2 -0.3 -0.1 -0.4 -0.1  3.8 -0.2 -0.3 -0.3  0.4  0.7  4.7  1.6  4.4 -0.4 -0.5 -0.2 -0.4 -1.9 -5.5 -0.2 -0.1  0.1  3.2 -0.2 -0.5  0.4 -0.1 -0.1 -0.2 -0.2 -0.2  3.9 -0.1 -1.  -0.   2.7 -0.1 -0.3 -0.3 -0.  -0.5  2.9 -0.4 -0.2 -1.2 -0.4 -0.2 -0.4 -0.2  0.3 -0.  -0.4 -0.1 -0.  -0.1 -0.2  0.4 -0.3 -0.5 -0.1 -0.4 -0.7 -0.3 -1.6 -0.2 -0.5 -1.  -0.3 -0.1  0.8 -0.6 -0.4  3.5 -0.1 -0.2 -0.8 -0.5  0.3 -0.5 -0.2  0.4 -0.1 -0.3 -0.1 -0.1 -0.3 -0.4 -0.1 -1.3  0.4 -0.1  4.7 -0.1 -0.5  3.3  0.   1.9 -0.3 -0.3  2.1 -0.2  0.  -0.7 -0.1 -0.1 -0.5 -1.1 -1.5  3.2 -1.  -0.1 -0.6  1.4 -0.8  0.2 -0.4  2.5 -0.5 -1.  -0.2 -0.5  0.4 -0.7 -0.1 -0.3 -0.2 -0.3 10.1 -0.9 -0.4 -0.3 -0.7  0.1  7.3 -0.5  5.1 -0.   4.7 -0.5]
ty_50sample [[8 3 5 1 9 7 2 0 6 4]
 [3 4 9 6 0 1 2 8 7 5]
 [9 7 1 2 8 6 3 0 4 5]
 [0 4 8 2 9 6 7 1 3 5]
 [8 7 9 9 3 1 6 4 2 0]
 [4 7 0 8 3 2 9 5 1 6]
 [4 0 0 7 9 2 8 1 6 3]
 [0 6 4 9 1 7 3 8 5 2]
 [2 2 9 6 3 4 5 1 0 8]
 [8 3 5 6 9 7 1 4 2 0]]
tt_50sample [[8 3 5 1 9 7 2 0 6 4]
 [3 4 9 6 0 1 2 8 7 5]
 [9 7 1 2 8 6 3 0 4 5]
 [0 4 8 2 9 6 7 1 3 5]
 [8 7 9 5 3 1 6 4 2 0]
 [4 7 0 8 3 2 9 5 1 6]
 [4 0 5 7 9 2 8 1 6 3]
 [0 6 4 9 1 7 3 8 5 2]
 [7 2 9 6 3 4 5 1 0 8]
 [8 3 5 6 9 7 1 4 2 0]]
vm  [-1.2 -0.2 -2.  -0.4 -1.5 -0.1 -0.2 -0.2 -0.9 -0.6  3.8  0.6 -0.7 -0.1 -0.9 -0.9 -0.1 -0.7 -0.1 -1.  -0.9 -0.3 -0.9 -0.1 -1.1  0.5 -0.3 -0.5 -1.3 -0.6  6.  -0.3 -0.   8.  -0.5  2.4  3.6 -0.1  7.5 -0.   0.6  2.8  1.6  4.8 -0.5 -0.2  5.1  0.8 -1.4 -2.5 -0.5 -0.2 -0.1 -2.2 -0.9  1.7 -0.8 -0.4 -0.5 -3.1  3.2 -0.4 -0.2 -0.5 -0.  -0.5 -0.1 -0.  -0.2 -0.1 -0.1  1.2 -0.1 -0.4 -0.8 -0.6  2.8 -0.5  0.4 -0.4 19.  -0.1 -0.4 -0.6  1.3  3.   0.8 -0.3 -0.1 -0.4 -0.2  0.2  0.4  1.6 -0.6 -0.1 -0.6 -0.4  1.1 -0.3  3.1 -0.2  3.2 -0.1 -0.1 -0.5 -0.8  5.8  0.6 -1.8 -0.8 -0.1  0.2 -0.2  1.3 -0.4  0.2 -0.7 -0.1 -0.2  0.3  7.1 -0.2 -0.4 -0.1 -1.   0.3 10.3  0.3 -0.6 -0.9 -0.1 -0.3 -0.3 -0.6  7.7 -0.1 -0.2  0.4 -0.8  2.6 -0.3  0.6 -0.3 -0.1 -0.2 -0.1 -0.1  4.1  0.1 -0.1  0.  -2.6 -0.  -0.3  0.  -0.4 -0.2  1.6 -0.  -0.2 -0.8 -0.4  0.6 -0.4 -0.  -0.5 -0.1  0.2 -0.3 -0.2 -0.  -0.2 -0.1 -0.3 -0.5 -0.5 -0.5 -0.8 -0.2 -1.3 -0.5  0.2 -0.9  0.4 -0.3 -1.  -0.2 -0.4  1.8  0.1 -0.3 -0.3 -1.1 -0.5  3.2  0.7  0.8 -0.4 -0.  -0.2 -0.2  0.7 -0.7 -0.2  0.2 -0.6 -0.4 -4.5 -0.2 -0.6 -0.8 -0.3  6.7  1.  -0.4 -1.6 -0.8 -0.2 -0.2 -0.4  0.2 -0.1 -1.2 -0.7 -1.2 -1.8 -0.5 -0.5 -1.  -0.7 -0.2 -0.  -2.7  1.5  5.3 -0.  -0.3 -0.1  0.9 -0.2  0.1 -0.1 -0.1 -4.2 -1.4 -0.5 -0.1 -0.9 -0.  -5.  -0.4  5.  -0.1  3.9  3.9]
vy_50sample [[1 4 5 9 0 3 7 6 2 8]
 [5 7 1 4 9 0 6 3 2 8]
 [3 9 5 4 6 7 1 2 8 0]
 [8 6 4 9 9 3 7 1 0 2]
 [0 5 8 1 9 2 7 4 6 3]
 [5 8 9 4 0 6 6 7 2 3]
 [6 5 1 4 8 3 2 9 7 0]
 [9 9 8 1 2 4 6 0 5 3]
 [7 5 8 2 0 1 6 4 3 9]
 [9 5 8 8 4 0 3 1 6 2]]
vt_50sample [[1 4 5 9 0 3 7 6 2 8]
 [5 7 1 4 9 0 6 3 2 8]
 [3 9 5 4 6 7 1 2 8 0]
 [8 6 4 9 5 3 7 1 0 2]
 [0 5 8 9 1 2 7 4 6 3]
 [5 8 9 4 0 6 1 7 2 3]
 [6 5 1 4 8 3 2 9 7 0]
 [9 7 8 1 2 4 6 0 5 3]
 [7 5 8 2 0 1 6 4 3 9]
 [9 5 7 8 4 0 3 1 6 2]]
Epoch 26510: Training cost= 0.2908, Training acc= 0.8320, Validation cost= 0.2797, Validation acc= 0.8321
Epoch 26520: Training cost= 0.2577, Training acc= 0.8320, Validation cost= 0.2624, Validation acc= 0.8321
Epoch 26530: Training cost= 0.3183, Training acc= 0.8320, Validation cost= 0.2890, Validation acc= 0.8322
Epoch 26540: Training cost= 0.3315, Training acc= 0.8320, Validation cost= 0.3113, Validation acc= 0.8322
Epoch 26550: Training cost= 0.2335, Training acc= 0.8321, Validation cost= 0.3275, Validation acc= 0.8322
Epoch 26560: Training cost= 0.2721, Training acc= 0.8321, Validation cost= 0.3286, Validation acc= 0.8322
Epoch 26570: Training cost= 0.2912, Training acc= 0.8321, Validation cost= 0.4153, Validation acc= 0.8322
Epoch 26580: Training cost= 0.3824, Training acc= 0.8321, Validation cost= 0.2603, Validation acc= 0.8322
Epoch 26590: Training cost= 0.3187, Training acc= 0.8321, Validation cost= 0.3193, Validation acc= 0.8323
Epoch 26600: Training cost= 0.3381, Training acc= 0.8321, Validation cost= 0.4140, Validation acc= 0.8323
tm  [-0.3 -0.  -1.2 -1.7 -1.7 -0.3  0.5 -0.2 -0.2 -0.7 -2.3 -0.3 -0.7 -0.4  1.4 -0.7 -0.1 -0.2 -0.2 -0.7 -0.7 -0.3  2.3 -0.1 -1.1  1.5 -0.4 -0.1  0.3  2.9  4.2 -0.6 -0.1  5.3 -0.4 -0.3  0.1 -1.1  2.8 -0.2 -0.7  2.9  0.6  2.8 -0.2  0.1  2.4  1.1  2.9  5.9 -0.5 -0.1  0.4 -1.9 -0.9 -0.  -0.3 -1.1 -0.1 -1.7 -0.6 -0.3 -0.2 -0.2  0.7 -0.3 -0.   0.2  1.2 -0.1 -0.2 -0.8  0.1  0.6 -1.4  0.8 -0.5  0.2 -0.1 -0.1  4.7 -0.3  0.  -0.1 -1.   4.6  5.9 -0.3 -0.2 -0.3 -0.1 -0.1 -0.2 -0.6 -0.6 -0.2 -0.  -1.4 -0.4 -0.1  1.4  6.3 -0.8 -0.1 -0.4  0.  -0.7  4.4 -0.9 -1.1 -0.2 -0.1 -0.1 -0.7  0.7  4.   0.  -0.2 -0.2 -0.3 -0.1  3.7 -0.1  1.1 -0.1  1.8 -0.1  9.7 -0.1 -1.1  2.4 -0.6 -0.  -0.3 -0.7  3.6 -0.3 -0.2 -0.1 -0.2  2.7 -0.5  2.9 -0.1 -0.3  0.4 -0.   0.2 -0.6 -0.1  1.2  0.2  2.5  1.3 -0.1 -0.1 -0.2 -0.1 -0.3 -0.5  0.4  0.   0.3 -0.2 -0.  -0.2 -0.3  0.7 -0.2 -0.5 -0.3 -0.2 -0.4 -0.2 -0.3  1.8 -0.6  1.1 -0.   0.4 -0.8 -0.1 -0.4 -1.7 -0.6 -0.3  2.6 -0.2  0.7 -0.6 -0.1 -0.2 -0.7 -0.9  6.5  0.2  0.9 -0.4 -0.  -0.1  0.  -0.1 -0.2 -0.4  0.3 -0.1  0.7  0.1  1.4 -0.3 -0.2  3.2 -0.6  0.9  0.8 -0.1 -0.9 -0.4  0.6 -0.2 -0.7 -0.5 -0.7 -1.   3.8  2.2 -2.1 -0.6  0.8  2.2 -0.8 -0.4 -0.2  1.2 -0.1  3.3  0.6 -0.3  2.8  5.2 -0.2  1.8  0.1 -0.3 -0.5 -1.6 -0.3  0.4 -1.  -0.3 -1.4 -0.2  1.9 -0.3  3.   7.7]
ty_50sample [[4 7 9 6 8 5 0 1 3 2]
 [9 0 6 5 2 2 3 1 7 4]
 [5 2 4 6 7 8 9 1 3 0]
 [1 4 6 5 0 7 9 9 8 3]
 [0 7 7 2 2 5 9 4 3 1]
 [4 1 8 8 9 0 7 5 2 6]
 [6 3 1 7 9 5 4 2 8 0]
 [4 7 3 9 1 8 2 5 6 0]
 [6 2 7 5 0 8 3 9 1 4]
 [3 2 1 8 0 9 5 7 6 4]]
tt_50sample [[4 7 9 6 5 8 0 1 3 2]
 [9 0 6 5 2 8 3 1 7 4]
 [5 2 4 6 7 8 9 1 3 0]
 [1 4 6 5 0 7 2 9 8 3]
 [0 8 7 2 6 9 5 4 3 1]
 [4 1 3 8 9 0 7 5 2 6]
 [6 3 1 7 9 5 4 2 8 0]
 [4 3 7 9 1 8 2 5 6 0]
 [6 2 7 5 0 8 3 9 1 4]
 [3 2 1 8 9 0 5 7 6 4]]
vm  [ 3.2 -0.5 -2.5 -1.2 -0.5 -0.4 -0.4 -0.2 -0.6  0.4 -2.6  0.6 -0.5 -0.  -0.8  0.1 -0.6 -0.1 -0.1 -0.8 -0.7  0.4  1.3  0.9 -1.4 -0.8 -0.6 -0.5 -0.3  1.2  0.4 -0.   3.2 -3.6 -0.3 -0.5  0.8 -0.8 -3.4 -0.8  1.9  6.4  0.7 -0.4 -0.6 -0.5  0.8 -0.5  2.6  7.4 -0.7 -0.2 -1.4 -0.3 -1.4  2.1 -0.8  2.9 -0.2  0.8 -0.7 -0.7 -0.5 -0.8 -0.1 -1.3 -0.2  2.1  1.5 -0.7 -0.1 -0.6 -0.4 -0.3 -4.6 -0.5 -1.  -0.6 -0.6 -0.3 -2.3  0.7 -0.5 -0.2 -1.6  5.6  4.7 -0.2 -0.4 -1.  -0.5  0.5 -0.3  1.1 -0.3 -0.2 -0.4 -1.7 -0.3 -0.5  0.  -0.3 -1.4 -0.2  1.3 -0.8 -2.5  0.8 -1.  -0.4  0.5 -0.5  0.4 -0.8  0.1  0.9 -0.3 -0.2 -0.2  0.1 -0.8 -0.3 -0.8 -0.7 -0.6 -1.2  0.   3.2  1.  -0.2  0.9 -0.6 -0.2 -0.1 14.   7.2  0.6 -0.2  0.1 -1.1 -0.2 -0.3 -0.1 -0.5  0.2 -0.3 -0.9 -0.   7.4 -0.3 -0.4  0.   3.8 -0.8 -0.2 -0.2  0.2 -0.5 -1.4 -0.1 -0.4 -0.  -0.4 -0.  -0.1  0.1 -0.  -0.7 -0.6  0.  -0.3  0.5 -0.5 -0.1 -0.3 -2.1 -3.  -0.9  6.3 -0.6 -2.2 -0.8  2.6 -0.5 -0.6 -0.   4.3  0.1 -0.7 -0.2 -0.2 -0.5 -0.2 -1.6  7.3 -0.4 -1.4 -0.3 -0.3 -0.1 -0.1 -0.7  1.  -0.5 -0.9 -2.1 -0.3 -0.2 -1.9  0.5 -0.3 -0.3 -0.5 -1.6  1.1 -0.3  1.5 -0.6 -0.3 -0.2 -0.3 -0.1 -0.2 -1.1  1.7  1.2 -1.2 -0.7 -0.4  3.   0.2  4.8 -0.3 -1.1 -1.1  3.8  1.3 -2.  -0.2 -4.3 -0.1 -1.8 -0.3  0.4  7.8 -0.3  1.1 -0.6 -0.8  1.4  5.8 -0.1 -2.1 -0.1  0.7  3.3]
vy_50sample [[5 6 4 8 0 0 3 3 7 1]
 [8 4 1 3 6 7 9 0 2 5]
 [4 0 3 1 7 5 9 8 2 6]
 [0 3 7 6 2 8 1 9 4 5]
 [7 5 8 6 9 2 1 0 4 3]
 [9 3 6 5 7 0 4 1 8 2]
 [1 5 6 3 9 2 8 4 7 0]
 [7 0 5 2 4 8 1 1 9 3]
 [0 9 8 4 1 3 6 2 5 7]
 [4 8 7 6 3 5 2 0 9 1]]
vt_50sample [[5 6 8 4 0 9 2 3 1 7]
 [8 4 1 3 7 6 9 0 2 5]
 [4 0 3 1 7 5 9 8 2 6]
 [0 3 7 6 2 8 1 9 4 5]
 [7 5 8 6 9 2 1 0 4 3]
 [3 9 6 5 7 0 4 1 8 2]
 [1 5 6 3 2 9 8 4 7 0]
 [7 0 5 2 4 8 1 3 6 9]
 [0 9 8 4 1 3 2 6 5 7]
 [4 8 7 6 3 5 2 0 9 1]]
Epoch 26610: Training cost= 0.3182, Training acc= 0.8322, Validation cost= 0.2526, Validation acc= 0.8323
Epoch 26620: Training cost= 0.2608, Training acc= 0.8322, Validation cost= 0.3511, Validation acc= 0.8323
Epoch 26630: Training cost= 0.2713, Training acc= 0.8322, Validation cost= 0.2993, Validation acc= 0.8323
Epoch 26640: Training cost= 0.3481, Training acc= 0.8322, Validation cost= 0.2693, Validation acc= 0.8323
Epoch 26650: Training cost= 0.3083, Training acc= 0.8322, Validation cost= 0.2914, Validation acc= 0.8324
Epoch 26660: Training cost= 0.3315, Training acc= 0.8323, Validation cost= 0.2914, Validation acc= 0.8324
Epoch 26670: Training cost= 0.3091, Training acc= 0.8323, Validation cost= 0.2950, Validation acc= 0.8324
Epoch 26680: Training cost= 0.2658, Training acc= 0.8323, Validation cost= 0.3438, Validation acc= 0.8324
Epoch 26690: Training cost= 0.2628, Training acc= 0.8323, Validation cost= 0.3137, Validation acc= 0.8324
Epoch 26700: Training cost= 0.2898, Training acc= 0.8323, Validation cost= 0.2928, Validation acc= 0.8325
tm  [-0.6  0.9  5.3 13.9 -2.  -0.4  0.7 -0.3 -0.9 -0.5  8.   1.3 -0.4 -0.6 -1.  -0.   1.3 -0.3  2.3 -0.8 -0.8 -0.5 -0.8  0.4 -1.1  1.8 -0.1 -0.2 -2.  -0.5  2.  -0.5 -0.2 11.2 -0.7  0.1  3.3  3.6 12.8 -0.2 -0.2  6.1  4.6  0.2 -0.4 -0.4  7.2 -0.4  1.6 -2.3 -0.3 -0.1  1.8 -1.5 -0.2  1.5 -0.3  8.3 -1.3 -1.3 -1.1 -0.1 -0.  -0.1 -0.8 -0.3 -0.2 -0.4  0.9  0.4 -0.2  1.8  1.1 -0.4  4.7 -0.3 -0.  -0.1 -0.3 -0.2 24.4 -0.2 -0.5 -0.5 -0.6  5.9 -0.2 -0.1 -0.3 -0.1 -0.3 -0.2  0.4  2.6  0.6 -0.7  0.1  1.3 -0.6 -0.5  2.8  4.6 -0.4 -0.2 -0.4 -0.3  1.9  2.1  0.9 -1.6 -0.2 -0.1 -0.2  1.6 -0.3 -1.4  0.3 -1.1  1.  -0.1 -0.3  6.6 -0.3  1.  -0.  -1.2 -0.   7.9 -0.3 -2.1 -0.5 -0.  -0.3 -0.5 -2.8  6.5 -0.4 -0.1 -0.  -0.6 -0.4 -1.1 -0.  -0.3 -0.1  0.1 -0.3 -0.3  4.1 -0.2 -1.2  0.1 -1.3 -0.1 -0.5 -0.2 -0.7 -0.3  3.1  2.1  0.8 -1.  -0.3 -0.1 -0.6 -0.4 -0.1 -0.9 -0.4  0.1 -0.4 -0.1 -0.1 -0.4 -0.1 -0.5 -0.   1.4 -1.4 -0.2 -1.6 -0.1  1.1 -1.  -0.1 -0.   1.2 -0.2 -0.2  1.   0.4 -0.4  0.1 -0.9  8.   3.7  3.8  1.3 -0.2 -0.4 -0.1 -0.1  0.2 -0.3 -0.2  7.5 -0.7 -0.5 -6.2 -0.1 -0.6 -1.   0.   1.9 -0.1 -0.4  0.7 -0.3 -0.  -0.5 -0.1 -0.  -0.2 -0.9 -0.3 -1.8 -0.7  0.3 -0.6 -0.6 -0.2 -1.  -0.3 -3.7  2.  -1.3 -0.1  4.5 -0.3  1.4 -0.1  0.5 -0.5 -0.  -5.3 -3.3 -0.3 -0.1 -0.3  0.2 -6.1 -0.2  8.3  0.1 -0.   8.7]
ty_50sample [[5 9 0 0 2 1 3 6 4 8]
 [5 4 2 1 9 0 3 7 8 6]
 [3 8 4 5 0 9 6 1 2 7]
 [0 9 3 6 1 4 8 5 7 2]
 [9 7 3 8 6 1 2 0 4 5]
 [1 4 3 7 0 2 6 8 9 5]
 [3 5 2 9 1 0 4 7 6 6]
 [6 0 2 8 3 5 1 7 7 4]
 [5 3 8 4 0 2 2 6 7 9]
 [4 9 0 7 7 1 2 5 3 8]]
tt_50sample [[5 9 0 7 2 1 3 4 6 8]
 [5 4 2 1 9 0 3 7 8 6]
 [3 8 4 5 0 9 6 1 2 7]
 [0 9 3 6 1 4 8 5 7 2]
 [9 7 3 8 6 1 2 0 4 5]
 [1 4 3 7 0 2 6 8 5 9]
 [3 5 2 9 1 0 4 7 6 8]
 [6 0 2 8 3 5 1 7 9 4]
 [5 3 8 4 1 0 2 6 7 9]
 [4 9 0 7 6 1 2 5 3 8]]
vm  [-0.7 -0.1 -2.5 -0.4 -0.5 -0.1 -0.3 -0.4 -0.6 -0.7  5.6 -0.  -0.4 -0.1 -1.5  7.1  0.7 -0.1 -0.4 -0.3 -0.8  0.6 -0.6 -0.4 -1.3  0.6 -0.1 -0.4  1.9 -1.6 -0.1 -0.6 -0.4 -3.9 -0.5 -0.3  1.1  5.1  2.  -0.5  0.8 -2.4 -0.2  2.6 -0.2 -0.1 -0.5 -1.1  0.8 -1.4 -0.5 -0.3 -0.3  7.9 -1.9  2.9 -0.5 -0.4  1.4  2.2  1.2 -0.3  0.1 -0.1 -0.9 -0.4 -0.1  0.3 -0.9 -0.1 -0.1 -1.3 -0.1  1.3 -4.1  0.  -0.6 -0.4 -0.5 -0.1 -1.4  0.2 -0.2 -0.4 -1.1 -2.1  1.3 -0.1  0.1 -0.5 -0.4 -0.4 -0.   0.5 -0.2 -0.  -0.5 -1.7 -0.2 -0.3  2.8 -3.3 -0.6  0.6 -0.2  1.6 -1.6 -0.   1.5 -0.9 -0.2 -0.3 -0.2 -0.8 -0.6  9.1  0.3 -0.5 -0.  -0.2  0.2  0.9 -0.4 -0.3 -0.3 -1.7 -0.  -1.9  1.5  8.9 -0.2 -0.2 -0.2 -0.1  6.3 -1.7 -0.4 -0.1 -0.   0.1 -1.2 -0.4 -1.2 -0.2 -0.1 -0.  -0.4 -0.1  4.5 -0.1 -0.  -0.1  1.9 -0.5 -0.1 -0.3 -0.5 -0.3  1.7 -0.5 -0.3 -1.4 -0.  -0.1  0.5 -0.1 -0.2 -0.  -0.  -0.2 -0.3 -0.4 -0.1 -0.2 -0.  -0.8 -0.5 -0.4  0.4 -0.4 -0.5  0.7 -0.4 -1.3 -0.6 -0.1  1.1  0.9 -0.5  4.8 -0.1  0.1 -0.2 -1.2  1.3 -0.5 -0.4  0.5  0.2 -0.2  0.1  0.1 -0.1 -0.4 -0.5 -1.2 -0.3 -0.2  4.2 -0.4 -0.   4.1 -0.6  0.8 -0.1 -0.3 -0.6 -0.7 -1.1  0.9 -0.4 -0.4 -0.4 -0.8 -1.8  4.1  0.6 -0.2 -0.3  1.2 -0.6  1.1 -0.2  2.7 -1.3  4.4 -0.2 -1.2 -0.4  2.4 -0.2  1.2 -0.2 -0.3  6.4 -0.6 -0.6 -0.1 -0.8 -0.3  3.1 -0.2  1.6 -0.2  0.5 -2.3]
vy_50sample [[3 2 8 4 1 1 6 6 0 7]
 [4 4 2 8 1 1 0 7 3 5]
 [9 2 2 3 0 0 4 6 6 5]
 [9 3 4 6 2 2 8 1 7 5]
 [6 4 0 1 9 5 7 3 2 8]
 [8 7 2 4 1 6 0 3 9 5]
 [6 1 1 4 3 2 0 9 8 7]
 [5 2 7 9 6 0 1 4 8 3]
 [2 5 9 0 6 3 3 7 4 1]
 [5 7 2 4 0 3 6 6 1 8]]
vt_50sample [[2 3 8 4 1 9 5 6 0 7]
 [4 2 6 8 9 1 0 7 3 5]
 [9 2 8 7 3 0 4 6 1 5]
 [9 3 4 6 2 0 8 1 7 5]
 [6 4 0 1 9 5 7 3 2 8]
 [8 7 2 4 1 6 0 3 9 5]
 [6 5 1 4 3 2 0 9 8 7]
 [5 2 7 9 6 0 1 4 8 3]
 [2 5 9 0 6 8 3 7 4 1]
 [5 7 2 0 4 3 6 9 1 8]]
Epoch 26710: Training cost= 0.2911, Training acc= 0.8324, Validation cost= 0.2687, Validation acc= 0.8325
Epoch 26720: Training cost= 0.2581, Training acc= 0.8324, Validation cost= 0.2796, Validation acc= 0.8325
Epoch 26730: Training cost= 0.2811, Training acc= 0.8324, Validation cost= 0.2243, Validation acc= 0.8325
Epoch 26740: Training cost= 0.2981, Training acc= 0.8324, Validation cost= 0.2985, Validation acc= 0.8326
Epoch 26750: Training cost= 0.2911, Training acc= 0.8324, Validation cost= 0.2804, Validation acc= 0.8326
Epoch 26760: Training cost= 0.2902, Training acc= 0.8325, Validation cost= 0.3869, Validation acc= 0.8326
Epoch 26770: Training cost= 0.3202, Training acc= 0.8325, Validation cost= 0.3780, Validation acc= 0.8326
Epoch 26780: Training cost= 0.2913, Training acc= 0.8325, Validation cost= 0.3476, Validation acc= 0.8326
Epoch 26790: Training cost= 0.3095, Training acc= 0.8325, Validation cost= 0.2981, Validation acc= 0.8326
Epoch 26800: Training cost= 0.2887, Training acc= 0.8325, Validation cost= 0.3044, Validation acc= 0.8327
tm  [-1.3 -0.4  6.1 12.5 -1.2 -0.2 -0.2 -0.2 -0.5 -0.2 -0.8 -0.4 -0.2 -0.1 -0.2  6.3  0.2  0.4  0.3 -0.9 -1.1 -0.3  0.4 -0.5 -0.5 -0.3 -0.3 -0.2  1.3 -0.8 -2.9 -0.3 -0.4 -4.3 -0.2 -0.5  0.2  7.1 10.3 -0.2 -0.3  2.7 -0.   0.2 -0.3 -0.2  3.4 -0.7 -1.1 11.7 -0.2 -0.1 -1.2  6.  -1.2  1.1 -0.5  7.5  0.7  8.   3.  -0.7 -0.6 -0.6 -1.1 -0.7 -0.   1.2 -0.1 -0.5 -0.4 -0.9 -0.1  0.5 -3.  -0.3 -0.2 -0.3 -0.5 -0.  -3.5 -0.3 -0.7 -0.5 -0.3  3.3 -1.9  0.  -0.4 -0.4  0.3 -0.3 -0.1  0.6 -0.3 -0.3 -0.8 -1.7 -0.2 -0.7  0.1  3.1  0.1 -0.  -0.4 -0.4 -1.5 -2.3  0.1 -1.7  1.2 -0.4 -0.2 -0.6 -0.4  6.4 -0.1 -0.7  0.2 -0.3  0.1  4.8 -0.3 -0.2  0.6 -0.4 -0.5 -1.2  1.  -0.6 -1.  -0.1 -0.2 -0.  -2.6 -7.2 -0.2 -0.2 -0.3  2.3 -1.4 -0.5 -1.3 -0.4 -0.2 -0.1 -0.5 -0.2  2.1 -0.3 -1.1  0.1  1.5 -0.3  0.  -0.4 -0.3 -0.4  3.6 -0.4 -0.2 -2.1 -0.1 -0.2 -0.5  0.3 -0.1  0.1 -0.6 -0.4 -0.2 -0.4 -0.3 -0.1 -0.1 -0.5  0.6 -0.5 -1.2 -0.2 -1.2 -0.2  0.9 -0.3 -0.4  1.4 -0.2 -0.5 -0.6  2.8 -0.1 -0.3 -0.5 -0.3 -0.3 -0.3 -0.4  1.5 -0.4 -0.3 -0.2 -0.2 -0.  -0.3 -0.3 -0.9 -0.2 -0.1  6.  -0.3 -0.3  1.9 -0.1  3.  -0.2 -0.4  1.2 -0.8 -0.6 -0.4  0.1 -0.4 -0.6 -1.2 -0.4  2.2  1.7  0.9 -0.6 -0.2 -0.8  0.6 -0.3  3.3 -1.1 -1.2  0.1 -0.8 -0.5 -0.1 -0.  -0.2 -0.3 -0.2 11.4 -1.   0.3 -0.2 -0.4 -0.1  8.8  0.1  7.1  0.1 -1.3  4.7]
ty_50sample [[8 2 1 5 9 7 3 0 6 4]
 [0 5 7 6 2 8 3 4 9 9]
 [0 7 7 4 2 5 6 8 9 3]
 [4 5 0 7 9 1 6 2 3 8]
 [2 4 9 5 0 8 6 7 3 1]
 [6 8 7 5 4 3 2 0 1 9]
 [9 5 1 3 2 7 4 4 0 6]
 [7 5 9 2 1 0 8 4 3 6]
 [3 9 9 6 4 1 5 7 8 2]
 [4 7 0 1 6 3 2 9 8 5]]
tt_50sample [[8 2 1 5 9 7 3 0 6 4]
 [0 5 7 6 2 8 3 4 1 9]
 [0 7 1 4 2 5 6 8 9 3]
 [4 5 0 7 9 1 6 2 8 3]
 [2 4 9 5 0 8 6 7 3 1]
 [6 8 7 5 4 3 2 1 0 9]
 [9 5 1 3 2 7 8 4 0 6]
 [7 5 9 2 1 0 8 4 3 6]
 [3 0 9 6 4 1 5 7 8 2]
 [4 7 0 1 6 3 2 9 8 5]]
vm  [-1.  -0.2 -1.1 -0.7 -0.6 -0.3 -0.4 -0.3 -0.3 -0.9 -2.2 -0.5 -0.  -0.  -0.2  3.8 -0.   0.7 -0.   1.1 -1.2 -0.1  1.  -0.2 -0.7  0.  -0.5 -0.1 -0.6 -2.  -1.4 -0.1  0.8 -5.8 -0.4 -0.1  0.2  4.1 -0.4 -0.6 -0.  -3.6 -0.8  1.2 -0.2 -0.2 -1.4 -0.4  0.6  4.8 -0.7 -0.2 -0.9  7.3 -0.9  0.6 -0.6 -1.1  3.7  5.3  4.6 -0.1 -0.   0.6 -1.4 -0.4 -0.  -0.3 -0.5  0.5 -0.2  0.5  0.7  0.3 -4.4  0.  -0.4 -0.5 -0.4 -0.3 -5.1 -0.3 -0.2 -0.1 -0.9 -3.7 -0.5 -0.4 -0.3 -0.2 -0.4 -0.4  0.2  0.8 -0.4 -0.3 -0.4 -2.6 -0.2 -0.4  3.2 -3.   0.2  0.2 -0.3 -0.3 -2.  -1.7 -0.6 -0.5 -0.2 -0.4 -0.1 -0.5  2.7  2.5 -0.1  0.1 -0.4 -0.4 -0.2  0.7 -0.4 -0.1 -0.4 -0.3 -0.3 -1.5  2.5  8.4 -0.3 -0.5 -0.2 -0.5  5.  -4.8 -0.  -0.2 -0.   3.9 -0.8 -0.7 -1.4 -0.1 -0.1 -0.1 -0.3 -0.1 -0.3 -0.1 -0.  -0.2  2.8 -0.6 -0.5 -0.2 -0.2 -0.6  2.5 -0.5 -0.4 -1.  -0.4 -0.3 -0.4 -0.   0.5  2.4  0.7 -0.3  0.1 -0.3 -0.3 -0.2 -0.2  1.3 -0.3 -0.6  2.1 -0.7  2.4 -0.1 -0.3 -0.7 -0.3  0.6 -0.1 -0.1 -0.5  6.  -0.1 -0.1 -0.2 -0.5 -1.  -0.9 -0.7 -0.5 -0.3 -0.1 -0.1 -0.2 -0.2 -0.5 -0.3 -2.5 -0.4  0.6 12.9 -0.4 -0.4  0.  -0.8  1.7 -0.2 -0.7  0.3 -0.7 -0.7 -0.1 -0.1  0.4 -0.2 -0.9 -1.5  1.1 -0.1  0.6 -0.8  2.2 -0.5 -0.1 -0.3  6.5  0.6  2.3 -0.1 -1.  -0.1  7.4 -0.2  3.4 -0.2 -0.3 15.8  1.8 -0.2 -0.2 -0.8  0.8 12.9 -0.  -0.2 -0.   2.3 -2. ]
vy_50sample [[8 3 2 1 0 4 6 9 7 5]
 [5 9 2 4 6 8 0 0 1 3]
 [6 3 2 9 7 1 8 0 5 4]
 [8 3 9 1 4 7 0 5 2 6]
 [5 3 2 7 8 0 4 1 6 9]
 [8 3 6 7 1 4 2 5 0 9]
 [4 1 0 2 8 6 3 9 5 7]
 [2 9 9 5 4 4 0 0 3 7]
 [2 6 0 5 3 8 4 1 7 9]
 [2 8 3 7 1 1 0 9 6 5]]
vt_50sample [[8 3 2 1 0 4 6 9 7 5]
 [5 9 2 4 6 8 7 0 1 3]
 [6 3 2 9 7 1 8 0 5 4]
 [8 3 9 1 4 7 0 5 2 6]
 [5 2 3 7 8 0 4 1 6 9]
 [8 3 6 7 1 4 2 5 9 0]
 [4 1 0 2 8 6 3 9 5 7]
 [2 1 9 5 4 6 8 0 3 7]
 [2 6 0 5 3 8 4 1 7 9]
 [2 8 3 7 4 1 0 9 6 5]]
Epoch 26810: Training cost= 0.2444, Training acc= 0.8326, Validation cost= 0.2966, Validation acc= 0.8327
Epoch 26820: Training cost= 0.2930, Training acc= 0.8326, Validation cost= 0.2836, Validation acc= 0.8327
Epoch 26830: Training cost= 0.3460, Training acc= 0.8326, Validation cost= 0.3046, Validation acc= 0.8327
Epoch 26840: Training cost= 0.3359, Training acc= 0.8326, Validation cost= 0.2658, Validation acc= 0.8327
Epoch 26850: Training cost= 0.3069, Training acc= 0.8326, Validation cost= 0.3233, Validation acc= 0.8327
Epoch 26860: Training cost= 0.3161, Training acc= 0.8326, Validation cost= 0.2782, Validation acc= 0.8328
Epoch 26870: Training cost= 0.2489, Training acc= 0.8327, Validation cost= 0.3150, Validation acc= 0.8328
Epoch 26880: Training cost= 0.2813, Training acc= 0.8327, Validation cost= 0.2566, Validation acc= 0.8328
Epoch 26890: Training cost= 0.2825, Training acc= 0.8327, Validation cost= 0.3026, Validation acc= 0.8328
Epoch 26900: Training cost= 0.2914, Training acc= 0.8327, Validation cost= 0.2377, Validation acc= 0.8329
tm  [-0.8 -0.8 -1.  13.1 -1.  -0.2 -0.6 -0.3  1.8  0.8  4.9 -0.3 -0.3 -0.2 -3.2 -1.  -0.  -0.4  0.4 -1.6 -1.3  0.6 -0.7 -0.1 -0.4  3.8 -0.2 -0.  -1.5 -4.1  0.2 -0.4 -0.7 -1.8  0.5 -0.2  1.   4.8 15.  -0.5  0.5 -2.1 -1.3  1.3 -0.3 -0.1  7.4 -0.6  0.8 -1.7 -0.2 -0.1  1.9 -0.7  2.5  4.5 -0.9 -0.4  6.   2.5 -0.5 -0.2  0.5  1.9 -0.4  0.5 -0.  -0.1 -0.4  0.7 -0.3  4.9 -0.4 -0.2 -0.1  0.2 -0.8 -0.5 -0.3  0.3 12.6  0.2 -0.3 -0.7 -0.3 -2.4 -0.5 -0.3 -0.3 -0.2 -0.3 -0.7  0.3 -1.   0.  -0.4 -0.4 -1.2 -0.1 -0.1 -0.3 -2.6 -0.1  0.2 -0.1  0.4  1.2 -0.1  1.2 -2.3 -0.2  0.7 -0.1 -0.4  7.2 -2.4  0.5  1.4 -0.2  0.3  0.6  9.  -0.1 -0.  -0.2 -3.8 -0.5  5.2  5.7 -0.1 -0.5 -0.2 -0.4 -0.1  1.7 -1.7 -0.2 -0.1 -0.1 -0.1 -0.4 -1.1 -1.  -0.4 -0.2 -0.3  0.1 -0.   2.4 -0.2 -0.7 -0.  -0.1 -0.1 -0.2 -0.2  0.4  0.2  3.7 -0.3 -0.2 -1.9 -0.  -0.  -0.2 -0.3 -0.2  1.5 -0.3 -0.2 -0.1 -0.6  0.1  0.1  0.4 -0.1  1.6 -0.  -1.8 -0.2 -0.1 -0.1 -0.4 -1.1  0.6 -0.1  1.3  0.5 -0.1 12.8  0.5  1.1 -0.8 -0.7  5.3 -1.4  1.1 -1.2 -0.1  0.7 -0.3 -0.1 -0.2 -0.4 -0.4  3.8 -0.3 -0.2  4.4  0.1 -0.1 -1.2 -0.7 -0.  -0.7 -0.1 -0.4 -1.  -0.7 -0.5 -0.4 -0.2  0.4 -0.7 -1.6 -1.4 -0.7  1.9 -0.   1.4 -0.4 -1.2 -0.   1.9  3.6  2.6  1.2  1.8  2.8 17.2 -0.1  6.8  0.2 -0.3 -2.4 -2.4 -0.2 -0.1 -1.4 -0.4 -3.4 -0.  10.4  0.7  2.3  2.8]
ty_50sample [[0 9 3 2 1 8 4 5 7 7]
 [2 1 0 6 7 3 5 4 9 9]
 [3 9 7 6 1 2 5 0 8 4]
 [4 9 2 2 8 8 1 6 5 7]
 [1 3 0 5 4 7 9 9 8 6]
 [7 2 9 6 8 5 3 0 4 1]
 [4 0 6 6 1 7 5 3 8 2]
 [1 5 0 4 8 2 6 7 9 9]
 [8 4 3 5 6 2 7 0 9 1]
 [1 2 2 9 8 3 0 4 7 7]]
tt_50sample [[0 9 3 2 1 8 4 5 6 7]
 [2 1 0 6 7 3 5 4 9 8]
 [3 9 7 6 1 2 5 0 8 4]
 [4 9 3 2 8 0 6 1 5 7]
 [1 3 0 5 4 7 9 2 8 6]
 [7 2 9 6 8 5 3 0 4 1]
 [4 0 6 9 1 7 5 3 8 2]
 [1 5 0 4 8 2 6 7 3 9]
 [8 4 3 5 6 2 7 0 9 1]
 [1 2 6 8 9 3 0 4 5 7]]
vm  [-1.2  5.4 -1.   0.8 -1.2  0.4 -0.7 -0.1 -2.1 -1.7 -0.  -0.6  0.7  1.  -0.7  4.5 -0.3 -0.4 -0.1 -1.8 -0.5 -0.4 -0.4  0.9 -1.5 -0.4  0.7  0.4 -0.1  2.8  1.3  0.3 -0.5 -1.  -0.8  0.6  4.9  1.9 10.6 -0.4 -0.2 -0.6  4.8  3.9 -0.   1.3  5.6  0.1 -0.8 -0.9 -0.4 -0.1  0.2 -0.3 -1.3  1.1 -0.8  3.4 -2.5  0.2  0.1 -0.2 -1.  -0.7 -0.6  2.6 -0.1 -1.  -0.2 -0.  -0.1 -1.5 -0.6 -0.4  2.7 -0.4 -0.  -0.1 -0.8  0.9  2.3 -0.6 -0.7 -0.1  1.1 -0.   1.9  0.6 -0.   0.8 -0.4  0.4 -0.1  6.7 -0.1  0.3 -0.1  0.5  0.6  0.5  7.2 -2.1  1.1 -0.   1.  -0.7 -0.6  1.2  0.1 -1.8 -0.5 -0.1 -0.2 -0.  -2.  11.1 -0.2 -2.2 -0.4 -1.  -0.4  7.4 -0.2 -0.  -0.6 -0.7  0.8  3.3 -1.4  2.8 -0.1 -0.9 -0.2 -0.3 -1.  -2.5 -0.3 -0.2  0.2 -0.9 -0.4 -0.3 -0.4 -0.2 -0.2  0.1 -0.3 -0.3  6.7  0.5 -0.5 -0.2  1.3  0.7 -0.6 -0.3 -0.4  0.9  0.8 -0.6 -1.3 -0.8 -0.6 -0.1 -0.2  1.7  0.7 -0.5 -0.   0.5  0.8 -0.4  0.3 -0.3 -0.  -1.   0.6 -0.4 -1.1 -0.7 -2.4  1.2 -0.1 -1.2 -0.4 -0.3 -0.3 -0.9 -0.2 -0.8 -0.2  0.8 -0.2 -1.3  3.2  4.9  1.5  6.1 -0.4 -0.1 -0.3 -0.  -0.5 -0.7  0.1 -0.9 -0.3 -0.3 -0.4  0.7 -0.2  2.  -0.1  2.2  0.1 -0.7 -1.1 -0.3 -0.4 -0.9 -0.5  0.4 -0.2 -0.5 -1.9  6.2 -0.5 -0.6  0.4 -0.5 -1.2 -0.5 -0.6 -0.4 -0.3  1.5 -1.2  1.3 -0.  -0.  -0.2 -0.2 -0.3  0.2  1.2 -0.7 -0.4 -0.4 -0.3 -0.2 -0.7  0.4  5.9 -0.1  4.9 -0.2]
vy_50sample [[3 5 4 4 8 2 7 7 6 0]
 [4 5 9 3 8 1 2 7 0 6]
 [5 4 1 8 3 0 9 6 2 7]
 [1 6 5 8 3 2 4 9 0 7]
 [2 2 4 9 9 0 3 8 6 1]
 [7 5 3 9 2 0 6 1 4 8]
 [0 6 1 8 5 2 2 7 3 4]
 [3 8 8 5 7 2 0 1 4 6]
 [7 2 0 6 3 5 1 4 9 8]
 [2 9 9 8 3 4 7 0 1 1]]
vt_50sample [[3 5 9 4 8 1 2 7 6 0]
 [4 5 9 3 8 1 2 7 0 6]
 [5 4 1 8 3 9 0 6 2 7]
 [1 6 5 8 3 2 4 9 0 7]
 [2 7 4 5 9 0 3 8 6 1]
 [7 5 3 9 2 0 6 1 4 8]
 [0 6 1 8 5 9 2 7 3 4]
 [3 9 8 5 7 2 0 1 4 6]
 [7 2 0 6 3 5 1 4 9 8]
 [2 9 6 8 3 4 7 0 1 5]]
Epoch 26910: Training cost= 0.3561, Training acc= 0.8327, Validation cost= 0.2791, Validation acc= 0.8329
Epoch 26920: Training cost= 0.2845, Training acc= 0.8328, Validation cost= 0.3604, Validation acc= 0.8329
Epoch 26930: Training cost= 0.2795, Training acc= 0.8328, Validation cost= 0.2853, Validation acc= 0.8329
Epoch 26940: Training cost= 0.2925, Training acc= 0.8328, Validation cost= 0.3380, Validation acc= 0.8329
Epoch 26950: Training cost= 0.3141, Training acc= 0.8328, Validation cost= 0.2791, Validation acc= 0.8329
Epoch 26960: Training cost= 0.3534, Training acc= 0.8328, Validation cost= 0.3324, Validation acc= 0.8330
Epoch 26970: Training cost= 0.2536, Training acc= 0.8329, Validation cost= 0.3000, Validation acc= 0.8330
Epoch 26980: Training cost= 0.3083, Training acc= 0.8329, Validation cost= 0.2984, Validation acc= 0.8330
Epoch 26990: Training cost= 0.2635, Training acc= 0.8329, Validation cost= 0.2885, Validation acc= 0.8330
Epoch 27000: Training cost= 0.2939, Training acc= 0.8329, Validation cost= 0.3000, Validation acc= 0.8330
tm  [ 1.6 -0.4 -0.6 -2.4 -1.  -0.7 -0.1 -0.3  0.2 -0.1  7.6  2.5 -1.  -0.3  5.3  3.9 -0.6 -0.2 -0.6  2.5 -1.2 -0.1 -0.9 -0.3 -1.3 -0.1 -0.  -0.2  1.1 -2.2  3.2 -0.5 -0.2  3.8 -0.4 -0.6 -0.7  5.9  0.7 -0.6  0.7  3.7  0.6  3.9 -0.4 -0.2 -2.1 -0.8  3.2 -2.6 -1.  -0.3 -0.2 10.9 -1.9 -0.5 -0.3  5.4  3.7 -1.   2.3 -0.8  0.5 -0.4  1.9 -1.5 -0.   3.5 -0.2 -0.4 -0.1 -1.  -0.2 -0.4 -7.2 -0.5 -0.8 -0.5 -0.5 -0.2 -1.1  0.5 -0.1 -0.3 -1.7  2.9  4.5 -0.2 -0.2 -0.7 -0.1 -0.2 -0.3 -0.1 -0.8 -0.3 -0.8 -2.7 -0.6 -0.7 -0.  -1.5 -1.4 -0.3 -0.4 -0.1 -3.1  3.   1.6  2.2  1.3 -0.5 -0.1 -1.  -0.2  4.4  1.   2.5 -0.   3.1 -0.1 -1.6 -0.1 -0.5 -0.3  6.3 -0.4 -2.7  6.7 11.1 -0.1 -0.2  0.9  1.2 -2.2 -1.1 -0.1 -0.3 -0.6 -1.1 -0.6  0.3 -0.3  0.3 -0.2 -0.4 -0.1 -0.2  6.5 -0.7  1.1 -0.3  1.8 -0.5 -0.1  0.4 -0.3  0.6  2.5 -0.4 -0.4 -2.4 -0.  -0.4 -0.1 -0.3 -0.8 -0.4 -0.3 -0.5 -0.6 -0.1 -0.6  1.1 -0.3 -2.  -0.4 -1.2  1.1 -0.2 -2.  -0.2  0.3 -1.7 -0.3 -0.1  2.3 -0.5 -0.2  6.2 -0.6 -0.3 -0.3 -1.7 -0.  -1.8 -1.7 -0.3 -0.2 -0.2  0.6 -0.3 -0.2 -0.2 -0.7 -3.   0.7 -0.3 -4.9 -0.2 -0.7  3.1 -0.7 -0.9  1.2  1.2 -1.2 -0.6 -0.3 -0.1 -0.1 -0.6  0.6 -1.  -2.   1.  -0.3 -0.7  1.9  4.3 -0.6  3.4 -0.2 -3.  -1.4  1.1  1.  -2.4 -0.3 -6.5 -0.2 -2.9 -0.3 -0.1  5.   3.1 -0.4 -0.6 -0.7 -0.1  2.2 -0.2  1.1 -0.1  0.5 -3.2]
ty_50sample [[5 3 2 4 7 8 0 1 6 9]
 [6 7 2 2 4 5 9 0 3 1]
 [5 8 3 3 0 6 7 1 4 2]
 [4 8 6 0 1 5 7 9 2 3]
 [5 1 8 0 2 4 3 6 9 7]
 [0 3 9 4 2 8 1 6 7 5]
 [2 7 3 9 8 6 5 1 4 0]
 [6 9 3 2 1 4 8 0 7 5]
 [0 1 2 9 5 7 6 4 3 8]
 [7 8 9 0 9 6 5 3 4 1]]
tt_50sample [[5 3 2 4 7 0 8 1 6 9]
 [6 7 8 2 4 5 9 0 3 1]
 [8 5 3 9 0 6 7 1 4 2]
 [4 8 6 0 1 5 7 9 2 3]
 [1 5 8 0 2 4 3 6 9 7]
 [0 3 9 4 2 8 1 6 7 5]
 [2 7 3 9 8 6 5 1 4 0]
 [6 9 3 2 1 4 8 0 7 5]
 [0 1 2 9 5 7 4 6 3 8]
 [7 8 0 9 2 6 5 3 4 1]]
vm  [-0.7  0.7  4.8 15.8 -1.2 -0.2 -0.2 -0.2 -1.  -0.4  2.2 -0.4 -0.3 -0.1 -1.3  3.2  0.1 -0.4 -0.3 -1.1 -0.5 -0.3  2.1 -0.3 -0.8  0.8 -0.4 -0.  -0.7  1.6 -1.6 -0.1  0.1 -2.4 -0.3 -0.1  3.  -0.3 -1.3 -0.2 -0.4  5.1  2.3 -2.  -0.5 -0.2  4.5 -0.5  0.8  8.3 -0.5  0.1 -0.1  1.7 -0.6  2.5 -0.5  8.7 -1.2  6.3 -0.6 -0.2 -0.5 -0.2 -0.7 -0.2 -0.1 -0.2  0.2 -0.4 -0.1 -0.1  0.3 -0.1 -1.  -0.2 -0.2 -0.3 -0.3  0.2  1.1 -0.3 -0.4  0.4 -0.5  6.3 -0.9  0.8 -0.3 -0.4 -0.8 -0.3  0.1  1.8 -0.1  0.  -0.3 -0.8 -0.3 -0.3  1.4  2.8 -0.4 -0.1 -0.3 -0.4 -0.5 -1.1  0.7 -1.7 -0.4 -0.2 -0.2 -0.3 -0.8  1.  -0.3 -1.3 -0.2 -0.4  0.2  5.7 -0.1 -0.3 -0.  -1.7  0.   0.8 -0.7 -1.6 -0.1 -0.3 -0.2 -0.4 11.7  7.9 -0.1 -0.2 -0.1 -0.5 -0.8 -0.5 -0.7 -0.2 -0.1 -0.1 -0.2 -0.1  4.9 -0.  -1.4 -0.   2.1 -0.1 -0.  -0.  -0.2 -0.2 -1.5 -0.7  0.4  2.9 -0.3 -0.1 -0.3  0.   0.2 -0.6 -0.1 -0.3 -0.1 -0.2 -0.2 -0.1 -0.2 -1.1 -1.3 -0.1  3.3 -0.1 -1.6 -0.3 -0.3 -0.8 -0.5 -0.   0.6 -0.3 -0.1 -0.3  0.4 -0.4 -0.5 -0.4  5.1  3.1  0.6  1.6 -0.2 -0.1 -0.3 -0.2 -0.  -0.1  0.2 -0.2 -0.3 -0.1 -0.3  0.2 -0.5 -0.4 -0.3  0.8 -0.3 -0.4  8.3 -0.5 -0.6 -0.4 -0.1 -0.1 -0.2 -0.8  5.   1.5 -0.2  0.6 -0.4 -0.   1.2 -0.5 -0.1 -0.2 -0.  -0.8 -0.1  0.5  0.2 -0.1 -0.1 -0.2 -0.  -0.2  1.  -1.6  0.6  0.7 -0.8 -0.6 -0.5 -0.2 -0.9 -0.1 -1.   8. ]
vy_50sample [[6 5 2 8 9 0 1 7 3 4]
 [8 4 2 9 1 5 3 6 7 0]
 [5 4 3 0 0 7 1 8 9 6]
 [9 7 8 2 6 3 1 0 4 5]
 [8 1 0 5 6 7 2 2 4 9]
 [5 8 7 9 0 6 4 3 1 2]
 [9 3 0 8 5 1 2 4 6 7]
 [2 9 5 1 6 0 7 7 8 3]
 [6 4 8 5 9 3 7 2 1 0]
 [0 4 6 8 7 2 1 3 5 9]]
vt_50sample [[6 5 2 8 9 0 1 7 3 4]
 [8 4 2 9 1 5 3 6 7 0]
 [5 4 3 2 0 7 1 8 9 6]
 [9 7 8 2 6 3 1 0 5 4]
 [8 1 0 5 6 7 3 2 4 9]
 [5 8 7 9 0 6 3 4 1 2]
 [9 3 0 8 1 5 2 4 6 7]
 [2 9 5 1 6 0 4 7 8 3]
 [6 4 5 8 9 3 7 2 1 0]
 [0 4 6 8 7 2 1 3 5 9]]
Epoch 27010: Training cost= 0.2886, Training acc= 0.8329, Validation cost= 0.3048, Validation acc= 0.8331
Epoch 27020: Training cost= 0.2578, Training acc= 0.8330, Validation cost= 0.2792, Validation acc= 0.8331
Epoch 27030: Training cost= 0.3221, Training acc= 0.8330, Validation cost= 0.2579, Validation acc= 0.8331
Epoch 27040: Training cost= 0.3338, Training acc= 0.8330, Validation cost= 0.2564, Validation acc= 0.8331
Epoch 27050: Training cost= 0.2825, Training acc= 0.8330, Validation cost= 0.2816, Validation acc= 0.8331
Epoch 27060: Training cost= 0.2276, Training acc= 0.8330, Validation cost= 0.2452, Validation acc= 0.8332
Epoch 27070: Training cost= 0.3056, Training acc= 0.8331, Validation cost= 0.3992, Validation acc= 0.8332
Epoch 27080: Training cost= 0.2710, Training acc= 0.8331, Validation cost= 0.3404, Validation acc= 0.8332
Epoch 27090: Training cost= 0.3226, Training acc= 0.8331, Validation cost= 0.2935, Validation acc= 0.8332
Epoch 27100: Training cost= 0.2713, Training acc= 0.8331, Validation cost= 0.2934, Validation acc= 0.8332
tm  [-1.2 -0.4  7.7 -0.7 -1.4 -0.5  0.7 -0.2 -0.6 -0.4 -2.   0.5 -0.6 -0.4 12.   2.4 -0.3  1.3 -0.1  3.6 -0.7 -0.3  1.9  0.8 -1.4  1.6 -0.5 -0.2 -0.   2.1 -1.2 -0.3 -0.2  2.8 -0.4 -0.5  1.4  0.9 -1.6 -0.3 -0.5 -0.6 -0.3 -0.3 -0.8 -0.6 -2.  -0.5 -0.8  9.6 -0.4 -0.2 -0.6  5.5 -1.3 -1.2 -0.5 -0.8  0.2  3.8  7.8 -0.   0.1 -0.2 -0.7 -0.5 -0.2  1.6  0.2 -0.4 -0.2 -0.9  0.8 -0.  -5.2 -0.1  0.4 -0.5  0.2  0.7 -4.8  0.8  0.6 -0.1  0.2 -0.3 -1.1  0.4 -0.1 -0.4  1.8 -0.4 -0.2 -0.4 -0.4 -0.4 -0.3 -2.2 -0.6 -0.7  0.1  7.6  0.  -0.3 -0.1 -0.1 -2.2 -1.  -0.6  1.6  0.1  0.1 -0.1 -0.3 -0.   3.1 -0.8 -0.3  0.6 -0.1 -0.1 -1.4 -0.2  1.1 -0.1 14.2 -0.3 -1.  -0.7  3.1 -0.  -0.3 -0.1 -0.2 -2.2 -2.1  0.4 -0.1 -0.1 -0.1 -0.3 -0.8 -0.5 -0.3  0.2  0.  -0.1 -0.2 -2.9 -0.4 -0.3 -0.1  0.7  0.2 -0.2 -0.1 -0.4 -0.5 -0.3 -0.   1.5 -0.4  0.3 -0.  -0.1 -0.6 -0.5  2.4 -0.3 -0.1 -0.3 -0.2 -0.1 -0.1 -0.3  4.6 -0.6  0.2  3.6 -0.3  3.8 -0.4  0.7 -1.4 -0.7 -0.4 -0.8 -0.5 -0.3 -0.6 -0.1 -0.8  0.1 -1.  -2.2  3.  -1.   0.2 -0.3 -0.1 -0.   0.2 -0.1 -0.4 -0.  -2.  -0.1 -0.1  9.3 -0.2 -0.6  0.9 -1.   6.9 -0.7 -0.2  2.9 -0.4 -0.3  0.1 -0.5 -0.5 -0.4 -1.1  4.2  1.6 -1.   2.1  2.1 -0.6 -0.1  0.9 -0.5  4.8 -0.9 -1.5  1.4 -1.7  0.8  1.7 -0.2  1.1 -0.3 -0.4 14.4  0.7 -0.3 -0.3 -0.6 -0.4 12.8 -0.2 -1.   0.3 -0.6 -0.3]
ty_50sample [[7 8 1 6 2 0 4 3 9 5]
 [1 0 8 2 3 5 7 6 6 4]
 [4 2 9 8 1 3 0 5 7 6]
 [0 1 1 9 4 5 8 6 2 7]
 [6 6 4 9 2 5 8 7 0 1]
 [8 9 5 3 0 7 2 6 1 4]
 [2 6 6 4 7 1 9 0 8 5]
 [4 6 3 5 0 8 1 9 7 7]
 [0 6 8 3 3 7 4 5 2 1]
 [5 6 3 8 8 0 1 7 9 2]]
tt_50sample [[7 8 1 6 2 0 4 3 9 5]
 [1 0 8 2 3 5 7 9 6 4]
 [4 2 9 8 1 3 0 5 7 6]
 [0 1 3 9 4 5 8 6 2 7]
 [6 3 4 9 2 5 8 7 0 1]
 [8 9 5 3 0 7 2 6 1 4]
 [2 3 6 4 7 9 1 0 8 5]
 [4 6 3 5 0 8 9 1 7 2]
 [0 8 6 9 3 7 4 5 2 1]
 [5 6 3 8 4 0 7 1 9 2]]
vm  [-1.7  1.  -3.1 -0.8 -0.8 -0.3 -0.3 -0.2 -1.3 -0.1 -1.7 -0.2 -0.3  0.1 -2.1  2.1 -0.2 -0.1 -0.1 -1.6 -0.8 -0.7  0.7 -0.1 -1.1  0.7 -0.3 -0.4 -0.5  3.5  1.3 -0.1  0.2 -4.1 -0.4 -0.1  4.5 -0.1  3.4 -0.  -0.   1.8  0.4  2.8 -0.4 -0.4  6.3  0.4 -1.7 13.4 -0.4 -0.  -0.2 -0.2 -0.7  2.8 -0.8 -2.5 -0.8  0.5  4.1  1.  -0.9 -0.8 -1.1  0.1 -0.2 -0.3  0.   0.1 -0.  -0.1  0.5 -0.2 -0.5  0.5  3.1 -0.1 -0.1 -0.4 -0.8 -0.4 -0.4  0.3  2.9  2.3  0.4 -0.3 -0.1 -0.3 -0.7 -0.2 -0.1  1.6 -0.4 -0.1 -0.4 -0.5 -0.4 -0.4  1.3  3.7  4.  -0.  -0.1 -0.4 -0.7  1.9 -0.5 -2.4 -0.5 -0.7 -0.3 -0.1 -0.3  2.1  0.7 -1.6  0.1 -0.3 -0.2  8.1 -0.3  0.  -0.2 -2.4  0.7  3.3 -1.4 -2.7 -0.7 -0.4 -0.4 -0.1  7.2 -1.4 -0.1 -0.3 -0.4 -0.3 -0.4 -0.3 -0.4 -0.1 -0.4 -0.  -0.4 -0.3 -0.1 -0.1 -0.  -0.1 -0.3 -0.1 -0.2 -0.3 -0.2 -0.7 -0.2 -0.3 -0.3  0.7 -0.4  0.2 -0.5  1.  -0.   0.5 -0.2 -0.4 -0.  -0.3 -0.  -0.5 -0.   0.9 -0.6 -0.3 -0.1 -0.3  1.   0.4  0.8 -0.6 -0.4  1.3 -1.1 -0.1 -0.2 -0.7 -0.2 -0.3 -0.3 -1.1 -0.6  5.7  0.5  2.5 -0.3 -0.3 -0.2 -0.3  0.6 -0.3 -0.  -0.1 -0.2 -0.2  9.5 -0.4  1.2 -0.7 -0.2  6.7  1.6 -0.2 -1.  -0.7 -0.1 -0.5 -0.1 -0.1 -0.6 -0.8  4.3  1.1 -0.6 -0.2 -0.1 -1.2 -0.4 -0.1 -0.3  5.1  0.5  5.  -0.4 -0.3 -0.5 14.4 -0.1  5.9 -0.1 -0.1  4.  -1.4  1.5 -0.5 -0.6 -0.4  1.3 -0.3  2.2 -0.2 -0.9 12.2]
vy_50sample [[1 4 8 9 6 2 0 7 5 3]
 [3 8 6 2 5 1 4 9 0 7]
 [5 6 2 8 9 4 1 0 3 7]
 [2 4 0 6 7 5 1 3 9 8]
 [8 0 5 6 7 4 3 9 2 1]
 [4 7 3 3 9 2 6 5 1 8]
 [3 7 8 6 5 4 9 2 0 1]
 [4 1 7 5 0 3 9 8 6 2]
 [5 9 8 4 3 2 0 1 6 7]
 [2 9 5 6 6 8 8 3 0 4]]
vt_50sample [[4 1 8 9 6 2 0 7 5 3]
 [3 8 6 2 5 1 4 9 0 7]
 [5 6 8 2 9 4 1 0 3 7]
 [2 4 0 6 7 5 1 3 9 8]
 [8 0 5 6 7 4 3 9 2 1]
 [4 0 7 3 9 2 6 5 1 8]
 [7 3 8 6 5 4 9 2 0 1]
 [4 1 7 5 0 3 9 8 6 2]
 [5 9 8 4 3 2 0 1 6 7]
 [2 9 1 5 6 8 7 3 0 4]]
Epoch 27110: Training cost= 0.3140, Training acc= 0.8331, Validation cost= 0.3227, Validation acc= 0.8333
Epoch 27120: Training cost= 0.2467, Training acc= 0.8331, Validation cost= 0.3357, Validation acc= 0.8333
Epoch 27130: Training cost= 0.3490, Training acc= 0.8332, Validation cost= 0.2891, Validation acc= 0.8333
Epoch 27140: Training cost= 0.2978, Training acc= 0.8332, Validation cost= 0.3456, Validation acc= 0.8333
Epoch 27150: Training cost= 0.2592, Training acc= 0.8332, Validation cost= 0.2208, Validation acc= 0.8333
Epoch 27160: Training cost= 0.2612, Training acc= 0.8332, Validation cost= 0.2231, Validation acc= 0.8333
Epoch 27170: Training cost= 0.2482, Training acc= 0.8332, Validation cost= 0.3540, Validation acc= 0.8334
Epoch 27180: Training cost= 0.2668, Training acc= 0.8333, Validation cost= 0.3536, Validation acc= 0.8334
Epoch 27190: Training cost= 0.3278, Training acc= 0.8333, Validation cost= 0.2713, Validation acc= 0.8334
Epoch 27200: Training cost= 0.2683, Training acc= 0.8333, Validation cost= 0.2662, Validation acc= 0.8334
tm  [-0.2 -0.2  0.4 -4.4 -1.7 -0.3 -0.2 -0.2 -0.3 -0.7  1.2 -0.4 -0.2 -0.2 11.9  2.6 -0.5 -0.3  0.2  4.3 -0.9 -0.4  2.2 -0.3 -1.   0.8 -0.4 -0.1 -0.5  1.2  2.6 -0.3 -0.5  4.7 -0.4 -0.2  0.6 -0.1 -3.1 -0.8 -0.4 -1.2 -0.2  2.3 -0.5 -0.1 -3.2 -0.2  4.4  4.1 -0.7 -0.1 -0.2  9.  -0.6 -1.2 -0.6 -2.4  3.1 -0.6  3.6  0.6 -0.5  2.2 -0.5  1.  -0.1 -0.3  1.9  0.2 -0.1 -0.4  0.9 -0.3 -4.9  0.4 -0.6 -0.1  0.2  1.  -3.7 -0.4 -0.   2.1 -0.7 -0.9  5.7 -0.3 -0.4 -0.4 -0.1  0.2 -0.2 -0.7 -0.6 -0.1 -0.2 -2.7 -0.4 -0.1  2.6  5.8 -0.8 -0.1 -0.1  0.5 -2.4  3.1  1.4  2.5 -0.8 -0.3 -0.1 -0.7  1.   4.1 -0.3  1.1 -0.1 -0.3 -0.1 -1.1 -0.1 -0.4 -0.2 13.5 -0.4 -1.9  1.2  5.7  3.  -1.   0.6 -0.9 -1.1  3.1 -0.  -0.2 -0.7 -0.4 -0.4 -0.6 -0.3 -0.  -0.1 -0.1 -0.2 -0.2 -2.5 -0.1  2.9 -0.2  3.5 -0.1 -0.   0.   0.1 -0.5 -0.6 -0.4  0.9  1.3 -0.1 -0.1 -0.3 -0.5 -0.1  2.  -0.1 -0.4 -0.5 -0.5 -0.2 -0.  -0.4  5.4 -0.4 -0.5  6.6 -0.2  1.4 -0.3 -0.6 -1.7 -0.3  0.2  1.3 -0.5 -0.1 -0.3 -0.  -0.5 -0.1 -0.8 -0.6 -0.6 -1.1 -0.4 -0.2 -0.1  0.  -0.3 -0.6 -0.5 -0.1 -3.8 -0.2 -0.   6.6 -0.4 -0.5  0.2 -1.4 -0.4 -0.6 -0.4 -0.2 -0.6  0.1  0.1 -0.5 -0.2 -0.4 -0.9  3.   2.2 -0.2 -0.2  2.4  4.7 -0.5 -0.1 -0.   4.2  0.2  0.6  1.4 -1.5  3.1 -0.3  0.1 -0.2 -0.1 -0.3 12.8  6.4 -0.4  1.1 -1.  -0.5  9.8 -0.1 -2.  -0.2 -0.1 -1.5]
ty_50sample [[7 4 6 8 8 0 3 1 5 9]
 [4 2 5 8 0 6 3 9 7 1]
 [5 1 2 4 0 8 9 7 3 6]
 [7 0 8 6 5 1 4 9 3 2]
 [2 8 0 7 4 6 9 5 1 3]
 [4 6 3 0 7 5 2 8 1 9]
 [2 3 6 0 5 4 1 8 7 9]
 [5 7 2 3 6 4 8 9 9 1]
 [2 0 1 4 3 9 7 6 8 5]
 [2 9 9 5 1 8 4 6 3 7]]
tt_50sample [[7 4 6 8 2 3 0 1 5 9]
 [4 2 5 8 0 6 3 9 1 7]
 [5 1 2 4 0 8 9 7 3 6]
 [7 0 8 6 5 1 4 9 3 2]
 [2 8 0 7 4 6 9 5 1 3]
 [4 6 3 0 7 5 2 8 1 9]
 [2 3 6 5 0 4 1 8 7 9]
 [5 7 2 3 6 4 8 9 0 1]
 [2 0 1 4 3 7 9 6 8 5]
 [2 9 0 5 1 8 4 6 7 3]]
vm  [-1.5  3.8  2.5  3.3 -1.5  0.5 -0.2 -0.2 -1.8 -1.3  0.  -0.1 -0.3 -0.1  0.2  3.6 -0.4 -0.2  0.6 -1.3 -0.  -0.4  1.9  1.  -1.9  1.1 -0.  -0.2 -0.3  5.8  1.1  0.5 -0.4  3.7 -0.8  1.8  5.7  0.9  7.4 -0.4 -0.   4.2  5.6  2.5 -0.1 -0.2  5.9  0.2 -2.   6.7 -0.7  0.6  1.  -0.5 -1.2 -0.1 -1.1  3.1 -2.6 -0.   3.3  0.2 -0.9 -0.7 -0.3  2.8  0.7 -0.8 -0.1  0.3  0.9 -0.9 -0.  -0.6  4.7  0.5  3.  -0.4 -0.1 -0.   4.6 -0.4 -0.4  0.6  4.1  7.6 -0.6 -0.2 -0.2 -0.1 -0.5 -0.1 -0.1  4.6 -0.1  0.1  1.2  1.1 -0.2  0.6  5.9  5.4  2.7 -0.2  0.2 -0.8 -0.4  1.2  0.7 -1.4 -0.7 -0.3  0.2  2.  -2.   7.5  0.7 -2.4 -0.4 -0.6 -0.4  6.4 -0.2 -0.2 -0.   0.7  0.9  4.5 -2.1 -2.1 -1.  -0.6 -0.4 -0.5 -2.2 -0.8  0.5 -0.2 -0.5 -1.  -0.1 -0.3  0.2 -0.2 -0.1  0.1  0.6 -0.1  2.9 -0.1 -0.8 -0.3 -0.8  0.4 -0.2 -0.2 -0.  -0.2  0.7 -0.2 -0.5 -0.3 -0.5 -0.1 -0.7 -0.2 -0.  -0.6 -0.2 -0.1 -0.   0.1 -0.2 -0.5  0.3 -0.2 -0.7  0.2 -0.7 -0.4 -1.8  0.2  0.5 -1.4 -0.8 -0.2 -1.3 -0.8  0.1 -1.6 -0.2 -0.2 -0.  -1.3 -0.6  7.9  1.7  5.4  0.2 -0.2  0.5 -0.2 -0.  -0.5 -0.  -0.2 -0.3 -0.2 -1.1 -0.1 -0.2 -0.2  1.1  7.1 -0.4 -0.2 -0.8 -0.2  1.1 -0.7 -0.   0.2 -0.4 -0.8  1.5  3.3 -0.3 -0.2  1.5 -1.7 -1.  -0.3 -0.  -0.6 -0.3 -0.4 -1.   1.4 -0.6  0.2 -0.  -0.1 -0.1 -0.1 -0.6 -1.4  0.4 -0.1 -0.1 -0.5 -1.3 -0.1  4.  -0.1 -0.4  9.3]
vy_50sample [[1 5 9 7 4 8 2 6 3 3]
 [1 9 0 0 7 2 5 4 6 3]
 [2 5 4 1 9 0 3 6 7 8]
 [7 3 4 1 0 6 9 5 8 2]
 [7 9 9 6 0 0 5 4 2 8]
 [8 4 3 9 1 6 2 5 0 7]
 [9 5 4 7 2 8 3 1 0 6]
 [5 2 8 1 4 0 9 3 6 7]
 [9 3 8 2 0 7 5 1 6 4]
 [7 2 4 6 3 1 5 9 8 0]]
vt_50sample [[1 5 9 7 4 8 2 6 3 0]
 [1 9 0 7 8 2 5 4 6 3]
 [2 5 4 1 9 0 3 6 7 8]
 [7 3 4 1 0 6 9 5 8 2]
 [7 9 1 6 3 0 5 4 2 8]
 [8 4 3 9 1 6 2 5 0 7]
 [9 5 4 7 2 8 3 1 0 6]
 [5 2 1 8 4 0 9 3 6 7]
 [9 3 8 2 0 7 5 1 6 4]
 [7 2 4 6 3 1 5 9 8 0]]
Epoch 27210: Training cost= 0.2341, Training acc= 0.8333, Validation cost= 0.2703, Validation acc= 0.8334
Epoch 27220: Training cost= 0.2513, Training acc= 0.8333, Validation cost= 0.3014, Validation acc= 0.8335
Epoch 27230: Training cost= 0.1880, Training acc= 0.8334, Validation cost= 0.2716, Validation acc= 0.8335
Epoch 27240: Training cost= 0.2990, Training acc= 0.8334, Validation cost= 0.2837, Validation acc= 0.8335
Epoch 27250: Training cost= 0.2668, Training acc= 0.8334, Validation cost= 0.3193, Validation acc= 0.8335
Epoch 27260: Training cost= 0.3330, Training acc= 0.8334, Validation cost= 0.2570, Validation acc= 0.8335
Epoch 27270: Training cost= 0.2552, Training acc= 0.8334, Validation cost= 0.2950, Validation acc= 0.8336
Epoch 27280: Training cost= 0.2849, Training acc= 0.8335, Validation cost= 0.3387, Validation acc= 0.8336
Epoch 27290: Training cost= 0.3282, Training acc= 0.8335, Validation cost= 0.3105, Validation acc= 0.8336
Epoch 27300: Training cost= 0.3284, Training acc= 0.8335, Validation cost= 0.3168, Validation acc= 0.8336
tm  [-0.4  0.2 -0.4  5.7 -1.1  0.1 -0.2 -0.1 -0.1 -0.8  3.6 -0.3 -0.1  0.8 -1.   7.  -0.2 -0.4 -0.1 -1.3 -0.8  0.3 -0.3 -0.2 -0.9 -0.1 -0.1 -0.4  2.5 -1.5 -0.  -0.2 -0.2 -1.3 -0.5 -0.4 -0.1  5.2 12.1 -0.7  1.1 -2.5 -0.4  3.6 -0.   1.   4.9 -0.5  2.2 -0.8 -0.5 -0.3  0.2  1.1 -1.3  2.5 -0.3 -0.8  3.2  2.5 -0.9 -0.2 -0.4  0.5 -0.3 -0.4  0.3  0.1  0.2 -0.3 -0.1 -1.8 -0.1  1.4 -0.8 -0.1 -0.9 -0.3 -0.3  0.3  2.8 -0.2 -0.3 -0.2 -0.8 -2.3  1.6 -0.  -0.2 -0.6 -0.1  0.5  0.  -0.7 -0.3 -0.1 -0.4 -1.4 -0.1 -0.3  3.3 -1.6 -0.8 -0.1 -0.1 -0.3 -0.4 -0.   1.4 -1.5 -0.3 -0.2 -0.2 -1.  -0.4 11.6 -0.  -0.4 -0.1 -0.2 -0.1  5.7 -0.1 -0.3 -0.4 -1.2  0.2  1.5  4.2  3.   0.  -0.7 -0.  -0.8 -2.  -3.4 -0.1 -0.2  0.2 -0.3 -0.8 -0.3 -0.8 -0.2 -0.  -0.2  0.2 -0.  -0.4  0.2 -0.3 -0.3  2.8 -0.2  0.  -0.1  0.1  0.6  3.8 -0.2 -0.5 -1.7 -0.3 -0.2 -0.3  0.3  0.8  1.4  0.1 -0.1 -0.3 -0.4  0.   0.6 -0.   1.5  0.8 -0.1 -1.4 -0.3 -0.2  0.2 -0.6 -1.  -0.6 -0.   3.3 -0.5 -0.4  4.1 -0.1  0.9 -0.8 -0.7  6.9 -1.3  1.1  0.3  0.1  0.5 -0.1  0.3 -0.3 -0.4 -0.4 -0.2 -0.3 -0.2  5.  -0.  -0.2  6.8 -0.8 -0.3 -0.5 -0.4 -1.1 -0.7 -0.5 -0.1 -0.6 -0.1 -0.  -0.7 -2.2  4.7 -0.1  0.3 -0.3  4.4 -0.5 -0.6  0.1  2.6 -0.8  1.5 -0.   1.1  1.7 10.9 -0.1  4.6  0.4 -0.   0.4 -1.7 -0.3 -0.  -1.  -0.2 -1.  -0.1  8.4 -0.3  2.  -0.2]
ty_50sample [[3 9 2 8 4 7 1 5 6 0]
 [3 6 0 2 7 5 8 4 1 9]
 [9 5 3 0 2 4 7 1 1 8]
 [3 5 2 9 8 6 7 1 4 0]
 [2 3 7 0 5 8 9 6 1 4]
 [4 6 9 8 1 2 0 7 3 5]
 [3 4 2 8 5 7 1 0 6 9]
 [4 5 3 6 2 9 1 7 8 0]
 [5 2 8 3 9 4 6 1 0 7]
 [4 0 2 6 1 1 7 3 8 5]]
tt_50sample [[3 9 2 8 4 7 1 5 6 0]
 [3 6 0 2 7 8 5 4 1 9]
 [9 5 3 0 2 4 7 6 1 8]
 [3 5 2 9 8 6 7 1 4 0]
 [2 3 7 0 5 8 9 6 1 4]
 [4 6 9 8 1 2 0 7 3 5]
 [3 4 8 2 7 5 1 0 6 9]
 [4 5 3 6 2 9 1 7 8 0]
 [5 2 8 3 9 4 6 1 0 7]
 [4 0 2 6 1 7 3 9 8 5]]
vm  [-1.6 -0.1  3.3  2.6 -1.7 -0.1 -0.6  0.2 -0.2 -0.7  7.2 -0.6  0.  -0.2  2.5  5.  -0.3 -0.1  1.  -0.9 -0.7 -0.5  1.8 -0.4 -1.4  2.4 -0.3  0.1 -0.5 -0.9  2.2 -0.4 -0.3  7.  -0.4 -0.1  2.6  4.9  7.3 -0.6 -0.1  3.2 -0.2  1.9 -0.3 -0.1  1.8 -0.6 -1.1  6.  -0.8 -0.  -0.   2.9 -0.9  0.1 -0.6  2.4  1.9 -0.4  3.7 -0.2 -0.4  0.9  0.1 -0.  -0.2 -0.5 -0.1  0.   0.2 -0.3 -0.   0.6 -0.8  0.2  0.9 -0.  -0.1  0.4  6.6 -0.5 -0.1 -0.1  2.5  5.4 -1.2 -0.2 -0.5 -0.3 -0.3 -0.3 -0.2 -1.  -0.2 -0.   1.4 -1.6 -0.7 -0.1  3.3  7.1  1.2  0.  -0.1 -0.4 -0.7  1.3  1.6 -1.3 -0.6 -0.3 -0.2 -0.6  0.5  4.4  0.6 -0.8 -0.4 -0.7 -0.3  5.2  0.7  0.2 -0.1  2.7  0.2 -0.2  2.1 -1.9 -0.8 -1.  -0.3 -0.8 -3.4 -0.2  0.2 -0.1 -0.  -0.5 -0.7 -0.3 -0.6 -0.3 -0.1 -0.2  0.1 -0.2 -0.7 -0.  -0.1 -0.2 -1.  -0.5  0.2  0.  -0.2 -0.1  3.5 -0.1  0.8 -0.9 -0.2 -0.2 -0.5 -0.5  0.5  1.1 -0.3 -0.1 -0.1 -0.2 -0.3 -0.2 -0.2  1.2 -0.1 -0.  -0.6 -0.2 -1.  -0.1 -0.1 -1.1 -0.4 -0.1 -0.7 -0.6 -0.2  2.8 -0.3 -0.2 -0.5 -0.6 -0.7 -0.2  0.5 -0.2 -0.2  0.1  0.  -0.1 -0.  -0.5 -0.1 -1.  -0.1  0.2 -0.9 -0.3  0.3  0.6 -0.2  6.6 -0.5 -0.3 -0.5 -0.8 -0.2 -0.4 -0.2 -0.2 -0.5 -1.1  2.3  0.2  1.3  3.4  0.8 -0.1 -0.3 -0.7 -0.1 -0.5  1.4 -0.6 -0.1  0.2 -0.   2.6  0.1  1.4 -0.2 -0.1 -0.9 -0.9 -0.3  0.8 -0.9 -0.  -1.9  0.1  4.7 -0.1 -1.5  9.7]
vy_50sample [[1 2 7 9 5 4 0 8 6 3]
 [2 0 4 7 5 5 1 9 3 8]
 [4 2 1 3 0 6 7 8 9 5]
 [8 6 4 3 9 7 5 0 1 2]
 [8 2 1 5 7 4 6 0 3 9]
 [1 6 9 2 7 0 4 3 5 8]
 [9 5 6 7 0 8 3 4 2 1]
 [0 3 3 1 8 2 9 5 4 7]
 [4 6 9 7 5 0 3 1 2 8]
 [9 0 8 7 4 5 6 3 1 2]]
vt_50sample [[1 2 7 9 5 4 0 8 6 3]
 [2 0 4 7 6 5 1 9 3 8]
 [4 2 1 3 0 6 7 8 9 5]
 [8 6 4 3 9 7 5 0 1 2]
 [8 1 2 5 7 4 6 0 3 9]
 [1 9 6 2 7 0 4 3 5 8]
 [9 5 6 7 0 8 3 4 2 1]
 [6 0 3 1 8 2 5 9 4 7]
 [4 6 9 7 5 0 3 1 2 8]
 [9 8 0 7 4 5 6 3 1 2]]
Epoch 27310: Training cost= 0.3066, Training acc= 0.8335, Validation cost= 0.3187, Validation acc= 0.8336
Epoch 27320: Training cost= 0.2591, Training acc= 0.8335, Validation cost= 0.3229, Validation acc= 0.8336
Epoch 27330: Training cost= 0.3291, Training acc= 0.8335, Validation cost= 0.3271, Validation acc= 0.8337
Epoch 27340: Training cost= 0.2684, Training acc= 0.8336, Validation cost= 0.3039, Validation acc= 0.8337
Epoch 27350: Training cost= 0.2968, Training acc= 0.8336, Validation cost= 0.3117, Validation acc= 0.8337
Epoch 27360: Training cost= 0.2985, Training acc= 0.8336, Validation cost= 0.2691, Validation acc= 0.8337
Epoch 27370: Training cost= 0.3190, Training acc= 0.8336, Validation cost= 0.2720, Validation acc= 0.8337
Epoch 27380: Training cost= 0.2905, Training acc= 0.8336, Validation cost= 0.2724, Validation acc= 0.8337
Epoch 27390: Training cost= 0.2777, Training acc= 0.8337, Validation cost= 0.3219, Validation acc= 0.8338
Epoch 27400: Training cost= 0.3389, Training acc= 0.8337, Validation cost= 0.3073, Validation acc= 0.8338
tm  [-1.1 -1.1 -1.7 -2.  -1.3 -0.3 -0.2 -0.2  2.4 -0.2 -0.7  0.4 -0.7 -0.4  1.6 -1.  -0.3 -0.4 -0.3  1.6 -1.1 -0.  -0.4 -0.2 -1.   2.3 -0.3 -0.5 -0.8 -1.6  4.2 -0.4  0.6  2.7 -0.3 -0.6 -0.5 -1.8 -3.5 -0.5 -0.1  0.5 -0.8 -0.3 -0.2  0.5 -2.1 -0.1  0.7 -0.9 -0.1 -0.3 -0.1 -0.6 -0.7  0.3 -0.7 -0.8  6.7 -1.6  5.4 -0.4  1.5  0.3 -0.2 -0.4  0.2  1.1  0.8  0.1 -0.1 -0.2 -0.1  1.8 -5.3 -0.3 -0.8 -0.1 -0.  -0.1  1.5 -0.2  1.  -0.4 -0.4  0.7  1.  -0.3 -0.3 -0.8 -0.1 -0.1 -0.  -1.7 -0.5  0.1 -0.6 -3.  -0.1 -0.3 -0.2 -0.2 -0.  -0.2 -0.4 -0.1 -1.7  3.5 -0.3 -0.2 -0.5 -0.1 -0.1 -1.3  6.5  1.4 -0.1  3.3 -0.1  1.   0.3 -0.3 -0.2 -0.1 -0.2  2.3 -0.1  5.1  6.6  4.  -0.1 -0.4 -0.1 -0.9 12.3 15.3 -0.2 -0.1 -0.1 -0.3  3.6 -0.5  1.6 -0.1  0.  -0.1 -0.2 -0.2  2.8  0.3  1.8 -0.1 -0.9  0.8 -0.2  0.2 -0.3 -0.4 -0.8 -0.4  1.1  1.5 -0.1 -0.1 -0.3 -0.3 -0.3  3.   1.1 -0.  -0.4 -0.2 -0.3 -0.3 -0.2 -0.1 -1.3  0.   6.9 -0.  -0.6 -0.4 -0.3 -1.5 -0.2 -0.2 -0.3 -0.2 -0.6  4.4  0.  -0.3 -0.2 -0.7 -1.3 -1.7 -0.6 -1.4  0.   0.3  0.4  0.4  0.9 -0.7  0.2 -2.3 -0.3 -0.4 -1.2 -0.3 -0.7  1.2 -1.   3.8 -0.8 -0.3  1.6 -0.8 -0.3 -0.2 -0.8 -0.1 -0.4 -0.8  4.  -0.5 -2.5 -0.1  1.4  3.   3.1 -0.3 -0.1 -0.9  0.2  4.3  0.7 -1.3  3.9 -1.  -0.2 -0.6 -0.2 -0.   1.2  1.5 -0.4  0.1 -1.4 -0.3 -0.4 -0.1 -2.5 -0.1  4.2 -0.5]
ty_50sample [[6 4 1 0 3 5 7 8 8 2]
 [7 2 0 1 4 9 6 5 3 8]
 [5 4 3 7 8 9 6 1 0 2]
 [6 4 7 9 5 3 8 0 2 1]
 [7 4 0 3 1 6 2 9 8 5]
 [5 3 6 2 8 7 1 0 4 9]
 [3 8 9 0 1 6 2 4 5 7]
 [6 1 8 4 0 2 5 9 3 7]
 [9 6 1 2 4 7 5 8 3 0]
 [7 5 0 6 8 9 2 1 3 4]]
tt_50sample [[6 1 4 0 3 5 7 9 8 2]
 [7 2 0 1 4 9 6 5 3 8]
 [5 4 3 7 8 9 6 1 0 2]
 [6 4 7 9 5 3 8 0 2 1]
 [7 4 0 3 1 6 2 8 5 9]
 [5 3 6 2 1 7 8 0 4 9]
 [3 8 9 0 1 6 4 2 5 7]
 [6 1 8 4 0 2 5 9 3 7]
 [9 6 1 2 4 7 5 3 8 0]
 [7 5 0 6 8 9 2 1 3 4]]
vm  [-1.2 -0.2 -1.7 -0.2 -1.2 -0.1  0.2 -0.1 -0.7 -0.4 -1.5  0.6 -0.8 -0.3 -1.2 -1.  -0.4 -0.2  0.2 -0.9 -0.8 -0.2  1.3 -0.2 -1.5  2.5 -0.3 -0.2 -0.4  0.5  3.2 -0.3  2.7  0.2 -0.4 -0.1  2.7 -1.5 -0.7 -0.5 -0.2 -0.4 -0.1 -0.1 -0.2 -0.5  6.5 -0.  -1.7  4.1 -0.8 -0.1  0.6 -1.9 -1.   2.8 -0.5 -1.9 -0.2 -1.1  4.5 -0.4  0.9 -1.1  1.3 -0.9 -0.1  0.5  1.1 -0.3 -0.1  1.1  1.2 -0.4 -1.2 -0.   2.2 -0.  -0.3 -0.5  8.2 -0.1 -0.2 -0.5  0.4 -0.5 -0.5 -0.3  0.2 -0.2 -0.8 -0.3 -0.3  0.  -0.7 -0.3 -0.4 -0.6 -0.6 -0.2  0.6  3.1  0.7 -0.3 -0.1 -0.6 -1.   3.1 -0.5 -1.1 -0.7 -0.2 -0.2 -0.2  1.9 -0.6  1.8 -0.7  0.2  1.4 -0.2  3.5 -0.2 -0.2 -0.2 -1.5  0.4  9.  -1.3 -1.5 -0.8 -0.1 -0.4  0.4  8.  10.3 -0.1 -0.2  0.8 -0.9  1.4 -0.8  1.1 -0.  -0.3 -0.1 -0.2 -0.  -0.8 -0.2 -0.2 -0.1 -1.   0.6 -0.2 -0.2 -0.4  0.4 -1.1 -0.5  0.2  0.  -0.  -0.1 -0.3 -0.6 -0.3  0.4 -0.2 -0.3 -0.2 -0.3 -0.3 -0.2 -0.6  2.4 -1.6  1.   2.3 -0.   1.  -0.3  1.5 -1.4 -0.5 -0.2 -0.9 -0.2  0.   0.  -0.4 -0.6 -0.5 -1.4 -0.9  5.9 -0.1 -0.3 -0.2 -0.1 -0.1 -0.4 -0.3 -0.1 -0.4  1.8 -0.  -0.1  5.1 -0.5 -0.4 -0.7 -0.1  6.6  1.7  0.3 -0.1 -0.7  0.1  1.4 -0.2 -0.2 -0.5 -1.4  2.9 -0.3 -2.2 -0.4  0.2 -1.1  1.4  1.5 -0.5  2.9 -0.2  2.2  0.2 -0.6 -0.4 13.7 -0.3  5.5 -0.5 -0.1 -1.4 -2.2 -0.2 -0.4 -0.7 -0.  -2.3 -0.3 -0.4 -0.2  2.7  8.1]
vy_50sample [[1 6 4 0 0 8 7 3 2 5]
 [2 5 6 8 1 7 7 4 9 0]
 [0 0 9 9 1 8 3 7 5 4]
 [2 9 4 1 5 3 8 7 6 6]
 [2 5 4 6 9 8 1 7 3 0]
 [1 6 4 0 9 3 5 8 7 2]
 [2 9 0 0 4 8 1 7 3 6]
 [3 8 6 9 5 7 4 2 1 0]
 [0 2 3 9 5 1 7 6 8 4]
 [2 6 8 1 5 9 7 3 4 0]]
vt_50sample [[1 6 4 9 0 8 7 3 2 5]
 [2 5 6 8 1 3 7 4 9 0]
 [6 0 9 2 1 8 3 7 5 4]
 [9 2 4 1 5 3 8 7 0 6]
 [2 5 4 6 8 9 1 7 3 0]
 [1 6 4 0 9 3 5 8 2 7]
 [2 9 0 5 4 8 1 7 3 6]
 [3 8 6 9 5 4 7 2 1 0]
 [0 2 3 9 5 1 7 6 8 4]
 [2 6 8 1 5 9 7 3 4 0]]
Epoch 27410: Training cost= 0.3096, Training acc= 0.8337, Validation cost= 0.2682, Validation acc= 0.8338
Epoch 27420: Training cost= 0.3200, Training acc= 0.8337, Validation cost= 0.2677, Validation acc= 0.8338
Epoch 27430: Training cost= 0.2937, Training acc= 0.8337, Validation cost= 0.2685, Validation acc= 0.8338
Epoch 27440: Training cost= 0.2996, Training acc= 0.8337, Validation cost= 0.2609, Validation acc= 0.8339
Epoch 27450: Training cost= 0.3138, Training acc= 0.8338, Validation cost= 0.2497, Validation acc= 0.8339
Epoch 27460: Training cost= 0.3109, Training acc= 0.8338, Validation cost= 0.3001, Validation acc= 0.8339
Epoch 27470: Training cost= 0.2801, Training acc= 0.8338, Validation cost= 0.2808, Validation acc= 0.8339
Epoch 27480: Training cost= 0.2958, Training acc= 0.8338, Validation cost= 0.3622, Validation acc= 0.8339
Epoch 27490: Training cost= 0.2833, Training acc= 0.8338, Validation cost= 0.3451, Validation acc= 0.8340
Epoch 27500: Training cost= 0.3143, Training acc= 0.8339, Validation cost= 0.3147, Validation acc= 0.8340
tm  [ 0.3 -0.8 -3.8 -5.3 -1.  -0.1 -0.6 -0.1  1.  -0.2  4.8 -0.1 -0.3 -0.2  2.2  2.8 -0.7 -0.4 -0.5  1.3 -1.  -0.2  1.8 -0.1 -1.  -0.1 -0.5  0.1 -0.2 -2.1  4.6 -0.5 -0.5 -2.2 -0.3 -0.6 -0.6  5.6  2.4 -0.6 -0.1  3.8 -0.7  6.1 -0.4 -0.1 -1.8 -0.2  2.8  4.6 -0.7 -0.2 -0.3 10.3 -1.  -0.2 -0.4 -0.5  7.1 -1.4  1.2 -0.6  0.9 -0.3  0.7 -0.8  0.2  1.4  0.4 -0.4 -0.2 -0.7 -0.1 -0.2 -6.1 -0.2 -0.9 -0.1 -0.3 -0.3 -2.8 -0.6 -0.1 -0.1 -1.2  4.5  5.6 -0.2 -0.4 -0.1 -0.3 -0.2 -0.3 -0.7 -0.9 -0.1 -0.  -2.9 -0.3 -0.2 -0.  -0.7 -1.  -0.2 -0.2 -0.7 -3.   4.1  1.   1.4  0.4 -0.1 -0.1 -1.2  3.7  2.3  1.   2.8 -0.4  0.  -0.5 -1.  -0.1 -0.4 -0.7  2.8 -0.2 -2.3  8.   2.7 -0.2 -0.9 -0.  -0.6 -1.  -3.1 -0.2 -0.2 -0.3 -0.5 -0.5 -0.5 -0.7 -0.1 -0.1 -0.3 -0.2 -0.1  6.6 -0.2  2.7 -0.2  3.6 -0.2 -0.4 -0.1 -0.1 -0.2  3.1 -0.5 -0.3 -2.1 -0.1 -0.4 -0.2 -0.1 -0.2  0.3 -0.3 -0.5 -0.1 -0.2 -0.4 -0.2 -0.1 -1.5 -0.2 -0.8  0.3 -0.3 -1.7 -0.4 -0.2 -1.4 -0.4 -0.2  2.4 -0.2 -0.3  5.8 -0.6 -0.3 -0.4 -1.1  1.  -2.5 -1.5 -1.1 -0.3 -0.  -0.  -0.3 -0.2 -0.3 -0.5 -3.5 -0.1 -0.2 -1.3 -0.2 -0.6  1.  -0.2 -1.1  1.7 -0.1 -2.4 -0.7 -0.4 -0.5 -0.4 -0.3 -0.3 -1.2 -0.9  0.9 -0.4 -0.3 -0.4  5.6 -1.   0.9 -0.4 -0.9 -0.3  6.5  0.8 -2.1  0.7 -4.2 -0.2 -1.8 -0.1 -0.  10.3  3.  -0.2 -0.2 -1.   1.4  6.6  0.   1.3 -0.1 -0.4 -0.3]
ty_50sample [[4 5 2 8 0 3 7 1 9 6]
 [1 4 6 5 9 3 2 8 7 0]
 [7 5 8 6 2 4 4 9 3 0]
 [2 1 9 0 6 3 4 7 5 8]
 [2 7 1 8 0 4 6 6 3 5]
 [6 8 1 0 2 5 7 3 4 9]
 [0 9 9 1 6 3 7 5 8 2]
 [0 3 9 9 2 1 7 6 5 8]
 [6 9 9 4 1 3 7 2 8 0]
 [8 2 6 5 5 7 7 3 3 0]]
tt_50sample [[4 5 2 8 0 3 1 7 9 6]
 [1 4 6 5 9 3 2 8 7 0]
 [7 5 8 6 2 4 1 3 9 0]
 [2 1 9 0 6 3 7 4 5 8]
 [7 2 1 8 4 0 9 6 3 5]
 [6 8 1 0 5 2 7 3 4 9]
 [0 4 9 1 6 3 7 5 8 2]
 [0 3 9 4 2 1 7 6 5 8]
 [6 9 5 4 1 3 2 7 8 0]
 [8 2 6 4 5 9 7 3 1 0]]
vm  [-0.3 -0.7 -2.   4.5 -0.8 -0.2 -0.3 -0.   0.5  1.1  5.6 -0.9 -0.1  0.3 -2.3  0.1 -0.5 -0.2 -0.  -2.  -0.9 -0.1  1.  -0.  -0.6  1.  -0.2 -0.1 -1.1 -1.5  1.8 -0.2 -0.7 -2.2  0.5 -0.6  0.8  4.8 11.4 -0.5 -0.2  1.1 -1.2  2.3 -0.2 -0.1 10.8 -0.9  0.   9.7 -0.6 -0.3 -0.3  0.9  1.1  4.1 -0.2 -2.2  5.2 -0.1 -1.1 -0.2 -0.8  0.2  0.   0.2 -0.2  1.6  0.  -0.2 -0.1  2.6 -0.1 -0.4  2.1  0.2 -0.8 -0.  -0.1  0.4  6.4 -0.1 -0.3  0.6 -0.3  0.7  2.   0.1 -0.6  0.2  0.5 -0.2 -0.4 -1.6 -0.3 -0.1 -0.3 -0.8 -0.2 -0.6 -0.7  3.4 -0.5 -0.2  0.4 -0.5 -0.4  2.   1.3 -1.7 -0.1  0.3  0.2 -0.1  5.8 -1.9 -0.4 -0.3 -0.4 -0.1 -0.4  7.2  0.6 -0.  -0.3 -2.8 -0.7  1.5  1.7 -3.1  1.  -0.6 -0.2 -0.4  3.3 -1.8 -0.3 -0.1  0.  -0.4 -1.1 -1.1 -1.1 -0.  -0.1  0.1 -0.4 -0.1 -0.6 -0.1 -0.4 -0.   1.4 -0.2 -0.  -0.1 -0.1 -0.1 -0.1 -0.1  0.6 -0.9  0.1 -0.1 -0.3 -0.5 -0.4  2.  -0.1 -0.  -0.1 -0.6 -0.  -0.1 -0.3  1.8 -0.   0.4 -1.3 -0.   1.7 -0.7 -0.3 -1.2 -0.2 -0.1  2.2 -0.3  0.1  4.5 -0.2 -0.4 -1.  -0.8  8.1 -0.4  0.3 -1.2 -0.2 -0.1 -0.4 -0.2 -0.6 -0.3 -0.3  1.  -0.1 -0.2  7.4 -0.1  0.3 -1.1 -1.1 -0.2 -0.3 -0.3 -0.7 -0.8 -0.7 -0.1 -0.4 -0.4  0.  -1.1  3.8 -0.5  1.1  2.3 -0.2  1.8 -1.1 -1.  -0.1  4.1  2.   4.7  3.4  0.8  1.  18.6 -0.1  7.9 -0.1  0.7 -0.9 -2.6  0.9 -0.3 -1.  -0.5 -2.  -0.   8.  -0.2 -1.8 13.6]
vy_50sample [[0 9 2 4 8 1 6 7 3 5]
 [8 3 4 2 5 7 9 1 0 6]
 [1 2 6 5 3 0 8 9 4 7]
 [0 8 5 4 6 1 2 3 9 7]
 [4 3 2 6 7 1 0 9 8 5]
 [5 3 0 7 8 1 9 6 4 2]
 [5 0 3 2 8 6 7 7 4 9]
 [0 7 6 8 4 5 3 9 1 2]
 [5 9 4 2 6 1 8 7 3 0]
 [6 3 5 9 1 4 0 8 7 2]]
vt_50sample [[9 0 2 4 8 1 6 7 5 3]
 [8 3 4 2 5 7 1 9 0 6]
 [1 2 6 5 3 0 8 9 4 7]
 [0 5 8 4 6 1 2 3 9 7]
 [4 3 2 6 7 1 0 9 8 5]
 [5 3 0 7 8 1 9 6 4 2]
 [5 0 3 2 8 6 7 1 4 9]
 [0 7 6 8 4 5 3 9 1 2]
 [5 9 4 2 6 1 8 7 3 0]
 [6 3 5 9 1 4 0 8 7 2]]
Epoch 27510: Training cost= 0.2659, Training acc= 0.8339, Validation cost= 0.3237, Validation acc= 0.8340
Epoch 27520: Training cost= 0.2623, Training acc= 0.8339, Validation cost= 0.3434, Validation acc= 0.8340
Epoch 27530: Training cost= 0.3023, Training acc= 0.8339, Validation cost= 0.2950, Validation acc= 0.8340
Epoch 27540: Training cost= 0.2588, Training acc= 0.8339, Validation cost= 0.2689, Validation acc= 0.8340
Epoch 27550: Training cost= 0.2340, Training acc= 0.8340, Validation cost= 0.2911, Validation acc= 0.8341
Epoch 27560: Training cost= 0.2770, Training acc= 0.8340, Validation cost= 0.3453, Validation acc= 0.8341
Epoch 27570: Training cost= 0.2583, Training acc= 0.8340, Validation cost= 0.3547, Validation acc= 0.8341
Epoch 27580: Training cost= 0.2977, Training acc= 0.8340, Validation cost= 0.2950, Validation acc= 0.8341
Epoch 27590: Training cost= 0.2345, Training acc= 0.8340, Validation cost= 0.2827, Validation acc= 0.8341
Epoch 27600: Training cost= 0.2852, Training acc= 0.8340, Validation cost= 0.2999, Validation acc= 0.8342
tm  [-0.9 -0.8  6.3  2.5 -2.4 -0.2 -0.3 -0.4 -0.2 -0.5  3.   0.4 -0.4  0.1  6.1 -1.6  0.2 -0.3  0.5 -0.6 -0.9 -0.4 -1.  -0.1 -0.8  2.5 -0.6 -0.1 -1.8 -2.2  2.5 -0.1 -0.7 12.5 -0.3 -0.   1.5  2.2 10.4 -0.7 -0.2 -0.7 -0.2  2.4 -0.4 -0.2  0.6  0.1  0.6 -2.9 -0.3 -0.1 -0.4 -0.8  1.2 -0.4 -0.9  2.3  2.8 -1.1  1.5 -0.1 -0.1  0.2 -0.5 -0.4 -0.2 -0.4  0.7 -0.2 -0.1  4.6 -0.1  0.5 -2.8 -0.4 -0.3 -0.5 -0.1 -0.2 10.4 -0.3 -0.3 -0.5 -0.6 -0.9 -0.2  0.6 -0.4 -0.4 -0.4 -0.3 -0.2 -0.  -0.2 -0.1 -0.2 -1.8 -0.4 -0.4  1.1  3.1 -0.1 -0.1 -0.  -0.  -1.1  1.8  0.7 -1.5 -0.2  0.1 -0.2 -0.5  4.  -2.4 -0.5  1.6  0.3 -0.7 -0.1  4.5 -0.3 -0.2 -0.3  7.4 -0.4  5.5  4.   3.9 -0.5 -0.4 -0.3  0.3 -6.3 -0.4 -0.2 -0.2 -0.2 -0.3  2.  -1.1 -0.2 -0.5 -0.2  0.3 -0.6 -0.1 -1.1 -0.1 -0.3  0.9 -1.  -0.  -0.3 -0.2 -0.  -0.3  4.3 -0.2 -0.2 -2.3 -0.2 -0.  -0.2 -0.3 -0.3 -0.  -0.3 -0.2 -0.4 -0.4 -0.1 -0.2 -0.1  3.2  2.7 -0.6 -1.2 -0.2 -1.   0.2 -0.2 -0.9  0.  -0.3 -0.  -0.4 -0.   5.8 -0.  -0.1 -0.1 -0.6  0.6 -0.6 -0.7 -0.9 -0.  -0.  -0.1 -0.1 -0.  -0.2 -0.  -1.1 -0.3 -0.1 -2.2 -0.1 -0.6 -1.6 -0.4  1.1 -0.1 -0.1 -1.  -0.7 -0.5 -0.1 -0.2 -0.3 -0.  -0.8 -1.6 -1.5 -1.8 -0.2 -1.3  1.5 -0.7 -0.  -0.1 -1.4  4.4 -1.2  1.  -0.5  1.3  1.5 -0.2  0.4 -0.3 -0.3 -2.  -0.6 -0.5 -0.3 -0.8 -0.2 -2.8 -0.1  7.3 -0.1  5.1 -0.5]
ty_50sample [[0 7 3 1 1 9 4 2 8 6]
 [6 5 8 1 4 9 3 0 7 2]
 [1 2 5 8 3 6 9 4 0 7]
 [9 2 0 3 1 4 7 5 8 6]
 [5 3 0 4 1 6 6 8 2 7]
 [4 6 9 5 1 3 8 0 7 2]
 [6 5 4 0 8 1 2 7 3 9]
 [3 2 1 9 8 7 0 5 4 6]
 [6 1 7 4 9 2 8 5 0 3]
 [9 7 6 2 3 1 4 8 5 0]]
tt_50sample [[0 7 3 1 5 9 4 2 8 6]
 [6 5 8 1 9 4 3 0 7 2]
 [1 2 5 8 3 6 9 4 0 7]
 [9 2 0 3 1 4 7 5 8 6]
 [5 0 3 4 1 9 6 8 2 7]
 [4 6 9 5 1 3 8 7 0 2]
 [6 5 4 8 0 1 7 2 3 9]
 [3 2 1 9 7 8 0 5 4 6]
 [6 1 7 4 9 2 8 5 0 3]
 [9 7 6 2 3 1 4 8 5 0]]
vm  [ 1.  -0.  -1.4 -2.4 -1.1 -0.2 -0.2 -0.3 -1.2 -0.9 -2.2 -0.2 -0.2  0.1  2.6 -0.8 -0.4 -0.4  0.4  0.3 -1.  -0.2 -0.1  0.6 -1.4  2.2 -0.1 -0.2 -1.1 -0.8  1.1 -0.2 -0.1 -1.9 -0.2 -0.1  3.1  0.1 -1.1 -0.6  0.1 -2.8  0.2  2.2 -0.3 -0.4 -0.7 -0.2  3.3 -0.4 -1.  -0.1 -0.5  2.5 -0.  -0.1 -0.5 -1.8 -0.2  1.3  0.2 -0.2 -0.3  0.4 -0.5  0.1 -0.2 -0.3  1.5 -0.  -0.   3.7  0.5 -0.5 -3.4  0.8 -0.8 -0.3 -0.2 -0.1 -3.1 -0.5 -0.2  0.9 -1.3 -2.8  5.4 -0.1  0.   0.1 -0.2 -0.3 -0.1  2.4 -0.5 -0.2 -0.3 -1.8 -0.2 -0.5  3.2 -1.7 -1.  -0.1  0.5 -0.2 -2.1  0.4 -0.7  0.3 -0.4 -0.2 -0.2 -0.1  1.4 -1.6 -0.3 -0.4 -0.2 -0.  -0.2 -0.3 -0.1 -0.4 -0.2  3.2 -0.6 -0.1 -0.6  9.4  2.5 -0.7 -0.1 -0.4  3.9 -1.2  0.3 -0.1  1.1 -0.  -0.1 -1.4 -0.1 -0.4 -0.1  0.3 -0.4 -0.  -0.6 -0.3  0.8  0.2  4.6 -0.1 -0.5 -0.   0.  -0.2 -0.6 -0.2 -0.3 -0.3 -0.1 -0.1 -0.3 -0.7  0.5 -0.1 -0.2 -0.1 -0.2 -0.5  0.3 -0.2 -0.2  2.4 -0.8 -0.4  3.  -0.4  0.7 -0.3 -0.2 -1.7 -0.   0.1  2.6 -0.3  0.1  2.1 -0.2  0.1 -0.4 -1.4  3.2  2.1 -1.1 -0.3 -0.1  0.1 -0.2 -0.1 -0.5 -0.4 -0.4 -2.7 -0.5 -0.2  7.9 -0.3 -0.3 -1.3 -0.9 -0.8 -0.4 -0.4 -0.4 -0.4 -0.4 -0.2 -0.6 -0.2 -0.  -0.9 -1.  -0.2 -1.  -0.3 -0.   2.9 -0.7  1.1 -0.3  3.9  2.5  2.7  2.3 -1.2  1.3  3.5 -0.1  1.3 -0.4  0.1 10.5  0.3  0.7 -0.5 -0.8 -0.2  7.4 -0.1 -0.6 -0.1  6.2 -2.2]
vy_50sample [[3 0 4 8 6 7 2 9 5 1]
 [4 5 0 8 6 1 3 9 9 2]
 [2 5 1 3 9 4 7 8 0 6]
 [9 7 2 2 6 0 3 8 4 1]
 [4 8 1 0 5 7 6 2 3 9]
 [6 2 3 8 5 0 1 7 7 4]
 [0 2 6 9 1 5 4 3 8 7]
 [8 2 0 6 5 9 7 1 4 3]
 [0 8 9 4 7 2 6 5 1 3]
 [1 3 4 4 0 0 9 6 5 2]]
vt_50sample [[3 0 4 8 6 7 2 9 1 5]
 [4 5 0 8 6 1 3 9 7 2]
 [2 5 1 3 9 4 7 8 0 6]
 [9 7 5 2 6 0 3 8 4 1]
 [4 8 1 0 5 7 6 2 3 9]
 [6 2 3 8 5 0 1 7 9 4]
 [0 2 6 9 1 5 4 3 8 7]
 [8 2 0 6 5 9 7 1 4 3]
 [0 8 9 4 7 2 6 5 1 3]
 [1 3 4 7 0 8 9 6 5 2]]
Epoch 27610: Training cost= 0.2835, Training acc= 0.8341, Validation cost= 0.2239, Validation acc= 0.8342
Epoch 27620: Training cost= 0.3340, Training acc= 0.8341, Validation cost= 0.2485, Validation acc= 0.8342
Epoch 27630: Training cost= 0.3181, Training acc= 0.8341, Validation cost= 0.2960, Validation acc= 0.8342
Epoch 27640: Training cost= 0.3232, Training acc= 0.8341, Validation cost= 0.2489, Validation acc= 0.8342
Epoch 27650: Training cost= 0.2785, Training acc= 0.8341, Validation cost= 0.2869, Validation acc= 0.8343
Epoch 27660: Training cost= 0.2803, Training acc= 0.8342, Validation cost= 0.2830, Validation acc= 0.8343
Epoch 27670: Training cost= 0.2947, Training acc= 0.8342, Validation cost= 0.3448, Validation acc= 0.8343
Epoch 27680: Training cost= 0.3161, Training acc= 0.8342, Validation cost= 0.2938, Validation acc= 0.8343
Epoch 27690: Training cost= 0.2420, Training acc= 0.8342, Validation cost= 0.2906, Validation acc= 0.8343
Epoch 27700: Training cost= 0.2979, Training acc= 0.8342, Validation cost= 0.3544, Validation acc= 0.8343
tm  [ 2.3 -0.6  3.   3.6 -1.7  0.1  0.1 -0.2 -0.2  1.9  4.7 -0.  -0.3 -0.4  1.7 -0.4  0.1 -0.  -0.2 -0.5 -0.9  0.3  1.8 -0.1 -1.4  3.9  0.3 -0.4 -1.2 -1.1 -0.3 -0.3 -0.6 -0.1  1.5 -0.2  1.   5.2  5.4 -0.4  0.3  3.6  1.2  2.6 -0.1 -0.1  1.4 -1.   4.9  8.5 -0.4 -0.1 -0.2  6.3  1.8  0.3 -0.5 -0.1  1.8  2.5 -0.7 -0.3 -0.   1.  -0.3 -0.3  0.2  0.8 -0.2 -0.  -0.2  5.5  0.5  0.2 -3.1  0.2 -0.7  1.5 -0.2 -0.3 -0.5  0.5 -0.2 -0.4 -1.8  3.4  4.2  0.1 -0.  -0.1 -0.1 -0.6 -0.2 -0.5 -0.3 -0.  -0.  -1.7 -0.3 -0.5 -1.1  5.7 -1.4 -0.1  0.1  0.4 -1.1 -0.3  1.  -0.5 -0.3 -0.1 -0.2 -0.1  3.4 -2.8 -0.1 -0.1 -0.3  0.4  0.   1.4 -0.2 -0.8 -0.2  1.8 -0.8 -1.3  0.3 -0.7  1.1 -0.  -0.4  1.8 -2.1 -2.2 -0.4 -0.2 -0.4 -0.1 -0.7 -1.7 -0.3 -0.  -0.2 -0.  -0.  -0.2 -0.5 -0.4 -0.2 -0.1  4.6 -0.2 -0.2 -0.2 -0.3  1.2  1.6  0.   1.3 -1.6  0.7 -0.2 -0.1 -0.8 -0.5 -0.9 -0.1 -0.1 -0.1 -0.4 -0.2 -0.1 -0.   1.8 -0.3  0.4 -0.5 -0.2 -0.6 -0.2 -0.4 -1.3 -0.3  0.   4.5 -0.2 -0.   3.7 -0.3 -0.4 -0.3 -0.6  7.6 -0.1 -0.5 -1.   0.3 -0.   0.7 -0.1 -0.2 -0.1 -0.4 -0.5 -0.3 -0.2  4.4 -0.3  0.3 -1.3 -0.5 -1.  -0.6  0.4 -0.5 -0.8 -0.8 -0.2 -0.2 -0.2 -0.2 -1.4  2.3 -1.   0.9  0.2 -0.3  1.9 -0.4  0.3 -0.   2.6  1.6 -0.3  3.3 -1.   1.7  4.7 -0.3  1.9 -0.2 -0.   3.5 -1.1 -0.2 -0.1 -0.8 -0.5  0.6 -0.2  4.2 -0.1 -1.4  6.2]
ty_50sample [[0 2 8 7 9 4 5 6 3 1]
 [0 5 6 7 8 3 1 9 4 2]
 [9 3 0 5 1 8 6 4 7 2]
 [9 9 1 3 5 0 7 8 8 2]
 [1 8 0 7 3 4 6 5 2 9]
 [7 5 0 8 9 9 3 4 1 2]
 [7 8 6 4 2 9 5 0 3 1]
 [4 7 8 6 5 1 2 9 0 3]
 [4 5 9 0 2 3 6 8 7 1]
 [9 2 7 6 6 5 3 1 8 4]]
tt_50sample [[0 2 8 7 9 4 5 6 3 1]
 [0 5 6 7 8 3 1 9 4 2]
 [9 3 0 5 1 8 6 4 7 2]
 [9 6 1 3 5 0 7 4 8 2]
 [1 8 7 0 3 4 6 5 2 9]
 [7 5 0 8 9 6 3 4 1 2]
 [7 8 6 4 2 9 5 0 3 1]
 [4 7 8 6 5 1 9 2 0 3]
 [4 5 9 0 2 3 6 8 7 1]
 [9 2 7 0 6 5 3 1 8 4]]
vm  [ 2.3  0.5  3.7  9.5 -0.9  0.1 -0.2 -0.1 -0.2 -0.7  7.7 -0.5 -0.2 -0.3 -0.7  4.1 -0.5 -0.7  1.  -1.4 -0.8 -0.1 -0.6 -0.3 -0.6  0.8 -0.  -0.2 -0.1  2.7  4.1 -0.8 -0.3  9.4 -0.  -0.2  0.6 -0.   5.5 -0.3 -0.6 -0.6 -0.1 -0.4 -0.4 -0.2  8.3 -0.5  5.8 -1.  -0.3 -0.3  1.4 -0.9 -0.9  1.2 -0.1 -0.8  0.  -1.3 -2.4 -0.1 -0.4  1.6  1.6  0.1 -0.2 -0.2  1.6 -0.3 -0.2 -1.   0.2 -0.1  5.5 -0.3 -1.3 -0.1  1.   0.4 19.3 -0.1 -0.5  1.  -1.3 -0.1  4.9 -0.2 -0.1 -0.5  0.5  0.4 -0.3 -1.  -0.4  0.3 -0.4 -0.6 -0.4 -0.2  2.1  5.4 -1.3 -0.3 -0.2  0.2  2.4  3.   1.7 -2.2 -0.4 -0.5 -0.1 -0.4 -0.3  5.9 -0.5 -0.4 -0.2 -0.2 -0.1  9.   1.4 -0.3  0.3 -1.1 -0.3  5.6 -0.2 -1.7  3.2 -0.7  0.9 -1.   1.4 12.2 -0.1 -0.  -0.4 -0.5 -0.4 -0.3 -0.1 -0.  -0.2 -0.2  0.2 -0.1 -1.8 -0.2 -0.5 -0.3  2.1 -0.2  1.1  0.1  0.3 -0.6 -1.2 -0.1  0.2  1.9 -0.2 -0.1 -0.3 -0.2  0.2  0.7 -0.1 -0.  -0.5 -0.3 -0.2 -0.  -0.1  3.4 -0.6  1.  -0.4 -0.1 -0.5 -0.4 -0.6 -1.5 -0.5  1.6  5.1 -0.4 -0.1 -0.6 -0.2 -0.4 -0.9 -0.5 13.8 -0.   4.1  0.3  0.1 -0.1 -0.2 -0.2 -0.3 -0.5 -0.3  3.7 -0.  -0.1 -0.6 -0.5 -0.5  3.  -1.1 -1.  -0.5 -0.1  2.6 -0.5  0.  -0.1 -0.5 -0.4 -0.1 -0.7  3.5  0.  -0.1  0.4 -0.2  4.9 -0.4 -1.4  0.3 -0.3 -0.4 -0.3  0.3  4.1  2.2 14.8 -0.2  6.1 -0.1 -0.  -4.  -2.6  0.2 -0.  -1.  -0.6 -4.9 -0.1  3.3 -0.  -0.3  8.3]
vy_50sample [[9 7 6 2 4 3 5 0 8 1]
 [8 4 3 1 0 5 7 6 9 2]
 [8 7 2 6 5 4 0 1 3 9]
 [6 1 7 5 3 2 8 8 0 4]
 [7 2 1 3 4 5 5 8 0 9]
 [5 4 6 8 7 0 0 9 2 3]
 [7 8 2 0 9 6 5 3 4 1]
 [6 5 1 4 9 7 0 8 3 2]
 [4 2 3 5 6 1 0 7 9 8]
 [7 3 8 6 9 4 2 2 0 5]]
vt_50sample [[9 6 7 2 4 3 0 5 8 1]
 [8 4 3 1 0 5 7 6 9 2]
 [8 7 2 6 5 4 1 0 3 9]
 [6 1 7 5 3 2 8 9 0 4]
 [7 2 1 3 4 6 5 0 8 9]
 [5 4 6 8 7 0 9 1 2 3]
 [7 8 2 0 9 6 5 3 4 1]
 [6 5 1 4 0 9 7 8 3 2]
 [4 2 3 5 6 1 0 7 9 8]
 [7 3 6 8 4 9 2 1 0 5]]
Epoch 27710: Training cost= 0.2967, Training acc= 0.8342, Validation cost= 0.2853, Validation acc= 0.8344
Epoch 27720: Training cost= 0.3379, Training acc= 0.8343, Validation cost= 0.3261, Validation acc= 0.8344
Epoch 27730: Training cost= 0.3738, Training acc= 0.8343, Validation cost= 0.3900, Validation acc= 0.8344
Epoch 27740: Training cost= 0.3010, Training acc= 0.8343, Validation cost= 0.2923, Validation acc= 0.8344
Epoch 27750: Training cost= 0.3056, Training acc= 0.8343, Validation cost= 0.2820, Validation acc= 0.8344
Epoch 27760: Training cost= 0.3356, Training acc= 0.8343, Validation cost= 0.2930, Validation acc= 0.8344
Epoch 27770: Training cost= 0.3050, Training acc= 0.8343, Validation cost= 0.3038, Validation acc= 0.8345
Epoch 27780: Training cost= 0.2496, Training acc= 0.8344, Validation cost= 0.2561, Validation acc= 0.8345
Epoch 27790: Training cost= 0.2845, Training acc= 0.8344, Validation cost= 0.2670, Validation acc= 0.8345
Epoch 27800: Training cost= 0.2650, Training acc= 0.8344, Validation cost= 0.2646, Validation acc= 0.8345
tm  [ 1.1 -0.1 -3.2  4.9 -0.7 -0.1 -0.3 -0.1  0.  -0.6 -0.9 -0.4 -0.3 -0.2 -3.7 -0.2 -0.5 -0.1  0.4 -2.1 -0.9 -0.1  1.4  0.6 -0.3 -0.1 -0.3  0.3 -0.8 -1.3  3.1 -0.2 -0.1 -2.6 -0.1 -0.3 -0.   2.9 18.3 -0.6 -0.4 -2.2 -1.   4.2 -0.4  0.2 12.8  0.1  3.9  3.4 -0.7 -0.3  1.5 -2.4 -0.4  4.8 -0.3 -3.3  3.7 -0.8 -2.5 -0.  -0.3 -0.2 -0.3 -0.4 -0.1  0.7  0.4 -0.2  0.4  0.2  1.  -0.1  8.9 -0.2 -0.9 -0.5 -0.2 -0.2 12.6 -0.4 -0.2 -0.2 -1.3 -2.3  5.9 -0.4 -0.4 -0.   1.1  0.  -0.  -1.  -0.1 -0.4 -0.7  0.2 -0.2  0.3  1.  -1.1 -1.  -0.2 -0.1 -0.6  3.8  3.1 -0.4 -2.5 -0.4 -0.4  0.1 -0.2  3.4 -0.3  0.1 -0.3 -0.2 -0.3 -0.4 10.  -0.2 -0.1 -0.  -4.4 -0.4 10.6  1.6 -2.4  1.  -0.7  0.5 -0.7 -0.2 -2.9  0.2 -0.3 -0.  -0.2 -0.1 -0.8 -0.6  0.1 -0.  -0.1 -0.4 -0.  -0.7 -0.1 -0.6 -0.1  4.3 -0.2  0.2 -0.1 -0.  -0.2  1.7 -0.  -0.4 -1.4 -0.2 -0.1 -0.4 -0.2  1.   2.6  0.2 -0.2 -0.3 -0.3 -0.5  0.5 -0.4  2.4 -0.   2.  -2.4 -0.   1.8 -0.2 -0.4 -1.1 -0.2  0.6  4.  -0.1  0.2  3.7 -0.1 -0.3 -1.  -0.6 14.5 -0.7  5.7 -0.7 -0.1  0.5 -0.2 -0.1 -0.4 -0.3 -0.3  7.3 -0.3 -0.3  7.9  0.1 -0.3 -0.2 -1.1 -1.   0.7 -0.6 -1.7 -0.5 -0.1 -0.1 -0.4 -0.1 -0.2 -0.6 -1.1  0.2 -1.1 -0.1 -0.4  3.7 -0.7 -1.8  0.2  4.4  0.9  5.8  0.4  5.6  2.  25.4 -0.1 10.1 -0.1 -0.1 -2.3 -3.9  0.1 -0.2 -1.  -0.1 -3.4  0.8 12.4 -0.3  2.1 10.6]
ty_50sample [[9 4 8 0 3 2 7 6 1 5]
 [6 5 3 7 4 0 9 8 1 2]
 [1 0 3 8 7 6 4 9 2 5]
 [6 5 1 7 0 9 2 3 8 4]
 [9 3 2 6 5 7 4 0 8 1]
 [5 8 7 0 6 3 2 9 4 1]
 [3 7 2 9 6 1 5 8 0 4]
 [2 1 0 5 3 7 4 6 8 9]
 [3 5 1 2 8 7 9 0 4 6]
 [6 8 3 4 2 7 7 0 9 1]]
tt_50sample [[9 4 8 0 3 2 7 6 1 5]
 [6 5 7 3 4 0 9 8 1 2]
 [1 0 3 7 8 6 4 9 2 5]
 [6 5 1 7 0 2 9 8 3 4]
 [9 3 2 6 5 7 4 0 8 1]
 [5 8 7 0 6 3 2 9 4 1]
 [3 7 2 9 6 1 5 8 4 0]
 [2 1 0 5 3 7 4 6 8 9]
 [3 5 1 2 8 7 9 0 4 6]
 [6 8 3 4 2 7 5 0 9 1]]
vm  [ 1.2  0.4 -0.3  0.2 -1.4 -0.2 -0.2 -0.2 -0.6 -0.7 -2.3  0.9 -0.5 -0.3  0.1 -0.3 -0.1 -0.3 -0.1 -0.4 -1.  -0.1 -0.4 -0.1 -1.1  0.8 -0.1 -0.1 -0.5 -1.4  0.1 -0.6 -0.3 -1.5 -0.3 -0.3  1.3  1.4  6.2 -0.6 -0.1 -0.4  1.7  3.  -0.3 -0.1 -0.   0.2  5.2 -1.  -0.8 -0.2 -0.1 -0.5 -0.6  0.6 -0.6  4.2  0.2  2.6 -0.6 -0.4 -0.2 -0.1 -0.4 -0.3 -0.  -0.2  0.9 -0.   0.   0.7  0.3  0.1 -2.9 -0.  -1.1 -0.5 -0.4 -0.1 -1.1 -0.4 -0.4  0.3 -1.6 -0.2  4.6 -0.3  0.6 -0.2 -0.5  0.2 -0.   1.3 -0.4 -0.1 -0.1 -1.8 -0.2 -0.2  2.9 -1.9 -1.2 -0.3 -0.1 -0.2 -1.4 -0.1 -0.9 -0.6 -0.2 -0.4 -0.1 -0.7 -0.   0.5 -0.4 -0.1 -0.1 -0.1 -0.3  2.2 -0.1 -0.6 -0.4  0.2 -0.3  4.4  3.1  7.3  1.6 -0.7  0.1 -0.4 -1.3 -2.9 -0.3 -0.1  0.2 -0.1  0.7 -0.7  1.1 -0.1 -0.2  0.  -0.3 -0.3  4.6  0.2 -0.2  0.5  5.3 -0.1 -0.2 -0.1 -0.2 -0.1  1.8 -0.5 -0.3 -1.4 -0.3 -0.  -0.1 -0.1  0.  -0.5 -0.1 -0.1 -0.1  0.5 -0.3 -0.1 -0.4 -0.9 -0.1 -0.4 -0.5 -0.3 -2.  -0.2 -0.3 -1.5 -0.   0.2  3.8 -0.2 -0.2  4.8 -0.1  0.3 -0.4 -0.9  6.5 -0.9 -0.5 -0.1 -0.2 -0.1 -0.2 -0.1 -0.2 -0.3 -0.2 -1.7 -0.1 -0.  -0.7 -0.3 -0.6 -0.  -0.7 -1.3 -0.2 -0.1 -0.7 -0.5 -0.2 -0.4 -0.3 -0.2  0.  -1.  -1.8  1.3 -1.4 -0.6 -0.3  5.  -0.8 -0.  -0.2 -0.6  0.1  0.9  0.7 -0.5  1.8 -1.9 -0.  -0.9 -0.2  0.1  5.7 -0.6 -0.2 -0.5 -1.  -0.3  2.2 -0.2  4.3 -0.   6.9 -1.5]
vy_50sample [[3 5 8 0 4 9 7 2 6 1]
 [8 7 4 6 1 2 5 0 9 3]
 [0 6 5 9 4 7 1 8 3 3]
 [9 4 2 6 7 0 3 5 1 8]
 [2 1 3 8 5 9 9 7 0 6]
 [1 7 0 9 5 5 8 2 3 4]
 [4 4 2 8 8 7 1 5 6 3]
 [8 9 2 0 6 4 4 5 7 3]
 [8 2 7 4 6 3 0 9 1 5]
 [4 2 9 8 5 3 1 7 0 6]]
vt_50sample [[3 5 8 0 4 9 7 2 6 1]
 [8 7 6 4 1 2 5 0 9 3]
 [0 6 5 9 4 1 7 8 2 3]
 [9 4 2 6 7 0 3 5 1 8]
 [2 1 3 8 5 4 9 7 0 6]
 [1 7 0 9 6 5 8 2 3 4]
 [4 9 2 8 0 7 1 5 6 3]
 [8 9 2 0 6 4 1 5 7 3]
 [8 2 7 4 6 3 0 9 1 5]
 [4 2 9 8 5 3 1 7 0 6]]
Epoch 27810: Training cost= 0.2219, Training acc= 0.8344, Validation cost= 0.2639, Validation acc= 0.8346
Epoch 27820: Training cost= 0.2982, Training acc= 0.8345, Validation cost= 0.2833, Validation acc= 0.8346
Epoch 27830: Training cost= 0.2449, Training acc= 0.8345, Validation cost= 0.2487, Validation acc= 0.8346
Epoch 27840: Training cost= 0.3327, Training acc= 0.8345, Validation cost= 0.2386, Validation acc= 0.8346
Epoch 27850: Training cost= 0.3372, Training acc= 0.8345, Validation cost= 0.2664, Validation acc= 0.8346
Epoch 27860: Training cost= 0.3280, Training acc= 0.8345, Validation cost= 0.2894, Validation acc= 0.8347
Epoch 27870: Training cost= 0.2905, Training acc= 0.8345, Validation cost= 0.3335, Validation acc= 0.8347
Epoch 27880: Training cost= 0.3463, Training acc= 0.8346, Validation cost= 0.2945, Validation acc= 0.8347
Epoch 27890: Training cost= 0.3236, Training acc= 0.8346, Validation cost= 0.2816, Validation acc= 0.8347
Epoch 27900: Training cost= 0.2764, Training acc= 0.8346, Validation cost= 0.3021, Validation acc= 0.8347
tm  [-0.9 -0.4  2.3 -2.6 -1.9 -0.3 -0.3 -0.4 -0.1 -0.4  6.9 -0.4  0.2 -0.4  9.4  2.3 -0.2 -0.3 -0.1  0.4 -1.  -0.3  0.  -0.3 -1.1  0.5 -0.3 -0.4 -0.1  0.4  5.6 -0.3 -0.3 13.7 -0.5 -0.  -0.1  2.1  0.4 -0.5  0.2  4.3 -0.   3.8 -0.4 -0.3 -1.1 -0.1 -0.7 -0.  -0.6 -0.2 -0.4  4.5 -1.2 -1.2 -0.6 -0.6  2.1 -2.6  5.4 -0.1 -0.1 -0.2  1.1 -0.4 -0.1 -0.2  1.3 -0.2 -0.  -0.9  0.2  0.4 -3.8 -0.5  0.3 -0.1  0.4 -0.4  6.3 -0.2 -0.2  0.  -0.2  5.4  1.8 -0.1 -0.3 -0.6 -0.4 -0.1 -0.  -0.9 -0.6 -0.1 -0.2 -2.2 -0.4 -0.3  1.9  8.9  0.9 -0.1 -0.2 -0.3 -1.9  4.5  1.1 -0.5 -0.3 -0.3 -0.2 -0.8  0.4  5.7 -0.2  0.5 -0.1 -0.4  0.   0.3 -0.1 -0.1  0.1 11.9 -0.1 -0.6  3.2 -0.1 -0.4 -0.6 -0.3 -0.4 -4.4  6.7  0.3 -0.3 -0.7 -0.2  0.  -0.2  0.5 -0.2 -0.2 -0.1  0.4 -0.1 -1.1 -0.3  1.8 -0.1 -1.6  0.3 -0.  -0.1 -0.3 -0.5  1.2 -0.3  0.5 -0.6 -0.1 -0.3 -0.4 -0.4 -0.4  1.4  0.  -0.2 -0.1 -0.  -0.3 -0.2 -0.1  2.7 -0.4 -0.6  1.1 -0.3 -0.9 -0.3 -0.3 -1.4 -0.6 -0.  -0.6 -0.5 -0.2 -0.2 -0.3 -0.3 -0.4 -0.6 -1.4 -0.8 -0.8 -0.2 -0.  -0.1 -0.  -0.4 -0.4 -0.5 -0.1 -2.4 -0.1 -0.2 -2.7 -0.3 -0.2  2.1 -0.5  5.2 -0.3 -0.2 -1.3 -0.7  0.1 -0.4 -0.3 -0.3 -0.5 -0.9  2.1 -0.3 -0.8 -0.2 -1.2  0.5 -0.9  1.  -0.4 -1.7 -0.1  0.7  0.2 -1.3  1.5 -1.6 -0.  -0.6  0.1 -0.1 -1.   1.3 -0.1 -0.3 -0.7 -0.1 -1.8 -0.2  0.1  0.3 -0.4  3.2]
ty_50sample [[7 4 1 5 2 6 9 0 3 8]
 [5 8 7 3 2 1 4 0 6 6]
 [4 6 7 9 1 2 8 3 0 5]
 [7 0 8 9 1 1 6 4 3 5]
 [6 7 2 4 3 1 9 9 8 0]
 [2 3 8 8 9 6 5 0 4 1]
 [4 5 1 8 0 2 9 3 6 7]
 [1 6 8 3 3 0 5 2 9 4]
 [2 4 0 9 1 3 6 5 7 8]
 [5 0 3 6 4 1 8 2 7 9]]
tt_50sample [[7 4 1 5 2 6 9 0 3 8]
 [5 8 7 3 2 1 4 0 9 6]
 [4 6 7 9 1 2 8 3 0 5]
 [7 0 8 9 1 2 6 4 3 5]
 [6 7 2 4 3 1 5 9 8 0]
 [2 3 7 8 9 6 5 0 4 1]
 [4 5 1 8 0 2 9 3 6 7]
 [1 6 8 3 7 0 5 2 4 9]
 [2 4 0 9 1 3 6 5 7 8]
 [5 0 3 6 4 1 8 2 7 9]]
vm  [-1.8 -0.5  4.1  4.  -1.9 -0.1  0.5 -0.1 -0.1 -0.7 -1.8 -0.2  0.3 -0.4  2.   3.3  0.4 -0.   0.7  0.9 -1.  -0.2  2.2 -0.5 -1.4  3.  -0.3 -0.5  1.1 -1.  -0.9 -0.5 -0.2 -0.8 -0.7 -0.1  0.6  3.5  7.9 -0.5  1.3  2.3  0.3  3.2 -0.1 -0.3 -0.3 -0.5 -0.8  8.5 -0.9 -0.  -0.2 -0.  -1.   0.3 -0.4  3.2  2.9  4.1  4.4  0.   0.3  0.6 -1.2 -0.1 -0.1 -0.6  0.8  1.  -0.1 -1.2  1.2  1.2 -1.9  1.1  0.3 -0.1  0.1  0.4 -1.5 -0.2 -0.1 -0.2  1.4  4.8 -1.4 -0.  -0.1 -0.  -0.5 -0.3 -0.3 -1.1 -0.5 -0.3  1.7 -2.  -0.6 -0.1  2.4  6.5  0.5  0.3 -0.3 -0.6 -0.8 -0.9 -0.6 -0.8 -1.  -0.2 -0.3 -0.7  0.5  8.1  1.  -0.4 -0.1 -0.4  0.2  2.2 -0.  -0.3  0.4  2.2  0.1  2.7  3.6 -0.5 -1.2 -0.9 -0.7 -0.7 -3.9 -4.4  0.4 -0.1 -0.7  0.6  0.2 -0.5  0.5 -0.1 -0.3 -0.1  0.6 -0.2 -0.3 -0.5 -0.2 -0.2 -0.   1.  -0.2 -0.2 -0.3 -0.1  5.3 -0.2  2.  -1.7 -0.  -0.1 -0.4 -0.7 -0.2  0.6 -0.5  0.2 -0.  -0.3 -0.  -0.5  0.1  0.7  0.5  0.3 -0.7 -0.3 -0.9  0.3 -0.1 -1.2 -0.6 -0.2 -0.6 -0.3  0.   2.8 -0.1 -0.3 -0.4 -0.4 -1.1 -1.1  0.4 -0.4  0.1 -0.1 -0.1 -0.1 -0.1 -0.7 -0.  -0.6 -0.1  0.8  4.7 -0.  -0.6  4.3 -0.1  7.  -1.  -0.  -0.8 -0.4  0.6 -0.2 -0.4 -0.3 -0.7 -1.1 -0.3  2.9 -1.   1.1 -0.2 -0.1 -0.  -0.5 -0.4  2.7 -0.1 -0.6 -0.3 -0.2  2.4  2.4 -0.1  1.1 -0.1 -0.3  6.  -1.1 -0.  -0.  -0.8 -0.5  3.  -0.3  5.5 -0.1 -0.1  4.6]
vy_50sample [[1 8 7 9 5 2 4 3 3 6]
 [1 6 3 5 8 7 9 0 2 4]
 [6 0 3 1 4 2 8 7 9 5]
 [6 0 9 1 8 4 7 3 3 2]
 [9 0 4 6 3 7 5 2 1 8]
 [7 0 3 5 6 1 8 8 4 2]
 [4 3 7 8 6 0 5 1 9 2]
 [6 8 9 5 4 0 2 3 1 7]
 [5 7 9 6 1 4 8 0 3 2]
 [8 0 9 5 6 1 2 3 7 4]]
vt_50sample [[1 8 7 9 5 2 4 3 0 6]
 [1 6 3 5 8 7 9 0 2 4]
 [6 0 3 1 2 4 8 7 9 5]
 [6 0 9 1 8 4 7 5 3 2]
 [9 0 6 4 3 7 5 2 1 8]
 [7 0 3 5 6 1 9 8 4 2]
 [4 3 7 8 6 0 5 1 9 2]
 [8 6 9 5 0 4 2 3 1 7]
 [5 7 9 6 1 4 8 0 3 2]
 [0 8 9 5 6 1 2 3 7 4]]
Epoch 27910: Training cost= 0.2586, Training acc= 0.8346, Validation cost= 0.2583, Validation acc= 0.8347
Epoch 27920: Training cost= 0.2713, Training acc= 0.8346, Validation cost= 0.2504, Validation acc= 0.8348
Epoch 27930: Training cost= 0.2862, Training acc= 0.8347, Validation cost= 0.2743, Validation acc= 0.8348
Epoch 27940: Training cost= 0.2526, Training acc= 0.8347, Validation cost= 0.2270, Validation acc= 0.8348
Epoch 27950: Training cost= 0.2567, Training acc= 0.8347, Validation cost= 0.2841, Validation acc= 0.8348
Epoch 27960: Training cost= 0.2455, Training acc= 0.8347, Validation cost= 0.2222, Validation acc= 0.8349
Epoch 27970: Training cost= 0.2475, Training acc= 0.8347, Validation cost= 0.3029, Validation acc= 0.8349
Epoch 27980: Training cost= 0.2645, Training acc= 0.8348, Validation cost= 0.2948, Validation acc= 0.8349
Epoch 27990: Training cost= 0.2711, Training acc= 0.8348, Validation cost= 0.2845, Validation acc= 0.8349
Epoch 28000: Training cost= 0.2793, Training acc= 0.8348, Validation cost= 0.2668, Validation acc= 0.8349
tm  [-0.   1.1 -3.2  4.7 -0.7 -0.3 -0.3 -0.2 -1.4 -0.8 -5.7 -0.2 -0.2 -0.3 -3.5 -0.9 -0.2 -0.3 -0.4 -1.6 -0.6 -0.2  1.3  0.8 -0.9  0.5 -0.4 -0.3 -1.2 -0.6 -0.5 -0.2  0.  -6.3 -0.1  0.8  2.5 -0.4 10.2 -0.4  0.1 -1.6  1.4  1.9 -0.  -0.5  8.3  1.3  2.1  4.7 -0.6 -0.2 -0.3 -2.4 -0.6  4.1 -0.4 -0.6 -0.7  3.4 -1.5 -0.4 -0.3 -0.6 -0.8 -0.4 -0.1 -0.5 -0.2  0.6 -0.1  2.2  0.4 -0.3  3.3  0.1 -0.3 -0.3 -0.4 -0.5 -0.4 -0.  -0.6  0.4 -1.5 -1.4  3.6 -0.4 -0.1 -0.1 -0.3  0.  -0.   3.6 -0.5 -0.2 -0.2 -0.4  0.1 -0.4  3.1 -3.2 -0.4 -0.3 -0.1 -0.5 -0.1 -0.9 -1.9 -2.  -0.2 -0.2 -0.1 -0.1 -0.1 -0.5 -0.3 -0.9 -0.1 -0.6 -0.4  7.4 -0.1 -0.4 -0.3 -3.9 -0.2 11.2 -0.5  0.1  0.6  0.1  0.3 -0.2  7.7 -4.2 -0.2 -0.2  0.3  3.6  2.3 -1.  -0.  -0.  -0.1 -0.  -0.4  0.1  5.7 -0.  -0.4 -0.2  4.2 -0.  -0.2  0.  -0.1 -0.5 -0.  -0.8 -0.4 -1.  -0.1 -0.1 -0.2 -0.3 -0.3 -0.3 -0.1 -0.2 -0.3 -0.1 -0.1 -0.  -0.  -1.1 -0.5 -0.1 -1.1 -0.1 -0.9 -0.7 -0.4 -1.4 -0.1  0.3  1.9  0.3 -0.2  2.  -0.3 -0.5 -0.6 -1.   9.6  1.8  2.1  0.1 -0.1  0.5 -0.3 -0.2 -0.3 -0.3  0.2  1.7 -0.  -0.3  7.4 -0.3 -0.5 -0.7 -0.2 -0.5 -0.  -0.5 -0.8 -0.3 -0.3 -0.2 -0.5 -0.3 -0.3 -0.7 -1.3  0.  -1.8 -0.5 -1.1  1.5 -0.9 -0.8 -0.1  3.7  0.9  5.2 -0.2  2.  -0.  11.2  0.   4.4 -0.1 -0.2  3.4 -2.5 -0.5 -0.7 -0.8 -0.2  0.3  0.1  6.6 -0.5  7.5  1.7]
ty_50sample [[8 9 3 0 4 5 6 1 2 7]
 [6 9 4 2 2 3 5 1 8 0]
 [4 5 0 2 9 6 3 8 1 7]
 [6 3 1 8 9 7 5 4 2 0]
 [7 7 3 9 0 1 4 2 8 6]
 [6 2 7 1 9 3 5 0 8 8]
 [1 4 7 2 5 9 0 8 3 6]
 [0 6 8 1 2 4 3 7 9 9]
 [5 3 1 9 4 2 2 0 7 6]
 [5 7 7 3 3 9 9 4 0 2]]
tt_50sample [[8 9 3 0 4 5 6 1 2 7]
 [6 9 4 7 2 3 5 8 1 0]
 [4 5 0 2 9 6 3 8 1 7]
 [6 3 1 8 9 7 5 4 2 0]
 [7 5 3 0 9 1 4 2 8 6]
 [6 2 7 1 9 3 5 0 4 8]
 [1 4 7 2 5 0 9 8 3 6]
 [0 6 8 1 2 4 3 7 5 9]
 [5 3 9 1 4 0 8 2 7 6]
 [5 7 8 1 3 9 6 0 4 2]]
vm  [-1.5 -0.5  7.6  7.7 -1.   0.3 -0.1  0.2  0.1 -0.3 -1.  -0.5 -0.3  0.8  5.   3.2 -0.6 -0.2  0.3 -0.8 -0.8 -0.5  1.5 -0.2 -0.7 -0.3 -0.2 -0.1  1.8 -0.1 -0.9 -0.2  1.1  3.3 -0.5 -0.5  0.6 -0.7 -1.9 -0.1 -0.3 -1.4 -1.1 -1.2 -0.4 -0.3  2.6 -0.4 -1.2  6.1 -0.6 -0.1 -0.6 -0.1 -1.2 -0.3 -0.3 -0.5  3.3  4.1  4.6 -0.5 -0.3  0.5 -0.1  0.  -0.   1.7  0.9 -0.6  0.  -1.6 -0.  -0.2 -2.2 -0.2 -0.7 -0.4 -0.1  0.7 -1.  -0.1 -0.5  0.8  1.7 -1.  -1.6 -0.1 -0.3 -0.1  0.   0.1 -0.2 -1.2 -0.4 -0.2 -0.4 -1.5 -0.  -0.3  0.3  4.7 -0.1 -0.1 -0.  -0.2 -1.4 -0.6 -0.3 -0.9 -0.2 -0.2  0.1 -0.8  1.5  7.4 -1.  -0.3 -0.  -0.4 -0.5  2.6  0.   0.8 -0.2  5.6 -0.1  2.5  0.2 -0.4  0.3 -0.8 -0.1 -0.2  4.4  6.  -0.1  0.7  0.6 -0.7 -0.5 -0.2 -0.5 -0.4  0.2  0.4 -0.4  0.3 -2.4 -0.1 -0.8  0.4 -0.1 -0.4  0.   0.3 -0.1 -0.2 -1.5  0.  -0.3  2.3 -0.2  0.2 -0.4 -0.   0.2  3.8 -0.2 -0.  -0.3 -0.5  0.6  1.3 -0.6  3.9 -1.  -0.3  4.1 -0.3  2.6 -0.2 -0.1 -1.  -0.5 -0.4 -0.5 -0.8 -0.3  0.8 -0.1 -0.3 -0.7 -0.8 -1.  -0.3 -0.7 -0.3 -0.5 -0.1 -0.3 -0.3 -0.4 -0.7 -0.1 -1.8 -0.4 -0.   8.1  0.5 -0.2  4.  -1.2  4.2 -0.6 -0.5  6.4 -0.4 -0.6  0.1 -0.4 -0.3 -0.4 -1.2  4.   4.1 -0.7  2.3  2.4  1.2  0.1 -0.  -0.1  3.6 -0.7 -1.7  1.6 -0.8  2.8 10.2 -0.   4.5 -0.2 -0.1  4.5 -0.5  0.3 -0.1 -1.2 -0.2  2.1  0.2 -1.1  0.7  0.   4.2]
vy_50sample [[6 1 7 8 9 2 3 4 0 5]
 [1 7 9 0 3 5 6 2 4 8]
 [1 4 4 6 6 7 9 3 3 0]
 [7 4 9 9 8 0 2 3 5 1]
 [0 6 1 7 5 9 2 3 8 4]
 [8 3 0 6 2 4 7 1 9 5]
 [7 4 2 6 8 9 0 1 5 3]
 [2 8 9 6 4 7 1 0 3 5]
 [3 2 7 1 1 6 8 8 9 4]
 [9 1 4 5 0 2 6 8 7 3]]
vt_50sample [[6 1 7 8 9 2 3 4 0 5]
 [1 7 9 0 3 5 6 2 4 8]
 [1 2 4 6 7 8 9 5 3 0]
 [7 4 6 9 8 0 2 3 5 1]
 [0 6 1 7 5 9 2 3 8 4]
 [8 3 0 6 2 4 7 1 9 5]
 [7 4 2 6 8 0 9 1 5 3]
 [2 8 9 6 7 4 1 0 3 5]
 [3 2 7 5 1 0 8 6 9 4]
 [9 1 4 5 0 2 6 8 7 3]]
Epoch 28010: Training cost= 0.3142, Training acc= 0.8348, Validation cost= 0.3044, Validation acc= 0.8350
Epoch 28020: Training cost= 0.2415, Training acc= 0.8349, Validation cost= 0.2768, Validation acc= 0.8350
Epoch 28030: Training cost= 0.3226, Training acc= 0.8349, Validation cost= 0.2744, Validation acc= 0.8350
Epoch 28040: Training cost= 0.3004, Training acc= 0.8349, Validation cost= 0.2813, Validation acc= 0.8350
Epoch 28050: Training cost= 0.2553, Training acc= 0.8349, Validation cost= 0.3481, Validation acc= 0.8350
Epoch 28060: Training cost= 0.2658, Training acc= 0.8349, Validation cost= 0.2968, Validation acc= 0.8351
Epoch 28070: Training cost= 0.2886, Training acc= 0.8349, Validation cost= 0.2881, Validation acc= 0.8351
Epoch 28080: Training cost= 0.3195, Training acc= 0.8350, Validation cost= 0.2509, Validation acc= 0.8351
Epoch 28090: Training cost= 0.2477, Training acc= 0.8350, Validation cost= 0.2542, Validation acc= 0.8351
Epoch 28100: Training cost= 0.2838, Training acc= 0.8350, Validation cost= 0.3118, Validation acc= 0.8351
tm  [-0.2  0.8 -1.6  5.2 -0.9 -0.4 -0.4 -0.4 -1.1 -0.6 -5.3  0.1 -0.2 -0.2 -1.9 -0.5  0.2 -0.  -0.2 -0.8 -0.7 -0.5  1.1  0.2 -0.8  1.2 -0.  -0.4 -0.5 -0.5 -1.2 -0.5 -0.1 -5.7 -0.4  0.2  2.3 -0.4  3.2 -0.5 -0.1  2.1  2.8  0.3 -0.4 -0.3  2.6  0.1  1.9  4.6 -0.7 -0.4 -0.4 -1.4 -0.8  2.8 -0.4  7.1 -0.9  4.8 -0.3 -0.4 -0.6 -0.6 -0.9 -0.6 -0.3 -0.3  0.4 -0.2 -0.4  1.1 -0.1 -0.3 -2.3 -0.4 -0.3 -0.7 -0.3 -0.1 -2.6  0.2 -0.3 -0.  -1.4  2.7  1.5 -0.3  1.  -0.5  0.   0.1  0.3  4.  -0.4 -0.  -0.2 -1.4 -0.1 -0.5  2.3 -2.5 -0.5 -0.2 -0.  -0.1 -1.2 -1.1 -1.8 -1.2 -0.1 -0.6 -0.1 -0.4 -0.4 -0.4 -0.4 -0.7 -0.1 -0.3 -0.1  3.3 -0.3 -0.5 -0.4 -2.2 -0.   7.4 -0.2  4.2  0.8 -0.3  0.9  0.   8.4 -3.1 -0.3  0.1  0.2  0.3  1.3 -0.8 -0.  -0.1 -0.2 -0.3 -0.5 -0.2  9.  -0.3 -0.6  0.4  3.8 -0.  -0.2 -0.1 -0.3 -0.9 -0.2 -0.9 -0.2 -0.6 -0.3 -0.2 -0.3 -0.2 -0.3 -0.6 -0.3 -0.  -0.2  0.1 -0.2 -0.2 -0.1 -2.1 -0.6 -0.2 -0.2 -0.3 -2.  -0.4 -0.2 -1.4 -0.3  0.9  2.1  0.5 -0.4  2.3 -0.5 -0.6 -0.6 -1.1  4.9  2.5 -0.2  0.7 -0.2 -0.3 -0.1 -0.2 -0.2  0.1  0.4 -0.7  0.4 -0.3  1.5 -0.5 -0.5 -0.4 -0.3 -0.2 -0.1 -0.3  0.9 -0.3 -0.3 -0.4 -0.4 -0.1 -0.3 -0.8 -0.7  0.2 -1.8 -0.5 -0.9  0.2 -0.5  0.5 -0.3  1.2 -0.2  3.   0.2 -0.6  0.4 -2.1 -0.2 -0.8 -0.1 -0.4  8.7 -1.2 -0.2 -0.7 -1.  -0.4  5.9 -0.1  2.2 -0.4  6.4 -0.5]
ty_50sample [[8 5 3 0 9 6 4 1 2 7]
 [4 8 5 7 2 6 1 3 0 9]
 [5 0 4 8 6 2 7 1 3 9]
 [5 9 2 1 7 6 4 0 8 3]
 [0 7 9 3 4 5 1 2 6 8]
 [2 4 0 0 1 7 3 5 6 9]
 [5 7 3 8 9 4 6 0 2 1]
 [1 1 4 0 8 3 7 5 2 6]
 [8 0 0 9 7 6 5 3 1 2]
 [8 4 6 5 1 7 9 9 3 0]]
tt_50sample [[8 5 3 0 9 6 4 1 2 7]
 [4 8 5 7 2 6 1 3 9 0]
 [5 0 4 8 6 2 7 1 3 9]
 [5 9 2 1 7 6 4 0 8 3]
 [0 7 9 3 4 5 1 2 6 8]
 [2 4 8 0 1 7 3 5 6 9]
 [5 7 3 8 9 4 6 0 2 1]
 [9 1 4 0 8 3 7 5 2 6]
 [8 0 9 4 7 6 5 3 1 2]
 [8 4 6 5 1 7 9 2 3 0]]
vm  [-0.4 -1.3  4.9 -2.7 -2.1 -0.2 -0.5 -0.1  2.1  1.6 -0.1 -0.6 -0.3 -0.3 14.1 -1.6 -0.4 -0.2 -0.5  1.  -1.   0.   1.4 -0.  -0.8  2.3 -0.3 -0.4 -1.  -1.2  3.8 -0.3 -0.2 12.7 -0.1 -0.4 -0.6 -0.3 -1.1 -0.5  0.9  5.  -0.7  2.7 -0.2  0.  -2.   0.8  1.7  4.  -0.4 -0.3 -0.2  2.   0.1 -1.5 -0.8 -0.3  6.6 -1.5  4.5 -0.4  1.   0.4  1.9 -0.5  0.4 -0.1  0.5 -0.3 -0.2  1.1 -0.4  0.6 -5.8 -0.5 -0.6  0.8 -0.2 -0.1 -0.6  0.7  0.7  0.5 -0.6  4.5  2.3 -0.2 -0.5 -0.8  0.1 -0.1 -0.  -1.8 -0.5  0.4 -0.2 -3.  -0.1 -0.2 -0.7  9.6 -0.1 -0.1 -0.2  0.4 -2.4  3.4 -0.1  1.5 -0.  -0.1 -0.2 -1.2  7.  -1.2 -0.5  4.1 -0.  -0.5 -0.4 -1.  -0.3  0.5 -0.2 16.9 -0.2  1.3  7.   0.6 -0.2 -0.4 -0.4 -0.2 -4.9  3.9 -0.3 -0.3 -0.7 -0.4  2.9 -0.8  1.3 -0.1 -0.2 -0.1  0.1 -0.1 -1.3 -0.1  2.2 -0.1 -0.6  0.7 -0.2 -0.1 -0.2 -0.5  1.4 -0.5 -0.2 -1.1 -0.  -0.2  0.5 -0.4 -0.6  1.4  0.1 -0.1 -0.1 -0.2 -0.1  0.2  0.1  3.2 -0.7 -0.4  2.8 -0.1 -1.  -0.3 -0.3 -1.4 -0.6 -0.3  0.8 -0.6 -0.1  2.7 -0.1 -0.3 -0.4 -0.5 -0.9 -2.  -1.5 -1.5  0.3  0.  -0.2 -0.3 -0.2 -0.5  0.1 -2.9 -0.2 -0.4 -1.5 -0.3 -0.1 -0.4 -0.7  0.4 -0.9 -0.6 -0.9 -0.8 -0.7 -0.2 -0.6 -0.3  0.1 -0.7  2.2 -0.8 -2.  -0.2 -1.2  2.8 -0.5 -0.2 -0.4 -1.1  1.5 -0.4  1.7 -1.7  3.7 -2.6  0.1 -1.2  0.  -0.2  3.8  2.9 -0.4 -0.3 -0.8 -0.   0.9 -0.1 -0.7 -0.1  1.3  2.3]
vy_50sample [[7 0 4 5 1 6 8 2 3 9]
 [3 6 1 8 0 2 4 7 9 5]
 [4 3 0 5 5 9 2 7 8 6]
 [0 3 5 2 4 9 8 7 6 1]
 [1 0 2 8 7 3 4 9 6 5]
 [9 7 3 5 2 6 4 4 0 1]
 [2 9 5 0 3 1 8 6 7 4]
 [6 2 0 1 7 4 9 3 5 8]
 [7 6 3 8 4 1 5 9 0 2]
 [3 9 5 7 1 8 2 6 0 4]]
vt_50sample [[7 0 4 5 1 6 8 2 3 9]
 [3 6 1 8 0 2 4 7 9 5]
 [4 3 5 1 0 9 2 7 8 6]
 [0 3 5 2 4 9 8 7 6 1]
 [1 2 0 8 7 3 4 9 6 5]
 [9 7 3 5 2 6 8 4 0 1]
 [2 9 5 0 3 1 8 6 7 4]
 [2 6 0 1 7 4 9 3 5 8]
 [7 6 3 8 4 1 5 0 9 2]
 [3 9 5 7 1 8 2 6 4 0]]
Epoch 28110: Training cost= 0.2788, Training acc= 0.8350, Validation cost= 0.2433, Validation acc= 0.8352
Epoch 28120: Training cost= 0.2784, Training acc= 0.8350, Validation cost= 0.3262, Validation acc= 0.8352
Epoch 28130: Training cost= 0.3737, Training acc= 0.8351, Validation cost= 0.2607, Validation acc= 0.8352
Epoch 28140: Training cost= 0.3569, Training acc= 0.8351, Validation cost= 0.2575, Validation acc= 0.8352
Epoch 28150: Training cost= 0.2846, Training acc= 0.8351, Validation cost= 0.3148, Validation acc= 0.8352
Epoch 28160: Training cost= 0.3245, Training acc= 0.8351, Validation cost= 0.2766, Validation acc= 0.8352
Epoch 28170: Training cost= 0.3430, Training acc= 0.8351, Validation cost= 0.2998, Validation acc= 0.8353
Epoch 28180: Training cost= 0.3148, Training acc= 0.8351, Validation cost= 0.3922, Validation acc= 0.8353
Epoch 28190: Training cost= 0.3483, Training acc= 0.8352, Validation cost= 0.2861, Validation acc= 0.8353
Epoch 28200: Training cost= 0.2903, Training acc= 0.8352, Validation cost= 0.2792, Validation acc= 0.8353
tm  [-1.1  1.5  4.3  2.1 -2.1 -0.3 -0.2 -0.1 -1.2 -1.  -1.7 -0.3 -0.4 -0.3  3.6 -0.6 -0.5 -0.3  0.3 -0.9 -0.7 -0.2  2.1 -0.  -1.5  2.7 -0.3 -0.3 -0.7  3.2  0.  -0.1 -0.3  5.7 -0.6  1.2  4.3 -0.1  5.1 -0.6  0.9  5.9  4.7  3.  -0.  -0.2  2.5  0.7 -0.5  7.9 -0.8  0.4  0.2 -0.8 -0.5 -0.3 -0.9  3.5 -1.5  1.   1.9  0.6 -1.1 -0.3 -0.7  1.7  0.3 -0.7  1.6  1.3  0.9  0.1  0.6 -0.1 -0.2  1.8  1.6  0.5  0.6  0.1  1.2 -0.1 -0.1  1.   1.6  7.6  0.3 -0.2 -0.2 -0.3 -0.7 -0.1  0.1  1.6 -0.3  0.4  2.  -1.  -0.6  0.4  4.1  7.5  0.8 -0.1  0.1 -0.4 -0.8  0.8 -0.5 -1.1 -0.7 -0.4 -0.   0.2 -0.6  1.9  1.3 -1.3 -0.3 -0.4 -0.4  5.2 -0.2 -0.2 -0.2  4.2  0.3  6.  -0.9 -1.5 -0.7 -0.3 -0.6 -0.6 -3.6 -1.2 -0.2 -0.2 -0.8 -0.7  1.8 -0.7  2.6  0.2 -0.3 -0.1  0.8 -0.3  0.  -0.2 -0.2 -0.3  0.4  1.3 -0.1 -0.2  0.6 -0.2  2.  -0.6 -0.4 -0.5 -0.3  0.  -0.6 -0.6 -0.2 -0.6 -0.2 -0.1 -0.2 -0.5 -0.1 -0.3 -0.1  1.4 -0.5 -0.1 -0.3 -0.2 -1.7  0.6  0.  -1.3 -0.5  0.5 -0.3 -0.6 -0.1 -0.7 -0.2 -0.1 -0.2 -1.   0.3  3.4  0.2  1.5  0.5 -0.3  0.  -0.3 -0.3 -0.5 -0.  -0.9 -0.   0.3 -0.7 -0.2 -0.1 -0.5  0.3  4.3 -0.7 -0.2 -0.4 -0.5  1.2 -0.5 -0.2  0.5 -0.4 -0.5  2.1  1.  -1.3 -0.5  2.  -0.5 -0.7 -0.4 -0.1 -0.5  2.  -0.8 -0.2  0.6  1.2 -0.4  0.1 -0.1  0.2 -0.2  1.2 -1.   0.3 -0.1 -0.5 -0.4 -0.5 -0.1  3.3 -0.3  1.   8.2]
ty_50sample [[7 5 1 1 9 0 0 6 2 3]
 [4 2 3 0 8 9 6 6 5 7]
 [6 7 1 0 9 3 2 5 8 4]
 [2 1 8 3 6 5 9 4 0 7]
 [1 2 9 6 3 7 8 4 0 5]
 [8 4 5 3 9 2 6 0 1 7]
 [7 9 2 2 5 6 3 0 4 1]
 [9 4 5 1 2 7 6 3 8 0]
 [5 4 1 0 8 7 6 3 9 2]
 [5 9 2 7 1 4 8 3 0 6]]
tt_50sample [[7 5 1 9 8 4 0 6 2 3]
 [4 2 3 0 8 9 6 1 5 7]
 [6 7 1 0 9 3 2 5 4 8]
 [2 1 8 3 6 5 9 0 4 7]
 [1 2 9 6 3 7 8 4 0 5]
 [8 4 5 3 9 2 6 0 1 7]
 [7 9 2 8 5 6 3 0 4 1]
 [9 4 5 1 2 7 6 3 8 0]
 [5 4 1 0 8 7 6 3 9 2]
 [5 9 2 7 1 4 8 3 0 6]]
vm  [-1.6 -0.9 -1.   2.  -1.3 -0.2  0.1 -0.1  0.   1.1 -3.5 -0.3 -0.6 -0.3 -0.5 -1.   0.9 -0.1 -0.3 -0.4 -1.  -0.3  1.4 -0.3 -0.9  3.5  0.6 -0.4 -0.6 -1.  -0.8 -0.8 -1.1 -3.1 -0.4 -0.3  0.7 -0.4  0.3  0.1 -0.4  2.6 -0.6 -0.1 -0.8 -0.1 -0.2 -0.2 -1.7 11.7 -0.4 -0.2 -0.5 -0.5 -0.4  1.4 -0.4 -0.3  2.7  2.5  7.5 -0.2  0.3 -0.3 -0.7 -0.1 -0.2  0.8 -0.3 -0.3 -0.3  0.8  0.6  1.2 -3.6 -0.4  0.8 -0.1 -0.1 -0.1 -2.2  0.6  0.3 -0.4  2.   3.8 -1.3 -0.  -0.1 -0.2 -0.  -0.4  0.3 -1.1 -0.6 -0.1 -0.4 -2.1  0.2 -0.5 -0.8  3.1  1.6 -0.2 -0.4  0.6 -1.2 -0.5 -1.4 -0.6  0.5 -0.1  0.  -0.4  4.5 -1.  -0.7 -0.3 -0.  -0.2 -0.   1.2 -0.3 -0.2  0.4 -0.5 -0.3  5.2  0.6 -1.  -0.3  0.2 -0.4  0.8  7.2 -1.6 -0.6 -0.1  1.4  0.8  1.9 -1.3  0.9 -0.2 -0.1 -0.2 -0.1 -0.1  2.7 -0.2 -0.1  0.2 -0.4  0.5 -0.3 -0.1 -0.7 -0.2 -0.5  1.1  1.  -0.3  0.3 -0.2 -0.1 -0.6 -0.5  1.8 -0.2 -0.2 -0.1 -0.4 -0.  -0.1 -0.1 -0.1 -0.2 -0.1  1.   0.1 -0.2 -0.1 -0.3 -1.6 -0.3 -0.2 -1.  -0.3 -0.4  3.6 -0.1 -0.3 -0.2 -0.7 -2.1  0.7 -0.4 -0.7 -0.2 -0.2 -0.2  0.7 -0.1 -0.4  0.4 -0.4 -0.2 -0.3  6.6 -0.3  0.  -0.2 -0.8  8.8 -0.7 -0.2  1.4 -0.7 -0.7 -0.1 -0.8 -0.3 -0.4 -1.1  5.  -0.2 -2.   0.9 -0.5 -1.  -0.  -0.3 -0.2  3.3  0.5  2.7  0.4 -1.   2.4  4.  -0.2  1.6 -0.2 -0.2  7.5 -1.  -0.1 -0.3 -1.  -0.8  5.3 -0.1  0.7 -0.   0.4  6.6]
vy_50sample [[1 8 0 6 9 4 5 2 7 3]
 [4 9 7 0 1 2 5 8 3 6]
 [3 2 9 4 8 6 0 5 1 7]
 [2 1 9 4 8 7 5 3 0 6]
 [3 4 0 9 7 6 8 2 1 5]
 [3 2 8 7 5 6 4 9 0 0]
 [4 8 6 9 9 5 0 0 7 3]
 [4 6 3 7 0 8 9 5 2 1]
 [9 6 1 8 7 2 0 4 3 5]
 [0 3 1 9 2 4 6 8 5 7]]
vt_50sample [[1 8 0 6 4 9 5 7 2 3]
 [4 9 7 0 1 2 5 8 3 6]
 [3 9 2 4 6 8 0 5 1 7]
 [2 1 9 4 8 7 5 3 0 6]
 [3 4 0 9 7 6 8 2 1 5]
 [3 2 8 7 5 6 4 9 1 0]
 [4 8 6 9 5 1 2 0 7 3]
 [4 6 3 7 0 8 9 5 2 1]
 [9 6 1 8 7 2 0 3 4 5]
 [0 3 1 9 2 4 6 8 5 7]]
Epoch 28210: Training cost= 0.2554, Training acc= 0.8352, Validation cost= 0.2824, Validation acc= 0.8353
Epoch 28220: Training cost= 0.2545, Training acc= 0.8352, Validation cost= 0.3464, Validation acc= 0.8353
Epoch 28230: Training cost= 0.2544, Training acc= 0.8352, Validation cost= 0.2818, Validation acc= 0.8354
Epoch 28240: Training cost= 0.2948, Training acc= 0.8352, Validation cost= 0.3206, Validation acc= 0.8354
Epoch 28250: Training cost= 0.3081, Training acc= 0.8353, Validation cost= 0.3014, Validation acc= 0.8354
Epoch 28260: Training cost= 0.2921, Training acc= 0.8353, Validation cost= 0.2624, Validation acc= 0.8354
Epoch 28270: Training cost= 0.2900, Training acc= 0.8353, Validation cost= 0.2907, Validation acc= 0.8354
Epoch 28280: Training cost= 0.2474, Training acc= 0.8353, Validation cost= 0.3107, Validation acc= 0.8355
Epoch 28290: Training cost= 0.4330, Training acc= 0.8353, Validation cost= 0.2909, Validation acc= 0.8355
Epoch 28300: Training cost= 0.3142, Training acc= 0.8353, Validation cost= 0.2738, Validation acc= 0.8355
tm  [-0.9 -0.4  8.8  3.9 -1.7 -0.2 -0.4 -0.   1.2 -0.7  3.3  0.6 -0.5 -0.1  8.6 -0.  -0.4 -0.6  0.5  2.1 -1.1 -0.2 -0.9 -0.3 -0.6  1.4 -0.  -0.4 -0.2 -2.3 -0.2 -0.1 -0.   8.  -0.6 -0.6 -0.6 -0.4 -1.5 -0.4 -0.1  3.4  0.2 -0.5 -0.1  0.  -2.5  1.   1.7 -2.3 -0.6 -0.1  0.   3.4 -0.6 -0.9 -0.6 11.4  3.6  3.2  5.4 -0.3 -0.1 -0.1  0.4 -0.1 -0.1  0.4  1.4 -0.2  0.3 -0.7 -0.2 -0.1 -5.7 -0.6 -0.8 -0.4 -0.3 -0.2 -0.4 -0.3  0.4 -0.5 -0.4  3.4 -1.1 -0.2 -0.5 -0.6  0.1 -0.  -0.  -0.6 -0.6 -0.1 -0.3 -2.9 -0.3 -0.3  2.6  0.3 -0.  -0.1 -0.3  0.9 -2.1 -0.   1.3  0.3  0.3 -0.3 -0.1 -1.2  1.9  5.2 -0.2  2.9  0.1  0.9 -0.1 -0.6 -0.   1.3 -0.3 10.3 -0.1 -0.2  7.6  8.4 -0.1 -0.6 -0.2 -0.4 -1.8  6.1 -0.2 -0.1 -0.5 -0.7  1.9  0.6  1.8 -0.  -0.1 -0.  -0.2 -0.   4.  -0.2 -0.2 -0.3 -0.6  1.8 -0.3 -0.2 -0.1 -0.5  1.8 -0.5 -0.7 -0.4  0.2 -0.1 -0.3 -0.3  0.   0.5  0.3 -0.2 -0.3 -0.2 -0.1 -0.2  0.1 -0.7 -0.8 -0.9  3.9 -0.  -2.2 -0.3 -0.3 -1.5 -0.1  0.8 -0.1 -0.5 -0.   6.7 -0.1 -0.2 -0.  -0.9 -1.3 -1.9 -1.2 -0.5  0.1 -0.1 -0.2 -0.2 -0.2 -0.5 -0.3 -3.1  0.2 -0.4 -4.5 -0.3 -0.4  2.5 -0.6  1.4 -0.6 -0.4  3.9 -0.7 -0.1 -0.2 -0.4 -0.3  1.3 -0.6 -0.8 -0.2 -1.7 -0.  -0.1  3.3 -0.3 -0.2 -0.1 -2.9 -0.1 -1.9  0.7 -1.5  3.4 -5.7 -0.1 -2.3 -0.1 -0.1  3.1  3.9 -0.4 -0.3 -1.3 -0.1  0.2 -0.2 -0.9 -0.1  6.3 -2.1]
ty_50sample [[5 3 7 1 6 0 2 8 9 4]
 [6 7 9 1 8 4 0 5 2 3]
 [4 5 5 0 9 7 7 2 3 6]
 [4 1 5 7 8 3 9 2 0 6]
 [8 6 1 7 2 5 0 4 3 9]
 [9 0 8 3 1 5 4 2 7 6]
 [1 6 8 8 0 4 4 5 2 3]
 [9 8 0 2 4 3 1 6 7 5]
 [5 2 4 3 1 9 6 8 7 0]
 [4 7 1 0 0 3 3 8 2 6]]
tt_50sample [[5 3 7 1 6 0 2 8 9 4]
 [6 7 9 1 8 4 0 5 2 3]
 [4 5 0 1 9 8 7 2 3 6]
 [4 1 5 7 8 3 9 2 0 6]
 [8 6 1 7 2 5 0 4 9 3]
 [9 0 8 3 1 5 4 2 7 6]
 [1 6 8 7 0 9 4 5 2 3]
 [9 8 0 2 4 3 1 6 7 5]
 [5 2 4 3 1 9 6 8 7 0]
 [4 7 1 0 5 9 3 8 2 6]]
vm  [-0.3 -0.5  7.1 -1.  -1.7  0.2 -0.3  0.3 -0.3 -0.6  7.4 -0.4  0.2 -0.3 10.5 -0.1 -0.6 -0.3  1.3  2.2 -1.1 -0.  -0.4 -0.  -1.2  3.7 -0.4  0.2 -1.3 -1.3  1.7 -0.2  0.4  9.1  0.2 -0.2  1.7  0.8 -2.8 -0.7 -0.4 -1.5 -0.5 -0.6 -0.  -0.3 -1.9 -0.6  1.9 -1.2 -0.6 -0.1 -0.5  9.3  1.1 -0.8 -0.8 -0.4  4.2 -0.1  4.4  0.1 -0.4  2.1  0.6 -0.1 -0.2 -0.2  3.  -0.1 -0.3  3.3 -0.2 -0.2 -4.1 -0.2 -0.6  0.2 -0.2  0.3 -0.6 -0.   0.2  0.6 -0.5 -1.4 -0.1 -0.1 -0.4 -0.1 -0.2 -0.2 -0.4 -0.5 -0.6 -0.   0.5 -2.7 -0.6 -0.4  2.3  5.2 -0.5 -0.2 -0.  -0.2 -2.5  1.1  1.5  1.7 -0.6 -0.  -0.1 -0.5  4.7 -1.3 -0.4  1.3 -0.2 -0.  -0.1 -0.6  0.3  0.2 -0.3 12.1 -0.5 -2.1  0.8  6.   1.8 -0.7 -0.2 -0.8 -1.   9.4 -0.2  0.  -0.2 -0.3 -0.5 -1.1 -0.4  0.  -0.1 -0.1 -0.3 -0.1 -2.6 -0.3 -0.1 -0.4 -0.1 -0.1 -0.2 -0.   0.5 -0.5 -0.8 -0.7  0.9  0.5 -0.1  0.2 -0.2 -0.8 -0.3  1.3 -0.1 -0.2 -0.3 -0.4  0.3 -0.  -0.1  5.5 -0.9 -0.5  5.9 -0.1  0.7 -0.4 -0.2 -1.6 -0.1  0.3  0.3 -0.5  0.3  3.3 -0.2 -0.5 -0.2 -0.8 -1.1 -0.5 -1.5 -1.2 -0.1  0.4 -0.2 -0.3 -0.6 -0.6 -0.2 -3.5 -0.1 -0.2  3.6 -0.2 -0.5 -1.2 -0.9 -0.  -0.7 -0.2  4.1 -1.   0.7 -0.3 -0.3 -0.3 -0.4 -1.2  2.4 -1.2  0.   1.1 -0.2  3.1 -0.5  0.3 -0.1  1.9  3.7 -1.7  2.8 -1.2  1.6  1.3 -0.2  1.  -0.2  0.3  4.2  4.6 -0.  -0.  -0.9 -0.3  1.2 -0.1 -1.8 -0.1 -0.1 -1.5]
vy_50sample [[7 0 2 6 3 1 4 8 5 9]
 [9 3 0 4 7 2 5 6 8 1]
 [1 6 6 3 3 7 5 5 4 2]
 [2 3 9 5 4 8 0 1 7 6]
 [4 7 6 5 9 0 3 1 2 8]
 [0 9 5 5 1 3 6 2 7 4]
 [5 6 4 0 9 8 1 7 2 2]
 [0 5 9 3 4 2 1 6 8 7]
 [2 2 4 3 6 5 5 8 1 0]
 [5 6 3 4 8 0 9 2 7 1]]
vt_50sample [[7 0 2 6 3 1 4 8 5 9]
 [9 3 0 4 7 2 5 6 8 1]
 [9 1 6 3 7 0 8 5 4 2]
 [3 2 9 5 4 8 0 1 7 6]
 [4 7 6 5 9 0 3 1 2 8]
 [0 9 5 1 8 3 6 2 7 4]
 [5 6 4 9 0 8 1 7 3 2]
 [0 5 9 3 4 2 1 6 8 7]
 [2 9 4 3 6 7 5 8 1 0]
 [5 6 3 4 8 0 9 2 7 1]]
Epoch 28310: Training cost= 0.2876, Training acc= 0.8354, Validation cost= 0.3024, Validation acc= 0.8355
Epoch 28320: Training cost= 0.2795, Training acc= 0.8354, Validation cost= 0.2664, Validation acc= 0.8355
Epoch 28330: Training cost= 0.2660, Training acc= 0.8354, Validation cost= 0.2411, Validation acc= 0.8355
Epoch 28340: Training cost= 0.3084, Training acc= 0.8354, Validation cost= 0.3033, Validation acc= 0.8356
Epoch 28350: Training cost= 0.2253, Training acc= 0.8354, Validation cost= 0.2818, Validation acc= 0.8356
Epoch 28360: Training cost= 0.2611, Training acc= 0.8355, Validation cost= 0.2886, Validation acc= 0.8356
Epoch 28370: Training cost= 0.2868, Training acc= 0.8355, Validation cost= 0.2797, Validation acc= 0.8356
Epoch 28380: Training cost= 0.2876, Training acc= 0.8355, Validation cost= 0.2966, Validation acc= 0.8356
Epoch 28390: Training cost= 0.2847, Training acc= 0.8355, Validation cost= 0.3570, Validation acc= 0.8357
Epoch 28400: Training cost= 0.2835, Training acc= 0.8355, Validation cost= 0.2967, Validation acc= 0.8357
tm  [-0.5  1.8  2.9 -0.7 -0.8  0.  -0.2 -0.2 -1.  -1.3 -0.8 -0.3 -0.1  0.5  5.3  7.3 -0.1 -0.2  0.2  1.2 -0.5 -0.3  1.1 -0.  -1.1 -0.6 -0.1 -0.1  0.4 -0.3 -1.7  0.1  0.6 -3.8 -0.4  0.4  1.8  1.7 -3.4 -0.6 -0.1 -1.8  1.1 -0.7 -0.1 -0.1 -2.1 -0.7 -0.1  1.6 -0.8 -0.2 -0.9 10.8 -1.4 -0.4 -0.7  4.5 -0.5  6.6  5.  -0.4 -0.5  0.6 -0.6 -0.3  0.1 -0.2 -0.2 -0.3 -0.1 -1.3 -0.4 -0.4 -5.  -0.4 -0.6 -0.6 -0.3  0.2 -5.9 -0.5 -0.4  0.5 -0.7 -1.3 -0.5 -0.2 -0.1 -0.1 -0.6  0.3 -0.2  3.5 -0.1 -0.1 -0.2 -2.4  0.3  0.1  5.4 -2.4 -0.5 -0.   0.1 -0.8 -2.8 -1.5 -0.3  2.1 -0.4 -0.3 -0.1 -0.6 -1.   9.  -0.4 -0.7 -0.3 -0.4 -0.4 -1.  -0.5 -0.4 -0.4  5.8  0.1 -2.9 -0.3 13.   0.4 -0.8  0.6 -0.4  7.6 -1.4 -0.  -0.1 -0.2  0.3 -1.1 -0.3 -1.2 -0.1  0.1 -0.1 -0.6  0.2  4.1 -0.1 -0.4 -0.1  3.3 -0.9 -0.2 -0.  -0.1 -0.3 -1.  -0.6 -0.8  0.4 -0.7 -0.1 -0.3  0.  -0.1  0.1  0.3  0.1  0.3  0.1 -0.2  0.2 -0.2 -0.7 -1.3 -0.9  6.1 -0.5 -1.2 -0.2 -0.1 -1.4 -0.6 -0.2 -0.1 -0.5 -0.3  0.8 -0.1 -0.1  0.1 -0.9 -1.3  0.3 -1.7  2.4 -0.2 -0.1 -0.  -0.3 -0.2 -0.6 -0.3 -4.4 -0.4 -0.3  5.5 -0.3 -0.3  1.8 -0.7 -0.  -0.2 -0.5  4.6 -0.4 -0.6 -0.  -0.1 -0.2 -0.3 -1.3 -0.7  4.9  1.4  0.4 -0.7  2.1 -0.6  2.7 -0.3  3.3 -0.9 -0.2 -0.  -2.   0.1 -3.6 -0.3 -1.6 -0.1 -0.1 18.1  7.2 -0.2  1.3 -0.6 -0.1 15.5 -0.3 -2.4 -0.2  1.7 -3.4]
ty_50sample [[8 3 2 6 5 1 7 4 0 9]
 [6 9 4 0 8 7 2 3 1 5]
 [3 8 5 4 6 7 2 9 0 1]
 [6 8 0 1 2 7 4 5 9 3]
 [5 4 8 0 1 6 3 2 2 7]
 [9 3 1 8 6 7 2 4 5 0]
 [3 1 6 6 2 4 8 0 7 9]
 [2 5 1 6 8 4 0 7 7 3]
 [6 5 2 1 4 9 0 7 8 3]
 [6 4 4 8 0 2 7 9 3 5]]
tt_50sample [[8 3 2 6 5 1 7 4 0 9]
 [6 9 4 0 8 7 2 3 1 5]
 [3 8 5 6 4 7 2 9 0 1]
 [6 8 0 1 2 7 4 5 9 3]
 [5 4 8 0 1 6 3 9 2 7]
 [9 3 1 8 6 7 2 4 5 0]
 [3 1 6 5 2 4 8 0 7 9]
 [2 5 1 6 8 4 0 9 7 3]
 [6 5 2 1 4 0 9 8 7 3]
 [6 1 4 8 0 2 7 9 3 5]]
vm  [ 0.3  2.4  6.  20.  -0.9 -0.1  0.3 -0.2 -0.8 -0.6  5.5  0.8 -0.5 -0.5 -2.2  5.1 -0.2 -0.1  0.2 -1.5 -0.8  0.9 -0.7 -0.  -0.6  0.4 -0.4 -0.2  0.7 -0.1 -0.9 -0.5  3.3  0.5 -0.5 -0.2  1.8  0.5  3.6 -0.3  0.4 -3.4 -0.  -1.6 -0.2 -0.4 11.3 -0.5  1.6 -2.4 -0.6 -0.2  1.6 -1.  -1.5  3.2 -0.   1.7 -1.1  4.7 -2.1 -0.   0.4 -0.6  0.4 -0.9  0.  -0.1 -0.  -0.2 -0.1 -0.9  0.4 -0.4  4.4  1.6 -0.4 -0.1 -0.6 -0.4 14.9 -0.2 -0.4 -0.2 -1.4 -3.1 -0.3 -0.4 -0.1  0.5 -0.3 -0.2  0.4  2.6 -0.4 -0.4 -0.2  2.2 -0.6 -0.2  3.2 -1.9 -0.9 -0.1 -0.5 -0.3  0.5 -0.6  1.6 -2.  -0.1 -0.4 -0.3 -0.3 -0.9  4.2  2.6 -0.9 -0.   0.9 -0.1  6.6 -0.2 -0.2 -0.  -2.7 -0.1  4.9 -1.4  1.5  0.1 -0.3  0.5 -0.1  6.9  8.9  0.  -0.1  0.4 -0.7 -1.1 -0.1 -0.8 -0.1 -0.1 -0.  -0.2 -0.2 -1.  -0.2 -1.8 -0.2  2.8 -0.4 -0.2 -0.2 -0.6  0.8 -0.9 -0.7 -0.3  0.2  0.1 -0.2 -0.1 -0.1 -0.3 -0.3 -0.4 -0.1 -0.2 -0.4 -0.   0.4 -0.   2.2 -1.7 -0.  -0.2 -0.2  1.8 -0.1  1.  -1.  -0.6 -0.2  2.8 -0.3 -0.2  1.4 -0.3 -0.2 -0.7 -1.  12.7  4.   2.9  0.9  0.  -0.2  0.3 -0.1 -0.2  0.1 -0.6  6.9 -0.1 -0.3  5.7 -0.5 -0.4  2.7 -0.5 -0.5  0.8  0.8  6.5 -0.5 -0.2  1.  -0.  -0.3  0.7 -0.6 -0.6  1.8 -0.3  0.2  0.4  1.3  0.3 -0.2  0.2  3.5 -1.3 -1.1 -0.1  2.2 -0.6 21.3 -0.2  8.7 -0.3 -0.3 -2.9 -3.4 -0.1 -0.2 -0.4 -0.3 -3.9 -0.1  2.5 -0.1  2.5  0.6]
vy_50sample [[9 3 6 2 8 7 1 0 5 4]
 [9 3 7 0 6 5 4 2 1 8]
 [4 8 5 3 1 9 9 2 7 6]
 [0 9 6 4 7 3 5 5 8 1]
 [3 6 4 5 8 7 0 1 2 9]
 [8 5 2 1 1 3 7 4 9 6]
 [1 7 5 4 9 6 2 0 8 3]
 [4 3 9 8 6 2 0 5 1 7]
 [5 7 1 0 3 4 6 9 2 8]
 [6 4 3 7 9 8 2 5 0 1]]
vt_50sample [[9 3 6 2 8 7 0 1 5 4]
 [9 3 7 0 6 5 4 2 1 8]
 [4 8 5 3 1 0 9 2 7 6]
 [0 9 6 4 7 3 2 5 8 1]
 [3 6 4 5 8 7 0 1 2 9]
 [8 5 2 0 1 3 7 4 9 6]
 [1 7 5 4 9 6 2 0 8 3]
 [4 9 3 8 6 2 0 5 1 7]
 [5 7 1 0 3 4 6 9 8 2]
 [6 4 3 7 9 8 2 5 0 1]]
Epoch 28410: Training cost= 0.3029, Training acc= 0.8355, Validation cost= 0.3007, Validation acc= 0.8357
Epoch 28420: Training cost= 0.2415, Training acc= 0.8356, Validation cost= 0.3298, Validation acc= 0.8357
Epoch 28430: Training cost= 0.2425, Training acc= 0.8356, Validation cost= 0.2316, Validation acc= 0.8357
Epoch 28440: Training cost= 0.3265, Training acc= 0.8356, Validation cost= 0.3206, Validation acc= 0.8357
Epoch 28450: Training cost= 0.3303, Training acc= 0.8356, Validation cost= 0.2642, Validation acc= 0.8358
Epoch 28460: Training cost= 0.2781, Training acc= 0.8356, Validation cost= 0.2608, Validation acc= 0.8358
Epoch 28470: Training cost= 0.2397, Training acc= 0.8357, Validation cost= 0.2312, Validation acc= 0.8358
Epoch 28480: Training cost= 0.2400, Training acc= 0.8357, Validation cost= 0.2594, Validation acc= 0.8358
Epoch 28490: Training cost= 0.3226, Training acc= 0.8357, Validation cost= 0.1988, Validation acc= 0.8358
Epoch 28500: Training cost= 0.2971, Training acc= 0.8357, Validation cost= 0.2642, Validation acc= 0.8359
tm  [-1.  -0.1  4.  -0.3 -1.4 -0.1 -0.3 -0.  -0.2 -1.   5.9 -0.4  0.6 -0.2  5.6  6.9 -0.5 -0.3  1.5  0.2 -0.8 -0.1  2.2 -0.4 -1.4  2.5 -0.4 -0.1  1.1 -0.1  0.9 -0.3 -0.2  5.1 -0.4  0.   1.6  2.1 -0.9 -0.7 -0.2 -0.5 -0.2  0.4 -0.2  0.  -0.8 -0.9 -0.3  5.1 -0.7 -0.1 -0.3  5.8 -1.2 -0.2 -0.6 -0.7  2.7  1.   4.1  0.1 -0.5  1.9  0.3  1.  -0.2 -0.2  1.8  0.1  0.6 -1.2  0.9  1.2 -1.9  0.5 -0.5 -0.3 -0.1  1.1 -0.4 -0.5  0.3  1.1  0.9  0.4 -0.5 -0.2 -0.3 -0.3 -0.4 -0.1 -0.3 -1.2 -0.5  0.1  0.1 -2.3 -0.6 -0.   3.7  6.5 -0.1  0.4  0.1  0.5 -1.1  0.5  1.9 -0.4 -0.8 -0.4 -0.1 -0.6 -0.2 10.9 -0.1 -0.7 -0.1 -0.1 -0.1  1.5  0.1  0.7  0.3  5.8 -0.1 -1.2  1.2  0.1 -0.  -0.9 -0.3 -1.  -1.   3.8 -0.1  0.  -0.2 -0.4 -0.7 -0.4 -0.5 -0.1 -0.2  0.  -0.2 -0.2 -1.8 -0.1  0.3 -0.2 -0.  -0.3  0.6 -0.2 -0.1 -0.4 -0.1 -0.3  0.7  0.6 -0.   0.2 -0.4 -0.9 -0.   2.3 -0.3 -0.1 -0.2 -0.2  0.2 -0.2 -0.1  3.2 -0.7 -0.1  2.7 -0.2  0.2 -0.2 -0.3 -1.6 -0.5 -0.  -0.2 -0.6 -0.2  0.9 -0.2 -0.3 -0.4 -0.6 -0.8 -0.4 -0.4 -0.1 -0.2  0.  -0.1 -0.2 -0.4 -0.8  0.  -2.   0.1  0.5  4.5 -0.3 -0.1  4.1 -0.9  4.7 -0.9 -0.3  1.9 -0.5  0.  -0.1 -0.3 -0.1 -0.4 -1.2  3.4  3.7  1.5  2.7  1.5  1.4 -0.3 -0.5  0.1  2.7 -0.1 -0.7  0.6 -0.3  2.   5.  -0.2  2.2  0.1 -0.2  3.6  0.4 -0.1  1.7 -1.1 -0.3  0.5 -0.2 -0.5 -0.1 -1.1  3.2]
ty_50sample [[2 2 1 6 4 8 9 3 5 0]
 [2 1 0 7 4 5 6 9 3 8]
 [3 6 5 7 1 9 4 2 2 0]
 [2 6 3 1 7 4 8 5 9 0]
 [0 1 4 7 6 8 5 3 9 2]
 [8 2 9 7 7 6 4 0 3 5]
 [2 4 9 9 3 5 7 7 6 1]
 [0 1 5 8 3 9 4 7 6 2]
 [5 9 7 6 8 3 1 2 0 4]
 [2 3 1 9 8 6 5 7 4 0]]
tt_50sample [[7 2 1 6 4 8 9 3 5 0]
 [2 1 0 7 4 5 6 9 3 8]
 [3 6 5 7 1 9 4 2 8 0]
 [2 6 3 1 7 4 8 5 9 0]
 [0 1 4 7 6 8 5 3 9 2]
 [8 2 9 7 1 6 4 0 3 5]
 [2 4 9 8 0 3 5 7 6 1]
 [0 1 5 8 3 9 4 7 6 2]
 [5 9 7 6 8 3 1 2 0 4]
 [2 3 1 9 8 6 5 7 4 0]]
vm  [ 0.9 -1.2  1.4 -3.5 -1.6 -0.2 -0.3 -0.2  4.5  0.5  6.  -0.2 -0.5 -0.2 11.3 -0.2 -0.7 -0.3 -0.3 -0.1 -1.4 -0.  -0.8 -0.2 -0.6 -0.3 -0.5  1.1 -0.2 -1.9  6.  -0.6  0.1 12.7 -0.3 -0.4 -1.2  2.   1.1 -0.6  0.2 -2.4 -1.9  4.5 -0.6 -0.2 -0.5 -0.3  1.9 -3.  -0.7 -0.1 -0.2  2.4 -1.1 -1.1 -0.6 -2.6  9.8 -2.5  0.8 -0.4  0.1 -0.   4.4 -0.7 -0.4  2.1  2.2 -0.9 -0.2 -1.  -0.3 -0.8 -5.   0.1 -1.3  0.2 -0.2  0.4  2.7 -0.1 -0.   3.8 -1.1 -2.3  4.6 -0.  -0.6 -0.4 -0.1 -0.4 -0.3 -1.9 -0.4 -0.2 -0.6 -2.7 -0.3 -0.3 -0.2  2.8 -1.2 -0.1 -0.2 -0.2 -3.   4.7  1.9  1.   2.  -0.3 -0.3 -1.5  6.2  1.   0.1  5.8 -0.3  0.1 -0.6 -1.3 -0.1  0.2 -0.1 12.6 -0.3 -0.1  7.6  7.9  1.3 -1.1  0.4 -0.5 -5.1  2.9  0.8 -0.2 -0.3 -0.9 -0.3 -0.4 -0.3 -0.2 -0.2 -0.2 -0.1 -0.  -2.8 -0.2  1.4 -0.3  0.6  0.4  0.8 -0.2 -0.3 -0.3  0.2 -0.3 -0.2 -1.8 -0.1 -0.3  0.3 -0.1 -0.6  4.8 -0.6 -0.1 -0.3 -0.2 -0.2 -0.3 -0.3  6.1 -0.6 -1.   0.5  0.4  2.1 -0.8 -0.2 -1.6 -0.5 -0.2  2.5 -0.6 -0.1  5.4 -0.1 -0.3 -0.6 -0.6  1.1 -2.6 -1.7 -1.9 -0.2 -0.2 -0.3 -0.5 -0.5 -0.7 -0.4 -3.   0.3  0.3  1.7  0.3 -0.6  2.2 -1.1 -1.1 -0.2  0.  -1.7 -0.9 -0.3  1.  -0.5 -0.3 -0.4 -1.2 -1.2  0.1 -1.4 -0.  -1.   6.3 -1.1  1.6 -0.2  0.9 -0.9  0.9  2.5 -1.9  2.6  3.3 -0.2  1.6 -0.  -0.2 -0.1  0.6 -0.1 -0.2 -0.9 -0.2 -0.8 -0.   1.6 -0.2  3.7 -2.1]
vy_50sample [[7 4 3 0 2 2 6 6 5 8]
 [8 1 9 7 2 0 6 3 4 5]
 [8 9 0 4 7 6 3 2 1 5]
 [4 9 0 1 3 5 2 6 8 7]
 [8 7 7 4 5 2 0 6 3 9]
 [4 9 3 6 7 2 0 8 1 5]
 [0 8 6 2 7 1 5 3 4 9]
 [0 1 4 2 7 6 9 3 8 5]
 [0 3 6 6 4 4 5 7 9 2]
 [4 3 1 6 9 7 0 8 2 5]]
vt_50sample [[4 7 3 0 2 1 9 6 5 8]
 [8 1 9 7 2 0 6 3 4 5]
 [8 9 0 4 7 6 3 2 1 5]
 [4 9 0 1 3 5 2 6 8 7]
 [8 1 7 4 5 2 0 6 3 9]
 [4 9 3 6 7 2 0 8 1 5]
 [0 8 6 2 7 1 5 3 4 9]
 [0 1 4 2 7 6 9 3 8 5]
 [0 3 8 6 4 1 5 9 7 2]
 [4 3 1 6 9 7 0 8 2 5]]
Epoch 28510: Training cost= 0.2671, Training acc= 0.8357, Validation cost= 0.2922, Validation acc= 0.8359
Epoch 28520: Training cost= 0.2675, Training acc= 0.8358, Validation cost= 0.3046, Validation acc= 0.8359
Epoch 28530: Training cost= 0.2878, Training acc= 0.8358, Validation cost= 0.3244, Validation acc= 0.8359
Epoch 28540: Training cost= 0.2758, Training acc= 0.8358, Validation cost= 0.2527, Validation acc= 0.8359
Epoch 28550: Training cost= 0.3335, Training acc= 0.8358, Validation cost= 0.3643, Validation acc= 0.8360
Epoch 28560: Training cost= 0.2614, Training acc= 0.8358, Validation cost= 0.3016, Validation acc= 0.8360
Epoch 28570: Training cost= 0.2995, Training acc= 0.8358, Validation cost= 0.2743, Validation acc= 0.8360
Epoch 28580: Training cost= 0.2998, Training acc= 0.8359, Validation cost= 0.2887, Validation acc= 0.8360
Epoch 28590: Training cost= 0.2949, Training acc= 0.8359, Validation cost= 0.2987, Validation acc= 0.8360
Epoch 28600: Training cost= 0.2884, Training acc= 0.8359, Validation cost= 0.3164, Validation acc= 0.8360
tm  [-1.4 -0.7  5.   0.1 -2.  -0.2 -0.4 -0.2  2.1 -0.8  4.  -0.2 -0.2 -0.1  6.5  2.1 -0.5 -0.5  0.1 -0.1 -0.9 -0.  -0.4 -0.4 -1.2  1.7 -0.1 -0.2  1.8 -2.2  2.4 -0.1 -0.   9.2 -0.6 -0.2 -0.6  1.2  3.9 -0.7  1.6  0.6 -0.5  3.   0.4  0.1 -0.4 -0.  -1.  -1.4 -0.7  0.1 -0.1  0.9 -1.2 -0.6 -0.6  3.7  6.2 -0.6  5.7 -0.2  0.   0.2  1.9 -0.2 -0.4 -0.1  2.5 -0.1  0.1 -1.9 -0.2 -0.  -3.3 -0.1 -0.5  0.2 -0.2 -0.1  4.1 -0.2 -0.1  0.7  0.7  2.1 -0.9 -0.  -0.2 -0.7 -0.5  0.5 -0.1 -1.5 -0.5  0.2  0.1 -2.5 -0.4 -0.3  2.7  4.4  0.8 -0.1  0.2 -0.3 -1.6  2.   1.9 -0.4 -0.5 -0.5 -0.4 -1.2  2.1 10.9  0.7  1.1 -0.1 -0.2 -0.3  0.3 -0.1 -0.3 -0.2  7.7 -0.   2.   8.3  3.3 -0.9 -0.8 -0.6 -0.7 -4.7  0.3 -0.  -0.2 -0.8 -0.4  1.3 -0.2  1.6 -0.4 -0.2 -0.2 -0.2 -0.  -0.5 -0.3  0.1 -0.1 -1.3  0.7  0.5 -0.3 -0.1 -0.6  3.3 -0.5 -0.5 -1.6 -0.3  0.1 -0.4 -0.7 -0.2  1.8 -0.4 -0.  -0.4 -0.2 -0.1 -0.3  0.2  0.8 -0.4 -0.4 -0.1 -0.  -1.2 -0.3 -0.4 -1.4 -0.6 -0.2 -0.6 -0.5 -0.4  5.1 -0.2 -0.1 -0.6 -0.8 -1.6 -2.3 -0.7 -0.7  0.6 -0.1 -0.5 -0.3 -0.3 -0.5 -0.3 -2.3 -0.1 -0.2 -2.2 -0.4 -0.6  5.3 -0.5  4.7 -1.1 -0.1 -0.8 -0.5 -0.3 -0.4 -0.6 -0.1 -0.2 -1.  -1.3  2.5 -1.6 -0.2 -0.3  2.  -0.5 -0.3 -0.2 -1.5 -0.7 -1.  -0.1 -0.6  2.8 -1.4 -0.1 -0.6 -0.1 -0.  -0.2  0.  -0.2 -0.1 -0.9 -0.1 -1.2 -0.2  2.7 -0.2  3.5 -0.4]
ty_50sample [[1 7 5 3 4 9 2 8 6 0]
 [6 2 3 7 5 1 9 0 8 4]
 [7 6 4 5 0 3 3 9 9 2]
 [7 4 4 1 2 3 6 9 5 0]
 [1 8 7 5 6 4 9 2 0 0]
 [2 9 5 3 7 0 8 4 1 6]
 [3 6 2 7 0 0 5 8 9 4]
 [1 0 2 2 4 3 3 8 5 9]
 [0 7 6 5 3 1 1 4 9 2]
 [1 0 2 6 7 4 8 3 3 9]]
tt_50sample [[1 7 5 3 4 9 2 8 6 0]
 [6 2 3 7 5 1 9 0 8 4]
 [7 6 4 5 0 3 1 8 9 2]
 [7 8 4 1 2 3 6 9 5 0]
 [1 8 7 5 6 4 9 2 3 0]
 [2 9 5 3 7 0 8 4 1 6]
 [3 2 6 7 0 1 5 8 9 4]
 [1 0 2 7 4 3 6 8 5 9]
 [0 7 6 5 3 1 8 4 9 2]
 [1 0 2 6 7 4 8 3 5 9]]
vm  [-0.5  0.7  2.9 -0.1 -1.9 -0.4 -0.4 -0.2 -0.9 -1.1 -1.  -0.3 -0.2 -0.2  4.4 -0.6 -0.8  0.3  0.5 -0.4 -1.1 -0.  -0.1  0.3 -1.1  3.3 -0.3 -0.7 -0.7  1.   3.3 -0.1 -0.3  8.5 -0.3  0.9  3.3  0.2  5.8 -0.7  0.5 -1.6  1.   4.  -0.5  0.5  1.2 -0.   1.3 -0.6 -0.9 -0.3  0.8 -1.  -0.4 -0.3 -0.7 -2.  -0.5 -0.8  0.7 -0.2 -0.4  0.5 -0.  -0.1 -0.3 -0.2  2.4 -0.1  0.5  0.3  0.4  1.3 -0.6 -0.5 -0.4 -0.6  1.2  0.   4.5  0.1  1.   0.4 -0.1 -1.4  3.6 -0.1 -0.3 -0.8  0.7 -0.1 -0.  -0.3 -0.2  0.8 -0.7 -1.6 -0.4 -0.2  4.4  4.7 -0.1  0.  -0.   0.7 -0.3  3.7 -0.2 -0.7 -0.6 -0.5 -0.  -0.3  0.3  1.6  0.4 -0.8 -0.3 -0.2  0.2  3.7 -0.   0.2 -0.3  5.3 -0.   6.6 -0.1  1.1 -0.1 -0.1  0.5 -0.7 -4.1 -0.5 -0.1 -0.1 -0.1 -0.4  3.4 -0.9  1.3  0.3 -0.1 -0.1 -0.3 -0.1 -2.3 -0.1  0.3 -0.1  0.1  0.9  0.6 -0.2  0.8 -0.5  2.7 -0.3 -0.3 -0.9  0.1 -0.1 -0.5 -0.8  0.9  1.5  0.6 -0.2 -0.5 -0.4 -0.2 -0.  -0.3  4.8 -0.2  0.3 -0.5  0.2  1.  -0.7 -0.5 -1.5 -0.3  1.   1.2 -0.4 -0.4 -0.3 -0.2 -0.2 -0.4 -0.9  2.2  1.1  0.9  0.4 -0.1  0.3 -0.3 -0.4 -0.8 -0.4 -0.2 -0.8 -0.  -0.1  3.6 -0.5 -0.1  0.3 -1.3  3.1 -0.7 -0.8 -1.2 -0.8 -0.2  1.  -0.4  0.2 -0.2 -0.5 -0.9 -0.1 -1.3 -0.1 -0.   0.6 -0.2 -1.  -0.3  2.5  2.3 -0.1  0.8  1.2  3.7  7.7  0.3  3.4 -0.2  0.1 -0.5 -1.   0.5  1.5 -0.9 -0.4 -1.4  0.4  4.3 -0.2  5.8  1.7]
vy_50sample [[7 4 9 3 0 1 8 6 6 2]
 [2 8 4 5 7 9 6 1 0 3]
 [9 6 3 7 8 2 5 1 4 0]
 [3 5 7 2 8 1 9 0 4 6]
 [4 6 3 7 0 2 5 9 8 1]
 [5 8 4 2 3 0 0 9 6 7]
 [7 9 8 2 4 5 3 0 6 1]
 [8 1 3 0 9 4 2 7 5 6]
 [6 2 4 3 0 7 1 8 9 5]
 [9 3 6 4 5 8 7 1 2 0]]
vt_50sample [[7 4 9 3 1 0 8 6 5 2]
 [2 8 4 5 7 9 6 1 0 3]
 [9 6 3 7 8 2 5 1 4 0]
 [3 5 2 7 1 8 9 0 4 6]
 [4 6 3 7 0 2 5 9 8 1]
 [5 8 4 2 3 1 0 9 6 7]
 [7 9 8 4 2 5 3 0 6 1]
 [1 8 3 0 9 4 2 7 5 6]
 [6 2 4 3 7 0 1 8 9 5]
 [9 3 6 4 5 8 7 1 2 0]]
Epoch 28610: Training cost= 0.2846, Training acc= 0.8359, Validation cost= 0.2839, Validation acc= 0.8361
Epoch 28620: Training cost= 0.2787, Training acc= 0.8359, Validation cost= 0.2372, Validation acc= 0.8361
Epoch 28630: Training cost= 0.2601, Training acc= 0.8359, Validation cost= 0.2725, Validation acc= 0.8361
Epoch 28640: Training cost= 0.2590, Training acc= 0.8360, Validation cost= 0.2735, Validation acc= 0.8361
Epoch 28650: Training cost= 0.3914, Training acc= 0.8360, Validation cost= 0.3009, Validation acc= 0.8361
Epoch 28660: Training cost= 0.2928, Training acc= 0.8360, Validation cost= 0.3256, Validation acc= 0.8361
Epoch 28670: Training cost= 0.3042, Training acc= 0.8360, Validation cost= 0.2550, Validation acc= 0.8362
Epoch 28680: Training cost= 0.3005, Training acc= 0.8360, Validation cost= 0.2965, Validation acc= 0.8362
Epoch 28690: Training cost= 0.2804, Training acc= 0.8360, Validation cost= 0.3192, Validation acc= 0.8362
Epoch 28700: Training cost= 0.3083, Training acc= 0.8361, Validation cost= 0.3027, Validation acc= 0.8362
tm  [ 0.2 -0.6 -0.8 -0.1 -1.  -0.2 -0.3 -0.2 -0.  -0.4 -5.1 -0.2 -0.3 -0.  -0.3 -1.4 -0.4 -0.8 -0.2 -0.3 -0.9 -0.3 -0.1 -0.3 -0.5 -0.1 -0.4 -0.3 -0.9 -2.2 -1.1 -0.2 -0.1 -4.2 -0.3 -0.4 -0.1 -1.5 -2.1 -0.7 -0.2 -1.4 -0.6 -0.5 -0.4  0.1 -0.8  0.7  2.7 -0.  -0.6 -0.2 -0.7 -0.5 -0.4  0.4 -0.7  2.4  5.2  4.1  0.8 -0.3 -0.9  0.4 -0.7 -0.2 -0.3 -0.3  1.6  0.1 -0.1  0.8 -0.2 -0.3 -3.9 -0.1 -1.  -0.1 -0.2 -0.2 -3.9 -0.1 -0.5  2.  -1.  -1.4  1.7 -0.  -0.5 -0.5 -0.4  0.1 -0.2 -0.4 -0.4 -0.   0.1 -2.6 -0.2 -0.4  1.6 -2.5 -0.6  0.1 -0.  -0.1 -2.2 -0.9 -1.7 -0.3 -0.2 -0.2 -0.1 -0.7  4.3 -0.4 -0.3  3.6 -0.3 -0.  -0.5  1.3 -0.3 -0.6 -0.6 -0.2 -0.2  4.5  6.   9.4  2.2 -0.9  0.8 -0.7 10.2 -0.4 -0.3 -0.1 -0.   0.1  1.8 -0.7  1.3 -0.2 -0.1 -0.2 -0.4 -0.1  4.6 -0.  -0.1 -0.1  4.2 -0.2 -0.3  0.4  0.  -0.3 -1.1 -0.6 -0.3  0.4 -0.2 -0.3 -0.3 -0.  -0.1  1.   0.1 -0.1 -0.4 -0.  -0.2  0.2 -0.3 -0.7 -1.1 -0.9  4.7 -0.1 -1.2 -0.5 -0.6 -1.4 -0.2  0.6  1.4  0.7 -0.4  6.2 -0.2 -0.1 -0.6 -0.7  1.1 -1.8 -1.3 -1.1 -0.1 -0.2 -0.4 -0.3 -0.3 -0.6 -0.1 -3.6 -0.5 -0.1  5.2 -0.2 -0.5 -0.3 -1.1 -1.1 -0.6 -0.6  3.3 -0.5 -0.3 -0.2 -0.5 -0.1 -0.3 -1.4 -0.4  0.9 -1.7 -0.2 -0.7  6.3 -0.6  0.5 -0.1  2.5  1.7  2.   1.6 -1.1  3.4 -1.7 -0.  -0.9 -0.1 -0.1 12.8  3.8  0.8 -0.2 -1.1 -0.2 10.  -0.2 -1.5 -0.5  8.  -2.4]
ty_50sample [[3 8 0 6 5 4 9 1 7 2]
 [4 5 3 1 0 8 2 7 6 9]
 [8 7 3 5 2 4 0 9 6 1]
 [8 7 4 4 1 9 2 6 3 5]
 [6 3 2 8 5 4 7 1 1 0]
 [2 9 5 8 0 7 3 6 1 4]
 [6 2 8 5 7 3 1 9 0 4]
 [2 9 7 1 8 0 0 3 5 4]
 [8 3 5 6 0 9 7 2 1 4]
 [6 8 2 0 5 1 7 4 3 9]]
tt_50sample [[3 8 0 6 5 4 9 1 7 2]
 [4 5 3 1 0 8 2 7 6 9]
 [8 7 3 5 2 4 0 9 6 1]
 [8 7 4 1 0 9 2 6 3 5]
 [6 3 2 8 5 4 7 9 1 0]
 [2 9 5 8 0 7 3 6 1 4]
 [6 2 8 5 7 3 9 1 0 4]
 [9 2 7 1 8 6 0 3 5 4]
 [8 3 5 6 0 9 7 2 1 4]
 [6 8 2 0 5 1 7 3 4 9]]
vm  [ 0.9 -0.5 -0.8  8.1 -0.6 -0.1 -0.3 -0.1 -0.1 -0.1 -0.7 -0.9 -0.  -0.1 -1.9  5.1  0.4 -0.5 -0.4 -1.2 -0.5  0.   1.5 -0.2 -0.5  1.  -0.1 -0.1 -0.2 -0.4 -1.2 -0.6 -0.4 -4.4  0.3 -0.2  0.7  3.4  5.8 -0.5 -0.   5.5  0.5  0.  -0.1 -0.2  4.6 -0.7  4.3 13.5 -0.3 -0.3 -0.5  1.5 -0.5  3.  -0.1  3.9  2.   4.3 -1.4 -0.2 -0.4  0.7 -1.3 -0.3 -0.1 -0.2 -0.2  0.7 -0.3 -0.2 -0.1  0.8 -0.6  1.4 -0.6 -0.1 -0.3 -0.1 -1.   0.3 -0.1  0.1 -1.3  7.3  2.3 -0.  -0.2 -0.1 -0.  -0.2 -0.3 -0.8 -0.4  0.   0.9 -1.4 -0.1 -0.2 -0.   3.  -0.8 -0.1 -0.2  0.1 -0.2 -1.1 -0.3 -1.7 -0.4 -0.1 -0.  -0.3 -0.   3.7 -0.4 -0.5 -0.  -0.4 -0.1  6.7 -0.  -0.7  0.1 -2.4 -0.4  0.4  1.9 -2.   1.8 -0.7  0.4 -0.7  6.8 -2.7 -0.3  0.1 -0.1  1.8 -1.2 -0.5 -0.8 -0.1 -0.2 -0.2 -0.  -0.1  5.3  0.2 -0.4 -0.1  4.1 -0.8 -0.1  0.2 -0.4 -0.5 -0.1 -0.4  1.6 -0.5 -0.1 -0.   0.3 -0.1 -0.3 -0.3 -0.1 -0.2 -0.1 -0.1 -0.2 -0.2 -0.2 -1.1 -0.6  0.1 -0.5 -0.2 -1.3 -0.3 -0.5 -1.1 -0.4 -0.4  3.1 -0.  -0.4  1.1  0.2 -0.2 -0.5  0.3  9.4 -0.6  1.6 -0.3  0.  -0.2 -0.3  0.1 -0.1 -0.4 -0.2  0.4 -0.1  0.7  4.7 -0.1 -0.3  1.6 -0.5 -0.6 -0.8 -0.4  1.5 -0.4 -0.6 -0.7 -0.3 -0.1 -0.3 -0.9  4.1  2.   1.6  1.2 -0.6  3.4 -0.8 -0.9  0.2  3.   0.1  2.8  0.8  1.1  1.1  4.  -0.2  1.3  0.2 -0.3  4.4 -1.8  0.3 -0.2 -0.8 -0.7  1.5 -0.2  3.8 -0.  -1.7 10.6]
vy_50sample [[8 2 9 5 6 0 4 7 7 3]
 [8 3 4 2 5 0 6 1 7 7]
 [2 0 7 3 5 4 6 8 1 9]
 [1 9 2 3 7 6 8 4 5 0]
 [3 3 8 1 1 6 9 7 5 2]
 [3 8 4 0 9 5 1 1 2 6]
 [1 6 3 2 7 0 8 5 4 9]
 [7 2 5 3 0 9 8 6 1 4]
 [0 8 1 9 5 2 4 3 6 7]
 [4 5 7 0 1 3 2 6 8 9]]
vt_50sample [[8 2 9 5 6 0 4 7 1 3]
 [3 8 4 2 5 0 6 1 9 7]
 [2 0 7 3 5 4 6 8 1 9]
 [1 9 2 3 7 6 8 4 5 0]
 [3 0 1 4 8 6 9 7 5 2]
 [3 8 4 0 9 1 5 7 2 6]
 [1 6 3 2 7 0 8 5 4 9]
 [7 2 5 3 0 9 8 6 1 4]
 [0 1 8 9 5 2 4 3 6 7]
 [4 5 7 0 1 3 2 6 8 9]]
Epoch 28710: Training cost= 0.3058, Training acc= 0.8361, Validation cost= 0.3241, Validation acc= 0.8362
Epoch 28720: Training cost= 0.2900, Training acc= 0.8361, Validation cost= 0.3063, Validation acc= 0.8362
Epoch 28730: Training cost= 0.2841, Training acc= 0.8361, Validation cost= 0.2812, Validation acc= 0.8363
Epoch 28740: Training cost= 0.2909, Training acc= 0.8361, Validation cost= 0.2752, Validation acc= 0.8363
Epoch 28750: Training cost= 0.2682, Training acc= 0.8362, Validation cost= 0.3185, Validation acc= 0.8363
Epoch 28760: Training cost= 0.3144, Training acc= 0.8362, Validation cost= 0.3359, Validation acc= 0.8363
Epoch 28770: Training cost= 0.3457, Training acc= 0.8362, Validation cost= 0.3138, Validation acc= 0.8363
Epoch 28780: Training cost= 0.2437, Training acc= 0.8362, Validation cost= 0.2871, Validation acc= 0.8363
Epoch 28790: Training cost= 0.3157, Training acc= 0.8362, Validation cost= 0.2804, Validation acc= 0.8364
Epoch 28800: Training cost= 0.2713, Training acc= 0.8362, Validation cost= 0.2776, Validation acc= 0.8364
tm  [-0.4 -0.8  4.1 -1.3 -2.2  0.1 -0.5 -0.1  0.   0.4  1.4 -0.3 -0.5 -0.3  9.6 -1.6 -0.4  0.8 -0.3 -0.3 -1.2 -0.2 -0.5  0.6 -1.1  3.1 -0.5 -0.4 -1.3 -1.   4.2 -0.4 -0.1 13.1 -0.2 -0.2  0.8 -0.1  1.4 -0.6 -0.1 -1.6 -0.8  2.9 -0.7 -0.2 -0.3 -0.1  0.7 -1.5 -0.6 -0.3 -0.4 -0.4  0.5 -1.  -0.7 -2.3  3.7 -1.6  2.7 -0.4  0.7 -0.1  2.5 -0.6 -0.1  0.4  0.8 -0.5 -0.2  3.4 -0.4 -0.  -4.4 -0.8 -1.  -0.5 -0.  -0.2  4.7  0.5  0.6 -0.4 -0.9 -1.7  2.5 -0.1 -0.1 -0.6 -0.2 -0.2 -0.1 -0.9 -0.  -0.1 -0.7 -2.3 -0.4 -0.3 -0.6  5.5 -0.5  0.  -0.1  0.5 -1.6  4.5  0.9 -0.2 -0.1 -0.3 -0.2 -0.6  6.4 -2.2 -0.7  1.8 -0.1 -0.3 -0.2 -0.2 -0.3  1.5 -0.4 11.7 -0.3  4.1  1.4  2.4  0.4 -0.3 -0.4  0.2 -4.7  4.6 -0.1 -0.1  0.  -0.6  1.3 -1.4  0.3 -0.4 -0.2  0.4 -0.6 -0.1 -3.1 -0.4  0.3 -0.  -0.5  1.6 -0.  -0.  -0.1 -0.5  0.1 -0.6 -0.2 -1.7  0.4 -0.   0.5 -0.4 -0.3  1.5 -0.3 -0.2 -0.3 -0.4 -0.1  0.6 -0.2  6.3 -0.5 -0.3  0.5 -0.1  1.7 -0.3 -0.2 -1.4 -0.4 -0.5  1.4 -0.5  0.1  2.5 -0.1 -0.2 -0.8 -0.8  0.1 -0.3 -1.1 -1.3 -0.1 -0.  -0.4 -0.1 -0.5 -0.2 -0.1 -1.4 -0.3 -0.5  3.4 -0.2 -0.1 -1.1 -1.   0.9 -0.3 -0.6 -1.  -0.8 -1.   0.6 -0.3 -0.4 -0.1 -0.8 -0.3 -1.1 -2.1 -0.  -1.1  0.9 -0.5 -0.1 -0.3  1.9  1.6 -0.3  2.2 -1.2  2.5  6.7  0.7  2.8 -0.2 -0.  -0.5 -0.3 -0.4 -0.4 -0.8 -0.1 -1.3  0.1  1.4 -0.   3.8 -0.2]
ty_50sample [[7 0 4 3 1 9 6 8 2 5]
 [6 2 1 3 4 7 9 5 0 8]
 [0 8 8 2 7 3 5 9 1 4]
 [3 0 4 6 1 5 8 2 9 7]
 [7 9 1 4 2 6 3 0 5 8]
 [2 9 7 0 6 5 3 3 4 1]
 [3 6 4 0 0 5 1 8 9 7]
 [6 3 5 8 7 1 9 4 2 0]
 [9 3 8 1 5 7 2 0 6 4]
 [1 3 5 0 8 4 9 2 6 7]]
tt_50sample [[7 0 4 3 1 9 6 8 2 5]
 [6 2 1 3 4 7 9 5 0 8]
 [0 8 6 2 7 3 5 9 1 4]
 [3 0 4 6 1 5 8 2 9 7]
 [7 9 1 4 2 6 3 0 5 8]
 [2 9 7 0 6 5 3 8 4 1]
 [3 4 6 2 0 5 1 8 9 7]
 [6 3 5 8 7 1 9 4 2 0]
 [9 3 8 1 5 7 2 0 6 4]
 [3 1 5 0 8 4 9 2 6 7]]
vm  [-1.4 -0.3 -3.  -6.3 -1.5  0.1 -0.2 -0.3 -0.4 -0.7 -4.   0.5 -0.4 -0.5  7.9 -0.9  0.3 -0.2 -0.4  3.4 -0.9 -0.4  1.7 -0.2 -1.2  1.1 -0.2 -0.4 -0.7 -1.   3.5 -0.6 -0.3 -1.5 -0.4  0.1  0.8 -0.  -1.2 -0.2  0.6  1.4 -0.1  6.2 -0.5 -0.  -3.4  0.4 -0.8  4.  -0.8 -0.3 -0.3  1.8 -1.2 -0.7 -0.9 -1.   2.9 -1.2  9.8 -0.1  0.9 -0.4 -0.7 -0.1 -0.1 -0.4 -0.3  0.5  0.1 -0.3 -0.  -0.2 -6.6 -0.2  0.3 -0.1 -0.2  0.  -4.8 -0.2  0.4 -0.3  0.2  2.9  2.3 -0.3 -0.  -0.4 -0.5 -0.1  0.3 -0.2 -0.6 -0.1 -0.1 -3.  -0.   0.1  2.1 -0.5  1.1 -0.5 -0.4  0.4 -3.   3.7 -1.2  2.6 -0.4 -0.1 -0.  -1.   2.7  2.4 -0.1  1.4 -0.2 -0.5 -0.1 -1.2 -0.2 -0.2 -0.4  9.4  0.3  0.7  3.9  7.3 -0.8 -0.4 -0.2 -0.1 -1.2 -2.8 -0.2  0.1 -0.1 -0.4  3.3 -0.6  1.5 -0.3  0.2 -0.2 -0.1 -0.1  4.2 -0.   3.7 -0.2 -0.2  0.1 -0.2  0.3 -0.5  0.2  3.1 -0.5  0.4 -1.3 -0.2 -0.1 -0.3 -0.1 -0.2  1.7  0.5 -0.4 -0.3  0.4 -0.4 -0.  -0.2 -0.5 -0.  -0.6  3.3 -0.2 -1.3 -0.1 -0.3 -1.6 -0.5 -0.4 -1.2 -0.2 -0.5  2.6 -0.4 -0.4  0.4 -1.1 -3.4 -0.7 -1.2 -0.6 -0.2 -0.2 -0.  -0.1  0.5 -0.4 -0.1 -3.6 -0.6 -0.4  0.8 -0.4 -0.5 -0.  -0.4  6.2  1.2 -0.5 -2.2 -0.5 -0.4 -0.6 -0.4  0.  -0.4 -1.1 -0.8  1.8 -2.  -0.3 -0.4  0.2 -0.4  0.8 -0.3  0.8 -0.   6.4 -0.3 -2.3  1.3 -4.2 -0.3 -1.8 -0.2 -0.  15.2  6.2 -0.4  0.5 -0.9  0.1 12.2 -0.3 -0.8 -0.1  4.8 -2. ]
vy_50sample [[4 1 8 8 3 0 7 6 2 9]
 [9 4 0 0 3 1 6 7 5 2]
 [1 7 8 2 0 6 9 3 5 4]
 [9 7 4 6 0 1 5 8 3 2]
 [8 0 6 2 3 4 9 1 7 5]
 [6 4 8 0 1 2 5 7 9 3]
 [2 0 9 7 7 8 6 3 4 5]
 [9 9 4 3 0 0 2 2 1 1]
 [1 9 4 0 7 6 8 5 2 3]
 [8 7 1 4 6 5 3 2 0 0]]
vt_50sample [[4 1 8 5 3 0 7 6 2 9]
 [9 4 0 8 3 1 6 7 5 2]
 [1 7 8 2 0 6 9 3 5 4]
 [9 7 4 6 0 1 5 8 3 2]
 [8 0 6 2 3 4 9 1 5 7]
 [6 4 8 0 1 2 5 7 9 3]
 [2 0 9 1 7 8 6 3 4 5]
 [9 7 4 3 6 0 2 5 8 1]
 [1 9 4 0 7 6 8 5 2 3]
 [8 7 1 4 6 5 3 2 9 0]]
Epoch 28810: Training cost= 0.2315, Training acc= 0.8363, Validation cost= 0.2564, Validation acc= 0.8364
Epoch 28820: Training cost= 0.2910, Training acc= 0.8363, Validation cost= 0.3272, Validation acc= 0.8364
Epoch 28830: Training cost= 0.3149, Training acc= 0.8363, Validation cost= 0.3115, Validation acc= 0.8364
Epoch 28840: Training cost= 0.3290, Training acc= 0.8363, Validation cost= 0.2896, Validation acc= 0.8365
Epoch 28850: Training cost= 0.3055, Training acc= 0.8363, Validation cost= 0.3010, Validation acc= 0.8365
Epoch 28860: Training cost= 0.3509, Training acc= 0.8364, Validation cost= 0.2680, Validation acc= 0.8365
Epoch 28870: Training cost= 0.2902, Training acc= 0.8364, Validation cost= 0.3415, Validation acc= 0.8365
Epoch 28880: Training cost= 0.3042, Training acc= 0.8364, Validation cost= 0.3089, Validation acc= 0.8365
Epoch 28890: Training cost= 0.2744, Training acc= 0.8364, Validation cost= 0.2877, Validation acc= 0.8365
Epoch 28900: Training cost= 0.3296, Training acc= 0.8364, Validation cost= 0.3186, Validation acc= 0.8366
tm  [ 1.5  0.4  4.7  7.7 -2.  -0.3 -0.2 -0.1 -0.9 -0.7 -0.1  0.8 -0.5 -0.2 -0.1 -0.6 -0.3 -0.3  0.8 -0.9 -1.  -0.2 -0.2 -0.  -1.3  3.   0.2 -0.2 -1.  -0.4  1.2 -0.4 -0.4  5.5 -0.2 -0.2  2.4  1.1 10.2 -0.4 -0.2  4.9  4.4  2.1 -0.3  0.3  4.5 -0.1  6.4 -0.4 -0.6 -0.2  1.6 -1.4 -0.2  0.7 -0.5  6.  -1.1  0.7 -1.8 -0.3 -0.  -0.1 -0.  -0.4 -0.3 -0.2  1.6 -0.2  0.2  2.   0.4  0.  -0.8 -0.2 -0.6 -0.6 -0.2 -0.3  9.6 -0.4 -0.3 -0.3 -1.4  4.3  5.  -0.2  0.  -0.2 -0.2 -0.1 -0.1  1.8 -0.3 -0.3 -0.3 -1.1 -0.5 -0.3  2.2  3.3 -1.3 -0.2 -0.3  1.5 -0.1  1.1  0.2 -1.4 -0.3 -0.4 -0.1 -0.3 -0.3 -0.6 -0.  -0.7 -0.1  0.1 -0.   4.9 -0.  -0.3 -0.3 -0.2 -0.3  7.7  0.2 -0.8  0.3 -0.2 -0.2 -0.2 -3.3 -0.7 -0.3 -0.1 -0.2 -1.   1.2 -1.   1.7  0.7 -0.2 -0.1 -0.3 -0.1  3.3 -0.4 -0.5 -0.3  3.6  0.5 -0.1 -0.2 -0.2 -0.3  2.7 -0.1 -0.2 -1.4 -0.2 -0.  -0.3 -0.5 -0.2 -0.9  0.6  0.1 -0.4 -0.2 -0.4 -0.2 -0.4 -0.4 -0.4  0.1 -1.  -0.  -2.  -0.1 -0.2 -1.4  0.2  0.3  4.6 -0.3 -0.3  1.1 -0.1 -0.1 -0.4 -1.1 12.   1.2  1.9  0.2 -0.2 -0.1 -0.1 -0.2 -0.4 -0.3 -0.2  2.1 -0.3 -0.2 -3.4 -0.4 -0.4 -0.6 -0.8 -1.  -0.4 -0.4 -0.5 -0.7 -0.1 -0.2 -0.3  0.2  0.8 -0.6 -1.  -0.5 -1.6 -0.6 -0.   2.7 -0.3 -0.8 -0.  -1.9  0.6 -0.9  0.5  2.2  1.8 -1.2 -0.1 -0.6 -0.3  0.3 -1.6 -2.3 -0.2 -0.3 -0.9 -0.3 -2.7 -0.2  7.4 -0.2  4.1  4.9]
ty_50sample [[5 9 7 0 3 4 8 2 6 1]
 [0 6 4 2 7 3 9 8 1 5]
 [0 4 4 1 3 9 5 6 2 7]
 [2 7 1 0 4 8 6 3 9 5]
 [2 7 8 4 5 0 9 1 6 3]
 [5 8 6 0 3 1 4 7 2 9]
 [4 9 7 2 8 3 5 1 0 6]
 [9 2 8 0 3 6 4 5 7 1]
 [5 7 7 3 2 8 4 1 9 6]
 [9 6 8 5 7 0 4 3 1 2]]
tt_50sample [[5 9 7 0 3 4 8 2 6 1]
 [0 6 4 2 7 3 9 8 1 5]
 [0 4 1 8 3 9 5 6 2 7]
 [2 7 1 0 4 8 6 3 9 5]
 [2 7 8 4 5 0 9 1 6 3]
 [5 8 6 0 3 1 4 7 2 9]
 [4 9 7 2 8 3 5 1 0 6]
 [9 2 8 0 3 6 4 5 7 1]
 [5 0 7 3 2 8 4 1 9 6]
 [9 6 8 5 7 0 4 3 1 2]]
vm  [-0.7 -0.  -2.4  3.8 -0.8 -0.3  0.3 -0.1 -0.3 -0.6 -3.7 -0.1 -0.5 -0.1 -2.1 -0.6  0.5 -0.2 -0.5 -1.  -0.9 -0.3 -0.6 -0.4 -0.4  0.5 -0.3 -0.6 -0.4 -1.5 -0.  -0.3 -0.5 -3.4 -0.4 -0.4  0.6 -1.3  3.4 -0.4 -0.7 -3.3 -0.5 -0.1 -0.3  0.4  2.6  0.9  1.9 -1.4 -0.3 -0.2  0.4 -2.1 -0.8  2.8 -0.2 -1.4  2.   2.  -0.3  0.5 -0.4 -0.4 -0.8 -0.1  0.2 -0.3 -0.1  0.3  0.9 -0.6  0.1  0.6 -1.4 -0.4 -0.6 -0.3 -0.3 -0.2  1.4 -0.2 -0.2 -0.  -0.8 -3.2  1.9 -0.1 -0.4 -0.5 -0.3 -0.2  0.  -0.6 -0.5 -0.2 -0.4 -1.5 -0.1 -0.3  2.3 -3.2 -0.1  0.4 -0.4  1.3 -0.5 -0.1 -1.4 -1.8 -0.   0.5 -0.1 -0.8  2.2  3.8 -0.7  1.  -0.2 -0.4 -0.1  6.3 -0.2  0.1 -0.1 -2.5 -0.1 10.5  2.8  6.   1.7 -0.5  0.9 -0.1 10.1 -0.2 -0.3 -0.1  0.9 -0.   2.9 -0.6  0.8  0.1 -0.1  0.3 -0.2 -0.1  2.8  0.2 -0.2 -0.2  2.3  1.5 -0.2  0.2 -0.4 -0.3 -0.5 -0.4 -0.1  1.   0.  -0.3  0.3  0.7  0.2  2.5  0.8 -0.2 -0.4 -0.2 -0.   0.4  0.2  0.6 -0.3 -0.2 -0.2 -0.1  0.  -0.  -0.7 -1.5 -0.4 -0.1  0.8  0.2 -0.1  4.5 -0.  -0.  -0.6 -0.6  4.9 -0.7  1.8 -0.6  0.3 -0.2  0.  -0.1  0.5 -0.4  0.7 -0.3 -0.5  0.   7.8 -0.  -0.3  3.  -1.1  1.7 -0.2 -0.3  1.  -0.5 -0.2 -0.1 -0.6 -0.2  0.  -0.8 -0.6  2.9 -2.2 -0.1 -0.7  3.2 -0.2 -0.8 -0.2  3.9 -0.   4.7 -0.2  0.1  2.9 12.4 -0.1  5.   0.5 -0.1  1.6 -1.3 -0.4 -0.1 -1.3 -0.5 -0.6 -0.2  2.2 -0.6  8.9 -1.2]
vy_50sample [[3 9 8 6 4 1 0 5 7 2]
 [3 6 4 5 8 1 2 9 7 0]
 [4 5 2 0 3 6 1 7 9 8]
 [8 2 2 1 1 6 3 5 0 7]
 [4 0 3 9 1 8 5 7 6 2]
 [4 7 0 8 1 2 3 5 9 6]
 [9 3 4 0 1 7 5 6 8 2]
 [5 0 6 3 1 7 8 4 9 2]
 [7 2 0 4 6 5 1 9 8 3]
 [5 6 1 1 0 3 7 4 2 8]]
vt_50sample [[3 9 8 6 4 1 0 5 7 2]
 [3 6 4 5 8 1 2 9 7 0]
 [4 5 2 0 3 6 7 1 9 8]
 [8 2 1 4 9 6 3 5 7 0]
 [4 0 3 9 8 1 7 5 6 2]
 [4 7 0 8 1 2 3 5 9 6]
 [9 3 4 0 1 7 5 6 8 2]
 [5 0 6 3 1 4 7 8 9 2]
 [7 2 0 4 6 5 1 9 8 3]
 [5 6 1 9 0 3 7 4 8 2]]
Epoch 28910: Training cost= 0.2673, Training acc= 0.8364, Validation cost= 0.2631, Validation acc= 0.8366
Epoch 28920: Training cost= 0.2398, Training acc= 0.8365, Validation cost= 0.2698, Validation acc= 0.8366
Epoch 28930: Training cost= 0.2498, Training acc= 0.8365, Validation cost= 0.2615, Validation acc= 0.8366
Epoch 28940: Training cost= 0.3318, Training acc= 0.8365, Validation cost= 0.2862, Validation acc= 0.8366
Epoch 28950: Training cost= 0.3277, Training acc= 0.8365, Validation cost= 0.2761, Validation acc= 0.8367
Epoch 28960: Training cost= 0.2496, Training acc= 0.8365, Validation cost= 0.2470, Validation acc= 0.8367
Epoch 28970: Training cost= 0.2738, Training acc= 0.8366, Validation cost= 0.2451, Validation acc= 0.8367
Epoch 28980: Training cost= 0.2107, Training acc= 0.8366, Validation cost= 0.2714, Validation acc= 0.8367
Epoch 28990: Training cost= 0.2525, Training acc= 0.8366, Validation cost= 0.2645, Validation acc= 0.8367
Epoch 29000: Training cost= 0.2707, Training acc= 0.8366, Validation cost= 0.2774, Validation acc= 0.8368
tm  [ 1.6 -0.5  3.7 -1.4 -1.8 -0.2 -0.  -0.2 -0.  -0.1 -1.4  0.  -0.6 -0.2  8.3 -0.8 -0.1 -0.2 -0.2  1.4 -0.9 -0.1  1.6 -0.  -1.1  1.3  0.1 -0.2 -0.7 -0.4  2.1 -0.5 -0.4  6.4 -0.1 -0.5 -0.4 -0.5 -0.6 -0.4 -0.6  7.2  0.9  1.7 -0.6 -0.  -1.8  0.1  7.1  4.1 -0.4 -0.1  0.9  0.3 -0.6 -0.9 -0.5  4.4  1.1 -0.3 -0.3 -0.4 -0.1  0.1 -0.  -0.6 -0.1  0.6  0.9 -0.3  0.3  0.1  0.5  0.5 -5.1 -0.8 -0.9 -0.6 -0.1 -0.3 -1.  -0.2  0.4 -0.4 -1.8  6.4  6.  -0.4 -0.1 -0.4 -0.1 -0.2 -0.1 -0.6 -0.4 -0.3 -0.6 -2.6 -0.3 -0.2 -0.3  5.3 -1.5 -0.2 -0.4  1.8 -1.7  1.6 -0.4 -0.1  0.3 -0.3 -0.2 -0.8  1.8 -0.1 -0.6  1.5 -0.1  0.2 -0.2 -0.4 -0.2 -0.4 -0.3 10.  -0.2  2.5  4.1  0.8  2.7 -0.3 -0.1 -0.  -2.5  0.9 -0.2 -0.2 -0.4 -0.9  2.2 -0.8  2.2  0.3 -0.3 -0.2 -0.3 -0.1  2.4 -0.3  1.2 -0.2  3.9  0.6 -0.2  0.3 -0.2 -0.3 -0.  -0.2 -0.1 -0.9 -0.2 -0.2 -0.3 -0.1 -0.3 -0.3  0.5 -0.1 -0.3  0.2 -0.5 -0.2 -0.2 -0.2 -0.8 -0.3  2.6 -0.2 -2.2 -0.1 -0.4 -1.9 -0.1 -0.2  3.8 -0.4 -0.3  0.9 -0.2 -0.  -0.1 -0.7  5.2 -1.1 -0.6 -0.7 -0.  -0.1  0.6 -0.2 -0.2 -0.5 -0.3 -1.9 -0.3 -0.1 -3.3 -0.5 -0.4 -0.2 -1.1 -1.3 -0.5 -0.5 -0.3 -0.6 -0.5 -0.2 -0.3 -0.2  0.4 -1.   1.4 -0.1 -2.  -0.6 -0.3  5.2 -0.5 -0.3 -0.1 -1.8 -0.3 -0.5  1.  -1.   3.  -4.9 -0.  -2.1 -0.3  0.1  5.3  0.5 -0.4 -0.3 -1.   0.5  2.  -0.  -0.3 -0.1  2.8  1.3]
ty_50sample [[5 7 0 4 8 6 3 9 2 1]
 [3 2 8 4 5 1 7 0 6 9]
 [2 1 9 7 6 8 0 4 5 3]
 [1 9 9 2 5 4 7 3 6 8]
 [9 2 7 0 6 5 8 1 3 4]
 [6 0 3 1 5 7 8 2 4 9]
 [3 9 1 6 5 7 2 4 4 0]
 [0 2 4 8 1 7 5 9 6 3]
 [3 4 7 9 8 2 6 5 0 1]
 [5 2 1 7 9 4 0 8 6 3]]
tt_50sample [[5 7 4 0 8 6 3 9 2 1]
 [3 2 8 4 5 1 7 0 6 9]
 [2 1 9 7 6 8 0 4 5 3]
 [1 9 0 2 5 4 7 3 6 8]
 [9 2 7 0 6 5 8 1 3 4]
 [6 0 3 1 5 7 2 8 4 9]
 [3 9 1 6 5 7 2 4 0 8]
 [0 2 4 8 1 5 7 9 6 3]
 [3 4 7 9 8 2 6 5 0 1]
 [5 2 1 7 9 4 0 8 6 3]]
vm  [-1.1 -0.6  5.1 18.4 -1.1 -0.6  0.9 -0.3 -0.   1.   5.5  3.3 -1.6 -0.3 -2.  -0.4 -0.5 -0.1  0.3 -1.  -0.8 -0.1 -1.4 -0.4 -0.6 -0.   0.2 -0.4 -0.4 -3.3 -0.2 -0.3 -0.3  4.5 -0.8 -0.7 -0.1  1.4 10.4 -0.5  0.1  1.  -0.3 -0.9 -0.8 -0.5  7.3 -0.9 -1.7 -4.1 -0.4 -0.3  0.9 -1.5 -1.5  3.5 -0.5 10.9  1.8  3.2  3.3 -0.3  0.5 -1.4  2.8 -1.4 -0.2  2.5 -0.1 -0.5 -0.2 -0.3 -0.1 -0.8 -2.5 -0.3 -0.  -0.8 -0.4 -0.2 17.1 -0.2 -0.1 -0.8 -0.2  0.9 -2.1 -0.2 -0.1 -0.3 -0.1 -0.2 -0.2  0.5 -1.  -0.7 -1.3 -0.9  0.1 -0.8 -0.1 -2.3  1.  -0.5 -0.1 -0.1 -1.5  0.5  1.2 -2.1  0.9 -0.4 -0.  -0.5 -0.1  0.2  0.9  1.1  0.4  2.8  0.8  4.7 -0.4 -0.3 -0.2 -2.4 -0.4  8.   4.2  5.5 -0.7  0.3 -0.1  3.3 -0.1  4.5  0.1 -0.5 -0.3 -1.1 -0.2  0.4  0.1 -0.1 -0.1 -0.5 -0.2 -0.3  7.1 -0.6 -1.6 -0.  -2.   0.3 -0.1 -0.6 -0.1 -0.2  0.7  0.7 -0.3 -1.8 -0.2 -0.2 -0.4 -0.3 -0.7 -0.2 -0.7  0.1 -0.3 -0.4 -0.3 -0.2 -0.5 -2.1 -0.5 -0.9 -1.1 -0.2 -1.6 -0.8  1.4 -1.9  0.4 -0.1 -0.7 -0.2  0.7 10.3 -0.4 -0.4 -0.5 -1.7 -0.7 -0.4 -0.5 -0.1 -0.4 -0.4  1.  -0.2 -0.1 -0.  -0.5  2.6  0.  -0.1 -5.7 -0.7 -0.5 -0.4 -0.5  4.1 -0.1  2.8  2.8 -0.9 -0.1  2.3 -0.  -0.6  2.2 -1.  -1.5 -0.7 -2.  -0.5  1.1 -0.4 -0.9  3.4  0.8 -3.2 -1.5 -0.9  0.6 -1.3 -1.  -1.9 -0.2 -0.9 -0.3 -0.5 -3.6 -2.3 -0.4 -0.4 -0.7 -0.7 -4.6 -0.4  7.2  0.5  4.8 -0.9]
vy_50sample [[5 1 1 9 0 0 2 6 8 4]
 [2 7 5 8 1 6 3 9 0 4]
 [3 9 2 7 8 5 4 0 1 6]
 [9 7 8 5 2 6 4 3 0 1]
 [8 6 0 4 5 9 3 3 7 1]
 [0 7 1 8 6 4 2 9 3 5]
 [3 1 2 9 6 5 7 4 0 8]
 [1 3 2 9 4 8 0 7 6 5]
 [6 4 1 1 8 3 5 9 7 0]
 [3 6 4 9 2 0 0 5 8 7]]
vt_50sample [[5 3 1 9 0 7 2 6 8 4]
 [2 7 5 8 1 6 3 9 4 0]
 [3 9 2 7 8 5 4 0 1 6]
 [9 7 8 5 6 2 4 3 0 1]
 [8 6 4 0 5 9 3 7 2 1]
 [0 7 1 8 6 4 2 9 3 5]
 [3 1 2 9 6 5 7 4 0 8]
 [1 3 9 2 4 8 0 7 6 5]
 [6 4 2 1 8 3 5 9 7 0]
 [3 6 4 9 2 0 8 5 1 7]]
Epoch 29010: Training cost= 0.2800, Training acc= 0.8366, Validation cost= 0.2869, Validation acc= 0.8368
Epoch 29020: Training cost= 0.2382, Training acc= 0.8367, Validation cost= 0.2899, Validation acc= 0.8368
Epoch 29030: Training cost= 0.2849, Training acc= 0.8367, Validation cost= 0.2981, Validation acc= 0.8368
Epoch 29040: Training cost= 0.2947, Training acc= 0.8367, Validation cost= 0.2775, Validation acc= 0.8368
Epoch 29050: Training cost= 0.2533, Training acc= 0.8367, Validation cost= 0.3026, Validation acc= 0.8368
Epoch 29060: Training cost= 0.2910, Training acc= 0.8367, Validation cost= 0.2933, Validation acc= 0.8369
Epoch 29070: Training cost= 0.2670, Training acc= 0.8367, Validation cost= 0.2975, Validation acc= 0.8369
Epoch 29080: Training cost= 0.2402, Training acc= 0.8368, Validation cost= 0.2672, Validation acc= 0.8369
Epoch 29090: Training cost= 0.2746, Training acc= 0.8368, Validation cost= 0.2331, Validation acc= 0.8369
Epoch 29100: Training cost= 0.2832, Training acc= 0.8368, Validation cost= 0.2309, Validation acc= 0.8369
tm  [-0.  -1.4  1.6 -2.3 -2.  -0.1 -0.4 -0.2  3.   2.   0.3 -0.2 -0.2 -0.5  8.6 -1.1 -0.4 -0.3 -0.1  1.7 -1.   0.8  1.6 -0.3 -0.9  2.4 -0.3 -0.3 -1.1 -2.1  2.5 -0.4 -0.4  5.6  0.6 -0.5 -0.9  1.6 -0.2 -0.9  0.4  4.8 -0.8  3.7 -0.1 -0.1 -1.8 -0.3  6.   7.1 -0.5 -0.2 -0.1  4.1  1.4 -0.8 -0.8 -0.7  9.5 -0.8  1.1 -0.4  0.4  2.3 -0.1 -0.1  0.3 -0.1  1.9 -0.2 -0.1  3.2 -0.1 -0.2 -5.   1.  -1.1  0.1 -0.1 -0.4 -1.7  0.8  0.2  0.5 -1.3  5.6  4.3 -0.1 -0.3 -0.5 -0.5 -0.3 -0.2 -2.3 -0.5 -0.2 -0.  -3.3 -0.6 -0.2 -0.9  8.3 -1.2 -0.  -0.1 -0.2 -1.6  2.   0.3  1.6 -0.4 -0.4 -0.2 -0.9  8.  -2.   0.6  4.5 -0.3 -0.1 -0.  -0.7 -0.2 -0.5 -0.1  9.7 -0.6 -0.4  7.9 -0.1  0.1 -0.8 -0.1 -0.8 -3.5 -1.  -0.3 -0.1 -1.  -0.2  0.1 -1.2  0.9 -0.2 -0.2 -0.2 -0.1 -0.1 -0.8 -0.2  2.   0.3  2.8 -0.  -0.1 -0.   0.3 -0.2  2.4 -0.2  0.9 -1.6  0.1 -0.2 -0.2 -0.8 -0.6  0.5 -0.3 -0.2 -0.  -0.4 -0.2 -0.3 -0.1  2.2 -0.4 -0.1  1.5 -0.3 -0.9 -0.4 -0.6 -1.7 -0.2 -0.2  3.2 -0.3 -0.2  5.6 -0.  -0.2 -0.5 -0.5  1.5 -2.7 -0.9 -2.  -0.  -0.1  0.6 -0.1 -0.2 -0.7 -0.3 -2.6  0.1 -0.2  0.3 -0.3  0.3 -1.  -0.9 -1.2 -1.  -0.1 -1.  -0.8 -0.2 -0.4 -0.3 -0.3 -0.4 -1.2  2.7 -0.9 -1.5 -0.1  0.6  5.2 -0.5 -0.5  0.4 -0.1  2.2 -0.   3.2 -1.1  4.4 -1.6 -0.1 -0.7  0.4  0.5  7.1  2.1  0.1  0.4 -1.  -0.3  4.1  0.1 -0.  -0.1 -0.6  2.8]
ty_50sample [[0 7 4 5 8 2 6 1 9 3]
 [4 9 1 6 0 2 5 7 8 3]
 [8 4 3 1 2 6 5 0 9 7]
 [4 8 5 9 3 6 7 1 2 0]
 [5 0 1 7 8 3 3 4 6 2]
 [8 1 0 7 3 9 2 5 6 4]
 [0 5 2 7 8 8 3 6 4 1]
 [2 6 1 1 4 7 3 5 9 0]
 [1 6 7 4 3 2 5 9 8 0]
 [0 7 6 8 5 9 2 1 4 3]]
tt_50sample [[0 7 4 5 8 2 6 1 9 3]
 [4 9 1 6 0 2 5 7 8 3]
 [8 4 3 1 2 6 0 5 9 7]
 [4 8 5 9 3 6 7 1 2 0]
 [5 0 1 7 3 8 9 4 6 2]
 [8 1 0 3 7 9 2 5 6 4]
 [0 5 2 7 8 9 3 6 4 1]
 [2 6 8 1 4 7 3 9 5 0]
 [1 6 7 4 3 2 5 9 8 0]
 [0 7 6 8 5 9 2 1 4 3]]
vm  [-1.6  0.2 -0.8 16.9 -0.6  0.1 -0.  -0.1 -0.1 -0.5 -0.9 -0.4  0.2 -0.2 -3.6  5.5 -0.3 -0.4 -0.3 -1.9 -0.6 -0.5  1.6 -0.1 -0.6 -0.1 -0.3  0.1  1.6 -1.3 -1.4 -0.5 -0.4 -4.2 -0.4  0.1  1.4  3.6 14.6 -0.2 -0.1  1.2 -0.2 -0.1 -0.4  0.6 10.9 -0.2 -1.7  5.3 -0.7 -0.1 -0.2 -1.6 -1.2  4.8 -0.   6.7  0.1  4.2  0.  -0.4 -0.5 -0.4 -0.3 -0.1  0.2 -0.2 -0.3 -0.4 -0.3 -1.9 -0.1 -0.3  6.  -0.  -0.1 -0.2 -0.3  0.6  6.3 -0.3 -0.5  1.3  2.6  3.6 -2.  -0.  -0.1 -0.   0.7  0.7 -0.1 -0.5 -0.3 -0.2 -0.2 -0.   0.4  0.5  2.2 -1.6  0.9 -0.1 -0.3 -0.6  1.2 -0.9 -0.2 -2.1 -0.1 -0.1 -0.1 -0.4 -0.6 10.6 -0.5 -1.1 -0.1 -0.6 -0.3  8.5  0.9  0.7  0.4 -4.4  0.2  8.1  1.6 -1.9 -1.  -0.4  0.2 -0.5  5.5 -3.1  0.3 -0.3  0.9 -0.4 -0.5 -0.4 -0.6 -0.3 -0.  -0.1  0.3 -0.   7.2 -0.3 -1.2 -0.3 -0.1 -0.1  1.2 -0.1 -0.2 -0.7  1.7 -0.1 -0.4 -0.8 -0.2 -0.   0.1  0.   0.7  1.3 -0.2 -0.2 -0.2 -0.  -0.   0.2 -0.1 -1.6 -0.3  0.2 -1.8  0.  -1.3 -0.1 -0.2 -1.3 -0.7 -0.1 -0.8 -0.2 -0.1  4.4 -0.3 -0.3 -0.7 -0.6  3.  -0.4  3.   1.7 -0.2 -0.1 -0.1 -0.1  0.  -0.4  0.3  4.8 -0.   0.5  1.6 -0.  -0.5  4.5 -0.3  6.2 -0.5 -0.2  1.7 -0.3 -0.5 -0.4 -0.4 -0.2 -0.3 -0.6 -0.4  4.6 -0.5  2.  -0.6 -0.3 -0.6 -1.  -0.1  1.3 -0.8  1.8 -0.4  3.4  1.   7.5 -0.2  3.2  0.1 -0.4 -0.8 -2.8 -0.   0.4 -0.9 -0.1 -2.  -0.1  9.8 -0.   0.1  8.9]
vy_50sample [[9 1 8 5 2 3 6 4 0 7]
 [2 7 5 9 0 4 6 6 8 1]
 [3 2 1 1 7 7 9 4 8 8]
 [6 8 4 5 9 7 3 0 1 2]
 [0 9 3 6 8 2 4 1 5 7]
 [6 7 8 9 1 0 5 3 2 4]
 [6 7 4 0 5 3 2 1 8 9]
 [4 7 3 8 5 1 0 2 6 9]
 [3 6 1 1 9 2 0 8 8 5]
 [3 6 0 2 7 5 4 9 1 8]]
vt_50sample [[9 1 8 5 2 3 6 4 7 0]
 [2 7 5 9 4 0 6 3 8 1]
 [3 2 5 1 7 6 9 4 0 8]
 [6 8 4 5 9 7 3 0 1 2]
 [0 9 3 6 8 2 4 1 5 7]
 [6 7 8 9 1 0 5 3 2 4]
 [6 7 4 0 5 3 2 9 8 1]
 [4 7 3 8 5 1 0 6 2 9]
 [3 6 1 7 9 2 0 4 8 5]
 [3 6 0 2 7 5 4 9 1 8]]
Epoch 29110: Training cost= 0.2511, Training acc= 0.8368, Validation cost= 0.2392, Validation acc= 0.8369
Epoch 29120: Training cost= 0.2937, Training acc= 0.8368, Validation cost= 0.2820, Validation acc= 0.8370
Epoch 29130: Training cost= 0.2520, Training acc= 0.8368, Validation cost= 0.2459, Validation acc= 0.8370
Epoch 29140: Training cost= 0.2558, Training acc= 0.8369, Validation cost= 0.2988, Validation acc= 0.8370
Epoch 29150: Training cost= 0.3093, Training acc= 0.8369, Validation cost= 0.2384, Validation acc= 0.8370
Epoch 29160: Training cost= 0.3160, Training acc= 0.8369, Validation cost= 0.2724, Validation acc= 0.8370
Epoch 29170: Training cost= 0.3051, Training acc= 0.8369, Validation cost= 0.2733, Validation acc= 0.8371
Epoch 29180: Training cost= 0.3059, Training acc= 0.8369, Validation cost= 0.3480, Validation acc= 0.8371
Epoch 29190: Training cost= 0.2368, Training acc= 0.8369, Validation cost= 0.3005, Validation acc= 0.8371
Epoch 29200: Training cost= 0.2580, Training acc= 0.8370, Validation cost= 0.2829, Validation acc= 0.8371
tm  [ 1.5 -0.4  9.7  0.1 -1.3 -0.1 -0.5  0.2 -0.1 -0.1  4.4 -0.5 -0.4 -0.1 11.6  1.9 -0.1 -0.3 -0.   1.2 -0.7 -0.1  1.6 -0.1 -0.9  0.8 -0.2  0.2 -0.6 -0.  -0.7 -0.4  0.7  6.5 -0.2 -0.4 -0.  -0.2 -3.8 -0.6 -0.5  0.9 -0.1 -1.4 -0.   0.3 -1.9 -0.4  5.6  5.7 -0.5 -0.  -0.2  7.9 -0.6 -1.2 -0.6  3.2  2.7  4.3 -0.1 -0.2  0.2  1.6 -0.1 -0.1 -0.2 -0.2  1.2 -0.3 -0.1 -0.1  0.1  0.2 -4.9 -0.3 -1.1  0.4 -0.3 -0.3 -2.4 -0.3  0.3 -0.  -1.8  1.9  1.7 -0.3 -0.2 -0.4 -0.7 -0.1 -0.1 -0.4 -0.4 -0.1  0.9 -2.6 -0.3  0.6  0.2  6.8 -1.1  0.3 -0.3  0.2 -1.8 -0.5  1.6  0.7 -0.3 -0.1  0.  -0.7  2.2  0.1 -0.4  1.4 -0.  -0.4 -0.1 -0.6  0.4 -0.5 -0.4 13.9 -0.2 -2.   0.7  2.3  2.9 -0.8 -0.3 -0.5 -0.2  8.2 -0.  -0.2 -0.  -0.5 -1.  -0.9 -0.5 -0.4 -0.1 -0.1 -0.3 -0.1 -1.8  0.1 -0.3 -0.1  4.1 -0.3 -0.2  0.2 -0.2 -0.2 -1.1 -0.3  0.1  1.9 -0.2 -0.1 -0.  -0.3 -0.  -0.2  0.2 -0.1 -0.5 -0.1 -0.4 -0.2 -0.4  3.2 -1.3 -0.2  6.9 -0.2 -0.7 -0.1 -0.5 -1.  -0.5 -0.4  3.1 -0.6 -0.3  0.1 -0.1 -0.1 -0.3 -0.4  3.5 -0.7 -0.8 -1.  -0.3  0.1 -0.1 -0.2  0.2 -0.2 -0.4 -3.  -0.1 -0.   4.2 -0.2 -0.2 -0.3 -0.7 -1.6 -0.5 -0.4  6.4 -0.5 -0.3 -0.6 -0.4 -0.  -0.2 -1.2  3.6  0.8 -0.1  0.5 -0.1  4.6  1.1  0.1 -0.3  2.4 -0.2 -2.1  1.1 -1.5  1.7 -0.9  0.2 -0.5 -0.1  0.4  8.8  3.3 -0.6 -0.  -0.8  0.1  6.2 -0.1 -2.5 -0.3 -0.7 -0.2]
ty_50sample [[7 6 2 0 8 5 3 4 9 1]
 [8 9 5 5 4 1 7 0 6 3]
 [0 9 8 6 7 2 4 1 3 5]
 [2 5 5 4 9 0 3 7 8 6]
 [9 1 3 8 0 6 7 5 2 4]
 [2 6 1 9 7 4 0 3 5 8]
 [1 8 8 2 2 7 3 5 5 4]
 [6 4 1 9 9 7 0 5 2 8]
 [0 6 8 3 5 4 1 7 9 2]
 [2 0 9 4 3 5 1 7 8 6]]
tt_50sample [[7 6 2 0 8 5 3 4 9 1]
 [8 9 5 2 4 1 7 0 6 3]
 [0 9 8 6 7 4 2 1 3 5]
 [2 1 5 4 9 0 3 7 8 6]
 [9 1 3 8 0 6 7 5 2 4]
 [2 6 1 9 7 4 0 3 5 8]
 [1 8 6 0 2 7 3 9 5 4]
 [6 4 1 3 9 7 0 5 2 8]
 [0 6 8 3 5 4 1 7 9 2]
 [2 0 9 4 3 5 1 7 8 6]]
vm  [ 1.1  2.7  0.6  1.3 -1.5 -0.1 -0.2  0.3 -1.7 -1.  -0.4 -0.1 -0.5 -0.3  0.4  0.5 -0.4  0.7 -0.3 -1.2 -0.7 -0.1  0.   1.5 -1.   0.9 -0.2 -0.3 -0.6  8.6  3.1 -0.4  0.2  8.  -0.3  1.2  3.7 -0.3  6.5 -0.4 -0.6 -2.1  3.   2.4 -0.4 -0.2  7.8 -0.1  3.3 -0.4 -0.4 -0.1  1.9 -2.1 -0.8  0.2 -0.5 -2.7 -2.4 -1.5 -1.7 -0.1 -0.2 -0.5 -0.2 -0.1  0.8 -0.5  0.3 -0.1 -0.  -0.3  0.3 -0.3  4.6 -0.1 -0.1 -0.4 -0.4 -0.  12.1 -0.4 -0.2  0.4 -1.2 -2.   7.  -0.2 -0.1 -0.2 -0.1  0.2 -0.1  3.7 -0.  -0.6 -0.7  2.  -0.2  0.1  3.2  4.  -0.7 -0.2 -0.3 -0.   1.5  3.6 -0.  -1.8 -0.4 -0.7  0.2  0.1 -0.9  1.8 -0.1 -1.5 -0.2 -0.4 -0.1  6.1 -0.3  0.1  0.2  0.5 -0.3  9.  -2.8 -0.9  1.5 -0.  -0.1 -0.3 -1.7  4.9  0.2 -0.1  0.5 -0.6 -0.1 -0.7 -0.2 -0.3 -0.1 -0.1 -0.2 -0.2 -2.5 -0.  -0.6 -0.2  2.6 -0.1 -0.2  0.1 -0.4 -0.4 -0.6 -0.5 -0.2 -0.2  0.2 -0.1 -0.2 -0.1  0.1 -0.3  0.7 -0.3 -0.4 -0.2 -0.2 -0.1 -0.2  5.1 -0.9  1.  -0.6 -0.1  1.8 -0.3 -0.1 -1.3 -0.6 -0.3  2.3 -0.6  0.1 -2.2 -0.  -0.2 -0.3 -0.9 11.3  8.8  3.5  2.6 -0.3 -0.1  0.9 -0.2 -0.1 -0.2 -0.1  5.  -0.2 -0.5  5.6 -0.6 -0.1 -0.4 -0.5 -0.3  1.5 -0.6 -0.7 -0.3 -0.2 -0.2 -0.3  0.6 -0.2 -0.4 -0.1  2.  -1.4 -0.6 -0.2 -0.3 -0.5 -0.9 -0.   4.  -0.5  1.2 -0.4  2.8  0.  20.1  0.1  7.8 -0.  -0.1 -2.3 -2.7 -0.3 -0.  -0.5 -0.3 -3.1  0.2  4.1 -0.1  3.1  5.4]
vy_50sample [[9 4 7 6 6 8 0 2 1 5]
 [3 6 7 8 1 5 9 4 0 2]
 [4 5 9 7 8 0 1 3 2 6]
 [2 6 5 1 8 3 9 0 7 4]
 [5 6 1 8 0 2 2 7 4 3]
 [5 5 3 0 2 8 7 4 4 6]
 [5 6 0 4 9 2 7 8 3 1]
 [8 0 4 2 5 1 9 6 3 7]
 [1 1 3 9 2 7 4 6 5 8]
 [1 5 6 3 3 8 8 7 4 9]]
vt_50sample [[9 4 7 6 3 8 0 2 1 5]
 [3 6 7 8 1 5 4 9 0 2]
 [4 5 7 9 8 1 0 3 2 6]
 [6 2 5 1 8 3 9 0 7 4]
 [5 6 1 8 0 9 2 7 4 3]
 [1 5 3 0 2 8 7 4 9 6]
 [5 6 0 4 9 2 7 8 3 1]
 [8 0 4 2 5 1 9 6 3 7]
 [0 1 3 9 2 7 4 6 5 8]
 [1 5 6 3 0 2 8 7 4 9]]
Epoch 29210: Training cost= 0.2445, Training acc= 0.8370, Validation cost= 0.2724, Validation acc= 0.8371
Epoch 29220: Training cost= 0.2483, Training acc= 0.8370, Validation cost= 0.2536, Validation acc= 0.8371
Epoch 29230: Training cost= 0.2660, Training acc= 0.8370, Validation cost= 0.3165, Validation acc= 0.8372
Epoch 29240: Training cost= 0.2823, Training acc= 0.8370, Validation cost= 0.3252, Validation acc= 0.8372
Epoch 29250: Training cost= 0.2517, Training acc= 0.8371, Validation cost= 0.2897, Validation acc= 0.8372
Epoch 29260: Training cost= 0.2573, Training acc= 0.8371, Validation cost= 0.2618, Validation acc= 0.8372
Epoch 29270: Training cost= 0.3205, Training acc= 0.8371, Validation cost= 0.3162, Validation acc= 0.8372
Epoch 29280: Training cost= 0.2753, Training acc= 0.8371, Validation cost= 0.2833, Validation acc= 0.8372
Epoch 29290: Training cost= 0.3150, Training acc= 0.8371, Validation cost= 0.2979, Validation acc= 0.8373
Epoch 29300: Training cost= 0.3086, Training acc= 0.8371, Validation cost= 0.2816, Validation acc= 0.8373
tm  [ 0.6  1.4  5.  -1.3 -1.5 -0.3 -0.1 -0.1 -1.8 -0.8  5.4 -0.1 -0.3  0.6  8.9 -0.4  0.7 -0.4 -0.6 -0.5 -0.9  0.  -1.1 -0.3 -1.2  0.6  0.2 -0.1 -0.9  7.5  3.9 -0.2  0.  14.4 -0.2  0.7  2.2 -1.3 -2.5 -0.3 -0.2  5.2  5.9 -0.3 -0.2 -0.3 -0.3  0.1  2.1 -2.6 -0.1  0.6 -0.7  1.9 -0.8 -0.9 -0.5  5.4 -2.4 -2.2 -0.4 -0.3 -0.7 -0.3 -0.2 -0.1  0.1 -0.5  1.6  0.3 -0.2  1.8 -0.2 -0.3 -3.4 -0.6 -0.1 -0.3 -0.2 -0.5 10.3 -0.4 -0.8 -0.3 -0.8  5.5  5.  -0.1  0.2 -0.2 -1.  -0.4 -0.3  6.6 -0.3 -0.4 -0.3 -1.4 -0.4 -0.4  3.2  4.9 -0.4  0.4 -0.3 -0.5 -2.4  2.2  0.4 -1.  -0.3 -0.3 -0.3 -0.3 -0.7 -0.3 -0.  -1.  -0.2 -0.4 -0.1  2.3 -0.1 -0.5 -0.  11.7 -0.1  0.4 -1.4  5.4  0.8 -0.1 -0.5 -0.1 -0.6 16.7  0.  -0.3 -1.  -0.9  1.  -0.3  1.   0.2 -0.3 -0.2 -0.1 -0.1  1.6 -0.3  0.8 -0.5 -0.2  1.  -0.4 -0.3 -0.5 -0.5 -1.7 -0.3 -0.2  1.7 -0.4 -0.1 -0.2 -0.  -0.5 -1.2 -0.1 -0.  -0.1  0.3 -0.  -0.7  0.5 -0.1 -1.3 -1.1  4.8 -0.3 -2.3  0.1 -0.2 -1.  -0.3 -0.3  0.7 -0.7 -0.3 -1.9 -0.1 -0.3 -0.1 -0.8  4.6  6.3 -0.9  2.  -0.1  0.1 -0.1 -0.4  0.  -0.4 -0.2 -2.6 -0.3 -0.4 -5.4 -0.4 -0.3 -1.2 -0.1 -0.8 -0.1 -0.2  1.7 -0.5  0.6 -0.9 -0.2 -0.3 -0.2 -0.8  1.8 -1.1 -1.2 -1.3 -1.4  0.9 -0.3  2.3 -0.1 -3.3 -0.  -0.7 -0.1 -1.2 -0.2 -3.6 -0.1 -1.6  0.2 -0.3 -1.9  2.2 -0.2 -0.8 -0.4 -0.2 -2.8  0.6 -1.8 -0.4  3.2 -0.9]
ty_50sample [[7 7 6 0 4 3 2 9 1 8]
 [1 4 3 7 6 8 9 2 0 5]
 [9 3 8 2 0 1 5 4 6 7]
 [5 7 9 9 1 6 3 4 8 2]
 [2 6 8 5 4 3 7 1 0 9]
 [3 0 1 6 7 5 2 4 9 8]
 [5 0 2 4 9 7 3 6 8 8]
 [0 0 3 1 9 6 7 8 4 5]
 [1 6 2 5 3 9 4 0 8 7]
 [7 6 9 5 8 0 4 1 2 3]]
tt_50sample [[5 7 6 3 4 0 2 9 1 8]
 [1 4 3 7 6 8 9 2 0 5]
 [9 3 8 2 0 1 5 4 6 7]
 [5 7 9 0 1 6 3 4 8 2]
 [2 6 8 5 4 3 7 1 0 9]
 [3 0 1 6 7 5 2 4 8 9]
 [5 0 2 4 9 7 3 6 8 1]
 [0 3 2 1 9 6 7 8 4 5]
 [1 6 2 5 3 4 9 0 8 7]
 [7 6 9 5 8 0 4 1 2 3]]
vm  [-0.3 -0.1  3.6  5.7 -1.6 -0.4 -0.4  0.1 -0.2 -1.  10.2  0.5 -0.2 -0.1  0.2  2.3 -0.1 -0.5  0.  -0.4 -1.  -0.2 -1.1 -0.2 -1.2  2.5 -0.2 -0.2 -1.  -2.3  2.  -0.3 -0.2  7.  -0.4 -0.1  1.5  4.3  5.5 -0.5  0.7  2.3  1.6  1.  -0.1 -0.   0.2 -0.4  2.7 -3.1 -0.6  0.3 -0.3  4.6 -0.4  1.2 -0.5  8.1  2.  -0.7  0.8 -0.4 -0.2  1.1  0.  -0.  -0.1 -0.1 -0.1  0.6 -0.1  0.9  0.5  0.  -2.4  0.4 -0.6 -0.2 -0.1 -0.1 10.8 -0.5 -0.3 -0.3 -0.6  3.3 -0.1 -0.2 -0.1 -0.4 -0.5 -0.3  0.4  0.2 -0.3 -0.1 -0.1 -2.1 -0.4 -0.8  3.9 -1.  -0.5  0.1 -0.2  0.3 -1.3  2.1  1.1 -0.8 -0.3 -0.1 -0.1 -0.4  1.   0.4  0.3 -0.1 -0.3 -0.1 -0.1  2.9 -0.1  0.1 -0.5  0.  -0.2 -0.6  5.1  3.5 -0.1 -0.4 -0.4 -0.7 -1.6  4.4 -0.3 -0.2 -0.1 -0.2 -0.5 -0.6 -0.4 -0.  -0.2  0.1 -0.1 -0.1  6.2 -0.2 -0.6 -0.1 -0.6 -0.6 -0.4 -0.1 -0.3 -0.4  3.2  0.1 -0.1 -1.3 -0.2  0.3 -0.2 -0.3 -0.1 -0.6  0.  -0.1 -0.2 -0.1 -0.1 -0.2 -0.2 -1.1 -0.2 -0.5 -0.3  0.1 -1.7 -0.3 -0.4 -1.6 -0.2 -0.1  1.4 -0.5 -0.4  7.2 -0.1 -0.  -0.4 -0.9  2.5 -1.4 -0.3 -0.3 -0.2 -0.1 -0.4 -0.1 -0.3 -0.4 -0.1 -1.6 -0.1 -0.1 -5.  -0.  -0.4 -0.4 -0.6  0.2 -0.6 -0.3 -0.  -0.8 -0.1 -0.7 -0.  -0.  -0.2 -1.  -1.3 -0.9  0.   0.3  0.2  3.1 -0.5 -0.3 -0.2 -2.9  1.9 -0.5  0.6 -0.4  0.3 -2.4 -0.1 -1.  -0.  -0.2 -2.  -0.5 -0.1 -0.4 -1.1 -0.  -2.9  0.1  3.8  0.1  1.4 -0.5]
vy_50sample [[5 2 3 0 9 7 1 4 6 8]
 [1 0 5 7 9 8 3 2 6 4]
 [4 0 7 9 8 1 3 6 5 2]
 [7 2 8 8 9 0 4 5 6 3]
 [7 5 0 8 3 6 1 4 2 9]
 [0 9 1 4 4 5 2 7 8 3]
 [8 7 9 1 4 3 0 5 6 2]
 [6 0 3 3 1 7 4 5 2 8]
 [5 0 4 1 2 8 8 7 3 3]
 [0 2 5 9 7 3 6 4 1 8]]
vt_50sample [[5 3 2 0 9 7 1 4 6 8]
 [1 0 5 7 8 9 3 2 6 4]
 [4 0 7 9 8 1 3 6 5 2]
 [7 2 1 8 9 0 4 5 6 3]
 [7 5 0 8 3 6 1 4 2 9]
 [0 1 9 4 6 5 2 7 8 3]
 [8 7 9 1 4 0 3 5 6 2]
 [6 9 0 3 1 7 4 5 2 8]
 [5 0 4 1 2 8 7 6 3 9]
 [0 2 5 9 7 3 6 1 4 8]]
Epoch 29310: Training cost= 0.2476, Training acc= 0.8372, Validation cost= 0.2482, Validation acc= 0.8373
Epoch 29320: Training cost= 0.2497, Training acc= 0.8372, Validation cost= 0.2822, Validation acc= 0.8373
Epoch 29330: Training cost= 0.2896, Training acc= 0.8372, Validation cost= 0.2627, Validation acc= 0.8373
Epoch 29340: Training cost= 0.2870, Training acc= 0.8372, Validation cost= 0.3063, Validation acc= 0.8374
Epoch 29350: Training cost= 0.2362, Training acc= 0.8372, Validation cost= 0.2532, Validation acc= 0.8374
Epoch 29360: Training cost= 0.2542, Training acc= 0.8372, Validation cost= 0.2671, Validation acc= 0.8374
Epoch 29370: Training cost= 0.3296, Training acc= 0.8373, Validation cost= 0.3161, Validation acc= 0.8374
Epoch 29380: Training cost= 0.2591, Training acc= 0.8373, Validation cost= 0.2926, Validation acc= 0.8374
Epoch 29390: Training cost= 0.3072, Training acc= 0.8373, Validation cost= 0.2886, Validation acc= 0.8374
Epoch 29400: Training cost= 0.2847, Training acc= 0.8373, Validation cost= 0.2559, Validation acc= 0.8375
tm  [-0.4  0.5 -3.  -0.7 -1.  -0.2 -0.  -0.1 -0.5 -0.6  7.6 -0.4 -0.1 -0.3 -1.5  4.5  0.5 -0.2 -0.4 -0.2 -0.9 -0.1  2.2 -0.2 -1.4  3.8 -0.2 -0.3 -0.9 -0.7  2.8 -0.7 -0.6 -2.3  0.2  0.9  3.8  5.9  3.7 -0.3  0.5  3.6  1.6  3.1 -0.3 -0.2 -0.1 -0.9  3.3  5.8 -0.6 -0.2  1.2  6.5 -0.6  2.  -0.4 -0.2 -0.2 -0.6 -0.2 -0.4  1.3  1.  -0.4 -0.1 -0.1 -0.2 -0.7  0.3 -0.2  1.3  0.3  0.1 -1.9 -0.3 -0.5 -0.2  0.1  0.2  1.8  0.   0.3 -0.1 -0.9  4.9  4.1 -0.3 -0.  -0.3 -0.2 -0.3 -0.2 -0.1 -0.3 -0.1 -0.1 -1.6 -0.2  0.2  1.9 -0.5 -0.9 -0.1 -0.3  1.8 -0.9  2.9  0.9 -1.  -0.5 -0.3 -0.  -0.4 -0.2 -0.  -0.3 -0.9 -0.2 -0.4 -0.1  2.6 -0.2 -0.1 -0.3 -1.8 -0.1 -1.4 -0.  -0.9  0.4 -0.3 -0.2 -0.2  6.2 -0.4 -0.3 -0.1 -0.1 -0.2 -0.9 -1.  -1.1  0.4 -0.3 -0.2 -0.3 -0.1  5.  -0.2  0.  -0.1  2.9 -0.6 -0.1  0.5 -0.3  0.1  1.5 -0.4  1.3 -0.7 -0.2 -0.1 -0.1 -0.3 -0.4 -0.4  0.4 -0.2 -0.2 -0.3 -0.2 -0.1 -0.2 -1.3 -0.3  0.8 -0.1  0.  -1.1  0.1 -0.6 -1.7 -0.3 -0.3  1.8  0.8 -0.3  2.2 -0.  -0.4 -0.1 -0.8  4.2  0.7  0.6 -0.1 -0.  -0.2 -0.1 -0.1 -0.3 -0.4 -0.2 -0.5 -0.2  0.5 -0.4 -0.  -0.2 -0.3 -0.7  0.7 -0.4 -0.3 -0.9 -0.9 -0.8 -0.1 -0.1 -0.1 -0.3 -1.   2.3  0.4  2.8  1.2 -0.2  1.3 -0.5 -0.7 -0.1 -0.   1.5  6.   0.1 -0.3  0.2  0.2 -0.1  0.1 -0.1  0.1  0.6 -1.1 -0.4  0.3 -0.9 -0.2 -0.9 -0.1  2.7 -0.2 -1.7  5. ]
ty_50sample [[2 4 5 0 9 8 6 1 3 7]
 [5 3 0 8 7 4 6 1 1 2]
 [3 2 4 9 0 5 7 1 8 6]
 [1 9 5 7 3 6 4 8 0 2]
 [9 3 5 8 6 0 1 7 4 2]
 [9 0 5 7 8 2 1 6 4 3]
 [4 2 7 8 6 0 9 3 5 1]
 [5 8 0 9 6 2 7 4 1 3]
 [3 8 5 7 9 4 2 6 0 1]
 [0 7 4 2 1 9 5 8 6 3]]
tt_50sample [[2 4 5 0 9 8 6 1 3 7]
 [5 3 0 8 7 4 6 9 1 2]
 [3 2 4 9 0 5 7 1 8 6]
 [1 9 5 7 3 4 6 0 8 2]
 [9 3 5 8 6 0 1 7 4 2]
 [0 9 5 7 8 2 1 6 4 3]
 [2 4 7 8 6 0 9 3 5 1]
 [5 8 0 9 6 2 7 4 1 3]
 [3 8 5 7 9 4 2 6 0 1]
 [0 7 2 4 1 9 5 8 6 3]]
vm  [ 0.  -0.9 -2.3 -2.8 -0.5 -0.4 -0.3 -0.3  0.9  1.7  5.2 -0.7 -0.1 -0.1  0.5  3.7 -0.1 -0.3 -0.3 -0.5 -1.   0.4  1.5 -0.4 -0.9  0.6 -0.2 -0.1 -0.4 -1.   1.3 -0.2 -0.4 -3.1 -0.  -0.8 -0.3  4.2 -0.3 -0.3 -0.5  1.4 -1.3  1.9 -0.4 -0.2 -0.1 -0.9  1.5 12.5 -0.5 -0.2 -0.8 10.7 -0.5  0.6 -0.5 -2.7  6.8  0.8  0.3 -0.2 -0.5 -0.3 -0.4 -0.5 -0.4  2.2  0.6 -0.5 -0.3 -0.4  0.6 -0.2 -4.4 -0.  -0.8 -0.1 -0.3 -0.3 -3.3 -0.2 -0.1  0.9 -1.   0.9  4.  -0.  -0.2 -0.3 -0.2 -0.3 -0.3 -1.3 -0.4 -0.  -0.4 -2.3 -0.2 -1.  -0.8  4.9 -0.6 -0.1 -0.1 -0.1 -2.3  1.4  1.  -0.5  1.7 -0.  -0.1 -0.7  3.8 -0.  -0.1  0.4  0.2  0.8 -0.5 -0.   0.4 -0.2 -0.2  0.7 -0.6 -2.6  2.9 -0.8  2.5 -0.7 -0.2 -0.3  5.2 -2.  -0.2 -0.4 -0.  -0.1 -1.6 -0.7 -0.9  0.4 -0.2 -0.1 -0.4 -0.2 -0.6 -0.3  1.5 -0.2  3.5 -0.2 -0.1  0.4 -0.4 -0.4 -0.4 -0.1  0.4 -0.6  0.7 -0.1 -0.3 -0.1 -0.2  2.4 -0.2 -0.  -0.1 -0.3 -0.2 -0.4 -0.2  1.9 -0.5 -0.3  1.2 -0.1  2.2 -0.4 -0.2 -1.1 -0.1  0.4  1.9 -0.4 -0.3  3.  -0.1 -0.3 -0.6 -0.6  2.8 -1.1 -1.  -1.1 -0.1 -0.2 -0.2 -0.1 -0.3 -0.2 -0.5 -2.5  0.  -0.2  8.9  0.3 -0.2 -0.3 -0.9 -0.7 -0.1  0.1 -0.7 -0.8 -0.3 -0.2 -0.2 -0.5 -0.2 -1.2  4.8  1.   1.6  1.3 -0.1  3.1 -0.9  1.4 -0.1  4.3 -0.5  4.4  2.8 -1.8  0.5  6.4 -0.1  3.  -0.2  0.1 10.5 -0.1  2.2 -0.5 -0.8 -0.2  8.  -0.2 -0.1 -0.4 -2.2  5.5]
vy_50sample [[2 4 8 0 6 9 7 1 3 5]
 [6 3 7 9 0 1 4 2 5 8]
 [9 4 8 0 3 7 6 5 1 2]
 [4 3 1 6 0 8 2 7 5 9]
 [0 2 6 1 8 3 4 5 7 9]
 [3 5 2 7 4 9 0 1 8 6]
 [8 5 3 3 1 6 6 9 4 2]
 [8 2 6 5 3 9 4 7 0 1]
 [8 1 9 3 6 0 7 5 2 4]
 [1 2 3 5 8 9 6 4 7 0]]
vt_50sample [[2 4 8 0 6 9 7 1 5 3]
 [6 3 7 9 0 1 4 2 5 8]
 [9 4 8 0 3 7 6 5 1 2]
 [4 3 1 6 8 0 2 7 9 5]
 [0 2 6 1 8 3 4 5 7 9]
 [3 5 2 7 4 9 0 1 8 6]
 [8 5 3 7 0 1 6 9 4 2]
 [8 2 6 5 3 9 4 7 0 1]
 [8 1 9 3 6 0 7 5 2 4]
 [1 2 3 5 8 9 6 4 7 0]]
Epoch 29410: Training cost= 0.3251, Training acc= 0.8373, Validation cost= 0.3149, Validation acc= 0.8375
Epoch 29420: Training cost= 0.2590, Training acc= 0.8373, Validation cost= 0.3014, Validation acc= 0.8375
Epoch 29430: Training cost= 0.3353, Training acc= 0.8374, Validation cost= 0.2795, Validation acc= 0.8375
Epoch 29440: Training cost= 0.2933, Training acc= 0.8374, Validation cost= 0.2622, Validation acc= 0.8375
Epoch 29450: Training cost= 0.2980, Training acc= 0.8374, Validation cost= 0.2608, Validation acc= 0.8375
Epoch 29460: Training cost= 0.2742, Training acc= 0.8374, Validation cost= 0.2536, Validation acc= 0.8376
Epoch 29470: Training cost= 0.2678, Training acc= 0.8374, Validation cost= 0.3220, Validation acc= 0.8376
Epoch 29480: Training cost= 0.2070, Training acc= 0.8374, Validation cost= 0.2680, Validation acc= 0.8376
Epoch 29490: Training cost= 0.2987, Training acc= 0.8375, Validation cost= 0.2612, Validation acc= 0.8376
Epoch 29500: Training cost= 0.2628, Training acc= 0.8375, Validation cost= 0.3110, Validation acc= 0.8376
tm  [ 4.1 -0.9 -0.1  2.2 -0.8  0.1 -0.7 -0.3  0.   2.1 -1.2 -0.1 -0.1 -0.2 -0.1 -0.3 -0.2 -0.3 -0.2 -0.6 -1.1 -0.   0.9  0.5 -0.8  0.1 -0.2 -0.2 -1.2 -2.  -1.7 -0.3 -0.3 -5.1  1.  -0.3 -0.1  4.6  1.6 -0.4  0.6  3.4 -0.3  1.1 -0.7 -0.4  0.2 -0.6  3.8  8.6 -0.5 -0.2 -1.3  7.4  0.6  1.  -0.9  5.8  3.9  5.4 -0.5 -0.4 -0.6 -0.3 -0.2 -0.6 -0.2  2.1  1.7 -0.8 -0.5  3.3 -0.5 -0.8 -4.6 -0.4 -1.2  0.2 -0.1 -0.4 -4.7  0.7 -0.4  0.3 -1.7  2.7  3.  -0.2  0.2 -0.5  0.4 -0.1 -0.2 -0.2 -0.4 -0.  -0.3 -2.5 -0.1 -0.7 -0.9 -0.8 -1.6 -0.3  0.4 -0.7 -2.3 -1.1 -0.3 -0.1  1.2 -0.4 -0.1 -0.3  3.7 -2.4 -0.   1.3 -0.   0.7 -0.1 -0.3 -0.2 -0.9 -0.4 -0.2 -0.7 -1.6  3.5  3.3  1.9 -0.5 -0.1  0.   2.7 -4.9 -0.   0.  -0.2 -0.3 -1.  -1.2 -0.8 -0.2 -0.  -0.7 -0.2  0.1  6.2 -0.3 -0.6 -0.2  5.8 -0.2  0.1 -0.4  1.2 -0.9 -0.1 -0.  -0.6 -1.8  0.2 -0.1 -0.1 -0.2 -0.2 -0.8 -0.5  0.1 -0.4 -0.2  0.   0.3 -0.1 -1.4 -0.8 -0.8 -0.1 -0.3 -1.6 -0.7 -0.  -1.2 -0.2  0.8  4.7 -0.1 -0.3  6.6 -0.4 -0.4 -0.4 -1.   6.7 -1.2 -1.8 -0.6 -0.3  0.1 -0.2 -0.3 -0.3 -0.2 -0.7 -2.7 -0.3 -0.5  3.1 -0.3 -0.4 -1.6 -0.6 -2.5 -0.5 -0.2  0.1 -0.8 -0.5 -0.6 -0.2 -0.3 -0.2 -1.5 -0.8 -0.7 -0.4 -0.3 -0.5  3.9 -0.9  3.1 -0.4  1.6 -0.3  1.1  4.  -1.9  1.  -3.3 -0.2 -1.3 -0.2  0.  14.2  0.7  2.4 -0.9 -0.7  0.4 11.9 -0.2  1.9 -0.   0.2 -0.2]
ty_50sample [[8 0 5 2 3 9 4 6 7 1]
 [1 6 3 5 0 2 4 9 7 8]
 [5 8 0 2 1 3 3 4 6 7]
 [5 9 8 8 0 4 3 6 7 1]
 [6 4 7 0 3 2 5 9 1 8]
 [5 8 1 0 4 9 3 7 2 6]
 [2 3 5 6 8 9 1 0 7 4]
 [6 4 1 2 3 5 7 8 9 0]
 [2 0 4 3 1 6 5 8 7 9]
 [5 1 9 0 8 2 3 7 4 6]]
tt_50sample [[8 0 5 2 3 9 4 6 7 1]
 [1 6 3 5 0 2 4 9 7 8]
 [5 8 0 2 1 9 3 4 6 7]
 [5 9 8 2 0 4 3 6 7 1]
 [6 4 7 0 3 2 5 1 9 8]
 [5 8 1 0 4 9 3 7 2 6]
 [2 3 5 6 8 9 1 0 7 4]
 [6 4 1 2 3 5 7 8 9 0]
 [2 0 4 3 1 6 5 8 7 9]
 [5 1 9 0 8 2 3 7 4 6]]
vm  [-0.8 -0.3  9.3 14.1 -1.3 -0.2  0.1 -0.2 -0.5 -0.3  2.3 -0.2 -0.3 -0.1  2.7  4.7 -0.5  0.4  0.1 -1.1 -0.8 -0.4  1.2  0.4 -0.5  1.1 -0.4 -0.1 -0.2  1.1 -1.3 -0.4 -0.   4.1 -0.3 -0.3  1.1  3.7  8.1 -0.3 -0.3 -1.5 -0.4 -0.5 -0.3 -0.4  7.5 -0.6 -0.1  7.6 -0.6 -0.  -0.1  0.3 -1.2 -0.1 -0.  -0.6  0.1  4.7 -0.6 -0.3 -0.4 -0.3 -0.4 -0.4  0.1  0.9  0.6 -0.5 -0.3 -1.3  0.9 -0.3 -0.1  0.  -0.5 -0.4 -0.1 -0.1  1.9 -0.5  0.1  0.9 -0.4 -1.2 -1.2 -0.3 -0.3 -0.3  1.7 -0.1 -0.1 -0.4 -0.3 -0.1 -0.3 -0.8 -0.5 -0.6  0.4  6.7 -0.3 -0.2 -0.1 -0.2 -0.2 -0.9  1.6 -1.7  1.3 -0.1  0.2 -0.3 -0.2  4.7 -0.6 -0.7  0.6 -0.3 -0.3  4.9 -0.1  0.2 -0.1  2.5 -0.2  2.  -0.8 -1.7 -0.  -0.6 -0.1 -0.3 -2.9 -1.9  0.2 -0.1  1.1 -0.7 -1.1 -0.7 -1.   0.2 -0.1  0.5 -0.2 -0.2 -3.2 -0.3 -1.2 -0.1  2.2 -0.1  0.1  0.5 -0.2 -0.3 -0.   0.2 -0.1 -0.6  0.7 -0.1 -0.1 -0.3  0.   2.1 -0.3 -0.1 -0.4 -0.5  0.2  0.3 -0.4  5.3 -0.6  0.5 -0.9 -0.1  3.2 -0.2 -0.  -1.  -0.6 -0.2  0.8 -0.5 -0.1 -0.2 -0.2 -0.4 -0.8 -0.5  5.9  2.3  1.4  0.3 -0.4 -0.1 -0.3 -0.  -0.3 -0.4 -0.2  2.4 -0.1  0.1  9.7 -0.2 -0.4  2.5 -0.9  2.  -0.4 -0.3  3.2 -0.4 -0.2 -0.1 -0.4 -0.3 -0.2 -0.7  1.8  2.6 -0.   2.3  1.5  0.  -0.7 -0.6 -0.1  4.3 -0.8 -2.2  0.8  0.5  1.2 19.2 -0.2  7.6 -0.2 -0.2  0.2 -2.6 -0.3 -0.2 -0.9 -0.2 -0.8 -0.   5.8 -0.1 -0.8  8.3]
vy_50sample [[7 9 2 8 1 6 3 0 4 5]
 [6 4 8 5 9 1 7 2 0 3]
 [0 2 7 6 8 4 1 3 3 5]
 [6 1 4 7 0 5 2 9 8 3]
 [2 4 5 1 8 9 6 3 0 7]
 [4 8 1 5 6 0 2 9 7 3]
 [2 9 4 6 7 1 5 0 3 8]
 [9 9 4 1 8 3 6 7 2 5]
 [7 9 5 4 0 6 1 2 3 8]
 [0 0 3 1 6 6 7 8 5 9]]
vt_50sample [[7 9 2 8 1 6 3 0 4 5]
 [6 4 8 5 9 1 7 2 0 3]
 [0 2 7 6 8 4 1 3 9 5]
 [6 1 4 7 0 5 2 9 8 3]
 [2 4 5 1 8 9 6 0 3 7]
 [4 8 1 5 6 0 2 9 7 3]
 [2 9 4 6 7 1 0 5 3 8]
 [9 0 4 1 8 3 6 7 2 5]
 [7 9 5 4 0 6 1 2 3 8]
 [2 0 3 1 6 4 7 8 5 9]]
Epoch 29510: Training cost= 0.2889, Training acc= 0.8375, Validation cost= 0.2815, Validation acc= 0.8377
Epoch 29520: Training cost= 0.3009, Training acc= 0.8375, Validation cost= 0.2584, Validation acc= 0.8377
Epoch 29530: Training cost= 0.2391, Training acc= 0.8375, Validation cost= 0.2539, Validation acc= 0.8377
Epoch 29540: Training cost= 0.3265, Training acc= 0.8376, Validation cost= 0.2624, Validation acc= 0.8377
Epoch 29550: Training cost= 0.2907, Training acc= 0.8376, Validation cost= 0.3132, Validation acc= 0.8377
Epoch 29560: Training cost= 0.2946, Training acc= 0.8376, Validation cost= 0.3144, Validation acc= 0.8377
Epoch 29570: Training cost= 0.3204, Training acc= 0.8376, Validation cost= 0.2532, Validation acc= 0.8378
Epoch 29580: Training cost= 0.2436, Training acc= 0.8376, Validation cost= 0.3061, Validation acc= 0.8378
Epoch 29590: Training cost= 0.2157, Training acc= 0.8376, Validation cost= 0.2931, Validation acc= 0.8378
Epoch 29600: Training cost= 0.2731, Training acc= 0.8377, Validation cost= 0.2728, Validation acc= 0.8378
tm  [-0.4 -0.4 -2.3  4.1 -0.8 -0.  -0.2 -0.3 -0.5  0.2  6.  -0.5 -0.3 -0.2 -2.4 -0.4  0.4 -0.4 -0.4 -1.2 -1.1 -0.2  0.4 -0.2 -0.8  2.8 -0.1 -0.3 -1.7 -2.1  1.5 -0.2 -0.8 -2.6  1.1 -0.   3.5  5.1 11.3 -0.5 -0.1 -2.1 -0.6  2.9 -0.2  0.1  6.2 -0.6  2.6  1.6 -0.3 -0.1 -0.1  2.2  2.   3.3 -0.4 -2.6  3.1 -0.1 -1.   0.4 -0.5  1.5 -0.4  1.  -0.2 -0.3 -0.3  1.1 -0.2  4.7 -0.4 -0.2 -0.3 -0.3 -0.7 -0.1 -0.  -0.   6.2  0.4 -0.3  0.1 -0.7 -2.4  3.7 -0.2 -0.  -0.1 -0.1 -0.4  0.2 -0.4 -0.3 -0.2 -0.3 -1.  -0.2 -0.2 -0.3 -1.1 -0.6 -0.2 -0.1  0.7 -0.1  1.8  1.5 -2.2 -0.3 -0.2 -0.2  0.1  4.2 -2.5 -0.2 -0.3 -0.1 -0.1  0.3  7.9 -0.3 -0.1 -0.2 -3.  -0.4 -0.1  0.6 -0.6  0.7 -0.2 -0.3 -0.1  3.8 -1.8 -0.5 -0.2 -0.2 -0.3 -0.9 -1.2 -1.2 -0.1 -0.1 -0.3 -0.3  0.3 -0.5 -0.1 -0.4 -0.2  2.1 -0.4 -0.3 -0.  -0.2 -0.   0.6 -0.4  0.2 -1.3 -0.4 -0.  -0.3 -0.1 -0.6  0.1 -0.  -0.2 -0.3 -0.4  0.4 -0.1  0.   1.5  1.6  0.1 -1.3 -0.1  2.3  0.  -0.4 -0.9  0.2  0.6  1.5  0.1  0.4  6.2 -0.1 -0.2 -0.5 -0.6  8.3 -0.   0.4 -0.6  0.2 -0.   0.2  0.9 -0.3 -0.3 -0.1  1.1 -0.3 -0.1  8.2  0.4 -0.2 -1.7 -0.7 -0.4 -0.4 -0.2 -1.  -0.8 -0.8 -0.4 -0.2 -0.2 -0.1 -1.  -0.5 -0.9  0.9  0.2 -0.1  1.4 -0.9 -0.8 -0.2  3.8  3.6  4.8  1.1  1.3  1.1 20.2 -0.2  8.8 -0.1 -0.1 -0.8 -1.6  0.4 -0.2 -1.  -0.4 -1.8 -0.2  7.6 -0.3 -0.7  4.2]
ty_50sample [[0 2 9 4 8 8 1 6 7 5]
 [4 5 0 6 8 3 9 2 1 7]
 [2 3 1 8 5 9 7 0 4 6]
 [4 7 2 1 6 8 9 3 5 0]
 [9 8 1 4 2 5 7 0 3 6]
 [5 0 7 8 2 1 4 6 3 9]
 [7 2 6 8 9 3 0 1 5 4]
 [4 7 8 0 0 2 6 3 1 5]
 [3 3 2 9 4 1 7 6 8 0]
 [7 6 0 8 1 2 9 3 5 4]]
tt_50sample [[0 2 9 4 8 3 1 6 7 5]
 [4 5 0 6 8 3 9 2 1 7]
 [2 3 1 8 5 9 0 7 4 6]
 [4 7 2 1 6 8 9 3 5 0]
 [9 8 4 1 2 5 7 0 3 6]
 [5 7 8 0 2 1 4 3 6 9]
 [7 2 6 8 9 3 0 1 5 4]
 [4 7 8 9 0 2 6 3 1 5]
 [5 3 2 9 4 1 7 6 8 0]
 [7 6 0 8 1 2 9 3 5 4]]
vm  [-1.6  1.5 -3.8  2.2 -0.6 -0.1 -0.5  0.2 -1.1 -0.8 -1.7  0.8 -0.2 -0.3 -3.8  3.7 -0.7 -0.2 -0.  -1.9 -0.2 -0.5  0.7 -0.  -1.2 -0.4 -0.6 -0.3  1.8  2.4  2.6 -0.4  1.6 -3.7 -0.7  0.4  3.6 -0.8  3.2 -0.5  0.4  0.8  0.7  0.8 -0.3 -0.2  9.4 -0.1 -2.1  4.3 -0.6 -0.3 -0.2 -2.5 -2.1  4.8 -0.7 -0.8 -1.1 -0.6  1.7 -0.5 -0.4 -1.  -0.5 -0.3 -0.  -0.4 -0.2 -0.2 -0.1 -2.1 -0.1 -0.3  4.2 -0.2  0.6 -0.1 -0.3 -0.2  9.1 -0.3 -0.6 -0.6  2.1  2.9 -0.8 -0.3 -0.2 -0.9 -0.7  0.9 -0.2  1.6 -0.3 -0.3 -0.5  1.6 -0.3  0.3  3.1 -1.1  2.2  0.1  0.1 -0.4 -0.2  2.6 -0.5 -2.3 -0.3 -0.4  0.4 -0.  -1.4 12.1  0.2 -1.6 -0.4 -0.4 -0.2  7.8 -0.6 -0.3 -0.4 -4.6  1.1 10.4 -1.2 -2.2 -1.2 -0.3 -0.4 -0.2 12.1  6.4 -0.1 -0.2 -0.4 -1.3 -0.1 -0.2 -0.2 -0.5 -0.3 -0.2 -0.7 -0.2  5.9 -0.1 -0.5 -0.2 -1.2 -0.5  0.2 -0.1 -0.1 -0.5 -0.7 -0.4 -0.6 -0.1 -0.4  0.1 -0.4 -0.1 -0.2  0.2 -0.6 -0.2 -0.2 -0.4 -0.4 -0.3 -0.  -1.5 -1.7  0.5 -0.1 -0.4 -1.5 -0.   2.1 -1.2 -0.6  0.5 -1.5  1.3 -0.2 -0.6 -0.4 -0.3 -0.4 -1.1 -0.1  4.4  2.6  3.2 -0.3 -0.2 -0.  -0.2  0.4 -0.2 -0.3  4.1 -0.3 -0.3  0.1 -0.2 -0.   1.7 -0.1  6.8  1.5 -0.4 -0.4 -0.1 -0.4 -0.1 -0.  -0.3 -0.4 -0.9  1.   4.8 -1.5 -0.4 -0.5 -1.2 -0.6 -0.2 -0.2 -0.1 -1.4  4.9 -1.1  1.6 -0.7  8.1 -0.1  3.1 -0.4  0.4 -1.5 -2.3 -0.1 -0.  -0.5  0.3 -2.3  0.3  1.8  0.2  1.3  9.5]
vy_50sample [[1 9 4 6 5 8 3 2 7 0]
 [2 0 3 9 5 8 7 4 6 1]
 [2 5 6 1 1 7 7 0 4 8]
 [3 4 8 7 5 9 2 6 6 0]
 [0 7 9 1 4 2 3 6 5 8]
 [2 7 1 0 9 8 3 5 4 6]
 [1 3 6 8 9 5 7 0 2 4]
 [7 0 1 5 2 9 9 6 8 4]
 [1 5 7 4 2 0 6 9 9 8]
 [1 7 3 5 4 9 9 8 0 6]]
vt_50sample [[1 9 4 6 5 8 3 2 7 0]
 [2 0 3 9 5 8 7 4 6 1]
 [2 5 6 1 9 3 7 0 4 8]
 [3 4 8 7 5 9 2 1 6 0]
 [0 7 1 9 4 2 3 6 5 8]
 [2 7 1 0 9 8 3 5 4 6]
 [1 3 6 8 9 5 7 0 2 4]
 [7 0 1 5 2 9 3 6 8 4]
 [1 5 7 4 2 0 6 3 9 8]
 [1 7 3 5 4 2 9 0 8 6]]
Epoch 29610: Training cost= 0.2266, Training acc= 0.8377, Validation cost= 0.2756, Validation acc= 0.8378
Epoch 29620: Training cost= 0.2476, Training acc= 0.8377, Validation cost= 0.2645, Validation acc= 0.8378
Epoch 29630: Training cost= 0.3213, Training acc= 0.8377, Validation cost= 0.2841, Validation acc= 0.8379
Epoch 29640: Training cost= 0.2312, Training acc= 0.8377, Validation cost= 0.2686, Validation acc= 0.8379
Epoch 29650: Training cost= 0.2814, Training acc= 0.8378, Validation cost= 0.2404, Validation acc= 0.8379
Epoch 29660: Training cost= 0.2326, Training acc= 0.8378, Validation cost= 0.2446, Validation acc= 0.8379
Epoch 29670: Training cost= 0.2580, Training acc= 0.8378, Validation cost= 0.2357, Validation acc= 0.8379
Epoch 29680: Training cost= 0.3285, Training acc= 0.8378, Validation cost= 0.2794, Validation acc= 0.8380
Epoch 29690: Training cost= 0.3721, Training acc= 0.8378, Validation cost= 0.3211, Validation acc= 0.8380
Epoch 29700: Training cost= 0.3245, Training acc= 0.8378, Validation cost= 0.2788, Validation acc= 0.8380
tm  [-0.9 -0.2  7.7 -0.3 -2.  -0.4 -0.5 -0.  -1.1 -0.8  5.9 -0.  -0.1 -0.2  9.6  0.2 -0.2 -0.1  2.2  1.9 -0.7 -0.1  0.3 -0.1 -1.9  5.3 -0.4 -0.1 -1.6 -0.7 -0.1 -0.2 -0.7  8.3 -0.1  0.9  4.3  5.   1.2 -0.9 -0.   1.1  3.2  1.3 -0.1 -0.3 -1.5 -0.5  0.1  0.5 -0.9 -0.1 -0.2  7.4  0.3 -0.9 -0.8  4.3 -0.5  2.7  5.4  0.2 -0.2  0.8 -0.2  0.4 -0.2 -0.7  2.1  0.2  0.5  5.2  0.5  0.9 -3.2  1.1 -0.1 -0.2 -0.2  0.5 -1.  -0.4  0.9  0.7 -0.   3.  -0.6 -0.2 -0.1 -0.2 -0.7 -0.4 -0.4  1.  -0.2  0.   1.4 -2.3 -0.8 -0.2  3.6  6.5 -0.3  0.1 -0.3 -0.  -1.7 -0.   1.2  1.  -0.6 -0.1 -0.1  0.2  0.6 -1.6  0.3 -0.9 -0.2  0.   0.4 -0.3  0.3  0.1 -0.1 11.4 -0.4 -1.6 -0.4  4.5 -0.5 -0.3 -0.5 -0.6 -5.1 -1.2 -0.1 -0.1 -0.3 -0.3 -0.6 -1.5 -0.2 -0.2 -0.4  0.   0.1 -0.3 -1.2 -0.2 -0.2 -0.  -0.1 -0.2 -0.4 -0.1 -0.2 -0.4  4.2 -0.3  1.7 -1.4  0.1 -0.1 -0.2 -1.2 -0.3 -0.6 -0.3 -0.1 -0.2 -0.4  0.3 -0.5 -0.1  2.  -0.1 -0.2  0.7 -0.1 -0.9 -0.3 -0.2 -1.6 -0.2 -0.1 -0.3 -0.3 -0.   1.8  0.1 -0.4  0.2 -0.8 -1.3  2.8 -0.8 -0.1  0.1 -0.1 -0.2 -0.2 -0.2 -0.2 -0.1 -2.6  0.4 -0.1 -0.6 -0.1 -0.6 -1.7 -0.3  3.  -0.9 -0.  -0.2 -0.5  0.6 -0.5 -0.2 -0.2 -0.2 -0.8 -0.4 -1.   0.2  0.5  0.7 -0.2 -0.2  0.2 -0.2 -0.4  3.7 -1.9  0.7 -0.7 -0.1 -1.9 -0.  -0.6  0.  -0.1  5.3  1.8  0.2 -0.  -0.4 -0.6  2.3 -0.1  1.  -0.1 -0.6 -0.9]
ty_50sample [[7 0 2 1 5 3 8 4 6 9]
 [3 0 8 4 2 9 1 6 5 7]
 [6 5 2 9 8 4 4 0 3 1]
 [8 0 2 7 4 3 6 5 9 1]
 [1 7 9 6 5 3 0 8 4 2]
 [3 0 8 5 7 2 9 6 1 4]
 [5 6 4 1 8 2 3 9 0 7]
 [9 9 6 4 8 5 3 7 1 2]
 [9 7 5 3 1 0 0 4 8 6]
 [9 4 7 2 3 1 0 6 5 8]]
tt_50sample [[7 0 2 1 5 3 8 4 6 9]
 [3 0 8 4 2 9 1 6 5 7]
 [6 5 2 9 8 7 4 0 3 1]
 [8 0 2 7 4 3 6 5 9 1]
 [1 7 9 6 5 3 0 8 4 2]
 [3 0 8 5 7 2 9 6 1 4]
 [5 6 4 1 8 2 3 9 7 0]
 [9 0 6 4 8 5 3 7 1 2]
 [9 7 5 3 1 2 0 4 8 6]
 [9 4 7 2 3 1 0 6 8 5]]
vm  [-0.6  0.4 -1.8 -1.4 -1.  -0.2 -0.4 -0.3 -0.7 -1.  -2.7  0.3 -0.2 -0.1  0.5  3.5  0.  -0.3 -0.4  0.3 -0.7 -0.1  0.8 -0.  -1.1  0.6 -0.1 -0.5  0.5 -0.7 -0.5 -0.5 -0.3 -4.2 -0.6  0.2  1.3  3.1  2.  -0.4  0.8  1.4  2.4  3.6 -0.2 -0.1 -1.3 -0.1  0.6  2.7 -0.8 -0.2 -0.4  3.5 -1.4  0.5 -0.5  4.6 -0.1  2.8  2.9 -0.2 -0.  -0.2 -0.6 -0.7 -0.1 -0.2 -0.3 -0.  -0.  -1.2 -0.  -0.  -4.4 -0.3 -0.6 -0.1 -0.3 -0.2 -4.1 -0.  -0.3 -0.1 -1.   2.6  1.3 -0.1  0.4 -0.6 -0.1  0.   0.2  1.8 -0.5 -0.  -0.2 -2.2 -0.2 -0.2  3.7 -2.  -0.2 -0.1 -0.3 -0.1 -2.1 -0.5 -1.  -0.1 -0.1 -0.3  0.2 -0.8 -0.8  7.9 -0.3 -0.5 -0.1 -0.4  0.2 -0.4 -0.3 -0.6 -0.4  0.6 -0.  -0.3  2.3  8.6 -0.2 -0.5 -0.  -0.2  0.1 -4.2 -0.2 -0.1 -0.2 -0.   0.1 -0.6 -0.3 -0.   0.1 -0.1 -0.  -0.   8.2  0.2  0.6 -0.2  2.8 -0.1 -0.2 -0.  -0.4 -0.6  3.1 -0.5 -0.  -1.4  0.  -0.2  0.5 -0.1 -0.4 -0.4  0.9 -0.1  0.3  0.6 -0.3 -0.2 -0.2 -1.7 -0.1 -0.3  0.3 -0.6 -1.9 -0.3 -0.6 -1.5 -0.5 -0.2  0.4 -0.1 -0.4  2.8 -0.3 -0.2 -0.1 -1.3 -0.6 -0.5 -0.7  1.  -0.4 -0.2  0.1  0.  -0.2 -0.2 -0.2 -2.5 -0.2 -0.3 -0.3 -0.3 -0.5  2.6 -0.5  2.1 -0.3 -0.1 -1.1 -0.5 -0.4 -0.3 -0.4  0.  -0.3 -1.  -1.9  3.6 -1.1 -0.3 -0.8  1.2 -0.6  1.9 -0.4 -0.2 -0.9  3.7 -0.2 -1.2  0.5 -4.  -0.3 -1.6 -0.1 -0.2 12.9  1.  -0.2 -0.3 -0.7 -0.3  9.7 -0.2  1.1 -0.1  4.5 -2. ]
vy_50sample [[5 8 3 4 1 2 9 7 6 0]
 [3 9 6 8 5 0 0 7 2 4]
 [6 1 2 5 0 0 8 3 9 4]
 [9 7 3 2 4 8 1 6 0 5]
 [8 3 0 2 1 5 6 9 7 4]
 [5 1 4 7 6 8 0 3 2 9]
 [2 0 6 1 5 8 4 9 7 3]
 [4 0 2 7 8 1 3 5 9 6]
 [9 0 1 1 4 6 8 5 2 3]
 [2 4 1 5 3 7 0 0 9 8]]
vt_50sample [[5 8 3 4 1 2 9 7 6 0]
 [3 9 6 8 5 0 7 1 2 4]
 [6 1 2 5 7 0 3 8 9 4]
 [7 9 3 2 4 8 1 0 6 5]
 [8 3 0 2 1 5 6 9 7 4]
 [5 1 4 7 6 8 0 3 2 9]
 [2 0 6 1 5 8 4 9 7 3]
 [4 0 2 7 8 1 3 5 9 6]
 [9 0 7 1 4 6 8 5 2 3]
 [2 4 1 5 3 7 6 0 9 8]]
Epoch 29710: Training cost= 0.3917, Training acc= 0.8379, Validation cost= 0.2976, Validation acc= 0.8380
Epoch 29720: Training cost= 0.2936, Training acc= 0.8379, Validation cost= 0.2994, Validation acc= 0.8380
Epoch 29730: Training cost= 0.2461, Training acc= 0.8379, Validation cost= 0.2880, Validation acc= 0.8380
Epoch 29740: Training cost= 0.2606, Training acc= 0.8379, Validation cost= 0.3054, Validation acc= 0.8380
Epoch 29750: Training cost= 0.3023, Training acc= 0.8379, Validation cost= 0.3016, Validation acc= 0.8381
Epoch 29760: Training cost= 0.3115, Training acc= 0.8379, Validation cost= 0.2861, Validation acc= 0.8381
Epoch 29770: Training cost= 0.2608, Training acc= 0.8380, Validation cost= 0.2623, Validation acc= 0.8381
Epoch 29780: Training cost= 0.2708, Training acc= 0.8380, Validation cost= 0.2657, Validation acc= 0.8381
Epoch 29790: Training cost= 0.3125, Training acc= 0.8380, Validation cost= 0.2832, Validation acc= 0.8381
Epoch 29800: Training cost= 0.2752, Training acc= 0.8380, Validation cost= 0.3181, Validation acc= 0.8382
tm  [ 1.3 -0.7  3.2 -0.9 -1.5 -0.1 -0.3 -0.  -0.2 -0.4  7.  -0.2  0.3 -0.1  6.7  1.6 -0.2 -0.9 -0.1 -0.8 -1.   0.5 -0.1 -0.3 -0.6 -0.3 -0.2 -0.4 -0.7  1.3  4.8 -0.2 -0.  12.6 -0.2  0.7  0.4 -0.1 -0.8 -0.4  1.1  6.8  1.5  2.4 -0.2 -0.1 -0.  -0.1  3.9 -0.6 -0.4 -0.2 -0.6  2.1 -0.7 -0.6 -0.7  3.3  1.1 -2.4 -0.8 -0.2 -0.3  0.8  0.8 -0.4 -0.3 -0.3  1.4 -0.1 -0.  -0.5 -0.3 -0.1 -2.8 -0.8 -0.7 -0.1  0.2 -0.4 10.9 -0.1 -0.4  0.1 -1.1  6.4  5.4 -0.3 -0.4 -0.3 -0.5  0.2 -0.2 -0.3 -0.4  0.2 -0.1 -2.1 -0.1 -0.1  1.7  6.3 -0.7 -0.  -0.2 -0.2 -1.6  3.6  0.7 -1.4 -0.7 -0.5 -0.2 -1.   1.5  4.3 -0.1  0.9 -0.3 -0.5 -0.2  4.8 -0.1 -0.4 -0.2  7.7  0.   0.4  4.2 -0.6  1.1 -0.7 -0.1 -0.6 -1.7 12.  -0.  -0.1 -0.9 -0.6 -0.1  0.1  0.6  0.5 -0.2 -0.3 -0.2 -0.1  2.5 -0.   0.8 -0.3  0.6 -0.3 -0.2 -0.2  0.2 -0.5 -0.4 -0.4 -0.1 -0.  -0.3 -0.1 -0.2  0.8 -0.1 -0.6  0.6 -0.4 -0.4  0.4 -0.2 -0.2 -0.1  0.4 -1.1 -0.8  2.5 -0.4 -2.4 -0.1 -0.3 -1.3 -0.2 -0.   2.3 -0.9 -0.4 -0.4 -0.2 -0.2 -0.5 -0.7  6.9 -1.2 -0.6 -0.4 -0.  -0.1 -0.1 -0.1 -0.1 -0.8 -0.1 -2.3 -0.4 -0.1 -4.8 -0.3 -0.3  0.3 -0.7 -1.1 -0.4 -0.6 -0.3 -0.8  0.4 -0.8 -0.2  0.  -0.2 -0.8  2.4 -0.3 -0.7 -0.6 -1.   5.2 -0.5 -0.  -0.2 -2.7  0.5 -0.1  0.6 -0.6  1.9 -2.7 -0.1 -1.2 -0.3 -0.1 -2.   1.1 -0.1 -0.1 -0.9  0.8 -2.9 -0.1 -0.6 -0.1 -0.3  5.1]
ty_50sample [[5 7 4 6 2 0 9 3 1 8]
 [6 0 3 7 2 5 4 8 9 1]
 [2 3 8 8 1 6 7 0 4 5]
 [1 1 3 5 0 6 8 2 4 7]
 [2 5 1 7 9 3 6 0 4 8]
 [6 8 0 9 1 3 7 2 4 5]
 [8 7 0 3 4 5 2 6 9 1]
 [5 4 6 9 3 1 2 0 0 7]
 [8 2 3 5 7 0 9 6 4 1]
 [5 3 7 2 1 9 8 0 4 6]]
tt_50sample [[5 7 4 6 2 9 0 3 1 8]
 [6 0 3 7 2 5 4 8 9 1]
 [2 3 9 8 1 6 7 0 4 5]
 [9 1 5 3 0 6 8 2 4 7]
 [2 5 1 7 9 3 6 0 4 8]
 [6 8 0 9 1 3 7 2 4 5]
 [8 7 0 3 4 5 2 6 9 1]
 [5 4 6 9 3 2 1 8 0 7]
 [8 2 3 5 7 0 9 6 4 1]
 [5 7 3 2 1 9 8 0 4 6]]
vm  [-1.2  0.9  1.8  9.4 -1.   0.3  0.7 -0.2 -0.4 -0.6 13.5 -0.  -0.3 -0.2 -1.   4.1  0.7 -0.2  0.8 -0.8 -1.  -0.3 -1.4 -0.1 -1.1  0.4 -0.5 -0.3 -1.3 -1.9  2.5 -0.8  0.6  7.9 -0.2  1.   2.1  4.7  4.6 -0.1 -0.2 -2.5 -0.8 -0.4 -0.4 -0.2  4.7 -0.9 -1.1 -4.  -0.5 -0.1 -0.3  4.8 -0.9  1.5 -0.1 -0.1  1.4 -1.8  3.  -0.4 -0.4 -0.4 -0.5 -0.9 -0.   0.1 -0.7 -0.4 -0.2  0.7  2.1 -0.1 -0.8 -0.4  0.3 -0.6  0.3 -0.5 19.8 -0.1 -0.4 -0.7  0.7 -1.9 -1.4 -0.3 -0.1 -0.3  0.3 -0.2  0.6 -0.  -0.6 -0.2 -0.6 -0.9 -0.  -0.4  2.7 -1.2  1.4 -0.2 -0.2 -0.5 -0.9  2.1  0.1 -1.4  0.1 -0.2 -0.1  0.1  1.1  0.4 -0.2 -0.8 -0.2 -0.2 -0.5  6.3 -0.2 -0.1 -0.2 -1.5 -0.1 -0.8 -0.  -0.  -0.4 -0.2  0.3 -0.   4.9 12.6 -0.7 -0.2  1.9 -0.1 -0.8 -0.5 -1.2  0.  -0.2 -0.2 -0.4  0.  -0.5 -0.2 -0.7 -0.1 -2.6 -0.9 -0.2 -0.1 -0.2 -0.5 -0.1  1.7 -0.  -0.3 -0.1 -0.1 -0.3  0.8  0.3  1.7  0.2 -0.3 -0.4 -0.3 -0.5  0.1 -0.4  2.1 -0.5 -0.3 -0.2 -0.2  0.5 -0.  -0.1 -1.3 -0.1 -0.4 -0.8 -0.2 -0.5  6.2 -0.4 -0.3 -0.4 -0.7 -0.4  1.   1.1 -0.1 -0.3 -0.1 -0.2  0.3 -0.2 -0.4 -0.3  1.2 -0.4  0.3 -1.3 -0.3 -0.5 -0.6 -0.9  6.4  1.2 -0.1  3.8 -0.9 -0.7 -0.2  0.7  0.4 -0.2 -1.  -0.1 -1.2  2.5  2.3 -0.4 -0.4 -0.5 -0.5 -0.2 -0.7  1.2 -0.  -0.1 -0.2 -0.6 13.6 -0.1  5.8 -0.3 -0.2 -4.5 -1.7 -0.  -0.5 -1.1 -0.1 -5.2 -0.2  2.9 -0.2 -0.3  2.3]
vy_50sample [[2 1 9 3 0 6 7 4 5 8]
 [7 9 0 8 2 1 3 4 5 6]
 [0 2 1 8 7 6 3 4 9 5]
 [2 8 1 3 9 4 6 5 0 7]
 [2 4 6 1 8 7 5 3 9 0]
 [0 3 8 4 6 7 9 5 2 1]
 [3 6 7 1 4 2 8 0 9 5]
 [2 3 1 8 0 7 6 9 5 4]
 [2 5 4 1 0 3 6 9 8 7]
 [5 9 1 3 0 6 2 7 7 8]]
vt_50sample [[2 1 9 3 0 6 4 7 5 8]
 [7 9 0 8 2 1 3 4 5 6]
 [0 2 1 8 7 6 3 4 9 5]
 [2 8 1 3 9 4 6 5 0 7]
 [2 4 6 1 8 7 5 3 9 0]
 [0 3 8 4 6 7 9 5 2 1]
 [3 6 7 1 4 2 8 0 9 5]
 [2 8 3 1 0 7 6 9 5 4]
 [2 5 4 1 0 3 6 9 8 7]
 [5 9 1 3 0 6 2 7 4 8]]
Epoch 29810: Training cost= 0.2498, Training acc= 0.8380, Validation cost= 0.2337, Validation acc= 0.8382
Epoch 29820: Training cost= 0.3045, Training acc= 0.8380, Validation cost= 0.3182, Validation acc= 0.8382
Epoch 29830: Training cost= 0.2353, Training acc= 0.8381, Validation cost= 0.3096, Validation acc= 0.8382
Epoch 29840: Training cost= 0.2585, Training acc= 0.8381, Validation cost= 0.3216, Validation acc= 0.8382
Epoch 29850: Training cost= 0.2856, Training acc= 0.8381, Validation cost= 0.2891, Validation acc= 0.8382
Epoch 29860: Training cost= 0.2245, Training acc= 0.8381, Validation cost= 0.2732, Validation acc= 0.8383
Epoch 29870: Training cost= 0.2397, Training acc= 0.8381, Validation cost= 0.2954, Validation acc= 0.8383
Epoch 29880: Training cost= 0.2885, Training acc= 0.8381, Validation cost= 0.2759, Validation acc= 0.8383
Epoch 29890: Training cost= 0.3259, Training acc= 0.8382, Validation cost= 0.2380, Validation acc= 0.8383
Epoch 29900: Training cost= 0.3421, Training acc= 0.8382, Validation cost= 0.3249, Validation acc= 0.8383
tm  [-1.  -0.4 -3.8 -3.4 -1.2 -0.1 -0.2 -0.1 -0.4 -0.4 -3.3 -0.2 -0.4 -0.2 -0.4 -1.3 -0.1 -0.2 -0.3 -0.3 -0.8 -0.4  1.5 -0.1 -1.1  1.9 -0.4 -0.2 -0.8 -0.5  4.  -0.4  0.2 -2.4 -0.2  0.3  3.2 -1.3 -1.7 -0.2  0.3  2.5 -0.3  3.3 -0.3 -0.1 -0.5  0.6 -1.   6.1 -0.7 -0.1 -0.4 -0.9 -0.6  0.8 -0.9 -1.7  1.8 -1.4  6.  -0.2 -0.3 -0.5 -0.2 -0.  -0.2 -0.1  1.2  0.2  0.1  0.7 -0.1 -0.2 -3.4 -0.1  0.8  0.2 -0.  -0.  -1.4 -0.1  0.   0.4  0.9  2.5  2.  -0.1 -0.1 -0.7 -0.5 -0.1 -0.1 -0.5 -0.5 -0.1 -0.2 -2.  -0.1 -0.3  1.4  0.4  1.2 -0.1 -0.1  0.4 -1.9  4.4 -1.1 -0.6 -0.5 -0.1 -0.  -0.7  3.3 -0.3 -0.3 -0.1 -0.1 -0.2 -0.2  1.9 -0.2 -0.1 -0.2 -0.4  0.5  5.7  1.  -0.2 -0.4 -0.4 -0.3 -0.4  8.8  4.5 -0.2 -0.1  0.4 -0.6  2.9 -0.9  1.5 -0.1 -0.3 -0.  -0.4 -0.1  3.5  0.   2.2  0.3 -0.3  0.  -0.1 -0.1 -0.2 -0.2 -0.4 -0.2 -0.1  0.2 -0.  -0.  -0.3 -0.3 -0.1  1.2 -0.1 -0.3 -0.3  0.  -0.3 -0.2 -0.2 -0.3 -1.  -0.3  3.7  0.  -0.9 -0.4 -0.1 -1.5 -0.2 -0.  -0.7  0.3 -0.3  1.8 -0.3 -0.3 -0.2 -1.2 -1.6  0.5 -0.9 -0.5 -0.2 -0.3 -0.3 -0.3 -0.1 -0.5 -0.  -2.4 -0.2 -0.1  2.7 -0.1 -0.2 -0.6 -0.5  4.8  0.4 -0.5 -1.1 -0.8 -0.3 -0.3 -0.3 -0.  -0.6 -1.4  3.   0.1 -1.8 -0.4 -0.2 -0.1 -0.2  0.8 -0.2  1.8  1.2  6.7  0.7 -1.2  1.9 -0.4  0.1 -0.2 -0.1  0.1  6.1  0.8 -0.3  0.1 -1.1 -0.1  3.3 -0.1 -1.  -0.3  3.1  3.1]
ty_50sample [[4 1 6 0 8 5 9 3 7 2]
 [4 2 0 9 5 3 7 1 8 6]
 [2 7 0 9 3 6 4 1 5 8]
 [1 5 0 3 2 6 8 9 7 4]
 [8 1 0 5 2 3 6 4 7 9]
 [8 8 6 0 9 5 4 3 2 1]
 [0 9 8 4 7 5 2 1 6 3]
 [6 4 7 0 1 5 3 2 9 8]
 [1 2 6 3 9 5 0 8 4 7]
 [1 3 0 5 2 8 9 7 4 6]]
tt_50sample [[4 1 6 0 8 5 9 3 7 2]
 [4 2 0 9 5 7 3 1 8 6]
 [2 7 0 9 3 6 4 1 5 8]
 [1 5 0 3 2 6 8 9 7 4]
 [8 1 0 5 2 3 6 4 7 9]
 [8 6 7 0 9 5 4 3 2 1]
 [0 9 8 4 7 5 2 6 1 3]
 [6 4 7 0 1 5 3 2 9 8]
 [1 6 2 3 9 5 0 8 4 7]
 [1 3 0 5 2 8 9 7 4 6]]
vm  [-0.6 -0.9 -1.  -4.6 -1.9 -0.2 -0.5 -0.   0.4 -0.   0.7 -0.2 -0.2 -0.2 10.   0.8 -0.5 -0.2  0.2  1.3 -1.   0.1  2.2 -0.3 -0.8  0.4 -0.4 -0.2 -0.9 -0.8  2.7 -0.1 -0.3  3.4 -0.1 -0.1 -0.   4.6  1.8 -0.7  0.2  1.5 -0.6  6.6 -0.2  0.4 -2.  -0.5  2.7  8.8 -0.9 -0.2 -0.5  7.  -0.4 -1.  -0.8 -2.3  6.5 -1.2  3.1  0.  -0.2  1.9 -1.  -0.4 -0.2 -0.3  0.6 -0.1  0.1  0.2 -0.1  0.  -4.8  1.9 -0.4 -0.1 -0.3  0.1 -3.3 -0.4  1.1  1.7 -0.5  2.3  4.2 -0.4 -0.3 -0.5 -0.4 -0.1 -0.1 -1.5 -0.5 -0.4  0.3 -3.  -0.4 -0.1  0.4  7.4 -0.3  0.2 -0.2 -0.3 -2.   3.1  0.6  0.1 -0.8 -0.3 -0.2 -0.9  4.6  0.1  0.9  1.9 -0.1 -0.4 -0.1 -0.3  0.5 -0.4 -0.1 11.7 -0.2 -1.4  5.3  0.4 -0.4 -0.9 -0.2 -1.3 -4.8 -3.6  0.3 -0.2 -0.6 -0.4 -0.4 -0.7 -0.4 -0.1 -0.1  0.1 -0.3 -0.3 -1.6  0.5  2.9 -0.2  2.2 -0.3 -0.1 -0.1 -0.2 -0.1  4.5 -0.1  0.8 -1.5 -0.1 -0.1 -0.4 -0.4  0.1  1.8 -0.  -0.3 -0.2 -0.3 -0.2 -0.3 -0.1  3.2  1.  -0.5  0.1 -0.4 -0.3 -0.5 -0.5 -1.2 -0.2 -0.3  0.8 -0.5 -0.2  1.9  0.3 -0.3 -0.2 -0.5 -0.7 -1.6 -1.  -1.2 -0.2 -0.1 -0.2 -0.2 -0.2 -0.4 -0.1 -3.4 -0.1 -0.2  5.  -0.1 -0.2 -0.3 -0.8 -0.2 -0.3 -0.4 -2.4 -0.7  0.3 -0.5 -0.3 -0.2 -0.5 -0.9  0.3  0.9 -0.2  0.2  1.1  3.4 -0.5 -0.1  0.4  2.8  0.8  2.7  1.7 -1.3  2.7 -0.5  0.1 -0.3 -0.1 -0.3 11.2  4.1 -0.5  0.6 -0.8 -0.4  8.4 -0.1  1.4 -0.2 -1.1  1.6]
vy_50sample [[4 7 8 2 0 1 5 9 3 6]
 [8 1 0 4 2 5 9 7 3 6]
 [8 3 6 6 7 9 0 4 5 2]
 [1 5 8 2 9 6 3 3 0 4]
 [2 6 0 3 1 9 7 4 8 5]
 [0 8 6 5 3 9 7 4 2 2]
 [9 1 2 7 6 4 0 8 3 5]
 [5 2 4 3 7 1 9 6 0 0]
 [1 1 4 4 2 5 3 9 0 6]
 [9 5 8 1 2 6 3 7 4 0]]
vt_50sample [[4 7 8 2 0 1 5 9 3 6]
 [8 1 0 4 2 5 9 7 3 6]
 [8 3 6 1 7 9 0 4 5 2]
 [1 5 8 9 2 6 3 7 0 4]
 [2 6 0 3 1 9 7 4 8 5]
 [0 6 8 5 3 9 7 4 2 1]
 [9 1 2 7 6 4 0 8 3 5]
 [5 2 4 3 7 1 9 6 8 0]
 [1 7 8 4 2 5 3 9 6 0]
 [9 5 8 1 2 6 3 7 4 0]]
Epoch 29910: Training cost= 0.2693, Training acc= 0.8382, Validation cost= 0.3027, Validation acc= 0.8383
Epoch 29920: Training cost= 0.2646, Training acc= 0.8382, Validation cost= 0.3098, Validation acc= 0.8384
Epoch 29930: Training cost= 0.2709, Training acc= 0.8382, Validation cost= 0.3068, Validation acc= 0.8384
Epoch 29940: Training cost= 0.2998, Training acc= 0.8382, Validation cost= 0.2576, Validation acc= 0.8384
Epoch 29950: Training cost= 0.3771, Training acc= 0.8383, Validation cost= 0.2695, Validation acc= 0.8384
Epoch 29960: Training cost= 0.2372, Training acc= 0.8383, Validation cost= 0.3298, Validation acc= 0.8384
Epoch 29970: Training cost= 0.2371, Training acc= 0.8383, Validation cost= 0.2816, Validation acc= 0.8384
Epoch 29980: Training cost= 0.2301, Training acc= 0.8383, Validation cost= 0.2857, Validation acc= 0.8385
Epoch 29990: Training cost= 0.3320, Training acc= 0.8383, Validation cost= 0.3520, Validation acc= 0.8385
Epoch 30000: Training cost= 0.2438, Training acc= 0.8383, Validation cost= 0.2789, Validation acc= 0.8385
tm  [-0.   1.2 -2.6 -0.  -1.1  0.8 -0.3 -0.1 -0.9 -1.1 -0.   0.1 -0.3 -0.1 -2.   6.4 -0.3 -0.2 -0.1 -1.4 -0.5 -0.1  1.7  0.1 -1.2  0.5  0.  -0.2  2.1  3.2  2.8 -0.3 -0.2 -1.9 -0.5 -0.   1.9  3.7 12.7 -0.3  0.5  2.6  2.9  5.  -0.1 -0.2  7.4 -0.5  2.1  4.7 -0.9 -0.1  1.1 -0.8 -1.4  3.3 -0.3 -0.5 -1.1 -0.9 -1.5 -0.5  0.2 -0.4 -0.3 -0.6 -0.2  0.6  0.5 -0.3  0.1 -2.   0.2 -0.2  1.   0.2 -0.4 -0.2 -0.1 -0.2  5.6 -0.4 -0.1 -0.2 -1.   4.7  5.6 -0.1 -0.1 -0.4  0.2 -0.  -0.3  1.3 -0.3 -0.1 -0.4 -0.4 -0.1 -0.2  4.   0.7 -0.9 -0.3 -0.1 -0.3 -0.   3.2  0.4 -1.6 -0.3 -0.4 -0.1 -0.4 -1.5 11.6  0.2 -1.2 -0.2 -0.2 -0.1  5.4 -0.3 -0.3 -0.1 -2.4 -0.   4.9 -0.7 -1.6 -0.  -0.3 -0.1 -0.5 -0.6 -2.4  0.  -0.2 -0.1 -0.6 -0.5 -0.2 -0.4 -0.  -0.1 -0.2 -0.5 -0.1  4.5 -0.3 -0.3 -0.2  3.3 -0.2 -0.1 -0.1 -0.3 -0.2  2.3 -0.1 -0.1 -1.2 -0.  -0.2 -0.2 -0.3 -0.2 -0.3  0.1 -0.2 -0.  -0.2 -0.1 -0.3 -0.1 -0.9 -0.5  1.1 -1.3 -0.1 -1.5 -0.  -0.2 -1.3 -0.6 -0.   1.9 -0.3  0.3 -1.  -0.3 -0.2 -0.4 -1.2 10.7  2.   2.2  2.7 -0.2  0.  -0.1 -0.1 -0.4 -0.5 -0.1  3.7 -0.3 -0.4 -0.6 -0.1 -0.3  4.  -0.4 -0.3  0.8 -0.3 -1.8 -0.3 -0.1 -0.2 -0.4 -0.2 -0.5 -0.8 -0.6  5.  -0.6 -0.2 -0.3  0.9 -0.7 -0.6 -0.1 -0.2 -1.3  4.9 -0.1  1.8 -0.1  3.2 -0.1  1.  -0.3 -0.1 -0.8 -2.6  0.3 -0.1 -0.5 -0.1 -1.7 -0.1  8.  -0.  -0.2  7.6]
ty_50sample [[4 9 5 8 2 3 7 1 6 0]
 [6 0 7 4 4 2 3 1 5 8]
 [7 8 3 1 5 9 9 0 6 4]
 [0 4 1 7 8 3 9 5 6 2]
 [9 5 4 2 8 7 6 1 0 3]
 [1 0 9 9 6 8 7 7 4 3]
 [0 7 8 5 5 9 3 1 6 2]
 [0 6 2 4 1 7 5 3 8 9]
 [0 3 6 1 7 8 4 9 2 5]
 [4 2 8 5 9 1 3 7 6 0]]
tt_50sample [[4 9 5 8 2 3 7 1 6 0]
 [6 0 7 9 4 2 3 1 5 8]
 [7 8 3 1 5 9 2 0 6 4]
 [0 4 1 7 8 3 9 5 6 2]
 [9 5 4 2 8 7 6 1 0 3]
 [1 0 2 9 6 8 7 5 4 3]
 [0 7 8 5 4 9 3 1 6 2]
 [6 0 2 4 1 7 5 3 8 9]
 [0 3 6 1 7 8 4 9 2 5]
 [4 8 2 5 9 1 3 7 6 0]]
vm  [-1.  -0.2  3.  12.3 -1.9  0.1 -0.3 -0.3 -0.6 -0.5 -2.1 -0.2 -0.3 -0.3 -1.3 -2.2  0.4 -0.3  0.6 -0.8 -0.7 -0.4 -0.1  0.5 -1.2  5.3 -0.  -0.2 -1.9 -2.1 -0.6 -0.1 -0.3 -0.6 -0.2  0.6  4.4 -0.5  6.7 -0.2  0.   0.9  2.4 -0.5 -0.4 -0.   4.1  0.4 -0.2 -0.4 -0.5 -0.   1.1 -2.2  3.4  2.2 -0.6  7.4 -0.3  3.6 -0.  -0.2  0.4  0.3 -0.1  1.6  0.1 -0.8  0.8  0.4  0.   6.9 -0.1 -0.1 -0.2 -0.  -0.   0.5 -0.4  0.3  7.  -0.3  0.2 -0.4 -0.1  1.5 -1.  -0.   0.4  0.1 -0.3 -0.2  0.5  0.4 -0.2 -0.2  1.2 -1.3 -0.2  0.3  1.5 -1.  -0.1 -0.1 -0.3  0.6 -0.1 -0.4 -0.7 -1.1 -0.5  1.2 -0.1  0.3  3.5 -2.6 -0.3 -0.8 -0.3  0.2 -0.2  5.4  0.3  0.7 -0.3 -1.6 -0.1 10.6 -0.  -0.4 -0.3 -0.2 -0.7 -0.5  3.4 -0.  -0.2 -0.2  1.4 -0.3  2.9 -1.7  1.4 -0.2 -0.2 -0.1  0.4 -0.2  4.8 -0.  -0.9 -0.   0.1  1.5 -0.3 -0.2 -0.4  0.9  1.3 -0.3 -0.1 -0.8  0.5 -0.  -0.2 -0.4 -0.3 -0.7 -0.1 -0.1 -0.3 -0.2 -0.1 -0.3 -0.4 -0.7 -0.5  1.  -0.3 -0.  -1.3  0.9 -0.4 -1.8 -0.1 -0.3 -0.1 -0.3  0.6  6.2 -0.1 -0.1 -0.3 -1.   2.8  2.4  0.4 -0.5 -0.1 -0.  -0.4  0.2 -0.2 -0.2  0.5  1.8 -0.1 -0.2 -0.7 -0.1 -0.2 -1.8 -0.1  3.2 -0.7 -0.4  3.  -0.7 -0.8 -0.9 -0.4  0.1 -0.  -0.9 -0.4 -1.  -2.   0.6 -0.1 -0.3 -0.4 -1.  -0.5 -0.6  5.1 -0.3  0.2  2.5  1.8  4.1 -0.1  1.5 -0.  -0.1 -1.1 -1.8 -0.1 -0.3 -1.2 -0.3 -2.1 -0.   4.3 -0.1  6.5  3.5]
vy_50sample [[0 9 5 5 1 8 6 7 4 2]
 [6 0 9 4 7 2 3 1 5 8]
 [5 0 6 4 7 2 1 9 8 3]
 [9 5 7 1 3 8 0 4 6 2]
 [8 4 1 3 7 2 6 0 5 9]
 [8 9 7 3 2 5 1 6 4 0]
 [2 7 3 6 9 4 5 0 8 1]
 [0 3 2 7 9 8 5 6 4 1]
 [9 8 6 1 3 7 5 0 4 2]
 [7 5 4 0 2 9 8 3 6 1]]
vt_50sample [[0 9 5 3 1 8 6 7 4 2]
 [6 0 9 4 2 7 3 5 1 8]
 [5 0 6 4 7 2 1 9 8 3]
 [9 5 7 1 3 8 0 4 2 6]
 [8 4 1 3 7 2 6 0 5 9]
 [8 9 7 3 2 5 1 6 4 0]
 [2 7 3 6 9 4 5 0 8 1]
 [0 3 2 7 9 8 5 6 4 1]
 [9 8 6 1 3 7 5 0 4 2]
 [7 5 0 4 2 9 8 3 6 1]]
Epoch 30010: Training cost= 0.3180, Training acc= 0.8384, Validation cost= 0.2457, Validation acc= 0.8385
Epoch 30020: Training cost= 0.3453, Training acc= 0.8384, Validation cost= 0.2720, Validation acc= 0.8385
Epoch 30030: Training cost= 0.2988, Training acc= 0.8384, Validation cost= 0.2985, Validation acc= 0.8385
Epoch 30040: Training cost= 0.2558, Training acc= 0.8384, Validation cost= 0.3029, Validation acc= 0.8385
Epoch 30050: Training cost= 0.2957, Training acc= 0.8384, Validation cost= 0.3391, Validation acc= 0.8386
Epoch 30060: Training cost= 0.2590, Training acc= 0.8384, Validation cost= 0.2814, Validation acc= 0.8386
Epoch 30070: Training cost= 0.3069, Training acc= 0.8385, Validation cost= 0.2684, Validation acc= 0.8386
Epoch 30080: Training cost= 0.3000, Training acc= 0.8385, Validation cost= 0.2733, Validation acc= 0.8386
Epoch 30090: Training cost= 0.3001, Training acc= 0.8385, Validation cost= 0.2604, Validation acc= 0.8386
Epoch 30100: Training cost= 0.2590, Training acc= 0.8385, Validation cost= 0.2715, Validation acc= 0.8386
tm  [-1.   0.2 -2.6 -0.1 -0.6 -0.  -0.1 -0.   0.1 -0.7 12.3 -0.4  0.8 -0.3 -2.   7.1 -0.1 -0.1 -0.1 -1.3 -1.2  0.  -0.7 -0.5 -1.3  0.7 -0.5 -0.2  0.2 -1.6  4.4 -0.8  3.5  1.2  0.1  0.8  1.4  4.7  0.  -0.2  0.6 -1.5 -0.6  1.  -0.  -0.2  5.6 -0.9 -1.2 -2.5 -0.6 -0.2 -0.7  6.9 -1.6  2.8 -0.6 -1.   2.4 -2.   3.1 -0.2 -0.4 -0.4  1.3 -1.   0.2  1.1 -0.7  0.1 -0.2 -0.6  0.3 -0.1 -1.6  2.   0.3  0.5 -0.  -0.3 14.1 -0.2 -0.7 -0.2  0.7 -1.1 -0.3 -0.2 -0.3 -0.3 -0.6 -0.2 -0.2 -0.  -0.6 -0.4 -0.1 -1.1 -0.4 -0.1  3.2 -1.8  0.1 -0.2 -0.3 -0.7 -2.   3.   0.5 -1.2 -0.2 -0.1 -0.1 -0.6  0.3  5.8  2.1 -0.5 -0.4 -0.2 -0.3  5.2 -0.1 -0.6 -0.  -2.6 -0.1 -1.5  0.4  1.9 -0.6 -0.4 -0.2 -0.2 10.4 12.1 -0.6 -0.1 -0.3 -0.7 -1.6  0.5 -1.3 -0.1 -0.1 -0.   0.1 -0.2  2.8 -0.2 -0.3 -0.2 -1.6 -1.1 -0.1 -0.2 -0.4  0.3 -0.4 -0.4  0.4 -0.3 -0.1 -0.1 -0.1 -0.2 -0.5  1.  -0.5 -0.2 -0.1 -0.4 -0.3 -0.2  0.3 -0.6 -1.4 -0.5  1.1  0.  -0.5 -0.3 -0.1 -1.3 -0.4 -0.7 -0.4 -0.  -0.5  5.6 -0.3 -0.4 -0.6 -0.4 -0.5 -0.1 -0.4 -0.2 -0.2 -0.3 -0.2  0.  -0.1 -0.3 -0.4 -1.2 -0.1 -0.1 -0.7 -0.3 -0.7  1.2 -0.1  4.2  1.1  0.7 -0.  -1.  -0.4 -0.1 -0.1 -0.1 -0.3 -1.3 -0.  -0.   3.2  0.4  1.  -0.2 -0.9  0.9  0.4 -0.4 -0.6  5.4  0.3 -0.9 -0.9  9.8 -0.1  3.9 -0.3 -0.1 -3.  -0.9 -0.1 -0.7 -1.1 -0.2 -3.9 -0.2  0.3 -0.2 -0.9  0.3]
ty_50sample [[2 1 1 3 9 9 5 0 7 8]
 [8 9 9 0 6 4 7 1 5 3]
 [6 0 2 3 5 8 9 7 4 1]
 [2 5 3 9 6 8 0 1 4 7]
 [1 4 9 6 3 0 8 7 5 2]
 [7 1 0 8 2 4 9 3 6 5]
 [4 0 6 2 2 8 5 3 1 7]
 [9 8 1 4 7 5 0 6 2 3]
 [7 0 4 9 8 3 5 2 6 1]
 [0 7 2 6 1 3 9 5 4 8]]
tt_50sample [[2 1 3 4 6 9 5 0 7 8]
 [8 9 0 2 6 4 7 1 5 3]
 [6 0 2 3 5 8 9 7 4 1]
 [2 5 3 9 6 8 0 1 4 7]
 [1 4 9 6 3 0 8 7 5 2]
 [7 1 0 8 2 4 9 3 6 5]
 [4 0 6 9 2 8 5 3 1 7]
 [9 8 1 4 7 5 0 6 2 3]
 [0 7 4 9 8 3 5 2 6 1]
 [0 7 2 6 1 3 9 5 4 8]]
vm  [-0.3 -0.2  4.8 16.4 -1.4 -0.1 -0.2 -0.2 -0.4  0.2  3.1 -0.3 -0.3  0.2 -1.8 -0.3 -0.4  0.   1.  -0.9 -0.9 -0.2  2.5 -0.1 -0.7  3.  -0.6 -0.1 -1.2 -0.7 -1.1 -0.2  1.3 -1.4 -0.2 -0.2  2.3 -0.6 -1.  -0.5 -0.3 -0.7  0.1 -1.8 -0.4 -0.3  5.3 -0.5  2.5  4.5 -0.4 -0.1  1.  -0.5  0.1  3.1 -0.3  2.9 -0.2  5.2 -1.  -0.4  0.8  0.6 -0.2 -0.7 -0.  -0.4 -0.  -0.2 -0.   3.6  1.6  0.2 -1.  -0.5 -0.4 -0.4 -0.2 -0.2  7.3 -0.4 -0.  -0.7 -1.1 -0.8 -0.7 -0.3 -0.1 -0.1 -0.3 -0.3  0.4  0.4  0.1 -0.3 -0.2 -1.  -0.3 -0.  -0.2 -0.  -0.7 -0.1 -0.2 -0.3  0.6 -0.9  1.1 -1.4 -0.5 -0.1  0.3 -0.1  2.1 -1.8  0.4 -0.5  0.   0.6 -0.1  4.6 -0.4 -0.  -0.4 -2.4 -0.   3.8 -0.8 -1.4 -0.1 -0.1  0.6 -0.3 12.4 11.7 -0.3 -0.   1.  -0.7 -0.4 -1.3 -0.6 -0.2  0.3 -0.1 -0.4  0.1 -0.3 -0.1 -1.3  0.1  2.3 -0.1 -0.3 -0.2 -0.3  0.3 -1.  -0.4  0.   1.1 -0.1  0.  -0.2 -0.8  0.  -0.2 -0.2 -0.   0.1 -0.4  0.5 -0.1 -0.3  1.4 -1.4  1.7  2.4 -0.3  0.9 -0.  -0.2 -0.8 -0.4 -0.1  2.1 -0.1  0.1  2.8 -0.1 -0.2 -0.3 -0.5  8.   3.4  1.2 -0.6 -0.2  0.5 -0.1 -0.1 -0.1 -0.  -0.3  3.7 -0.6 -0.2  6.  -0.  -0.3 -1.3 -0.6  0.1 -0.1 -0.4  8.2 -0.7 -0.7  0.6 -0.3  0.4 -0.1 -1.   3.3 -0.8 -0.7  1.8 -0.3 -0.   3.4 -0.7 -0.1  3.2  1.2 -0.6  1.6  1.   0.9 14.  -0.3  5.5 -0.  -0.2 -1.2 -2.4 -0.2  0.6 -1.2  0.  -2.2 -0.1 -0.7  0.3 -0.3  7.3]
vy_50sample [[6 0 9 2 8 3 1 7 5 4]
 [7 4 2 2 8 1 6 6 0 5]
 [0 6 3 4 8 5 1 7 2 2]
 [3 2 6 8 0 7 5 9 4 1]
 [5 8 9 1 3 7 4 2 0 6]
 [2 6 7 1 8 9 9 4 3 0]
 [0 7 1 6 5 2 2 8 4 3]
 [1 9 2 0 0 5 4 6 3 7]
 [4 3 9 8 1 1 7 6 5 2]
 [6 8 2 1 0 3 7 4 5 9]]
vt_50sample [[6 0 9 2 8 3 1 7 5 4]
 [7 4 2 9 8 1 6 3 0 5]
 [0 3 6 4 8 5 1 7 2 9]
 [3 2 6 8 0 7 5 9 4 1]
 [5 8 9 1 7 3 4 2 0 6]
 [2 6 7 1 8 9 5 4 3 0]
 [0 1 7 6 5 2 9 8 4 3]
 [1 9 2 8 0 5 6 4 3 7]
 [4 3 9 8 1 0 7 6 5 2]
 [6 8 2 1 0 3 7 4 5 9]]
Epoch 30110: Training cost= 0.2286, Training acc= 0.8385, Validation cost= 0.2640, Validation acc= 0.8387
Epoch 30120: Training cost= 0.2989, Training acc= 0.8386, Validation cost= 0.2816, Validation acc= 0.8387
Epoch 30130: Training cost= 0.2671, Training acc= 0.8386, Validation cost= 0.2584, Validation acc= 0.8387
Epoch 30140: Training cost= 0.3029, Training acc= 0.8386, Validation cost= 0.3051, Validation acc= 0.8387
Epoch 30150: Training cost= 0.3014, Training acc= 0.8386, Validation cost= 0.2785, Validation acc= 0.8387
Epoch 30160: Training cost= 0.2832, Training acc= 0.8386, Validation cost= 0.3000, Validation acc= 0.8387
Epoch 30170: Training cost= 0.2684, Training acc= 0.8386, Validation cost= 0.3213, Validation acc= 0.8388
Epoch 30180: Training cost= 0.2320, Training acc= 0.8387, Validation cost= 0.2631, Validation acc= 0.8388
Epoch 30190: Training cost= 0.2357, Training acc= 0.8387, Validation cost= 0.3133, Validation acc= 0.8388
Epoch 30200: Training cost= 0.2689, Training acc= 0.8387, Validation cost= 0.2427, Validation acc= 0.8388
tm  [ 1.2  0.4  4.6 -3.1 -1.5 -0.2 -0.7  0.1 -1.2 -0.6  7.5 -0.2 -0.2  0.2 12.   3.  -0.1 -0.1  2.8  3.6 -0.5  0.7  2.1 -0.  -1.9  2.9 -0.9  0.  -1.6  0.7 -0.1 -0.2 -0.5  4.   0.   0.2  3.8  4.1 -3.5 -1.1 -0.6  2.9  2.5 -0.  -0.1 -0.1 -3.8 -1.   5.2  5.7 -0.5 -0.1 -0.3 16.  -0.3 -1.2 -1.   3.4 -0.7  2.4  2.1  0.7 -0.9  2.2 -0.9  1.4 -0.1 -0.6 -0.   0.3  0.3  5.   0.4 -0.1 -5.5  0.8 -0.5 -0.4 -0.   0.9 -4.3 -0.5  0.8 -0.2 -1.2  4.8  4.1 -0.3 -0.2 -0.2 -0.9 -0.4 -0.3  1.8 -0.2  0.3  1.1 -2.7 -0.9  0.9  2.8  6.1 -1.   0.2 -0.1  1.3 -2.7  0.2  2.2  2.7 -0.5 -0.4  0.1  0.3 -0.3 -0.9  0.9 -0.6 -0.2 -0.1 -0.2 -1.1 -0.2 -0.4  0.3 14.6 -0.1 -4.4 -0.6  6.3  1.1 -0.3  0.2 -0.6 -1.3  2.3 -0.3 -0.2 -0.5 -0.4 -1.6 -1.1 -0.8 -0.2  0.  -0.1 -0.  -0.1 -0.8 -0.1  1.5 -0.2  4.  -0.8 -0.3 -0.2  0.2 -0.3  0.3 -0.6  1.8 -0.1  0.1  0.  -0.5 -0.3 -0.4 -0.7 -0.5 -0.2 -0.2 -0.1 -0.4 -0.3 -0.1  1.4 -0.6 -0.4  6.6 -0.2 -1.4  0.  -0.2 -1.4 -0.   0.1  1.5 -0.1 -0.  -0.1 -0.1 -0.5  1.6 -0.7 -0.   2.6 -1.3 -0.1 -0.  -0.1  1.2 -0.3  0.  -0.3 -0.2 -4.1 -0.3 -0.1  0.1 -0.4 -0.2 -2.  -0.2 -1.1 -0.4 -0.3  1.9 -0.5 -0.2 -0.4  0.7 -0.  -0.1 -1.   3.  -0.5  4.6  0.8  2.5  2.2 -0.6  0.3  0.1  0.2  2.3 -1.   0.8 -1.8 -0.2 -4.4 -0.  -1.7 -0.2 -0.4 14.2  8.4 -0.   0.6 -0.6 -0.6 11.7  0.  -2.3 -0.3 -2.1 -1.4]
ty_50sample [[2 7 0 5 6 8 4 3 1 9]
 [6 0 2 1 7 9 5 3 4 8]
 [8 5 2 1 0 4 9 3 7 6]
 [7 4 1 8 2 3 0 6 5 9]
 [8 5 4 2 7 9 1 0 3 6]
 [2 3 0 7 9 4 1 8 6 5]
 [0 3 1 9 4 8 5 5 6 7]
 [4 9 2 8 5 0 7 3 1 6]
 [2 4 3 0 1 6 7 5 9 8]
 [1 0 6 4 2 9 8 3 7 5]]
tt_50sample [[2 7 0 5 6 8 4 3 1 9]
 [6 0 2 1 7 9 5 3 4 8]
 [8 5 2 1 0 4 9 3 7 6]
 [7 4 1 8 2 3 0 6 5 9]
 [8 5 4 2 7 9 1 0 3 6]
 [2 3 0 7 9 4 1 8 6 5]
 [3 0 1 9 4 8 2 5 6 7]
 [4 2 9 8 5 0 7 1 3 6]
 [2 4 3 0 1 6 7 5 9 8]
 [1 0 6 4 2 9 8 3 7 5]]
vm  [-0.5 -0.4 -4.2  2.  -0.2 -0.2 -0.1 -0.2 -0.6  0.5  7.6 -0.3 -0.3 -0.4 -4.2  1.4  1.2 -0.2 -0.2 -1.7 -1.1 -0.2  1.1 -0.1 -0.9  2.4 -0.4  0.2 -1.3 -1.8  2.2 -0.5 -0.6 -4.  -0.  -0.1  3.7  7.9 18.1 -0.3 -0.5 -0.6 -0.3  4.2 -0.3 -0.4 10.3 -0.6 -0.2  4.1 -0.6 -0.1 -0.3  2.1 -0.3  5.4 -0.5 -1.9  1.2 -0.8 -1.1 -0.3 -0.1 -0.5 -0.5 -0.4  0.3  0.5 -0.4 -0.2 -0.4  2.4 -0.3 -0.5  1.6  2.  -0.2  1.1 -0.3 -0.  10.  -0.  -0.7 -0.4 -0.5 -0.7  2.5 -0.1  0.5 -0.1 -0.3 -0.4  0.4  0.5 -0.2 -0.5 -0.2  0.4 -0.3 -0.5 -0.2 -1.3 -0.6 -0.2 -0.4 -0.  -0.7  2.4  1.7 -2.3  0.5 -0.2 -0.2  0.3  2.3 -1.8  1.1 -0.9  0.1 -0.  -0.3  8.3  0.  -0.  -0.1 -5.  -0.2 -0.1 -0.4 -1.9 -0.4  0.3 -0.3  0.1  3.6 -3.5 -0.6 -0.1  0.  -0.4 -1.3 -1.  -1.3 -0.3 -0.1 -0.  -0.2 -0.   3.6 -0.2 -0.3 -0.1  1.2 -0.3 -0.2 -0.2 -0.5 -0.4  2.6 -0.4  0.1 -2.  -0.  -0.2 -0.  -0.1 -0.3 -0.  -0.5 -0.4 -0.1 -0.4 -0.3 -0.3  0.2 -0.7  1.1  0.6 -2.2  0.   0.4  0.1  0.9 -0.9 -0.4 -0.  -0.1  1.7  0.2  5.7 -0.1 -0.5 -0.6 -0.9  8.9  2.   1.2 -0.4 -0.1 -0.2  0.4 -0.1  1.  -0.1 -0.2  5.  -0.1 -0.2  4.7 -0.1 -0.5 -1.5 -0.1  0.6  2.6  0.1 -1.8 -0.8 -0.8 -0.4 -0.1 -0.4 -0.3 -1.  -0.8 -0.9  2.7 -0.  -0.3 -0.4 -1.2 -0.4 -0.3  2.7  0.4  6.8  0.9  0.8 -0.7 18.9 -0.3  7.5 -0.3 -0.3 -1.7 -2.8  0.8 -0.3 -0.6  0.5 -2.6 -0.  11.7 -0.2 -1.3  8.2]
vy_50sample [[2 9 4 4 8 1 3 5 6 7]
 [0 5 9 4 7 2 3 6 1 8]
 [9 2 3 8 6 7 4 1 5 0]
 [3 7 2 6 0 5 1 9 4 8]
 [1 6 7 9 9 8 4 3 5 0]
 [1 8 6 5 9 7 4 0 2 3]
 [4 2 0 6 7 9 1 8 5 3]
 [1 9 7 6 5 8 3 0 4 2]
 [0 4 7 3 1 2 5 6 8 9]
 [5 6 7 2 4 3 8 9 1 0]]
vt_50sample [[2 9 4 0 8 1 3 5 6 7]
 [0 5 9 4 7 2 3 6 1 8]
 [9 2 3 8 6 7 4 1 5 0]
 [3 7 2 6 0 5 1 9 4 8]
 [1 6 7 9 2 8 4 3 5 0]
 [1 8 6 5 9 7 4 0 2 3]
 [4 2 0 6 7 1 9 8 5 3]
 [9 1 7 6 5 8 3 0 4 2]
 [0 4 7 3 1 2 6 5 8 9]
 [5 6 7 2 4 3 8 9 1 0]]
Epoch 30210: Training cost= 0.2911, Training acc= 0.8387, Validation cost= 0.3742, Validation acc= 0.8388
Epoch 30220: Training cost= 0.2553, Training acc= 0.8387, Validation cost= 0.3002, Validation acc= 0.8389
Epoch 30230: Training cost= 0.3100, Training acc= 0.8387, Validation cost= 0.3329, Validation acc= 0.8389
Epoch 30240: Training cost= 0.3015, Training acc= 0.8388, Validation cost= 0.3751, Validation acc= 0.8389
Epoch 30250: Training cost= 0.3109, Training acc= 0.8388, Validation cost= 0.3055, Validation acc= 0.8389
Epoch 30260: Training cost= 0.3110, Training acc= 0.8388, Validation cost= 0.2552, Validation acc= 0.8389
Epoch 30270: Training cost= 0.3544, Training acc= 0.8388, Validation cost= 0.2798, Validation acc= 0.8389
Epoch 30280: Training cost= 0.2768, Training acc= 0.8388, Validation cost= 0.3006, Validation acc= 0.8389
Epoch 30290: Training cost= 0.2564, Training acc= 0.8388, Validation cost= 0.2856, Validation acc= 0.8390
Epoch 30300: Training cost= 0.2802, Training acc= 0.8388, Validation cost= 0.2900, Validation acc= 0.8390
tm  [ 1.  -0.1  5.6 12.  -1.4  0.5 -0.2 -0.3 -1.1  0.2  1.5 -0.1 -0.7 -0.1 -0.1 -0.9 -0.4 -0.2 -0.3 -1.  -1.2 -0.  -0.5  0.4 -1.2  3.2 -0.2 -0.5 -1.2  0.9 -0.1 -0.4  2.3  5.7 -0.   0.2  3.9 -0.9 -0.9 -0.2  0.5 -1.9  1.7 -1.1 -0.1 -0.4  6.4 -0.2  3.5 -1.4 -0.3 -0.1  2.1 -1.4  0.1  0.7 -0.4 -0.5 -1.3  2.7 -1.2 -0.6  0.8  0.3  1.  -0.7 -0.  -0.4  0.  -0.1 -0.   5.3 -0.1 -0.4 -1.  -0.2 -0.7 -0.3 -0.3 -0.  10.6  1.   0.  -0.3 -1.5 -1.9  1.5 -0.6  0.2  0.1 -0.1 -0.1 -0.2  2.8 -0.1 -0.2 -0.4 -0.6 -0.1  0.4 -0.2  0.1 -1.1 -0.1 -0.3 -0.2 -0.5 -0.2  0.4 -1.1 -0.2 -0.3 -0.1 -0.1  1.3 -2.8 -0.2 -0.7  0.6  0.4 -0.2  2.7 -0.1 -0.3 -0.1 -0.2 -0.2  6.9 -2.   0.7  0.6  0.5  0.8  0.2  5.9 12.9  0.  -0.1  0.7 -0.8 -0.1 -1.3 -0.1 -0.4 -0.  -0.2 -0.2 -0.2 -1.6 -0.2 -0.9 -0.2  2.4  0.1 -0.1 -0.2 -0.3 -0.2 -1.3 -0.3  0.1  0.3  0.1 -0.   0.7 -0.6 -0.6 -0.6 -0.3  0.7 -0.  -0.6  0.3 -0.1 -0.4  4.4 -1.6  0.9  2.2 -0.3  1.9 -0.4  0.2 -1.3 -0.2 -0.4  3.1 -0.5  0.1 -0.1 -0.  -0.2 -0.5 -1.   9.6  7.6 -0.3 -0.2 -0.2  0.2  0.6 -0.2 -0.  -0.3 -0.5  2.7 -0.2 -0.1  4.8 -0.3 -0.3 -1.6 -0.5 -0.6 -0.4  0.2  5.6 -0.8 -0.7  0.5 -0.4 -0.1  0.6 -0.8  1.5 -1.4 -1.3  0.3 -0.2 -0.1  2.7 -0.  -0.1  2.9  0.6 -1.1  3.1 -0.1  0.2 14.8 -0.1  6.  -0.1 -0.2 -2.  -2.4 -0.3 -0.2 -0.8 -0.3 -3.  -0.4 -0.6  0.4  2.4  1.4]
ty_50sample [[0 6 9 3 7 8 2 4 1 5]
 [1 2 9 4 4 0 0 5 3 3]
 [4 2 0 9 3 8 5 1 6 7]
 [9 0 4 7 6 8 1 5 2 3]
 [2 2 3 8 9 5 7 1 4 0]
 [4 7 2 8 1 5 3 0 6 9]
 [3 8 0 9 1 1 2 5 7 4]
 [2 1 3 8 4 0 0 6 5 9]
 [3 2 4 9 5 1 0 8 7 6]
 [3 7 2 0 9 1 5 8 4 6]]
tt_50sample [[0 6 9 3 7 8 2 1 4 5]
 [1 2 9 4 7 0 6 5 3 8]
 [4 2 0 9 3 8 5 1 6 7]
 [9 0 4 7 6 8 1 5 2 3]
 [2 6 3 8 9 7 5 1 4 0]
 [4 7 2 8 1 5 3 0 6 9]
 [3 8 0 9 1 6 2 5 7 4]
 [2 1 3 8 7 4 0 6 5 9]
 [3 2 4 9 5 1 0 8 7 6]
 [3 7 2 0 9 1 5 8 4 6]]
vm  [-0.8 -0.3  5.5 -0.2 -1.9 -0.1 -0.4 -0.2 -0.9 -0.6  3.9 -0.1 -0.3 -0.   7.5 -0.   1.   0.1  1.1  3.2 -1.  -0.2  1.8  0.7 -1.8  4.8 -0.5 -0.1 -1.7 -1.4 -1.4  0.  -0.5 -1.2 -0.   0.2  3.6  6.8 -0.5 -0.6  0.9 -0.3  0.9 -0.  -0.5 -0.4 -1.8 -0.8 -0.3  6.6 -0.7 -0.2 -0.5 12.   1.2 -0.5 -0.6  3.4 -0.2  4.7  5.7 -0.3 -0.1  0.6 -0.7 -0.1 -0.2 -0.2 -0.1 -0.5 -0.4  5.7  0.3 -0.1 -4.7 -0.1 -0.1 -0.2 -0.2  0.1 -4.4 -0.1  0.6 -0.2 -0.4 -0.1 -1.  -0.1  0.7  0.7 -0.4 -0.4 -0.3  1.6 -0.3 -0.2  0.6 -2.3 -0.6 -0.4  1.3  3.5 -0.6 -0.3 -0.  -0.4 -2.4 -1.   1.2  3.4 -0.3 -0.1 -0.2  0.6  1.9 -2.7 -0.1 -0.9  0.3  0.1 -0.  -1.3 -0.1  0.   0.   8.9 -0.2 -2.9 -0.5  4.2 -0.4 -0.  -0.5 -0.  -2.1 -3.1 -0.3 -0.2  0.8 -0.2 -1.  -2.  -1.  -0.2 -0.1 -0.1 -0.1  0.3 -0.9 -0.3 -0.4 -0.2  2.  -0.  -0.4 -0.3 -0.4  1.1  2.4 -0.1  0.5 -1.6  0.5  0.  -0.3 -1.  -0.3 -0.5 -0.3 -0.2 -0.1 -0.2  0.2 -0.1 -0.2  1.6 -0.6 -0.3  2.3 -0.2 -0.1 -0.4 -0.2 -1.4 -0.3 -0.2 -0.3 -0.3 -0.1  4.1 -0.  -0.5  0.8 -0.9 -1.4  3.4 -1.4 -0.5 -0.2  0.1 -0.3 -0.1 -0.2 -0.2 -0.3 -2.6 -0.2 -0.3  6.   0.1 -0.4 -1.9 -0.1  2.8 -0.5 -0.4  1.1 -0.6 -0.8 -0.5 -0.2 -0.1 -0.4 -1.2 -0.2 -0.9  2.   1.7 -0.2 -0.5 -0.3  1.1 -0.3  3.   2.9 -1.2  1.9 -1.6  0.4 -1.  -0.1 -0.4 -0.2 -0.1 13.6  1.6  0.1 -0.3 -0.7 -0.3 10.8 -0.  -0.2  0.1 -1.  -0.8]
vy_50sample [[0 2 8 1 1 3 5 6 4 9]
 [5 9 6 3 2 8 7 4 0 1]
 [0 6 1 5 5 9 2 8 8 4]
 [2 8 4 6 7 5 0 3 1 9]
 [1 9 7 2 2 8 8 0 5 4]
 [2 1 9 3 6 0 8 5 4 4]
 [9 0 3 5 1 2 7 6 8 4]
 [9 6 0 1 4 3 5 7 8 8]
 [3 5 4 9 0 8 2 7 1 6]
 [5 0 9 1 4 8 6 2 7 3]]
vt_50sample [[0 2 8 7 1 3 5 6 4 9]
 [5 9 3 6 2 8 7 0 4 1]
 [0 6 1 5 7 9 2 3 8 4]
 [2 8 4 6 7 5 0 3 1 9]
 [1 9 7 2 6 3 8 5 0 4]
 [2 1 9 3 6 0 8 5 4 7]
 [9 0 3 5 1 2 7 6 8 4]
 [9 6 0 1 4 3 5 7 2 8]
 [3 5 4 9 0 8 2 7 1 6]
 [5 0 9 1 4 8 6 2 7 3]]
Epoch 30310: Training cost= 0.2812, Training acc= 0.8389, Validation cost= 0.2895, Validation acc= 0.8390
Epoch 30320: Training cost= 0.2779, Training acc= 0.8389, Validation cost= 0.3087, Validation acc= 0.8390
Epoch 30330: Training cost= 0.2644, Training acc= 0.8389, Validation cost= 0.3191, Validation acc= 0.8390
Epoch 30340: Training cost= 0.3029, Training acc= 0.8389, Validation cost= 0.2808, Validation acc= 0.8390
Epoch 30350: Training cost= 0.3207, Training acc= 0.8389, Validation cost= 0.3078, Validation acc= 0.8390
Epoch 30360: Training cost= 0.2966, Training acc= 0.8389, Validation cost= 0.2781, Validation acc= 0.8391
Epoch 30370: Training cost= 0.2599, Training acc= 0.8390, Validation cost= 0.2546, Validation acc= 0.8391
Epoch 30380: Training cost= 0.2763, Training acc= 0.8390, Validation cost= 0.2638, Validation acc= 0.8391
Epoch 30390: Training cost= 0.2498, Training acc= 0.8390, Validation cost= 0.2895, Validation acc= 0.8391
Epoch 30400: Training cost= 0.2573, Training acc= 0.8390, Validation cost= 0.2124, Validation acc= 0.8391
tm  [-1.   0.5  6.8  5.8 -1.7  0.  -0.2 -0.  -0.6 -0.7 -0.8  0.6 -0.6 -0.2  6.   1.   0.2 -0.3 -0.3 -0.8 -0.7 -0.1 -1.1 -0.  -1.2  0.8 -0.1 -0.2  1.8 -0.4  0.9 -0.5  1.2  9.5 -0.5 -0.1  1.2 -0.5  1.5 -0.2  1.2 -1.8  1.3 -0.2 -0.1 -0.3  1.5 -0.  -0.8 -3.3 -0.7 -0.1  0.8 -1.4 -1.7 -0.5 -0.6  4.5 -0.7  0.8  3.9 -0.3  0.9 -0.6  1.3 -0.4 -0.1 -0.5 -0.4 -0.2  0.2 -1.3 -0.1 -0.2 -3.1  0.1 -0.2 -0.2 -0.6 -0.   6.5 -0.1 -0.  -0.3 -0.4 -1.2 -0.7 -0.  -0.1 -0.5 -0.5  0.2 -0.3  1.9 -0.2 -0.2 -0.4 -1.2 -0.2 -0.2  3.3 -0.6  0.2 -0.2 -0.1  0.8 -1.5  1.  -0.2 -1.   0.6 -0.3 -0.3 -0.8 -0.6  8.8 -0.1 -0.5  0.4 -0.5 -0.4  2.1 -0.3 -0.2 -0.1  7.1  0.3  7.4 -0.4  8.6 -0.4 -0.1 -0.1  0.9 -2.5  5.4 -0.1 -0.2 -0.2 -0.4  0.6 -0.2  1.1 -0.3 -0.2 -0.2 -0.4 -0.3 -0.5 -0.1 -0.5  0.  -0.7  0.3 -0.3 -0.  -0.6 -0.2  0.7 -0.5 -0.7 -1.  -0.1 -0.   0.6  0.1 -0.4 -0.2 -0.4 -0.  -0.1 -0.3 -0.2 -0.1 -0.1  1.4 -0.9 -0.4  0.7 -0.1 -1.1  0.2  0.5 -1.7 -0.4 -0.4 -0.3 -0.9 -0.1  1.6 -0.3  0.6 -0.3 -1.3 -0.7  1.2 -0.4  1.3 -0.2 -0.1 -0.  -0.  -0.  -0.3 -0.3 -0.8  0.1 -0.  -1.4 -0.6 -0.2  3.8  0.3  4.  -0.3  0.2  1.1 -0.6 -0.5 -0.3 -0.6  0.1 -0.1 -0.8 -1.6  2.8 -2.2 -0.5 -0.5 -0.2 -0.2  1.3 -0.1 -0.8 -1.4 -1.3 -0.4 -1.1 -0.1 -0.  -0.2  0.1 -0.2 -0.3 -1.  -1.  -0.7 -0.3 -0.6 -0.4 -1.9 -0.1  0.9 -0.2  8.3 -1.8]
ty_50sample [[3 7 1 5 9 6 8 8 0 2]
 [4 7 8 5 3 9 6 1 0 2]
 [0 5 1 8 3 2 6 4 7 9]
 [7 8 0 1 5 6 6 2 3 4]
 [8 2 0 1 9 9 3 7 4 6]
 [2 3 0 8 6 4 9 5 7 1]
 [8 2 7 9 1 5 4 3 3 6]
 [1 4 0 3 2 7 5 6 8 9]
 [2 0 3 7 6 9 1 8 5 4]
 [9 5 8 4 1 6 0 3 2 7]]
tt_50sample [[3 7 1 5 9 6 4 8 2 0]
 [4 7 8 5 3 9 6 1 0 2]
 [0 5 1 8 3 2 6 4 7 9]
 [7 8 0 1 5 9 6 2 3 4]
 [8 2 0 1 9 5 3 7 4 6]
 [2 3 0 8 6 4 9 5 7 1]
 [8 7 2 9 1 5 4 0 3 6]
 [1 4 0 3 2 7 5 6 8 9]
 [2 0 3 7 6 9 1 8 5 4]
 [9 5 8 4 1 6 0 3 2 7]]
vm  [-0.6 -0.7 -0.4 -0.1 -0.8 -0.1 -0.  -0.   1.   0.6 -0.9 -0.6 -0.3 -0.1  1.3  3.3 -0.1 -0.  -0.2  0.8 -0.8  0.   0.7 -0.4 -0.7  0.8 -0.5 -0.1 -0.6 -1.6 -2.1 -0.6 -0.7 -5.5  0.3  0.5 -0.2  5.1 -0.9 -0.6 -0.2  6.1 -0.4 -0.1 -0.2 -0.4 -1.6 -0.7 -0.  15.1 -0.8 -0.3 -1.2 10.5 -0.5  0.3 -0.4  5.8  4.7  5.6  4.2 -0.5 -0.5  0.4 -1.3 -0.4  0.2  1.  -0.2 -0.3 -0.3  0.1 -0.5 -0.1 -4.6 -0.1 -0.5 -0.1 -0.2 -0.2 -5.8 -0.3 -0.2  1.3 -0.8  7.7 -0.6 -0.2 -0.3 -0.1 -0.2 -0.4 -0.1 -1.  -0.5 -0.3  0.7 -3.  -0.  -0.4 -0.1  3.3 -0.4 -0.1 -0.3 -0.7 -1.9 -1.8 -0.4  0.5 -0.5 -0.2 -0.1 -0.6  3.1  0.5 -0.2 -0.1 -0.3 -0.4 -0.2 -0.2  0.6 -0.3  0.8  1.  -0.3 -2.5  4.4 -0.  -0.  -0.3 -0.1 -0.5  5.6 -4.6 -0.1 -0.1 -0.2  2.9 -1.1 -0.9 -1.2 -0.2  0.2  0.2 -0.1  0.3  5.5 -0.2 -0.3 -0.3  1.7 -0.6  0.  -0.  -0.1 -0.7  1.  -0.4  1.2 -0.9  0.2 -0.3  0.5 -0.3 -0.5  0.4 -0.1 -0.4 -0.1 -0.  -0.3 -0.2 -0.2 -1.4 -0.7 -0.7  2.2 -0.1 -1.1 -0.5 -0.6 -1.3 -0.4 -0.1 -0.1 -0.3 -0.4  4.5 -0.  -0.4 -0.2  0.2 -0.8 -1.4 -0.7 -0.8 -0.2 -0.  -0.4  0.5 -0.5 -0.6 -0.4 -3.1 -0.1 -0.   5.1 -0.1 -0.2 -0.3 -0.6  1.  -1.  -0.4  2.1 -0.7 -0.6 -0.6 -0.  -0.2 -0.3 -1.1  4.1  0.4  1.3  0.6 -0.8  2.3 -1.  -0.1 -0.1  3.   0.5  2.   1.2 -1.4  0.7 -3.  -0.2 -1.3 -0.  -0.3 17.2  3.1  0.2 -0.3 -0.7 -0.4 15.  -0.2 -0.4 -0.1 -2.1  3.2]
vy_50sample [[8 2 5 0 1 6 4 9 9 3]
 [8 9 7 2 6 3 4 0 5 1]
 [7 1 3 5 6 8 0 2 9 4]
 [0 0 1 5 7 2 3 9 6 8]
 [3 7 5 0 8 1 6 4 2 9]
 [5 0 3 9 6 1 8 4 2 7]
 [5 3 3 0 1 9 4 7 8 2]
 [8 3 7 1 9 6 5 0 2 4]
 [4 1 9 5 2 3 7 7 8 6]
 [8 0 7 6 1 9 5 2 3 4]]
vt_50sample [[8 2 5 0 1 6 4 7 9 3]
 [8 7 9 6 2 3 4 0 5 1]
 [7 1 3 5 6 8 0 2 9 4]
 [0 4 1 5 7 2 3 9 6 8]
 [3 7 5 0 1 8 6 4 2 9]
 [5 0 9 3 6 1 8 4 2 7]
 [5 3 0 1 6 9 4 7 8 2]
 [8 3 7 1 9 6 5 0 2 4]
 [4 1 9 5 2 3 0 7 8 6]
 [8 0 7 6 1 9 5 2 3 4]]
Epoch 30410: Training cost= 0.2965, Training acc= 0.8390, Validation cost= 0.2366, Validation acc= 0.8392
Epoch 30420: Training cost= 0.2916, Training acc= 0.8391, Validation cost= 0.2920, Validation acc= 0.8392
Epoch 30430: Training cost= 0.3338, Training acc= 0.8391, Validation cost= 0.3086, Validation acc= 0.8392
Epoch 30440: Training cost= 0.2466, Training acc= 0.8391, Validation cost= 0.2797, Validation acc= 0.8392
Epoch 30450: Training cost= 0.2688, Training acc= 0.8391, Validation cost= 0.2174, Validation acc= 0.8392
Epoch 30460: Training cost= 0.2646, Training acc= 0.8391, Validation cost= 0.2961, Validation acc= 0.8392
Epoch 30470: Training cost= 0.2325, Training acc= 0.8391, Validation cost= 0.3278, Validation acc= 0.8393
Epoch 30480: Training cost= 0.2821, Training acc= 0.8392, Validation cost= 0.3670, Validation acc= 0.8393
Epoch 30490: Training cost= 0.3047, Training acc= 0.8392, Validation cost= 0.2715, Validation acc= 0.8393
Epoch 30500: Training cost= 0.3354, Training acc= 0.8392, Validation cost= 0.4099, Validation acc= 0.8393
tm  [-1.2 -0.5  3.3 17.1 -1.1 -0.2 -0.3 -0.1  2.2 -0.3  3.9  1.1 -0.9 -0.4 -2.3 -0.5 -0.3 -0.3  0.4 -1.7 -1.  -0.2 -1.4 -0.4 -0.4  2.  -0.1 -0.1 -0.2 -2.7  1.6 -0.7 -0.4  5.9 -0.6 -0.7 -0.5 -0.8  9.8 -0.1 -0.3 -3.4 -1.6 -0.9 -0.5 -0.3  9.4 -0.2 -0.7 -4.1 -0.3 -0.1  2.7 -2.9 -1.   3.5 -0.1 -0.1  4.8 -0.4 -0.2 -0.5  0.1 -0.5  1.7 -0.2 -0.2  1.1  1.2 -0.3 -0.2 -0.6  0.4 -0.3  0.3  0.  -0.4 -0.5 -0.2 -0.3 21.1  0.4  0.3 -0.2 -0.2 -2.8 -1.6 -0.3 -0.7 -0.5 -0.  -0.  -0.1 -1.4 -0.5 -0.2 -0.7 -0.9 -0.5 -0.5  1.  -1.9  0.3 -0.2 -0.   1.4  1.2  1.3  1.6 -2.2  1.5 -0.1 -0.1 -0.4  3.9  2.4 -0.2  1.6 -0.   0.4 -0.4  7.5 -0.2 -0.2 -0.2 -2.8 -0.2 12.9  3.6  0.7 -0.2 -0.4  1.9 -0.5  4.8 10.1 -0.1 -0.1  2.  -0.4  0.6 -0.3  0.2 -0.3 -0.1 -0.2 -0.3 -0.2 -0.8 -0.1 -1.1 -0.  -1.4  0.6 -0.1 -0.1 -0.3 -0.5 -0.1  0.5 -0.2 -0.5  0.7 -0.1 -0.3 -0.1 -0.1  3.9 -0.2 -0.  -0.3 -0.6 -0.3 -0.  -0.5  2.9 -0.3  0.6 -0.9  0.4  1.4 -0.3 -0.1 -1.7 -0.2  0.3 -0.1 -0.2  0.   8.5 -0.1  0.7 -0.6 -0.8  3.7 -0.9  3.5 -0.6 -0.4 -0.2 -0.  -0.1 -0.4 -0.4 -0.3  6.4 -0.  -0.3  1.2 -0.6 -0.2  1.9 -1.1  4.2 -0.4  0.9  3.8 -0.8  0.   1.1 -0.8 -0.2 -0.5 -0.8 -0.5 -0.4 -2.4  0.5  1.9  0.9 -0.1 -1.3  0.9  0.2 -0.7 -0.5 -0.1  1.9  1.7 19.9 -0.2  7.9 -0.2 -0.2 -4.4 -3.3 -0.1 -0.  -1.2 -0.5 -5.4 -0.1  6.  -0.1  6.6  1.7]
ty_50sample [[9 3 1 6 0 7 4 2 5 8]
 [1 4 8 3 0 6 7 9 5 2]
 [2 4 1 3 7 6 9 8 0 5]
 [0 6 9 7 4 3 1 8 2 5]
 [1 2 0 3 6 5 8 4 7 9]
 [9 4 1 1 8 8 2 5 0 3]
 [8 5 7 9 6 0 2 3 4 1]
 [5 2 2 1 3 7 8 0 4 9]
 [9 4 2 0 1 7 6 8 5 3]
 [9 5 3 7 1 0 2 6 4 8]]
tt_50sample [[3 9 1 6 0 7 4 2 5 8]
 [1 4 8 3 0 6 7 9 5 2]
 [2 4 1 3 7 6 9 8 0 5]
 [0 6 9 7 4 3 1 8 2 5]
 [1 2 0 3 6 5 8 4 7 9]
 [9 4 1 6 7 8 5 2 0 3]
 [8 5 7 9 6 0 2 3 4 1]
 [5 2 6 1 3 7 8 0 4 9]
 [9 4 2 0 1 7 6 8 5 3]
 [9 5 3 7 1 0 2 6 4 8]]
vm  [-1.  -0.8  0.8  0.8 -1.9 -0.4  0.8 -0.3 -0.4  0.8 -5.4 -0.4 -0.6 -0.2  1.8 -2.6  3.5 -0.1 -0.3  0.5 -0.9 -0.3  0.6 -0.3 -1.3  5.7  0.2 -0.2 -1.3 -1.1 -1.1 -0.6 -1.1 -2.9 -0.1  0.1  1.2 -0.8 -0.1 -0.  -0.4  4.1  1.8  0.2 -0.4 -0.2 -1.2 -0.2 -0.4  9.8 -0.6 -0.1 -0.7 -0.8  2.5 -0.  -0.4  3.7  1.1  3.8  3.4 -0.3 -0.1 -0.1 -1.3  0.9 -0.2 -0.5  0.2  0.5 -0.3  5.4 -0.3  1.3 -4.1 -0.   0.8  1.7  0.   0.2 -3.4 -0.  -0.3 -0.7 -0.4  5.2 -0.7 -0.1  0.5 -0.1 -0.1 -0.5  0.1 -0.4 -0.6  0.2  1.9 -2.3 -0.1 -0.4 -0.5  3.6 -0.3 -0.2 -0.3  1.4 -1.1 -1.  -1.8 -0.3 -0.3 -0.  -0.1  0.4  5.  -3.  -0.4 -0.2 -0.3  0.   0.4  0.7 -0.1 -0.3  0.7  2.3 -0.1  5.7 -0.2 -0.  -0.4  0.9 -0.8 -0.   3.2 -2.8 -0.4 -0.2 -0.   2.2  4.2 -2.2  2.5 -0.1  0.2 -0.3 -0.1 -0.1  3.4 -0.2  0.4 -0.3  2.1  2.  -0.4 -0.1 -0.7 -0.3  0.  -0.   1.7 -0.9  1.  -0.2  0.3 -0.8 -0.8 -0.4 -0.  -0.3 -0.3 -0.3 -0.1 -0.7 -0.2 -0.2 -0.1  0.   1.5  0.6 -0.8  0.4 -0.8 -1.5 -0.2 -0.2 -0.5 -0.4  0.2  3.   0.2 -0.1 -0.1 -0.7 -0.8  1.6 -0.4 -0.9  0.2 -0.3 -0.   0.5  0.1 -0.1 -0.  -0.6  0.  -0.2  4.5  0.1 -0.3 -1.2 -0.2  5.7 -0.9 -0.   1.4 -0.6 -0.8 -1.  -0.6 -0.2 -0.4 -1.   3.4 -1.2 -2.4 -0.1 -0.6 -0.7 -0.1 -0.2 -0.6  2.2  2.4  0.3 -0.  -0.9  2.  -0.4 -0.3 -0.2 -0.1 -0.2 10.6 -0.5 -0.3 -0.7 -0.7 -0.9  8.5  0.4 -0.  -0.3  2.2  1.8]
vy_50sample [[0 8 1 5 6 7 7 9 3 2]
 [8 0 1 6 2 3 4 7 5 9]
 [9 7 6 5 4 0 1 8 2 3]
 [7 9 6 3 3 2 5 8 0 4]
 [1 5 4 4 8 8 2 9 3 7]
 [5 0 1 3 7 2 4 6 8 9]
 [3 3 7 0 0 6 2 5 4 8]
 [9 9 1 8 0 3 5 7 4 2]
 [0 5 5 1 8 8 7 9 2 3]
 [6 9 9 4 1 0 0 3 3 5]]
vt_50sample [[0 8 1 5 6 7 4 9 3 2]
 [8 0 1 6 2 3 4 7 5 9]
 [9 7 6 5 4 0 8 1 2 3]
 [7 9 6 1 3 2 5 8 0 4]
 [1 5 6 4 8 0 2 9 7 3]
 [5 0 1 3 7 2 4 6 8 9]
 [3 9 7 1 0 6 2 5 8 4]
 [9 6 1 8 0 3 7 5 2 4]
 [0 5 6 1 8 4 7 9 2 3]
 [9 6 8 2 4 1 0 7 3 5]]
Epoch 30510: Training cost= 0.3039, Training acc= 0.8392, Validation cost= 0.3891, Validation acc= 0.8393
Epoch 30520: Training cost= 0.3440, Training acc= 0.8392, Validation cost= 0.3723, Validation acc= 0.8393
Epoch 30530: Training cost= 0.3495, Training acc= 0.8392, Validation cost= 0.2130, Validation acc= 0.8393
Epoch 30540: Training cost= 0.2682, Training acc= 0.8392, Validation cost= 0.2171, Validation acc= 0.8393
Epoch 30550: Training cost= 0.3160, Training acc= 0.8392, Validation cost= 0.2599, Validation acc= 0.8394
Epoch 30560: Training cost= 0.2999, Training acc= 0.8393, Validation cost= 0.3307, Validation acc= 0.8394
Epoch 30570: Training cost= 0.3795, Training acc= 0.8393, Validation cost= 0.2984, Validation acc= 0.8394
Epoch 30580: Training cost= 0.3299, Training acc= 0.8393, Validation cost= 0.3352, Validation acc= 0.8394
Epoch 30590: Training cost= 0.2684, Training acc= 0.8393, Validation cost= 0.3084, Validation acc= 0.8394
Epoch 30600: Training cost= 0.2595, Training acc= 0.8393, Validation cost= 0.3169, Validation acc= 0.8394
tm  [-0.4 -0.5  9.  16.3 -1.7 -0.2 -0.2 -0.2 -0.1 -0.2 -1.3 -0.5 -0.3 -0.  -0.1 -1.6 -0.7 -0.1  0.3 -1.3 -1.1 -0.5 -0.1  0.3 -0.4  3.1 -0.3 -0.1 -1.1 -1.6 -0.6 -0.2 -0.4  6.4 -0.1 -0.4  1.4 -0.5  7.3 -0.2 -0.4 -2.2 -0.6 -0.7 -0.2 -0.   7.9  0.   2.7 -0.5 -0.3 -0.2  0.8 -2.   1.   1.  -0.5 -0.2  1.8  3.5 -1.  -0.3 -0.6 -0.1 -0.1 -0.  -0.  -0.1  2.1 -0.1  0.2  4.1 -0.2 -0.   0.4 -0.4 -0.9 -0.6 -0.2  0.1  9.8 -0.  -0.1 -0.2 -0.9 -2.3 -0.4 -0.2 -0.3 -0.2  0.8 -0.3 -0.1 -0.7 -0.1 -0.2 -0.  -1.3 -0.4 -0.4  0.1  2.5 -0.6 -0.1 -0.1  0.9  1.3 -0.6 -0.4 -1.7 -0.2 -0.1  0.2 -0.1  5.1 -2.2 -0.5  0.5 -0.2 -0.  -0.1  6.4 -0.1  1.3 -0.2 -0.2 -0.3  9.8 -0.1 -0.5  1.5 -0.2  0.1 -0.3 -1.5  2.6 -0.2 -0.   0.1 -0.3  1.2 -1.4 -0.1 -0.2  0.1  0.  -0.5 -0.1 -2.5 -0.4 -1.2  0.6  1.6  0.6 -0.1 -0.1  0.4 -0.2 -0.1 -0.2 -0.2 -0.5  0.1  0.2 -0.1 -0.5 -0.2  1.4 -0.1 -0.  -0.4 -0.4  0.1  0.1 -0.3  5.2 -0.4  1.6 -0.5 -0.   1.8 -0.2 -0.1 -1.3 -0.  -0.1  2.8 -0.3  1.1  5.1 -0.2 -0.1 -0.5 -0.4  8.1  1.1  0.8 -1.   0.2  0.   0.4 -0.1 -0.6 -0.3 -0.2  2.2 -0.4 -0.   7.   0.  -0.2 -1.1 -1.  -0.1 -0.6 -0.2  4.4 -0.8 -0.2  0.2 -0.4 -0.3 -0.2 -0.8 -0.1 -0.9 -1.5  1.1  0.4  1.7 -0.5 -1.2 -0.2  2.8  3.2 -2.   2.   2.5  3.5 18.7 -0.1  7.2  0.  -0.1 -1.7 -2.3 -0.1 -0.  -1.3 -0.2 -2.6 -0.1  5.3 -0.3  5.   4.6]
ty_50sample [[0 9 7 3 6 8 1 2 4 5]
 [2 5 6 4 7 0 9 1 8 3]
 [4 7 1 9 3 0 8 2 5 6]
 [9 3 8 1 5 4 7 6 2 0]
 [6 7 9 0 5 5 2 4 3 1]
 [2 3 5 7 6 4 9 8 8 1]
 [7 5 9 8 1 4 3 0 2 2]
 [1 4 7 5 3 0 0 6 2 9]
 [5 8 2 1 7 4 3 0 9 6]
 [8 4 1 7 0 5 9 6 3 2]]
tt_50sample [[0 9 7 3 6 8 1 2 4 5]
 [2 5 6 4 7 0 9 1 8 3]
 [4 7 1 9 3 0 8 2 5 6]
 [9 3 8 1 5 4 7 6 2 0]
 [6 7 9 0 8 5 2 4 3 1]
 [2 3 5 7 6 4 9 8 0 1]
 [7 5 9 8 1 4 3 0 6 2]
 [1 4 7 5 3 8 0 6 2 9]
 [5 8 2 1 7 4 3 0 9 6]
 [8 4 1 7 0 5 9 6 3 2]]
vm  [-0.2 -0.4  7.5 -0.6 -1.2 -0.  -0.4 -0.1  0.8 -0.4  9.1 -0.7 -0.1  0.2 10.8  3.6 -0.5 -0.4  1.3  0.8 -1.   0.1  1.4 -0.2 -1.1  1.6 -0.3  0.2 -0.7 -0.9  1.  -0.3  0.1  9.7 -0.1 -0.2  0.   2.5 -2.9 -0.7 -0.1  4.1 -0.7 -0.7 -0.1 -0.3 -1.8 -0.5  1.7  4.2 -0.4 -0.4 -0.5 11.6 -0.5 -0.9 -0.6  4.5  5.4  1.   4.3 -0.4 -0.2  1.7  1.7 -0.2 -0.2  0.   1.8 -0.3 -0.2 -0.1 -0.1 -0.1 -4.5 -0.3 -1.  -0.2 -0.1  0.  -0.8 -0.   0.6  0.8 -0.7  5.4 -0.3 -0.3 -0.4 -0.3 -0.3 -0.2 -0.3 -1.  -0.6 -0.1  0.4 -3.1 -0.3 -0.4  1.6  8.4 -0.4 -0.3  0.4 -0.1 -2.3  0.3  1.   1.6 -0.4 -0.2  0.  -0.7  3.   2.  -0.1  1.2 -0.2 -0.1 -0.4 -0.8  0.3  0.7 -0.1 12.1 -0.4 -2.9  4.2  0.9  1.5 -0.7 -0.1 -0.6 -0.9  9.7  0.2 -0.2 -0.3 -0.3 -0.8 -0.6 -0.6  0.   0.  -0.1 -0.2  0.2 -1.  -0.1  0.2 -0.2 -0.1 -0.4  0.2 -0.   0.5 -0.4 -0.5 -0.3  0.4  0.7 -0.  -0.2 -0.1 -0.6 -0.1  0.9 -0.1 -0.1 -0.2  0.  -0.2  0.4 -0.1  1.7 -1.  -0.6  5.2 -0.2 -1.1 -0.5 -0.4 -1.7 -0.4 -0.   0.8 -0.6 -0.2  2.7 -0.2 -0.5 -0.3 -0.6 -1.1 -1.5 -1.1 -0.9 -0.2  0.1 -0.  -0.1 -0.4 -0.8 -0.3 -3.7 -0.2 -0.  -1.7 -0.3  0.4 -0.1 -0.9 -0.3 -0.7 -0.4  4.5 -0.8  0.6 -0.1 -0.3 -0.2 -0.  -1.2  4.4 -0.4  1.9  1.7 -0.3  3.9 -0.5 -0.2 -0.1 -1.1  1.2 -1.7  1.8 -1.4  1.3 -3.1 -0.2 -1.3 -0.2  0.1  4.3  4.6 -0.1  0.1 -0.9 -0.2  1.1 -0.2 -1.8  0.3 -1.6  2. ]
vy_50sample [[7 7 6 5 0 1 4 8 3 9]
 [1 5 6 9 2 3 7 4 0 8]
 [3 5 8 7 6 9 2 0 1 4]
 [8 7 9 4 3 1 2 0 5 6]
 [7 1 5 2 3 6 4 9 0 8]
 [6 5 2 4 3 9 0 1 7 8]
 [4 9 0 3 1 2 5 6 7 8]
 [9 5 2 7 1 6 4 0 3 8]
 [6 2 5 4 8 3 9 0 1 7]
 [5 6 3 0 4 2 9 1 8 7]]
vt_50sample [[2 7 6 5 0 1 8 4 9 3]
 [5 6 1 9 2 3 7 4 0 8]
 [3 5 8 7 6 9 2 0 1 4]
 [8 7 9 4 3 1 2 0 5 6]
 [7 1 5 2 3 6 4 9 8 0]
 [6 5 2 4 3 9 0 1 7 8]
 [4 9 0 3 1 5 2 6 7 8]
 [9 5 2 7 1 6 4 0 3 8]
 [6 2 5 4 8 3 9 0 1 7]
 [5 6 3 0 4 2 1 9 8 7]]
Epoch 30610: Training cost= 0.2313, Training acc= 0.8393, Validation cost= 0.3075, Validation acc= 0.8394
Epoch 30620: Training cost= 0.2738, Training acc= 0.8393, Validation cost= 0.2695, Validation acc= 0.8395
Epoch 30630: Training cost= 0.2587, Training acc= 0.8394, Validation cost= 0.2576, Validation acc= 0.8395
Epoch 30640: Training cost= 0.2365, Training acc= 0.8394, Validation cost= 0.2332, Validation acc= 0.8395
Epoch 30650: Training cost= 0.2238, Training acc= 0.8394, Validation cost= 0.2901, Validation acc= 0.8395
Epoch 30660: Training cost= 0.2897, Training acc= 0.8394, Validation cost= 0.2622, Validation acc= 0.8395
Epoch 30670: Training cost= 0.2664, Training acc= 0.8394, Validation cost= 0.2603, Validation acc= 0.8395
Epoch 30680: Training cost= 0.2308, Training acc= 0.8394, Validation cost= 0.2939, Validation acc= 0.8396
Epoch 30690: Training cost= 0.2892, Training acc= 0.8395, Validation cost= 0.2981, Validation acc= 0.8396
Epoch 30700: Training cost= 0.2522, Training acc= 0.8395, Validation cost= 0.2501, Validation acc= 0.8396
tm  [ 0.5  1.   2.5 -3.2 -1.8 -0.4 -0.3 -0.  -1.1 -0.3 -4.5 -1.1 -0.4  0.3 10.7 -1.6 -0.7 -0.5  0.9 -0.3 -0.8 -0.5  2.2 -0.2 -1.3 -0.4 -0.6  1.5 -1.   3.  -0.   0.3 -0.3  1.9 -0.  -0.2  1.4 -1.9 -3.8 -0.4 -0.8  2.4  0.5 -0.3 -0.6 -0.  -1.3 -0.   1.5  9.4 -0.5 -0.2 -1.1  1.7 -0.6 -1.2 -0.8 -0.2 -0.3  2.2  1.4 -0.2 -1.1 -0.5 -0.1  0.3 -0.4 -0.2  2.3 -0.6 -0.1  1.2  0.2 -0.5 -3.9 -0.6 -0.8 -0.3 -0.1  0.8 -4.7 -0.4 -0.2  1.1 -0.9  3.4  4.7 -0.  -0.6  0.2 -0.4 -0.2 -0.2 -0.2 -0.5  1.1 -0.2 -2.5  0.1  0.2  1.9  5.2 -0.5 -0.3  0.6 -0.1 -2.5  0.3 -1.6  1.6 -0.4  0.8  0.6 -0.4  0.9 -0.4 -0.6 -0.3 -0.4 -0.3 -1.  -0.4  0.4 -0.2 -0.5 13.   0.1  1.3 -0.5  2.1  3.1 -0.8  0.3 -0.5  3.3  3.5 -0.2 -0.   0.6 -0.4  2.5 -1.   1.4 -0.1 -0.2  0.  -0.5  0.5 -0.6  0.1  1.7 -0.   4.8  1.   0.  -0.1  1.   1.  -1.8 -0.6 -0.7  2.8 -0.1 -0.1 -0.3  1.  -0.1  0.7  0.1 -0.2 -0.5  0.4 -0.2  0.5 -0.5  1.9 -0.9 -1.   6.6 -0.3 -1.4 -0.4 -0.6 -1.7 -0.1 -0.1  0.4 -0.9 -0.  -0.6 -0.4 -0.2 -0.1 -1.3  0.9  1.4 -1.4 -0.2 -0.2 -0.1 -0.5 -0.3 -0.9 -0.8 -0.3 -4.5 -0.1  0.2  4.8 -0.1 -0.2 -1.  -1.  -0.9 -0.4 -0.5  2.4 -0.6 -0.2 -0.2 -0.3 -0.2 -0.  -1.4  4.9  1.9 -1.5 -0.1  1.7  3.8 -0.9  0.2 -0.4  2.   1.9 -0.1  1.4 -1.3  3.5 -3.1 -0.2 -1.2 -0.3  0.2 14.5  6.3  0.5 -0.2 -1.2 -0.1 12.2  0.  -2.4 -0.7  3.8  0.5]
ty_50sample [[6 8 7 4 0 5 3 1 9 2]
 [2 2 4 4 6 9 9 7 8 5]
 [4 3 5 2 6 6 0 8 7 9]
 [6 7 9 1 8 3 4 0 2 5]
 [5 3 1 7 4 8 0 9 6 2]
 [2 3 1 4 5 8 9 6 6 7]
 [8 4 6 2 1 3 9 7 5 5]
 [4 0 9 8 1 6 5 3 2 7]
 [8 6 7 5 9 2 1 0 3 4]
 [6 2 3 4 8 5 7 9 0 1]]
tt_50sample [[6 8 7 0 4 5 3 1 2 9]
 [1 2 4 3 6 0 9 7 5 8]
 [3 4 5 2 1 6 0 8 9 7]
 [6 7 9 1 8 3 4 0 2 5]
 [5 3 1 7 4 8 0 9 6 2]
 [2 3 1 4 5 8 9 0 6 7]
 [8 4 6 2 1 3 9 7 5 0]
 [4 0 9 8 1 6 5 3 2 7]
 [8 6 7 5 9 2 1 0 3 4]
 [6 2 3 8 4 5 7 9 0 1]]
vm  [-0.8  1.  -3.3 -4.1 -1.  -0.1 -0.3 -0.2 -1.  -0.6 -4.9 -0.5 -0.3 -0.3  3.5 -0.3 -0.2 -0.  -1.1  4.8 -0.8 -0.3  0.6  0.3 -1.3  0.9 -0.1 -0.6 -0.7 -0.  -0.4 -0.1 -0.1 -5.4 -0.4 -0.1 -0.  -0.8 -3.7 -0.3 -0.3 -1.1  1.3  1.  -0.1 -0.3 -3.4 -0.   1.5  7.7 -0.3 -0.3 -0.3  7.1 -1.1 -0.6 -0.2 -1.7 -0.1  2.2  5.8 -0.3 -0.1 -0.5 -0.7 -0.8 -0.3 -0.4 -0.1 -0.2 -0.4 -0.2  0.9  0.3 -5.8 -1.1 -0.3 -0.3 -0.2 -0.6 -7.   0.7 -0.  -0.4 -1.1 -1.1  4.3  0.2 -0.2 -0.5  1.2 -0.1  0.   0.3 -0.6 -0.2 -1.1 -3.2  1.7 -0.2  2.9 -1.6  0.   0.1 -0.3 -0.3 -2.4 -0.6 -1.7  3.1 -0.3 -0.2 -0.  -0.8 -0.1  3.5 -0.9 -0.4 -0.  -0.6 -0.2 -1.8 -0.6 -0.2 -0.5  4.5 -0.2 -1.2 -0.1  8.7  1.1 -0.2 -0.3 -0.1 11.2 -2.   0.1 -0.2  0.2  2.6  3.5 -0.9 -0.1  0.  -0.2  0.1 -0.4 -0.   4.  -0.3  2.6 -0.1  2.5  2.  -0.2 -0.  -0.4 -0.4 -0.7 -0.4 -0.6  1.1  0.6 -0.2  0.1 -0.3 -0.3  1.2  1.  -0.1 -0.2  0.5 -0.1 -0.   0.2 -0.4 -1.  -0.3  6.5 -0.4  0.2 -0.9 -0.6 -1.9 -0.2 -0.1 -0.6 -0.1 -0.4 -0.2 -0.6 -0.4  0.8 -1.3 -1.6  0.9 -0.8  0.5 -0.2 -0.2 -0.3 -0.2 -0.5 -0.8 -0.2 -3.4 -0.3 -0.3  8.7 -0.4 -0.2  1.1 -1.2  3.7 -0.8 -0.8 -0.2 -0.6 -0.7 -0.1 -0.7  0.3 -0.2 -1.2  1.4  1.2 -1.9 -0.3 -1.   1.2 -0.2 -0.1 -0.4  4.   0.3  6.8 -0.2 -1.7  2.9 -2.3 -0.3 -1.1 -0.1 -0.  20.5  4.  -0.7 -0.2 -1.  -0.2 18.1  0.1 -2.4 -0.6  6.5 -2.1]
vy_50sample [[8 4 6 3 1 0 5 2 7 9]
 [6 1 5 7 0 9 3 4 2 8]
 [5 1 2 0 9 7 6 4 8 3]
 [9 4 6 7 2 5 3 0 8 1]
 [1 6 9 5 2 7 0 8 3 4]
 [4 0 5 1 2 9 3 6 8 7]
 [3 7 0 5 4 2 8 9 1 6]
 [7 4 1 6 6 8 5 9 2 3]
 [4 9 3 8 7 1 5 2 0 6]
 [2 6 7 4 0 5 1 3 9 8]]
vt_50sample [[8 4 6 3 1 0 5 2 7 9]
 [6 1 5 7 0 3 9 4 2 8]
 [5 1 2 0 9 7 6 4 8 3]
 [9 4 6 7 2 5 3 0 1 8]
 [1 6 9 5 2 0 7 8 3 4]
 [4 0 5 1 2 9 3 6 8 7]
 [7 3 0 5 4 2 8 9 1 6]
 [7 4 1 6 0 8 9 5 2 3]
 [4 9 3 8 7 1 5 2 0 6]
 [2 6 7 4 0 5 1 3 9 8]]
Epoch 30710: Training cost= 0.3052, Training acc= 0.8395, Validation cost= 0.2898, Validation acc= 0.8396
Epoch 30720: Training cost= 0.2576, Training acc= 0.8395, Validation cost= 0.2475, Validation acc= 0.8396
Epoch 30730: Training cost= 0.2599, Training acc= 0.8395, Validation cost= 0.2982, Validation acc= 0.8397
Epoch 30740: Training cost= 0.2831, Training acc= 0.8396, Validation cost= 0.2447, Validation acc= 0.8397
Epoch 30750: Training cost= 0.3001, Training acc= 0.8396, Validation cost= 0.2257, Validation acc= 0.8397
Epoch 30760: Training cost= 0.2252, Training acc= 0.8396, Validation cost= 0.3041, Validation acc= 0.8397
Epoch 30770: Training cost= 0.2627, Training acc= 0.8396, Validation cost= 0.2547, Validation acc= 0.8397
Epoch 30780: Training cost= 0.2755, Training acc= 0.8396, Validation cost= 0.2739, Validation acc= 0.8397
Epoch 30790: Training cost= 0.3087, Training acc= 0.8396, Validation cost= 0.3716, Validation acc= 0.8398
Epoch 30800: Training cost= 0.3260, Training acc= 0.8396, Validation cost= 0.2340, Validation acc= 0.8398
tm  [-0.8 -0.6 -0.4  4.  -1.5 -0.3 -0.2 -0.1  1.2  0.7 -4.4 -0.7 -0.3 -0.  -0.5 -1.7  0.1 -0.6 -0.  -0.6 -0.5 -0.1  1.7 -0.4 -0.6  1.3  0.1 -0.1 -0.6 -1.9 -0.8 -0.4 -1.  -2.7 -0.  -0.1 -0.6 -1.1  0.8 -0.2 -0.6  6.7 -0.2 -0.3 -0.   0.6 -0.2  0.5  0.1  9.9 -0.8 -0.1 -0.5 -1.3 -0.1  0.  -0.4  7.   5.2  3.9  1.9 -0.1 -0.5 -0.3 -0.7 -0.2  0.3 -0.2  1.6 -0.2  0.9  0.5 -0.   1.9 -3.2 -0.4 -0.5 -0.2  0.1 -0.2 -1.6 -0.1 -0.3  0.6 -0.6  7.9 -0.5  0.  -0.2 -0.  -0.4 -0.3 -0.1 -1.7 -0.7 -0.   0.2 -2.6 -0.3  0.1 -0.3  2.9 -0.1  0.5 -0.5  0.1 -1.1 -0.9 -1.5 -0.8 -0.3 -0.1 -0.2 -0.5  5.2 -0.2 -0.3  1.5 -0.4 -0.2 -0.4  2.9  0.5 -0.4 -0.1 -0.6 -0.2  7.6  6.8 -0.8  0.2 -0.7 -0.5 -0.5  5.8 -1.2 -0.4 -0.2 -0.3  0.3  3.5 -0.9  1.8 -0.1 -0.1 -0.1 -0.2 -0.2  6.6 -0.  -0.2 -0.2  2.4  1.8 -0.1  0.8 -0.1 -0.3 -0.2 -0.5  0.1 -0.2 -0.2 -0.2 -0.1 -0.3 -0.5  0.5 -0.  -0.3 -0.3  0.1 -0.2 -0.3 -0.2 -1.1 -0.4 -0.3  1.   0.2 -1.9 -0.3 -0.7 -2.  -0.  -0.1 -0.1 -0.4 -0.1  5.2  0.   0.2 -0.5 -0.3 -0.1 -1.9 -0.1 -1.3  0.7 -0.2 -0.4 -0.  -0.5 -0.4  0.5 -1.4 -0.3 -0.  -0.7 -0.2 -0.3 -0.1 -0.5  1.7 -1.  -0.4  2.1 -0.4 -0.  -0.6 -0.5  0.3 -0.  -1.2  3.8  1.2 -2.6 -0.1 -0.7  2.2 -0.7 -0.7 -0.  -0.6  1.7  1.5 -0.  -0.2  3.8 -2.4 -0.1 -0.9 -0.  -0.2  6.5 -0.4 -0.1 -0.4 -1.1 -0.7  3.2  0.   0.4 -0.8  3.5  5.6]
ty_50sample [[5 8 0 1 6 9 4 7 3 2]
 [2 9 8 7 5 1 3 0 4 6]
 [5 8 9 1 7 2 0 6 4 3]
 [1 2 3 4 5 7 6 0 9 8]
 [1 2 3 8 0 5 9 4 6 7]
 [1 6 3 4 8 5 2 9 0 7]
 [7 6 3 2 5 0 8 1 4 9]
 [8 9 2 6 0 1 7 3 5 4]
 [6 3 1 9 4 8 5 0 7 7]
 [2 2 5 3 6 1 0 4 8 7]]
tt_50sample [[5 8 0 1 6 9 4 7 3 2]
 [2 9 8 7 5 1 3 0 4 6]
 [5 8 9 1 2 7 0 6 4 3]
 [1 2 3 4 5 7 6 0 9 8]
 [1 2 3 8 0 5 9 4 6 7]
 [1 3 6 4 5 8 2 9 0 7]
 [7 6 3 2 5 8 0 1 4 9]
 [8 9 2 6 0 1 7 3 5 4]
 [6 3 1 9 4 8 5 0 7 2]
 [2 9 5 3 6 1 0 4 8 7]]
vm  [-0.4 -0.5 -2.4 -0.1 -1.2 -0.4 -0.3 -0.3 -0.9  0.  -6.2 -0.5 -0.1  0.  -1.3 -2.1  0.3 -0.4 -0.3 -1.  -0.8 -0.   1.2 -0.3 -0.6  1.2 -0.1 -0.4 -1.6 -1.1 -0.5 -0.3 -0.3 -4.3 -0.1  0.6  2.5 -0.9  2.3 -0.6 -0.4 -1.8 -0.2  2.2 -0.2 -0.   3.7  1.2  1.4  6.  -0.7 -0.2 -0.8 -2.  -0.   1.7 -0.7 -2.3  1.9  2.5  0.4  0.7 -0.9 -0.1 -1.1 -0.3 -0.1 -0.6  1.8  0.8  0.5  5.2  0.7  0.1 -1.5 -0.1 -0.3 -0.3  0.2 -0.1 -1.9  0.3 -0.3  0.7 -0.9 -2.2  4.2 -0.3 -0.1 -0.2 -0.4 -0.3 -0.3 -0.  -0.6 -0.2 -0.3 -1.6 -0.3 -0.3  0.  -1.1 -0.2 -0.1 -0.2 -0.2 -0.8 -0.5 -2.1 -1.5 -0.4 -0.2 -0.3 -0.   4.  -2.3 -0.2 -0.1 -0.4 -0.2 -0.2  5.7 -0.1 -0.5 -0.1 -1.6 -0.3  9.2 -0.2  1.6  0.2 -0.1 -0.3 -0.4  5.9 -2.6 -0.4 -0.3 -0.5  1.7  2.5 -1.3  1.  -0.1 -0.1 -0.4 -0.3 -0.2 -0.2 -0.3 -0.1 -0.2  2.9 -0.2 -0.1  0.3 -0.1 -0.4 -0.3 -0.6  0.7 -0.4 -0.3 -0.3 -0.1 -0.3 -0.5 -0.2 -0.2 -0.1 -0.2 -0.3 -0.1 -0.4 -0.   2.  -0.5 -0.2  0.3  0.1  0.9 -0.3 -0.3 -1.2  0.   0.5  0.1 -0.2  0.2  2.3 -0.3 -0.3 -0.5 -0.6  3.2  1.6 -0.3 -0.9  0.3 -0.1 -0.2 -0.  -0.3 -0.3 -0.3 -1.1 -0.4 -0.1 10.7 -0.3 -0.8 -1.6 -0.6 -0.  -0.4 -0.3 -0.6 -0.4 -0.2 -0.3 -0.3 -0.  -0.2 -1.2 -0.2 -0.5 -2.  -0.6 -0.6  1.3 -0.5 -0.2 -0.   4.7  3.5  4.4  0.7 -0.   0.9 12.5 -0.1  5.2 -0.1 -0.1  7.5 -0.8  0.  -0.4 -0.7 -0.4  4.3 -0.2  1.5 -0.6  5.8  0.3]
vy_50sample [[8 8 4 3 9 6 1 7 5 2]
 [0 4 1 3 6 2 9 5 8 7]
 [6 1 0 2 3 4 8 7 9 5]
 [6 9 4 1 2 0 3 8 7 5]
 [1 9 4 7 3 6 0 5 2 8]
 [3 6 7 1 2 9 4 8 5 0]
 [4 1 8 0 9 2 5 6 7 3]
 [1 3 5 4 7 8 6 9 2 0]
 [6 5 2 1 7 9 3 8 0 4]
 [8 1 3 2 5 7 4 0 9 6]]
vt_50sample [[0 8 4 3 9 6 1 7 5 2]
 [0 4 1 3 6 2 9 5 8 7]
 [6 1 0 2 3 4 8 7 9 5]
 [6 9 4 1 2 0 3 8 7 5]
 [1 9 4 7 3 6 0 5 2 8]
 [3 6 7 1 9 2 4 8 5 0]
 [4 1 8 0 9 2 5 6 7 3]
 [1 3 5 4 7 8 6 9 2 0]
 [6 5 2 1 7 9 3 8 0 4]
 [8 1 3 2 5 4 7 9 0 6]]
Epoch 30810: Training cost= 0.3045, Training acc= 0.8397, Validation cost= 0.3037, Validation acc= 0.8398
Epoch 30820: Training cost= 0.2379, Training acc= 0.8397, Validation cost= 0.3071, Validation acc= 0.8398
Epoch 30830: Training cost= 0.2626, Training acc= 0.8397, Validation cost= 0.2545, Validation acc= 0.8398
Epoch 30840: Training cost= 0.2699, Training acc= 0.8397, Validation cost= 0.2807, Validation acc= 0.8398
Epoch 30850: Training cost= 0.3285, Training acc= 0.8397, Validation cost= 0.2874, Validation acc= 0.8398
Epoch 30860: Training cost= 0.2859, Training acc= 0.8397, Validation cost= 0.2901, Validation acc= 0.8399
Epoch 30870: Training cost= 0.3013, Training acc= 0.8398, Validation cost= 0.3150, Validation acc= 0.8399
Epoch 30880: Training cost= 0.2683, Training acc= 0.8398, Validation cost= 0.2760, Validation acc= 0.8399
Epoch 30890: Training cost= 0.2866, Training acc= 0.8398, Validation cost= 0.2749, Validation acc= 0.8399
Epoch 30900: Training cost= 0.2642, Training acc= 0.8398, Validation cost= 0.3172, Validation acc= 0.8399
tm  [-0.2 -0.9 -1.6 -2.1 -1.8 -0.1 -0.1 -0.  -0.1 -0.2 -1.5 -0.3 -0.5 -0.3  1.4 -2.3 -0.2 -0.3 -0.1 -0.  -1.2 -0.3 -0.4 -0.  -1.2  5.5 -0.1 -0.1 -1.5 -1.2  4.3 -0.5 -0.6  4.6 -0.1 -0.4  1.7 -1.2 -0.5 -0.4 -0.7 -0.1 -0.1  1.6 -0.4 -0.2 -0.7 -0.1  4.  -0.6 -0.3 -0.1 -0.1 -1.3  1.8  0.3 -0.6 -1.1  2.7 -1.9  1.2 -0.4  0.4  0.8 -0.1  0.6  0.5 -0.1  2.4  0.2 -0.2  5.6 -0.2  0.7 -3.3 -0.2 -0.7 -0.2  0.   0.5  3.9 -0.3  1.1 -0.4 -0.9  0.5  5.4 -0.2  0.  -0.3  0.1 -0.3 -0.4 -0.8 -0.4  0.1 -0.  -2.3 -0.2 -0.4 -0.   1.5 -0.9 -0.2 -0.2  1.6 -1.3  4.2 -0.5 -0.6 -0.3  0.2 -0.1 -0.5  5.8 -2.5 -0.4  0.6 -0.1  0.5 -0.   1.2 -0.1  1.4 -0.3  1.7 -0.2  7.4  1.5  1.5  1.5 -0.2 -0.4 -0.3  4.8  7.4 -0.1  0.4  0.6 -0.2  3.3 -1.6  2.  -0.3 -0.   0.  -0.3 -0.2 -0.  -0.2  1.5  0.3  0.7  1.1 -0.3 -0.  -0.5 -0.3 -0.4 -0.   0.1 -0.5  0.8  0.1 -0.1 -0.5 -0.5  0.  -0.3 -0.2 -0.5 -0.3 -0.2 -0.5 -0.4  1.3 -0.5  0.7  2.4  0.2 -0.5 -0.1 -0.4 -2.   0.3  0.2  2.3 -0.2  0.5  3.5 -0.2 -0.3 -0.1 -1.1  2.5 -0.2 -0.7 -1.1 -0.2 -0.2 -0.2 -0.2 -0.2 -0.5 -0.1 -1.1 -0.  -0.3 -0.4 -0.4 -0.5 -1.3 -0.7  0.3 -0.3 -0.3 -0.4 -1.  -0.3 -0.3 -0.4 -0.3 -0.4 -1.3  2.9 -1.3 -2.3 -0.2  1.6  2.3 -0.3 -0.3 -0.2 -0.3  3.9  3.5  1.9 -0.6  3.4  1.4  0.   0.7 -0.1 -0.1 -0.3 -0.6  0.2 -0.  -1.2 -0.4 -1.1  0.1 -0.3 -0.   4.5  1. ]
ty_50sample [[0 4 6 6 7 5 1 8 8 2]
 [2 8 9 1 5 6 3 7 4 0]
 [3 3 6 4 5 0 8 7 2 1]
 [3 6 0 5 1 8 4 4 7 9]
 [7 4 6 1 8 5 3 0 9 2]
 [8 8 1 0 7 2 9 3 5 6]
 [8 3 0 2 5 9 6 7 4 1]
 [9 6 5 4 7 1 8 2 3 0]
 [7 1 4 0 5 6 3 9 2 8]
 [8 4 0 5 1 2 9 6 3 7]]
tt_50sample [[0 4 6 7 3 9 5 1 8 2]
 [2 8 9 1 5 6 3 7 0 4]
 [3 9 6 4 5 0 8 7 2 1]
 [3 6 0 5 1 8 4 2 7 9]
 [7 4 6 1 8 5 3 0 2 9]
 [8 4 1 0 7 2 9 3 5 6]
 [8 3 0 2 5 6 9 7 4 1]
 [9 6 5 4 7 1 8 2 3 0]
 [7 1 4 0 5 6 3 9 2 8]
 [8 4 0 5 1 2 9 6 3 7]]
vm  [-0.9 -0.3 -0.1 -0.7 -1.4 -0.1 -0.2 -0.   1.5 -0.8 -0.  -0.  -0.6 -0.4  2.7 -0.3 -0.2 -0.4 -0.4  0.4 -1.  -0.2 -1.2 -0.2 -1.2  1.6 -0.1 -0.2  0.9 -1.8  2.6 -0.1  1.   4.5 -0.4 -0.6 -0.5 -1.6 -2.7 -0.3 -0.  -1.4 -0.5 -0.7 -0.1 -0.2 -1.1 -0.2 -0.3 -3.2 -0.7 -0.   0.1 -0.  -1.  -0.2 -0.4  3.1  3.7 -0.8  5.  -0.3 -0.1 -0.2  1.4 -0.3 -0.1  0.7  1.1 -0.3 -0.4 -1.2 -0.3 -0.2 -4.3  0.1 -0.6 -0.  -0.2 -0.3  2.1 -0.3 -0.   0.8 -0.2 -0.9 -0.4 -0.1 -0.3 -0.4 -0.2  0.4 -0.2 -0.8 -0.5 -0.3 -0.2 -2.7 -0.2 -0.5  3.7 -1.7 -0.1 -0.2 -0.1 -0.6 -2.2  1.8  0.   0.4  0.2  0.1 -0.2 -1.1  2.2  7.1 -0.1  1.1 -0.1  0.8 -0.4 -0.6  0.3  0.1 -0.2  3.3 -0.2  3.2  4.9  9.2 -0.1 -0.7 -0.1 -0.6  9.2 12.9  1.  -0.2  0.6 -0.6  1.6 -0.2  1.8 -0.1 -0.1 -0.2 -0.3 -0.   3.3 -0.1  0.3 -0.2 -0.8  1.3 -0.3 -0.2 -0.3 -0.1 -0.9  0.2 -0.7  0.9 -0.1 -0.1 -0.3 -0.3 -0.3  2.1 -0.2 -0.1 -0.3 -0.2 -0.2 -0.2 -0.1 -0.4 -1.4 -0.5  5.3 -0.1 -0.9 -0.3 -0.4 -1.8 -0.5 -0.2 -0.3 -0.5 -0.4  5.4 -0.2  0.1 -0.4 -1.2 -1.3 -1.4 -0.9 -0.3 -0.1 -0.2 -0.3 -0.2 -0.3 -0.6 -0.2 -2.7  0.2 -0.2 -2.  -0.3 -0.3  4.1 -0.8  3.5 -0.7 -0.   3.7 -0.7 -0.1 -0.2 -0.5 -0.3 -0.2 -1.  -0.1  1.7 -2.1 -0.3  1.2  3.  -0.1  0.1 -0.  -1.1 -0.7  0.9  0.4 -1.2  3.  -1.8  0.1 -0.8  0.1 -0.   0.6  0.7 -0.2 -0.5 -1.2 -0.2 -0.7 -0.4 -1.9 -0.2  7.9 -2.3]
vy_50sample [[3 6 1 5 4 7 9 0 8 2]
 [6 8 7 2 4 1 5 9 3 0]
 [0 8 7 6 2 4 9 9 3 1]
 [0 3 9 7 4 5 2 8 6 1]
 [8 8 4 9 9 6 0 2 3 5]
 [9 5 4 0 6 2 3 7 1 8]
 [1 6 8 9 0 4 7 5 2 3]
 [7 8 1 1 4 2 5 9 6 0]
 [6 7 9 4 1 5 8 2 3 0]
 [5 1 8 2 4 7 0 9 3 6]]
vt_50sample [[3 6 1 5 4 7 0 9 8 2]
 [6 8 7 2 4 1 5 0 3 9]
 [0 8 7 6 2 4 9 5 3 1]
 [0 3 9 7 4 5 2 8 6 1]
 [8 1 7 4 9 0 6 2 3 5]
 [9 5 4 0 6 2 3 7 1 8]
 [1 6 8 9 0 4 7 5 2 3]
 [7 8 1 3 4 2 5 9 6 0]
 [6 7 9 1 4 5 8 2 3 0]
 [5 1 8 2 4 7 0 9 3 6]]
Epoch 30910: Training cost= 0.2804, Training acc= 0.8398, Validation cost= 0.3028, Validation acc= 0.8399
Epoch 30920: Training cost= 0.3013, Training acc= 0.8398, Validation cost= 0.2322, Validation acc= 0.8400
Epoch 30930: Training cost= 0.3013, Training acc= 0.8399, Validation cost= 0.2830, Validation acc= 0.8400
Epoch 30940: Training cost= 0.2880, Training acc= 0.8399, Validation cost= 0.2766, Validation acc= 0.8400
Epoch 30950: Training cost= 0.3147, Training acc= 0.8399, Validation cost= 0.2944, Validation acc= 0.8400
Epoch 30960: Training cost= 0.2686, Training acc= 0.8399, Validation cost= 0.2639, Validation acc= 0.8400
Epoch 30970: Training cost= 0.3754, Training acc= 0.8399, Validation cost= 0.3286, Validation acc= 0.8400
Epoch 30980: Training cost= 0.2659, Training acc= 0.8399, Validation cost= 0.2532, Validation acc= 0.8401
Epoch 30990: Training cost= 0.2566, Training acc= 0.8400, Validation cost= 0.2763, Validation acc= 0.8401
Epoch 31000: Training cost= 0.2502, Training acc= 0.8400, Validation cost= 0.2843, Validation acc= 0.8401
tm  [ 2.4 -0.1  9.3 16.8 -1.5 -0.2 -0.4  0.  -1.4 -0.1 -2.2 -0.4 -0.3 -0.1  0.6 -0.9 -1.  -0.4 -0.1 -2.2 -0.8 -0.1  1.  -0.1 -0.9 -0.1 -0.3 -0.4 -1.1  5.2 -0.6 -0.2  0.7  7.9 -0.1 -0.1  3.7 -1.4  2.9 -0.5  0.3  3.2  2.3 -1.  -0.2 -0.2 10.9  0.7  4.8  2.9 -0.3 -0.  -0.1 -3.2 -0.7  0.  -0.8  4.6 -1.8  3.2 -2.6 -0.5 -0.9 -0.   0.2 -0.2 -0.  -0.4  1.2 -0.2 -0.   2.  -0.5 -0.7  5.2 -0.5 -0.9 -0.5  0.5 -0.1 11.1  1.  -0.3  0.2 -1.4  2.9  3.3 -0.4 -0.1 -0.2 -0.   1.  -0.3  2.2  0.2  0.4 -0.3 -0.  -0.1 -0.   0.8  5.8 -1.  -0.3 -0.  -0.1  0.4 -0.2 -0.6 -2.3 -0.2 -0.4 -0.1 -0.1 -0.4 -0.8 -0.5 -0.9 -0.  -0.6 -0.1  9.2 -0.3 -0.5 -0.2  0.8 -0.  12.8 -1.5 -1.9  2.2 -0.1  0.9 -0.4 -0.9  8.1 -0.3  0.3 -0.3 -0.9  0.8 -0.6  1.1 -0.1 -0.  -0.4 -0.5 -0.1 -0.9 -0.3 -1.3 -0.2  3.  -0.5 -0.1  0.2  0.6 -0.5 -1.1 -0.7 -0.5  1.1 -0.5 -0.1 -0.3  1.  -0.3 -0.9 -0.2 -0.  -0.4  0.3 -0.3  0.1 -0.2  1.9 -1.4 -0.2 -0.1 -0.3 -1.7 -0.5 -0.2 -0.6 -0.2 -0.1  2.9 -0.6 -0.3 -1.2 -0.4 -0.3 -0.6 -0.8 15.7  4.6  2.1  1.  -0.1 -0.1 -0.  -0.3  0.2 -0.6 -0.5  2.2 -0.4 -0.4 -1.1 -0.3 -0.4 -1.3 -0.5 -1.8 -0.5 -0.4  4.5 -0.5 -0.  -0.1 -0.2 -0.2  0.8 -0.7  1.6 -0.5 -1.4 -0.6 -0.1  2.3 -0.4 -0.5 -0.1 -0.6 -0.1 -2.2  0.9  2.   0.7  4.8 -0.   2.4 -0.1 -0.2 -2.1 -2.1 -0.3 -0.2 -0.7 -0.1 -2.9 -0.1  1.9 -0.2  2.9  9. ]
ty_50sample [[7 9 6 5 0 8 3 4 2 1]
 [8 2 0 3 6 4 9 5 7 1]
 [8 8 7 3 6 2 5 1 0 4]
 [7 3 2 1 8 5 9 0 6 4]
 [2 9 7 5 3 6 1 0 4 8]
 [9 0 5 4 2 1 3 7 6 8]
 [9 6 8 5 7 4 2 1 0 3]
 [4 0 6 1 7 2 9 8 3 5]
 [4 2 0 5 3 9 8 6 7 1]
 [6 0 8 3 2 1 7 4 9 5]]
tt_50sample [[9 7 6 5 0 8 3 4 2 1]
 [8 2 0 3 6 4 9 5 7 1]
 [8 9 7 3 6 2 5 0 1 4]
 [7 3 2 1 8 5 9 0 6 4]
 [2 9 7 5 3 6 1 0 4 8]
 [9 0 5 4 2 1 3 7 6 8]
 [9 6 8 5 7 4 2 1 0 3]
 [4 6 0 1 7 2 9 8 3 5]
 [4 2 0 5 3 9 8 6 7 1]
 [6 0 8 3 2 1 4 7 5 9]]
vm  [-0.6  1.7  8.1 17.3 -1.4  0.3 -0.1 -0.  -1.2 -0.8  2.9 -0.1 -0.2 -0.3  0.   5.2 -0.1 -0.4 -0.5 -0.7 -0.5 -0.3  1.7  0.  -0.8  1.3  0.1 -0.2 -0.6  4.  -1.8 -0.3 -0.4  1.  -0.3  0.1  3.9  3.3  6.9 -0.3  0.   6.   4.6 -0.8  0.3 -0.1  5.  -0.2  2.7  8.2 -0.3  0.   1.3  0.8 -0.7 -0.  -0.4 10.4 -2.1  6.4 -0.9 -0.4 -0.3 -0.  -0.8  0.5  0.5 -0.3 -0.1  0.1 -0.1 -0.3 -0.1 -0.3  0.8  0.3 -0.1 -0.2  0.2  0.6  2.   0.2  0.1 -0.2 -0.8  7.8 -0.5 -0.1 -0.  -0.2 -0.2  0.1 -0.2  2.9 -0.3 -0.2 -0.  -0.5  0.1 -0.1  2.6  4.8 -0.6 -0.  -0.4  0.1 -0.2 -1.1  0.9 -1.8 -0.2  0.3 -0.2 -0.  -1.5  2.7 -0.7 -1.6  0.1 -0.6  1.4  6.2 -0.2 -0.2  0.3  0.4 -0.1  1.4 -1.5 -1.7  1.2 -0.3 -0.3 -0.2 -1.2 -1.3 -0.1 -0.2  0.1 -0.5 -0.8 -0.4 -0.4 -0.2 -0.1  0.5  0.3 -0.3  3.6  0.  -1.6 -0.1  2.5 -0.2 -0.3  0.  -0.4  0.1  0.1 -0.5 -0.1 -0.1 -0.1 -0.2 -0.3  0.5 -0.3 -1.   0.1 -0.1 -0.1 -0.  -0.1 -0.2  0.2 -0.4 -0.4  0.2 -0.6  0.3 -1.8 -0.3 -0.2 -1.2 -0.3 -0.6  0.3 -0.7 -0.2 -1.   0.4 -0.4 -0.1 -0.4  7.1  5.4  1.6  3.2  0.  -0.2 -0.2 -0.1 -0.  -0.4 -0.   2.2 -0.2 -0.3 -1.   0.4 -0.5 -0.  -0.1  0.1 -0.4 -0.3  4.2 -0.5 -0.1 -0.4 -0.2 -0.1 -0.3 -0.9  2.4  1.8  0.3 -0.3  0.3 -0.1 -0.6 -0.7 -0.  -0.5 -0.1 -1.8 -0.3  0.9  0.1 -0.3 -0.1 -0.3  0.3 -0.1 -0.1 -1.8 -0.4 -0.  -0.4 -0.6 -0.9 -0.   4.1 -0.1 -1.1  8.5]
vy_50sample [[5 9 2 8 7 6 0 1 3 4]
 [5 3 3 1 2 2 6 4 0 9]
 [0 9 7 2 5 1 3 6 8 4]
 [8 3 2 7 6 5 1 0 0 4]
 [3 5 2 0 4 9 1 8 6 7]
 [1 4 7 7 3 2 0 5 6 9]
 [5 1 0 9 6 3 7 2 4 8]
 [4 5 3 7 9 6 1 2 0 8]
 [0 8 6 7 9 1 4 2 5 3]
 [9 1 7 8 3 5 4 2 0 0]]
vt_50sample [[5 9 2 8 7 6 0 1 3 4]
 [5 3 7 1 2 8 6 4 9 0]
 [0 9 7 2 5 1 3 6 8 4]
 [8 3 2 7 6 5 1 9 0 4]
 [3 5 2 0 9 4 1 8 6 7]
 [1 4 7 8 3 2 0 5 9 6]
 [5 1 0 9 6 3 7 2 4 8]
 [4 5 3 7 9 6 1 2 0 8]
 [0 8 6 7 9 1 4 2 5 3]
 [9 1 7 8 3 5 4 2 0 6]]
Epoch 31010: Training cost= 0.2786, Training acc= 0.8400, Validation cost= 0.2892, Validation acc= 0.8401
Epoch 31020: Training cost= 0.3438, Training acc= 0.8400, Validation cost= 0.2996, Validation acc= 0.8401
Epoch 31030: Training cost= 0.2972, Training acc= 0.8400, Validation cost= 0.3085, Validation acc= 0.8401
Epoch 31040: Training cost= 0.2869, Training acc= 0.8400, Validation cost= 0.2721, Validation acc= 0.8401
Epoch 31050: Training cost= 0.2837, Training acc= 0.8401, Validation cost= 0.2466, Validation acc= 0.8402
Epoch 31060: Training cost= 0.2293, Training acc= 0.8401, Validation cost= 0.2847, Validation acc= 0.8402
Epoch 31070: Training cost= 0.2495, Training acc= 0.8401, Validation cost= 0.2603, Validation acc= 0.8402
Epoch 31080: Training cost= 0.2661, Training acc= 0.8401, Validation cost= 0.2413, Validation acc= 0.8402
Epoch 31090: Training cost= 0.2645, Training acc= 0.8401, Validation cost= 0.3008, Validation acc= 0.8402
Epoch 31100: Training cost= 0.3210, Training acc= 0.8401, Validation cost= 0.1960, Validation acc= 0.8402
tm  [-0.1 -0.7 -0.7  2.6 -1.3  0.7 -0.  -0.1 -0.   0.1  4.5 -0.8 -0.   0.2 -0.6 -0.7 -0.1 -0.2 -0.1 -0.1 -1.1 -0.2  1.5 -0.  -0.7  3.5 -0.1 -0.1 -1.6 -2.3 -0.3 -0.1 -0.1 -2.2 -0.1 -0.1  2.4  1.5 -1.1 -0.7 -0.2 -1.9 -0.7 -0.4 -0.1 -0.3 -0.1 -0.5  4.   3.6 -0.4  0.1 -0.2  5.9  2.6  1.7 -0.5 -1.4  4.   2.9  0.2 -0.2  0.2  1.8 -0.3  0.4  0.1 -0.2 -0.  -0.1  0.4  6.3  0.1 -0.1 -2.7 -0.5 -0.7 -0.1 -0.3 -0.2 -0.7 -0.1  0.2 -0.5 -1.2 -2.4  1.7  0.1 -0.1 -0.3 -0.2 -0.2  0.  -0.7 -0.1 -0.1 -0.1 -2.2 -0.1 -0.4 -0.3 -0.8 -1.  -0.1  0.2 -0.  -1.1 -0.3  1.1 -0.8 -0.4 -0.1  0.2 -0.3  5.8 -2.9 -0.6  0.3  0.2 -0.1 -0.1  1.8 -0.6 -0.  -0.5 -0.7 -0.5 -1.2  0.6  1.6  1.9 -0.3 -0.2  0.4  9.4  4.1 -0.3 -0.1  0.3 -0.2 -0.8 -1.7 -1.  -0.3 -0.1 -0.2 -0.4  0.4 -0.5 -0.5 -0.4  0.1  2.5 -0.2 -0.5 -0.2 -0.2  0.3 -0.7 -0.1 -0.1 -0.3 -0.1 -0.3 -0.2 -0.6 -0.3 -0.1 -0.1 -0.1 -0.2 -0.3  0.3 -0.1 -0.1  1.9 -0.7  0.2  2.9 -0.3  3.2  0.4 -0.4 -1.3 -0.1 -0.3  1.9 -0.1  0.2  6.7 -0.4 -0.2 -0.3 -0.7  3.7 -0.2 -0.9 -1.4 -0.2  0.5 -0.1 -0.1 -0.2 -0.1 -0.2 -1.5 -0.5 -0.2  8.9 -0.  -0.3 -1.6 -0.7 -0.6 -0.6 -0.3  3.2 -1.  -1.  -0.2 -0.2  0.2  0.1 -1.3  1.7 -1.3 -0.   1.6 -0.4  2.2 -0.1 -0.1 -0.3  4.1  4.3  2.1  2.6 -0.5  2.  12.3 -0.   5.4  0.1 -0.3  4.1 -0.5 -0.  -0.4 -1.3 -0.1  1.2 -0.1 -0.7 -0.1 -0.3  1.6]
ty_50sample [[0 2 6 8 3 9 4 1 7 5]
 [8 3 9 4 7 2 6 1 0 5]
 [1 9 0 2 4 5 8 6 3 7]
 [0 1 9 3 3 7 2 4 8 5]
 [1 5 4 3 7 2 9 8 6 0]
 [0 2 8 1 5 9 4 7 7 3]
 [7 1 6 0 5 8 8 4 9 3]
 [3 0 7 5 8 6 9 4 2 1]
 [8 5 1 6 0 3 9 7 2 4]
 [6 2 8 9 5 1 7 4 0 3]]
tt_50sample [[0 2 6 8 3 9 4 1 7 5]
 [8 3 9 4 7 2 6 1 0 5]
 [1 9 0 2 5 4 8 6 3 7]
 [0 1 9 3 6 7 2 4 8 5]
 [1 5 4 3 7 2 9 8 6 0]
 [0 2 8 1 5 9 6 4 7 3]
 [7 1 6 0 5 8 4 9 2 3]
 [3 0 7 5 8 6 9 4 2 1]
 [8 5 1 6 0 3 9 7 2 4]
 [6 2 8 9 5 1 7 4 0 3]]
vm  [-0.1 -0.5 -2.2 -0.4 -0.6 -0.4 -0.4 -0.1  0.3 -0.5  7.7 -0.9  0.5 -0.1 -1.5  2.2 -0.4 -0.2  0.  -0.8 -1.  -0.3  2.  -0.1 -1.1  1.1 -0.4  0.7 -0.5 -1.4  3.6 -0.1  0.5 -1.4 -0.1 -0.4  1.2 -0.1 -1.9 -0.5 -0.6  5.7 -0.3 -0.8 -0.2 -0.5  1.5 -0.7  1.3  4.  -0.5 -0.2 -0.6  5.9 -0.7  1.9 -0.4  3.4  3.5 -0.8  0.2 -0.3 -0.1  0.2  1.8 -0.8 -0.5  0.8  0.1 -0.5 -0.2  0.1 -0.2 -0.5 -2.4 -0.3 -0.7 -0.  -0.4 -0.2  5.5  0.1 -0.3 -0.1 -0.7  6.4  1.8  0.5 -0.3 -0.1 -0.4 -0.3 -0.5 -0.8 -0.4 -0.4  0.7 -2.2 -0.2 -0.5  1.8 -0.1 -0.7  0.  -0.2 -0.7 -2.   1.4  0.5 -1.  -0.3 -0.1 -0.1 -0.7  2.6  0.5 -0.3 -0.1 -0.3 -0.1 -0.4  2.4  0.6  0.5 -0.3 -1.7 -0.4 -1.2  4.6 -0.6  1.6 -0.6 -0.4 -0.6 15.  13.   0.1 -0.1 -0.4 -0.6 -0.8 -0.3 -0.9  0.1 -0.3 -0.3  0.   0.3  7.6 -0.2 -0.2 -0.2  0.7 -0.4 -0.4 -0.2 -0.   0.9 -1.5 -0.7 -0.   1.7 -0.3 -0.4 -0.2 -0.6 -0.4  0.3 -0.1 -0.  -0.   0.7 -0.2 -0.  -0.2 -2.  -1.4 -0.3  3.6 -0.1 -1.7 -0.6 -0.5 -1.5 -0.5 -0.4  1.  -0.  -0.3  3.8 -0.2 -0.7 -0.7 -0.7  2.5 -1.4 -0.8 -0.7 -0.3  0.5 -0.4 -0.3 -0.5 -0.3 -0.3 -2.6  0.4 -0.1 -3.1 -0.  -0.4 -0.  -0.7 -0.5 -0.3 -0.4  3.  -0.9 -0.2 -0.4 -0.1 -0.3 -0.1 -1.1  5.1 -0.4  1.1  0.8 -0.4  3.8 -0.3  0.9 -0.3 -1.7  1.3  4.1  1.5 -0.8  0.9 -2.  -0.1 -0.8 -0.1 -0.3 -0.7 -0.3 -0.1 -0.6 -1.2  0.4 -1.8 -0.1 -1.3 -0.  -1.2  5.7]
vy_50sample [[6 5 2 0 4 9 1 8 3 7]
 [9 1 7 4 8 0 2 5 6 3]
 [1 2 2 7 4 4 8 0 6 3]
 [3 3 9 7 6 4 8 2 0 1]
 [4 2 9 5 1 7 8 6 0 3]
 [0 1 7 5 8 4 6 2 9 3]
 [7 4 5 3 2 1 8 9 6 0]
 [7 4 3 9 0 5 2 8 6 1]
 [3 6 4 4 5 1 2 0 7 8]
 [6 9 1 2 7 3 5 0 4 8]]
vt_50sample [[6 5 2 0 4 9 1 8 3 7]
 [9 1 7 4 8 0 2 5 6 3]
 [1 2 9 5 7 4 8 0 6 3]
 [5 3 9 7 6 4 8 2 0 1]
 [4 2 9 5 1 7 8 6 0 3]
 [0 1 7 5 8 4 6 2 9 3]
 [7 4 5 3 2 1 8 9 6 0]
 [7 4 3 9 0 5 2 8 6 1]
 [3 6 9 4 5 1 2 0 7 8]
 [6 9 1 2 7 3 5 0 4 8]]
Epoch 31110: Training cost= 0.2380, Training acc= 0.8402, Validation cost= 0.2395, Validation acc= 0.8403
Epoch 31120: Training cost= 0.2828, Training acc= 0.8402, Validation cost= 0.2983, Validation acc= 0.8403
Epoch 31130: Training cost= 0.2843, Training acc= 0.8402, Validation cost= 0.2622, Validation acc= 0.8403
Epoch 31140: Training cost= 0.3665, Training acc= 0.8402, Validation cost= 0.2580, Validation acc= 0.8403
Epoch 31150: Training cost= 0.3210, Training acc= 0.8402, Validation cost= 0.3120, Validation acc= 0.8403
Epoch 31160: Training cost= 0.2668, Training acc= 0.8402, Validation cost= 0.3029, Validation acc= 0.8403
Epoch 31170: Training cost= 0.2723, Training acc= 0.8402, Validation cost= 0.2685, Validation acc= 0.8404
Epoch 31180: Training cost= 0.2930, Training acc= 0.8403, Validation cost= 0.2465, Validation acc= 0.8404
Epoch 31190: Training cost= 0.2928, Training acc= 0.8403, Validation cost= 0.2707, Validation acc= 0.8404
Epoch 31200: Training cost= 0.2561, Training acc= 0.8403, Validation cost= 0.2594, Validation acc= 0.8404
tm  [-1.4 -0.4 -2.  13.9 -0.9  0.2 -0.   0.1 -0.2 -0.1 -0.7 -0.5  0.1 -0.1 -4.3 -0.8 -0.4 -0.4 -0.2 -1.8 -0.8 -0.2  2.4 -0.1 -0.7  2.9 -0.1  0.3 -1.2 -2.3 -0.3 -0.2 -0.7 -3.7  0.1  1.   2.5  3.3 18.8 -0.1  0.4  3.7 -0.3  2.1  0.   0.3 11.4 -0.2 -1.1  8.3 -0.6 -0.1  0.7 -2.3  1.1  4.8 -0.4  1.7  2.   3.2 -0.6 -0.2 -0.1  0.1 -0.6  1.9  0.  -0.4 -0.2 -0.  -0.1  1.9 -0.  -0.5 11.2 -0.3  0.2 -0.1 -0.1  0.2 11.2  0.5 -0.2  1.1  3.2  4.6 -1.1 -0.1 -0.1  0.8  0.7 -0.1 -0.2 -1.  -0.3 -0.1  0.7 -0.1  0.3  2.   1.  -0.5  1.4 -0.1 -0.2 -0.5  3.5 -0.2 -0.2 -2.2 -0.5  0.3 -0.2 -0.   3.8 -1.  -0.1 -1.  -0.2 -0.4 -0.2  9.8  1.6  0.1 -0.2 -5.  -0.2 10.3  2.5 -3.2 -0.8 -0.4 -0.2 -0.7  3.7 -3.5  0.5 -0.1 -0.1 -0.2  1.4 -1.2 -0.6 -0.1 -0.  -0.2 -0.  -0.1  6.4 -0.1 -0.9 -0.1 -0.   1.2  0.3 -0.1  0.8 -0.2  3.2  0.4  0.9 -1.1 -0.3 -0.1  0.  -0.4  0.4  0.5  0.3 -0.1  0.  -0.  -0.2  0.3 -0.1 -1.1  1.4  0.5 -2.3  0.4 -0.9 -0.3 -0.4 -1.3 -0.1 -0.1 -0.9  0.7 -0.1  6.5 -0.2 -0.1 -0.5 -0.4  5.6 -0.4  3.4 -0.6  0.   0.3 -0.1  0.2 -0.3 -0.7  0.2  5.5 -0.2  0.5  2.3  0.3 -0.1 -0.9 -0.3  5.6 -0.9 -0.2 -0.7 -0.7 -0.4 -0.4 -0.2 -0.2  0.7 -0.6 -0.1 -0.2 -0.8  1.6 -0.4 -0.5 -0.6 -1.5 -0.1  1.6  4.   3.6  0.6  5.5  3.  12.7 -0.2  4.5  0.2 -0.1 -2.  -2.9  0.2  0.  -1.1 -0.1 -3.  -0.1 12.3 -0.2 -0.1 13.2]
ty_50sample [[9 1 0 8 5 4 2 3 6 7]
 [0 2 9 7 5 3 6 6 8 1]
 [5 9 3 3 0 2 6 7 1 4]
 [3 2 2 9 6 5 7 0 1 8]
 [2 1 4 3 5 6 9 8 0 7]
 [7 9 0 5 4 1 8 6 3 2]
 [1 0 8 3 6 5 2 7 9 4]
 [4 5 0 7 1 6 2 8 3 9]
 [9 1 3 8 5 0 4 6 7 2]
 [0 3 7 2 1 9 4 5 8 6]]
tt_50sample [[9 1 0 8 5 2 4 3 6 7]
 [0 2 9 7 5 3 6 8 4 1]
 [5 9 3 0 8 2 6 7 1 4]
 [3 4 2 9 6 5 7 0 1 8]
 [2 1 4 3 5 6 9 8 0 7]
 [7 9 0 5 4 1 8 6 3 2]
 [1 0 8 3 6 5 2 7 9 4]
 [4 5 0 7 1 6 2 8 3 9]
 [9 1 3 8 5 0 4 6 7 2]
 [0 3 7 2 1 9 4 5 8 6]]
vm  [-1.4 -0.3 -2.3  4.3 -0.4 -0.1 -0.4 -0.1  1.1 -0.6  6.9 -0.4 -0.2 -0.  -2.1  5.7 -0.3 -0.2 -0.5 -0.9 -1.1 -0.1 -0.3 -0.4 -0.6  0.4 -0.2 -0.1 -0.  -3.  -0.1 -0.6 -0.4 -3.5 -0.1 -0.2  0.5  5.6  6.5 -0.4 -0.2 -3.2 -1.5  1.  -0.3  0.2  2.8 -0.7 -0.5 -0.8 -0.3 -0.1 -0.2  5.7 -1.2  3.  -0.3 -1.6  6.6  2.4  2.  -0.2 -0.4  0.9  0.2  0.7 -0.1  0.5 -0.5 -0.1  0.1 -1.  -0.   0.7 -1.6 -0.5 -0.8 -0.4 -0.2 -0.   0.9 -0.1 -0.1  0.7  0.2 -3.1 -0.6 -0.  -0.2 -0.4 -0.1 -0.1  0.4 -1.3 -0.4 -0.2 -0.7 -2.1  0.4 -0.2  2.2 -3.   0.2  0.3 -0.2  0.5 -1.   0.2  1.6 -1.6 -0.   0.2 -0.1 -0.8  2.9  6.  -0.6 -0.1 -0.1 -0.4 -0.2  5.   0.5  0.8 -0.4 -2.5 -0.1 -0.9  5.9  3.3 -0.2 -0.7  0.2 -0.3  7.1 -1.5 -0.2 -0.1  1.2 -0.5 -0.9 -0.3 -1.7 -0.1 -0.2 -0.  -0.2 -0.2  2.6 -0.  -0.5 -0.1  0.1 -0.4 -0.  -0.1 -0.  -0.4  1.2 -0.2 -0.1 -0.8 -0.2 -0.1 -0.3  0.3  0.7  3.7  0.9  0.1 -0.2 -0.1 -0.1  0.8 -0.  -0.1  0.5 -0.5 -0.5 -0.2  1.6 -0.3 -0.6 -1.4 -0.3 -0.3 -0.1 -0.  -0.4  9.   0.2 -0.1 -0.6 -0.7  0.2 -1.9 -0.  -0.6 -0.2 -0.  -0.2 -0.1 -0.3 -0.8 -0.1 -1.4 -0.3 -0.1  7.  -0.1 -0.3  3.5 -1.1  3.2 -0.7 -0.5 -0.3 -0.8 -0.8 -0.2 -0.4 -0.1 -0.  -1.  -1.2  2.8  1.1  1.8 -0.3  2.8 -0.7 -0.7 -0.2  3.7 -0.1  4.7 -0.  -0.2  1.2 12.1 -0.2  4.8  0.5 -0.2  2.  -0.9 -0.1 -0.  -1.2 -0.2 -0.4 -0.   4.2 -0.2 -0.2 -0.3]
vy_50sample [[2 3 1 8 9 4 6 0 5 7]
 [6 2 7 8 5 0 3 1 9 4]
 [2 2 7 9 0 1 5 3 4 8]
 [5 2 1 0 3 8 6 9 7 4]
 [7 3 8 8 9 4 0 5 6 2]
 [7 2 2 0 8 5 4 9 6 1]
 [6 5 2 0 7 8 4 3 9 1]
 [4 8 0 5 7 6 1 2 9 3]
 [3 8 5 2 2 1 9 9 0 7]
 [6 2 4 9 8 3 5 5 1 7]]
vt_50sample [[2 3 1 8 9 4 6 0 5 7]
 [6 2 7 8 5 0 3 1 9 4]
 [6 2 7 9 0 1 5 3 4 8]
 [2 5 1 0 3 8 6 9 7 4]
 [7 3 8 1 9 4 0 5 6 2]
 [7 3 2 0 8 5 4 9 6 1]
 [6 5 2 0 7 8 4 3 9 1]
 [4 8 0 5 7 6 1 2 9 3]
 [3 8 5 2 1 4 9 6 0 7]
 [6 2 4 8 9 3 5 0 1 7]]
Epoch 31210: Training cost= 0.2395, Training acc= 0.8403, Validation cost= 0.3021, Validation acc= 0.8404
Epoch 31220: Training cost= 0.2179, Training acc= 0.8403, Validation cost= 0.2543, Validation acc= 0.8404
Epoch 31230: Training cost= 0.2914, Training acc= 0.8403, Validation cost= 0.2367, Validation acc= 0.8405
Epoch 31240: Training cost= 0.2707, Training acc= 0.8404, Validation cost= 0.2755, Validation acc= 0.8405
Epoch 31250: Training cost= 0.3242, Training acc= 0.8404, Validation cost= 0.2693, Validation acc= 0.8405
Epoch 31260: Training cost= 0.3161, Training acc= 0.8404, Validation cost= 0.3090, Validation acc= 0.8405
Epoch 31270: Training cost= 0.2658, Training acc= 0.8404, Validation cost= 0.3082, Validation acc= 0.8405
Epoch 31280: Training cost= 0.3048, Training acc= 0.8404, Validation cost= 0.2840, Validation acc= 0.8405
Epoch 31290: Training cost= 0.3001, Training acc= 0.8404, Validation cost= 0.2312, Validation acc= 0.8405
Epoch 31300: Training cost= 0.2510, Training acc= 0.8405, Validation cost= 0.2825, Validation acc= 0.8406
tm  [-1.7  0.4  7.4 13.6 -1.7 -0.2 -0.2 -0.1 -0.6 -0.5 -3.2 -0.4 -0.5 -0.1  1.3 -0.5 -0.3 -0.6 -0.2 -1.  -0.8 -0.1  0.6 -0.3 -0.7  0.8 -0.2 -0.3 -0.2  2.  -0.7 -0.4  0.1  5.8 -0.3 -0.1  2.  -2.  -1.  -0.3 -0.4  1.6  1.  -1.5 -0.5  0.2  4.3  0.2 -0.8  2.1 -0.4 -0.2  0.2 -2.8 -1.1 -0.2 -0.5  6.8 -0.9  3.7  2.4 -0.3 -0.2 -0.2 -0.1 -0.2 -0.  -0.3 -0.  -0.2 -0.1 -0.5 -0.1 -0.  -0.6 -0.2 -0.2 -0.3  0.4  0.8  6.1 -0.  -0.2  0.   1.5  3.6 -1.5 -0.2 -0.4 -0.2 -0.1 -0.  -0.3 -0.1 -0.2  0.3 -0.3 -1.1 -0.1 -0.4  2.9  4.   1.4 -0.2 -0.2 -0.1 -0.5 -0.3 -1.2 -1.8 -0.1 -0.2 -0.  -0.5 -0.3  5.2 -0.5 -0.8 -0.2 -0.4 -0.1  6.3  0.2  0.7 -0.1  1.7  0.3 11.8 -0.6 -0.7 -0.  -0.3 -0.1 -0.4  5.5 10.6 -0.2 -0.  -0.1 -0.6  2.5 -0.   1.1 -0.3 -0.  -0.3 -0.1  0.   0.1 -0.2 -1.1  0.4 -0.5 -0.2 -0.1 -0.1 -0.3 -0.3 -1.2 -0.3 -0.4  2.9 -0.  -0.1 -0.1  0.7 -0.1  0.7 -0.2  0.1 -0.4 -0.2 -0.1 -0.1 -0.4  1.3 -0.7  0.7  2.4  0.3 -1.2 -0.2 -0.4 -1.  -0.1 -0.2 -0.6 -0.6 -0.1 -0.3 -0.2 -0.4 -0.5 -0.7 -0.1  2.7  0.8  1.1 -0.2 -0.2 -0.  -0.2 -0.1 -0.7  0.2 -0.3 -0.2 -0.2 -1.  -0.  -0.7  2.1 -0.5  5.3 -0.4 -0.5  6.4 -0.7 -0.3 -0.2 -0.3 -0.2 -0.1 -0.7  3.3  1.9 -1.6  0.2  0.9 -0.1  0.7 -0.6 -0.2 -0.6 -0.1 -1.6 -0.1  0.5  2.6  1.4 -0.2  0.7 -0.1 -0.2 -1.  -1.3 -0.3  1.1 -1.  -0.4 -1.8 -0.2 -0.6 -0.1  4.8  5.2]
ty_50sample [[6 1 7 5 5 8 3 0 4 2]
 [0 4 5 7 6 1 9 3 8 2]
 [4 5 2 6 7 8 0 0 1 3]
 [3 8 0 0 6 5 9 2 1 7]
 [8 7 1 2 3 9 4 5 0 6]
 [9 6 3 0 1 4 2 7 8 5]
 [6 5 0 8 9 4 2 7 1 3]
 [9 7 4 2 3 0 1 8 5 6]
 [9 0 5 4 3 8 2 1 7 6]
 [7 5 3 8 2 0 4 6 1 9]]
tt_50sample [[6 1 7 5 9 8 3 0 4 2]
 [0 4 5 7 6 1 9 3 8 2]
 [4 5 2 6 7 8 9 0 1 3]
 [3 8 4 6 0 5 9 2 1 7]
 [8 7 1 2 3 9 4 5 0 6]
 [9 6 3 0 1 4 2 7 8 5]
 [6 5 0 8 9 4 2 7 1 3]
 [9 7 4 2 3 0 1 8 5 6]
 [9 0 5 4 3 8 2 1 7 6]
 [7 5 3 8 2 0 4 6 1 9]]
vm  [-0.7 -1.3 -0.4 -3.5 -1.8 -0.1 -0.1 -0.3  2.9  2.6 -0.8 -0.6 -0.3 -0.4  8.9 -2.3 -0.3 -0.4 -0.6 -0.7 -0.7 -0.2  0.9 -0.  -0.6 -0.  -0.4  1.4 -1.1 -1.9  5.3 -0.3 -0.2  8.8 -0.2 -0.5 -0.7 -0.4  2.2 -0.3 -1.   0.6 -2.   2.4 -0.5 -0.4  1.8 -0.  -0.5  5.6 -0.3 -0.2 -0.7 -0.5  1.  -1.1 -0.8 -3.1 10.  -2.3  4.8 -0.3  1.4 -0.4  3.5 -0.6  0.   0.5  1.  -0.7 -0.6  2.8 -0.9 -1.  -4.4 -0.3 -0.5  0.6 -0.2 -0.4  1.8 -0.  -0.3 -0.2 -0.6  0.4  2.1 -0.2 -0.3  0.4 -0.4 -0.1 -0.6 -2.  -0.4 -0.4  0.2 -2.5 -0.3 -0.4 -1.4  7.1 -0.6 -0.4  0.3 -0.7 -2.6  3.8 -0.6 -0.5  1.6  0.7 -0.3 -0.8 10.2 -3.1 -1.1  4.4 -0.3 -0.2 -0.5 -0.  -0.4  1.  -0.3  9.8 -0.6  4.   4.3 -0.7  1.4 -0.6 -0.7  1.1 -3.   1.   0.4  0.1 -0.1 -0.5  0.5 -1.3 -0.  -0.2 -0.2  0.3 -0.2 -0.1 -2.  -0.4  1.5 -0.  -0.6  1.1 -0.5 -0.3 -0.4 -0.3 -0.9 -0.4 -0.3 -1.3  1.  -0.2  1.3  0.6 -0.8  3.  -0.6 -0.3 -0.2 -0.1 -0.3 -0.6 -0.4  4.9 -0.2 -0.5 -0.2 -0.1  1.5 -0.5 -0.1 -1.8 -0.2 -0.8 -0.2 -0.8  1.1  4.5 -0.3 -0.4 -0.6 -0.6 -1.4 -1.  -1.9 -2.3 -0.4 -0.3 -0.2 -0.1 -0.6 -0.2  0.2 -2.4  0.3 -0.3  4.8 -0.1 -0.4 -1.6 -0.7 -0.   0.8  0.  -1.3 -1.  -0.7 -0.3 -0.2 -0.4 -0.3 -1.3  3.9 -1.  -2.2 -0.3 -1.   1.7 -1.6  3.3 -0.4  1.9  1.3  2.1  2.6 -1.8  1.3  7.7 -0.1  2.3 -0.  -0.1  0.4 -0.  -0.1 -0.7 -0.7  0.8 -0.7 -0.1  1.5  0.   0.3  5.3]
vy_50sample [[0 4 7 1 9 6 8 2 3 5]
 [4 7 9 6 5 1 2 0 3 8]
 [7 0 1 9 6 2 5 4 8 8]
 [7 4 3 8 6 5 2 1 0 9]
 [5 3 8 6 7 1 2 4 0 9]
 [3 9 5 1 0 2 2 8 6 4]
 [9 2 0 3 7 7 5 1 8 6]
 [4 7 1 5 6 3 3 0 2 8]
 [5 6 7 9 3 2 2 4 1 0]
 [1 9 3 8 4 6 0 5 7 2]]
vt_50sample [[0 4 7 1 9 8 6 3 2 5]
 [4 7 9 6 5 1 2 0 3 8]
 [7 0 1 9 6 5 2 4 8 3]
 [7 4 3 8 6 5 2 1 0 9]
 [5 3 8 6 7 1 2 4 0 9]
 [3 9 5 1 0 7 2 6 8 4]
 [9 2 0 3 7 4 5 1 8 6]
 [4 7 1 5 6 3 9 0 2 8]
 [5 6 7 9 3 2 8 4 1 0]
 [1 9 3 8 4 6 0 5 7 2]]
Epoch 31310: Training cost= 0.2819, Training acc= 0.8405, Validation cost= 0.2379, Validation acc= 0.8406
Epoch 31320: Training cost= 0.2488, Training acc= 0.8405, Validation cost= 0.2676, Validation acc= 0.8406
Epoch 31330: Training cost= 0.2622, Training acc= 0.8405, Validation cost= 0.2842, Validation acc= 0.8406
Epoch 31340: Training cost= 0.2922, Training acc= 0.8405, Validation cost= 0.2449, Validation acc= 0.8406
Epoch 31350: Training cost= 0.3106, Training acc= 0.8405, Validation cost= 0.2695, Validation acc= 0.8407
Epoch 31360: Training cost= 0.3144, Training acc= 0.8406, Validation cost= 0.2486, Validation acc= 0.8407
Epoch 31370: Training cost= 0.2759, Training acc= 0.8406, Validation cost= 0.2938, Validation acc= 0.8407
Epoch 31380: Training cost= 0.2701, Training acc= 0.8406, Validation cost= 0.2997, Validation acc= 0.8407
Epoch 31390: Training cost= 0.2914, Training acc= 0.8406, Validation cost= 0.2817, Validation acc= 0.8407
Epoch 31400: Training cost= 0.2358, Training acc= 0.8406, Validation cost= 0.2360, Validation acc= 0.8407
tm  [-1.3  0.5  0.6  8.  -1.3 -0.2  0.4 -0.3 -0.5 -0.9 -3.1 -0.1 -0.  -0.1 -1.1  6.   0.2 -0.  -0.2 -0.6 -1.  -0.5  1.1 -0.4 -1.1  1.6 -0.2 -0.3  3.5 -0.5 -1.4 -0.5  0.2 -4.  -0.3 -0.1  0.1  3.1  7.6 -0.2  0.9  1.7  2.3  1.8 -0.2 -0.1  2.3 -0.4 -0.2  7.  -0.8 -0.  -0.3 -0.2 -1.3  2.2 -0.2  6.7 -0.6  5.   1.2 -0.4 -0.2 -0.1 -0.8 -0.7 -0.1 -0.3  0.2 -0.3 -0.  -1.9  0.3  2.7 -1.7 -0.4 -0.2 -0.4 -0.3 -0.3 -1.9 -0.3 -0.1 -0.4 -0.5  4.2 -0.8 -0.3  0.2 -0.1  0.3 -0.2 -0.1  0.  -0.4 -0.3 -0.1 -1.7  0.5 -0.4  3.9 -0.9 -0.2  0.1 -0.3 -0.3 -0.3 -1.3 -0.9 -0.9 -0.4 -0.2 -0.  -0.7 -1.  13.7 -0.1 -0.9  0.1 -0.2 -0.1  3.4 -0.1 -0.3 -0.  -1.3  0.4  4.1  0.3  0.  -0.4  0.5  0.1 -0.5  0.3 -4.4 -0.2 -0.1 -0.1  1.4  0.4 -0.3 -0.1 -0.   0.1 -0.2 -0.3  0.5  6.1 -0.1 -0.6 -0.2  1.4  0.3 -0.2 -0.3 -0.1 -0.9  3.2  0.1 -0.2 -1.2 -0.1 -0.  -0.2 -0.5 -0.2 -0.   0.4 -0.4 -0.1 -0.3 -0.   0.1 -0.1 -1.1 -0.4  0.6 -0.7 -0.2 -1.5  0.5 -0.6 -1.4 -0.5 -0.1  0.2 -0.6 -0.1  1.6 -0.2 -0.3 -0.2 -0.8  2.  -0.2  0.9  1.8 -0.4 -0.2 -0.3 -0.   0.1 -0.3 -0.1 -0.1 -0.1 -0.   2.5  0.1 -0.4  6.2 -0.4  4.8 -0.7 -0.4  0.  -0.2 -0.3 -0.4 -0.4 -0.2 -0.5 -1.1 -0.9  3.7 -0.9  0.8 -0.8 -0.2 -0.2 -0.6 -0.2  1.4 -1.2  1.  -0.1  0.3  1.  -0.7 -0.2 -0.1 -0.1 -0.5  6.7 -1.5 -0.2 -0.1 -1.  -0.3  3.7 -0.3  5.4 -0.2  2.2  3.1]
ty_50sample [[8 5 9 1 3 2 4 6 6 0]
 [5 9 8 1 3 0 4 7 2 6]
 [5 4 7 3 8 0 1 6 2 9]
 [5 2 3 1 6 7 4 0 9 8]
 [0 8 9 9 6 7 1 3 4 2]
 [3 0 7 1 9 4 8 5 2 6]
 [0 2 2 9 5 7 1 8 3 6]
 [3 1 5 6 7 4 2 0 9 8]
 [4 5 8 7 0 3 6 9 1 2]
 [9 3 2 0 1 7 6 4 8 5]]
tt_50sample [[8 5 9 1 3 2 4 7 6 0]
 [5 9 8 1 3 0 4 7 2 6]
 [5 4 3 7 8 0 1 2 6 9]
 [5 2 3 1 6 7 4 0 9 8]
 [0 8 9 5 6 7 1 3 4 2]
 [3 0 7 1 9 4 8 5 6 2]
 [0 2 4 9 5 7 1 8 3 6]
 [3 1 5 6 7 4 2 0 9 8]
 [4 5 8 7 0 3 6 9 1 2]
 [9 3 2 0 1 7 6 4 8 5]]
vm  [-0.8 -0.4 -1.4 -1.1 -1.8  0.4 -0.3 -0.1 -0.5 -0.5  2.8 -0.3 -0.2 -0.4  0.9 -1.3 -0.5 -0.4 -0.3 -1.6 -1.1 -0.1 -0.6 -0.2 -0.5  1.2 -0.3 -0.3 -1.4  1.7  5.8 -0.4  0.7 11.2  0.3  2.   3.3 -0.7  2.9 -0.4  1.2 -1.5 -0.1  4.7 -0.1  0.   7.6  0.9 -0.3 -1.8 -0.6 -0.3 -0.7 -2.2  0.5 -0.  -0.8 -3.3 -0.  -3.6  1.2 -0.1 -0.3  0.3  0.3 -0.1  0.5 -0.5  0.4  0.6  0.1  3.9 -0.5 -0.4 -0.1  0.   0.6 -0.3  1.4 -0.3 17.8  0.  -0.6  0.1  0.2 -1.3  4.7 -0.2 -0.2 -0.1 -0.2  0.1 -0.1  0.5 -0.3 -0.1 -0.  -0.9  0.3  0.9  1.9  4.1  0.6 -0.1 -0.1 -0.7 -0.8  5.5  0.4 -1.8 -0.9 -0.3 -0.  -0.5  4.2 -1.4 -0.1 -0.4 -0.2 -0.4  0.1  7.7 -0.1 -0.2  0.1  0.7 -0.3  9.8 -0.9 -0.6 -0.2 -0.1 -0.4 -0.6 -0.7 11.2 -0.4 -0.2 -0.3 -0.5  0.1 -0.5 -0.1 -0.1 -0.1 -0.1 -0.2 -0.2 -2.1 -0.2  0.1 -0.1 -1.3 -0.3 -0.2 -0.  -0.1 -0.4 -0.6 -0.8  0.5 -0.2 -0.1 -0.1  0.   1.6 -0.6  0.1 -0.2 -0.1 -0.3 -0.2  0.1 -0.3 -0.2  5.4 -0.9 -0.2 -0.1  0.  -0.  -0.2 -0.2 -1.  -0.  -0.4 -0.3 -0.5 -0.2 -0.4 -0.1  0.1 -0.7 -0.4  1.9  4.5 -0.3 -0.6 -0.2 -0.  -0.1  0.9 -0.3 -0.3  0.4 -0.4 -0.3 -0.2  2.3 -0.1 -0.7 -1.4 -0.4  2.3  0.4 -0.3 -1.3 -1.  -0.3 -0.5 -0.1  0.4 -0.3 -0.7  1.5 -1.2 -1.3 -0.8 -0.8 -0.1 -0.8 -0.5 -0.1  1.6  3.2  4.3  1.2  0.4  0.8 18.3 -0.   6.7  0.1  0.4 -3.7 -0.9 -0.1 -0.2 -1.1 -0.5 -4.7 -0.2  2.3 -0.2  2.8  4.3]
vy_50sample [[4 0 7 9 1 6 3 2 8 5]
 [7 6 4 2 5 0 1 1 9 8]
 [8 1 1 5 6 0 9 4 7 2]
 [2 1 0 0 7 3 4 8 9 5]
 [7 4 6 1 5 2 8 9 3 0]
 [9 1 2 5 8 6 0 4 7 3]
 [1 4 4 6 3 0 2 9 8 7]
 [3 2 6 5 8 0 1 9 7 4]
 [1 6 3 4 7 0 8 5 9 2]
 [7 8 9 1 6 2 5 3 0 4]]
vt_50sample [[4 0 7 9 1 6 3 2 8 5]
 [7 4 6 2 5 0 3 1 9 8]
 [8 3 1 5 6 0 9 4 2 7]
 [2 6 1 0 7 3 4 8 9 5]
 [7 4 6 1 2 5 8 9 3 0]
 [9 1 2 5 6 8 0 4 7 3]
 [1 5 4 6 3 0 2 9 7 8]
 [3 2 6 5 8 0 1 9 7 4]
 [1 6 3 4 0 7 8 5 9 2]
 [7 8 9 6 1 2 5 3 0 4]]
Epoch 31410: Training cost= 0.2853, Training acc= 0.8406, Validation cost= 0.3292, Validation acc= 0.8407
Epoch 31420: Training cost= 0.2765, Training acc= 0.8407, Validation cost= 0.2711, Validation acc= 0.8408
Epoch 31430: Training cost= 0.2828, Training acc= 0.8407, Validation cost= 0.2759, Validation acc= 0.8408
Epoch 31440: Training cost= 0.2722, Training acc= 0.8407, Validation cost= 0.2435, Validation acc= 0.8408
Epoch 31450: Training cost= 0.2534, Training acc= 0.8407, Validation cost= 0.2403, Validation acc= 0.8408
Epoch 31460: Training cost= 0.2529, Training acc= 0.8407, Validation cost= 0.2508, Validation acc= 0.8408
Epoch 31470: Training cost= 0.2443, Training acc= 0.8407, Validation cost= 0.2421, Validation acc= 0.8408
Epoch 31480: Training cost= 0.3054, Training acc= 0.8408, Validation cost= 0.2590, Validation acc= 0.8409
Epoch 31490: Training cost= 0.3052, Training acc= 0.8408, Validation cost= 0.2292, Validation acc= 0.8409
Epoch 31500: Training cost= 0.2428, Training acc= 0.8408, Validation cost= 0.2724, Validation acc= 0.8409
tm  [-0.5 -0.  -1.8 -1.2 -1.4 -0.2 -0.6 -0.2 -1.1 -0.4 -5.8 -0.  -0.3 -0.3  0.6 -1.5  1.2 -0.4 -0.2 -0.  -0.8 -0.1  1.2 -0.4 -1.3  2.2 -0.  -0.5 -1.4 -0.1 -0.2 -0.7 -0.5 -2.7 -0.1  0.1  3.9 -0.6 -0.1 -0.5 -0.   4.4  3.5  2.6 -0.2  0.2 -1.4  0.2  3.5  6.  -0.3 -0.5 -0.3 -1.7 -0.3 -0.1 -0.8  4.  -0.9  2.5  1.8 -0.5  0.2  0.4 -1.4 -0.5 -0.1 -0.8 -0.3  0.8 -0.   4.3 -0.1  0.4 -3.7 -0.6 -0.5 -0.5 -0.1  1.  -3.  -0.1  0.6 -0.6 -1.   5.6  4.1 -0.2  0.8 -0.3 -0.4 -0.3 -0.4  2.4 -0.4  0.3 -0.3 -2.1  0.6 -0.1  1.  -0.7 -0.3 -0.2 -0.3  2.  -1.5 -0.2 -2.1 -1.1 -0.5 -0.3 -0.  -0.3  0.1 -1.2 -0.4 -0.7 -0.1 -0.4 -0.1  3.3 -0.2 -0.3 -0.3  1.3 -0.   7.6 -0.2  3.9  0.9 -0.2 -0.1 -0.2  3.8 -2.5 -0.5  0.   0.1 -0.1  3.1 -1.1  0.6 -0.4 -0.1 -0.2 -0.2 -0.4  7.2 -0.   0.9 -0.   3.5 -0.4 -0.4  0.1 -0.8 -0.1  1.2 -0.6  0.3 -0.5 -0.3 -0.2 -0.   0.6 -0.4 -0.7  0.3 -0.1 -0.2  0.4 -0.1 -0.4 -0.4 -1.3 -0.2 -0.2  1.5 -0.4 -2.2 -0.  -0.4 -1.7  0.  -0.4  0.8 -0.1 -0.2  0.3 -0.  -0.5  0.7 -0.9  0.4  2.3 -0.5 -0.2 -0.1 -0.1 -0.1  0.1  0.2 -0.3 -0.1 -1.5 -0.5 -0.3 -0.8 -0.3 -0.7 -1.  -0.4  0.4 -0.4 -0.3 -0.8 -0.6 -0.7 -0.6 -0.3  0.1 -0.2 -0.9 -0.1  0.2 -2.  -0.5 -0.5  0.6 -0.3 -0.2 -0.2 -0.5  2.   2.9 -0.3 -0.7  0.7 -3.6 -0.2 -1.4 -0.2 -0.2 10.5  0.3 -0.6  0.4 -0.5 -0.6  7.4 -0.1 -0.1 -0.1  5.  -0.3]
ty_50sample [[5 8 0 4 3 6 1 7 9 2]
 [0 3 2 8 5 4 9 6 7 1]
 [2 1 0 8 4 6 9 7 3 5]
 [7 3 8 0 0 1 4 2 6 5]
 [8 9 7 3 5 1 0 6 2 4]
 [1 6 3 0 5 2 8 9 4 7]
 [7 2 8 4 6 1 0 9 3 5]
 [6 9 4 3 2 7 1 5 0 8]
 [1 9 7 0 4 6 2 3 8 5]
 [6 5 7 4 1 0 2 8 8 3]]
tt_50sample [[5 8 0 4 3 6 1 9 7 2]
 [0 3 8 2 5 4 9 6 7 1]
 [2 1 8 0 4 6 9 7 3 5]
 [7 8 3 0 9 1 4 2 6 5]
 [8 9 7 3 5 1 0 6 2 4]
 [1 6 3 5 0 2 8 9 4 7]
 [7 2 8 4 6 1 9 0 3 5]
 [6 9 4 3 2 7 1 5 0 8]
 [1 9 7 0 4 6 2 3 5 8]
 [6 5 7 4 1 0 2 8 9 3]]
vm  [-0.2 -1.   2.6 -1.9 -2.4  0.6 -0.1 -0.3 -0.6  0.4  2.4 -0.2 -0.2 -0.3  8.9 -1.9 -0.3 -0.4 -0.3 -0.4 -0.9 -0.4 -0.3 -0.2 -1.   3.4 -0.2 -0.1 -1.8 -1.   3.4 -0.4 -0.5 10.7 -0.1 -0.3  2.8  3.4  9.9 -0.6 -0.3  2.4  1.7  4.5 -0.3 -0.4 -0.1  0.1  2.9 -0.5 -0.8 -0.1 -0.1  0.1  1.7 -0.9 -0.7 -0.1  0.8 -1.7 -0.1 -0.4  1.  -0.1 -0.3 -0.7 -0.1 -0.6  1.2 -0.3 -0.2  6.1 -0.4 -0.4 -3.7 -0.5 -0.5 -0.2 -0.2 -0.2  3.8 -0.5 -0.4 -0.5 -1.3  2.2  4.9 -0.2 -0.  -0.3 -0.6 -0.3 -0.2  0.2 -0.1 -0.2 -0.  -1.9 -0.1 -0.4 -0.4  5.3 -1.  -0.2 -0.3 -0.3 -2.   2.5  0.8 -0.8 -0.4 -0.2 -0.3 -0.5  3.9 -3.6 -0.4 -0.2  0.  -0.2 -0.2  1.1 -0.3 -0.2 -0.6 10.4 -0.2  2.2  1.   1.5 -0.3 -0.2 -0.7  0.5 -7.  -2.2 -0.  -0.1 -0.2 -0.5  1.2 -1.6  0.8 -0.4 -0.3 -0.1 -0.3  0.1 -0.5 -0.3  1.1  0.1  0.4 -0.1 -0.3 -0.2 -0.5 -0.4  3.2 -0.4 -0.4 -2.9 -0.1 -0.1 -0.1 -0.2 -0.5 -0.8 -0.3 -0.1 -0.1 -0.2  0.  -0.5 -0.3  1.6  1.9 -0.3 -0.9 -0.3 -1.3 -0.2 -0.2 -1.3 -0.3 -0.3  1.6 -0.6 -0.2  1.5 -0.4 -0.5 -0.4 -0.9  3.2  0.4 -1.3 -1.  -0.1 -0.2 -0.3 -0.3 -0.4 -0.2 -0.2 -1.5 -0.3 -0.3 -2.  -0.2 -0.6 -2.1 -0.2 -0.6 -0.3 -0.  -2.  -1.  -0.8 -0.4 -0.  -0.1 -0.4 -1.1 -1.4 -1.6 -1.8 -0.8 -1.   1.3 -0.7  2.1 -0.2 -1.2  3.  -0.   1.3 -0.8 -0.  -1.4  0.1 -0.6 -0.2 -0.2 -0.4 -0.5 -0.3 -0.5 -0.4 -0.1 -1.3 -0.1  6.4 -0.1  1.9  0.6]
vy_50sample [[0 7 4 5 3 9 2 8 8 6]
 [0 8 6 5 1 9 7 4 3 2]
 [1 3 6 8 7 5 4 9 0 2]
 [9 1 1 5 7 0 0 4 3 8]
 [3 6 2 5 7 9 1 0 8 4]
 [0 2 3 8 4 1 5 7 9 6]
 [0 8 2 4 7 1 1 5 3 3]
 [4 3 5 8 6 0 2 1 9 7]
 [0 2 4 4 7 9 3 8 5 1]
 [9 1 5 4 3 6 8 2 0 7]]
vt_50sample [[0 7 4 5 3 9 2 1 8 6]
 [0 8 6 5 1 9 7 4 3 2]
 [1 3 6 8 7 5 4 9 0 2]
 [9 1 5 2 7 6 0 4 3 8]
 [6 3 2 5 7 9 1 0 8 4]
 [0 2 3 8 4 1 5 7 9 6]
 [0 8 2 4 7 1 6 5 9 3]
 [4 3 5 8 6 0 2 1 9 7]
 [0 2 6 4 7 3 9 8 5 1]
 [9 1 5 4 3 6 2 8 0 7]]
Epoch 31510: Training cost= 0.2902, Training acc= 0.8408, Validation cost= 0.2718, Validation acc= 0.8409
Epoch 31520: Training cost= 0.2496, Training acc= 0.8408, Validation cost= 0.2378, Validation acc= 0.8409
Epoch 31530: Training cost= 0.3798, Training acc= 0.8408, Validation cost= 0.2761, Validation acc= 0.8409
Epoch 31540: Training cost= 0.2773, Training acc= 0.8409, Validation cost= 0.3029, Validation acc= 0.8410
Epoch 31550: Training cost= 0.2852, Training acc= 0.8409, Validation cost= 0.2859, Validation acc= 0.8410
Epoch 31560: Training cost= 0.2257, Training acc= 0.8409, Validation cost= 0.2357, Validation acc= 0.8410
Epoch 31570: Training cost= 0.2670, Training acc= 0.8409, Validation cost= 0.2873, Validation acc= 0.8410
Epoch 31580: Training cost= 0.2511, Training acc= 0.8409, Validation cost= 0.2410, Validation acc= 0.8410
Epoch 31590: Training cost= 0.3323, Training acc= 0.8409, Validation cost= 0.2618, Validation acc= 0.8410
Epoch 31600: Training cost= 0.3144, Training acc= 0.8410, Validation cost= 0.2861, Validation acc= 0.8411
tm  [ 2.3 -0.6 -3.6 -0.8 -1.2 -0.1 -0.3 -0.1  0.5 -0.3  2.   0.6 -0.4 -0.1 -2.3 -0.5 -0.5 -0.3 -0.3 -1.4 -1.2 -0.2 -0.  -0.2 -0.8  1.3 -0.2  0.3 -0.4 -1.9  5.3 -0.4  0.3 -0.2  0.2 -0.4 -0.4  3.1 16.3 -0.2  0.7  2.4 -0.2  5.7  0.2  0.6  8.4  0.5  5.5 -0.5 -0.7 -0.3  1.2 -1.8 -0.6  3.  -0.4 -0.6  3.3 -2.5 -2.2 -0.8  2.2 -0.5  1.2 -0.9 -0.2  0.1  0.6 -0.3 -0.  -0.3 -0.3 -0.1 -1.2  0.1 -0.7  0.4 -0.3 -0.6 14.1 -0.5 -0.2 -0.3 -2.   3.   8.5 -0.  -0.1 -0.1 -0.6 -0.1 -0.2 -0.3 -0.3 -0.3 -0.  -1.3 -0.3 -0.4 -0.  -0.9 -1.3 -0.4 -0.4 -0.5 -0.4  4.8  0.4 -1.7 -0.1  0.3 -0.1 -0.9  3.6 -0.   1.5  0.5 -0.4  0.1 -0.3  6.1 -0.2 -0.2 -0.7 -2.8 -0.1  8.9  4.8 -1.4 -0.1 -0.4 -0.5 -0.2 -1.6 -1.8 -0.2 -0.1 -0.  -0.8 -0.1 -0.4  0.1 -0.1 -0.3 -0.2  0.2 -0.1  6.  -0.1 -0.2 -0.1  3.6 -0.1 -0.4 -0.3 -0.3  0.8  4.3 -0.3 -0.3 -2.4 -0.1 -0.1  0.1 -0.1 -0.  -0.4 -0.2 -0.4 -0.3 -0.3 -0.3 -0.4 -0.1 -1.3 -0.6  0.2 -1.7  0.1 -1.8  0.2 -0.5 -1.3 -0.3 -0.4  5.1 -0.2 -0.2  5.  -0.1  0.5 -0.6 -1.  14.7 -1.5  1.9 -1.2 -0.1 -0.  -0.1  0.1 -0.1  0.1 -0.4  3.5 -0.1 -0.3 -2.1  0.  -0.8  0.5  0.  -1.9  2.4 -0.2 -2.7 -0.8 -0.2 -0.7 -0.4 -0.1 -0.3 -1.  -1.6 -0.3 -2.  -0.9 -0.3  4.3 -0.5 -0.6 -0.2 -1.3 -0.6  6.2 -0.4  0.2  0.4  5.4 -0.   1.7 -0.1  0.2 -2.8 -3.  -0.4 -0.4 -1.   0.8 -3.9 -0.1 10.7 -0.3  2.8  7.3]
ty_50sample [[4 9 5 0 3 8 2 7 1 6]
 [1 9 2 0 4 7 8 3 6 5]
 [3 9 6 8 0 1 2 5 7 4]
 [0 8 1 7 7 2 6 3 4 9]
 [3 0 4 5 8 1 2 9 6 7]
 [7 6 9 3 8 5 2 2 0 1]
 [2 9 7 6 3 8 1 0 0 5]
 [6 1 7 9 0 5 2 3 4 8]
 [5 4 7 3 0 1 2 6 9 8]
 [0 5 7 7 6 8 1 4 4 2]]
tt_50sample [[4 9 5 0 3 8 2 7 1 6]
 [1 9 2 0 4 7 8 3 6 5]
 [9 3 6 8 0 1 2 5 7 4]
 [0 8 1 7 5 2 6 3 4 9]
 [3 0 4 5 1 8 2 9 6 7]
 [7 6 9 3 8 5 4 2 0 1]
 [2 9 7 6 3 8 1 0 4 5]
 [6 1 7 9 0 5 2 3 4 8]
 [5 4 7 3 0 1 2 6 9 8]
 [0 5 3 7 6 8 1 4 9 2]]
vm  [-0.9  1.4 -0.9 13.8 -0.7  0.2 -0.3 -0.  -0.6 -1.   6.8 -0.2 -0.3 -0.3 -3.4  2.7 -0.1 -0.1  0.2 -1.3 -1.2 -0.3 -1.2 -0.2 -0.7  2.2 -0.4  0.3 -0.4 -1.8  0.7 -0.6  1.  -1.3 -0.2 -0.2  2.6 -0.1  3.  -0.3 -0.4 -3.1 -0.6 -1.4 -0.3 -0.2  7.5 -0.3 -0.3 -3.8 -0.5 -0.1  1.3 -0.7 -1.   4.1 -0.2  2.3 -0.5  0.6 -0.5 -0.3  0.1 -0.2  0.4 -0.5 -0.1 -0.3 -0.4 -0.2 -0.1 -0.3 -0.1 -0.1  0.4  0.2 -0.4 -0.4 -0.3 -0.4 16.2 -0.2 -0.2 -0.4 -0.2 -2.8 -0.9 -0.2 -0.3 -0.4 -0.   0.   0.6  1.9 -0.1 -0.2 -0.5 -0.6 -0.5 -0.4  4.4 -3.7  0.2 -0.4 -0.5 -0.2 -0.2  1.2  1.8 -2.   0.3 -0.3 -0.1 -0.5 -0.2  2.9 -0.  -0.9  0.4 -0.  -0.3  6.4 -0.1  1.1 -0.1 -4.1 -0.1  5.2 -0.3  3.2 -0.3 -0.   1.1 -0.4 13.8 12.4 -0.1  0.3  1.7 -0.7 -0.6  0.  -0.8 -0.  -0.1 -0.  -0.1 -0.2  3.3 -0.1 -1.2 -0.  -0.8 -0.1 -0.  -0.1 -0.1  0.6 -0.6 -0.4 -0.4 -0.  -0.3 -0.2 -0.  -0.2  0.4  1.3 -0.3 -0.2 -0.  -0.1 -0.3 -0.1 -0.2 -0.7 -1.2 -0.4 -0.1 -0.1 -0.2 -0.2 -0.2 -1.3 -0.4 -0.2 -0.3  0.7 -0.3  6.1 -0.2  0.4 -0.7 -0.9  5.4  1.8  2.1  1.1 -0.  -0.1 -0.  -0.1 -0.2 -0.4 -0.3  3.1  0.1 -0.1 -0.3 -0.3 -0.4 -0.1 -0.7  3.3  0.8  0.3  6.  -0.8 -0.5  0.3 -0.1 -0.2  0.3 -0.4 -0.4 -0.2 -0.7  0.8 -0.   0.1 -0.  -0.8 -0.1 -0.1 -0.2  2.1 -0.5  1.2 -0.3 13.5 -0.1  5.3 -0.2 -0.1 -3.2 -2.5  0.3 -0.4 -1.2 -0.3 -4.3 -0.1  1.7 -0.   4.3 -0.3]
vy_50sample [[3 9 6 1 2 0 5 4 8 7]
 [5 4 7 0 1 6 3 2 8 9]
 [0 2 5 6 3 9 8 7 1 4]
 [2 7 9 4 1 1 6 8 3 5]
 [9 5 6 8 7 3 0 1 2 4]
 [3 4 5 0 0 1 6 9 7 2]
 [8 3 9 1 5 6 0 7 4 2]
 [3 6 1 7 4 9 2 0 0 8]
 [8 7 5 9 6 0 2 3 4 1]
 [6 5 0 2 1 1 3 4 8 7]]
vt_50sample [[3 9 6 1 2 0 5 4 8 7]
 [5 4 7 1 0 6 3 2 8 9]
 [0 2 5 6 3 9 8 7 1 4]
 [2 7 9 4 0 1 6 8 3 5]
 [9 5 6 8 7 0 3 1 2 4]
 [3 4 5 8 0 1 6 9 2 7]
 [3 8 9 1 5 6 0 7 4 2]
 [3 6 1 7 4 9 2 0 5 8]
 [8 7 5 9 6 0 2 3 4 1]
 [6 0 5 2 1 3 9 4 8 7]]
Epoch 31610: Training cost= 0.2634, Training acc= 0.8410, Validation cost= 0.3215, Validation acc= 0.8411
Epoch 31620: Training cost= 0.2429, Training acc= 0.8410, Validation cost= 0.2588, Validation acc= 0.8411
Epoch 31630: Training cost= 0.3008, Training acc= 0.8410, Validation cost= 0.3057, Validation acc= 0.8411
Epoch 31640: Training cost= 0.2232, Training acc= 0.8410, Validation cost= 0.2922, Validation acc= 0.8411
Epoch 31650: Training cost= 0.2828, Training acc= 0.8410, Validation cost= 0.3071, Validation acc= 0.8411
Epoch 31660: Training cost= 0.2432, Training acc= 0.8411, Validation cost= 0.2215, Validation acc= 0.8412
Epoch 31670: Training cost= 0.2502, Training acc= 0.8411, Validation cost= 0.2750, Validation acc= 0.8412
Epoch 31680: Training cost= 0.2247, Training acc= 0.8411, Validation cost= 0.2614, Validation acc= 0.8412
Epoch 31690: Training cost= 0.2585, Training acc= 0.8411, Validation cost= 0.2505, Validation acc= 0.8412
Epoch 31700: Training cost= 0.2485, Training acc= 0.8411, Validation cost= 0.2682, Validation acc= 0.8412
tm  [-0.8 -1.  -2.2 -1.6 -0.6 -0.  -0.1 -0.3 -0.1  1.7  3.6 -0.8  0.4 -0.1 -0.5 -0.4 -0.2 -0.5 -0.   0.4 -1.1 -0.3  1.3 -0.1 -0.8  2.6 -0.2 -0.2 -1.9 -2.1 -0.4 -0.2 -0.3 -4.9  0.4 -0.2  2.4  1.5 -2.6 -0.5 -0.3  2.6 -0.6 -0.1 -0.2 -0.  -1.5 -0.4  0.1 11.2 -0.4 -0.2 -0.7 10.3  2.8  0.4 -1.  -0.9  5.7  3.6  4.8  0.3 -0.5  1.8 -1.2  0.9  0.1 -0.2  1.2  0.4  0.1  5.8 -0.2 -0.5 -4.7 -0.4 -0.4  0.6 -0.3 -0.  -3.8 -0.6 -0.3  0.3 -0.5  1.7  0.2 -0.3 -0.2 -0.4 -0.8 -0.3 -0.1 -0.6 -0.2 -0.2  0.5 -2.6 -0.5 -0.1 -0.8  0.1 -0.5 -0.1  0.1 -0.1 -2.2 -0.4  1.5 -0.6 -0.6 -0.  -0.2 -0.4  5.9 -3.  -0.4 -0.  -0.1 -0.1 -0.2  1.  -0.3 -0.1 -0.1 -0.6 -0.6 -2.5  2.8  0.5 -0.2 -0.5 -0.6 -0.4 12.2  0.1 -0.2 -0.3 -0.4 -0.5 -1.  -1.6 -1.  -0.4  0.1 -0.2 -0.4 -0.1  3.  -0.2  1.   0.3  1.4 -0.2 -0.3 -0.3  0.1 -0.4 -0.7 -0.2  0.6 -0.2 -0.3 -0.4 -0.3 -0.7 -0.4 -0.2 -0.2 -0.4 -0.1 -0.3  0.1 -0.4  0.5 -0.4 -0.8 -0.7  4.7 -0.2 -0.1 -0.2 -0.2 -1.  -0.  -0.1 -0.4  1.  -0.1  5.9 -0.1 -0.1 -0.2 -0.3 -1.4 -0.5 -1.7 -1.2 -0.   0.1 -0.3 -0.1  0.2 -0.3 -0.1 -3.2 -0.5 -0.   7.6 -0.1 -0.2 -2.3 -0.3  0.4 -0.5 -0.4  2.1 -1.  -1.  -0.2  0.5 -0.2  0.3 -1.2  4.8 -1.1  1.3  1.  -0.5  0.9 -0.4  1.2  0.4  3.1  4.8  3.9  2.7 -1.5  1.   1.1  0.   0.4  0.4 -0.1 12.6  4.1  0.7 -0.3 -0.9 -0.2 10.1 -0.3 -1.6 -0.2 -1.8  2. ]
ty_50sample [[0 2 8 6 1 4 5 9 3 7]
 [3 0 5 6 4 2 1 7 8 8]
 [3 7 5 2 4 6 1 8 9 0]
 [4 2 1 3 8 5 7 9 0 6]
 [3 2 8 0 7 6 9 4 5 1]
 [5 4 8 1 1 6 2 3 9 0]
 [6 0 7 1 5 3 8 2 9 4]
 [8 6 9 3 5 1 0 4 7 2]
 [6 4 5 8 2 1 7 0 3 9]
 [2 4 7 0 6 8 5 1 9 3]]
tt_50sample [[0 2 8 6 1 4 9 5 3 7]
 [3 0 5 6 4 2 1 7 9 8]
 [3 7 5 2 4 6 1 8 9 0]
 [4 2 1 3 8 5 7 9 0 6]
 [3 2 8 0 7 6 9 4 5 1]
 [5 4 8 1 7 6 2 3 0 9]
 [6 0 7 1 5 3 8 2 9 4]
 [8 6 9 3 5 1 0 4 7 2]
 [6 4 5 8 2 1 7 0 3 9]
 [2 4 7 0 6 8 5 1 9 3]]
vm  [-1.1  2.8  4.2  7.6 -1.4 -0.3 -0.4 -0.1 -1.6 -1.  -7.3 -0.3 -0.1 -0.2 -0.2 -0.  -0.4 -0.   1.6 -2.3 -0.5  0.2  1.1 -0.1 -0.6 -0.9 -0.3 -0.3  0.9  6.7 -0.7 -0.4  1.  -0.7 -0.2 -0.   2.4 -0.7 10.4 -0.3 -0.1 -2.1  1.7  2.3 -0.2 -0.2 10.   1.4 -1.   4.2 -0.3 -0.1 -0.3 -3.9 -1.8 -0.1 -1.1 -0.8 -2.1  4.1 -0.6 -0.1 -0.9 -0.6 -0.8 -0.5 -0.3 -0.5 -0.1 -0.  -0.  -1.6 -0.3 -0.3  5.3  0.1 -0.  -0.6 -0.4  1.   0.6 -0.1 -0.4 -0.3 -0.2 -1.9 -0.1 -0.1 -0.3 -0.1 -0.4 -0.1 -0.2  4.2 -0.2 -0.2 -0.4  0.6 -0.1 -0.1  5.6  0.3  1.5 -0.1  0.2 -0.2  0.3 -0.7 -2.3 -2.5 -0.2 -0.2 -0.3 -0.1 -1.5 11.6  0.9 -1.4  0.1 -0.7 -0.4  9.6 -0.5 -0.4 -0.4 -0.3 -0.1 14.9 -1.9 -0.3 -0.5  0.2  0.  -0.4 -2.8 -3.5 -0.3  0.  -0.8  0.5  1.9  0.3  0.3 -0.2 -0.1  0.1 -0.5 -0.2 -1.4 -0.1 -1.  -0.3  1.3 -0.7 -0.2 -0.2  0.7  0.8  0.4 -0.8 -0.8 -0.8 -0.4  0.2 -0.6  1.6 -0.2  0.6 -0.1 -0.2 -0.3 -0.2 -0.3 -0.  -0.4  3.3 -0.2 -0.2 -0.9 -0.2 -0.9  0.9  1.  -0.9 -0.4 -0.  -0.6 -0.6 -0.2 -1.5 -0.3  0.4 -0.1 -1.1  4.9  6.1  2.6  3.7 -0.1 -0.1  0.9 -0.3 -0.3 -0.7 -0.3  1.8 -0.5 -0.2  8.4 -0.3 -0.3  2.6 -0.4  1.9  0.4 -0.4 -0.7 -0.2 -0.1 -0.2 -0.2  0.3 -0.  -0.6 -1.3  5.3 -1.7 -0.5 -0.3 -0.6 -0.7 -0.6 -0.1  3.8 -1.  -0.8 -0.8  2.7 -0.5 14.2 -0.1  5.8 -0.5 -0.2  1.6 -1.9 -0.4  0.2 -0.4 -0.2 -0.3  0.   6.4 -0.3  7.   3.4]
vy_50sample [[8 9 7 3 1 4 6 5 0 2]
 [1 7 0 3 8 6 6 4 9 5]
 [7 1 8 4 6 0 5 3 9 9]
 [3 6 4 7 8 2 1 0 0 5]
 [0 1 9 4 8 2 6 3 7 5]
 [1 2 7 9 5 4 0 8 3 6]
 [8 9 7 5 2 3 1 4 6 0]
 [4 9 3 8 5 7 1 6 0 2]
 [2 1 3 7 7 4 8 6 0 9]
 [1 0 8 2 3 4 9 5 7 6]]
vt_50sample [[8 9 7 3 1 4 6 5 0 2]
 [1 7 0 3 8 2 6 4 9 5]
 [7 1 8 4 0 6 5 3 9 2]
 [3 6 4 7 8 2 1 0 9 5]
 [0 1 9 4 8 2 6 3 7 5]
 [1 2 7 9 5 4 0 8 3 6]
 [8 9 7 5 2 3 1 4 6 0]
 [4 9 8 3 5 7 1 0 6 2]
 [2 1 5 3 7 4 8 6 0 9]
 [1 0 8 2 3 9 4 7 5 6]]
Epoch 31710: Training cost= 0.2922, Training acc= 0.8411, Validation cost= 0.2349, Validation acc= 0.8412
Epoch 31720: Training cost= 0.2467, Training acc= 0.8412, Validation cost= 0.2590, Validation acc= 0.8413
Epoch 31730: Training cost= 0.3021, Training acc= 0.8412, Validation cost= 0.2947, Validation acc= 0.8413
Epoch 31740: Training cost= 0.2935, Training acc= 0.8412, Validation cost= 0.2896, Validation acc= 0.8413
Epoch 31750: Training cost= 0.2366, Training acc= 0.8412, Validation cost= 0.2781, Validation acc= 0.8413
Epoch 31760: Training cost= 0.2485, Training acc= 0.8412, Validation cost= 0.2402, Validation acc= 0.8413
Epoch 31770: Training cost= 0.3179, Training acc= 0.8412, Validation cost= 0.2512, Validation acc= 0.8413
Epoch 31780: Training cost= 0.2785, Training acc= 0.8413, Validation cost= 0.3066, Validation acc= 0.8414
Epoch 31790: Training cost= 0.2494, Training acc= 0.8413, Validation cost= 0.3448, Validation acc= 0.8414
Epoch 31800: Training cost= 0.2589, Training acc= 0.8413, Validation cost= 0.2937, Validation acc= 0.8414
tm  [-0.7 -0.2  2.1  9.5 -1.1  0.1 -0.2 -0.1 -0.1 -0.6 12.3 -0.5 -0.1 -0.2 -0.9  2.2 -0.2 -0.3  0.5 -0.9 -1.3 -0.1 -1.3 -0.4 -1.   1.  -0.3 -0.4 -1.4 -2.6  1.5 -0.8  1.   6.7  0.2  0.2  2.8  5.3  2.4 -0.5  0.  -2.2 -0.8 -0.4 -0.4 -0.3  4.2 -0.6  0.  -3.8 -0.5 -0.3 -0.6  5.2 -0.1  1.3 -0.5  0.1  3.2 -1.1  1.2 -0.5 -0.5  1.4 -0.1 -0.6 -0.  -0.1 -0.3 -0.3 -0.   4.1  0.9 -0.1 -1.  -0.2 -0.7 -0.7 -0.1 -0.2 16.8 -0.3 -0.5 -0.3 -0.4 -2.1 -0.7 -0.3 -0.1 -0.6 -0.2 -0.1  0.2 -0.1 -0.2 -0.3 -0.3 -1.5 -0.2 -0.5  2.7 -1.4 -0.1  0.1 -0.2 -0.3 -1.1  1.   0.3 -1.3 -0.4 -0.1  0.1 -0.1  3.8 -1.6  0.2 -0.5 -0.1 -0.  -0.4  5.8 -0.2  0.2 -0.  -1.2 -0.1 -1.   1.4  2.4 -0.2 -0.3  0.2 -0.4  5.  11.6 -0.5 -0.1  1.  -0.3 -1.4 -0.8 -1.3 -0.3 -0.  -0.1 -0.3 -0.1 -0.5 -0.2 -0.9  0.7 -1.5 -1.1 -0.  -0.4 -0.1 -0.3 -0.1  0.6 -0.  -0.6 -0.2 -0.1 -0.3 -0.1 -0.4  0.7 -0.2 -0.2 -0.2 -0.3 -0.2 -0.  -0.4  1.7 -0.8 -0.3  0.6 -0.   0.3 -0.1 -0.2 -1.3 -0.1 -0.3  0.1 -0.4 -0.4  8.  -0.1  0.1 -0.4 -0.5  1.5 -0.2 -0.2 -0.7 -0.3 -0.1 -0.3 -0.1 -0.3 -0.6 -0.1 -0.9 -0.3 -0.2 -1.1 -0.2 -0.6 -1.3 -0.5  1.7 -0.5 -0.4  4.1 -1.  -0.8 -0.2 -0.1 -0.  -0.4 -1.  -0.4 -1.5  3.6  1.3 -0.2  1.3 -0.7 -0.4  0.3 -0.5  3.3 -0.1  1.1 -0.3 -0.5 11.2 -0.1  4.5 -0.1 -0.2 -3.5 -1.1  1.  -0.4 -1.3 -0.2 -4.5  0.   1.1  0.2 -0.3  0. ]
ty_50sample [[2 0 3 9 1 6 7 4 5 8]
 [6 5 7 4 3 8 2 9 0 1]
 [5 9 0 4 6 2 1 1 3 7]
 [5 0 7 2 3 3 1 4 4 9]
 [7 9 5 4 0 8 3 1 1 6]
 [1 7 8 0 2 2 4 3 6 9]
 [8 1 4 6 7 0 3 9 9 5]
 [2 1 8 8 9 0 5 4 6 3]
 [0 3 9 6 8 7 2 1 5 4]
 [7 6 8 1 5 0 2 4 3 9]]
tt_50sample [[2 0 3 1 9 6 7 4 5 8]
 [6 5 7 4 3 8 2 9 0 1]
 [5 9 0 4 6 2 1 8 3 7]
 [5 7 0 2 3 8 1 6 4 9]
 [7 9 5 4 0 8 3 1 2 6]
 [1 7 8 0 5 2 4 3 9 6]
 [8 1 4 6 7 3 0 9 2 5]
 [2 1 8 7 9 0 5 4 6 3]
 [0 3 9 6 8 7 2 1 5 4]
 [7 6 8 1 0 5 2 4 3 9]]
vm  [ 0.7 -0.5 -0.1  4.4 -1.5 -0.1 -0.5 -0.1 -0.1 -0.4 -0.4 -0.2 -0.1 -0.1 -0.4  2.1 -0.6 -0.2  0.5 -1.1 -1.   0.9  1.7 -0.4 -0.7  0.1 -0.1 -0.6 -0.4 -0.6  0.7 -0.3 -0.5 -0.1  0.  -0.1  0.5  4.6 15.1 -0.7  1.  -0.4 -0.   5.4 -0.2  1.   5.3 -0.2  6.6  6.4 -0.4 -0.2  0.3 -0.7 -0.3  0.5 -0.5 -1.8  3.6  1.  -1.5 -0.1 -0.4  2.1 -0.7 -0.3 -0.2 -0.2  2.4 -0.2 -0.  -0.3  1.3  1.4  0.7 -0.3 -1.  -0.4 -0.  -0.   3.4 -0.1 -0.2  0.8 -1.3 -0.1  6.5 -0.  -0.3 -0.6 -0.3  0.4 -0.3 -1.3 -0.4 -0.2 -0.6 -1.8 -0.3  0.4  1.8  4.7 -0.7  0.2 -0.1 -0.4  1.1  0.5 -0.3 -1.9 -1.1 -0.3 -0.2 -0.6  0.8  4.5  0.2 -0.3 -0.3 -0.6 -0.1  7.9  0.2 -0.8 -0.3 -0.6 -0.2  4.8  4.5 -1.3  0.2 -1.   0.2 -0.9 -4.6 -4.3  0.1 -0.2 -0.8 -0.3 -0.2 -0.5 -0.1 -0.1 -0.1 -0.2  0.5 -0.3 -1.3  0.8 -0.2 -0.2  4.9 -0.2  0.4 -0.1  1.   0.2  4.6 -0.3  0.7 -1.4 -0.2  0.1 -0.6 -0.2  0.8  0.5  0.  -0.1 -0.2 -0.2 -0.1 -0.1 -0.2  2.6  1.8 -0.  -1.6 -0.3 -0.9 -0.5 -0.6 -1.2 -0.2  0.5  3.9 -0.4 -0.3  1.6  0.4 -0.3 -0.6 -0.5 11.  -1.4  2.5 -0.4 -0.1 -0.1 -0.3 -0.2 -0.5 -0.6 -0.1 -0.  -0.3 -0.2  5.9 -0.3 -0.5  1.4 -1.1 -1.4 -0.9 -0.5 -2.  -0.7  0.8  0.8 -0.4 -0.1 -0.  -1.1 -1.2  2.3 -0.6 -0.3 -0.   5.2 -0.2 -1.4  2.   3.8  1.1  0.7  0.7  2.9  3.9 11.3 -0.2  3.8 -0.2  0.  -0.  -1.6 -0.1  1.9 -1.2 -0.6 -1.3 -0.2 10.1 -0.3 -0.1  7.4]
vy_50sample [[9 8 4 7 2 0 3 5 1 6]
 [6 9 3 1 2 4 8 7 5 0]
 [2 8 1 6 9 3 4 0 5 7]
 [4 7 3 1 5 2 0 6 9 8]
 [3 4 6 2 8 1 0 7 9 5]
 [7 8 3 1 4 9 6 2 0 5]
 [3 7 7 6 1 4 9 8 0 2]
 [3 8 6 2 5 1 9 4 0 7]
 [1 1 5 7 2 3 4 8 0 6]
 [3 1 2 0 4 9 6 5 7 8]]
vt_50sample [[9 8 4 7 2 0 3 5 1 6]
 [6 9 3 2 1 4 8 7 5 0]
 [2 8 1 6 9 3 4 0 5 7]
 [4 7 3 1 5 2 0 6 9 8]
 [3 4 6 2 1 8 0 7 9 5]
 [7 8 3 1 4 9 6 2 0 5]
 [3 5 7 6 1 4 9 8 0 2]
 [3 8 6 2 1 5 9 4 0 7]
 [1 9 5 7 2 3 4 8 0 6]
 [3 1 2 0 4 9 6 5 7 8]]
Epoch 31810: Training cost= 0.2532, Training acc= 0.8413, Validation cost= 0.3158, Validation acc= 0.8414
Epoch 31820: Training cost= 0.2667, Training acc= 0.8413, Validation cost= 0.3217, Validation acc= 0.8414
Epoch 31830: Training cost= 0.3238, Training acc= 0.8413, Validation cost= 0.2891, Validation acc= 0.8414
Epoch 31840: Training cost= 0.2902, Training acc= 0.8413, Validation cost= 0.2199, Validation acc= 0.8415
Epoch 31850: Training cost= 0.2967, Training acc= 0.8414, Validation cost= 0.2984, Validation acc= 0.8415
Epoch 31860: Training cost= 0.3471, Training acc= 0.8414, Validation cost= 0.2805, Validation acc= 0.8415
Epoch 31870: Training cost= 0.2746, Training acc= 0.8414, Validation cost= 0.2402, Validation acc= 0.8415
Epoch 31880: Training cost= 0.2815, Training acc= 0.8414, Validation cost= 0.2713, Validation acc= 0.8415
Epoch 31890: Training cost= 0.2545, Training acc= 0.8414, Validation cost= 0.2504, Validation acc= 0.8415
Epoch 31900: Training cost= 0.3083, Training acc= 0.8414, Validation cost= 0.3293, Validation acc= 0.8415
tm  [-2.2  0.   6.4  1.  -2.2 -0.4 -0.6 -0.2 -1.2 -0.6 -4.8  1.  -0.3 -0.2  7.8 -1.3  0.2  0.5  0.7  0.2 -0.6 -0.1  1.7 -0.1 -1.5  3.2 -0.5 -0.3 -1.3 -0.  -0.7 -0.3 -0.2  4.1 -0.3  0.3  5.1 -0.3  0.8 -0.4  0.8  1.1  2.6  2.  -0.1 -0.2 -1.1 -0.2 -1.6  4.6 -0.4 -0.3 -0.2 -1.5 -0.8 -0.7 -1.1  3.4 -1.   3.3  7.3  0.3  0.8 -0.3 -1.8 -0.1 -0.1 -1.2 -0.4  1.2 -0.   3.4  0.4  0.5 -3.1  0.1  1.6 -0.3 -0.3  1.4 -2.  -0.6  0.6 -0.7  2.9  3.1 -1.7 -0.4  0.2 -0.1 -0.9 -0.4 -0.3  2.1 -0.2 -0.3  0.6 -1.8 -0.4  0.3  2.7  4.7  1.4 -0.1 -0.3  1.1 -1.5 -0.3 -1.6 -1.3 -0.7 -0.2  0.2  0.1 -0.1 -0.6  0.9 -1.1 -0.1 -0.5 -0.1  3.9 -0.6 -0.1 -0.2  9.3  0.5  7.2 -1.   1.8 -1.1 -0.2 -0.9  0.3 -3.6 -2.2  0.2 -0.  -0.4 -0.3  2.1 -0.9 -0.1 -0.5 -0.1 -0.2 -0.3 -0.1 -0.7 -0.3 -0.4 -0.2 -0.5 -0.7 -0.1 -0.4 -0.4 -0.4  3.3 -0.3 -0.1 -1.4 -0.3 -0.1 -0.5 -0.1 -0.2 -0.4 -0.4 -0.2 -0.1 -0.2 -0.2 -0.5 -0.3  1.3 -0.4 -0.1  1.2 -0.2 -1.2  1.1  0.6 -1.3 -0.2 -0.5 -1.4 -0.1 -0.1  0.4 -0.1 -0.4  1.1 -1.1 -2.4  4.6 -0.4 -0.2 -0.2 -0.2  0.2 -0.2  1.2 -0.5 -0.3 -1.2 -0.3 -0.   2.6 -0.4 -0.4 -1.   0.6  8.2 -0.4  0.2 -0.5 -0.4 -0.6 -0.7  0.6 -0.  -0.5 -0.9 -0.6 -0.  -1.7 -0.5  1.3 -1.4 -0.  -0.  -0.1  1.8  0.7 -1.6 -0.7 -1.  -0.2 -0.6 -0.2 -0.2 -0.1 -0.5  7.7 -0.2 -0.6  0.7 -0.6 -0.6  4.3 -0.1  0.4 -0.1  3.6  0.7]
ty_50sample [[1 7 8 0 5 3 4 6 9 2]
 [5 7 6 8 4 2 9 1 3 0]
 [1 6 2 9 3 0 5 8 7 4]
 [8 3 4 1 5 9 0 2 7 6]
 [2 4 0 1 6 3 9 9 5 7]
 [9 1 8 7 4 3 0 2 6 5]
 [8 7 1 0 2 6 5 9 3 4]
 [9 1 8 6 0 4 3 2 7 5]
 [6 8 8 5 2 7 1 3 4 0]
 [7 2 1 0 3 5 6 4 8 9]]
tt_50sample [[1 7 0 8 5 4 3 6 9 2]
 [5 7 6 8 4 2 9 1 3 0]
 [1 6 2 9 3 0 5 8 7 4]
 [8 3 4 1 5 0 9 2 7 6]
 [2 4 0 1 3 6 9 8 5 7]
 [1 9 8 7 4 3 0 2 6 5]
 [8 7 1 0 2 6 5 9 3 4]
 [9 1 8 6 0 4 3 2 7 5]
 [6 9 8 5 2 1 7 3 4 0]
 [7 2 1 0 3 5 6 4 8 9]]
vm  [ 1.8  0.9  2.9 -1.5 -1.  -0.1 -0.2 -0.3 -0.8 -0.2 -3.8 -0.2 -0.3 -0.5  7.1  2.8  0.4 -0.  -0.1  3.3 -0.7 -0.4  0.7  0.6 -0.9  0.2 -0.4 -0.4  0.   2.1 -1.9 -0.4  2.6 -4.6 -0.4 -0.5 -0.2 -0.9 -5.9 -0.2 -0.1 -0.2  1.4 -1.6 -0.3 -0.5 -2.9 -0.4  5.4  6.3 -0.6 -0.2 -0.7  8.7 -1.2 -0.5 -0.5  5.4 -0.8  6.6  1.5 -0.4  0.6  0.5 -0.4 -0.7 -0.2 -0.3 -0.2 -0.4 -0.5 -0.5 -0.3 -0.4 -7.2 -0.3 -0.9 -0.1 -0.6 -0.1 -7.8  0.1 -0.  -0.  -2.2 -0.1  2.5  0.1 -0.2 -0.8 -0.3 -0.2 -0.1  3.2 -0.2 -0.2  1.  -3.3 -0.5 -1.1  2.3 -1.4 -1.1  0.2 -0.4 -0.5 -2.9 -1.6 -1.1  4.2  0.6 -0.1 -0.2 -0.6 -0.9  4.1 -0.4  0.2 -0.  -0.2 -0.5 -2.  -0.3 -0.6 -0.3  8.5 -0.1 -1.9 -0.6 12.   1.7 -0.2  0.6 -0.3 12.1  0.3 -0.3 -0.2  1.   1.4 -0.5 -0.8 -0.1 -0.3 -0.1 -0.1 -0.  -0.   4.7 -0.2 -0.1 -0.1  3.7 -0.4 -0.3 -0.2 -0.3 -0.7 -1.5 -0.4 -0.2  2.4 -0.2  0.2 -0.1 -0.4 -0.1 -0.6 -0.3 -0.3 -0.3  0.1 -0.5 -0.3 -0.2 -0.8 -1.9 -0.2  9.3 -0.3 -1.  -0.6 -0.2 -1.3 -0.7  0.2  2.1 -0.5 -0.5 -0.6 -0.  -0.4  0.2 -0.8  0.7  1.2 -1.4  0.7 -0.  -0.2  0.1 -0.2  1.4 -0.  -0.6 -3.8  0.2 -0.6  6.2 -0.5 -0.7  0.1 -0.8 -1.1  0.3 -0.   6.6 -0.3 -0.2 -0.6 -0.3 -0.1 -0.3 -0.9  2.2  1.1 -1.  -0.3 -0.9  3.1  2.   1.9 -0.5  3.5 -1.1  0.3  0.  -2.3 -0.2 -4.2 -0.2 -1.7 -0.2 -0.  22.7  4.7  0.7 -0.2 -0.6 -0.3 20.4 -0.5 -3.9  1.   2.4 -3.2]
vy_50sample [[8 6 3 5 2 0 7 4 1 9]
 [3 5 9 9 8 1 2 4 0 6]
 [5 6 4 9 9 7 3 1 2 8]
 [5 0 2 7 9 6 8 1 4 3]
 [8 0 3 7 2 9 5 6 1 4]
 [1 9 2 0 7 4 3 5 8 6]
 [7 0 8 1 5 4 2 6 3 9]
 [8 3 9 5 2 4 6 1 7 0]
 [5 9 8 2 4 3 6 0 7 1]
 [2 0 4 7 3 8 9 6 5 1]]
vt_50sample [[8 6 3 5 2 7 0 4 1 9]
 [3 5 7 9 8 1 2 4 0 6]
 [5 6 4 9 7 0 3 1 2 8]
 [0 5 2 7 9 6 8 1 4 3]
 [8 0 3 7 2 9 5 6 1 4]
 [1 9 2 0 7 4 3 5 8 6]
 [7 0 8 1 5 4 2 6 3 9]
 [8 3 9 5 2 4 6 1 7 0]
 [5 9 8 2 3 4 6 0 7 1]
 [2 0 4 7 3 8 9 6 5 1]]
Epoch 31910: Training cost= 0.2650, Training acc= 0.8415, Validation cost= 0.2825, Validation acc= 0.8416
Epoch 31920: Training cost= 0.3002, Training acc= 0.8415, Validation cost= 0.2592, Validation acc= 0.8416
Epoch 31930: Training cost= 0.2536, Training acc= 0.8415, Validation cost= 0.2744, Validation acc= 0.8416
Epoch 31940: Training cost= 0.2674, Training acc= 0.8415, Validation cost= 0.2895, Validation acc= 0.8416
Epoch 31950: Training cost= 0.2768, Training acc= 0.8415, Validation cost= 0.2550, Validation acc= 0.8416
Epoch 31960: Training cost= 0.2851, Training acc= 0.8415, Validation cost= 0.2940, Validation acc= 0.8416
Epoch 31970: Training cost= 0.2742, Training acc= 0.8416, Validation cost= 0.3318, Validation acc= 0.8417
Epoch 31980: Training cost= 0.2604, Training acc= 0.8416, Validation cost= 0.3371, Validation acc= 0.8417
Epoch 31990: Training cost= 0.2545, Training acc= 0.8416, Validation cost= 0.3059, Validation acc= 0.8417
Epoch 32000: Training cost= 0.2575, Training acc= 0.8416, Validation cost= 0.2757, Validation acc= 0.8417
tm  [ 0.4 -0.  -2.9 -3.7 -0.9 -0.1  0.  -0.2 -0.6 -0.5 10.5  0.8 -0.3 -0.3  1.2  5.3 -0.  -0.4 -0.4  0.4 -1.2 -0.3 -0.5 -0.2 -1.4  0.7 -0.2 -0.3  0.6  2.9  6.3 -0.8  1.8  6.2 -0.3 -0.3  0.6  0.2 -2.7 -0.1 -0.   2.   1.5  1.7 -0.1 -0.2 -0.9 -0.5  3.2 -1.9 -0.2 -0.1 -0.7  8.4 -1.8 -0.1 -0.6 -1.3 -0.2 -3.8  0.8 -0.4 -0.2 -0.5  0.8 -0.7 -0.   1.2  0.3 -0.2 -0.5 -1.2  0.   0.2 -4.8  0.  -0.7  0.4 -0.1 -0.2  7.8 -0.4 -0.5 -0.4 -1.4  2.6  8.1 -0.2  0.1 -0.6 -0.7 -0.3 -0.2  1.  -0.5 -0.3 -0.1 -2.2 -0.3 -0.5  2.2 -0.1 -1.2 -0.2 -0.3 -0.5 -2.3  5.6  1.1 -0.5 -0.2 -0.6 -0.  -0.7 -0.4  7.9  1.6 -0.4 -0.3  0.3  0.4  0.1 -0.2 -0.2 -0.3  1.5  0.2 -1.9 -0.2  3.9  0.3 -0.1  0.2  0.4  8.9 15.9 -0.1 -0.  -0.6 -0.8 -0.9 -0.1 -0.1 -0.3 -0.  -0.3 -0.1 -0.1  3.6 -0.5  1.3 -0.2 -0.  -0.3 -0.2 -0.2 -0.2 -0.4 -1.   0.1 -0.3 -0.1 -0.2 -0.3 -0.2 -0.3 -0.6 -0.5 -0.5 -0.3 -0.3 -0.2 -0.2 -0.2  0.2 -0.7 -1.5 -0.2  5.  -0.2 -1.1  0.3 -0.2 -1.5 -0.4 -0.   1.9 -0.3 -0.5 -0.8 -0.5 -0.3 -0.4 -1.3  3.1 -0.1 -0.7  0.9 -0.1 -0.4  0.4 -0.4  0.3 -0.4 -0.4 -2.   0.1 -0.2 -3.2 -0.4 -0.8  2.  -0.5 -0.6  1.8  0.3 -0.6 -0.9 -0.3 -0.4 -0.2 -0.4 -0.8 -1.4  2.2 -0.2 -0.4 -1.   1.4  2.   0.3  3.3 -0.3 -1.6 -1.   5.3 -0.2 -1.7 -0.6 -1.4 -0.  -0.5 -0.2 -0.2 -1.4  0.1 -0.1 -0.3 -0.7 -0.  -2.  -0.  -1.8 -0.  -0.5 -0.3]
ty_50sample [[4 6 2 5 3 7 9 1 0 8]
 [1 5 6 3 4 9 7 0 2 8]
 [7 1 0 3 6 2 5 4 8 9]
 [3 4 9 1 0 7 5 8 2 6]
 [8 1 4 2 7 3 0 5 9 9]
 [2 3 0 5 1 8 9 7 6 4]
 [9 3 6 8 7 5 1 0 4 4]
 [1 4 0 7 9 5 2 6 3 8]
 [1 7 0 3 2 9 4 6 8 5]
 [4 5 6 1 3 0 9 7 8 2]]
tt_50sample [[4 6 2 5 3 7 9 1 0 8]
 [1 5 6 3 4 9 7 0 2 8]
 [7 1 0 3 6 2 5 4 8 9]
 [3 4 1 9 0 7 5 8 2 6]
 [8 1 4 2 7 3 0 5 6 9]
 [2 0 3 5 1 8 9 7 6 4]
 [9 3 6 8 7 5 1 0 2 4]
 [1 4 0 7 9 5 2 6 3 8]
 [1 7 0 3 9 2 4 6 8 5]
 [4 5 6 1 3 0 9 7 8 2]]
vm  [-1.8 -0.2 -3.3  4.3 -0.5 -0.  -0.3 -0.  -0.3 -0.4  4.8 -0.6  0.4 -0.2 -3.3  6.1 -0.7 -0.3 -0.3 -1.3 -0.8 -0.4  1.4 -0.3 -0.8  0.1 -0.4  0.1  0.8 -0.9  0.  -0.1 -0.2 -4.5 -0.1 -0.1  2.4  2.7  5.6 -0.4  0.6  2.  -0.6  1.2 -0.1  0.7  7.6 -0.5 -2.1  9.2 -0.2 -0.2 -0.2  2.  -1.3  4.2 -0.6 -0.8  2.1  1.5  3.2 -0.2 -0.8 -0.2 -0.2  0.9 -0.1  0.3 -0.1 -0.2 -0.1 -1.3 -0.3 -0.3  0.3  0.5  0.4  0.7 -0.3 -0.1  2.7 -0.4 -0.3  1.7  4.1  3.2 -1.  -0.3 -0.2 -0.5 -0.3 -0.1 -0.3 -0.5 -0.5 -0.1 -0.3 -0.9  0.1 -0.   1.7 -0.4  1.8 -0.2 -0.1 -0.4 -0.8  1.   1.4 -1.9 -0.3 -0.  -0.1 -0.6 -0.2  9.3  0.6 -1.1 -0.2 -0.3 -0.   7.4  0.2 -0.1 -0.2 -3.9 -0.1  0.5  0.5 -2.2 -0.8 -0.7 -0.  -0.4  9.9 -0.7 -0.  -0.1 -0.2 -0.7 -0.9 -0.2 -1.2 -0.3 -0.2 -0.1 -0.4 -0.1  5.2 -0.3 -0.5  0.1 -0.5 -0.4  0.9 -0.3  0.5 -0.5 -0.1 -0.1 -0.3 -0.3 -0.2  0.5 -0.1 -0.1  0.3  2.  -0.3  0.2 -0.1 -0.4  0.1 -0.3 -0.  -0.9 -0.7 -0.2 -0.6 -0.2 -0.7 -0.2 -0.1 -1.1 -0.2 -0.  -1.2  0.5 -0.1  4.1 -0.1 -0.1 -0.6 -0.7 -0.6 -0.2  0.3  1.1 -0.3 -0.2 -0.4 -0.1 -0.2 -0.5 -0.3 -0.6 -0.1 -0.   4.8 -0.1 -0.2  2.3 -0.6  6.1 -0.2 -0.2 -0.3 -0.8 -0.5 -0.1 -0.3 -0.4 -0.3 -1.   2.6  3.8  1.5  1.1 -0.2 -0.5 -0.8 -0.3 -0.1  2.  -0.4  4.7  0.1 -0.2  0.3  9.9 -0.1  3.8 -0.1 -0.  -0.  -1.4  0.7 -0.1 -1.3 -0.2 -1.  -0.1  4.1 -0.2 -1.2 10.9]
vy_50sample [[1 2 9 8 4 6 5 3 0 7]
 [9 7 0 8 1 4 2 6 5 3]
 [9 3 7 4 1 0 0 6 5 8]
 [6 4 5 1 2 2 9 9 3 0]
 [4 8 2 0 6 5 9 7 1 1]
 [8 1 3 4 5 7 0 0 2 9]
 [5 8 7 9 3 0 6 4 1 2]
 [6 3 5 9 7 8 4 0 0 2]
 [2 4 6 3 1 0 9 8 5 7]
 [6 5 7 8 2 3 4 1 9 0]]
vt_50sample [[1 2 9 8 4 6 5 3 0 7]
 [9 7 0 8 1 4 2 6 5 3]
 [9 3 7 4 1 2 0 6 5 8]
 [6 4 5 1 7 2 8 9 3 0]
 [4 8 2 0 6 5 9 7 1 3]
 [8 1 3 4 5 7 0 9 2 6]
 [5 8 7 9 3 0 6 4 1 2]
 [6 3 9 5 7 8 4 1 0 2]
 [2 4 6 3 1 0 9 8 5 7]
 [6 5 7 8 2 3 4 1 9 0]]
Epoch 32010: Training cost= 0.2711, Training acc= 0.8416, Validation cost= 0.2910, Validation acc= 0.8417
Epoch 32020: Training cost= 0.2992, Training acc= 0.8416, Validation cost= 0.2733, Validation acc= 0.8417
Epoch 32030: Training cost= 0.2951, Training acc= 0.8416, Validation cost= 0.2497, Validation acc= 0.8417
Epoch 32040: Training cost= 0.3359, Training acc= 0.8417, Validation cost= 0.2622, Validation acc= 0.8418
Epoch 32050: Training cost= 0.2666, Training acc= 0.8417, Validation cost= 0.3266, Validation acc= 0.8418
Epoch 32060: Training cost= 0.3141, Training acc= 0.8417, Validation cost= 0.2405, Validation acc= 0.8418
Epoch 32070: Training cost= 0.2450, Training acc= 0.8417, Validation cost= 0.2394, Validation acc= 0.8418
Epoch 32080: Training cost= 0.3302, Training acc= 0.8417, Validation cost= 0.2638, Validation acc= 0.8418
Epoch 32090: Training cost= 0.2671, Training acc= 0.8417, Validation cost= 0.2439, Validation acc= 0.8418
Epoch 32100: Training cost= 0.2414, Training acc= 0.8418, Validation cost= 0.2656, Validation acc= 0.8419
tm  [-1.9 -0.6  9.8 15.9 -1.5  0.1  0.2  0.3  1.1 -0.3  7.2 -0.1 -0.4 -0.   2.5  6.  -0.  -0.3 -0.4 -1.2 -0.7 -0.2 -0.7 -0.6 -0.7  0.3  0.2  0.6  3.3 -1.1 -0.5 -0.4 -0.3  9.9 -0.1 -0.   0.2  2.7  7.5 -0.3  0.2 -1.2 -1.1 -0.8 -0.   0.1  6.2 -0.5 -2.2 -1.6 -0.3 -0.  -0.1  0.5 -1.6 -0.  -0.3  3.3  3.6  3.4  4.7 -0.3 -0.  -0.6  2.1 -0.4 -0.  -0.2 -0.1 -0.3 -0.3 -2.1 -0.6 -0.2 -1.3 -0.   0.3  1.4 -0.2  0.2 11.7 -0.  -0.5  0.2  3.  -0.6 -2.8 -0.1 -0.2 -0.4 -0.3 -0.2 -0.5 -0.8 -0.7 -0.  -0.1 -1.3 -0.  -0.2  0.9  3.2  1.2 -0.  -0.2 -0.  -1.1 -0.4  0.8 -1.8  0.2 -0.3  0.3 -1.  -0.1 11.7 -0.4 -0.3  0.1 -0.5 -0.2  6.3  0.2 -0.4  0.5  2.6  0.1  1.8  1.   1.  -0.7 -0.2 -0.1 -0.2 -3.1  4.4 -0.2 -0.2 -0.4 -0.4 -0.9  0.1 -0.4 -0.2  0.1 -0.1 -0.2 -0.  -1.7 -0.1 -1.2 -0.1 -1.7 -0.4  0.4  0.2  0.4 -0.3 -0.1 -0.5  0.2 -0.9 -0.2  0.5  0.4  0.3 -0.5  2.3 -0.5 -0.1 -0.2 -0.3  0.2 -0.3  0.2  2.8 -0.6 -0.3 -0.7  0.  -0.5  0.3 -0.3 -1.8 -0.2 -0.5 -1.1 -0.8  0.3  4.1 -0.2 -0.3 -0.7 -0.5 -1.1 -0.4 -0.  -0.   0.  -0.4 -0.2  0.5  0.1 -0.1 -0.1 -0.2  0.7 -0.   1.4 -0.1 -0.4  4.7 -0.4  6.9 -0.6  1.6  3.  -0.5 -0.1 -0.1 -0.4 -0.4 -0.1 -0.9 -0.1  4.1 -0.5 -0.  -0.5 -0.5 -0.7 -0.   0.5  0.4 -1.3 -2.3 -0.3 -0.4  0.5 11.4 -0.1  4.2  0.3 -0.1 -2.2 -1.3 -0.5  0.2 -1.1 -0.7 -3.2 -0.1  5.3 -0.3 -0.3  1.5]
ty_50sample [[1 7 9 9 3 6 5 8 4 0]
 [3 9 8 2 4 1 0 5 6 7]
 [5 9 8 2 1 4 6 7 0 3]
 [7 0 4 8 3 2 1 6 5 9]
 [7 1 2 8 0 5 6 4 9 3]
 [8 9 3 7 2 1 4 0 6 5]
 [3 0 2 6 7 4 1 9 8 5]
 [1 5 8 2 4 7 3 0 0 6]
 [5 4 9 9 8 7 7 6 0 0]
 [6 0 1 8 7 2 3 5 4 9]]
tt_50sample [[1 7 2 9 3 6 5 8 4 0]
 [3 9 8 2 4 1 0 5 6 7]
 [5 9 8 2 1 4 6 7 0 3]
 [7 0 4 8 3 2 1 6 5 9]
 [7 1 2 8 0 5 6 4 9 3]
 [8 9 3 7 2 1 4 0 6 5]
 [3 0 2 6 7 4 1 9 8 5]
 [1 5 8 2 4 7 3 9 0 6]
 [4 5 9 1 2 8 7 6 3 0]
 [6 0 1 8 7 2 3 5 4 9]]
vm  [ 0.4  2.3  4.2 -1.6 -1.2 -0.1 -0.4 -0.  -1.9 -1.5 -4.7 -0.2 -0.4  0.1  8.2 -0.1 -0.4  1.1  1.2  0.3 -0.8 -0.1  1.2  0.7 -1.3  0.2 -0.  -0.7 -0.5  5.9 -0.6 -0.1  0.  -0.8 -0.2  0.8  2.2 -0.4 -1.3 -0.4 -0.6 -2.5  3.4  0.6 -0.1 -0.3 -0.8  0.5  4.5  6.1 -0.6 -0.1 -0.5  1.8 -0.9 -0.7 -0.4 -1.9 -1.7  3.7  1.  -0.2 -0.7 -0.1 -0.5 -0.9 -0.1 -0.4  1.9 -0.2  0.1  1.   1.7  0.5 -3.  -0.2 -0.4 -0.9 -0.2 -0.6 -4.4 -0.6  0.2 -0.4 -1.7 -2.5  5.3 -0.3 -0.1 -0.5 -0.3 -0.2 -0.5  4.1 -0.3 -0.2 -0.8 -2.2 -0.5 -0.4  5.8  2.8 -0.6 -0.2 -0.2 -0.3 -1.5 -0.8 -1.4 -0.2 -0.7 -0.6 -0.  -0.  -1.3  3.2 -0.4 -1.1 -0.1 -0.1 -0.2  0.2 -0.3 -0.4 -0.3 10.1 -0.5  0.3 -1.8  6.8  1.8 -0.3  0.3 -0.1 -1.8 -2.8 -0.2 -0.4 -0.5  1.9  0.  -0.9 -0.2  0.2  0.   0.2 -0.2 -0.1 -2.5  0.2 -0.  -0.1  3.7 -0.1 -0.2 -0.   0.6  0.9 -0.4 -0.5 -0.6 -0.1 -0.2 -0.2 -0.6 -0.5  0.8 -0.2  0.1 -0.1 -0.1 -0.1 -0.5 -0.3 -0.4  4.2 -0.8 -0.3  3.4 -0.1  0.7 -0.5 -0.2 -1.5 -0.3 -0.1  1.2 -0.5 -0.1 -1.6 -0.3 -0.4 -0.2 -1.2  1.4  6.5 -0.5  2.  -0.1  0.1 -0.3 -0.2 -0.7 -0.2 -0.5 -2.6 -0.3 -0.5 10.7 -0.8 -0.3 -0.5 -0.8 -0.6 -0.2 -0.8 -0.1 -0.2  0.4  0.1 -0.2  0.2 -0.2 -1.  -0.6  2.1 -1.1 -0.7 -0.3  1.3 -0.6 -0.1 -0.   5.5  0.8 -0.6 -0.2 -0.6 -0.1  4.2 -0.   1.3 -0.1 -0.1 13.6 -0.  -0.5  0.3 -0.4 -0.4 10.6 -0.  -0.8 -0.2  5.4 -1.2]
vy_50sample [[8 7 3 4 6 0 2 9 1 5]
 [2 9 8 0 5 3 4 6 7 1]
 [7 2 2 8 4 0 3 5 6 1]
 [7 8 1 0 0 2 4 5 6 6]
 [5 1 0 9 2 7 4 8 6 3]
 [0 8 6 1 5 7 2 9 3 4]
 [2 7 3 5 0 6 8 4 9 1]
 [8 5 1 4 0 6 7 3 2 9]
 [3 2 7 8 5 4 6 0 0 9]
 [4 9 0 5 8 6 3 7 1 2]]
vt_50sample [[8 7 3 4 6 0 2 9 1 5]
 [2 9 8 5 0 3 4 6 7 1]
 [7 9 2 8 4 0 3 5 6 1]
 [7 1 8 0 3 2 4 5 9 6]
 [5 1 0 9 2 7 4 8 6 3]
 [0 8 6 1 5 7 2 9 3 4]
 [2 7 3 5 0 6 8 4 9 1]
 [8 5 1 4 0 6 7 3 2 9]
 [3 2 7 8 5 4 6 0 1 9]
 [4 9 0 5 8 6 3 7 1 2]]
Epoch 32110: Training cost= 0.2573, Training acc= 0.8418, Validation cost= 0.2634, Validation acc= 0.8419
Epoch 32120: Training cost= 0.2619, Training acc= 0.8418, Validation cost= 0.2697, Validation acc= 0.8419
Epoch 32130: Training cost= 0.2818, Training acc= 0.8418, Validation cost= 0.2113, Validation acc= 0.8419
Epoch 32140: Training cost= 0.2325, Training acc= 0.8418, Validation cost= 0.2446, Validation acc= 0.8419
Epoch 32150: Training cost= 0.2682, Training acc= 0.8418, Validation cost= 0.2940, Validation acc= 0.8419
Epoch 32160: Training cost= 0.2639, Training acc= 0.8419, Validation cost= 0.2303, Validation acc= 0.8420
Epoch 32170: Training cost= 0.2848, Training acc= 0.8419, Validation cost= 0.3135, Validation acc= 0.8420
Epoch 32180: Training cost= 0.2443, Training acc= 0.8419, Validation cost= 0.3273, Validation acc= 0.8420
Epoch 32190: Training cost= 0.2449, Training acc= 0.8419, Validation cost= 0.3122, Validation acc= 0.8420
Epoch 32200: Training cost= 0.2644, Training acc= 0.8419, Validation cost= 0.2939, Validation acc= 0.8420
tm  [-0.9 -0.3  1.8 -3.6 -2.1 -0.5 -0.4 -0.2 -0.5 -0.1 -3.8 -0.  -0.6 -0.2 11.3 -0.8  0.7  0.6 -0.3 -0.3 -0.6 -0.3  1.8 -0.1 -1.1  1.5 -0.7  0.  -0.4  3.6  1.7 -0.4 -0.5  6.9 -0.3 -0.4  0.2 -0.4  0.7 -0.4 -0.6  3.3  0.1  3.5 -0.4 -0.3 -1.  -0.1 -0.  10.  -0.4 -0.2 -0.5 -0.2 -1.1 -1.2 -0.5 -1.8 -0.  -0.8  2.5 -0.  -0.2 -0.4 -0.8 -0.6 -0.1 -0.2 -0.1 -0.3 -0.1 -0.4  1.4  1.3 -4.8  1.  -0.  -0.2 -0.1 -0.5 -2.5 -0.6 -0.  -0.5 -0.8  4.   2.9 -0.1 -0.2 -0.5 -0.5 -0.4 -0.  -0.4 -0.3 -0.3 -0.2 -2.4 -0.6 -0.3 -0.1  8.5 -0.3 -0.1 -0.2 -0.  -1.8  2.2 -1.  -0.3  0.7 -0.2 -0.3 -0.4  1.2  1.4 -0.2 -0.1 -0.  -0.2 -0.4 -0.2 -0.1 -0.  -0.2 13.6 -0.   3.3 -0.3 -0.5 -0.2 -0.1 -0.5 -0.  -4.5 -2.2 -0.3 -0.3 -0.3 -0.1  1.8 -1.   1.5 -0.1 -0.3  0.2 -0.1 -0.1 -2.  -0.3  2.1 -0.2  1.4  0.9 -0.2 -0.  -0.2 -0.1  1.3 -0.4  0.7 -1.1  0.2 -0.2 -0.1 -0.4 -0.4  0.7 -0.2 -0.2 -0.1 -0.1 -0.3 -0.3 -0.5  3.5 -0.2 -0.1  0.7 -0.2 -0.2 -0.  -0.4 -1.4 -0.6 -0.6 -0.1 -0.4  0.1 -0.9 -0.2 -0.3 -0.3 -0.9 -0.3  1.  -0.6 -0.8 -0.1 -0.1 -0.  -0.4 -0.4 -0.1 -0.  -1.7  0.2 -0.1  5.  -0.5 -0.1 -0.  -0.5  3.1  0.4  0.2 -1.3 -0.5 -0.4 -0.6 -0.  -0.3 -0.5 -0.7  3.2  1.3 -1.9 -0.5 -0.1 -0.1 -0.8  0.7 -0.1  2.7 -0.3 -0.   0.1 -1.3  0.9 -0.  -0.2 -0.1 -0.1 -0.4  8.6 -0.2 -0.4 -0.4 -0.8 -0.4  6.1 -0.   0.7 -0.2 -0.1  4.1]
ty_50sample [[7 4 8 1 0 5 9 9 2 3]
 [3 0 7 9 8 2 1 6 4 5]
 [0 0 3 1 6 9 5 8 7 2]
 [0 5 7 9 3 6 8 2 4 1]
 [3 0 2 5 4 6 7 8 8 9]
 [5 8 8 3 0 9 4 7 6 1]
 [1 1 2 4 0 8 7 3 9 6]
 [7 9 8 2 3 4 4 6 0 5]
 [9 1 1 7 5 2 0 8 4 3]
 [8 2 1 7 6 5 3 0 9 9]]
tt_50sample [[7 4 8 1 0 5 6 9 2 3]
 [3 0 7 9 8 2 1 4 6 5]
 [0 4 3 1 9 6 5 8 7 2]
 [0 5 7 9 3 6 8 2 4 1]
 [3 0 2 5 4 6 7 1 8 9]
 [5 8 2 3 0 9 4 7 6 1]
 [5 1 2 4 0 8 7 3 9 6]
 [7 9 8 2 3 4 1 6 0 5]
 [9 6 1 7 5 2 0 8 4 3]
 [8 2 1 7 6 5 3 0 4 9]]
vm  [-0.3  2.  -1.5 -3.3 -0.9  0.7 -0.2 -0.  -0.8 -1.2  4.8 -0.3 -0.   0.1  5.1  6.5 -0.2 -0.3 -0.1  3.9 -1.1 -0.1 -0.2  0.7 -1.4  1.4 -0.3  0.1  0.7 -0.8  0.4 -0.1  0.7 -2.4 -0.4 -0.2  1.9  2.3 -3.9 -0.5  0.2 -2.7 -0.2 -0.2 -0.1 -0.1 -2.8 -0.7  1.3 -1.1 -0.6 -0.  -0.  12.3 -1.1 -0.5 -0.5 -0.8  0.3  2.4  5.3 -0.1  0.   1.2  0.   0.8 -0.1 -0.1 -0.3 -0.2 -0.1 -1.1 -0.1 -0.3 -5.2 -0.  -0.7 -0.2 -0.5 -0.  -4.7 -0.4  1.   0.9 -0.6 -2.4  2.4 -0.2 -0.2 -0.2 -0.1 -0.   0.2  1.2 -0.2 -0.3 -0.4 -2.8  0.4 -0.2  5.7 -2.5 -0.4 -0.1 -0.1 -0.  -2.8  0.9  1.7  4.6 -0.1  0.3 -0.  -0.8 -0.6  8.1 -0.5 -0.5  0.1 -0.6 -0.4 -2.1 -0.3  1.  -0.4  6.3 -0.  -3.  -0.1 13.7  1.6 -1.   0.3 -0.6  9.2  3.7  0.2 -0.   1.2 -0.4 -0.8 -0.7 -1.1 -0.2  0.2  0.4 -0.5 -0.1  2.9  0.1  1.   0.3  2.2 -0.2 -0.2 -0.2 -0.3 -0.1 -0.7 -0.2 -0.4  0.4 -0.1 -0.2  0.6 -0.4  0.4  1.1  0.1  0.8  0.4  0.4 -0.1 -0.1 -0.1 -0.  -1.2 -0.6  6.9 -0.3  0.4 -0.2 -0.3 -1.9 -0.5 -0.4 -0.1 -0.4 -0.4  2.9 -0.  -0.2  0.4 -1.4 -1.5 -0.1 -1.4  1.1 -0.3 -0.1 -0.4 -0.3 -0.2 -0.9 -0.2 -4.1 -0.3 -0.3  5.2 -0.1  0.1  1.9 -1.1  1.3 -0.4 -0.7  1.8 -0.8 -0.7  0.9 -0.5  0.3 -0.  -1.1 -0.6  3.5  0.6  1.6 -0.4  2.5 -0.4  1.  -0.6  2.8 -0.3  3.7  0.3 -1.8  1.5 -2.1 -0.  -0.8 -0.2 -0.1 14.8  4.9 -0.1  0.1 -1.1 -0.2 11.9 -0.1 -2.4  0.4  2.8 -3.5]
vy_50sample [[3 2 6 8 8 1 5 0 0 9]
 [5 2 2 8 6 3 7 4 9 1]
 [4 1 7 5 0 6 2 8 3 9]
 [4 7 3 6 0 5 1 8 9 2]
 [0 1 2 5 4 7 3 9 6 6]
 [8 7 6 4 1 3 2 9 0 5]
 [3 9 4 2 1 0 8 7 5 6]
 [0 0 4 8 2 9 7 1 5 3]
 [4 6 7 8 2 2 1 5 0 3]
 [6 7 3 1 9 0 8 5 4 2]]
vt_50sample [[3 2 6 8 4 1 5 7 0 9]
 [5 2 0 6 8 3 7 4 9 1]
 [4 1 7 5 0 6 2 8 3 9]
 [4 7 6 3 0 5 1 8 9 2]
 [0 1 2 5 4 7 3 9 8 6]
 [8 7 6 4 1 3 2 9 0 5]
 [3 9 4 2 1 0 8 7 5 6]
 [0 6 4 8 2 9 7 1 5 3]
 [4 6 7 8 9 2 1 5 0 3]
 [6 7 3 1 9 0 8 5 4 2]]
Epoch 32210: Training cost= 0.2992, Training acc= 0.8419, Validation cost= 0.3058, Validation acc= 0.8420
Epoch 32220: Training cost= 0.3089, Training acc= 0.8419, Validation cost= 0.3207, Validation acc= 0.8420
Epoch 32230: Training cost= 0.3190, Training acc= 0.8420, Validation cost= 0.3291, Validation acc= 0.8421
Epoch 32240: Training cost= 0.2629, Training acc= 0.8420, Validation cost= 0.2569, Validation acc= 0.8421
Epoch 32250: Training cost= 0.2985, Training acc= 0.8420, Validation cost= 0.2743, Validation acc= 0.8421
Epoch 32260: Training cost= 0.2720, Training acc= 0.8420, Validation cost= 0.2284, Validation acc= 0.8421
Epoch 32270: Training cost= 0.2795, Training acc= 0.8420, Validation cost= 0.2310, Validation acc= 0.8421
Epoch 32280: Training cost= 0.2269, Training acc= 0.8420, Validation cost= 0.2860, Validation acc= 0.8421
Epoch 32290: Training cost= 0.2167, Training acc= 0.8421, Validation cost= 0.2521, Validation acc= 0.8422
Epoch 32300: Training cost= 0.2554, Training acc= 0.8421, Validation cost= 0.2608, Validation acc= 0.8422
tm  [-1.5  3.  -0.9  1.1 -0.8 -0.2 -0.2 -0.1 -1.2 -1.  -3.2 -0.1 -0.4 -0.1 -0.7  2.4  0.7  0.8 -0.2  1.7 -0.9 -0.6  0.9 -0.1 -1.1  1.4 -0.6 -0.1 -0.2  0.8 -1.8 -0.2 -0.1 -6.4 -0.3  0.   1.7 -0.8 -3.6 -0.5 -0.3  2.6  3.1 -1.2 -0.3 -0.1 -1.7 -0.2 -0.6  8.  -0.5  0.1 -0.8  5.4 -1.   0.4 -0.7  7.9 -1.5  6.7  6.2 -0.2 -0.4 -0.5 -1.2 -0.5 -0.5 -0.6 -0.  -0.5 -0.1 -0.  -0.1 -0.  -4.4 -0.5  0.6 -0.2 -0.4 -0.1 -5.1 -0.5 -0.5  0.1 -0.4  3.4 -1.2 -0.2 -0.1 -0.3 -0.6  0.2 -0.3  3.5 -0.  -0.1  0.2 -2.3 -0.5 -0.   4.2 -1.4  0.3 -0.2  0.  -0.5 -2.  -1.4 -1.  -0.8 -0.5 -0.7 -0.2 -0.4 -1.2  4.3 -0.1 -1.2  0.  -0.4 -0.2  0.5 -0.6  0.4 -0.2 -0.7 -0.1 -0.9 -0.8  6.4 -0.3 -0.3 -0.3  0.1 15.  -0.4 -0.  -0.2 -0.7 -0.2  0.3 -0.5 -0.3 -0.2 -0.1 -0.  -0.4 -0.1  7.3 -0.3 -0.2 -0.2  1.9  0.  -0.1 -0.3 -0.1 -0.8 -1.2 -0.9 -0.4  2.  -0.4 -0.  -0.  -0.4  0.  -0.2 -0.7 -0.2 -0.2 -0.3 -0.2 -0.6 -0.1 -1.7 -1.1 -0.3  5.8 -0.3 -1.7 -0.1 -0.  -1.2 -0.5  0.7 -0.9  1.6 -0.2  0.1 -0.2 -0.4  0.2 -0.9 -1.8  3.5 -0.8  3.2 -0.2 -0.3 -0.3 -0.5  0.7 -0.2  0.2 -2.9  0.4 -0.2  3.8 -0.2 -0.5 -0.3 -0.4  5.5  0.6 -0.1  5.7 -0.5 -0.3 -0.1  0.1 -0.  -0.7 -0.8  3.2  2.1 -0.8 -0.5 -0.9 -0.5  0.4  1.6 -0.5  2.2 -0.1  1.4 -0.5 -1.2  0.1 -3.5 -0.1 -1.4 -0.1 -0.4 16.2  2.6 -0.2  0.3 -0.7 -0.5 13.4 -0.1 -2.3 -0.2  2.2 -1.1]
ty_50sample [[8 6 5 1 3 2 0 4 4 7]
 [8 9 9 5 5 1 6 4 2 0]
 [4 1 9 3 0 6 7 2 5 8]
 [8 6 7 2 3 5 4 1 0 9]
 [0 5 7 1 9 2 2 3 8 4]
 [0 9 2 4 1 6 7 8 5 3]
 [3 9 2 5 1 8 0 7 4 6]
 [0 9 1 2 3 8 7 6 5 4]
 [1 1 7 3 9 5 5 6 8 4]
 [8 5 6 9 3 4 7 0 2 1]]
tt_50sample [[8 6 5 1 3 2 0 4 9 7]
 [3 8 9 7 5 1 6 4 2 0]
 [4 1 9 3 0 6 7 2 5 8]
 [8 6 7 2 3 5 4 1 0 9]
 [0 5 7 1 9 6 2 3 8 4]
 [0 9 2 4 1 6 7 8 5 3]
 [3 9 2 1 5 8 0 7 4 6]
 [0 9 1 2 8 3 7 6 5 4]
 [1 0 7 3 2 9 5 6 8 4]
 [8 5 6 9 3 4 7 0 2 1]]
vm  [-0.5 -1.   1.8  2.5 -1.1 -0.4 -0.4 -0.2  3.8  2.1 11.6 -0.6 -0.3 -0.2  1.2 -0.1 -0.1 -0.5 -0.1 -0.2 -1.1 -0.  -0.  -0.2 -1.1  2.4 -0.1 -0.1 -1.2 -4.   1.7 -0.8 -0.8  4.6 -0.2 -0.5 -0.6  3.8  0.6 -0.3 -0.5  5.4 -1.6 -0.3 -0.3 -0.2 -0.6 -0.8 -0.2 -0.1 -0.2 -0.1 -0.6  8.2  1.   0.1 -0.5  5.4 11.5 -0.4  3.8 -0.2 -0.2  1.8  2.2  0.6 -0.   1.1  1.2 -0.1 -0.4  2.9 -0.3 -0.3 -4.   0.  -1.  -0.4 -0.2  0.4  5.8  0.2 -0.1  1.7 -0.3  6.2 -0.9 -0.1 -0.4 -0.1  0.5 -0.4 -0.2 -2.6 -0.5 -0.2  0.1 -3.1 -0.6 -0.6 -0.6  3.8 -0.4  0.3  0.  -0.1 -1.9  1.4  1.1  0.   0.7  0.7 -0.1 -0.5  8.6 -1.7 -0.2  3.3 -0.3 -0.1 -0.4 -0.1 -0.1  0.5  0.5  1.  -0.2 -1.6 10.5 -0.1  0.2 -0.6 -0.2 -0.7  3.7  6.7 -0.4 -0.1 -0.1 -0.1 -0.9 -1.  -0.9 -0.3 -0.1 -0.2 -0.2 -0.   4.  -0.1 -0.6 -0.2 -0.7 -0.6 -0.1  0.4 -0.2 -0.3 -0.1  0.   2.  -0.8  0.4 -0.1 -0.2 -0.3 -0.6  2.1 -0.3 -0.2 -0.3 -0.2 -0.1 -0.2 -0.2 -0.8 -0.2 -0.4  1.5  0.  -0.9 -0.5 -0.3 -2.  -0.1 -0.5  0.3 -0.4 -0.  11.6  0.6 -0.2 -0.3 -0.5 -0.7 -3.3 -1.  -2.1 -0.  -0.  -0.1  0.  -0.1 -0.9 -0.  -2.6 -0.1 -0.3 -3.3 -0.2 -0.2 -1.  -0.8  0.5 -1.  -0.1  2.4 -0.9 -0.5 -0.4 -0.4 -0.3 -0.3 -1.2  4.6 -1.4  0.5  2.   1.3  3.4 -1.2 -0.3  0.3 -1.9  1.7 -0.   2.6 -1.   2.4 -2.3 -0.1 -1.  -0.  -0.4 -0.6  1.4  1.6 -0.2 -1.3 -0.3 -1.6  0.1  0.2 -0.1 -1.6  3.7]
vy_50sample [[0 2 5 1 6 9 7 4 3 8]
 [2 5 8 8 3 0 7 1 1 4]
 [4 6 5 3 7 0 0 1 2 8]
 [6 7 2 4 3 5 1 8 0 0]
 [5 1 1 4 0 6 3 7 9 9]
 [6 4 9 1 3 3 2 0 0 5]
 [2 9 8 5 0 3 6 7 4 1]
 [8 7 4 2 3 9 0 1 6 5]
 [6 9 2 8 1 5 7 0 3 4]
 [2 8 4 3 7 5 1 9 0 6]]
vt_50sample [[0 2 5 1 6 9 7 4 3 8]
 [2 5 8 9 3 0 7 6 1 4]
 [4 6 5 3 7 0 1 9 2 8]
 [6 7 2 4 3 5 1 8 0 9]
 [5 1 8 4 6 0 3 7 2 9]
 [6 4 9 1 8 3 2 0 7 5]
 [2 9 8 5 0 3 6 7 4 1]
 [8 7 4 2 3 9 0 1 6 5]
 [6 9 2 8 1 5 7 0 3 4]
 [2 4 8 7 3 5 1 9 0 6]]
Epoch 32310: Training cost= 0.2278, Training acc= 0.8421, Validation cost= 0.2600, Validation acc= 0.8422
Epoch 32320: Training cost= 0.2630, Training acc= 0.8421, Validation cost= 0.2368, Validation acc= 0.8422
Epoch 32330: Training cost= 0.3247, Training acc= 0.8421, Validation cost= 0.2787, Validation acc= 0.8422
Epoch 32340: Training cost= 0.2919, Training acc= 0.8421, Validation cost= 0.3252, Validation acc= 0.8422
Epoch 32350: Training cost= 0.3068, Training acc= 0.8422, Validation cost= 0.2917, Validation acc= 0.8423
Epoch 32360: Training cost= 0.2754, Training acc= 0.8422, Validation cost= 0.3126, Validation acc= 0.8423
Epoch 32370: Training cost= 0.2452, Training acc= 0.8422, Validation cost= 0.3180, Validation acc= 0.8423
Epoch 32380: Training cost= 0.3085, Training acc= 0.8422, Validation cost= 0.3013, Validation acc= 0.8423
Epoch 32390: Training cost= 0.3028, Training acc= 0.8422, Validation cost= 0.2647, Validation acc= 0.8423
Epoch 32400: Training cost= 0.3451, Training acc= 0.8422, Validation cost= 0.2821, Validation acc= 0.8423
tm  [-0.6  0.5 -3.8  2.4 -1.   0.1 -0.1 -0.  -0.8 -1.4  6.1  0.2  0.2 -0.4 -3.1  4.  -0.3 -0.4 -0.5 -0.4 -1.  -0.3 -0.5 -0.2 -1.1  3.  -0.2 -0.8 -1.  -0.8  4.2 -0.5 -0.2 -1.7 -0.2  0.9  5.3  3.4  7.6 -0.4  3.1  1.6  2.2  4.2  0.7 -0.   2.5 -0.3  4.1 -1.5 -0.5 -0.4  1.4 -0.8 -0.6  3.6 -0.2 -0.1 -0.3 -2.  -0.7 -0.9  1.2  0.9 -1.3  0.8 -0.1 -0.9 -0.4  1.3 -0.  -0.2 -0.2  0.6  1.4 -0.1 -0.6 -0.2 -0.   0.3 14.1 -0.1 -0.  -0.4 -0.6  3.9  5.  -0.5 -0.  -0.5 -0.1 -0.2 -0.2  0.9 -0.  -0.   0.1 -0.9 -0.3 -0.1  5.  -1.7 -0.4 -0.2 -0.2  0.1  0.9  3.7  1.2 -2.  -1.4 -0.4 -0.1 -0.3 -0.4  3.7  0.6 -1.1  0.4 -1.  -0.1  7.1 -0.2  0.8 -0.1 -3.8  0.4  5.   1.3 -0.7  0.  -0.1 -0.  -0.9  6.3  3.9 -0.2  0.1 -0.3 -0.3 -0.3 -0.6 -0.8 -0.1 -0.  -0.2 -0.2 -0.2  7.3 -0.  -0.3 -0.1 -0.3 -1.  -0.3 -0.2 -0.5  0.2  3.9 -0.1  1.2 -1.  -0.3 -0.  -0.1 -0.1 -0.1 -0.5  0.  -0.  -0.1 -0.1 -0.1 -0.3 -0.2 -1.8 -0.5  0.4 -0.4 -0.2 -1.6 -0.2 -0.4 -1.5 -0.2 -0.1  1.2  1.6 -0.5  1.8 -0.2 -0.3  0.3 -1.2  6.1 -0.4  3.6  1.1 -0.2 -0.  -0.2  0.2  0.2 -0.8 -0.3  3.2 -0.3 -0.3 -2.8 -0.1 -0.1  0.8 -0.5  1.4 -0.4 -0.8 -1.4 -0.5 -0.4 -0.2 -0.4 -0.  -0.2 -0.8 -0.8 -0.5  0.  -0.1 -0.4  1.4 -0.2 -1.6 -0.1 -1.4  1.7  6.7 -0.5  1.9  0.8  3.2 -0.2  1.3 -0.1  0.2 -2.8 -2.2 -0.7  1.3 -1.1 -0.4 -3.9 -0.1  4.7  1.  -0.1  5.2]
ty_50sample [[9 4 5 2 3 0 1 6 8 7]
 [5 5 0 0 1 7 9 4 6 3]
 [5 2 0 3 9 1 7 6 4 8]
 [6 0 3 2 8 5 7 4 9 1]
 [1 0 8 9 4 5 6 3 2 7]
 [3 0 4 7 2 9 1 8 5 6]
 [0 7 1 8 9 2 6 5 4 3]
 [9 2 8 6 5 4 1 0 3 7]
 [9 3 6 5 4 8 0 1 7 2]
 [7 8 2 1 9 9 5 4 3 6]]
tt_50sample [[9 4 5 2 3 1 0 6 8 7]
 [5 2 8 0 1 7 4 9 6 3]
 [5 2 0 3 9 1 7 6 4 8]
 [6 0 3 2 8 5 7 4 9 1]
 [1 0 8 9 4 5 3 6 2 7]
 [3 0 4 7 2 9 1 8 5 6]
 [0 7 1 8 9 2 6 5 3 4]
 [9 2 8 6 5 4 1 0 3 7]
 [9 3 6 5 4 0 8 1 7 2]
 [7 8 2 1 0 9 4 5 3 6]]
vm  [-1.3 -0.6 -4.5 -3.6 -1.2 -0.2 -0.2 -0.2 -0.4 -0.3 -1.1 -0.5 -0.3 -0.4 -1.  -1.9  0.8 -0.1 -0.4  3.4 -0.9 -0.4  2.5 -0.2 -1.2  4.9 -0.7 -0.1 -2.  -2.1  2.3 -0.4 -1.3 -4.1 -0.   0.3  3.1 -0.6 -1.5 -0.9 -0.5  2.  -0.1  2.1 -0.3 -0.1 -2.7 -0.2  0.5  4.3 -0.5 -0.2 -0.   3.6  1.3  0.7 -0.5 -1.   3.  -1.   4.7 -0.1  0.7 -0.  -1.3  1.1 -0.2 -0.7  0.4 -0.  -0.1  6.1  0.8  0.7 -4.7 -0.5 -0.1  0.2 -0.  -0.1 -2.1 -0.4 -0.  -0.8 -0.6  2.3  2.4 -0.3 -0.1 -0.3 -0.4 -0.3 -0.1 -0.3 -0.5 -0.1 -0.2 -2.7 -0.4  1.3 -0.1 -1.4 -0.3 -0.2 -0.2  1.8 -1.4  2.5 -0.3 -0.7 -0.6 -0.2 -0.1 -0.   4.5 -2.7 -0.3  0.4  0.3 -0.2 -0.1 -0.  -0.3  0.9 -0.3 -1.3 -0.2 -0.2  2.1  3.5  0.8 -0.1 -0.4 -0.1 11.1  1.  -0.3 -0.2 -0.5 -0.4  2.7 -1.9 -0.  -0.  -0.1 -0.3 -0.2 -0.   5.  -0.3  3.5 -0.1  1.   2.6 -0.1 -0.4 -0.  -0.3 -0.1 -0.3  0.2 -0.6  0.7 -0.2  0.4 -1.  -0.5 -0.1 -0.3 -0.1 -0.3 -0.4 -0.1 -0.3  0.2 -1.1 -0.1  0.1  3.5 -0.3 -1.   0.4 -0.4 -2.  -0.1  0.  -0.5  4.1  1.2  5.4 -0.3 -0.4  1.5 -0.9 -1.1 -0.2 -0.8 -0.9  0.1 -0.1  0.5 -0.1 -0.3 -0.5  0.2 -1.7 -0.4 -0.1  2.3 -0.1 -0.2 -2.  -0.5  3.9 -0.3 -0.3 -0.7 -0.7 -0.7  0.4  0.1 -0.5 -0.6 -1.4  3.3 -1.4 -1.6 -0.2 -0.7 -0.1 -0.4 -0.5 -0.2  1.5  5.7  7.1  0.4 -1.   3.1 -1.5 -0.4 -0.7 -0.  -0.1  8.1  1.8 -0.7  1.3 -1.  -0.6  4.6 -0.1 -0.9 -0.1  1.4 -0.4]
vy_50sample [[0 4 8 1 5 5 3 9 9 7]
 [9 1 6 8 0 5 3 4 2 7]
 [1 4 7 6 2 0 8 3 5 9]
 [3 8 0 9 5 2 4 1 7 6]
 [3 1 9 4 5 2 7 0 6 8]
 [5 6 1 8 4 9 2 7 3 0]
 [0 9 2 1 4 6 7 5 8 3]
 [9 7 8 3 1 4 4 0 6 2]
 [9 6 5 8 0 4 7 3 1 2]
 [6 8 3 1 7 0 5 4 9 2]]
vt_50sample [[0 4 8 6 1 5 3 2 9 7]
 [9 1 6 8 0 5 3 4 2 7]
 [1 4 7 6 2 0 8 3 5 9]
 [3 8 0 9 5 2 4 1 7 6]
 [3 1 9 4 5 2 7 0 6 8]
 [5 6 1 8 4 9 2 7 3 0]
 [0 9 2 1 4 6 7 8 5 3]
 [9 7 8 3 1 5 4 0 6 2]
 [9 6 5 8 0 4 7 3 1 2]
 [6 8 3 1 7 0 5 4 9 2]]
Epoch 32410: Training cost= 0.2229, Training acc= 0.8422, Validation cost= 0.3124, Validation acc= 0.8423
Epoch 32420: Training cost= 0.2370, Training acc= 0.8423, Validation cost= 0.3484, Validation acc= 0.8424
Epoch 32430: Training cost= 0.2364, Training acc= 0.8423, Validation cost= 0.3028, Validation acc= 0.8424
Epoch 32440: Training cost= 0.2959, Training acc= 0.8423, Validation cost= 0.2797, Validation acc= 0.8424
Epoch 32450: Training cost= 0.3293, Training acc= 0.8423, Validation cost= 0.2852, Validation acc= 0.8424
Epoch 32460: Training cost= 0.2513, Training acc= 0.8423, Validation cost= 0.2589, Validation acc= 0.8424
Epoch 32470: Training cost= 0.2696, Training acc= 0.8423, Validation cost= 0.2856, Validation acc= 0.8424
Epoch 32480: Training cost= 0.2493, Training acc= 0.8423, Validation cost= 0.2809, Validation acc= 0.8424
Epoch 32490: Training cost= 0.2948, Training acc= 0.8424, Validation cost= 0.2539, Validation acc= 0.8425
Epoch 32500: Training cost= 0.2433, Training acc= 0.8424, Validation cost= 0.2563, Validation acc= 0.8425
tm  [-1.5  0.3  7.   3.1 -1.8 -0.1 -0.1  0.  -0.9 -1.1 -6.  -0.3 -0.5 -0.1  6.9 -0.6  0.5  0.1  0.  -0.2 -0.6 -0.2  1.5 -0.  -1.3  1.  -0.2 -0.1 -0.1  2.9 -1.4 -0.3 -0.1 -0.3 -0.1 -0.4  1.3 -0.9 -0.2 -0.3 -0.4  2.9  2.3 -0.2 -0.3 -0.5 -0.2  0.  -1.1  9.1 -0.7  0.  -0.2 -1.  -1.3 -0.6 -0.5  5.6 -0.9  4.9  4.2 -0.3 -0.6 -0.7 -0.7 -0.5 -0.2 -0.3  1.  -0.3 -0.4 -0.5  0.9 -0.3 -2.7 -0.1  0.4 -0.1 -0.2  1.2 -3.3 -0.2 -0.1 -0.1  0.3  4.2 -1.4  0.1 -0.2 -0.4 -0.2 -0.4 -0.3  0.3 -0.5 -0.4  0.4 -1.8 -0.5 -0.3  3.   6.1 -0.1 -0.2  0.2 -0.1 -1.8 -1.1 -1.7 -0.6 -0.  -0.1 -0.3 -0.2 -0.4  4.3 -0.5 -0.8 -0.  -0.2 -0.4  1.5 -0.2 -0.1  0.2  8.4 -0.1  6.3 -0.7  0.3 -0.2 -0.5 -0.4 -0.1 -2.1 -2.4  0.5 -0.2 -0.5 -0.1  2.7 -0.6  1.9 -0.1 -0.1  0.3 -0.1 -0.  -0.5 -0.3 -0.3 -0.1  1.5  1.2 -0.3 -0.3 -0.2  0.3 -0.2 -0.4 -0.2 -0.3 -0.  -0.1 -0.4 -0.5 -0.1  0.  -0.4 -0.2 -0.  -0.1 -0.2 -0.3 -0.2  1.  -0.7 -0.1  1.3 -0.  -1.3 -0.3 -0.3 -1.7 -0.3 -0.2 -0.7 -0.5 -0.  -0.6 -0.2 -0.3 -0.2 -1.  -1.2  3.1 -0.5  0.6 -0.  -0.1 -0.2 -0.2 -0.2 -0.4  0.1 -1.6 -0.   0.3  4.3 -0.2 -0.6  1.7 -0.3  6.4 -0.3 -0.1  2.1 -0.3  0.1 -0.4 -0.1 -0.1 -0.5 -1.   1.5  2.9 -1.8 -0.3 -0.3 -0.4 -0.6  0.  -0.2  2.3 -0.4 -1.5 -0.2 -0.9  0.8 -1.3 -0.2 -0.6 -0.1 -0.3 10.6 -0.6 -0.4 -0.3 -0.6 -0.3  7.7 -0.1 -0.1 -0.3  4.2  1.7]
ty_50sample [[8 7 1 5 6 9 0 3 4 2]
 [8 5 3 2 1 9 7 0 4 6]
 [2 5 6 3 9 4 8 1 0 0]
 [3 1 8 4 0 6 2 7 9 5]
 [3 1 7 7 2 9 4 8 0 6]
 [7 3 8 5 2 4 0 9 6 1]
 [2 7 4 8 5 1 1 3 6 6]
 [0 6 8 4 3 1 7 2 5 9]
 [2 9 5 1 0 6 7 4 8 3]
 [2 9 7 5 1 0 3 6 8 4]]
tt_50sample [[8 7 1 5 6 9 0 3 4 2]
 [5 8 3 2 1 9 7 0 4 6]
 [2 5 6 3 9 4 8 1 0 7]
 [3 1 8 4 0 6 2 7 9 5]
 [3 1 5 7 2 9 4 8 0 6]
 [7 3 8 5 2 4 0 9 6 1]
 [2 7 4 8 5 1 0 9 3 6]
 [0 6 8 4 3 1 7 2 5 9]
 [2 9 5 1 0 6 7 4 8 3]
 [2 9 7 5 1 0 3 6 8 4]]
vm  [-0.9 -0.3 -4.4 -2.9 -0.6 -0.   0.1 -0.1 -0.5 -0.7 -1.4  0.1 -0.6  0.1 -1.6 -0.8 -0.4 -0.5 -0.5 -0.9 -1.  -0.4 -0.9 -0.3 -1.  -0.  -0.2  0.1 -0.6 -2.2  5.1 -0.4 -0.7 -2.2 -0.3 -0.3  0.9 -0.1  6.8 -0.6 -0.9 -0.9 -0.6  4.2 -0.4 -0.1  1.7 -0.1 -0.8 -2.7 -0.5 -0.1 -0.5 -1.  -1.4  2.  -0.3 -0.5  3.9 -2.   3.3 -0.8 -0.5 -0.7  1.5 -0.9 -0.3  1.2  0.4 -0.5 -0.3 -0.3 -0.4 -0.3 -3.1 -0.3 -0.2 -0.4 -0.1 -0.3  2.8 -0.1 -0.3 -0.1 -0.4 -0.5  3.6  0.4  0.4 -0.1 -0.2  0.2 -0.4 -0.  -0.7 -0.3 -0.7 -1.8  0.3 -0.5  3.1 -3.2 -0.1 -0.2 -0.2 -0.3 -2.5  3.6 -0.6 -1.2 -0.  -0.2 -0.4 -0.9  2.   1.3 -0.6  0.9  0.  -0.1 -0.2  3.7  0.9  0.2 -0.2 -1.8 -0.4  6.4  5.6  9.5  2.  -0.5  1.4 -0.   5.2 -1.2  0.  -0.1  0.9 -0.7  1.4 -0.2  0.2  0.1 -0.  -0.2 -0.5  0.   7.5 -0.2  1.4 -0.1 -0.6 -0.  -0.1 -0.1 -0.1 -0.   0.1 -0.4 -0.2 -1.3 -0.1 -0.3  0.6  0.  -0.1  2.2 -0.1 -0.2 -0.2  0.  -0.3  0.4 -0.3 -2.   0.5 -1.2 -0.6 -0.1 -1.8 -0.7 -0.4 -2.  -0.1 -0.2 -0.3  0.4 -0.1  6.6 -0.3 -0.2 -0.6 -1.4 -0.6 -1.2 -0.8 -0.3 -0.2 -0.  -0.3  0.1 -0.3 -0.8 -0.2 -2.7  0.2 -0.2 -2.6  0.3 -0.6 -0.2 -0.8  1.8  1.5 -0.  -1.8 -0.8 -0.1  0.2 -0.3 -0.3 -0.1 -1.4 -1.6 -0.  -2.  -0.5 -0.5  2.8 -1.6  1.9 -0.4 -1.5 -0.   7.9  1.3 -1.2  0.1 -2.6  0.2 -1.1 -0.3 -0.1  0.  -0.  -0.2 -0.6 -1.  -0.2 -1.1 -0.   3.9  0.   7.6 -2. ]
vy_50sample [[3 4 5 1 0 9 8 6 2 7]
 [1 9 9 5 5 6 3 8 2 0]
 [0 8 7 1 4 6 2 3 9 5]
 [0 6 1 7 5 3 2 9 4 8]
 [7 4 0 8 1 6 9 5 3 2]
 [6 4 0 8 9 7 1 2 3 5]
 [9 2 7 6 4 8 3 5 1 0]
 [6 5 9 3 7 2 1 8 4 0]
 [9 5 3 6 8 1 7 2 4 0]
 [1 6 7 5 2 8 0 4 9 3]]
vt_50sample [[4 3 5 1 0 9 8 6 2 7]
 [1 4 9 5 7 6 8 3 2 0]
 [0 8 7 1 4 6 2 3 9 5]
 [0 6 1 7 5 3 2 9 4 8]
 [7 4 0 8 6 1 9 5 3 2]
 [6 4 0 8 9 7 1 2 3 5]
 [9 2 7 6 4 8 3 5 1 0]
 [6 5 9 3 7 2 1 8 4 0]
 [9 5 3 6 8 1 7 2 4 0]
 [1 6 7 5 2 8 0 4 9 3]]
Epoch 32510: Training cost= 0.2930, Training acc= 0.8424, Validation cost= 0.2406, Validation acc= 0.8425
Epoch 32520: Training cost= 0.2570, Training acc= 0.8424, Validation cost= 0.3181, Validation acc= 0.8425
Epoch 32530: Training cost= 0.2396, Training acc= 0.8424, Validation cost= 0.3093, Validation acc= 0.8425
Epoch 32540: Training cost= 0.2615, Training acc= 0.8424, Validation cost= 0.2688, Validation acc= 0.8425
Epoch 32550: Training cost= 0.2240, Training acc= 0.8424, Validation cost= 0.2322, Validation acc= 0.8426
Epoch 32560: Training cost= 0.2250, Training acc= 0.8425, Validation cost= 0.3148, Validation acc= 0.8426
Epoch 32570: Training cost= 0.2613, Training acc= 0.8425, Validation cost= 0.2797, Validation acc= 0.8426
Epoch 32580: Training cost= 0.3174, Training acc= 0.8425, Validation cost= 0.3047, Validation acc= 0.8426
Epoch 32590: Training cost= 0.3533, Training acc= 0.8425, Validation cost= 0.3466, Validation acc= 0.8426
Epoch 32600: Training cost= 0.2734, Training acc= 0.8425, Validation cost= 0.3501, Validation acc= 0.8426
tm  [ 2.1 -0.3  3.9 -3.9 -1.7  0.4 -0.5 -0.2 -0.9 -0.6  4.2  0.7 -0.4 -0.3 14.5 -0.2 -0.2 -0.3  0.2  3.5 -1.1 -0.1 -0.9 -0.1 -1.3  1.7 -0.1 -0.3 -1.  -1.1  1.5 -0.2 -0.5  7.6 -0.1 -0.1  1.   3.6 -1.7 -0.6  0.5 -2.7 -0.2  2.2 -0.4 -0.2 -3.5 -0.2  5.6 -2.9 -0.7 -0.3 -0.  10.8 -0.5 -1.4 -0.8 -0.8  1.  -0.4  1.8 -0.3  0.4  0.3 -0.5 -0.3 -0.4 -0.5  0.2 -0.3 -0.   2.3 -0.1 -0.  -6.8 -0.2 -0.8 -0.5 -0.2 -0.2 -3.5 -0.4  0.4 -0.3 -1.7 -2.8  5.3 -0.3 -0.2 -0.5 -0.5 -0.1  0.3  2.2 -0.2 -0.1 -0.5 -3.  -0.3 -0.1  2.3 -0.4 -1.3 -0.2 -0.3  1.  -2.7  1.4  1.3  3.2 -0.3 -0.3 -0.2 -0.7  1.  -1.1  0.   1.2  0.3 -0.3 -0.1 -1.7 -0.2 -0.4 -0.2 17.  -0.2 -2.6  0.8 16.4  0.5 -0.5  0.1 -0.1 -4.3 -0.9 -0.2 -0.   0.2 -0.4 -0.3 -1.  -0.2  0.2 -0.  -0.1 -0.4 -0.3 -1.8  0.   2.2 -0.2  3.3 -0.1 -0.  -0.1 -0.2 -0.2  1.8 -0.7 -0.4 -2.   0.5 -0.1 -0.2 -0.3 -0.  -0.2  0.1 -0.3 -0.3 -0.1 -0.3 -0.1 -0.4  3.8 -0.4 -0.8  3.9 -0.3 -0.3 -0.2 -0.2 -1.6 -0.4  0.2  2.  -0.7 -0.3  2.8 -0.1  0.2  1.2 -1.3  0.8 -0.3 -1.5 -0.4 -0.2 -0.2 -0.  -0.1 -0.3 -0.5 -0.3 -3.6 -0.2 -0.   2.6 -0.5 -0.3 -1.2 -0.5 -1.3 -0.  -0.2 -1.  -0.7 -0.6  0.9 -0.3  0.3 -0.2 -0.8 -2.2 -0.5 -1.  -0.5 -0.   3.2 -0.1  1.1 -0.4  1.9 -0.  -0.8  0.3 -2.   0.5 -2.6 -0.2 -1.1 -0.4  0.3 12.1  6.2 -0.3  0.2 -0.7 -0.4  9.2 -0.2 -1.1 -0.1  4.6 -4.8]
ty_50sample [[3 7 0 2 2 8 5 6 1 9]
 [1 2 9 0 8 5 3 7 4 6]
 [3 6 6 4 1 2 9 8 5 0]
 [2 8 4 0 6 1 9 5 3 7]
 [6 2 5 0 4 9 9 1 3 8]
 [7 6 6 3 5 5 1 9 4 2]
 [1 5 9 4 0 2 7 3 6 8]
 [1 3 2 7 4 5 8 6 0 9]
 [7 1 2 0 9 3 8 5 4 6]
 [2 0 8 1 9 9 4 7 5 6]]
tt_50sample [[3 7 0 2 4 8 5 6 1 9]
 [1 9 2 0 8 5 3 7 4 6]
 [3 6 7 4 1 9 2 8 5 0]
 [8 2 4 6 0 1 9 5 3 7]
 [6 2 5 4 0 9 7 1 3 8]
 [8 7 6 3 0 5 1 9 4 2]
 [5 1 9 4 0 2 7 3 6 8]
 [1 3 2 7 4 5 8 6 0 9]
 [7 1 2 0 9 3 8 5 4 6]
 [2 0 8 1 9 3 4 7 6 5]]
vm  [-1.1 -0.1  5.6 11.9 -0.9  0.2 -0.2 -0.1  0.8 -0.8  4.7 -0.3 -0.3 -0.  -0.1  5.6  0.1 -0.2 -0.1 -0.6 -1.  -0.2 -0.5 -0.4 -0.2 -0.1 -0.   0.   0.8 -2.3 -1.5 -0.4 -0.4 -1.2 -0.3 -0.3 -0.1  2.7  2.2 -0.3 -0.4 -3.8 -1.1 -1.2 -0.4  0.2  0.7 -0.5  1.3 -1.5 -0.3 -0.2  0.4  3.8 -1.1  0.8 -0.   1.7  4.1  6.4  0.6 -0.2 -0.2  1.  -0.7 -0.1 -0.1 -0.1 -0.2 -0.2  0.3 -1.1  0.4  1.6 -2.3 -0.1 -0.6 -0.2 -0.6 -0.1 -0.3 -0.6 -0.   0.2 -0.9 -3.7 -1.4 -0.1 -0.2 -0.  -0.3 -0.3  0.1 -0.6 -0.4 -0.2 -0.2 -2.1 -0.  -0.4  2.9 -2.  -0.2  0.  -0.3  1.2 -1.1 -1.2  1.  -1.7 -0.2  0.7 -0.3 -0.9  0.9  7.4 -0.6  0.6  0.4 -0.3 -0.2  5.   0.2 -0.  -0.3 -0.3  0.1 -0.6  4.2  7.2  0.8 -0.9  0.1 -0.4  3.7 -0.5 -0.3 -0.1  1.4 -0.1 -1.1 -0.3 -1.2 -0.  -0.3  0.3 -0.4 -0.2 -0.9  0.3 -1.1 -0.   1.9 -0.5 -0.2 -0.1 -0.6  0.8 -0.1 -0.2 -0.4 -0.5 -0.2 -0.1 -0.2  1.3  0.1  2.7  0.4 -0.2 -0.2 -0.2 -0.2 -0.2 -0.4  2.3 -0.1 -0.5  0.2 -0.   1.3  0.6 -0.6 -1.3 -0.2 -0.1  0.5 -0.7 -0.3  7.4 -0.1  0.7 -0.3 -0.6  2.  -1.4 -0.1 -0.6 -0.2 -0.1 -0.1 -0.1 -0.1 -0.6 -0.1 -1.2 -0.3  0.8  8.1  0.3 -0.3  4.6 -0.8  0.5 -0.3 -0.3  5.4 -0.8 -0.7 -0.1 -0.4  0.3 -0.2 -1.  -1.   3.9 -0.1  1.  -0.4  3.4 -0.5 -0.4 -0.3  4.  -0.6 -0.8 -0.2 -0.3  1.3 12.  -0.   4.4 -0.  -0.2  3.1 -0.6 -0.4  0.1 -1.2 -0.2 -0.  -0.   1.2 -0.1  2.2 -1.5]
vy_50sample [[3 2 8 9 6 1 7 0 5 4]
 [0 8 9 3 7 5 4 6 1 2]
 [0 1 2 4 6 9 7 5 3 8]
 [2 3 1 4 9 5 0 6 8 8]
 [3 7 5 8 4 0 9 1 2 6]
 [7 8 1 2 0 6 5 9 9 3]
 [3 8 4 7 1 0 9 6 2 5]
 [8 3 0 9 7 6 5 2 4 1]
 [9 2 4 8 1 5 0 3 7 6]
 [2 4 1 7 6 9 0 3 8 5]]
vt_50sample [[3 2 8 9 6 1 7 0 5 4]
 [0 8 9 3 7 5 4 6 1 2]
 [0 1 2 4 6 9 7 5 3 8]
 [2 3 1 4 9 5 0 6 7 8]
 [3 7 5 8 4 0 9 1 2 6]
 [7 8 1 2 0 6 5 4 9 3]
 [3 8 4 7 1 0 9 2 6 5]
 [8 3 0 9 7 6 5 2 4 1]
 [9 2 4 8 1 5 0 3 7 6]
 [4 2 1 7 6 9 0 3 8 5]]
Epoch 32610: Training cost= 0.2788, Training acc= 0.8425, Validation cost= 0.2567, Validation acc= 0.8426
Epoch 32620: Training cost= 0.2502, Training acc= 0.8426, Validation cost= 0.2816, Validation acc= 0.8427
Epoch 32630: Training cost= 0.2369, Training acc= 0.8426, Validation cost= 0.2598, Validation acc= 0.8427
Epoch 32640: Training cost= 0.2741, Training acc= 0.8426, Validation cost= 0.2574, Validation acc= 0.8427
Epoch 32650: Training cost= 0.2927, Training acc= 0.8426, Validation cost= 0.2388, Validation acc= 0.8427
Epoch 32660: Training cost= 0.2766, Training acc= 0.8426, Validation cost= 0.2668, Validation acc= 0.8427
Epoch 32670: Training cost= 0.2612, Training acc= 0.8426, Validation cost= 0.2795, Validation acc= 0.8427
Epoch 32680: Training cost= 0.3136, Training acc= 0.8427, Validation cost= 0.3472, Validation acc= 0.8428
Epoch 32690: Training cost= 0.2578, Training acc= 0.8427, Validation cost= 0.3159, Validation acc= 0.8428
Epoch 32700: Training cost= 0.2555, Training acc= 0.8427, Validation cost= 0.2635, Validation acc= 0.8428
tm  [ 1.6 -0.5 -1.6 -2.1 -1.7  0.2 -0.3  0.1 -0.  -0.7 -0.2 -0.  -0.6 -0.4  1.5 -0.7 -0.5 -0.3 -0.3 -0.2 -1.2 -0.1 -0.7 -0.1 -1.2  3.1 -0.3 -0.3 -0.6 -1.   4.5 -0.5 -0.4  5.6 -0.  -0.2 -0.  -0.5  0.9 -0.4 -0.2 -1.8 -0.5  2.6 -0.3 -0.  -0.2  0.   6.7 -2.1 -0.5  0.   0.6 -0.8 -0.7 -0.  -0.5 -2.1  3.7 -2.2 -0.5 -0.6  0.1 -0.1  1.2 -0.3 -0.1  0.5  2.2 -0.3 -0.2  0.9 -0.   0.9 -2.8  0.  -1.1 -0.3  0.6 -0.1  4.7 -0.1  0.4 -0.1 -1.7 -1.5  8.7 -0.2 -0.1 -0.7 -0.2 -0.1 -0.3 -0.9 -0.4 -0.1 -0.4 -2.4 -0.1 -0.4  2.1 -0.5 -1.4 -0.1 -0.2  0.5 -1.1  4.5 -0.1 -0.6 -0.4 -0.3 -0.  -0.7  3.7  0.2 -0.1  1.  -0.2 -0.2 -0.2  1.5 -0.2 -0.2 -0.3  2.  -0.2  5.3  3.2  4.7  2.9 -0.5 -0.1 -0.5 -0.4  4.8  0.2  0.1  0.6 -0.4  1.1 -0.8  1.2 -0.1 -0.2 -0.  -0.2 -0.1 -0.8 -0.1  0.4 -0.1  2.8 -0.   0.2  0.1  0.1 -0.5 -0.1 -0.3 -0.2 -1.   0.3 -0.  -0.3 -0.4 -0.   0.8 -0.1 -0.2 -0.2 -0.1 -0.4  0.2 -0.2  2.1 -1.  -0.1  1.3  0.1 -0.4 -0.4 -0.5 -2.1 -0.  -0.1  4.1 -0.2 -0.   3.  -0.1 -0.1 -0.4 -1.3  7.1 -1.2 -0.2 -0.8 -0.1 -0.2 -0.4 -0.2 -0.5 -0.5 -0.2 -1.3 -0.1 -0.1  0.6 -0.4 -0.4 -0.2 -1.  -1.2 -0.2 -0.3 -1.1 -0.8  0.1  0.6 -0.3  0.4 -0.5 -1.4 -0.7 -0.4 -2.1 -0.7  1.6  5.3 -0.5 -0.6 -0.1  0.7  0.3  2.7  0.8 -0.6  2.9  4.4  0.   1.6 -0.2 -0.1 -0.5 -1.  -0.1 -0.1 -1.3 -0.3 -1.5 -0.   0.8 -0.1  6.1 -0.8]
ty_50sample [[4 3 0 7 6 6 5 8 2 1]
 [0 2 1 6 4 4 7 8 9 3]
 [0 0 6 2 3 8 1 4 7 9]
 [1 3 4 5 7 9 0 6 8 2]
 [7 6 8 1 0 3 2 5 9 9]
 [2 6 8 4 3 1 1 9 9 5]
 [6 1 9 4 7 5 3 8 2 0]
 [8 5 0 2 3 7 9 1 4 6]
 [1 6 4 9 9 5 2 0 3 7]
 [8 0 9 3 1 4 7 5 2 6]]
tt_50sample [[4 3 0 7 9 6 5 8 2 1]
 [0 2 1 6 5 4 7 8 9 3]
 [0 6 5 2 3 8 1 4 7 9]
 [1 3 4 5 7 0 9 6 8 2]
 [7 6 8 1 0 3 2 5 9 4]
 [2 6 8 4 3 7 1 9 0 5]
 [6 1 9 4 7 5 3 8 2 0]
 [8 5 0 2 3 7 9 1 4 6]
 [1 6 4 8 9 5 2 0 3 7]
 [8 0 9 3 1 4 7 5 2 6]]
vm  [-1.9  1.5  4.5 -0.5 -1.4 -0.1 -0.1  0.2 -1.  -1.  -0.7  0.2 -0.5  0.5  5.8  5.4  0.7  0.6  1.5  1.  -0.9 -0.3  1.9 -0.2 -1.5  0.9 -0.3  0.1 -0.2 -0.6 -1.3 -0.  -0.6 -2.2 -0.3 -0.1  1.7  6.7  7.3 -0.5 -0.7 -0.9  1.5  2.2 -0.4  0.5 -1.6 -0.4 -1.5  6.5 -0.5  0.2 -0.4  8.4 -1.3 -0.4 -0.6  3.4 -0.6  5.7  7.9 -0.  -0.4 -0.3 -1.2 -0.7 -0.3 -0.5 -0.  -0.3 -0.  -0.6  2.5  1.  -3.9 -0.3  1.9 -0.6 -0.3 -0.1 -4.3 -0.8  0.5 -0.2  1.4 -0.4 -1.8 -0.1 -0.1  0.3 -0.4 -0.3  0.2  1.9 -0.4 -0.1 -0.2 -2.2 -0.4 -0.2  4.5  1.   1.5 -0.4 -0.  -0.6 -1.8 -1.  -0.1 -0.7 -0.4 -0.1  0.1 -0.5 -0.9  8.3  0.2 -1.   0.8 -0.2 -0.3  0.9 -0.5 -0.2  0.6  7.3 -0.1 -1.8 -0.2  6.  -0.9 -0.2 -0.2 -0.1 -4.3 -6.6 -0.1 -0.2 -0.2  1.  -0.6 -0.6 -0.7 -0.1 -0.1 -0.2 -0.3  0.  -0.4 -0.1 -0.2 -0.4 -0.   0.1 -0.3 -0.3 -0.4 -0.2  4.3 -0.1 -0.3 -2.  -0.  -0.1 -0.4 -0.1  0.5  1.  -0.2 -0.4 -0.1 -0.4 -0.1 -0.4 -0.2  1.5  3.6 -0.3 -0.7 -0.  -0.9  1.1 -0.4 -0.8 -0.4  0.  -1.4 -0.5 -0.2  2.4 -0.4 -0.2  0.4 -0.9 -2.5  1.6 -0.6  3.  -0.2 -0.  -0.1 -0.  -0.1 -0.3 -0.1 -2.3 -0.3  0.2  7.  -0.2 -0.5  2.1 -0.1  8.5  0.5 -0.1 -1.  -0.7 -0.  -0.2 -0.1 -0.1 -0.3 -1.1 -1.6  3.4  0.4  1.  -0.8 -0.7 -0.3  0.6 -0.4  3.4 -0.4 -0.6 -0.7 -1.  -0.  -0.9 -0.2 -0.4 -0.2 -0.4 14.2  2.2 -0.4  0.2 -0.5 -0.3 10.9 -0.1  4.8 -0.2 -0.2 -1. ]
vy_50sample [[8 1 2 7 3 5 4 9 0 6]
 [4 4 0 8 2 3 9 1 6 5]
 [3 5 2 6 9 7 4 1 1 8]
 [5 2 9 1 8 7 0 6 3 4]
 [7 9 1 2 8 5 4 6 3 0]
 [8 9 0 0 7 4 5 3 2 1]
 [7 2 8 9 0 3 3 5 1 6]
 [3 9 0 5 2 7 4 1 8 6]
 [2 0 5 8 6 4 7 9 3 1]
 [1 9 5 3 6 8 4 7 0 2]]
vt_50sample [[8 1 2 7 3 5 4 9 0 6]
 [7 4 0 8 2 3 9 1 6 5]
 [3 5 2 6 7 9 4 1 0 8]
 [5 2 9 1 8 7 0 6 3 4]
 [7 9 1 2 8 5 4 6 3 0]
 [8 9 6 0 7 4 5 3 2 1]
 [7 2 8 9 0 3 1 4 5 6]
 [3 9 0 5 2 7 4 1 8 6]
 [2 0 5 8 6 4 7 9 3 1]
 [1 9 5 3 6 8 4 7 0 2]]
Epoch 32710: Training cost= 0.2733, Training acc= 0.8427, Validation cost= 0.3247, Validation acc= 0.8428
Epoch 32720: Training cost= 0.2682, Training acc= 0.8427, Validation cost= 0.2653, Validation acc= 0.8428
Epoch 32730: Training cost= 0.2342, Training acc= 0.8427, Validation cost= 0.3010, Validation acc= 0.8428
Epoch 32740: Training cost= 0.3248, Training acc= 0.8427, Validation cost= 0.3118, Validation acc= 0.8428
Epoch 32750: Training cost= 0.2498, Training acc= 0.8428, Validation cost= 0.2173, Validation acc= 0.8429
Epoch 32760: Training cost= 0.2635, Training acc= 0.8428, Validation cost= 0.2469, Validation acc= 0.8429
Epoch 32770: Training cost= 0.2153, Training acc= 0.8428, Validation cost= 0.3250, Validation acc= 0.8429
Epoch 32780: Training cost= 0.2925, Training acc= 0.8428, Validation cost= 0.2694, Validation acc= 0.8429
Epoch 32790: Training cost= 0.2366, Training acc= 0.8428, Validation cost= 0.2238, Validation acc= 0.8429
Epoch 32800: Training cost= 0.2105, Training acc= 0.8428, Validation cost= 0.2330, Validation acc= 0.8429
tm  [-2.1 -0.1 -0.4  0.5 -1.1  0.1 -0.6  0.1  0.4 -1.4  4.2 -0.3 -0.  -0.2 -0.2  6.3 -0.4 -0.5  0.5  0.8 -1.1 -0.4  0.8  0.1 -1.4  2.2 -0.5  0.4  2.  -2.7 -0.5  0.  -0.2 -2.3 -0.2 -0.1  0.1  2.3 -0.9 -0.3  0.7 -1.3 -0.7 -0.3 -0.3  0.6 -1.9 -0.3 -0.9 -0.5 -0.6  0.2 -0.1  6.6 -1.   0.8 -0.6  3.8  4.3  3.8  6.6 -0.1 -0.2  1.2 -0.5  0.2 -0.4 -0.3  0.6 -0.5  0.4 -1.7  0.4  2.6 -3.3 -0.8 -0.2 -0.3 -0.2 -0.1 -1.7 -0.4  1.1 -0.2  1.9 -0.7 -1.9 -0.3 -0.  -0.1 -0.2 -0.  -0.2 -1.  -0.2  1.  -0.  -3.  -0.3  1.4  5.2 -1.9  1.5  0.4 -0.2  0.1 -1.3 -0.4  1.  -0.4 -0.8  0.1 -0.3 -1.   0.4 13.5 -0.2 -0.3 -0.2 -0.  -0.1  0.6  0.5  0.7 -0.3 -0.2  1.  -1.2  6.6  5.9 -0.6 -0.9 -0.5 -0.8  5.9  0.1  0.4 -0.2  1.  -0.4 -0.1 -0.4 -0.9 -0.3 -0.2  0.  -0.5 -0.1  3.5 -0.2 -0.2 -0.2 -0.3 -0.1  0.2 -0.  -0.2 -0.2  2.6  0.1 -0.5 -0.6 -0.1  0.1 -0.2 -0.4  0.3  3.   0.1 -0.1 -0.2 -0.3 -0.1 -0.3 -0.3 -0.6 -0.7 -0.3  2.9 -0.4 -1.1  1.  -0.6 -1.9 -0.3 -0.2 -0.9 -0.2 -0.   7.6 -0.3  0.  -0.1 -0.7 -1.8 -2.  -0.5  0.1  0.   0.3 -0.3 -0.3 -0.5 -0.8  0.2 -2.5 -0.2  0.2  1.4  0.4  0.   5.4 -0.8  6.9 -1.  -0.5  1.9 -0.6 -0.5 -0.1 -0.3 -0.1 -0.3 -1.1 -1.   4.6 -0.4  2.6 -0.4  1.4 -0.1 -0.6 -0.4  0.9 -0.3  1.1 -0.1 -0.3  3.4 -1.7 -0.1 -0.6 -0.   0.5  7.5  3.2 -0.2  1.4 -1.2  0.1  4.2 -0.2 -0.6 -0.3  2.3 -1.2]
ty_50sample [[1 3 2 8 5 6 4 9 7 0]
 [3 7 5 6 8 4 1 2 9 9]
 [7 5 9 0 3 8 4 2 1 6]
 [5 7 3 6 4 2 9 1 1 8]
 [3 8 9 7 2 1 6 5 0 4]
 [2 3 4 4 7 8 6 5 1 0]
 [0 8 6 1 5 7 2 2 3 3]
 [4 1 0 6 7 8 3 5 2 2]
 [2 3 3 1 6 8 5 7 0 4]
 [4 5 2 8 3 7 9 6 1 0]]
tt_50sample [[1 3 2 8 5 6 4 9 7 0]
 [3 7 5 6 8 4 1 2 0 9]
 [7 5 9 0 3 8 4 2 1 6]
 [5 7 3 6 2 4 9 0 1 8]
 [3 8 9 7 2 1 6 5 0 4]
 [2 3 9 4 7 8 6 5 1 0]
 [0 8 6 5 1 7 2 4 9 3]
 [4 1 0 6 7 8 3 5 9 2]
 [2 3 9 6 1 5 8 7 4 0]
 [4 5 2 8 3 7 9 6 1 0]]
vm  [ 1.1  0.4 -0.2 -1.3 -1.2 -0.2 -0.4 -0.  -0.7 -0.7 -0.2 -0.1 -0.2 -0.3  3.5  1.  -0.3 -0.4  0.5  1.7 -0.9 -0.3  0.3  0.2 -1.2  1.2 -0.1 -0.3 -1.  -1.8 -0.9 -0.3 -0.4 -3.1 -0.1  0.1  1.4  1.9 -2.5 -0.5  0.4  2.1  1.9 -0.3 -0.2  0.4 -2.7 -0.1  5.7  0.1 -0.9 -0.1 -0.5  9.3 -0.5 -0.6 -0.6  8.7  0.   4.8  1.1 -0.3 -0.2  0.7 -0.7 -0.1  0.1 -0.5  0.3 -0.1  0.5  1.9  0.1 -0.2 -5.3 -0.4 -0.6 -0.2 -0.2 -0.2 -4.4 -0.5  0.2  0.7 -1.6  2.4  2.9 -0.4  0.1 -0.5 -0.6  0.2 -0.2  2.  -0.5 -0.   1.2 -3.1 -0.1  0.4  3.1 -2.  -0.9 -0.1 -0.1  0.7 -2.3 -0.7 -0.2  1.4 -0.5 -0.2 -0.2 -0.6 -0.1 -0.1 -0.1 -0.1 -0.2 -0.2 -0.3 -0.7  0.4 -0.7 -0.5  4.1 -0.1 -2.1  3.1 11.1  1.2 -0.7 -0.4 -0.4  5.9 -0.9 -0.1 -0.1  0.2 -0.2 -0.5 -0.8 -0.5 -0.1  0.  -0.2 -0.1 -0.4  7.8  0.   0.  -0.3  4.5 -0.3 -0.3  0.4 -0.3 -0.2  0.7 -0.4 -0.4 -0.5 -0.1 -0.1 -0.1 -0.2 -0.1 -0.8  0.7 -0.2 -0.4 -0.1 -0.6 -0.5 -0.2 -1.8 -0.7 -0.5  4.8 -0.2 -2.4 -0.  -0.7 -1.9 -0.3  0.7  2.  -0.2 -0.2  5.  -0.3 -0.1 -0.  -0.9  2.  -0.9 -1.2 -0.3  0.  -0.1 -0.2 -0.2 -0.4 -0.2 -0.3 -3.9 -0.2 -0.2 -1.2 -0.5 -0.3 -1.  -0.4 -1.4 -0.4 -0.5  1.9 -0.6 -0.4 -0.6 -0.1  0.5 -0.  -0.9 -1.   1.  -0.4 -0.1 -0.5  4.2 -0.4  0.8 -0.4 -0.7  1.2  1.   0.9 -1.3  1.  -5.9 -0.1 -2.2  0.2  0.7 14.6  6.3  0.1 -0.2 -0.9 -0.1 11.5 -0.1 -1.6 -0.5  3.3 -2.8]
vy_50sample [[5 3 8 0 2 6 4 7 1 9]
 [1 2 3 9 0 5 4 8 6 7]
 [4 1 2 6 9 3 8 7 5 0]
 [2 9 3 5 4 1 0 7 6 8]
 [8 9 4 3 1 6 5 2 7 0]
 [6 4 7 7 8 2 5 9 1 1]
 [2 5 0 1 4 7 7 8 6 9]
 [6 2 9 0 7 5 8 3 4 1]
 [6 5 9 1 4 2 7 0 8 3]
 [6 8 9 4 7 3 0 2 1 5]]
vt_50sample [[5 3 8 0 2 6 4 7 1 9]
 [1 2 3 9 0 5 4 8 6 7]
 [4 1 2 6 9 3 8 7 5 0]
 [2 9 3 5 4 1 0 7 6 8]
 [8 9 4 3 1 6 5 2 7 0]
 [6 4 3 7 8 2 5 0 9 1]
 [2 5 0 1 4 3 7 8 6 9]
 [6 2 9 0 7 5 8 3 4 1]
 [6 5 9 1 4 2 0 7 8 3]
 [6 8 9 4 7 3 0 2 1 5]]
Epoch 32810: Training cost= 0.3281, Training acc= 0.8429, Validation cost= 0.2223, Validation acc= 0.8430
Epoch 32820: Training cost= 0.2562, Training acc= 0.8429, Validation cost= 0.2634, Validation acc= 0.8430
Epoch 32830: Training cost= 0.3699, Training acc= 0.8429, Validation cost= 0.2824, Validation acc= 0.8430
Epoch 32840: Training cost= 0.2851, Training acc= 0.8429, Validation cost= 0.2535, Validation acc= 0.8430
Epoch 32850: Training cost= 0.2688, Training acc= 0.8429, Validation cost= 0.2697, Validation acc= 0.8430
Epoch 32860: Training cost= 0.2753, Training acc= 0.8429, Validation cost= 0.2805, Validation acc= 0.8430
Epoch 32870: Training cost= 0.2213, Training acc= 0.8429, Validation cost= 0.3255, Validation acc= 0.8430
Epoch 32880: Training cost= 0.2918, Training acc= 0.8430, Validation cost= 0.2400, Validation acc= 0.8431
Epoch 32890: Training cost= 0.2578, Training acc= 0.8430, Validation cost= 0.2843, Validation acc= 0.8431
Epoch 32900: Training cost= 0.2879, Training acc= 0.8430, Validation cost= 0.2633, Validation acc= 0.8431
tm  [ 2.1  0.   4.9 -1.5 -1.2 -0.1 -0.4 -0.2 -0.6  0.   2.3 -0.1 -0.5 -0.3 10.6  3.2 -0.1 -0.3 -0.4 -0.4 -0.8  0.2  1.8 -0.4 -1.2 -0.3  0.1 -0.4  1.8  7.6  2.1 -0.4  1.4  9.5 -0.2 -0.4 -0.1 -1.5 -4.7 -0.6 -0.   3.6  2.4 -1.1 -0.3 -0.  -1.1 -0.   5.1  3.7 -0.5 -0.2 -0.1  2.5 -1.5 -1.  -0.6  2.2 -0.8 -0.7 -0.4 -0.5  1.   0.3  1.9 -0.6  0.1 -0.3  0.  -0.2 -0.2 -1.6 -0.5 -0.  -5.4 -0.5 -0.7 -0.1 -0.4 -0.2 -0.5  0.7 -0.1 -0.1 -2.1  4.   6.   0.3 -0.2 -0.8 -0.8 -0.1 -0.1  1.2 -0.1 -0.1  0.  -2.4 -0.4 -0.2  0.2  5.7 -1.  -0.1 -0.3 -0.4 -2.   1.3  0.8 -0.4  0.6 -0.2 -0.4 -1.1 -0.6  8.5 -0.3 -0.2 -0.1 -0.3 -0.3 -0.3 -0.2 -0.6 -0.3 12.9  0.4 -0.1 -0.6  1.9 -0.  -0.2 -0.3  0.   4.5 16.7 -0.1  0.5 -0.4 -1.  -0.3 -0.2  0.7 -0.5 -0.2 -0.5  0.2 -0.1 -0.5 -0.2  0.1 -0.1  3.1 -0.4 -0.2 -0.2 -0.6 -0.2 -1.9 -0.6 -0.4  1.2 -0.2 -0.3 -0.1  0.9 -0.6 -0.7 -0.1 -0.2 -0.1 -0.1 -0.3 -0.1 -0.1  0.8 -1.9 -0.1  7.3 -0.5 -1.6  0.1 -0.3 -0.9 -0.6 -0.5  3.4 -1.  -0.6 -2.  -0.2 -0.4 -0.2 -1.1  6.   0.4 -0.8 -0.1 -0.2 -0.2  0.6 -0.2  0.8 -0.1 -0.5 -2.   0.2 -0.3 -1.8 -0.  -0.5  3.8 -0.3 -1.7 -0.1 -0.2  3.8 -0.6 -0.5 -0.7 -0.2 -0.1 -0.  -0.7  3.4  3.3 -1.6 -0.8 -0.9  3.7  4.   2.4 -0.4 -1.  -1.7 -0.9 -0.4 -1.4  0.3 -2.7 -0.3 -1.1 -0.3 -0.1  3.5  1.2 -0.7 -0.4 -0.3  0.7  0.5 -0.  -3.1  0.7 -0.1  1.1]
ty_50sample [[6 7 5 4 8 2 3 9 0 1]
 [2 4 7 6 8 3 0 9 5 1]
 [0 0 1 9 6 3 3 7 5 5]
 [4 5 3 9 8 6 7 0 2 1]
 [3 5 2 6 0 9 7 4 1 8]
 [8 4 1 7 0 3 6 2 9 5]
 [7 6 5 4 2 9 0 8 3 1]
 [8 2 1 1 0 6 4 7 5 9]
 [2 2 9 9 3 5 1 6 4 7]
 [4 1 5 8 3 0 0 7 6 2]]
tt_50sample [[6 7 5 4 2 8 3 9 0 1]
 [2 4 7 6 8 3 0 9 5 1]
 [0 8 1 9 6 3 2 7 5 4]
 [4 5 3 9 8 6 7 0 2 1]
 [3 5 2 6 0 9 7 4 1 8]
 [8 4 1 7 0 3 6 2 9 5]
 [7 6 5 2 4 9 0 8 3 1]
 [8 2 1 3 0 6 4 7 5 9]
 [8 2 9 0 3 5 1 6 4 7]
 [4 1 5 8 3 0 9 7 6 2]]
vm  [-0.8 -0.2  4.5 10.8 -1.1 -0.2 -0.  -0.3  1.4 -0.9 10.2 -0.3 -0.1 -0.4 -0.9  7.  -0.3 -0.4  1.8 -0.8 -0.8 -0.2 -0.3 -0.5 -1.   3.4 -0.3 -0.2  1.3 -0.6  2.3 -0.8 -0.7  9.  -0.3 -0.3 -0.1  2.6  8.  -0.5 -0.6  1.7 -0.6 -0.6 -0.2 -0.1  5.6 -0.9  1.8 -0.4 -0.2 -0.2  1.9 -0.  -1.   2.3 -0.1  2.3  3.7 -0.7 -0.9  0.2 -0.5  1.   0.4  0.8 -0.2 -0.1  0.7  0.1 -0.4 -1.5  1.1  0.4  2.2  0.6 -0.8 -0.2 -0.   1.3 16.8 -0.3 -0.1  1.5 -0.3  4.5 -0.5 -0.1 -0.1 -0.4 -0.2 -0.2 -0.1 -1.8 -0.2  0.9  0.6 -1.7 -1.1 -0.7  3.   6.7 -0.6 -0.2 -0.1  0.7  2.   1.4  1.7 -1.4 -0.3 -0.1  0.3 -0.4 -0.1 10.8  0.4 -0.6 -0.2 -0.2 -0.2  5.6  0.4  1.5 -0.  -1.2  0.7  2.6  2.6 -2.1  0.3 -0.5  0.3 -1.1 -0.6  8.7 -0.3  0.  -0.4 -0.4 -0.7 -0.8 -0.3 -0.1 -0.1 -0.   0.5 -0.1 -0.9 -0.5 -0.7 -0.  -0.4 -0.2  0.7  0.2 -0.4 -0.6  0.3  0.5  1.6 -0.2 -0.  -0.  -0.2 -0.6 -0.4  2.5 -0.4  0.3 -0.5 -0.1 -0.1 -0.3 -0.2  1.7 -0.1  1.5 -0.7 -0.1 -0.2 -0.2 -0.4 -1.7 -0.2  0.3  1.7 -0.2 -0.1  1.9 -0.1 -0.1 -0.5 -0.7  7.1 -1.3  3.3 -0.2  0.4  0.  -0.  -0.  -0.4 -0.6 -0.1  3.7  0.8 -0.2 -1.4 -0.1 -0.2  5.  -0.9  2.9 -0.8 -0.   3.  -0.5  0.4 -0.3 -0.5 -0.3 -0.7 -0.8  4.3  0.8 -0.   1.8  2.2  2.4 -0.3 -1.7 -0.1 -0.6 -0.6 -0.9 -0.1  2.6  1.7 11.1 -0.1  4.5 -0.1 -0.1 -3.4 -2.8  0.7  0.8 -1.2 -0.7 -4.4 -0.1  4.7  0.2 -1.4  9.8]
vy_50sample [[9 2 7 6 1 5 4 3 0 8]
 [3 6 0 1 4 5 8 2 9 7]
 [3 6 1 2 7 7 5 4 4 0]
 [7 7 3 1 0 4 6 5 2 9]
 [5 9 3 7 0 2 4 6 8 1]
 [3 8 7 2 9 4 0 6 5 1]
 [5 1 4 6 8 9 7 0 2 3]
 [8 7 9 2 0 5 3 6 4 1]
 [3 2 5 8 0 4 1 6 7 9]
 [9 5 4 1 8 3 0 2 7 6]]
vt_50sample [[9 2 7 6 1 5 4 3 0 8]
 [3 6 0 1 4 5 8 2 9 7]
 [3 6 1 2 7 8 5 9 4 0]
 [8 7 3 1 0 4 6 5 2 9]
 [9 5 3 7 0 2 4 6 8 1]
 [3 8 7 2 9 0 4 6 5 1]
 [5 1 4 6 8 9 7 0 2 3]
 [8 7 9 2 0 5 3 6 4 1]
 [3 2 5 8 0 4 1 6 7 9]
 [5 9 4 1 8 3 0 2 7 6]]
Epoch 32910: Training cost= 0.2434, Training acc= 0.8430, Validation cost= 0.2933, Validation acc= 0.8431
Epoch 32920: Training cost= 0.3385, Training acc= 0.8430, Validation cost= 0.3196, Validation acc= 0.8431
Epoch 32930: Training cost= 0.2473, Training acc= 0.8430, Validation cost= 0.3173, Validation acc= 0.8431
Epoch 32940: Training cost= 0.2984, Training acc= 0.8430, Validation cost= 0.2893, Validation acc= 0.8431
Epoch 32950: Training cost= 0.2384, Training acc= 0.8431, Validation cost= 0.2856, Validation acc= 0.8432
Epoch 32960: Training cost= 0.2547, Training acc= 0.8431, Validation cost= 0.2405, Validation acc= 0.8432
Epoch 32970: Training cost= 0.2876, Training acc= 0.8431, Validation cost= 0.2898, Validation acc= 0.8432
Epoch 32980: Training cost= 0.2830, Training acc= 0.8431, Validation cost= 0.2563, Validation acc= 0.8432
Epoch 32990: Training cost= 0.2284, Training acc= 0.8431, Validation cost= 0.2311, Validation acc= 0.8432
Epoch 33000: Training cost= 0.2528, Training acc= 0.8431, Validation cost= 0.2590, Validation acc= 0.8432
tm  [-0.8 -0.6 -2.1 -4.9 -1.2 -0.4 -0.3 -0.1  2.1 -0.2  3.2  2.6 -0.8 -0.3  5.2  2.1 -0.1 -0.3 -0.1 -0.1 -1.1  0.2 -1.  -0.5 -0.8  0.2 -0.1  0.5  2.  -2.3  5.1 -0.6  0.4  4.8 -0.2 -0.1 -0.9  3.7  3.5 -0.8  1.3 -3.5 -1.4  5.1 -0.2 -0.4 -0.9 -0.3 -0.9 -3.5 -0.8 -0.3 -0.3  3.6 -1.8 -0.4 -0.9 -2.8  8.9 -2.1  7.6 -0.4  1.7 -0.7  0.4 -0.7  0.2  0.9  0.6 -0.2 -0.2 -1.4 -0.3 -0.5 -6.1  4.1 -0.3  1.  -0.5 -0.5 -0.5 -0.2  0.3 -0.3 -0.4 -3.2  1.4 -0.3 -0.1 -0.5 -1.4 -0.3 -0.3 -0.2 -0.8 -0.7  0.1 -2.9 -1.  -0.4  1.7 -1.7 -0.4 -0.  -0.  -0.5 -2.9  2.9  1.2 -0.1  0.1 -0.1 -0.1 -1.4  2.9  6.3  3.5  4.  -0.4  1.3 -0.  -0.7 -0.2 -0.4 -0.2  6.1 -0.3 -0.3  5.5 14.1 -0.9 -0.3 -0.4 -0.1 -3.3 -1.4 -0.2 -0.2 -0.2 -0.6 -0.5  1.   0.2 -0.2 -0.2 -0.1 -0.1 -0.2 -1.1 -0.1  3.2 -0.  -1.  -0.4 -0.2 -0.1 -0.3 -0.2  3.4 -0.6  0.7 -2.8 -0.1 -0.   0.4 -0.3 -0.6  2.1 -0.4 -0.5 -0.3 -0.3 -0.6 -0.7 -0.1  2.  -0.5 -1.2 -0.2 -0.1  1.2  0.2  0.1 -1.7 -0.3 -0.3 -0.4 -0.5 -0.3  7.1  0.2  0.3 -0.4 -1.  -2.7 -1.9 -1.7 -1.  -0.2 -0.2 -0.3 -0.1 -0.1  0.2 -0.6 -2.7  0.8 -0.   5.  -0.5 -0.4  1.7 -0.2  2.6  2.7  2.6 -2.6 -0.8  0.6 -0.1 -0.3 -0.3 -0.5 -1.3 -2.6  2.1 -2.  -1.   1.5  0.9 -0.8  4.4 -0.1  1.9 -1.6  3.  -0.1 -2.2 -0.8  5.1 -0.1  1.8  0.   0.2  3.   1.6 -0.2 -0.4 -1.  -0.2  0.5 -0.1  2.7 -0.   5.  -3.7]
ty_50sample [[3 4 1 7 2 8 9 0 5 6]
 [8 3 7 1 0 9 2 4 5 6]
 [0 3 7 1 2 8 6 5 4 9]
 [1 4 6 5 0 2 7 9 8 3]
 [8 4 9 9 1 6 2 7 3 5]
 [5 5 3 0 6 7 4 4 8 8]
 [0 9 5 7 3 2 2 1 6 4]
 [6 7 3 2 4 1 5 0 9 8]
 [6 3 5 8 4 2 9 7 7 1]
 [7 9 3 3 5 8 8 4 1 6]]
tt_50sample [[3 4 1 7 2 8 9 0 5 6]
 [8 3 7 1 0 9 2 4 5 6]
 [0 3 7 1 2 8 6 5 4 9]
 [1 4 6 5 0 2 7 9 8 3]
 [8 4 0 9 1 6 2 7 3 5]
 [5 1 3 6 0 7 4 2 9 8]
 [9 0 5 7 3 8 2 1 6 4]
 [6 7 3 2 4 1 5 0 9 8]
 [6 3 5 8 4 2 9 7 0 1]
 [7 9 3 5 2 8 0 4 1 6]]
vm  [-0.8 -0.7  5.4  0.2 -1.7 -0.3 -0.1 -0.   1.1 -0.2  1.8 -0.3 -0.1 -0.3  5.9 -0.  -0.3 -0.2  1.5  0.4 -1.1 -0.1  1.5 -0.4 -1.   3.3 -0.2  0.  -0.6 -1.8  0.7 -0.2 -0.7  5.5 -0.2 -0.4 -0.1  2.8  3.4 -0.5 -0.   7.4 -0.1  1.5 -0.2 -0.2 -1.3 -0.2  1.9  6.3 -0.7 -0.1 -0.1  3.  -0.1 -0.6 -0.6  6.4  5.4  2.3  3.9 -0.1  0.2  0.9 -0.4  0.4  0.3 -0.2  1.6  0.1  0.4  1.1  0.1  1.1 -3.8  0.3 -0.6 -0.4  0.  -0.1 -0.7 -0.4  0.5  0.4 -0.1  8.6 -0.5 -0.3 -0.5 -0.3 -0.2 -0.2 -0.2 -1.4 -0.3 -0.2  1.1 -3.1 -0.7 -0.3  1.4  7.2 -0.5 -0.1 -0.3 -0.1 -1.3  0.1  0.7 -0.2 -0.4 -0.1 -0.1 -0.9  4.1  0.2  0.1  1.1 -0.4 -0.1 -0.1  0.3  0.9  0.6 -0.2  7.5 -0.2 -0.   6.6 -0.3 -0.4 -0.8 -0.4 -0.9 -4.  -1.6  0.3 -0.2 -0.5 -0.3  0.7 -0.7  0.7  0.4 -0.1  0.4 -0.  -0.2  2.6 -0.  -0.  -0.1 -0.  -0.1 -0.2 -0.1 -0.2 -0.3  4.3 -0.3  1.1 -1.3 -0.1 -0.2 -0.3 -0.9 -0.2  0.5 -0.1 -0.1 -0.2 -0.2 -0.1 -0.5 -0.1 -0.2  0.  -0.4 -0.2  0.  -1.8 -0.3 -0.2 -1.5 -0.2 -0.1 -0.  -0.5 -0.1  5.6 -0.1  0.2 -0.4 -0.4 -0.8 -2.  -0.8 -1.   0.2 -0.1 -0.  -0.1 -0.1 -0.5 -0.2 -2.3 -0.2 -0.1 -2.6 -0.1  0.1 -0.2 -0.7  2.2 -1.  -0.3 -0.2 -0.7  1.6 -0.3 -0.2 -0.4  0.  -0.9  2.  -0.5 -1.1  0.3  0.9  2.6 -0.2 -0.4 -0.1 -1.6  1.9 -1.1  1.2 -0.5  3.6 -3.8  0.  -1.3 -0.1  0.2  4.3  1.  -0.1 -0.2 -1.   0.2  1.3 -0.2  2.4  0.2 -0.5  4.1]
vy_50sample [[5 7 0 1 2 8 4 9 6 3]
 [8 6 4 7 0 5 2 3 9 1]
 [2 9 0 5 1 6 3 8 4 7]
 [5 0 7 1 9 3 4 6 8 2]
 [1 3 9 6 0 4 8 5 2 7]
 [4 1 1 8 3 2 6 5 7 0]
 [6 7 3 1 2 4 5 8 8 0]
 [5 1 6 2 0 4 7 9 8 3]
 [4 6 3 8 1 2 9 7 7 5]
 [6 8 0 3 3 9 2 5 7 4]]
vt_50sample [[5 7 0 1 8 2 4 9 6 3]
 [8 6 4 7 0 2 5 3 9 1]
 [2 9 0 5 1 6 3 8 4 7]
 [5 0 7 1 9 3 4 6 8 2]
 [1 3 9 6 0 4 8 5 2 7]
 [4 9 1 8 3 2 6 7 5 0]
 [6 7 3 1 2 4 5 8 9 0]
 [5 1 6 2 0 4 9 7 8 3]
 [4 6 3 8 1 9 2 0 7 5]
 [6 8 0 3 1 9 2 5 7 4]]
Epoch 33010: Training cost= 0.2513, Training acc= 0.8432, Validation cost= 0.2277, Validation acc= 0.8433
Epoch 33020: Training cost= 0.2915, Training acc= 0.8432, Validation cost= 0.2556, Validation acc= 0.8433
Epoch 33030: Training cost= 0.2602, Training acc= 0.8432, Validation cost= 0.2788, Validation acc= 0.8433
Epoch 33040: Training cost= 0.2530, Training acc= 0.8432, Validation cost= 0.2577, Validation acc= 0.8433
Epoch 33050: Training cost= 0.2946, Training acc= 0.8432, Validation cost= 0.2666, Validation acc= 0.8433
Epoch 33060: Training cost= 0.2601, Training acc= 0.8432, Validation cost= 0.2971, Validation acc= 0.8433
Epoch 33070: Training cost= 0.3077, Training acc= 0.8432, Validation cost= 0.2577, Validation acc= 0.8434
Epoch 33080: Training cost= 0.2846, Training acc= 0.8433, Validation cost= 0.2886, Validation acc= 0.8434
Epoch 33090: Training cost= 0.2940, Training acc= 0.8433, Validation cost= 0.2310, Validation acc= 0.8434
Epoch 33100: Training cost= 0.2634, Training acc= 0.8433, Validation cost= 0.2969, Validation acc= 0.8434
tm  [-0.6  0.7  5.1  8.4 -1.3 -0.2 -0.1  0.3 -1.2 -0.5  7.2 -0.4 -0.4 -0.3  1.5  1.5  0.  -0.4  0.6 -0.9 -0.6 -0.1  1.2  0.  -1.   1.8 -0.1 -0.5 -1.2  1.1 -0.6 -0.  -0.5  3.1 -0.3 -0.1  4.7  2.6  0.7 -0.2 -0.1  8.6  3.8 -0.5 -0.3 -0.3  0.8 -0.4  2.7  9.8 -0.4  0.2 -0.   5.8 -0.4 -0.2 -0.6  8.  -1.4  3.7 -0.4 -0.1 -0.8 -0.1 -0.9  0.3  0.8 -0.4 -0.1  0.2 -0.1  3.7 -0.1  0.  -1.9 -0.2 -0.1 -0.7 -0.1 -0.   2.4 -0.3 -0.1 -0.7 -0.9  9.   0.  -0.  -0.2 -0.4 -0.3 -0.3 -0.2  1.4 -0.1 -0.2 -0.  -1.2 -0.1 -0.3  1.6  6.  -0.4 -0.1 -0.   2.1 -0.8 -0.3  1.4 -2.1 -0.5 -0.2 -0.1  0.3 -0.5 -1.1 -0.1 -1.2 -0.  -0.1 -0.1  6.6 -0.3 -0.1 -0.3  1.8 -0.1 -1.1 -0.9 -2.3  0.1 -0.3 -0.4 -0.4 -0.3  3.4 -0.1 -0.2 -0.3 -0.6 -0.9 -0.7 -0.4 -0.1 -0.3 -0.   0.1 -0.1  3.9  0.3 -0.5 -0.2  1.6 -0.4 -0.4 -0.2 -0.5 -0.2 -0.  -0.3 -0.6 -0.3 -0.  -0.1 -0.4  0.3  0.  -1.  -0.  -0.1 -0.2 -0.1 -0.2 -0.4 -0.  -0.7 -0.5 -0.4  1.  -0.  -2.2  0.3 -0.1 -1.  -0.1 -0.2  0.1 -0.6  0.  -0.3  0.1  0.3 -0.1 -0.8  4.7  3.7 -0.1  1.8 -0.3 -0.3 -0.  -0.1 -0.1 -0.2 -0.1 -0.7 -0.2  0.5 -2.7 -0.2  2.3 -1.2 -0.2 -0.3 -0.3 -0.4  2.9 -0.6 -0.2 -0.3 -0.1  0.4 -0.  -0.8  3.4 -0.6  1.3 -0.4  1.7  0.3 -0.3 -0.2 -0.4 -1.5  1.9 -1.3 -0.4 -0.2 -0.1 -2.2 -0.  -0.9 -0.2 -0.2  0.  -0.6 -0.6 -0.2 -0.6 -0.3 -0.8 -0.   0.3 -0.3 -1.9 10.9]
ty_50sample [[5 2 0 7 6 9 8 1 4 3]
 [5 8 3 9 6 7 7 0 4 2]
 [7 9 0 8 2 1 4 6 5 3]
 [0 9 5 2 4 6 7 3 8 1]
 [1 6 4 5 8 9 7 0 2 3]
 [9 4 8 3 0 1 7 2 6 5]
 [9 8 3 2 7 5 6 6 4 1]
 [5 9 4 2 8 7 1 6 0 0]
 [0 1 3 8 9 5 7 4 2 6]
 [5 4 0 3 2 1 7 6 9 9]]
tt_50sample [[5 2 0 7 6 9 8 1 4 3]
 [5 8 3 9 6 7 1 0 4 2]
 [7 9 0 8 1 2 4 6 5 3]
 [0 9 5 2 4 6 7 3 8 1]
 [1 6 4 5 8 9 7 2 0 3]
 [9 4 8 3 0 1 7 2 6 5]
 [9 8 3 2 7 5 6 4 0 1]
 [5 9 4 2 8 7 6 1 3 0]
 [1 0 3 9 8 5 7 4 2 6]
 [5 4 0 3 1 2 7 6 9 8]]
vm  [ 1.4 -0.2  4.1 -1.3 -1.3 -0.1 -0.3 -0.3 -0.2 -0.2 10.1  0.2 -0.4 -0.4  8.9  5.9  0.6 -0.5 -0.1  1.5 -0.9 -0.1 -0.  -0.3 -1.4  2.  -0.1 -0.3 -0.1 -0.6  1.2 -0.5 -0.5  7.2  0.  -0.3 -0.2  7.2  1.6 -0.4  0.8  2.4  1.1  2.4 -0.1  0.  -1.9 -0.5  7.7  0.9 -0.5 -0.1  0.3 13.9 -1.  -0.9 -0.7  2.3  2.5 -0.3 -0.3 -0.4  0.1  0.9 -0.1 -0.4 -0.3 -0.2 -0.2  0.3 -0.2 -0.7 -0.2  0.8 -5.5 -0.3 -0.9  1.2 -0.1 -0.1 -1.1 -0.  -0.1  0.3 -2.2  3.1  6.3 -0.2  0.4 -0.9 -0.5 -0.2 -0.  -0.2 -0.3  0.1  0.  -2.8 -0.5 -0.4  0.2  5.3 -1.4 -0.1 -0.2  1.9 -1.6  1.2  1.1 -0.2  0.2 -0.2 -0.4 -0.9 -0.2  5.7  1.6 -0.  -0.2 -0.1 -0.4 -0.3 -0.1 -0.6 -0.4 10.2 -0.2 -3.4  3.7  3.5  1.  -0.4 -0.5  0.2 -4.2 -1.  -0.4 -0.1 -0.4 -0.3 -1.  -0.6 -0.4 -0.2 -0.2 -0.3  0.5 -0.  -0.4 -0.2  0.6 -0.2  3.5 -0.5 -0.1  0.4 -0.6 -0.   3.4 -0.5 -0.2 -2.   0.7 -0.2 -0.5  0.2 -0.3 -0.8 -0.  -0.1 -0.5  0.1 -0.5 -0.1 -0.1  0.4 -0.3 -0.2  0.9 -0.1 -1.4 -0.1 -0.4 -1.4 -0.6  0.2  3.7 -0.5 -0.6  1.4 -0.4 -0.  -0.1 -0.8  5.6 -1.5 -0.5 -0.2 -0.  -0.2  0.5  0.1 -0.1 -0.1 -0.3 -1.9 -0.3 -0.3 -1.2 -0.4 -0.6  2.3 -0.3 -1.6 -0.1 -0.4 -0.8 -0.7 -0.7 -0.6 -0.2 -0.1 -0.2 -1.  -0.7  1.3  1.8 -0.4  0.3  4.5 -0.1  0.1 -0.3 -0.6 -1.  -0.7 -0.3 -1.2  0.  -2.3 -0.3 -0.8 -0.3 -0.   5.5  1.8 -0.2 -0.1 -0.6 -0.1  2.6  0.1  0.7 -0.2 -1.3 -0.4]
vy_50sample [[2 7 5 4 3 8 0 9 6 1]
 [3 9 8 5 7 2 4 6 0 1]
 [2 3 4 5 0 6 8 1 7 9]
 [2 7 9 5 6 4 3 0 8 1]
 [8 2 9 6 0 3 7 7 4 5]
 [9 2 3 7 8 1 6 4 0 5]
 [5 5 9 6 1 4 4 2 7 3]
 [7 5 3 1 4 8 2 2 9 6]
 [4 2 0 1 9 6 3 5 7 8]
 [0 1 5 3 8 4 7 9 2 6]]
vt_50sample [[2 7 5 4 3 8 0 6 9 1]
 [3 9 8 5 7 2 4 6 0 1]
 [2 3 4 0 5 6 8 1 7 9]
 [2 7 9 5 6 4 3 0 8 1]
 [8 2 9 6 0 3 7 1 4 5]
 [9 2 3 7 8 1 6 4 0 5]
 [5 9 6 8 0 1 4 2 7 3]
 [7 5 3 8 1 4 2 9 0 6]
 [4 2 0 1 9 6 3 5 7 8]
 [0 1 5 3 8 4 7 9 2 6]]
Epoch 33110: Training cost= 0.2806, Training acc= 0.8433, Validation cost= 0.3087, Validation acc= 0.8434
Epoch 33120: Training cost= 0.2694, Training acc= 0.8433, Validation cost= 0.2480, Validation acc= 0.8434
Epoch 33130: Training cost= 0.3042, Training acc= 0.8433, Validation cost= 0.2553, Validation acc= 0.8434
Epoch 33140: Training cost= 0.2145, Training acc= 0.8434, Validation cost= 0.2340, Validation acc= 0.8435
Epoch 33150: Training cost= 0.3109, Training acc= 0.8434, Validation cost= 0.2713, Validation acc= 0.8435
Epoch 33160: Training cost= 0.3872, Training acc= 0.8434, Validation cost= 0.2839, Validation acc= 0.8435
Epoch 33170: Training cost= 0.3202, Training acc= 0.8434, Validation cost= 0.3065, Validation acc= 0.8435
Epoch 33180: Training cost= 0.2610, Training acc= 0.8434, Validation cost= 0.2515, Validation acc= 0.8435
Epoch 33190: Training cost= 0.2943, Training acc= 0.8434, Validation cost= 0.2556, Validation acc= 0.8435
Epoch 33200: Training cost= 0.2586, Training acc= 0.8434, Validation cost= 0.2697, Validation acc= 0.8436
tm  [-1.4 -0.6 -3.9 -1.6 -0.4 -0.4 -0.  -0.3  1.8 -0.3 11.2 -0.7 -0.5 -0.1 -1.8  4.7 -0.2 -0.2 -0.7 -1.  -1.3 -0.2 -0.5 -0.3 -1.2 -0.3 -0.4  0.1 -0.1 -3.4  5.  -0.6 -0.4 -0.7 -0.1 -0.2 -0.1  7.4  8.9 -0.3 -0.2 -0.1 -1.3  3.7 -0.6 -0.5  2.4 -0.7 -1.7 -1.9 -0.5 -0.3 -0.5  8.  -1.9  1.7 -0.3 -0.7  8.  -2.2  4.4 -0.5 -0.2 -0.4  1.5 -0.8 -0.2  2.3 -0.4 -0.5 -0.5 -1.  -0.2 -0.3 -3.   0.3 -0.2  0.5 -0.4 -0.4  9.2 -0.1 -0.6 -0.2 -0.1  1.  -0.2  0.1 -0.4 -0.4 -0.3 -0.3 -0.3 -1.  -1.1 -0.6 -0.3 -2.1  0.1 -0.5  1.7 -2.1  0.6  0.1 -0.3 -0.3 -2.7  2.7  0.  -1.3  0.1 -0.1 -0.4 -0.9  2.5  5.6 -0.2  1.2  0.1 -0.1 -0.3  3.8  0.3 -0.4 -0.2 -2.1 -0.1 -1.6  8.7  3.5 -0.3 -0.8 -0.1 -0.   4.2 -0.2 -0.1 -0.5 -0.2 -0.3 -1.1  0.8 -1.1 -0.4 -0.3 -0.  -0.1 -0.1  5.6 -0.4  0.7  0.1 -1.6 -0.6 -0.  -0.3 -0.1  0.6  0.8 -0.3  0.7 -1.6 -0.3 -0.2 -0.1 -0.1 -0.3  2.8 -0.2 -0.4 -0.3 -0.3 -0.4 -0.  -0.2 -1.8  0.8 -0.9 -0.8 -0.1 -1.1 -0.6 -0.4 -1.9 -0.2 -0.8 -0.8  0.4 -0.1 10.  -0.1 -0.5 -0.5 -1.  -1.3 -2.3 -0.6 -0.8 -0.  -0.3 -0.3 -0.1 -0.1 -0.7  0.  -2.5  0.7  0.1 -2.5 -0.1 -0.9  1.5 -0.6  5.2 -0.   1.  -1.6 -0.9 -0.4 -0.  -0.3 -0.4 -0.2 -1.5 -0.8  1.2  1.6  1.5 -0.1  1.6 -1.5  0.7 -0.2 -1.4 -0.4  7.5  0.5 -1.3 -0.3 -0.4 -0.1 -0.3 -0.3 -0.5 -1.7 -0.3 -0.1 -0.5 -1.3 -0.2 -2.8 -0.1  5.4 -0.  -1.  -0.3]
ty_50sample [[2 1 4 3 5 9 0 8 6 7]
 [4 0 9 9 7 5 3 3 1 6]
 [7 9 3 1 5 4 6 0 8 2]
 [4 9 5 5 7 0 3 1 2 6]
 [1 4 6 7 8 3 2 2 9 9]
 [9 0 0 7 4 8 2 1 6 5]
 [4 6 5 7 0 3 1 9 8 2]
 [0 2 4 3 9 8 1 6 5 7]
 [7 8 3 9 1 2 4 5 6 0]
 [1 7 0 9 8 3 6 5 2 4]]
tt_50sample [[2 1 4 3 5 9 0 8 6 7]
 [4 0 9 2 7 5 3 8 1 6]
 [7 9 3 1 5 4 6 0 8 2]
 [4 9 8 5 7 0 3 1 2 6]
 [1 4 6 7 8 3 2 5 0 9]
 [9 0 3 7 4 2 8 1 6 5]
 [4 6 5 7 0 3 9 1 8 2]
 [0 2 4 3 9 8 1 6 5 7]
 [7 8 3 9 1 2 4 5 6 0]
 [1 0 7 9 8 6 3 5 2 4]]
vm  [-0.7 -0.4  1.7 -0.9 -1.8  0.6 -0.  -0.  -0.3 -1.4  7.6 -0.5  0.8 -0.6  5.  -0.1  0.1 -0.8  0.  -0.5 -1.2 -0.4 -0.1 -0.3 -0.7  1.6 -0.3 -0.5 -1.6  1.5  5.1 -0.2 -0.3 14.3 -0.2  1.   1.9  0.3 -0.1 -0.6  3.9  5.   3.4  4.7  0.3 -0.3 -0.5  1.   3.6 -0.6 -0.6 -0.4 -0.2  2.3 -0.  -0.4 -1.  -0.   1.2 -3.4  1.4 -0.3 -0.1  0.8 -1.5  0.8 -0.1 -0.9  1.7  0.4 -0.1  1.   1.2  2.2 -1.4 -0.2 -0.4  0.1 -0.1 -0.4 14.8 -0.5 -0.4 -0.2 -0.7  5.7  5.  -0.4 -0.4 -0.8 -0.7 -0.1 -0.2  0.4 -0.6 -0.3  1.3 -2.4 -0.2 -0.2  4.9  7.5 -0.  -0.2 -0.2 -0.6 -0.7  2.9  0.3 -1.8 -1.8 -0.3 -0.2 -0.3  0.9  2.   1.5 -0.6  0.1 -0.7 -0.4  6.6 -0.  -0.3 -0.6  6.  -0.4  0.6  3.1 -1.5  0.2 -0.7 -0.5 -0.5 -2.6 11.4 -0.2 -0.2 -0.8 -0.   1.4 -0.5  0.5  0.2 -0.3 -0.2  0.6 -0.3 -0.5  0.5  0.6 -0.4 -0.9  0.  -0.4 -0.2  0.6 -0.5  2.   0.9 -0.4 -0.2 -0.4 -0.1 -0.6 -0.3 -0.1 -0.7  0.6 -0.4 -0.1 -0.3 -0.3 -0.3 -0.1  1.6 -0.8 -0.3  1.4 -0.1 -1.8  1.  -0.7 -1.3 -0.1  0.9  1.  -0.6 -0.5 -0.8 -0.3  0.5 -0.1 -0.3  0.9 -1.1  0.1 -0.3 -0.1  0.1 -0.2  0.1 -0.5 -0.6 -0.1 -1.4 -0.3 -0.1 -4.  -0.3 -0.2 -0.1 -0.5 -0.1 -0.8 -1.1 -0.9 -0.8  0.4 -0.4 -0.2  0.8 -0.6 -0.9  1.  -0.9 -0.8 -1.  -1.   3.5 -0.3 -0.9 -0.1 -2.2  4.6  0.4 -0.3  0.1  2.9 -0.4 -0.2 -0.3 -0.1  0.2 -3.  -0.2 -0.2 -0.2 -0.9  0.5 -4.  -0.2 -0.1 -0.   0.2  8.3]
vy_50sample [[7 4 5 0 0 2 9 9 3 8]
 [6 3 4 0 5 2 1 9 9 8]
 [0 3 2 1 7 7 4 5 8 8]
 [6 6 8 8 2 7 3 0 4 5]
 [7 0 9 2 5 1 4 6 8 3]
 [5 8 9 6 4 0 1 2 7 3]
 [2 3 6 0 1 7 4 5 8 8]
 [7 2 1 3 4 8 0 0 5 9]
 [0 9 3 4 6 1 8 2 7 5]
 [4 6 5 1 0 8 7 2 3 9]]
vt_50sample [[7 4 5 0 2 6 1 9 3 8]
 [6 3 4 0 5 2 1 7 9 8]
 [0 3 2 1 7 9 4 5 8 6]
 [6 1 9 8 2 7 3 0 4 5]
 [7 0 9 2 5 1 4 6 8 3]
 [5 8 9 6 4 0 1 2 7 3]
 [2 3 6 0 1 7 4 5 9 8]
 [7 2 1 3 4 8 6 0 5 9]
 [0 9 3 4 6 1 8 2 7 5]
 [4 6 5 1 0 8 7 2 3 9]]
Epoch 33210: Training cost= 0.2542, Training acc= 0.8435, Validation cost= 0.2960, Validation acc= 0.8436
Epoch 33220: Training cost= 0.2680, Training acc= 0.8435, Validation cost= 0.2440, Validation acc= 0.8436
Epoch 33230: Training cost= 0.2270, Training acc= 0.8435, Validation cost= 0.2654, Validation acc= 0.8436
Epoch 33240: Training cost= 0.2669, Training acc= 0.8435, Validation cost= 0.2676, Validation acc= 0.8436
Epoch 33250: Training cost= 0.2568, Training acc= 0.8435, Validation cost= 0.2442, Validation acc= 0.8436
Epoch 33260: Training cost= 0.2770, Training acc= 0.8435, Validation cost= 0.2302, Validation acc= 0.8436
Epoch 33270: Training cost= 0.2329, Training acc= 0.8436, Validation cost= 0.2788, Validation acc= 0.8437
Epoch 33280: Training cost= 0.2661, Training acc= 0.8436, Validation cost= 0.2319, Validation acc= 0.8437
Epoch 33290: Training cost= 0.3573, Training acc= 0.8436, Validation cost= 0.2435, Validation acc= 0.8437
Epoch 33300: Training cost= 0.2588, Training acc= 0.8436, Validation cost= 0.2717, Validation acc= 0.8437
tm  [-1.2 -0.8 -1.5 10.9 -1.1  0.2 -0.3 -0.2 -0.5  1.2 -3.  -0.5  0.  -0.2 -3.3 -1.4 -0.4 -0.3 -0.  -1.8 -1.  -0.1  0.9 -0.2 -0.6  2.7 -0.2 -0.  -1.5 -1.9 -0.3 -0.4 -0.4 -3.9  0.1  0.4  3.6  3.2 19.2 -0.1  0.7  5.5 -0.3  2.8 -0.4 -0.3 11.4 -0.4 -1.4 11.9 -0.5 -0.1 -0.2 -2.7  1.8  4.3 -0.6  1.8  1.1  2.7 -0.  -0.1 -0.5 -0.  -1.1 -0.2 -0.3 -0.2  1.   0.  -0.2  4.5 -0.3 -0.6  4.8  0.5  0.3 -0.1 -0.3 -0.1  5.4 -0.3 -0.2 -0.2  2.7  6.2 -1.  -0.3 -0.1 -0.1  0.6 -0.1 -0.3 -0.7 -0.2 -0.2 -0.2  0.1 -0.2 -0.1 -0.3  3.3  0.5 -0.1 -0.4 -0.7  1.1 -0.3 -0.7 -2.4 -0.6 -0.2 -0.  -0.   3.8 -2.5  0.1 -0.9 -0.  -0.1  0.1  9.1  0.4 -0.3  0.5 -4.  -0.3 11.1  0.5 -3.5 -0.7  0.3  0.  -0.6 -0.9 -5.2  0.3  0.  -0.1 -0.1  1.  -1.  -0.2 -0.4  0.  -0.2 -0.2 -0.   4.6 -0.1 -0.8 -0.2 -0.  -0.  -0.2 -0.2  0.4 -0.5  3.7 -0.1  0.4 -1.9  0.3 -0.1 -0.1 -0.6 -0.2  0.1 -0.7 -0.2  0.4 -0.2 -0.1  0.5 -0.1 -0.8  1.1 -0.  -2.2 -0.1 -1.1 -0.2  1.  -0.9  0.3 -0.1 -1.  -0.1  0.4  5.2 -0.  -0.2 -0.6 -0.6  3.1  1.6  0.4 -0.6 -0.2  0.2 -0.2 -0.  -0.2 -0.3 -0.4  4.4 -0.3 -0.4  2.8 -0.2 -0.1 -2.  -0.1  4.7 -0.2 -0.1 -1.1 -0.8 -0.2 -0.3 -0.  -0.4 -0.3 -0.8  0.8 -1.  -0.9  0.4 -0.2 -0.7 -0.7 -0.7 -0.2  1.2  3.1  2.3  1.8  2.6  0.7  9.2 -0.1  3.3 -0.  -0.3 -0.9 -2.7  2.  -0.6 -0.9 -0.2 -1.6 -0.2 12.3 -0.  -0.5 14.9]
ty_50sample [[9 0 1 8 5 4 2 7 6 3]
 [6 0 2 9 4 5 1 8 7 3]
 [8 2 4 7 3 0 9 5 1 6]
 [8 5 6 1 7 2 9 4 0 3]
 [6 8 9 5 2 1 7 3 0 4]
 [9 4 8 5 0 2 1 7 3 6]
 [6 1 3 4 7 5 0 9 8 2]
 [4 5 8 3 1 7 0 9 2 6]
 [7 1 2 4 6 9 0 5 3 8]
 [0 1 4 4 3 2 7 9 5 6]]
tt_50sample [[9 0 1 8 5 4 2 7 6 3]
 [6 2 0 9 4 5 1 8 7 3]
 [8 2 4 7 3 0 9 5 1 6]
 [8 5 6 1 7 2 9 4 0 3]
 [6 8 5 9 2 1 7 3 0 4]
 [9 4 8 5 0 2 1 7 3 6]
 [6 1 3 4 7 5 0 9 8 2]
 [4 8 5 3 1 7 0 9 2 6]
 [7 1 2 4 6 9 0 3 5 8]
 [0 8 1 4 3 2 7 9 5 6]]
vm  [-1.3 -1.  -1.3  8.1 -1.  -0.2  0.3 -0.3  0.3  2.2  5.4  0.6 -0.6  0.2 -2.2 -1.4 -0.4 -0.1 -0.4 -0.9 -1.3 -0.1 -0.6 -0.5 -0.9  1.3  0.9 -0.5 -1.4 -4.4  2.3 -0.5 -0.5 -1.2 -0.1 -0.3  1.4  4.  10.4 -0.3  0.6  3.5 -0.5  1.3 -0.8 -0.2  4.3 -0.7 -1.3 -1.8 -0.3 -0.2 -0.3 -0.2 -0.2  2.6 -0.6  6.3  4.8 -0.1  4.2 -0.5  0.4 -0.5  1.9 -0.9 -0.4  1.8 -0.1 -0.2 -0.3  5.5 -0.5 -0.5 -3.6 -0.7 -0.3 -0.6 -0.2 -0.3  9.9  0.6 -0.4 -1.  -0.2  2.4 -1.1 -0.1 -0.2 -0.5  0.3 -0.2 -0.3 -0.4 -0.7 -0.5 -1.  -1.7 -0.1 -0.9 -0.7 -2.  -0.2 -0.2 -0.2 -0.1 -1.8  1.4  1.  -1.5 -0.  -0.5 -0.3 -0.7  4.8 -3.  -0.4  1.4  0.4  1.   0.1  3.5 -0.3 -0.4 -0.1 -2.6 -0.3  3.4  6.6  3.2 -0.5  0.5 -0.2  2.4  3.8 -0.7 -0.1 -0.1 -0.  -0.5 -0.1 -0.8 -0.3 -0.2 -0.4 -0.2 -0.6 -0.   8.6 -0.5 -0.5  0.2 -1.4 -0.2 -0.1 -0.5 -0.2  0.8  1.6 -0.5 -0.1 -2.4  0.1 -0.2 -0.1 -0.5 -0.8 -0.2 -0.5  0.  -0.2 -0.5 -0.   0.1 -0.3 -2.3 -0.1 -0.8 -0.9 -0.2 -1.8 -0.4  0.4 -1.7  0.6 -0.5 -0.6  0.3  0.6 13.2 -0.2 -0.5 -0.4 -1.2 -0.9 -1.3 -1.1 -1.2 -0.1 -0.2  0.4 -0.1 -0.4 -0.3 -0.3 -0.8 -0.2 -0.3 -4.3 -0.1 -0.4 -1.9 -0.3  3.2 -0.3  1.2 -0.5 -1.3 -0.4 -0.1  0.3 -0.3  0.5 -1.1 -1.1 -1.6 -1.3 -0.3 -0.2 -0.3 -1.   1.6 -0.1 -2.4  1.   2.6  2.7 -1.2 -0.  -2.3 -0.2 -1.  -0.3 -0.2 -1.9 -1.2 -0.2 -0.5 -1.2 -0.5 -2.9 -0.2  7.   0.6  1.8  0.1]
vy_50sample [[0 5 1 3 9 2 4 8 6 7]
 [6 4 8 0 1 3 9 7 2 5]
 [2 7 9 9 5 8 6 0 0 3]
 [2 8 7 4 5 1 9 0 3 6]
 [2 0 9 3 6 7 1 4 5 8]
 [5 3 2 8 6 6 1 4 9 0]
 [3 4 7 0 6 6 5 1 2 2]
 [1 6 3 0 4 9 8 7 5 2]
 [8 2 5 4 3 0 6 7 1 9]
 [1 6 3 7 2 5 0 8 4 9]]
vt_50sample [[0 5 1 3 9 2 4 8 6 7]
 [6 4 8 0 1 3 9 7 2 5]
 [2 7 9 5 1 4 6 8 0 3]
 [8 2 7 4 5 1 9 0 3 6]
 [2 0 9 3 6 7 1 4 5 8]
 [5 3 2 8 7 6 1 4 9 0]
 [3 4 7 0 6 9 5 1 8 2]
 [1 6 3 0 4 9 8 7 5 2]
 [8 2 5 4 3 0 6 7 1 9]
 [1 6 3 7 2 5 0 8 4 9]]
Epoch 33310: Training cost= 0.2599, Training acc= 0.8436, Validation cost= 0.2787, Validation acc= 0.8437
Epoch 33320: Training cost= 0.2336, Training acc= 0.8436, Validation cost= 0.3026, Validation acc= 0.8437
Epoch 33330: Training cost= 0.2704, Training acc= 0.8436, Validation cost= 0.2981, Validation acc= 0.8437
Epoch 33340: Training cost= 0.2495, Training acc= 0.8437, Validation cost= 0.3003, Validation acc= 0.8438
Epoch 33350: Training cost= 0.2917, Training acc= 0.8437, Validation cost= 0.3073, Validation acc= 0.8438
Epoch 33360: Training cost= 0.2265, Training acc= 0.8437, Validation cost= 0.2792, Validation acc= 0.8438
Epoch 33370: Training cost= 0.2701, Training acc= 0.8437, Validation cost= 0.2742, Validation acc= 0.8438
Epoch 33380: Training cost= 0.3753, Training acc= 0.8437, Validation cost= 0.2318, Validation acc= 0.8438
Epoch 33390: Training cost= 0.2754, Training acc= 0.8437, Validation cost= 0.3216, Validation acc= 0.8438
Epoch 33400: Training cost= 0.2332, Training acc= 0.8437, Validation cost= 0.2441, Validation acc= 0.8438
tm  [-0.7 -0.1  8.6 11.  -1.7 -0.3 -0.4 -0.1 -0.7 -0.9 -0.8  1.2 -0.3 -0.2  4.1  6.2 -0.3  1.4  0.2 -0.9 -0.7  0.6  1.6  0.3 -1.2  0.6 -0.3 -0.2  1.6  2.7 -0.9 -0.1  1.3  6.1 -0.4  0.5  1.9  5.5 12.1 -0.3  2.4 -1.3  1.   1.5 -0.4  0.   5.5 -0.6  0.5  5.1 -0.4 -0.1  0.2 -1.  -1.4 -0.2 -0.4 -0.4 -0.9  4.1 -0.6 -0.3  0.7  0.  -0.8 -0.9  0.2 -0.4 -0.5 -0.2  0.6 -1.8  0.5  0.9 -0.6 -0.  -0.3 -0.7 -0.3  0.5  3.  -0.2  0.3  0.3 -0.5 -0.8 -0.7  0.3 -0.1 -0.5 -0.2 -0.3 -0.2 -0.   1.2 -0.5 -0.3 -1.  -0.6  0.1  2.7  5.5 -0.4 -0.  -0.2 -0.3  1.  -0.5 -0.1 -1.2 -0.2 -0.2  0.2 -0.4 -1.  10.5  0.3 -1.2  0.1 -0.5 -0.4  3.9 -0.2  0.1  0.5  4.8 -0.1  5.5 -0.8 -1.2 -0.5  0.4 -0.1 -0.5 -5.7 -3.3 -0.3 -0.4  0.2 -0.3 -0.7 -0.6 -0.9 -0.3  0.2  0.  -0.2 -0.2 -2.6 -0.  -1.2 -0.   1.1 -0.6 -0.1  0.4 -0.3 -0.3  5.3  0.9  0.6 -1.9 -0.3 -0.1 -0.3 -0.3 -0.2  0.6 -0.  -0.1 -0.2  0.2  0.3 -0.3 -0.3  3.4 -0.5  1.6 -1.2 -0.3  0.2 -0.1 -0.3 -0.9 -0.5 -0.8  0.1 -0.5 -0.4 -0.7 -0.  -0.4 -0.  -0.8  6.   2.9  2.5  1.7 -0.5 -0.1 -0.1  0.1  0.2 -0.4 -0.1  4.8 -0.2 -0.2  6.  -0.2 -0.8  4.7 -0.3  2.6 -0.3 -0.3 -0.4 -0.1 -0.4 -0.1 -0.3  0.1 -0.2 -0.4 -1.   4.  -0.5  1.5 -0.1 -0.3  0.5 -0.8 -0.1  3.5 -1.2 -1.5 -0.3  1.8  0.4 14.1 -0.1  5.  -0.  -0.4 -0.2 -2.8 -0.7  0.3 -0.8 -0.1 -1.  -0.1  7.8  0.2 -0.4  5.9]
ty_50sample [[7 9 8 2 1 3 4 5 6 0]
 [7 4 9 6 3 8 2 1 0 5]
 [5 7 0 9 8 4 6 6 1 3]
 [2 4 0 6 8 3 5 7 1 9]
 [0 3 6 1 9 7 2 8 5 4]
 [1 6 4 8 5 3 0 7 2 9]
 [2 5 9 0 1 4 8 6 3 7]
 [0 2 8 9 9 1 5 6 7 4]
 [3 3 8 8 2 4 6 1 5 7]
 [3 8 6 4 0 5 2 7 1 9]]
tt_50sample [[7 9 8 2 1 3 4 5 6 0]
 [7 4 9 6 3 8 2 1 0 5]
 [5 7 0 9 8 4 2 6 1 3]
 [4 2 0 6 8 3 5 7 1 9]
 [0 3 1 6 9 7 2 8 5 4]
 [1 6 4 8 3 5 0 7 2 9]
 [2 5 9 0 4 1 8 6 3 7]
 [0 2 8 9 1 3 5 6 7 4]
 [3 0 9 8 2 4 6 1 5 7]
 [3 8 6 4 0 5 2 7 1 9]]
vm  [-0.7 -0.2 -1.3 -4.7 -1.8 -0.   0.4 -0.2  0.1 -0.9 -3.3 -0.7 -0.2 -0.2  8.6  1.2  0.1 -0.7 -0.4  2.5 -0.8 -0.4  1.9 -0.3 -1.2  0.3 -0.1 -0.2  1.6  1.5  2.1 -0.3 -0.4 -0.3 -0.1 -0.4 -0.5 -1.5 -3.9 -0.5 -0.2  1.2 -0.2  1.7 -0.   1.1 -3.1 -0.1  2.8  5.7 -0.4 -0.2 -0.3  3.5 -0.9 -0.9 -0.5 -1.2  4.  -0.4  4.4 -0.2 -0.5  0.3 -0.5  0.9 -0.2 -0.3  0.7  0.1 -0.3 -2.  -0.  -0.  -4.7 -0.3 -0.5  0.5 -0.2  0.7 -4.4  0.1 -0.   0.8 -0.6  3.5  4.8 -0.  -0.2 -0.4 -0.2 -0.1 -0.3 -1.2 -0.6 -0.2 -0.4 -3.5 -0.2  0.3  3.2  3.9 -0.3 -0.2  0.1  0.4 -2.2  1.7 -1.2  2.4 -0.6  0.1 -0.2 -1.2  0.4 12.  -0.5  1.  -0.  -0.5 -0.4 -0.8 -0.  -0.2 -0.  10.8  0.1 -0.1  4.3  6.4  2.2 -1.  -0.2 -0.8  4.8  4.  -0.5 -0.3 -0.6 -0.2  3.  -0.3  1.9 -0.2 -0.2 -0.2 -0.1  0.1  0.1 -0.2  3.3 -0.3  2.1  0.1 -0.2 -0.  -0.3  0.9 -0.9 -0.6  0.8  2.7 -0.2 -0.1 -0.1 -0.1 -0.4  1.8  0.5 -0.4 -0.2 -0.1 -0.2 -0.2 -0.1  1.2 -0.4 -0.2  6.8 -0.3 -1.2 -0.1 -0.7 -2.2 -0.1  0.1 -0.1 -0.7 -0.  -0.4  0.1 -0.3 -0.  -0.7 -1.1 -1.6 -0.9 -0.2  0.  -0.  -0.2 -0.1 -0.3 -0.6  0.1 -3.7  0.5 -0.4  3.8  0.9 -0.5  5.3 -1.   0.6 -1.  -0.1 -0.4 -0.7 -0.3  0.6 -0.3 -0.3 -0.3 -1.2  3.8  4.9 -1.5 -0.3 -0.1  4.7 -0.3 -0.7 -0.1  2.2 -0.4  3.1  0.7 -1.2  4.7 -2.9 -0.2 -1.1 -0.2  0.3 14.5  6.  -0.   0.3 -1.4 -0.7 11.6 -0.2 -2.4 -0.3  3.4 -1.3]
vy_50sample [[4 6 8 7 5 1 3 2 0 9]
 [1 4 6 9 8 0 7 3 2 5]
 [4 1 9 9 7 8 2 5 3 6]
 [8 6 4 9 3 5 0 2 7 1]
 [4 3 8 2 5 9 1 7 0 0]
 [8 2 4 3 1 6 5 7 0 0]
 [7 8 3 4 0 9 6 2 1 5]
 [2 4 8 9 0 7 6 3 1 5]
 [9 8 2 4 7 1 0 3 5 6]
 [6 6 0 5 7 8 4 3 9 2]]
vt_50sample [[4 6 8 7 5 1 3 2 0 9]
 [1 4 6 9 8 0 7 3 2 5]
 [4 1 0 9 7 8 2 5 6 3]
 [8 6 4 3 9 5 0 2 7 1]
 [4 3 8 2 5 9 7 1 6 0]
 [8 2 4 3 1 6 5 7 9 0]
 [7 8 3 4 0 9 6 2 1 5]
 [2 8 4 9 0 7 6 3 1 5]
 [9 8 2 4 7 1 0 3 5 6]
 [6 1 0 5 7 8 4 3 9 2]]
Epoch 33410: Training cost= 0.2388, Training acc= 0.8438, Validation cost= 0.2719, Validation acc= 0.8439
Epoch 33420: Training cost= 0.3182, Training acc= 0.8438, Validation cost= 0.2351, Validation acc= 0.8439
Epoch 33430: Training cost= 0.3067, Training acc= 0.8438, Validation cost= 0.2623, Validation acc= 0.8439
Epoch 33440: Training cost= 0.3026, Training acc= 0.8438, Validation cost= 0.3149, Validation acc= 0.8439
Epoch 33450: Training cost= 0.2699, Training acc= 0.8438, Validation cost= 0.2273, Validation acc= 0.8439
Epoch 33460: Training cost= 0.2238, Training acc= 0.8438, Validation cost= 0.2824, Validation acc= 0.8439
Epoch 33470: Training cost= 0.2229, Training acc= 0.8438, Validation cost= 0.2875, Validation acc= 0.8439
Epoch 33480: Training cost= 0.2653, Training acc= 0.8439, Validation cost= 0.2449, Validation acc= 0.8440
Epoch 33490: Training cost= 0.2767, Training acc= 0.8439, Validation cost= 0.2962, Validation acc= 0.8440
Epoch 33500: Training cost= 0.2835, Training acc= 0.8439, Validation cost= 0.2800, Validation acc= 0.8440
tm  [-1.5 -0.1 -0.9 -0.5 -1.  -0.1 -0.4 -0.   0.3 -1.  -2.4 -0.3  0.2 -0.2 -0.1  5.8  0.6 -0.3 -0.2  1.6 -0.9 -0.4  0.7  0.2 -0.8 -0.3 -0.7 -0.2  1.  -2.7 -1.9 -0.3  0.5 -6.  -0.3 -0.1 -0.3  3.6 -1.5 -0.7  0.2 -2.1 -0.7 -0.3 -0.3 -0.  -2.3 -0.2  0.2  3.5 -0.6 -0.1 -0.7  8.3 -1.3  0.3 -0.5  3.7  5.4  6.   5.8 -0.3 -0.2  1.2 -1.3 -0.5 -0.2 -0.5 -0.3 -0.5  0.2 -1.7  0.3  1.6 -5.2 -0.4 -0.5 -0.4 -0.2 -0.4 -5.9 -0.4 -0.1 -0.3 -0.6 -1.6 -1.2 -0.2 -0.  -0.5 -0.3 -0.1  0.2 -0.3 -0.3 -0.2 -0.4 -3.2  0.3  0.9  4.3 -3.2  0.8 -0.  -0.1 -0.5 -2.1 -1.4 -0.6  0.1 -0.4 -0.1  0.  -0.9  0.4 11.8 -0.1  0.5 -0.1 -0.8 -0.4 -0.4 -0.3  1.  -0.4 -0.1  0.2 -1.7  6.8  8.9 -0.4 -0.4 -0.1 -0.9  7.3 -3.7 -0.1 -0.1 -0.1  1.7 -0.4 -0.4 -1.1 -0.6  0.1 -0.1 -0.3 -0.3  4.9  0.4 -0.2 -0.3  0.9 -0.5 -0.3 -0.2 -0.2 -0.6  2.7  0.2 -0.8 -0.8 -0.2 -0.  -0.4 -0.   0.1  1.8  0.8 -0.5  0.  -0.  -0.2  0.4 -0.4 -1.  -0.5 -0.2  3.4 -0.5 -1.   0.9 -0.6 -1.4 -0.4 -0.3 -0.2  0.  -0.3  7.2 -0.3 -0.2 -0.  -0.6 -1.9 -2.4 -0.9 -0.1 -0.2  0.8 -0.  -0.1 -0.3 -0.5 -0.1 -3.1 -0.4 -0.2  7.1  0.4 -0.2  4.7 -0.7  2.2 -0.4 -0.9  2.1 -0.5 -0.6 -0.1 -0.1  0.3 -0.4 -1.2 -1.7  4.4 -0.5  0.6 -0.8  2.5 -0.1 -0.3 -0.3  3.1 -0.7  1.7 -0.2 -1.1  1.4 -2.4 -0.1 -1.   0.2 -0.2 18.3  4.1 -0.4  0.7 -0.8  0.5 15.7  0.1 -0.9 -0.1  3.  -2.3]
ty_50sample [[8 3 1 2 5 6 4 9 7 7]
 [3 2 7 0 9 4 8 6 5 1]
 [1 5 7 4 2 9 6 0 3 8]
 [3 5 0 6 2 9 4 1 8 7]
 [9 9 0 2 1 8 7 6 5 4]
 [0 8 1 4 3 9 7 5 5 2]
 [3 1 5 7 2 6 9 0 4 8]
 [0 8 7 4 3 6 9 5 2 1]
 [3 6 7 7 9 0 1 5 8 4]
 [7 9 6 8 0 5 1 3 4 2]]
tt_50sample [[8 3 1 2 5 6 4 9 7 0]
 [3 2 7 0 9 4 8 6 5 1]
 [1 5 7 4 2 9 6 0 3 8]
 [3 5 0 6 2 9 4 1 8 7]
 [9 3 0 2 1 8 7 6 5 4]
 [0 8 1 4 3 6 7 9 5 2]
 [3 1 5 7 2 6 0 9 4 8]
 [0 8 7 4 3 6 9 5 2 1]
 [3 6 2 7 0 9 1 5 8 4]
 [9 7 6 8 5 0 1 3 4 2]]
vm  [ 1.2 -0.4 -1.1 -0.8 -1.2 -0.1 -0.3 -0.1 -0.7 -1.  -0.8 -0.  -0.3  0.  -0.4 -1.4 -0.2 -0.6  1.5 -1.1 -1.  -0.  -0.9 -0.2 -1.   0.1 -0.4 -0.3 -1.2 -1.5  3.1 -0.1  0.7  3.  -0.3 -0.1  2.6 -1.  -0.6 -0.4  0.6 -0.1  1.6  0.9 -0.1 -0.3  2.1  0.2  4.7 -3.1 -0.4 -0.3 -0.8 -1.6 -0.3  0.1 -0.9  3.8  0.1 -1.3 -1.3 -0.7 -0.7  0.1 -0.6  0.3 -0.1 -0.8  1.3 -0.1  0.1  3.  -0.3 -0.2 -2.   0.5 -0.9 -0.4 -0.2 -0.2  7.  -0.8 -0.2 -0.1 -1.4  0.   4.7 -0.1 -0.1  0.1 -0.6  0.1 -0.2  1.2 -0.4 -0.1  0.6 -1.8 -0.4 -0.3  4.3 -1.9 -0.6 -0.2 -0.1 -0.1 -1.6  1.8 -0.3 -1.5 -0.7 -0.1 -0.2 -0.5  2.3 -0.8  1.  -0.1 -0.1 -0.1 -0.5  6.   0.1 -0.3 -0.2 -0.5 -0.   7.4  3.4  5.9  0.  -0.9 -0.2 -0.9  4.7  7.7 -0.2  0.  -0.3 -0.4 -0.1 -0.4  1.1 -0.2 -0.  -0.  -0.4 -0.1  5.9 -0.2  0.1  0.1  2.  -0.6 -0.3 -0.1 -0.  -0.1  0.3 -0.5 -0.5 -0.7 -0.3 -0.1 -0.3 -0.1  0.1 -0.7 -0.3 -0.3 -0.1 -0.  -0.1 -0.5 -0.4 -1.2 -1.2 -0.7  2.  -0.1 -2.5 -0.2 -0.3 -1.4  0.5 -0.4  2.7 -0.4 -0.4  4.  -0.1 -0.  -0.3 -0.9  9.6 -1.  -0.5 -0.5 -0.3 -0.2 -0.4 -0.1 -0.2 -0.5 -0.4 -2.2 -0.2  0.4 -3.3 -0.  -0.1 -1.2 -0.3 -1.7  0.3 -0.2 -0.2 -0.6 -0.1 -0.8 -0.2 -0.1 -0.1 -1.  -1.4 -0.9 -1.6 -0.7  1.9  4.7 -0.8 -0.  -0.3 -1.9  1.3  1.4  0.  -0.6 -0.  -1.9 -0.  -0.8 -0.2 -0.4 -1.  -0.1 -0.2 -0.3 -1.1  0.3 -1.9 -0.2 -0.2 -0.3  7.2 -1.2]
vy_50sample [[3 5 0 4 6 9 7 8 2 1]
 [8 0 1 2 4 9 5 3 6 7]
 [8 9 7 6 3 0 1 5 2 4]
 [4 7 8 9 0 3 5 6 2 1]
 [6 4 7 1 8 0 9 3 2 5]
 [9 9 2 3 8 5 7 6 1 4]
 [7 5 4 8 6 9 2 1 0 3]
 [0 6 5 9 1 3 7 8 2 4]
 [5 0 2 4 4 7 3 6 1 1]
 [3 8 6 2 7 4 0 1 5 5]]
vt_50sample [[3 5 0 4 6 9 7 8 2 1]
 [8 0 1 2 4 9 5 3 6 7]
 [8 9 7 3 6 0 1 5 2 4]
 [4 7 8 9 0 3 5 6 2 1]
 [6 4 7 1 8 0 9 3 2 5]
 [9 0 2 3 8 5 7 6 1 4]
 [5 7 4 8 6 9 2 1 0 3]
 [0 6 5 9 3 1 7 8 2 4]
 [5 0 2 8 4 7 3 6 9 1]
 [3 8 6 2 7 0 4 1 5 9]]
Epoch 33510: Training cost= 0.2883, Training acc= 0.8439, Validation cost= 0.2901, Validation acc= 0.8440
Epoch 33520: Training cost= 0.2832, Training acc= 0.8439, Validation cost= 0.2356, Validation acc= 0.8440
Epoch 33530: Training cost= 0.2450, Training acc= 0.8439, Validation cost= 0.2574, Validation acc= 0.8440
Epoch 33540: Training cost= 0.2731, Training acc= 0.8439, Validation cost= 0.2347, Validation acc= 0.8440
Epoch 33550: Training cost= 0.3336, Training acc= 0.8440, Validation cost= 0.3427, Validation acc= 0.8441
Epoch 33560: Training cost= 0.2769, Training acc= 0.8440, Validation cost= 0.3194, Validation acc= 0.8441
Epoch 33570: Training cost= 0.2281, Training acc= 0.8440, Validation cost= 0.2748, Validation acc= 0.8441
Epoch 33580: Training cost= 0.2538, Training acc= 0.8440, Validation cost= 0.2223, Validation acc= 0.8441
Epoch 33590: Training cost= 0.2443, Training acc= 0.8440, Validation cost= 0.2619, Validation acc= 0.8441
Epoch 33600: Training cost= 0.2404, Training acc= 0.8440, Validation cost= 0.3099, Validation acc= 0.8441
tm  [ 0.9 -0.1  6.6 -0.6 -1.7 -0.  -0.5 -0.1 -0.6 -0.8 -2.7 -0.5 -0.2 -0.2  9.3 -0.2 -0.2 -0.1  1.2  1.4 -1.  -0.4  0.8  0.1 -1.1  2.2 -0.4 -0.2 -0.9 -0.1 -1.1 -0.2 -0.1 -0.4  0.1 -0.1  0.4  0.9 -1.3 -0.7 -0.6 -1.1 -0.  -0.4 -0.1 -0.3 -1.8 -0.4  6.8  7.5 -0.7 -0.3 -0.4  5.4 -0.4 -1.  -0.5 -0.3  0.2  5.3  0.2 -0.2 -0.3  0.2 -0.9 -0.8 -0.3 -0.1  1.8 -0.4 -0.2  3.3  1.3  1.1 -4.1 -0.4 -0.9 -0.6 -0.1 -0.2 -4.8 -0.5  0.8 -0.2 -2.1 -1.3  3.3 -0.2 -0.1 -0.2  0.4 -0.1 -0.5 -0.1 -0.3 -0.1 -0.4 -2.7 -0.1 -0.3  1.7  4.2 -1.2 -0.1 -0.2 -0.  -1.7 -1.  -0.9  0.2 -0.4 -0.1 -0.1 -0.4  1.3 -0.7 -0.7 -0.2 -0.1 -0.1 -0.3 -0.3 -0.1 -0.7 -0.3 11.6 -0.4 -1.  -0.3  4.3  2.8 -0.5 -0.2 -0.7 -1.8 -2.7 -0.  -0.3  0.9  1.8 -0.3 -1.3 -0.3 -0.2 -0.1  0.2 -0.5 -0.3 -2.1  0.3 -0.  -0.2  4.5 -0.  -0.2 -0.1 -0.1  0.9 -0.   0.2 -0.2 -0.3 -0.1 -0.2 -0.5 -0.6 -0.1 -0.1 -0.  -0.  -0.3 -0.3 -0.4 -0.2 -0.5  4.4 -0.6 -0.   3.5 -0.   0.1 -0.3 -0.3 -1.6 -0.1 -0.4  2.5 -0.5 -0.1  0.5 -0.2 -0.5  0.4 -0.6  3.7  1.1 -0.7 -0.5  0.2 -0.2 -0.3 -0.2 -0.4 -0.3 -0.2 -2.4 -0.5 -0.3  9.6 -0.2 -0.4 -0.7 -0.9 -1.2 -0.5 -0.5  2.5 -0.5 -0.2  0.3  0.1 -0.1 -0.3 -1.5  1.  -0.1 -0.7  0.2 -0.3  4.  -0.2 -0.3 -0.   4.2  1.  -1.4  1.8 -0.8  2.   0.  -0.   0.3 -0.2 -0.1 14.6  1.2 -0.4 -0.2 -0.9 -0.1 12.1 -0.2 -0.8 -0.1  1.6 -0.7]
ty_50sample [[8 7 0 0 6 2 4 5 9 1]
 [4 8 5 7 1 9 0 6 3 2]
 [3 4 5 0 2 8 6 7 1 9]
 [0 2 6 7 9 3 8 1 5 4]
 [4 3 7 7 5 1 1 2 8 9]
 [3 4 8 5 0 2 9 1 7 6]
 [0 4 6 5 3 9 7 9 8 2]
 [6 2 7 5 9 9 3 8 1 0]
 [8 1 0 0 2 3 5 4 9 6]
 [0 6 5 7 9 9 2 2 3 4]]
tt_50sample [[8 7 0 6 2 3 4 5 9 1]
 [4 8 7 5 1 9 0 6 3 2]
 [3 4 5 0 2 8 6 1 7 9]
 [0 2 6 7 9 3 8 1 5 4]
 [4 3 0 7 5 6 1 2 8 9]
 [3 4 8 5 0 2 9 7 1 6]
 [0 4 6 5 3 7 9 1 8 2]
 [6 2 7 5 9 4 3 8 1 0]
 [8 1 0 7 2 3 5 4 9 6]
 [0 6 5 7 9 1 8 2 3 4]]
vm  [-1.4 -0.1 -1.7 -1.  -1.5 -0.1 -0.4 -0.1 -0.1 -0.9  5.6  0.8 -0.4 -0.2 -0.5  5.7 -0.1 -0.2 -0.2 -0.7 -1.1  0.1 -0.2 -0.2 -1.2  2.  -0.  -0.4  1.8 -0.7  3.6 -0.5 -0.1  3.8 -0.1  0.8  1.2  4.7 10.1 -0.4  1.  -1.2 -0.4  4.5 -0.4  0.4  2.4 -0.6 -1.1 -0.6 -0.4 -0.2  0.9 -0.1 -1.6  1.4 -0.5 -2.   2.  -1.7  3.3 -0.4  1.3 -0.1  0.8 -0.5 -0.1  0.2 -0.3 -0.1  0.7 -1.6 -0.2  1.4 -1.9  0.9  0.3 -0.1 -0.  -0.2  8.  -0.2  0.1 -0.5  0.8 -0.7 -0.1 -0.2  0.2 -0.7 -0.6 -0.   0.  -0.5 -0.3 -0.3 -0.4 -1.6 -0.4 -0.1  3.3  1.  -0.1  0.3 -0.2  0.2 -0.4  4.5  1.9 -1.  -0.5 -0.4 -0.2 -0.8 -0.3 11.   1.8 -0.8 -0.2 -0.1 -0.1  3.3 -0.1 -0.2 -0.1 -0.6  0.6  2.7  1.  -0.4 -1.  -0.1  0.2 -0.3 -2.2 -1.  -0.2 -0.1 -0.1 -0.4 -0.2 -0.3 -0.4 -0.2  0.3 -0.2 -0.2 -0.1 -0.6 -0.2  0.1 -0.1 -1.1 -0.4 -0.1  0.1 -0.4 -0.2  4.5 -0.3  0.  -1.8 -0.   0.6 -0.3 -0.4 -0.2  1.   0.6 -0.2 -0.4 -0.1 -0.4 -0.4 -0.3  1.4 -0.3  1.  -0.9 -0.2 -0.1  0.2 -0.4 -1.5 -0.3 -0.1 -0.6 -0.6 -0.2  2.8 -0.1 -0.1 -0.2 -1.  -0.7 -0.3  1.2  0.2  0.1 -0.1 -0.1 -0.1 -0.2 -0.6 -0.2  1.2 -0.1 -0.2  2.6 -0.4 -0.4  4.7 -0.7  7.7  0.5 -0.4 -2.  -0.7  0.  -0.3 -0.3  0.  -0.6 -1.  -1.   3.  -1.  -0.2  1.4 -0.5  0.4 -0.4 -0.1  2.2 -1.1  3.8 -0.3 -0.3  0.2 10.7 -0.   3.8 -0.2 -0.  -1.3 -1.7 -0.4  0.9 -1.1 -0.3 -2.4 -0.1  6.6  0.2 -0.1  3.1]
vy_50sample [[1 4 9 2 3 7 8 5 6 0]
 [0 5 9 7 8 4 6 3 2 1]
 [6 3 4 1 0 9 8 2 7 5]
 [2 9 6 5 8 1 3 7 4 0]
 [8 7 2 3 1 6 5 9 4 0]
 [4 6 8 9 0 7 5 1 3 2]
 [9 1 4 5 6 3 0 7 2 8]
 [8 2 6 3 0 7 4 9 1 5]
 [9 6 7 5 2 8 4 1 0 3]
 [7 6 3 4 5 8 9 9 2 1]]
vt_50sample [[1 4 9 2 3 7 8 5 6 0]
 [5 0 9 7 8 4 6 2 3 1]
 [6 3 4 1 0 9 8 2 7 5]
 [2 6 9 5 8 1 3 7 4 0]
 [8 2 7 3 1 6 5 9 4 0]
 [4 6 8 9 0 7 5 1 3 2]
 [9 1 4 5 6 3 0 7 2 8]
 [8 2 6 3 0 7 9 4 1 5]
 [9 6 7 5 2 8 4 1 0 3]
 [7 6 3 4 8 5 9 0 2 1]]
Epoch 33610: Training cost= 0.2487, Training acc= 0.8440, Validation cost= 0.2582, Validation acc= 0.8441
Epoch 33620: Training cost= 0.2857, Training acc= 0.8441, Validation cost= 0.2532, Validation acc= 0.8442
Epoch 33630: Training cost= 0.2279, Training acc= 0.8441, Validation cost= 0.3305, Validation acc= 0.8442
Epoch 33640: Training cost= 0.3095, Training acc= 0.8441, Validation cost= 0.2494, Validation acc= 0.8442
Epoch 33650: Training cost= 0.2669, Training acc= 0.8441, Validation cost= 0.2310, Validation acc= 0.8442
Epoch 33660: Training cost= 0.2578, Training acc= 0.8441, Validation cost= 0.2611, Validation acc= 0.8442
Epoch 33670: Training cost= 0.2913, Training acc= 0.8441, Validation cost= 0.2136, Validation acc= 0.8442
Epoch 33680: Training cost= 0.2780, Training acc= 0.8442, Validation cost= 0.2255, Validation acc= 0.8443
Epoch 33690: Training cost= 0.3030, Training acc= 0.8442, Validation cost= 0.2641, Validation acc= 0.8443
Epoch 33700: Training cost= 0.3224, Training acc= 0.8442, Validation cost= 0.2862, Validation acc= 0.8443
tm  [ 0.2 -0.8 -3.  -2.1 -1.3 -0.1 -0.1 -0.2  0.8 -0.1  6.8  0.5 -0.3  0.2 -0.7 -1.  -0.4 -0.5 -0.6 -0.9 -1.4 -0.2 -0.9 -0.4 -0.7  2.3 -0.2  0.4 -1.2 -2.8  6.3 -0.4 -0.4  5.4 -0.1 -0.3 -0.   3.9 11.  -0.2  0.2 -0.5 -0.7  5.5 -0.3 -0.   2.6 -0.1  4.4 -2.8 -0.5 -0.1 -0.3  0.6 -0.2  0.9 -0.7 -1.4  6.4 -3.2 -0.4 -0.6  0.3 -0.   0.8 -0.5 -0.   0.4  1.1 -0.2 -0.3  3.2 -0.4 -0.  -3.3  0.3 -0.7  0.  -0.1 -0.2 11.6 -0.4 -0.3 -0.2 -1.3 -0.4  7.  -0.1 -0.  -0.6 -0.6 -0.2 -0.1 -0.6 -0.5 -0.2 -0.3 -2.2 -0.2 -0.4 -0.1 -1.2 -1.1 -0.1 -0.2 -0.3 -1.5  4.9  1.1 -1.5 -0.2 -0.2 -0.1 -0.8  5.7 -1.8  0.7  2.3 -0.4  0.4  0.5  4.3 -0.1  0.3 -0.5 -0.8 -0.1  2.4  6.9  3.6 -0.1 -0.2 -0.3 -0.  -2.  -0.4 -0.  -0.1 -0.2 -0.7 -0.  -0.6  0.  -0.2 -0.2 -0.2 -0.  -0.1  3.6 -0.3  0.9  0.3  0.2 -0.1 -0.1 -0.2  0.3 -0.3  3.4 -0.3 -0.3 -2.4 -0.  -0.1 -0.  -0.2 -0.4 -0.2 -0.4 -0.1 -0.2 -0.2  0.  -0.2  0.1 -0.6  0.1 -0.7 -1.  -0.1 -1.1 -0.2 -0.4 -1.7  0.4 -0.4  2.5 -0.4 -0.   7.9 -0.3  0.2 -0.6 -0.8  5.9 -2.1 -0.7 -1.3  0.1 -0.  -0.3 -0.2 -0.1 -0.2 -0.  -1.4 -0.1 -0.1 -2.4 -0.1 -0.4 -1.  -0.4 -1.2  1.2  0.3 -2.4 -1.  -0.4 -0.4 -0.1 -0.3 -0.6 -1.2 -1.8 -1.4 -1.5 -0.7  1.1  4.  -0.9  0.2 -0.3 -1.4  1.5  5.6  1.4 -0.9  1.3  1.5  0.2  0.5  0.  -0.2 -2.2 -0.9 -0.2 -0.5 -1.3 -0.1 -3.2 -0.   7.5 -0.   3.3 -0.3]
ty_50sample [[4 0 3 9 5 2 7 1 8 6]
 [1 1 8 2 9 4 6 7 5 3]
 [8 2 4 6 5 0 1 3 7 9]
 [1 4 7 0 9 3 6 5 8 2]
 [8 5 4 3 6 6 2 0 7 1]
 [9 7 4 6 1 5 2 8 0 3]
 [9 7 0 3 5 8 2 6 4 4]
 [7 4 5 3 1 2 6 8 9 0]
 [7 4 8 2 6 0 5 3 1 9]
 [6 0 3 1 8 9 5 5 7 2]]
tt_50sample [[4 0 3 9 5 2 7 1 8 6]
 [1 0 8 2 9 4 6 7 3 5]
 [8 2 4 6 5 0 1 3 7 9]
 [1 4 7 0 9 3 6 5 8 2]
 [8 5 4 3 6 2 9 0 7 1]
 [9 7 4 6 1 5 2 8 0 3]
 [9 7 0 3 8 5 2 1 6 4]
 [7 4 5 3 1 2 6 8 9 0]
 [7 4 8 0 2 6 5 3 1 9]
 [6 0 3 1 9 8 4 5 7 2]]
vm  [-1.1 -0.1 -1.9 -3.  -1.6 -0.3 -0.1 -0.2 -0.4 -0.9 -2.  -0.1 -0.4 -0.2  3.1 -0.1 -0.5 -0.1 -0.4 -0.1 -1.2 -0.2 -0.2 -0.2 -1.2  1.2 -0.3 -0.4 -0.1 -0.8  3.8 -0.3 -0.3  0.1 -0.1 -0.2  1.2 -0.   1.6 -0.4  0.6 -2.4 -0.6  4.2 -0.5  0.2 -0.6 -0.3 -0.9 -0.4 -0.6 -0.3 -0.2 -0.2 -1.4 -0.2 -0.7 -3.2  2.8 -1.2  5.4 -0.2 -0.3 -0.2  0.5 -0.5 -0.2  0.8  1.4 -0.2 -0.1 -0.6  0.9  0.  -3.2 -0.4 -0.1 -0.5  0.6 -0.2 -1.2 -0.1  0.2  0.3  0.4 -2.1  2.2 -0.2 -0.2 -0.6 -0.1 -0.1 -0.  -0.7 -0.6 -0.1 -0.9 -2.4 -0.2 -0.3  3.1 -0.4  0.3 -0.1 -0.2 -0.  -1.7  3.4 -0.6 -0.2 -0.4 -0.2 -0.2 -0.8  1.6  4.1 -0.2 -0.1 -0.3 -0.1 -0.1 -0.   0.2 -0.2 -0.3  3.8 -0.   3.2  1.6  6.3 -0.4 -0.6  0.3 -0.3 -1.  -1.2  0.1 -0.1  0.  -0.5  2.5 -0.5  0.5  0.2 -0.2 -0.  -0.3 -0.1 -1.2 -0.   1.6 -0.2 -0.3  0.7 -0.1  0.1 -0.2  1.   1.  -0.3 -0.1 -0.7  0.1 -0.2 -0.2 -0.6 -0.   2.8  0.3  0.2 -0.3 -0.1 -0.2  0.2 -0.3  2.9 -0.3 -0.4  0.9 -0.1  1.6 -0.5 -0.4 -2.2 -0.2 -0.1 -0.7 -0.4 -0.   2.6 -0.4 -0.3 -0.4 -1.3 -1.5 -0.4 -0.6 -0.3 -0.1 -0.2 -0.3 -0.3 -0.7 -0.7 -0.1 -2.2 -0.4 -0.2  6.4 -0.3 -0.4  1.7 -1.2  6.2 -0.5 -0.4 -1.6 -1.  -0.   1.3 -0.3 -0.1 -0.3 -1.4 -0.7  2.7 -1.7 -0.1  0.3  0.7 -0.5  0.4 -0.2  3.2 -0.3  4.3  0.9 -1.   2.4  5.5 -0.1  1.6 -0.2 -0.1  5.4 -0.2 -0.1  0.5 -1.1 -0.3  1.9 -0.2  1.3 -0.2  5.4 -1.2]
vy_50sample [[4 1 3 8 7 9 9 9 2 5]
 [1 5 6 2 3 9 7 4 0 8]
 [3 6 2 9 5 1 7 4 8 0]
 [7 9 2 0 8 1 6 3 5 4]
 [0 9 8 8 5 6 7 1 3 4]
 [0 2 1 5 6 7 8 9 4 3]
 [9 2 7 6 0 5 3 8 4 1]
 [8 5 3 7 6 2 4 0 1 9]
 [7 2 5 8 4 1 3 9 0 6]
 [7 6 5 1 1 2 0 9 8 4]]
vt_50sample [[4 1 3 8 7 0 9 6 2 5]
 [1 5 2 6 3 9 7 0 4 8]
 [3 6 2 9 5 1 7 4 8 0]
 [7 9 2 0 1 8 6 3 5 4]
 [9 0 8 2 6 5 7 1 3 4]
 [0 2 1 5 6 7 8 4 9 3]
 [9 2 7 6 0 5 3 8 4 1]
 [8 5 3 7 6 2 4 0 1 9]
 [7 2 5 8 1 4 3 9 0 6]
 [7 6 5 3 1 2 0 9 8 4]]
Epoch 33710: Training cost= 0.2615, Training acc= 0.8442, Validation cost= 0.2619, Validation acc= 0.8443
Epoch 33720: Training cost= 0.2284, Training acc= 0.8442, Validation cost= 0.2854, Validation acc= 0.8443
Epoch 33730: Training cost= 0.2344, Training acc= 0.8442, Validation cost= 0.2561, Validation acc= 0.8443
Epoch 33740: Training cost= 0.2635, Training acc= 0.8443, Validation cost= 0.2529, Validation acc= 0.8443
Epoch 33750: Training cost= 0.3629, Training acc= 0.8443, Validation cost= 0.2789, Validation acc= 0.8444
Epoch 33760: Training cost= 0.2639, Training acc= 0.8443, Validation cost= 0.2534, Validation acc= 0.8444
Epoch 33770: Training cost= 0.2560, Training acc= 0.8443, Validation cost= 0.2617, Validation acc= 0.8444
Epoch 33780: Training cost= 0.2898, Training acc= 0.8443, Validation cost= 0.3667, Validation acc= 0.8444
Epoch 33790: Training cost= 0.2714, Training acc= 0.8443, Validation cost= 0.2597, Validation acc= 0.8444
Epoch 33800: Training cost= 0.2745, Training acc= 0.8443, Validation cost= 0.3185, Validation acc= 0.8444
tm  [-1.5 -0.4  1.6 -1.5 -0.9 -0.1 -0.3 -0.1  1.9 -0.1 11.  -0.2  0.3 -0.4  6.3  7.2  0.4 -0.1 -0.  -0.3 -1.1 -0.  -0.1 -0.3 -1.1 -0.2 -0.1 -0.1  2.6 -1.3  3.3 -0.6  1.4  8.2  0.9 -0.  -0.4  3.1 -2.6 -0.4  0.  -1.1 -1.4 -0.1 -0.4 -0.1 -1.3 -0.5 -1.9 -0.8 -0.4 -0.2 -0.8 11.8 -1.3 -0.5 -0.7 -1.4  7.2 -1.4  9.5 -0.2 -0.1  0.2  2.1 -0.7 -0.   0.4 -0.2 -0.4 -0.2 -1.8 -0.4  0.7 -5.  -0.2 -0.  -0.1 -0.1 -0.4  3.6  0.2 -0.4 -0.6  1.1 -0.9 -1.4 -0.1  0.1 -0.5 -0.4 -0.  -0.2 -1.2 -0.6 -0.2 -0.3 -2.6 -0.   0.8  0.5  3.2  0.8 -0.  -0.1 -0.2 -2.5  1.7  0.3 -0.3 -0.3 -0.1 -0.1 -1.1  2.  10.8  0.3  0.7 -0.1 -0.1 -0.4  0.7  0.6 -0.6 -0.1  7.3 -0.1 -2.9  3.7  3.2 -0.6 -0.4 -0.2  0.4  4.2 13.2 -0.6 -0.1 -0.4 -0.4 -0.9 -0.2 -1.  -0.1 -0.1 -0.3 -0.4 -0.2 -1.5  0.1  0.2 -0.1 -1.7 -0.8  0.4  0.  -0.2 -0.1 -0.9 -0.6 -0.1 -0.2 -0.2 -0.1 -0.2  0.1 -0.4  2.5 -0.1 -0.5 -0.4 -0.2 -0.3 -0.  -0.2  2.8 -1.2 -0.4  4.5 -0.2  0.4  1.5 -0.3 -1.6 -0.4 -0.5 -1.1 -0.8 -0.4  4.1 -0.2 -0.2 -0.3 -0.7 -3.3 -1.4 -1.1 -0.8  0.  -0.  -0.   0.4 -0.1 -0.3 -0.3 -2.7 -0.2 -0.4  2.7 -0.4 -0.6  4.2 -0.6  6.4 -0.3 -0.3  1.9 -0.9 -0.2 -0.4 -0.2  0.1 -0.2 -1.6  3.   2.6  1.3  0.6 -0.4 -0.3 -0.1  2.1 -0.2  1.7 -1.4  0.4 -0.  -1.6  0.5  4.6 -0.1  2.2 -0.2  0.1 -0.2  4.7 -0.3 -0.1 -1.2  0.2 -1.   0.3 -1.6 -0.  -1.3 -0.1]
ty_50sample [[1 2 6 7 4 3 9 8 5 0]
 [3 6 4 5 1 0 8 9 2 7]
 [0 6 4 1 7 3 5 2 8 8]
 [2 6 3 8 5 0 1 4 7 9]
 [1 6 3 8 9 7 4 5 2 0]
 [0 8 1 4 7 5 3 9 9 2]
 [9 8 2 5 0 6 3 3 1 4]
 [5 2 1 0 9 6 3 4 7 8]
 [6 3 3 5 2 1 1 0 4 8]
 [5 2 0 6 1 3 7 7 4 8]]
tt_50sample [[1 2 6 7 4 3 9 8 5 0]
 [3 6 4 5 1 0 8 9 2 7]
 [0 6 4 1 7 3 5 2 8 9]
 [6 2 3 8 5 0 1 4 7 9]
 [1 6 3 8 9 7 4 5 2 0]
 [0 8 1 4 7 5 3 9 6 2]
 [9 8 2 5 0 6 3 7 1 4]
 [5 2 1 0 9 6 3 4 7 8]
 [6 3 5 7 9 2 1 0 4 8]
 [5 2 0 6 1 3 7 4 9 8]]
vm  [-0.2  1.5  3.6  2.5 -1.  -0.4 -0.1 -0.3 -0.9 -0.6 -1.2 -0.2 -0.5 -0.1  1.3  2.4 -0.2  0.2  0.3 -1.8 -0.7 -0.1 -0.6 -0.1 -0.9 -0.7 -0.2  0.3  1.5  7.2  2.5 -0.3  2.6  8.  -0.3 -0.6  2.1 -1.5 -0.8 -0.4 -0.6 -2.9  0.3 -1.1 -0.4 -0.5  8.2 -0.2 -0.3 -1.9 -0.3 -0.1 -0.  -2.5 -1.7 -0.1 -0.3 -1.8 -1.3 -1.  -1.4 -0.2 -0.2 -0.4  0.7 -0.8  0.1 -0.5  0.2 -0.2 -0.1 -2.  -0.4 -0.7 -0.7  1.3 -0.5 -0.2 -0.6  0.5 11.8 -0.4 -0.3  0.3 -0.9 -2.4  2.5  0.  -0.1  0.9 -0.5 -0.2 -0.1  1.4 -0.1 -0.4 -0.  -0.4 -0.6 -0.2  2.6  0.2 -0.5  0.2 -0.1 -0.5 -1.1  1.3 -0.5 -1.7  0.7 -0.1 -0.1 -0.7 -0.9  8.7  0.1 -0.8 -0.2 -0.3 -0.5  5.8 -0.1 -0.1  0.2  1.5  0.9 10.7 -2.   1.5 -0.1 -0.3 -0.  -0.1  4.9 14.2 -0.1 -0.  -0.5 -0.7 -0.3 -0.3  0.  -0.2 -0.   0.1 -0.3 -0.2 -2.2 -0.3 -0.6  0.1  2.2 -0.3 -0.4 -0.1 -0.6 -0.2 -2.  -0.6 -0.4  1.7 -0.2 -0.2  0.8  1.3 -0.4  0.8 -0.4 -0.2 -0.2 -0.3 -0.1 -0.5 -0.2  3.9 -1.4 -0.1  1.6 -0.2  1.7  1.3  0.6 -1.4 -0.3 -0.7  1.  -1.1  0.2 -1.8 -0.1 -0.3 -0.5 -1.2  9.3  6.3 -0.1  0.4 -0.4 -0.1 -0.3 -0.2 -0.1 -0.5 -0.5  1.7  0.   0.6  5.9 -0.1 -0.7  3.6 -0.2 -0.2  2.2  0.6  3.2 -0.5 -0.1 -0.2 -0.3 -0.3 -0.  -0.9  1.6  4.  -1.6 -0.1 -0.5  0.4 -0.   1.4 -0.4  3.3 -1.8 -0.2 -0.3 -0.1 -0.5 19.  -0.   6.8 -0.2 -0.6 -2.3 -2.1 -0.5 -0.6 -0.5  0.6 -3.1 -0.1 -0.6 -0.2  4.   0.6]
vy_50sample [[6 3 7 9 4 8 1 2 5 0]
 [9 3 4 7 8 0 2 1 5 6]
 [2 1 6 9 5 0 8 3 7 4]
 [0 3 5 8 4 9 6 1 7 2]
 [3 3 2 6 4 7 8 9 5 1]
 [7 9 0 2 5 6 8 4 1 3]
 [0 4 6 5 2 7 8 3 1 9]
 [2 0 4 3 6 1 8 9 5 7]
 [6 5 9 3 7 0 2 4 8 1]
 [4 1 9 3 8 5 2 7 0 0]]
vt_50sample [[6 7 3 9 4 8 1 2 5 0]
 [9 3 4 7 8 0 2 1 5 6]
 [2 1 6 9 5 0 8 3 4 7]
 [0 3 5 8 4 9 6 1 7 2]
 [3 0 2 6 4 7 8 9 5 1]
 [9 7 0 2 5 6 8 4 1 3]
 [0 4 6 5 2 7 8 3 1 9]
 [2 0 4 6 3 1 8 9 5 7]
 [6 5 9 3 7 0 2 4 8 1]
 [4 1 9 3 8 5 2 7 0 6]]
Epoch 33810: Training cost= 0.2328, Training acc= 0.8444, Validation cost= 0.2639, Validation acc= 0.8444
Epoch 33820: Training cost= 0.2440, Training acc= 0.8444, Validation cost= 0.2358, Validation acc= 0.8445
Epoch 33830: Training cost= 0.2733, Training acc= 0.8444, Validation cost= 0.2660, Validation acc= 0.8445
Epoch 33840: Training cost= 0.2467, Training acc= 0.8444, Validation cost= 0.2365, Validation acc= 0.8445
Epoch 33850: Training cost= 0.2923, Training acc= 0.8444, Validation cost= 0.2500, Validation acc= 0.8445
Epoch 33860: Training cost= 0.2699, Training acc= 0.8444, Validation cost= 0.2478, Validation acc= 0.8445
Epoch 33870: Training cost= 0.2751, Training acc= 0.8444, Validation cost= 0.3169, Validation acc= 0.8445
Epoch 33880: Training cost= 0.2710, Training acc= 0.8445, Validation cost= 0.2811, Validation acc= 0.8445
Epoch 33890: Training cost= 0.2324, Training acc= 0.8445, Validation cost= 0.2187, Validation acc= 0.8446
Epoch 33900: Training cost= 0.2921, Training acc= 0.8445, Validation cost= 0.2636, Validation acc= 0.8446
tm  [-0.4 -0.8  0.1 -0.6 -1.3 -0.6 -0.3 -0.5  2.3  0.3  3.6  2.9 -0.5 -0.2  2.4  1.7 -0.8 -0.3  0.4  1.1 -1.2  0.6 -0.6 -0.  -1.1  1.2 -0.  -0.6  2.1 -2.   3.5 -0.1 -0.3  7.  -0.2 -0.2 -1.2  1.1  3.1 -0.4  3.1  3.7 -0.5  4.3 -0.5 -0.1 -1.1 -0.4  3.5 -1.7 -0.2 -0.1  2.1 -0.1 -1.5 -0.  -0.5  2.6  6.9 -1.2  1.  -0.8  0.7 -0.1  2.2 -0.7 -0.3  3.1  3.1 -0.3 -0.3 -2.1 -0.4  1.1 -5.  -1.3 -0.9 -0.9 -0.5 -0.1  5.1 -0.   0.5 -0.2 -1.4  3.3  3.7  0.4 -0.3 -0.7  0.9  0.  -0.2 -1.7 -0.2 -0.  -0.8 -3.  -0.5 -0.7 -0.2  1.3 -0.9 -0.1  0.7  0.9 -1.2  3.5  2.   0.  -0.1 -0.6 -0.2 -1.3  2.1 10.8  2.6  3.2 -0.3  2.1 -0.  -0.6 -0.3  0.9 -0.3  3.  -0.4  3.8 10.9  3.1 -0.3 -0.2  0.2  0.5 -2.3  2.1  0.5  0.1 -0.9 -1.   2.4 -0.2  1.5 -0.5 -0.1 -0.5 -0.5  0.2  3.8 -0.5 -0.   0.2  0.4  0.6  0.8 -0.4 -0.1 -0.4  4.2  1.2 -0.1 -2.1 -0.1 -0.  -0.5 -0.5 -0.2  1.1 -0.1  0.4 -0.4 -0.1  0.6 -0.2 -0.2 -0.7 -0.8 -0.4  0.  -0.4 -1.4 -0.4  0.2 -2.  -0.3  0.3  2.5 -0.1 -0.3  6.  -0.3 -0.1 -0.2 -1.6  2.7 -3.5 -0.5 -0.4  0.1 -0.3 -0.  -0.3 -0.4 -1.  -0.6 -0.9 -0.3 -0.4 -4.7 -0.4 -0.4  6.5 -1.4 -0.5 -1.  -0.3 -1.4 -0.4 -0.   0.8 -0.5 -0.2 -0.1 -1.2 -1.3  1.5 -2.6 -0.7  2.5  3.5  0.2 -0.3 -0.1 -2.5 -1.5  0.4  1.8 -1.   3.6 -4.3 -0.3 -1.6 -0.4 -0.2 -0.5 -0.7  0.3  0.4 -1.3  0.1 -1.4 -0.3  2.6  0.9  4.5 -0.2]
ty_50sample [[5 4 3 9 9 1 2 6 8 8]
 [6 4 5 1 8 8 0 3 7 9]
 [7 5 2 6 8 1 3 0 4 9]
 [3 6 7 5 8 1 2 4 4 0]
 [6 9 4 3 2 8 7 5 1 0]
 [9 8 6 7 4 3 5 2 0 1]
 [7 7 8 8 0 4 5 3 2 9]
 [8 6 3 4 7 0 5 2 1 9]
 [3 6 8 4 7 5 0 2 9 1]
 [0 8 3 3 5 2 1 6 4 9]]
tt_50sample [[5 4 3 7 9 1 2 0 6 8]
 [6 4 5 1 8 2 0 3 7 9]
 [7 5 2 6 1 8 3 0 9 4]
 [3 6 7 5 8 1 2 9 4 0]
 [6 9 4 3 2 8 7 5 1 0]
 [9 8 6 7 4 3 5 2 0 1]
 [7 1 6 8 0 4 3 5 2 9]
 [8 6 3 4 7 5 0 2 1 9]
 [3 6 8 4 7 5 0 9 2 1]
 [0 8 3 7 5 2 1 6 4 9]]
vm  [-1.  -0.3 -1.5 12.6 -0.7 -0.2 -0.4 -0.   2.5  0.3 10.4 -0.7  0.1 -0.2 -3.4  4.2 -0.1  0.  -0.  -1.3 -1.  -0.1  0.1 -0.  -0.6  3.1 -0.3  0.6 -0.8 -2.9  1.6 -0.7 -0.6 -1.2  0.5 -0.2  0.4  4.1  8.  -0.3 -0.5 -0.9 -1.7 -0.6 -0.5  0.2  6.7 -0.5  0.7 -0.2 -0.  -0.2  1.3 -0.  -0.6  4.1 -0.2 -0.8  6.8 -0.3 -0.6 -0.1  0.8  1.2  1.5  0.3  0.2 -0.1 -0.4  0.5 -0.1 -0.2 -0.2  1.6  0.9 -0.5 -0.7 -0.5 -0.2  1.1 17.1 -0.1 -0.  -0.2 -0.3 -0.7 -0.7 -0.2 -0.6 -0.2  1.1 -0.2  0.2 -2.1 -0.2 -0.1 -0.2 -1.4 -0.2 -0.4 -0.  -1.  -0.2 -0.1 -0.2  1.7  1.3  1.4  1.4 -2.  -0.1  0.2  0.2 -0.5  5.1  1.5 -0.4 -0.1 -0.3 -0.4 -0.3  7.  -0.   2.2 -0.2 -4.1 -0.2  2.6  5.3 -2.1  0.  -0.5 -0.1 -0.4 11.2  8.1 -0.2 -0.1  0.6 -0.2 -0.8 -0.5 -1.5 -0.2 -0.  -0.1 -0.1 -0.3  1.7 -0.  -1.2 -0.2 -0.6 -0.6  0.8 -0.1 -0.3 -0.  -0.  -0.4  1.8 -0.4 -0.3 -0.  -0.   0.2  0.   3.3 -0.1 -0.1 -0.2 -0.2 -0.   0.3 -0.1 -0.  -0.3  1.6 -0.7 -0.   0.8 -0.1 -0.2 -1.7 -0.1 -0.4  0.9  0.5 -0.3  8.7  0.2 -0.  -0.3 -0.4  6.9 -1.6  3.4 -1.4 -0.1  0.4 -0.1  0.2 -0.3 -0.8  0.3  5.1 -0.3 -0.1  4.1 -0.1 -0.5  0.8 -1.   2.9 -0.7 -0.6  3.2 -0.9 -0.4 -0.  -0.4  0.1  0.1 -1.1  4.  -0.2  1.3  3.9 -0.2  1.6 -0.2 -2.   0.3  2.1 -0.   3.8 -0.1  2.3  2.2 19.7 -0.1  7.5 -0.1 -0.2 -3.4 -2.7 -0.2  0.3 -1.5 -0.1 -4.5  0.4  5.3 -0.1 -1.4  9.4]
vy_50sample [[9 9 6 6 0 4 3 8 5 7]
 [0 8 8 4 9 3 6 5 2 7]
 [9 6 7 4 3 2 2 8 5 1]
 [5 1 3 6 9 4 2 0 7 8]
 [1 7 7 3 4 0 2 2 5 8]
 [3 3 4 6 8 1 5 0 9 2]
 [3 0 5 6 9 7 1 2 4 8]
 [0 6 4 3 2 9 9 7 1 8]
 [7 9 9 4 0 0 3 6 2 1]
 [0 7 1 5 9 2 8 4 3 6]]
vt_50sample [[9 2 6 1 0 4 3 8 5 7]
 [0 8 4 1 9 3 6 5 2 7]
 [9 6 7 4 0 3 2 8 5 1]
 [5 1 3 6 9 4 2 0 7 8]
 [1 6 7 3 4 0 2 9 5 8]
 [7 3 4 6 8 1 5 0 2 9]
 [3 0 5 6 9 7 1 2 4 8]
 [0 6 4 3 2 5 9 7 1 8]
 [7 9 8 4 5 0 3 6 2 1]
 [0 7 1 5 9 2 8 4 3 6]]
Epoch 33910: Training cost= 0.2456, Training acc= 0.8445, Validation cost= 0.2693, Validation acc= 0.8446
Epoch 33920: Training cost= 0.2825, Training acc= 0.8445, Validation cost= 0.2769, Validation acc= 0.8446
Epoch 33930: Training cost= 0.2766, Training acc= 0.8445, Validation cost= 0.3228, Validation acc= 0.8446
Epoch 33940: Training cost= 0.4087, Training acc= 0.8446, Validation cost= 0.2433, Validation acc= 0.8446
Epoch 33950: Training cost= 0.2231, Training acc= 0.8446, Validation cost= 0.3162, Validation acc= 0.8446
Epoch 33960: Training cost= 0.2345, Training acc= 0.8446, Validation cost= 0.2833, Validation acc= 0.8447
Epoch 33970: Training cost= 0.2389, Training acc= 0.8446, Validation cost= 0.2878, Validation acc= 0.8447
Epoch 33980: Training cost= 0.2391, Training acc= 0.8446, Validation cost= 0.2486, Validation acc= 0.8447
Epoch 33990: Training cost= 0.2893, Training acc= 0.8446, Validation cost= 0.2724, Validation acc= 0.8447
Epoch 34000: Training cost= 0.2894, Training acc= 0.8446, Validation cost= 0.2670, Validation acc= 0.8447
tm  [ 1.6 -0.3  4.1  3.  -1.6 -0.  -0.5 -0.1 -0.5 -0.4  8.1 -0.3 -0.1  0.1  3.4 -0.4 -0.1 -0.6  1.3 -0.  -0.9 -0.1 -0.5  0.1 -1.6  4.7 -0.2 -0.2 -1.6 -2.2 -0.1 -0.4 -0.3  3.3 -0.  -0.1  3.4  3.9 -0.7 -0.4  0.8 -0.2  1.1 -0.4 -0.2 -0.2 -0.9 -0.5  6.8 -1.5 -0.3 -0.1 -0.5  7.5  2.3 -0.3 -0.9  5.2  0.2  2.4 -0.7 -0.2 -0.   2.4 -0.1  1.5  0.  -0.4 -0.  -0.1 -0.   7.6 -0.3  0.6 -3.1 -0.  -0.9 -0.2  0.2 -0.1  0.9 -0.3 -0.1 -0.3 -1.6 -0.1  2.8 -0.1  0.2 -0.1 -0.3 -0.2 -0.  -0.1  0.1 -0.1  0.5 -2.3 -0.3 -0.1  0.9 -0.7 -1.3  0.  -0.4  1.2 -1.3 -0.1  0.7 -0.3 -0.3  0.4  0.2 -0.1  3.1 -2.8 -0.2 -0.3 -0.3 -0.1 -0.2  0.9 -0.2 -0.3 -0.1  3.8 -0.1 -1.6  0.9  5.3  0.4 -0.2 -0.4 -0.5  1.   4.4 -0.3 -0.1  1.  -0.  -0.8 -1.5 -0.7 -0.4 -0.1  0.4 -0.2 -0.1  2.4 -0.1 -0.4 -0.1  2.5 -0.6 -0.4 -0.2 -0.4 -0.3  1.1 -0.2  0.1 -0.9  0.6  0.  -0.  -0.4 -0.4 -1.  -0.2 -0.1 -0.3 -0.1 -0.2 -0.3 -0.2 -0.2 -0.8 -0.2  2.7 -0.2 -1.4 -0.  -0.5 -1.7  0.2 -0.3  3.  -0.5 -0.1  6.5  0.3 -0.2 -0.1 -0.7  7.6 -0.2 -0.9 -0.7 -0.3 -0.  -0.1 -0.3 -0.1 -0.5 -0.1 -2.  -0.2 -0.1 -1.1 -0.1 -0.1 -2.1 -0.4 -1.4 -0.7 -0.2  3.  -1.1 -0.9 -0.4 -0.1 -0.1  0.4 -1.1 -0.4 -1.5  1.   1.2  0.5  3.4 -0.5 -0.1 -0.3 -0.7  3.8 -0.7  2.1 -0.6  1.  -1.4 -0.1 -0.4  0.  -0.3  1.7  0.7 -0.  -0.1 -1.2 -0.2 -0.3 -0.  -0.4  0.2 -0.1 -1.1]
ty_50sample [[0 2 3 5 6 6 8 9 4 1]
 [1 4 6 6 9 5 7 3 3 0]
 [1 2 5 6 0 4 7 8 3 9]
 [5 7 1 0 8 2 6 4 3 9]
 [8 2 4 4 7 6 3 9 1 5]
 [7 0 1 6 8 5 3 4 9 9]
 [7 4 3 1 5 9 0 0 6 8]
 [3 1 5 7 2 9 8 4 0 6]
 [5 8 0 3 6 6 4 9 2 1]
 [9 2 5 6 4 0 1 8 3 7]]
tt_50sample [[0 2 3 5 7 6 8 9 4 1]
 [1 4 8 6 9 5 7 3 2 0]
 [1 2 5 6 0 4 7 8 3 9]
 [5 7 1 0 8 2 6 4 3 9]
 [8 2 4 0 7 6 3 9 1 5]
 [7 0 1 6 8 5 3 4 2 9]
 [7 4 3 1 5 9 2 0 6 8]
 [3 1 5 7 2 9 8 4 0 6]
 [5 8 0 7 3 6 4 9 2 1]
 [9 2 5 6 4 0 1 8 3 7]]
vm  [ 1.4 -0.2  6.   1.  -1.  -0.3  0.6 -0.2 -0.3 -0.4  7.  -0.2 -0.3 -0.2  6.6  2.5 -0.3 -0.9 -0.4  1.4 -1.2 -0.1 -0.5 -0.  -1.1 -0.1 -0.1 -0.2  1.5 -0.8 -0.3 -0.3  1.   3.6 -0.4 -0.2 -0.3 -0.5 -4.8 -0.2  1.7  2.8  2.  -1.4  0.1 -0.4 -1.6 -0.4  2.3 -2.1 -0.6 -0.1 -0.5 12.1 -0.9 -0.8 -0.4 10.3  0.4  4.1  0.7 -0.3 -0.5 -0.4  2.6 -0.4 -0.1  1.5  1.2 -0.5 -0.5 -0.8 -0.3 -0.9 -5.3 -0.1 -0.4  0.3 -0.2 -0.6 -1.6  1.2 -0.4  1.4 -1.2  2.9  0.4  0.1 -0.1 -0.  -0.2  0.2 -0.3  0.6 -0.7 -0.2 -0.1 -2.7 -0.3 -0.2  2.3 -0.7 -1.   0.8 -0.5 -0.9 -3.5 -0.4  0.   2.6  0.3 -0.4 -0.1 -1.1 -0.3  4.8  1.1  1.3 -0.4  0.9 -0.1 -1.5  0.2 -0.7 -0.1  8.1 -0.1 -2.9  3.  12.6  0.4 -0.7 -0.5 -0.2  9.1 12.9 -0.  -0.3 -0.9 -0.8 -0.4  0.   0.8  0.4 -0.  -0.1  0.3 -0.2  5.8 -0.2 -0.2 -0.3  3.   1.5 -0.2 -0.2  0.3 -0.1 -1.6 -0.8 -0.4  2.3  0.2 -0.4 -0.  -0.3 -0.6 -0.7 -0.4 -0.1 -0.2 -0.1 -0.2 -0.4  0.4 -1.3 -2.1 -0.9  7.2 -0.1 -2.  -0.7 -0.5 -2.1 -0.2 -0.3  0.9 -0.6 -0.1  2.9 -0.3 -0.5 -0.7 -0.9  1.8 -1.2 -1.8  0.   0.2 -0.3 -0.1 -0.6 -0.6 -0.3 -0.3 -4.4  0.9 -0.  -3.3 -0.3 -0.4  1.2 -0.4 -1.2 -0.7  1.7  6.6 -0.8  0.5 -0.3  0.1 -0.7  0.5 -0.7  1.1  1.5 -0.2 -0.7  1.4  4.3 -0.4  3.5 -0.3 -1.7 -0.7 -1.2  2.6 -1.9  1.4 -6.  -0.2 -2.3  0.6 -0.2  6.   5.4  1.  -0.4 -0.8 -0.5  3.5 -0.2 -2.8 -0.4  3.1 -3.4]
vy_50sample [[5 6 3 2 7 8 0 1 4 9]
 [1 3 2 7 8 5 0 6 9 4]
 [0 2 3 8 6 7 5 4 1 9]
 [5 4 0 3 7 2 6 9 1 8]
 [0 8 7 9 2 4 1 3 6 5]
 [2 0 8 6 3 7 4 1 5 9]
 [2 6 4 5 8 0 9 9 3 3]
 [0 3 4 9 8 5 5 2 7 1]
 [6 1 5 4 0 7 3 8 2 9]
 [3 0 2 5 7 8 9 4 6 1]]
vt_50sample [[5 6 3 2 7 8 0 1 4 9]
 [1 3 2 7 8 5 0 6 9 4]
 [0 2 3 8 6 7 5 4 9 1]
 [5 4 7 0 3 2 6 9 1 8]
 [0 8 7 9 2 4 1 3 5 6]
 [2 0 8 6 3 7 4 1 5 9]
 [2 6 4 5 8 0 9 1 3 7]
 [0 3 4 8 9 6 5 2 7 1]
 [6 1 5 4 0 7 8 3 2 9]
 [3 5 0 2 7 8 9 4 6 1]]
Epoch 34010: Training cost= 0.2794, Training acc= 0.8447, Validation cost= 0.2863, Validation acc= 0.8447
Epoch 34020: Training cost= 0.2822, Training acc= 0.8447, Validation cost= 0.2792, Validation acc= 0.8448
Epoch 34030: Training cost= 0.2572, Training acc= 0.8447, Validation cost= 0.2445, Validation acc= 0.8448
Epoch 34040: Training cost= 0.2521, Training acc= 0.8447, Validation cost= 0.2855, Validation acc= 0.8448
Epoch 34050: Training cost= 0.3013, Training acc= 0.8447, Validation cost= 0.2754, Validation acc= 0.8448
Epoch 34060: Training cost= 0.2526, Training acc= 0.8447, Validation cost= 0.2935, Validation acc= 0.8448
Epoch 34070: Training cost= 0.2563, Training acc= 0.8447, Validation cost= 0.2992, Validation acc= 0.8448
Epoch 34080: Training cost= 0.2901, Training acc= 0.8447, Validation cost= 0.2638, Validation acc= 0.8448
Epoch 34090: Training cost= 0.2510, Training acc= 0.8448, Validation cost= 0.2317, Validation acc= 0.8448
Epoch 34100: Training cost= 0.2277, Training acc= 0.8448, Validation cost= 0.2202, Validation acc= 0.8449
tm  [-1.7  1.1 11.5 16.6 -1.2 -0.2 -0.4 -0.1 -1.4 -0.6  2.8 -0.4 -0.5  0.6  4.9  2.2 -0.9 -0.6 -0.7 -1.3 -0.8 -0.3  0.8  0.  -0.7 -0.3 -0.5 -0.1 -0.3  7.7 -1.7  0.8 -0.5  6.8 -0.4 -0.1  3.6 -1.  -1.6 -0.1 -0.3  2.8  3.4 -1.8 -0.3  0.2  4.2  0.6 -1.5  7.9 -0.1 -0.1 -0.1  1.5 -0.8 -0.6 -0.5  7.2 -2.3  6.6  2.3 -0.3 -1.2 -0.7 -0.3  1.1  0.1  0.5  1.7 -0.5 -0.3 -0.9 -0.1 -0.3 -0.8 -0.5 -0.1 -0.4  0.2  0.1  1.3  0.4 -0.2 -0.1  2.1  4.9 -2.1  0.2 -0.4 -0.6 -0.2 -0.1  0.3  2.6 -0.2  0.3 -0.5 -0.8  0.7 -0.2  1.8  7.2  1.9  0.6 -0.1 -0.2 -0.9 -0.7  1.2 -2.  -0.   0.2 -0.1 -0.  -1.5  5.3 -0.6 -1.4 -0.4 -0.5  0.8  6.6 -0.1  0.6 -0.2  6.6  0.5  0.9 -2.3 -1.7 -0.1 -0.4 -0.1 -0.1  2.3  8.8  0.  -0.1 -0.3 -1.2 -0.1 -0.3 -0.1 -0.3 -0.2 -0.1 -0.2 -0.1 -1.1 -0.1 -1.4 -0.  -0.3  0.8 -0.1 -0.1 -0.1 -0.3 -1.7 -0.1 -0.7  3.9 -0.1 -0.1 -0.5  0.9  0.4 -0.2 -0.1 -0.2 -0.1 -0.4  0.6  0.7 -0.   2.2 -0.9 -0.3  2.4 -0.2 -1.2 -0.1 -0.1 -0.8 -0.2 -0.1 -1.1 -0.8  0.5 -1.8 -0.1 -0.2 -0.  -0.7 -0.2  8.2  0.3  4.5 -0.2 -0.2 -0.2 -0.3 -0.2 -0.4  0.1 -0.9 -0.2 -0.3  1.5  0.4 -0.1 -0.  -0.5  4.6 -0.6 -0.4  8.7 -0.7  0.1 -0.2 -0.3 -0.1 -0.4 -0.7  4.7  2.9 -0.4 -0.6  1.3 -0.7  0.1 -0.2 -0.3  0.2 -0.3 -3.1 -0.6 -0.2  1.3  1.4 -0.1  0.4 -0.1  0.5  1.1 -0.7 -0.3  0.9 -0.6 -0.4 -0.4  0.2 -1.  -0.3 -0.4  8.3]
ty_50sample [[6 7 1 1 2 8 8 0 3 4]
 [8 3 2 9 1 7 7 6 6 5]
 [5 2 1 4 9 8 6 7 3 0]
 [0 6 1 3 7 2 5 4 9 8]
 [9 8 0 3 6 5 1 4 7 2]
 [8 7 2 0 9 1 1 4 3 5]
 [3 8 1 0 7 2 4 9 5 6]
 [3 5 6 2 7 9 4 1 8 0]
 [1 3 9 9 6 4 2 0 5 7]
 [6 0 3 5 9 2 4 8 1 7]]
tt_50sample [[6 7 1 2 5 8 9 0 3 4]
 [8 3 2 1 9 4 7 6 0 5]
 [5 2 1 4 9 8 6 7 3 0]
 [0 6 1 3 7 2 5 4 9 8]
 [9 8 0 3 6 5 1 4 7 2]
 [8 7 2 0 9 6 1 4 3 5]
 [3 8 1 7 0 2 4 9 5 6]
 [3 5 6 2 7 9 4 1 8 0]
 [1 3 8 9 6 4 2 0 5 7]
 [6 0 3 5 9 2 4 8 1 7]]
vm  [ 1.6 -0.5 -2.4 -3.8 -0.7 -0.2 -0.1 -0.2 -0.8 -0.8 -4.3  0.8 -0.3 -0.5  1.2  1.3  0.5 -0.4  0.6 -0.2 -0.9 -0.1 -0.5  0.3 -1.5 -0.2 -0.2 -0.6  1.6  0.5  1.1 -0.3  2.3 -3.3 -0.5 -0.5 -0.1 -1.1 -3.2 -0.5  2.4 -2.1 -0.   1.  -0.3 -0.5 -0.8 -0.4  3.9 -0.6 -0.4 -0.1 -0.9  0.2 -1.4 -0.  -1.2 -1.4  0.9 -0.1 -0.3 -0.4 -0.2 -0.3 -0.4  0.6 -0.  -0.4  2.3 -0.1 -0.4 -1.8 -0.6 -0.7 -5.   2.8 -1.   2.  -0.4 -0.2 -4.3 -0.1 -0.4  1.2 -1.7 -2.   8.  -0.2  0.6 -0.5 -0.9 -0.3 -0.4  2.2 -0.5 -0.1 -0.  -2.3 -1.  -1.4  3.1 -1.7 -0.8 -0.2  0.3 -0.6 -2.8  0.5 -1.3  0.1  0.3  0.2 -0.1 -0.8 -0.4  9.1  2.3  0.5  0.3 -0.3 -0.5 -0.5 -0.5 -0.3  0.1  1.3 -0.2  2.6  0.1 11.8  0.5 -0.7 -0.5 -0.6  7.8  1.4 -0.4 -0.3 -0.5  0.1 -0.4 -0.1  1.8 -0.4  0.5 -0.1 -0.2 -0.1  2.1 -0.4  1.3 -0.1  3.3 -0.3 -0.5 -0.3 -0.2 -0.4 -1.  -0.3 -0.  -0.4 -0.2  0.1 -0.5 -0.3 -0.5 -0.4 -0.5 -0.3 -0.3 -0.3 -0.3 -0.6  0.3 -0.1 -2.2 -0.6  5.4 -0.4 -0.6 -0.3  0.8 -1.6 -0.4  0.6  2.7 -0.2 -0.5 -0.3  0.3 -0.1 -0.4 -1.4  5.7 -0.6 -1.   0.4 -0.1 -0.2 -0.1 -0.2  1.  -0.3 -0.6 -2.7 -0.2 -0.4  5.6 -0.2 -0.9  2.3 -0.4 -1.9  0.6  0.2 -0.5 -0.1 -0.1 -0.6 -0.5 -0.4 -0.6 -1.2 -0.8  3.7 -2.  -1.   0.5  3.6 -0.5  2.8 -0.5  2.  -1.9  2.3  0.5 -1.7 -0.5 -0.2 -0.2 -0.1 -0.6  0.3 13.3  0.3  2.1 -0.7 -0.6 -0.2 12.1 -0.4 -2.   0.8  6.6 -2.9]
vy_50sample [[3 4 6 8 5 7 9 2 0 1]
 [7 4 6 2 0 9 5 1 8 3]
 [5 4 6 9 0 3 2 8 7 1]
 [1 9 2 7 5 8 6 3 0 4]
 [2 6 0 8 4 7 9 1 5 3]
 [2 5 4 7 1 6 0 3 8 9]
 [8 5 9 0 7 3 1 6 4 2]
 [5 1 6 7 4 8 9 2 3 0]
 [4 2 6 0 9 8 3 5 7 1]
 [6 2 3 8 0 7 1 5 4 9]]
vt_50sample [[3 4 8 6 5 7 9 2 0 1]
 [7 4 6 2 0 9 5 1 8 3]
 [5 4 6 9 0 3 2 8 7 1]
 [1 9 2 7 5 8 3 6 0 4]
 [2 6 0 8 4 7 9 1 5 3]
 [2 5 4 7 1 6 0 3 8 9]
 [8 5 0 9 7 3 1 6 4 2]
 [5 1 6 7 4 8 9 2 3 0]
 [4 2 6 0 9 8 3 5 7 1]
 [6 2 3 0 8 7 1 5 4 9]]
Epoch 34110: Training cost= 0.2684, Training acc= 0.8448, Validation cost= 0.2936, Validation acc= 0.8449
Epoch 34120: Training cost= 0.3406, Training acc= 0.8448, Validation cost= 0.2592, Validation acc= 0.8449
Epoch 34130: Training cost= 0.2873, Training acc= 0.8448, Validation cost= 0.2606, Validation acc= 0.8449
Epoch 34140: Training cost= 0.1975, Training acc= 0.8448, Validation cost= 0.2332, Validation acc= 0.8449
Epoch 34150: Training cost= 0.3131, Training acc= 0.8449, Validation cost= 0.2699, Validation acc= 0.8449
Epoch 34160: Training cost= 0.2570, Training acc= 0.8449, Validation cost= 0.2425, Validation acc= 0.8450
Epoch 34170: Training cost= 0.2730, Training acc= 0.8449, Validation cost= 0.3184, Validation acc= 0.8450
Epoch 34180: Training cost= 0.2610, Training acc= 0.8449, Validation cost= 0.3622, Validation acc= 0.8450
Epoch 34190: Training cost= 0.2793, Training acc= 0.8449, Validation cost= 0.3365, Validation acc= 0.8450
Epoch 34200: Training cost= 0.2376, Training acc= 0.8449, Validation cost= 0.2250, Validation acc= 0.8450
tm  [ 0.3 -0.1  2.8 -0.5 -1.3 -0.3  0.1 -0.2 -0.2 -0.5 -2.6 -0.3 -0.3 -0.3  4.2  1.  -0.  -0.4 -0.   1.6 -0.7 -0.5  0.6  0.4 -1.1  1.  -0.2  0.1 -0.4 -0.7 -1.9 -0.2  0.8 -4.9 -0.3 -0.1 -0.4 -0.5 -4.6 -0.2 -0.2  3.5  0.7 -1.5 -0.3 -0.5 -1.7 -0.4  3.6 11.  -0.9 -0.1 -0.7 10.  -0.6 -0.4 -0.4  7.4  1.3  7.   2.9 -0.2 -0.3 -0.3 -0.6 -0.2 -0.2  0.3  0.7 -0.5 -0.3 -0.  -0.1 -0.6 -5.4  0.9 -0.4  1.2 -0.3 -0.3 -6.8 -0.3 -0.   1.4 -1.6  4.2 -0.   0.1 -0.2 -0.5 -0.4 -0.1 -0.2 -0.1 -0.5 -0.4  1.3 -3.3 -0.2 -0.8  1.4  0.1 -1.  -0.2 -0.1 -0.7 -2.6 -1.6 -0.7  3.5 -0.2  0.1 -0.2 -0.5  0.4  0.9 -0.1  0.1 -0.3 -0.  -0.5 -1.4 -0.1 -0.6 -0.1  4.8 -0.2 -2.2  1.5  5.1  0.8 -0.5 -0.3 -0.8 11.7 -0.6 -0.3 -0.4  0.5  1.5 -0.6 -0.8 -0.1 -0.2  0.2 -0.1 -0.1 -0.3  5.4 -0.2 -0.2 -0.1  3.5 -0.  -0.2 -0.1  0.2 -0.6 -1.4 -0.4 -0.1  2.4 -0.1 -0.1 -0.1 -0.6 -0.2 -0.4  0.2 -0.2 -0.2 -0.1 -0.4 -0.3 -0.2 -1.  -1.7 -0.4  7.1  0.5 -1.2 -0.5 -0.4 -1.4 -0.4 -0.   1.4 -0.6 -0.5  1.3 -0.1 -0.2 -0.4 -0.5 -0.4 -0.6 -1.3 -0.6 -0.3 -0.2 -0.6 -0.2 -0.1 -0.  -0.1 -3.8  0.5  0.   5.1 -0.3 -0.9 -0.5 -0.5 -0.9 -0.4 -0.4  6.8 -0.3 -0.3 -0.6 -0.3  0.4 -0.6 -1.2  4.2  1.7 -0.3 -0.2 -0.6  4.  -0.1  0.8 -0.3  2.4 -0.2 -0.2  1.5 -1.5  0.9 -3.8 -0.1 -1.6 -0.1 -0.1 19.9  3.2  1.  -0.4 -1.1 -0.1 17.6 -0.3 -2.9 -0.2 -0.2 -1. ]
ty_50sample [[8 6 5 2 0 3 1 4 4 9]
 [5 4 1 6 9 0 7 8 3 2]
 [6 1 4 7 0 9 5 8 3 2]
 [2 1 0 6 5 4 8 7 9 3]
 [1 5 8 0 4 3 2 9 7 6]
 [7 1 3 4 2 6 0 5 8 9]
 [1 5 0 8 9 2 7 3 4 6]
 [9 6 2 4 7 5 1 3 8 0]
 [5 2 9 1 6 8 4 0 7 3]
 [6 9 3 1 2 2 0 5 4 7]]
tt_50sample [[8 6 5 2 0 3 7 1 4 9]
 [5 4 1 6 9 0 7 8 2 3]
 [6 1 4 7 0 9 5 8 2 3]
 [2 1 0 6 5 4 8 7 9 3]
 [1 5 8 0 4 3 2 9 7 6]
 [7 1 3 4 2 6 0 5 8 9]
 [1 5 0 8 9 2 7 3 4 6]
 [9 6 2 4 7 5 1 3 8 0]
 [5 2 9 1 6 8 4 0 7 3]
 [6 9 3 1 2 8 0 5 4 7]]
vm  [-0.5 -0.  -1.  -3.5 -1.3 -0.2 -0.1 -0.2 -0.6 -0.2  8.7 -0.2 -0.4 -0.4  6.7 -0.5  0.6 -0.3  0.3  5.2 -0.8 -0.5 -0.3  0.8 -2.   4.  -0.1 -0.1 -1.7 -2.9  1.5 -0.3 -0.1 -0.5 -0.2 -0.3  2.6  4.7 -3.2 -0.1 -0.3  4.   0.4 -0.4 -0.5 -0.6 -3.5 -0.9 -0.4 -0.8 -0.5  0.1 -0.3 15.6  0.3 -0.7 -0.4  7.3  1.  -0.3  8.5 -0.6  1.  -0.1  1.  -0.4 -0.1  0.8 -0.3 -0.3 -0.4  5.9 -0.4 -0.7 -7.3 -0.3 -0.3 -0.1 -0.5  0.7 -3.1 -0.4  0.7 -0.7 -0.6  3.8 -0.7 -0.2  0.5 -0.1 -0.  -0.5 -0.3  1.8 -0.4 -0.4 -0.  -3.  -0.4 -0.7  0.2 -1.1 -0.4 -0.1 -0.   1.3 -3.6  1.3  0.5  6.3  0.7  0.3 -0.2 -0.   2.8 -3.1 -0.2 -0.2  0.8  1.6 -0.4 -2.8 -0.1  1.9 -0.1  8.1 -0.2 -4.   2.1  8.8 -0.2 -0.1 -0.5  1.7  6.2  4.8 -0.1 -0.2  0.7 -0.5 -0.7 -1.5 -0.9 -0.5 -0.1  0.8 -0.5 -0.1  7.1 -0.4  1.4  0.4 -0.7 -0.4 -0.6 -0.3 -0.4  1.6 -0.1 -0.4 -0.1 -1.   0.8 -0.2  0.1 -0.5 -0.4 -0.4 -0.2  0.  -0.2  0.4 -0.2 -0.1 -0.6 -1.8 -0.8 -0.4  5.9 -0.2 -1.2 -0.1  0.5 -1.8 -0.2 -0.5 -0.5 -0.   0.3  7.4 -0.  -0.4  0.3 -1.5 -3.1  0.3 -2.1 -0.7 -0.1 -0.  -0.2 -0.3 -0.1 -0.6 -0.2 -3.7 -0.1 -0.  -3.8 -0.  -0.5 -1.9 -0.4  3.5  0.2 -0.3  1.8 -0.6 -1.1 -0.3 -0.4 -0.2  1.2 -1.1  0.6 -1.8  0.6  1.2 -0.3 -0.5 -0.6  2.5 -0.7 -2.   1.6  1.6  1.4 -2.5 -0.6 -7.1 -0.  -2.7 -0.3 -0.2 10.   5.3 -0.4 -0.5 -0.6  0.9  7.4 -0.  -1.9  0.3 -0.5 -2.5]
vy_50sample [[0 5 2 1 3 6 4 8 7 9]
 [9 5 3 1 7 0 6 4 2 8]
 [0 3 3 2 6 5 9 4 8 1]
 [7 6 1 5 0 2 3 4 4 9]
 [6 8 0 0 9 7 2 2 1 3]
 [3 7 7 4 5 8 6 0 2 9]
 [6 3 4 5 5 7 2 0 1 9]
 [4 0 1 9 7 3 6 2 5 8]
 [6 2 1 9 5 0 7 3 4 8]
 [2 0 5 3 7 1 8 9 4 6]]
vt_50sample [[0 5 2 1 3 6 4 8 7 9]
 [9 5 3 1 7 0 6 4 2 8]
 [0 7 3 2 6 5 9 4 8 1]
 [7 6 1 5 0 2 3 4 8 9]
 [8 6 0 5 9 4 7 2 1 3]
 [3 1 7 4 5 8 6 0 2 9]
 [6 3 4 5 8 7 2 0 1 9]
 [4 0 1 9 7 3 6 5 2 8]
 [6 2 1 9 5 0 7 3 4 8]
 [2 0 5 3 7 1 8 9 4 6]]
Epoch 34210: Training cost= 0.2642, Training acc= 0.8449, Validation cost= 0.2693, Validation acc= 0.8450
Epoch 34220: Training cost= 0.2699, Training acc= 0.8450, Validation cost= 0.2368, Validation acc= 0.8450
Epoch 34230: Training cost= 0.3153, Training acc= 0.8450, Validation cost= 0.2887, Validation acc= 0.8450
Epoch 34240: Training cost= 0.2641, Training acc= 0.8450, Validation cost= 0.2631, Validation acc= 0.8451
Epoch 34250: Training cost= 0.2678, Training acc= 0.8450, Validation cost= 0.2882, Validation acc= 0.8451
Epoch 34260: Training cost= 0.3502, Training acc= 0.8450, Validation cost= 0.2370, Validation acc= 0.8451
Epoch 34270: Training cost= 0.2641, Training acc= 0.8450, Validation cost= 0.2891, Validation acc= 0.8451
Epoch 34280: Training cost= 0.3043, Training acc= 0.8450, Validation cost= 0.2436, Validation acc= 0.8451
Epoch 34290: Training cost= 0.2292, Training acc= 0.8451, Validation cost= 0.2647, Validation acc= 0.8451
Epoch 34300: Training cost= 0.2456, Training acc= 0.8451, Validation cost= 0.2934, Validation acc= 0.8451
tm  [ 0.9 -0.6  3.5  3.1 -1.9 -0.3 -0.2 -0.  -0.1 -0.5 -0.8 -0.3 -0.2 -0.1  3.  -0.8 -0.6 -0.2  0.3 -0.5 -1.2 -0.2  1.4 -0.2 -0.9  3.2 -0.3 -0.5 -0.7 -0.5  1.6 -0.2 -0.7  6.4  0.4  0.2  0.5 -0.1  5.6 -0.6  0.  -0.9 -0.4  1.9 -0.3  1.4  1.8 -0.1  7.3  2.4 -0.4 -0.1  0.5 -1.  -0.1 -0.2 -0.6 -1.9  2.5 -0.3 -1.3 -0.  -0.4  1.  -0.2  0.2  0.2 -0.2  2.2 -0.  -0.1  2.3  0.8  2.  -1.  -0.5 -0.9 -0.7  0.6 -0.   4.9  0.1  0.2  0.2 -1.4 -0.8  6.6 -0.2 -0.4 -0.7  0.1  0.2 -0.3 -1.3 -0.2  0.3 -0.7 -2.2 -0.2  0.5  0.8  5.6 -1.1 -0.1 -0.2  1.6 -0.1  1.4 -0.3 -1.3 -0.7 -0.4  0.5 -0.6  3.2 -0.5 -0.1  0.  -0.4 -0.2 -0.1  5.  -0.2 -0.4 -0.1  3.4 -0.2  6.2  2.4 -0.6  1.5 -0.5 -0.  -0.6 -2.8 -0.3 -0.2 -0.1 -0.2 -0.2  2.  -1.1  0.7  0.2 -0.3 -0.1 -0.  -0.2 -2.2 -0.  -0.2 -0.3  3.6 -0.   0.8 -0.   0.4 -0.3  1.1 -0.  -0.  -0.6 -0.  -0.1 -0.4 -0.6 -0.1  0.6 -0.  -0.  -0.2 -0.4 -0.3 -0.1 -0.2  4.7 -0.4  0.3 -0.2  0.2 -0.3 -0.5 -0.5 -1.9  0.9  0.1  3.7 -0.3 -0.1  1.5  0.1 -0.2 -0.2 -0.7 10.6 -1.   1.1 -0.8  0.  -0.1  0.1 -0.2 -0.6 -0.5 -0.2 -0.2 -0.2 -0.3  5.  -0.2 -0.1 -0.4 -1.4 -1.3 -1.  -0.4 -0.7 -0.8 -0.   1.5 -0.3 -0.  -0.2 -1.1  0.  -0.3 -1.5 -0.3 -0.   4.9 -0.2 -1.3  0.4  2.8  1.8 -0.4  1.2  1.4  5.2 10.6 -0.1  3.7 -0.1 -0.1 -0.3 -1.4 -0.2  1.4 -1.4 -0.5 -1.5 -0.2  4.2 -0.2  3.2  4.8]
ty_50sample [[7 9 0 4 8 3 6 2 5 1]
 [0 3 8 5 2 4 9 7 1 6]
 [4 3 2 9 5 6 7 8 1 0]
 [8 6 1 0 4 7 9 5 3 2]
 [5 9 1 8 6 2 4 3 0 7]
 [2 1 7 4 0 8 5 3 9 6]
 [9 9 5 2 7 3 0 6 8 4]
 [6 0 8 5 5 9 1 4 2 2]
 [7 3 9 9 5 4 1 0 6 2]
 [6 4 5 8 3 2 7 0 1 9]]
tt_50sample [[7 9 0 4 8 3 6 2 5 1]
 [0 3 8 5 2 4 9 7 1 6]
 [4 3 2 9 5 6 7 8 1 0]
 [8 6 1 0 4 7 9 5 3 2]
 [5 9 8 1 6 2 4 3 0 7]
 [2 1 7 4 0 8 5 3 9 6]
 [9 1 5 2 7 3 0 6 8 4]
 [6 0 8 3 5 9 1 4 7 2]
 [7 3 9 8 5 4 1 0 6 2]
 [6 4 5 8 3 2 7 0 1 9]]
vm  [-0.9 -0.5 -0.4 -0.9 -1.  -0.3 -0.  -0.1 -0.  -0.4 -2.5  0.1 -0.4  0.2  2.5  0.5  0.1  0.  -0.2  1.6 -1.3 -0.3 -0.3 -0.1 -0.9 -0.1 -0.6 -0.4 -0.3 -2.  -1.3 -0.4  2.3 -4.5 -0.5 -0.3 -0.  -1.2 -5.  -0.6  1.2 -3.6 -1.3 -1.2 -0.6 -0.3 -2.1 -0.3 -0.4 -0.6 -0.6 -0.3 -0.5  6.4 -1.2 -0.2 -0.8 -0.8  5.1  5.   6.3 -0.4 -0.4 -0.2 -0.7 -0.6 -0.1  0.2  0.5 -0.1 -0.  -0.9  0.8 -0.4 -6.2 -0.1 -0.2 -0.3 -0.2 -0.2 -5.6  0.3 -0.   1.4 -0.5 -3.9 -1.  -0.3 -0.3 -0.6 -0.3 -0.2  0.5 -0.2 -0.4 -0.3 -0.5 -3.1 -0.6 -0.5  1.6 -2.7 -0.1 -0.4 -0.1 -0.2 -3.  -0.8 -0.7  2.  -0.1 -0.2 -0.1 -1.   2.3  2.5 -0.2  2.2 -0.1 -0.6 -0.4 -1.5 -0.7 -0.  -0.3  2.8  0.1 -1.   3.  13.6 -0.1 -0.4 -0.  -0.4 13.7  4.2 -0.1 -0.1 -0.1 -0.4 -0.2 -0.4 -0.4 -0.4 -0.1 -0.2 -0.3 -0.1 -0.2 -0.5 -0.3 -0.   1.  -0.3 -0.2 -0.1 -0.5 -0.5 -1.2 -0.4 -0.3  1.5 -0.2 -0.2  0.3 -0.1 -0.2  2.2 -0.1 -0.  -0.3 -0.2 -0.   0.2 -0.2  1.9 -1.8 -0.4  8.1 -0.2  2.6 -0.4 -0.  -1.4 -0.3  0.7 -0.4 -0.1 -0.3  6.1 -0.2 -0.2 -0.5 -1.2 -2.1 -1.1 -1.6 -0.8 -0.2 -0.1 -0.1 -0.1 -0.3 -0.4 -0.2 -3.7 -0.4 -0.2 10.2 -0.3 -0.8  0.3 -1.   3.  -0.3 -0.5  5.6 -0.8 -0.4  1.2 -0.3 -0.3 -0.2 -0.9 -0.2  1.7 -1.2  0.4 -0.3  1.8  0.1  2.  -0.4  3.7 -0.8  1.   1.2 -1.8  0.8  0.2  0.3 -0.  -0.1  0.2 17.5  3.1  0.9 -0.1 -1.1 -0.  14.9 -0.2 -3.2 -0.1  5.1 -3.7]
vy_50sample [[3 6 8 1 0 2 4 7 5 9]
 [7 8 9 3 0 4 2 5 6 1]
 [7 4 5 3 1 6 2 9 0 8]
 [2 4 6 8 0 3 1 7 9 5]
 [9 1 5 6 6 8 3 0 2 4]
 [4 7 1 9 6 5 3 8 8 2]
 [5 3 8 0 4 1 7 6 2 9]
 [2 5 8 4 9 0 1 3 7 6]
 [7 0 1 3 4 5 9 8 8 6]
 [1 2 9 0 5 7 6 4 3 8]]
vt_50sample [[3 6 8 1 0 2 4 7 5 9]
 [7 8 9 3 0 4 2 5 6 1]
 [7 4 5 3 1 6 2 9 0 8]
 [2 4 6 8 0 1 3 7 9 5]
 [9 1 5 6 7 8 3 0 2 4]
 [4 7 1 9 6 5 3 0 8 2]
 [5 3 8 0 4 1 7 6 2 9]
 [2 5 8 4 9 0 1 3 7 6]
 [7 0 1 3 4 5 9 2 8 6]
 [1 2 9 0 5 7 6 4 3 8]]
Epoch 34310: Training cost= 0.2757, Training acc= 0.8451, Validation cost= 0.3224, Validation acc= 0.8452
Epoch 34320: Training cost= 0.2157, Training acc= 0.8451, Validation cost= 0.2777, Validation acc= 0.8452
Epoch 34330: Training cost= 0.2918, Training acc= 0.8451, Validation cost= 0.3148, Validation acc= 0.8452
Epoch 34340: Training cost= 0.2570, Training acc= 0.8451, Validation cost= 0.2823, Validation acc= 0.8452
Epoch 34350: Training cost= 0.3097, Training acc= 0.8451, Validation cost= 0.2662, Validation acc= 0.8452
Epoch 34360: Training cost= 0.2225, Training acc= 0.8451, Validation cost= 0.3201, Validation acc= 0.8452
Epoch 34370: Training cost= 0.3111, Training acc= 0.8452, Validation cost= 0.2839, Validation acc= 0.8452
Epoch 34380: Training cost= 0.2976, Training acc= 0.8452, Validation cost= 0.2718, Validation acc= 0.8452
Epoch 34390: Training cost= 0.2809, Training acc= 0.8452, Validation cost= 0.2495, Validation acc= 0.8453
Epoch 34400: Training cost= 0.2568, Training acc= 0.8452, Validation cost= 0.2666, Validation acc= 0.8453
tm  [-0.4 -0.7 -0.6 12.  -1.1 -0.  -0.1 -0.2  0.8  2.2  9.8 -0.6  0.3 -0.2 -2.6 -0.4 -0.1 -0.5 -0.2 -1.4 -1.2  0.3  2.  -0.3 -0.7  2.9 -0.  -0.5 -1.3 -1.6  2.3 -0.7  1.8  1.6  0.1 -0.   1.9  2.2  3.8 -0.4  2.4  0.4 -1.  -0.   0.3 -0.4 10.1 -0.8 -0.   5.  -0.3 -0.1 -0.1  0.7  0.7  3.2 -0.6 -1.5  3.4 -0.4 -0.8 -0.6  0.  -0.1  3.1 -0.8 -0.1  0.7 -0.3  0.2 -0.1  4.3 -0.2 -0.7 -0.1 -0.2 -0.4 -0.   0.  -0.2 17.4  0.6 -0.5 -0.4 -0.6  0.  -0.1 -0.1  0.2 -0.4  0.1 -0.3 -0.3 -0.7 -0.4  0.3 -0.5 -0.8 -0.1 -0.3 -0.9  3.8 -0.3 -0.  -0.1 -0.1 -0.2  2.   0.9 -1.8 -0.2 -0.2 -0.1 -0.3  5.4 -2.7  1.4 -0.3 -0.1  1.5 -0.3  5.8 -0.4 -0.1 -0.2 -3.1 -0.2  1.1 -0.3 -2.9 -0.4  0.6 -0.2  0.8  8.9 11.5 -0.3 -0.1 -0.4 -0.6 -0.8 -0.7 -1.1 -0.2 -0.2 -0.3 -0.2  0.2 -0.7 -0.3 -1.1  0.  -0.4 -0.5 -0.  -0.1  0.2  0.5 -0.6 -0.6 -0.1 -0.7  0.6 -0.1 -0.1 -0.7 -0.7 -0.1 -0.3 -0.  -0.1 -0.3 -0.   0.  -0.2  2.2 -1.2  1.3 -0.4 -0.2  1.6 -0.5 -0.1 -1.2 -0.1 -0.2  0.3 -0.2 -0.   5.6 -0.5 -0.3 -0.3 -0.7  7.2  0.2 -0.1 -1.3  0.5  0.3  1.3 -0.1 -0.3 -0.2 -0.3  4.8 -0.1 -0.1  5.1 -0.4 -0.1 -1.3 -0.4  0.9 -0.4  0.4  1.9 -1.1 -0.5  1.2 -0.1 -0.3 -0.2 -1.1  4.3 -1.6  0.9 -0.   1.4 -0.4  0.3 -0.4  0.1  3.1  0.4  2.1  2.  -0.1  0.1 21.4 -0.2  7.9 -0.1 -0.2 -3.6 -2.9  0.3 -0.3 -1.1 -0.4 -4.6 -0.1  2.7 -0.2 -1.6 13.5]
ty_50sample [[0 2 9 6 1 4 7 8 3 5]
 [1 1 2 0 7 6 3 3 8 5]
 [9 0 6 7 2 3 1 4 5 8]
 [7 6 1 2 4 9 3 3 5 5]
 [7 6 0 9 2 3 8 5 1 4]
 [6 0 7 4 1 2 8 9 3 5]
 [6 0 3 5 2 8 4 7 1 9]
 [7 0 9 8 6 4 1 3 2 5]
 [1 3 0 6 4 2 9 8 5 7]
 [8 0 7 1 3 5 9 4 2 6]]
tt_50sample [[0 2 9 6 1 4 7 8 3 5]
 [1 4 2 0 7 6 3 9 8 5]
 [9 0 6 7 2 3 1 4 5 8]
 [7 6 1 2 4 9 3 8 0 5]
 [7 6 0 9 2 3 8 5 1 4]
 [6 0 7 4 1 2 8 9 3 5]
 [6 0 3 2 5 8 4 7 1 9]
 [7 0 9 8 4 6 1 3 2 5]
 [1 3 0 6 4 2 9 8 5 7]
 [8 0 7 1 3 5 9 4 2 6]]
vm  [-0.7 -0.1  3.8 -0.6 -1.5 -0.3 -0.4 -0.2 -0.2 -0.7  1.8 -0.2 -0.1 -0.3  5.5  0.2  0.  -0.5  0.4 -1.2 -1.2 -0.1 -0.4 -0.3 -0.8 -0.2 -0.1 -0.   1.1  3.5  4.9 -0.1 -0.  13.6 -0.1 -0.2  0.3 -1.4 -0.6 -0.2 -0.3  5.   2.7  0.6 -0.  -0.1  1.9  0.3  0.2 -1.6 -0.4 -0.3 -0.6 -1.6 -1.3 -0.4 -0.7  4.4 -0.4 -2.3  1.1 -0.3 -0.2 -0.4  1.4 -0.1 -0.1 -0.3  0.4 -0.1 -0.3 -1.3 -0.5 -0.2 -2.3 -0.2 -0.4 -0.3 -0.3 -0.1 13.9 -0.3 -0.4 -0.1 -0.4  6.2  2.6 -0.2 -0.2 -0.1 -0.5 -0.3 -0.5  0.9 -0.4 -0.3  0.7 -1.8 -0.4 -0.2  3.8  5.2 -0.1 -0.1 -0.  -0.3 -1.5  2.2 -0.1 -1.5 -0.4 -0.1 -0.1 -1.  -0.4  8.6 -0.2 -0.2 -0.1 -0.2 -0.2  6.1 -0.  -0.  -0.2  7.1 -0.2  8.   1.7  0.2  0.9 -0.3 -0.1 -0.5 -1.3 14.2 -0.2 -0.1 -0.5 -0.4  1.7  0.9  1.8 -0.3 -0.1 -0.3 -0.3 -0.1  2.8  0.   0.6 -0.1 -0.9 -0.2 -0.5 -0.2 -0.2 -0.5 -0.8 -0.4 -0.1  0.6 -0.2 -0.1 -0.1  0.4 -0.3 -0.3 -0.1 -0.2 -0.1 -0.2 -0.  -0.3  0.3 -0.1 -1.  -0.7  1.7  0.4 -2.5  0.3 -0.5 -1.3 -0.2 -0.3  0.  -0.9 -0.3 -1.   0.1 -0.1 -0.4 -0.6  1.  -0.3 -0.3  0.4 -0.2  0.8 -0.1 -0.1  0.6 -0.5 -0.2 -2.1 -0.3 -0.  -5.2 -0.3 -0.6  2.8 -0.6  0.6  0.4 -0.1  0.1 -0.8 -0.2 -0.4 -0.3 -0.  -0.3 -0.8  1.8  0.  -1.7 -0.7 -1.2  2.4 -0.8  0.3 -0.1 -2.6 -0.3 -0.4 -0.1 -0.5  0.8 -2.6 -0.1 -1.  -0.1 -0.2 -2.7 -0.1 -0.3 -0.5 -1.   0.1 -3.7 -0.1 -0.5 -0.1  3.9  1.9]
vy_50sample [[5 7 6 4 1 9 3 0 2 8]
 [1 8 3 7 2 6 9 4 5 0]
 [4 7 0 2 8 6 9 3 5 1]
 [8 2 7 9 5 3 6 1 4 0]
 [2 3 5 7 1 4 9 8 6 0]
 [1 7 9 9 6 0 2 8 4 3]
 [0 5 6 2 7 7 1 4 8 3]
 [8 9 5 0 6 7 1 3 2 4]
 [5 9 2 7 4 4 3 6 1 0]
 [1 3 4 0 5 6 2 7 7 9]]
vt_50sample [[5 7 6 4 1 9 3 0 2 8]
 [1 8 3 7 2 6 9 4 5 0]
 [4 7 0 2 8 6 9 3 5 1]
 [8 2 7 9 5 3 6 1 4 0]
 [2 3 5 7 1 4 9 8 0 6]
 [1 5 7 9 6 0 2 8 4 3]
 [0 5 6 2 9 7 1 4 3 8]
 [8 9 5 0 6 7 1 3 2 4]
 [5 9 2 7 4 8 3 6 1 0]
 [1 3 4 0 5 6 2 8 7 9]]
Epoch 34410: Training cost= 0.2487, Training acc= 0.8452, Validation cost= 0.2510, Validation acc= 0.8453
Epoch 34420: Training cost= 0.2808, Training acc= 0.8452, Validation cost= 0.2446, Validation acc= 0.8453
Epoch 34430: Training cost= 0.2556, Training acc= 0.8452, Validation cost= 0.2669, Validation acc= 0.8453
Epoch 34440: Training cost= 0.2253, Training acc= 0.8453, Validation cost= 0.2738, Validation acc= 0.8453
Epoch 34450: Training cost= 0.2713, Training acc= 0.8453, Validation cost= 0.2950, Validation acc= 0.8453
Epoch 34460: Training cost= 0.2557, Training acc= 0.8453, Validation cost= 0.3018, Validation acc= 0.8454
Epoch 34470: Training cost= 0.2708, Training acc= 0.8453, Validation cost= 0.3456, Validation acc= 0.8454
Epoch 34480: Training cost= 0.3017, Training acc= 0.8453, Validation cost= 0.2004, Validation acc= 0.8454
Epoch 34490: Training cost= 0.2229, Training acc= 0.8453, Validation cost= 0.2512, Validation acc= 0.8454
Epoch 34500: Training cost= 0.2304, Training acc= 0.8453, Validation cost= 0.2670, Validation acc= 0.8454
tm  [-1.2  0.4  2.9  9.4 -2.3  0.  -0.2 -0.1 -1.5 -1.   1.8  0.3 -0.1 -0.3 -1.  -2.1 -0.  -0.4  0.8 -0.6 -0.6 -0.2 -0.5  0.7 -1.6  6.1  0.  -0.2 -2.3 -1.1  2.  -0.2 -0.6  5.8 -0.1  0.8  5.8 -0.4  8.4 -0.1  2.2 -0.1  4.1  0.9  0.3 -0.2  4.5  0.8 -0.8 -1.7 -0.4  0.2  1.5 -2.   3.9  1.4 -1.   3.9 -1.7 -0.3  1.5 -0.1 -0.2 -0.  -0.5  2.8  0.2 -0.8  0.7  0.4 -0.1  7.9 -0.2 -0.4  3.9  0.4  0.5  0.8  0.1 -0.2 14.4 -0.2 -0.2 -0.5  1.2  0.1 -1.  -0.3 -0.2 -0.2 -0.1  0.1  0.1  3.7 -0.2 -0.1  0.5  0.1 -0.3 -0.2  2.7 -0.3  0.5 -0.4 -0.2  0.5  1.5  1.7  0.7 -1.2 -0.7  0.1 -0.   2.4  0.1 -3.4  1.6 -1.8 -0.4 -0.1  0.1  6.  -0.4 -0.2 -0.  -1.3 -0.2  8.9 -1.6 -0.8 -0.9  0.1 -0.7 -0.7 -1.   4.6 -0.3 -0.1  0.4 -0.1  2.4 -1.5  1.6 -0.1 -0.2 -0.1 -0.1 -0.2  2.5 -0.  -0.7 -0.1 -1.2  0.6 -0.5  0.1 -0.2 -0.4  1.9  0.1 -0.4 -1.2  0.5  0.2 -0.2 -0.8 -0.1 -1.1  0.2 -0.1 -0.1 -0.3 -0.3 -0.3 -0.1  0.  -0.5  0.2 -0.6 -0.  -1.2  0.9 -0.1 -1.8 -0.4  1.2 -1.3 -0.5  0.4  2.5 -0.2 -0.1  0.1 -1.2  0.8  7.5  1.5  0.5 -0.1 -0.1  0.  -0.  -0.1 -0.2  0.2  3.3 -0.2 -0.4 -1.9 -0.   0.5 -2.7 -0.1  6.7 -0.5 -0.5 -0.  -0.6 -0.5 -0.6 -0.4 -0.   0.  -0.4 -0.7 -2.  -1.8 -0.6  0.9 -1.3 -0.3 -1.1 -0.4 -1.   4.5 -0.5 -0.3  3.1 -0.2  7.  -0.2  2.7 -0.1 -0.  -2.9 -1.7 -0.  -0.1 -0.5 -0.4 -3.7 -0.1  4.9 -0.1  6.1  3.8]
ty_50sample [[0 9 1 3 5 7 4 6 2 8]
 [7 8 0 2 6 3 5 9 1 4]
 [6 5 7 8 0 9 4 1 2 3]
 [0 8 4 1 9 5 2 6 3 3]
 [7 9 4 3 8 2 1 0 6 5]
 [6 8 4 5 3 2 1 0 7 9]
 [6 7 8 3 2 4 0 9 1 5]
 [7 9 6 0 2 3 1 8 4 5]
 [8 0 2 6 1 5 7 4 9 3]
 [8 2 7 6 1 1 4 3 0 5]]
tt_50sample [[0 9 1 3 5 7 6 4 2 8]
 [7 8 0 2 6 3 5 9 1 4]
 [6 5 7 8 0 9 4 1 2 3]
 [0 8 4 9 1 5 2 6 3 7]
 [7 9 4 3 8 2 1 0 6 5]
 [6 8 4 5 3 2 1 0 7 9]
 [6 7 8 3 2 4 0 9 1 5]
 [7 9 6 0 2 3 1 8 4 5]
 [8 0 2 6 1 5 7 4 9 3]
 [8 2 7 6 1 9 4 3 0 5]]
vm  [ 1.6 -0.7 -2.6 -3.4 -1.2  0.2 -0.1 -0.1 -0.1 -0.2  4.4 -0.7 -0.1 -0.2  1.5 -1.  -0.1 -0.6 -0.5  1.  -1.3 -0.  -0.4 -0.1 -1.4  3.3 -0.2  0.1 -1.3 -1.6  3.5 -0.3  0.1 -0.8 -0.1 -0.   1.  -0.7 -3.8 -0.5 -0.  -1.  -0.6 -0.1 -0.2 -0.1 -1.5 -0.2  3.9 -1.4 -0.4 -0.2 -0.4  7.   1.3 -0.2 -0.7 -1.3  4.4 -1.3  1.1 -0.  -0.1  0.7  1.5 -0.2 -0.   0.2  0.8  0.2  0.   4.  -0.4 -0.5 -4.4  0.4 -0.8  0.8 -0.1 -0.1 -1.2  0.1 -0.2  0.6 -1.2 -1.   5.8  0.8 -0.2 -0.3 -0.  -0.3 -0.4 -0.6 -0.5 -0.2  0.2 -2.9 -0.1 -0.1  0.6 -1.2 -1.2 -0.2 -0.1 -0.3 -2.7  2.3  1.2  1.9 -0.5  0.3 -0.2 -0.6  5.3 -2.1 -0.5  1.6 -0.2 -0.1 -0.  -0.9  0.5 -0.4 -0.2  1.8 -0.5 -1.3  2.7  9.1  1.9 -0.4 -0.4 -0.5 12.4 11.5 -0.1 -0.1 -0.4 -0.3 -0.4 -1.3 -0.2 -0.1 -0.1 -0.1 -0.1 -0.1  2.5 -0.3  1.9 -0.2  2.5  0.  -0.  -0.1  0.1  1.  -1.6 -0.6  0.4  0.5  0.2 -0.2  0.3 -0.9 -0.5 -0.1 -0.2 -0.1 -0.  -0.2 -0.2  0.1 -0.  -0.3 -1.4 -0.6  6.  -0.1 -0.4 -0.5 -0.8 -1.9  0.  -0.3  1.7  0.1  0.4  4.2 -0.1 -0.5 -0.4 -0.9  2.  -0.8 -1.5 -1.4 -0.   0.3 -0.2 -0.2 -0.3 -0.2 -0.2 -3.5  0.5 -0.2  2.   0.4 -0.7 -1.6 -0.7 -0.9 -0.7  0.6  0.9 -1.2 -0.4 -0.  -0.3 -0.3 -0.2 -1.4  3.1 -1.2 -0.7 -0.1 -0.2  4.9 -0.   0.7 -0.3  1.6  3.3  5.1  3.3 -1.3  2.5 -0.8 -0.1 -0.4 -0.1 -0.1  5.3  3.  -0.  -0.5 -1.4 -0.3  2.4 -0.1 -2.3 -0.3  1.5 -2.2]
vy_50sample [[0 6 4 3 2 8 5 7 1 9]
 [2 1 8 0 7 6 9 5 3 4]
 [2 7 9 9 8 6 0 5 1 4]
 [5 5 4 6 1 7 2 2 0 8]
 [1 3 7 5 8 2 9 0 4 6]
 [4 3 2 5 0 7 9 1 6 8]
 [4 1 5 7 7 2 3 6 8 9]
 [3 2 5 9 7 1 4 0 8 6]
 [1 2 7 5 8 0 4 3 6 9]
 [2 6 4 1 3 9 7 0 5 8]]
vt_50sample [[0 6 4 3 2 8 5 1 7 9]
 [2 1 8 0 7 9 6 5 3 4]
 [2 7 9 3 8 6 0 5 1 4]
 [3 5 4 6 1 7 2 9 0 8]
 [1 3 7 5 8 2 9 0 4 6]
 [4 3 2 0 5 7 1 9 6 8]
 [4 1 5 0 7 2 3 6 8 9]
 [3 2 5 9 7 1 4 0 8 6]
 [1 2 7 5 8 0 4 3 6 9]
 [2 6 4 1 3 9 7 0 5 8]]
Epoch 34510: Training cost= 0.2763, Training acc= 0.8454, Validation cost= 0.3285, Validation acc= 0.8454
Epoch 34520: Training cost= 0.2800, Training acc= 0.8454, Validation cost= 0.2778, Validation acc= 0.8454
Epoch 34530: Training cost= 0.2566, Training acc= 0.8454, Validation cost= 0.3123, Validation acc= 0.8455
Epoch 34540: Training cost= 0.3234, Training acc= 0.8454, Validation cost= 0.3086, Validation acc= 0.8455
Epoch 34550: Training cost= 0.2785, Training acc= 0.8454, Validation cost= 0.2833, Validation acc= 0.8455
Epoch 34560: Training cost= 0.3428, Training acc= 0.8454, Validation cost= 0.2299, Validation acc= 0.8455
Epoch 34570: Training cost= 0.3101, Training acc= 0.8454, Validation cost= 0.2964, Validation acc= 0.8455
Epoch 34580: Training cost= 0.2473, Training acc= 0.8455, Validation cost= 0.2566, Validation acc= 0.8455
Epoch 34590: Training cost= 0.2502, Training acc= 0.8455, Validation cost= 0.2505, Validation acc= 0.8455
Epoch 34600: Training cost= 0.2063, Training acc= 0.8455, Validation cost= 0.2601, Validation acc= 0.8455
tm  [ 1.6  0.7 10.9 14.2 -1.5 -0.3 -0.4 -0.5 -1.2  0.2  1.1 -0.5 -0.1 -0.2  6.6 -0.1 -0.7 -0.5 -0.9 -2.  -0.7 -0.6 -0.3 -0.2 -0.4 -0.9 -0.5  0.1 -0.5  4.3 -1.9  1.2 -0.9  5.2 -0.1 -0.6  1.1  5.  14.9 -0.1 -0.1  4.5  1.7  1.1 -0.1  0.2  9.7 -0.1  3.2  8.2 -0.4 -0.3 -0.7  3.7 -0.9 -0.8  0.4  7.6 -1.9  5.6 -1.8 -0.9 -1.6 -0.9 -0.2 -0.6 -0.3  1.8  2.5 -0.6 -0.  -0.2 -0.3 -0.5 -1.5 -1.1 -0.7 -0.1  0.3 -0.8 -1.2 -0.  -0.4 -0.3 -1.6  3.2  3.2 -0.3 -0.3 -0.8  1.1 -0.1  0.   3.6 -0.4  2.2 -0.8 -0.8  1.5 -0.3 -0.4  4.9 -0.6  0.3 -0.2 -0.3 -1.4 -0.6  0.9 -1.9  2.2 -0.4 -0.2 -0.3 -1.2 -0.3 -1.  -0.7 -0.1 -0.6 -0.2  5.8 -0.3 -0.6 -0.9  8.  -0.  -0.4 -1.5 -1.9  1.2 -0.6 -0.4  0.8 -7.  -5.5  0.1  0.5  1.8 -1.4 -0.5 -0.6 -0.  -0.2 -0.3 -0.3 -0.8 -0.3 -0.2 -0.2 -1.3 -0.3  4.3  2.   0.1 -0.1  0.9 -0.1  0.6 -0.2 -1.6 -1.7  0.3 -0.4 -0.7  2.1  1.4 -0.8 -0.1 -0.2 -0.4 -0.2 -0.1 -0.2 -0.1  2.2 -0.  -0.8 -1.7 -0.2 -2.7 -1.  -0.1 -0.7 -0.2  0.5  2.5 -0.8 -0.3 -0.8 -0.5 -0.2 -0.8 -0.6 12.8  5.9 -0.4  3.9 -0.3 -0.6 -0.5 -0.4 -1.2 -0.  -0.6 -0.8 -0.3 -0.2 -0.3 -0.3 -0.4 -0.8 -0.9 -2.6 -0.2 -0.7 -0.1 -0.6 -0.3 -0.3 -0.   0.1 -0.6 -0.8 -1.3  0.9 -0.7 -0.9  1.1  2.2 -1.4  1.2 -0.6 -0.3 -0.9 -2.7 -0.2 -0.8  0.6 -1.6 -0.6 -0.7 -0.3  1.8  5.  -1.3 -0.2 -0.7 -0.7  0.4  2.1 -0.1  9.8 -0.7  1.5  8.6]
ty_50sample [[7 5 8 2 9 0 3 4 6 1]
 [8 7 1 9 3 6 2 5 0 4]
 [3 1 2 0 8 6 9 7 5 4]
 [8 2 1 4 4 6 3 3 5 7]
 [7 9 8 4 0 1 2 3 5 6]
 [8 6 7 0 2 4 4 3 5 1]
 [3 4 5 0 2 8 7 1 9 6]
 [1 6 5 9 7 0 8 2 4 3]
 [4 2 1 5 7 3 8 9 6 0]
 [6 4 3 5 0 8 1 9 2 7]]
tt_50sample [[7 5 8 2 9 0 3 4 6 1]
 [8 7 1 9 3 6 2 5 0 4]
 [3 1 2 0 8 6 9 7 5 4]
 [8 2 1 4 9 6 0 3 5 7]
 [9 7 8 4 0 1 2 3 5 6]
 [8 6 7 0 2 9 4 3 5 1]
 [3 4 5 0 2 8 7 1 9 6]
 [1 6 5 9 7 0 8 2 4 3]
 [4 2 1 5 7 3 8 9 6 0]
 [6 4 3 5 0 8 1 9 7 2]]
vm  [ 0.1 -0.7 -1.9 -1.5 -0.2 -0.2 -0.1 -0.4  0.9  2.2 -0.8 -0.3 -0.3 -0.2  0.2  6.7  0.9 -0.5 -0.7  0.4 -0.8 -0.3 -0.4 -0.5 -1.1 -0.3 -0.  -0.5  2.3 -0.6 -1.9 -0.5 -0.5 -7.6  0.  -0.5 -1.4  2.5 -3.  -0.4  0.6  2.3 -0.4 -0.5 -0.3 -0.6 -1.8 -0.6  3.2 13.8 -0.3 -0.5 -0.7 15.1 -1.8 -0.1 -0.2  2.   3.6  5.2  2.7 -0.5 -0.2 -0.6 -0.7 -0.8 -0.2  2.5 -0.3 -0.4 -0.4 -1.9 -0.4  0.  -7.1 -0.2 -0.6  2.3 -0.1 -0.7 -7.7  1.  -0.4 -0.2 -2.   3.6  2.8 -0.   0.2 -0.9 -0.  -0.3 -0.3 -0.4 -1.  -0.  -0.4 -3.1 -0.3 -1.2 -0.9 -0.4 -0.9 -0.2 -0.1 -0.6 -2.6 -1.6 -0.   1.5  2.4  0.7  0.1 -1.2 -0.   9.8 -0.7  1.3  0.2 -0.3  0.5 -1.3 -0.5 -0.6 -0.1  0.4 -0.2 -3.7  2.3  3.3  1.2  0.  -0.3  1.3 12.7 -3.3 -0.2 -0.2 -0.2  2.2 -1.2 -0.6 -0.8 -0.1 -0.1 -0.3 -0.3 -0.1  6.9 -0.3  0.5 -0.1  1.9  0.2 -0.4 -0.2 -0.6 -1.3 -0.9 -0.1  0.  -0.5  1.  -0.3  0.6 -0.3 -1.  -0.3 -0.1 -0.  -0.5 -0.5 -0.4 -0.2  0.5 -1.2 -1.5 -0.2  4.3 -0.2 -0.9 -0.4 -0.2 -1.2 -0.5  0.2  1.7 -0.1 -0.8  1.3 -0.2 -0.3 -0.4 -0.8  0.  -1.2 -1.  -0.3 -0.  -0.5  0.2 -0.2  1.   0.2 -0.6 -2.5  0.5 -0.5  7.8 -0.4 -0.7  3.8 -0.8 -1.2 -0.2 -0.4  3.2 -0.7 -1.1 -0.3 -0.4 -0.3 -0.6 -1.2  3.3  1.8 -0.  -0.4 -1.3  2.4 -0.5  1.5 -0.5  3.1 -1.9  2.8 -0.  -2.  -0.1 -2.3 -0.2 -0.8 -0.5  0.4 22.5  1.6  0.4 -0.8 -0.6 -0.1 20.6 -0.1 -1.8 -0.4 -1.4 -0.2]
vy_50sample [[8 2 6 5 4 3 1 0 7 7]
 [0 4 7 8 5 5 3 1 2 6]
 [3 1 7 4 6 5 0 0 2 8]
 [0 1 3 2 6 5 8 9 4 7]
 [6 4 3 1 8 9 7 2 5 0]
 [1 0 5 9 6 4 7 3 3 8]
 [1 0 5 9 2 2 7 4 4 3]
 [0 8 4 5 9 3 2 1 6 7]
 [1 9 5 0 6 8 4 7 2 3]
 [4 2 8 0 9 1 6 7 5 3]]
vt_50sample [[8 2 6 5 4 3 1 0 9 7]
 [0 4 7 8 5 9 1 3 2 6]
 [3 1 7 6 4 5 0 9 2 8]
 [0 1 3 2 6 5 8 9 4 7]
 [6 4 3 1 8 9 7 2 5 0]
 [1 0 5 9 6 4 7 2 3 8]
 [1 0 5 9 2 6 7 8 4 3]
 [0 8 4 5 9 3 1 2 6 7]
 [1 9 5 6 0 8 4 7 2 3]
 [4 2 0 8 9 1 6 7 5 3]]
Epoch 34610: Training cost= 0.2742, Training acc= 0.8455, Validation cost= 0.2434, Validation acc= 0.8456
Epoch 34620: Training cost= 0.2550, Training acc= 0.8455, Validation cost= 0.3029, Validation acc= 0.8456
Epoch 34630: Training cost= 0.3108, Training acc= 0.8455, Validation cost= 0.2172, Validation acc= 0.8456
Epoch 34640: Training cost= 0.2609, Training acc= 0.8455, Validation cost= 0.2542, Validation acc= 0.8456
Epoch 34650: Training cost= 0.2256, Training acc= 0.8456, Validation cost= 0.2337, Validation acc= 0.8456
Epoch 34660: Training cost= 0.3094, Training acc= 0.8456, Validation cost= 0.3000, Validation acc= 0.8456
Epoch 34670: Training cost= 0.2772, Training acc= 0.8456, Validation cost= 0.2812, Validation acc= 0.8456
Epoch 34680: Training cost= 0.2013, Training acc= 0.8456, Validation cost= 0.3303, Validation acc= 0.8457
Epoch 34690: Training cost= 0.2882, Training acc= 0.8456, Validation cost= 0.2520, Validation acc= 0.8457
Epoch 34700: Training cost= 0.2714, Training acc= 0.8456, Validation cost= 0.2473, Validation acc= 0.8457
tm  [-0.6 -0.3 10.9  1.9 -1.8  0.2  0.   0.1 -0.3 -0.4  6.6 -0.3 -0.4 -0.3 12.5 -1.3 -0.   0.2  0.4  1.7 -1.1 -0.4 -1.3 -0.  -1.   3.  -0.5 -0.1 -1.6 -0.9  2.   0.2  0.1 18.1 -0.3 -0.3  1.  -0.6 -1.9 -0.4 -0.1 -1.3 -0.4 -1.3 -0.1 -0.4 -1.2 -0.1  1.5 -3.5 -0.3 -0.2 -0.2  3.4  2.  -1.2 -0.7  3.3  1.8 -1.   4.1 -0.2  0.6  0.2 -0.4 -0.2 -0.1 -0.4  1.8 -0.3 -0.3  4.3  0.3 -0.2 -4.5 -0.2 -0.7 -0.3 -0.2 -0.6  7.9 -0.5  0.5 -0.3 -0.3 -1.  -0.7 -0.  -0.3 -0.4  0.2 -0.2 -0.1  0.3 -0.4 -0.1  0.5 -2.6 -0.4 -0.6  1.4  5.4 -0.4 -0.2 -0.4 -0.3 -1.8  0.7  0.6  0.1  0.8  0.6 -0.1 -0.6  3.5 -1.9 -0.8  0.3  1.  -0.3 -0.2 -0.4 -0.3  0.5 -0.1 15.2 -0.1 -0.   0.2  5.6  0.3 -0.3 -0.  -0.4 -2.5 14.4 -0.2 -0.   0.8  0.2  0.5 -1.4 -0.1 -0.2  0.1 -0.1 -0.6 -0.2 -2.4 -0.1 -0.3 -0.1 -1.3  1.7 -0.5  0.3 -0.4 -0.5 -0.4  2.9 -0.5 -0.4 -0.1 -0.1 -0.2 -0.3 -0.1  0.7 -0.4 -0.3 -0.3 -0.4 -0.2 -0.1 -0.2  5.2 -0.4 -0.2  3.7 -0.3 -0.1 -0.  -0.3 -1.2 -0.2 -0.3  0.4 -0.5 -0.1  2.9 -0.1 -0.  -0.3 -0.6 -0.9  0.5 -1.2 -1.  -0.3 -0.1 -0.5 -0.2 -0.6 -0.1 -0.5 -2.1 -0.3 -0.4 -1.8  0.2 -0.3 -1.1 -0.5  2.1 -0.2 -0.5  5.6 -1.2 -0.6 -0.3 -0.4 -0.2 -0.1 -0.9  1.7 -2.  -1.3  0.8 -1.4  0.7  0.2  0.5 -0.4 -1.2  1.9 -2.4  1.4 -1.2  1.5  0.4  0.6  0.1 -0.2 -0.1 -1.4  0.3 -0.4 -0.7 -0.9  0.6 -2.2 -0.2 -1.3 -0.   4.8 -1.1]
ty_50sample [[7 0 6 3 1 2 5 9 4 8]
 [8 0 7 1 3 6 4 9 5 2]
 [1 7 5 4 3 0 9 6 2 8]
 [1 3 9 8 2 2 6 7 4 0]
 [2 8 5 1 9 0 0 6 4 7]
 [0 5 8 3 6 2 1 7 4 4]
 [6 3 5 8 2 1 4 0 9 7]
 [6 4 2 9 3 5 7 8 0 1]
 [5 3 9 2 4 1 6 7 0 8]
 [3 5 0 1 7 2 6 4 9 8]]
tt_50sample [[7 0 6 3 1 2 5 9 4 8]
 [8 7 0 1 6 3 4 9 5 2]
 [1 7 5 4 3 0 2 9 6 8]
 [1 3 9 8 2 5 6 7 4 0]
 [2 8 5 1 9 3 0 6 4 7]
 [0 5 8 3 6 2 1 9 7 4]
 [6 3 5 8 2 1 4 0 9 7]
 [6 4 2 9 3 5 7 8 0 1]
 [5 3 9 2 4 1 6 7 0 8]
 [3 5 0 7 1 2 6 4 9 8]]
vm  [ 1.6  0.5 -4.1 -0.4 -0.7 -0.2  0.1 -0.2 -1.9 -0.2  6.4 -0.3 -0.4 -0.1 -3.  -0.1 -0.4 -0.3 -0.2 -1.4 -0.7 -0.2 -0.3 -0.4 -1.   0.5 -0.4 -0.2 -1.7  4.3  3.7 -0.2 -0.2 -2.  -0.  -0.2  5.9 -0.3 -0.  -0.5 -0.3 -0.1  1.8  0.6 -0.2 -0.   6.5 -0.1  3.3 -0.7 -0.1 -0.1 -0.2  0.9 -0.5  3.1 -0.5 -2.1 -2.2 -1.9 -2.4 -0.3 -0.9 -0.5 -0.6 -0.4 -0.1 -0.2  0.1 -0.2 -0.2  3.7 -0.3 -0.7  1.2 -0.8 -0.4 -0.2 -0.1 -0.2 11.7 -0.3 -0.6 -0.2 -1.6 -0.3  9.2 -0.2 -0.3 -0.5 -0.1 -0.  -0.1  3.8 -0.2  0.5 -0.8  0.8 -0.  -0.2  0.6 -1.  -0.6 -0.1 -0.  -0.1 -0.8  2.8  0.7 -2.4 -0.6 -0.3 -0.   1.2 -0.7 -1.4  0.4 -1.3  0.2 -0.4  0.6  8.8 -0.1 -0.6 -0.1 -3.8 -0.1  1.4 -2.2 -0.5  0.1 -0.1 -0.  -0.2 13.8 11.1 -0.3 -0.2 -0.9 -0.7 -1.1 -0.7 -0.5  0.  -0.3 -0.3 -0.5 -0.2  2.8 -0.3 -0.2 -0.1  1.8 -0.4  0.3 -0.  -0.1 -0.  -1.6 -0.9 -0.1  0.9 -0.4 -0.1 -0.1 -0.1 -0.5 -0.7 -0.4 -0.1 -0.2 -0.4 -0.1 -0.4  0.4 -0.9 -1.1 -0.4  0.8 -0.2 -1.3 -0.1 -0.  -1.2  0.3  0.5  0.8  1.   0.9 -1.4 -0.3 -0.4 -0.2 -0.7 15.7  8.6  1.7  2.5 -0.  -0.1 -0.  -0.2 -0.2 -0.3 -0.3  0.5 -0.1 -0.2 -0.3 -0.3 -0.4 -1.9 -0.6 -1.   1.3  0.8 -0.3 -0.6 -0.5  0.7 -0.  -0.4 -0.5 -0.7  2.9 -1.  -0.1 -0.7 -0.1  0.9 -0.3 -0.2 -0.1 -0.1  0.5  6.9 -0.2  1.2 -0.9  9.3 -0.   3.1  0.3 -0.1 -2.2 -1.4  0.6 -0.  -0.8 -0.6 -3.1 -0.  -0.2 -0.4 -0.8  3.7]
vy_50sample [[6 6 9 2 0 3 5 8 7 1]
 [4 3 6 9 7 0 8 1 5 2]
 [1 4 9 0 3 7 2 5 8 6]
 [2 2 4 9 7 1 6 3 5 8]
 [1 6 7 3 0 2 4 8 9 5]
 [7 9 4 8 5 0 2 6 3 1]
 [7 8 2 4 3 1 6 0 5 9]
 [8 2 0 7 1 3 9 4 5 6]
 [8 6 4 2 7 9 3 1 5 0]
 [3 5 4 7 6 8 9 1 2 0]]
vt_50sample [[4 6 9 2 0 3 5 8 7 1]
 [4 3 6 9 7 0 8 1 5 2]
 [1 4 9 0 3 7 2 5 8 6]
 [2 0 4 9 7 1 6 3 5 8]
 [1 6 7 3 0 2 4 8 9 5]
 [7 9 4 8 5 0 2 6 3 1]
 [7 8 2 4 3 1 6 0 5 9]
 [8 2 0 7 1 3 9 4 5 6]
 [8 6 4 2 7 9 3 1 5 0]
 [3 5 4 7 6 8 9 1 2 0]]
Epoch 34710: Training cost= 0.3359, Training acc= 0.8456, Validation cost= 0.2568, Validation acc= 0.8457
Epoch 34720: Training cost= 0.2816, Training acc= 0.8457, Validation cost= 0.3225, Validation acc= 0.8457
Epoch 34730: Training cost= 0.2867, Training acc= 0.8457, Validation cost= 0.2798, Validation acc= 0.8457
Epoch 34740: Training cost= 0.2766, Training acc= 0.8457, Validation cost= 0.2745, Validation acc= 0.8457
Epoch 34750: Training cost= 0.2809, Training acc= 0.8457, Validation cost= 0.2680, Validation acc= 0.8458
Epoch 34760: Training cost= 0.3453, Training acc= 0.8457, Validation cost= 0.3264, Validation acc= 0.8458
Epoch 34770: Training cost= 0.3375, Training acc= 0.8457, Validation cost= 0.2479, Validation acc= 0.8458
Epoch 34780: Training cost= 0.2530, Training acc= 0.8457, Validation cost= 0.2627, Validation acc= 0.8458
Epoch 34790: Training cost= 0.2809, Training acc= 0.8457, Validation cost= 0.3168, Validation acc= 0.8458
Epoch 34800: Training cost= 0.2533, Training acc= 0.8458, Validation cost= 0.2581, Validation acc= 0.8458
tm  [-1.  -0.3  4.7  8.5 -2.2 -0.  -0.1 -0.1 -0.7 -0.1 -5.2 -0.2  0.5 -0.4  1.  -1.5 -0.1  0.3 -0.1 -1.  -0.8 -0.3  0.1 -0.  -1.   2.2 -0.5  0.1 -1.5  0.3 -1.2  0.2 -0.  -1.4  0.   0.3  3.2  1.9 12.2 -0.   1.3  4.7  1.9  2.  -0.2 -0.5  6.2 -0.3 -0.5 14.9 -0.5 -0.2 -0.3 -1.8  0.7 -0.1 -0.6  2.3 -1.   4.5  0.4 -0.3 -0.4 -0.3 -1.2 -0.7 -0.3 -0.5  0.1 -0.1 -0.4  4.6 -0.1 -0.5 -0.3  0.4  0.4  1.  -0.3  0.1 -1.4 -0.3 -0.1 -0.2 -0.3  5.3 -0.7 -0.1 -0.1 -0.2  0.3 -0.2 -0.1  0.3 -0.3 -0.4  1.2 -1.  -0.2 -0.3 -0.2  7.2 -0.4 -0.2 -0.2 -0.8 -0.5 -1.1 -1.6 -1.4 -0.3 -0.3 -0.   0.   1.6 -2.4 -0.  -1.1 -0.1 -0.4 -0.2  5.4  0.2 -0.1 -0.1  1.2 -0.1  8.2 -1.3 -2.5 -0.6 -0.1 -0.3 -0.2 -4.1 -5.6 -0.  -0.1 -0.4  1.9  1.6 -1.2  0.5 -0.3 -0.2  0.  -0.2 -0.1 -0.5  0.3 -0.8 -0.2  1.7  0.1 -0.2 -0.4 -0.3  0.   2.5 -0.2 -0.  -1.8 -0.3  0.1 -0.1 -0.4 -0.2 -0.5 -0.4 -0.1  0.4 -0.2  0.1 -0.3 -0.1  1.  -0.4 -0.  -1.3 -0.1 -0.6 -0.3 -0.  -0.9 -0.3 -0.4 -0.5 -0.5 -0.3 -0.3 -0.  -0.3 -0.2 -0.6  2.6  6.1 -0.2 -0.5 -0.1 -0.1 -0.4 -0.1 -0.2 -0.   0.1  1.7 -0.2 -0.   7.2  0.3 -0.  -1.5  0.   4.3 -0.5  0.  -0.5 -0.5 -0.4 -0.5  0.2 -0.  -0.5 -0.6  2.3 -0.5 -1.6 -0.1 -0.4 -0.8 -0.4 -0.3 -0.2  3.1  2.5 -0.8  0.8 -0.1 -0.1  8.6 -0.3  2.7  0.6 -0.2  5.  -2.2 -0.3 -0.6 -0.6 -0.2  2.3 -0.3  7.9  0.6 -0.1 10.8]
ty_50sample [[8 0 7 9 1 5 4 2 6 3]
 [1 4 0 6 3 2 8 9 7 5]
 [6 7 5 3 2 4 1 8 0 9]
 [2 6 8 7 1 4 0 9 3 5]
 [1 3 8 9 0 7 4 6 5 2]
 [8 4 0 3 2 7 6 5 1 9]
 [9 5 4 3 0 8 1 7 6 2]
 [9 1 4 2 0 5 6 7 3 8]
 [3 7 7 0 9 4 5 6 8 1]
 [1 7 6 6 5 3 4 2 9 8]]
tt_50sample [[8 0 7 9 1 5 4 2 6 3]
 [1 4 6 0 3 2 8 9 7 5]
 [6 7 5 3 2 4 1 8 0 9]
 [2 6 8 7 1 4 0 9 3 5]
 [1 3 8 9 0 7 4 6 5 2]
 [8 4 0 3 2 7 6 5 1 9]
 [9 5 4 3 8 0 1 7 6 2]
 [1 9 4 2 0 5 6 7 3 8]
 [3 7 2 0 9 4 5 6 8 1]
 [1 7 6 5 3 0 4 2 9 8]]
vm  [-0.6 -0.6 -2.4 -3.3 -1.4 -0.6  0.4 -0.3 -0.1  1.1 -2.2 -0.2 -0.2  0.4  4.3 -0.1 -0.5 -0.2 -0.6  2.5 -1.4 -0.3  1.8 -0.  -1.1  0.7 -0.1 -0.5 -1.  -0.8 -0.1 -0.3  0.3 -3.8 -0.3 -0.2 -0.1 -1.1 -5.7 -0.5  1.  -0.3 -0.7 -0.4 -0.5  0.  -3.  -0.2  2.3  9.2 -0.4 -0.2 -0.1  7.3 -0.7 -0.4 -0.6 -2.6  5.2  2.5  5.3 -0.  -0.2  0.  -0.8 -0.5 -0.4  0.3 -0.2 -0.3  0.3  0.2 -0.1 -0.2 -6.1 -0.5 -0.3 -0.4  0.3 -0.  -5.6  1.4 -0.   1.1 -0.9 -0.4  3.4 -0.2 -0.3 -0.7  0.1 -0.1  0.6 -1.3 -0.2 -0.3 -0.9 -3.3  0.3 -0.2 -0.4 -0.2 -0.4 -0.2 -0.2 -0.2 -2.4 -0.1 -0.8  2.7 -0.5 -0.2  0.2 -1.   4.  -0.3 -0.7  1.6 -0.2 -0.6 -0.1 -1.6 -0.5 -0.3 -0.2  5.  -0.1 -1.3  3.   5.8 -0.  -0.2  0.6 -0.5 14.5  6.5 -0.3 -0.1 -0.3 -0.4  0.1 -1.  -0.3 -0.4 -0.1 -0.3 -0.3 -0.   0.6 -0.2  1.3 -0.   1.8 -0.5 -0.1  0.2 -0.6 -0.5 -1.3 -0.5  0.7  3.1 -0.2 -0.1  0.2 -0.4 -0.4  1.7  0.3 -0.2 -0.2 -0.2 -0.1  0.  -0.1  1.2 -1.4 -0.1  8.6 -0.1  1.6 -0.6 -0.2 -1.5 -0.3 -0.2 -0.2 -0.2 -0.2  1.7 -0.2 -0.5  0.3 -1.  -1.5 -1.1 -1.1 -1.1 -0.1 -0.4 -0.1 -0.3 -0.2 -0.6  0.6 -3.7 -0.5 -0.2  9.1 -0.  -0.5 -0.5 -1.4  2.  -1.  -0.3  1.9 -0.7 -0.5  1.1 -0.3 -0.1  0.8 -1.2  5.1  1.1 -1.1  0.5 -0.6  2.3  3.2 -0.1 -0.   4.   0.4  5.3  2.3 -1.5  4.3 -0.9 -0.  -0.3  0.  -0.2 17.   4.1 -0.1  0.5 -1.4 -0.6 14.6  0.4 -3.5 -0.1 -0.2 -1.2]
vy_50sample [[6 8 4 0 1 2 3 7 5 9]
 [6 4 8 8 9 0 7 1 5 3]
 [7 4 8 5 9 2 0 1 3 6]
 [4 9 5 1 6 7 2 3 8 0]
 [4 1 9 5 6 2 2 3 0 0]
 [4 0 5 9 1 2 6 7 8 3]
 [9 7 0 5 8 2 1 3 4 6]
 [3 2 4 8 7 6 9 9 0 5]
 [5 1 4 2 0 9 3 7 6 8]
 [5 4 4 8 0 0 1 6 9 3]]
vt_50sample [[6 8 4 0 1 2 3 7 5 9]
 [6 4 8 2 9 0 7 1 5 3]
 [7 4 8 5 9 2 0 1 3 6]
 [4 9 5 1 6 7 2 3 8 0]
 [4 1 9 5 6 2 3 7 8 0]
 [4 0 5 1 9 2 6 7 8 3]
 [9 7 0 5 8 2 1 3 4 6]
 [3 2 4 8 7 6 9 1 0 5]
 [5 1 4 2 0 9 3 7 6 8]
 [5 4 0 8 2 7 1 6 9 3]]
Epoch 34810: Training cost= 0.2385, Training acc= 0.8458, Validation cost= 0.3067, Validation acc= 0.8458
Epoch 34820: Training cost= 0.2481, Training acc= 0.8458, Validation cost= 0.3111, Validation acc= 0.8459
Epoch 34830: Training cost= 0.2195, Training acc= 0.8458, Validation cost= 0.2517, Validation acc= 0.8459
Epoch 34840: Training cost= 0.3007, Training acc= 0.8458, Validation cost= 0.3254, Validation acc= 0.8459
Epoch 34850: Training cost= 0.2757, Training acc= 0.8458, Validation cost= 0.2447, Validation acc= 0.8459
Epoch 34860: Training cost= 0.2078, Training acc= 0.8459, Validation cost= 0.2913, Validation acc= 0.8459
Epoch 34870: Training cost= 0.2416, Training acc= 0.8459, Validation cost= 0.2011, Validation acc= 0.8459
Epoch 34880: Training cost= 0.2694, Training acc= 0.8459, Validation cost= 0.2609, Validation acc= 0.8459
Epoch 34890: Training cost= 0.2444, Training acc= 0.8459, Validation cost= 0.3160, Validation acc= 0.8460
Epoch 34900: Training cost= 0.3011, Training acc= 0.8459, Validation cost= 0.3095, Validation acc= 0.8460
tm  [-0.6 -1.   5.5  2.6 -1.5  0.2 -0.  -0.2 -0.1  1.2  5.7 -0.3 -0.3 -0.4  6.2 -1.1 -0.6 -0.1 -0.4 -0.9 -1.1  0.  -0.1  0.4 -0.9  2.5 -0.4 -0.6 -1.2  0.1  4.3 -0.2  2.  14.5 -0.1 -0.4  1.2 -1.  -1.1 -0.3  1.9  1.1 -0.6 -0.2 -0.1 -0.2  4.7 -0.2 -0.1  1.1 -0.3 -0.2 -0.2 -0.7 -0.5 -0.5 -0.7 -1.7  3.3 -1.7 -0.  -0.6  1.1 -0.1  2.4 -0.8 -0.  -0.   1.9 -0.3 -0.2  1.4 -0.3 -0.2 -2.5 -0.6 -0.7 -0.3 -0.  -0.4 12.7  1.2 -0.4  1.2 -0.8  1.2  2.  -0.2 -0.1 -0.7 -0.1 -0.2 -0.  -0.9 -0.3  0.4 -0.4 -1.9 -0.2 -0.4 -0.8  8.8 -0.3 -0.  -0.2 -0.3 -1.4  2.4  1.5 -1.3 -0.3 -0.2  0.3 -0.8  5.5 -1.5 -0.4  0.3  0.1 -0.3 -0.2  3.  -0.1 -0.  -0.7  7.9 -0.1  5.4  0.6 -1.5 -0.1 -0.1 -0.  -0.4 -1.  15.3 -0.2 -0.1 -0.3 -0.5  0.7 -1.1 -0.  -0.1 -0.2 -0.  -0.3 -0.2 -2.8 -0.1 -0.3 -0.2 -0.8  0.9 -0.2  0.2 -0.3 -0.5 -1.  -0.3 -0.1 -0.2 -0.2 -0.2 -0.1 -0.3 -0.6  0.6 -0.2 -0.1 -0.  -0.1 -0.1 -0.1 -0.3  4.9 -1.3  0.2  2.2 -0.2  0.8 -0.6 -0.2 -1.5 -0.3 -0.2  1.3 -0.5 -0.3 -0.2 -0.4 -0.2 -0.6 -0.7  3.5 -0.2 -0.7 -1.4  0.1 -0.2  0.4 -0.1 -0.7 -0.4 -0.3 -0.7  0.1 -0.2 -0.1 -0.4 -0.1 -0.5 -0.6  0.9 -0.8  0.7  1.5 -0.9 -0.1 -0.1 -0.1 -0.2 -0.4 -1.2  5.2 -1.2 -1.5 -0.3 -1.   1.2 -0.1  1.6 -0.1 -0.1 -0.2 -0.9  1.9 -0.8  2.  11.  -0.   4.  -0.3 -0.1 -2.4 -1.7 -0.2 -0.3 -0.8 -0.1 -3.5  0.3 -0.8 -0.  -0.3  9. ]
ty_50sample [[7 6 0 9 4 1 2 5 3 8]
 [8 9 3 6 2 0 0 4 7 5]
 [7 2 4 0 9 3 5 8 1 6]
 [8 9 3 7 6 6 5 1 0 2]
 [0 4 1 9 3 2 5 7 6 8]
 [9 3 1 7 5 8 6 2 4 0]
 [7 4 2 0 3 5 1 6 9 8]
 [3 4 6 1 0 8 9 2 5 7]
 [3 4 2 9 7 5 6 0 8 1]
 [4 3 6 1 8 9 7 7 5 0]]
tt_50sample [[7 6 0 9 4 1 2 5 3 8]
 [8 9 3 1 2 6 0 7 4 5]
 [2 7 4 0 9 3 5 8 1 6]
 [8 9 3 7 6 4 5 0 1 2]
 [0 4 1 9 3 2 5 7 8 6]
 [9 3 1 7 5 8 2 6 4 0]
 [7 4 2 0 3 1 5 6 9 8]
 [3 4 6 1 0 8 9 2 5 7]
 [3 4 2 9 7 5 6 0 8 1]
 [4 3 6 1 8 9 2 7 5 0]]
vm  [-0.3  0.8  3.2 19.4 -1.3 -0.3  0.3 -0.2 -0.3 -0.8 -5.1 -0.3 -0.2 -0.  -2.8 -0.6 -0.2  0.  -0.2 -1.5 -0.7 -0.5  1.2  0.5 -0.4  0.8 -0.2  0.3 -0.5 -1.2 -2.3 -0.2 -0.  -5.4 -0.4 -0.2  1.3 -0.9  5.1 -0.3 -0.2 -0.8  0.2 -1.4 -0.2 -0.1  9.2 -0.1  1.8  4.7 -0.6 -0.1 -0.  -2.3 -0.4  3.4 -0.2  8.3 -0.5  7.5 -1.3 -0.6 -0.4 -0.3 -0.4 -0.6 -0.  -0.2  0.3 -0.3 -0.3 -0.3 -0.1 -0.4  1.8 -0.2 -0.3 -0.1 -0.2 -0.3 -0.5 -0.1 -0.3  1.  -1.  -0.7 -1.  -0.1 -0.3 -0.3  0.9  0.1 -0.2 -0.  -0.4 -0.3  0.7 -1.1  0.5 -0.3  3.5 -2.2 -0.5 -0.2 -0.  -0.4 -0.1 -1.4 -1.6 -1.6 -0.  -0.1  0.7 -0.3 -0.3  2.4 -0.6 -0.6 -0.3 -0.4 -0.4  6.4 -0.2 -0.1 -0.3 -3.4  0.1 10.4 -0.2 -0.1  1.3 -0.4 -0.1 -0.4 11.7 -1.5 -0.1 -0.2  1.6  0.6  0.4 -0.7 -0.2  0.1 -0.1 -0.2 -0.1  0.6  5.5 -0.2 -1.8 -0.2  2.5 -0.2 -0.1 -0.  -0.  -0.7 -0.8 -0.2 -0.4  1.2 -0.2 -0.2 -0.2 -0.1  0.7 -0.1 -0.1  0.2 -0.1 -0.2 -0.3  0.2 -0.2 -0.9 -1.1  0.5 -0.4  0.3 -1.1 -0.4 -0.7 -1.6 -0.2 -0.2  0.8 -0.2 -0.3  3.3 -0.4 -0.1 -0.6 -0.4  9.3  0.8  1.4 -0.1 -0.4  0.7 -0.4 -0.2 -0.3  0.2  0.   1.2 -0.2 -0.1  5.8 -0.3 -0.6 -0.  -0.5 -0.3 -0.2 -0.6  7.2 -0.6 -0.4 -0.2 -0.1 -0.2 -0.6 -0.8 -0.1  2.3 -1.3  1.4 -0.9  1.6 -0.5 -0.9 -0.3  2.8 -0.3 -0.1 -0.   1.7  0.8  7.6 -0.1  2.7  0.2 -0.2  3.1 -2.2  0.1 -0.2 -1.   0.1  0.2 -0.2  2.6 -0.2  7.3  3.2]
vy_50sample [[8 9 3 6 5 0 1 2 7 4]
 [9 0 6 5 2 4 3 8 1 7]
 [0 2 3 8 4 6 5 1 7 9]
 [5 7 6 3 1 0 8 4 9 2]
 [9 4 6 0 3 2 7 8 5 1]
 [4 8 3 2 6 1 0 7 9 5]
 [8 6 7 9 4 0 3 1 2 5]
 [1 7 0 0 6 4 5 9 8 3]
 [2 6 9 0 1 5 5 7 8 3]
 [2 1 3 4 8 6 6 7 5 5]]
vt_50sample [[8 9 3 6 5 0 1 2 7 4]
 [9 0 6 5 2 4 3 8 1 7]
 [0 2 3 8 4 6 1 5 7 9]
 [5 7 6 3 1 0 8 4 9 2]
 [9 4 6 0 3 2 7 8 5 1]
 [4 8 3 2 6 1 0 7 9 5]
 [8 6 7 9 4 0 3 1 2 5]
 [1 7 0 2 6 4 5 9 8 3]
 [2 6 9 0 1 4 5 7 8 3]
 [2 1 3 4 8 6 9 0 7 5]]
Epoch 34910: Training cost= 0.2742, Training acc= 0.8459, Validation cost= 0.2608, Validation acc= 0.8460
Epoch 34920: Training cost= 0.2945, Training acc= 0.8459, Validation cost= 0.2028, Validation acc= 0.8460
Epoch 34930: Training cost= 0.2565, Training acc= 0.8459, Validation cost= 0.2800, Validation acc= 0.8460
Epoch 34940: Training cost= 0.2225, Training acc= 0.8460, Validation cost= 0.2470, Validation acc= 0.8460
Epoch 34950: Training cost= 0.2967, Training acc= 0.8460, Validation cost= 0.3116, Validation acc= 0.8460
Epoch 34960: Training cost= 0.2479, Training acc= 0.8460, Validation cost= 0.3003, Validation acc= 0.8460
Epoch 34970: Training cost= 0.2567, Training acc= 0.8460, Validation cost= 0.2582, Validation acc= 0.8461
Epoch 34980: Training cost= 0.2458, Training acc= 0.8460, Validation cost= 0.2460, Validation acc= 0.8461
Epoch 34990: Training cost= 0.2318, Training acc= 0.8460, Validation cost= 0.2676, Validation acc= 0.8461
Epoch 35000: Training cost= 0.2694, Training acc= 0.8460, Validation cost= 0.2322, Validation acc= 0.8461
tm  [-0.2 -0.2 -0.9 -2.1 -1.4  0.   0.3 -0.4 -0.4 -0.7  8.  -0.6 -0.1 -0.5  4.9  3.6 -0.  -0.5 -0.2  1.9 -1.1 -0.2 -0.1 -0.1 -1.4  4.1 -0.1 -0.2 -0.9  1.7  4.1 -0.7 -1.1  7.1 -0.2 -0.   1.8  0.3 -1.9 -0.6 -0.8  1.4 -0.1 -0.  -0.6 -0.  -1.5 -0.5  3.4 -0.3 -0.3 -0.3  0.1  6.6 -0.7 -0.2 -0.1 -1.3  1.9 -2.   2.4  0.4 -0.1  0.7 -0.1 -0.  -0.2  0.6  0.2 -0.2 -0.3 -0.4  0.4  0.5 -2.8 -0.  -0.6 -0.5  0.3  0.9  2.9  0.5 -0.   1.6 -0.7  3.3  5.2 -0.1  0.7 -0.4  0.3 -0.1 -0.3 -0.9 -0.3 -0.1 -0.1 -2.7 -0.1 -0.7  2.   4.7 -1.  -0.2 -0.1  0.4 -1.4  3.3  1.7  0.4 -0.7  0.  -0.1 -0.2  0.2  3.4 -1.3 -0.7 -0.1 -0.6  0.7 -0.3  1.2  0.7 -0.3  5.4 -0.1 -1.1  0.5  1.9  3.7 -0.2  0.3 -0.4  5.4 11.  -0.1  0.2 -0.1 -0.2 -0.2 -1.3 -0.4 -0.1 -0.2 -0.2  0.4 -0.3 -0.7 -0.1  0.3 -0.2 -0.2  0.1 -0.2 -0.2 -0.5 -0.1 -1.2  0.   2.2  2.3 -0.1 -0.1  0.  -0.7 -0.8  1.5 -0.3 -0.1 -0.2 -0.1  0.2 -0.3 -0.3  1.8  0.1 -0.   3.6 -0.  -0.1 -0.5 -0.8 -2.2 -0.  -0.2  1.2 -0.5 -0.3 -0.4 -0.2 -0.3 -0.2 -0.9 -0.1 -0.2 -0.2 -0.2 -0.1 -0.1 -0.3 -0.1 -0.6 -0.6 -0.2 -2.   0.2 -0.2 -0.9 -0.2 -0.9  0.3 -1.4  1.7 -1.  -0.2  1.  -0.9 -0.2 -0.1 -0.3 -0.4 -0.7 -1.3  6.6 -0.4  0.   0.2  1.   3.6 -0.2 -0.9 -0.4 -0.3  1.6  2.6  1.2 -0.5  3.4 -0.2 -0.2  0.3 -0.1 -0.   0.  -0.4  0.2  1.2 -1.3 -0.8 -0.9  0.  -1.2  0.2 -1.2  0.9]
ty_50sample [[6 4 2 7 0 5 1 3 9 8]
 [7 0 6 9 1 8 3 2 5 4]
 [1 1 2 0 4 5 6 8 9 3]
 [6 7 1 0 8 3 2 5 9 4]
 [7 3 8 1 5 0 6 2 9 4]
 [0 5 3 4 7 6 2 1 1 8]
 [7 6 3 1 1 4 8 0 2 9]
 [4 8 1 6 5 0 7 9 2 3]
 [7 1 9 6 8 3 2 5 0 4]
 [7 5 3 4 6 0 1 1 9 8]]
tt_50sample [[6 4 2 7 0 5 1 3 9 8]
 [7 0 6 9 1 8 3 2 5 4]
 [7 1 2 0 4 5 6 8 9 3]
 [6 7 1 0 8 3 2 5 9 4]
 [7 3 8 1 5 0 2 6 9 4]
 [0 5 3 4 7 6 2 1 9 8]
 [7 6 3 1 5 4 8 0 2 9]
 [4 8 1 6 5 0 7 9 2 3]
 [7 1 9 6 8 3 2 5 0 4]
 [7 5 3 4 6 0 2 1 9 8]]
vm  [ 1.8  0.2 -0.4 -0.2 -0.9 -0.3 -0.3 -0.  -0.8 -0.5 12.  -0.3 -0.3  0.2 -0.3  2.5  1.9 -0.1  2.4 -0.4 -1.1 -0.3 -0.8 -0.4 -1.3  1.4 -0.6  0.2 -1.4 -1.1  2.1 -0.4 -0.4  3.6  0.5 -0.2  3.   3.5 -1.4 -0.5 -1.   0.6 -0.  -0.9 -0.4  0.  -0.7 -0.5  5.7 -2.6 -0.2 -0.1 -0.8 10.4 -0.3  0.6 -0.3  3.4 -0.4 -1.1 -1.2 -0.2 -0.6 -0.1 -0.8 -0.6 -0.1  0.4 -0.8 -0.2  0.2  4.9  0.7  1.3 -3.4 -0.4 -0.5 -0.7 -0.1 -0.2  8.9 -0.8 -0.4 -1.2 -1.8  0.3  4.  -0.2 -0.1  0.1 -0.2 -0.2 -0.2  1.7 -0.3 -0.2  0.1 -2.2 -0.5 -0.3  1.6 -1.  -1.  -0.2 -0.4  0.1 -1.7  0.7 -0.1 -1.2 -0.1 -0.   0.1  0.3  1.  -1.2 -0.  -0.5  0.2  0.4 -0.2  4.4  0.2 -0.3  0.2 -0.5  0.2 -2.6 -0.1  4.4  1.1 -0.1  0.1 -0.2  9.2 12.3 -0.6 -0.  -0.4 -0.3 -1.4 -0.9 -1.  -0.1  0.1 -0.  -0.4 -0.3  3.5 -0.1  0.2 -0.2  1.7 -0.7 -0.2 -0.3 -0.1 -0.3 -0.7 -0.3  0.2 -0.   0.4 -0.2 -0.1 -0.2 -0.6 -0.4 -0.2 -0.3 -0.5 -0.1 -0.5 -0.6 -0.3 -0.7 -0.7 -0.5  2.9  0.4 -1.6  0.8 -0.4 -1.1  0.2 -0.4  2.4 -0.2 -0.1  3.4 -0.1 -0.2 -0.1 -0.7 10.6  1.2 -0.5 -0.3 -0.2 -0.1 -0.1 -0.1  1.  -0.2  0.6 -1.8 -0.3  0.3 -2.9 -0.2 -0.8 -1.7 -0.7 -1.3  2.  -0.3  4.5 -0.7 -0.8 -0.4 -0.  -0.3  0.2 -1.   2.2 -1.5  4.4  1.6 -0.1  3.4 -0.5 -0.1 -0.2 -1.4  1.8  0.8  0.6 -0.7 -0.5 -1.1 -0.2 -0.4 -0.1 -0.2 -1.6  0.9 -0.1 -0.2 -1.2 -0.2 -2.5 -0.1 -0.9 -0.3 -1.3 -0.8]
vy_50sample [[2 0 6 3 5 4 9 7 8 1]
 [0 9 3 1 1 2 4 5 6 7]
 [5 3 8 0 6 1 4 9 2 7]
 [3 4 0 7 2 8 6 1 1 5]
 [2 1 5 8 9 0 6 3 4 7]
 [9 0 2 7 1 3 4 5 8 6]
 [2 4 5 0 1 8 7 3 6 9]
 [7 1 5 8 2 6 4 0 9 3]
 [7 8 9 0 0 3 1 5 2 6]
 [4 0 5 9 7 6 1 8 2 3]]
vt_50sample [[2 0 6 3 5 4 9 7 8 1]
 [0 9 3 1 8 2 4 5 6 7]
 [5 3 8 0 6 1 4 9 2 7]
 [3 4 0 7 2 8 6 1 9 5]
 [2 1 5 8 9 0 6 3 4 7]
 [9 0 2 7 1 3 4 5 8 6]
 [2 4 5 0 1 8 7 3 6 9]
 [7 1 5 8 2 4 6 0 9 3]
 [7 8 4 9 0 3 1 5 2 6]
 [4 0 5 9 7 6 1 8 2 3]]
Epoch 35010: Training cost= 0.2772, Training acc= 0.8461, Validation cost= 0.2613, Validation acc= 0.8461
Epoch 35020: Training cost= 0.2757, Training acc= 0.8461, Validation cost= 0.2747, Validation acc= 0.8461
Epoch 35030: Training cost= 0.2363, Training acc= 0.8461, Validation cost= 0.2781, Validation acc= 0.8461
Epoch 35040: Training cost= 0.2972, Training acc= 0.8461, Validation cost= 0.3316, Validation acc= 0.8462
Epoch 35050: Training cost= 0.2944, Training acc= 0.8461, Validation cost= 0.3140, Validation acc= 0.8462
Epoch 35060: Training cost= 0.2719, Training acc= 0.8461, Validation cost= 0.3310, Validation acc= 0.8462
Epoch 35070: Training cost= 0.2898, Training acc= 0.8461, Validation cost= 0.2638, Validation acc= 0.8462
Epoch 35080: Training cost= 0.2850, Training acc= 0.8462, Validation cost= 0.2769, Validation acc= 0.8462
Epoch 35090: Training cost= 0.3465, Training acc= 0.8462, Validation cost= 0.3190, Validation acc= 0.8462
Epoch 35100: Training cost= 0.3698, Training acc= 0.8462, Validation cost= 0.2821, Validation acc= 0.8462
tm  [-1.5 -0.1 -3.4 -1.5 -0.9 -0.1 -0.4  0.1 -0.7 -1.3 -1.2 -0.3 -0.2  0.3 -1.6 -0.4 -0.7 -0.3  0.7 -0.5 -1.1  0.4 -0.7 -0.3 -1.3  0.7 -0.6 -0.2 -0.9 -2.7  3.3 -0.3 -0.2 -1.9 -0.1  1.1  3.4 -0.8 -1.2 -0.8  1.3 -0.9 -0.2  2.6 -0.2  0.5 -0.3  0.5 -1.3 -2.9 -0.6 -0.1 -0.8 -1.2 -1.   1.8 -0.9  1.   3.2 -1.5  6.6 -0.5 -0.4 -0.2 -0.9 -0.1 -0.1 -0.6 -0.1 -0.   0.5  0.2 -0.1  0.5 -2.3 -0.4  0.2 -0.4 -0.2 -0.2  4.6 -0.4 -0.1 -0.3  2.2 -0.6 -0.7 -0.  -0.3 -0.3 -0.6  0.1 -0.3 -0.1 -0.5  0.2  0.2 -2.2 -0.2 -0.1  5.9 -2.8  3.1 -0.2  1.1 -0.3 -1.6  1.2 -0.4 -1.1 -1.1 -0.2 -0.3 -0.5  1.9  4.3  1.1 -0.3 -0.3 -0.9 -0.2  5.6 -0.1 -0.3 -0.  -2.1 -0.2  6.7  5.7  8.9 -0.8 -0.5 -0.2 -0.9 10.6  7.8 -0.3 -0.2 -0.5 -0.2  0.6 -0.1 -0.2 -0.  -0.5 -0.1 -0.4  0.4  6.7 -0.1  0.7 -0.1 -1.5 -0.6  0.2 -0.2  1.2  0.1  0.5 -0.5  0.4 -0.3 -0.3 -0.  -0.1 -0.4  0.2  1.1 -0.1 -0.3 -0.1  0.1 -0.1 -0.4 -0.2 -1.6 -1.2 -0.9  3.  -0.2 -2.2 -0.2 -0.1 -1.5  0.4 -0.  -1.3  1.7 -0.2  7.1 -0.2 -0.4 -0.2 -0.9 -1.8 -1.2 -0.4 -0.6 -0.2 -0.1 -0.1  0.1  1.2 -0.7 -0.4 -2.9 -0.3  0.7 -2.4 -0.1 -0.6 -0.6 -0.6  6.6 -0.1 -0.3 -0.4 -0.7 -0.  -0.2 -0.2 -0.1 -0.1 -1.  -1.  -0.3 -1.3 -0.1 -0.2  0.7 -0.6 -0.3  0.1 -1.2  2.   4.9 -0.  -0.7 -0.  -1.6 -0.2 -0.5 -0.1 -0.1 -0.4  2.6 -0.3  0.6 -1.3 -0.4 -1.5 -0.2 -0.7 -0.1  6.9 -1.9]
ty_50sample [[1 3 4 4 6 0 9 8 2 7]
 [7 1 0 2 5 8 3 3 4 6]
 [8 4 7 1 6 3 5 9 2 0]
 [9 3 2 8 5 7 1 1 0 4]
 [8 3 1 0 5 6 2 4 7 9]
 [4 7 9 3 5 0 6 2 8 1]
 [0 1 7 2 3 8 5 6 4 9]
 [0 1 9 3 4 4 7 5 2 8]
 [3 0 8 6 7 2 5 1 9 4]
 [3 3 7 7 5 2 1 8 4 6]]
tt_50sample [[3 1 5 4 6 0 9 8 2 7]
 [7 1 0 2 8 5 9 3 4 6]
 [8 4 7 1 6 3 5 9 2 0]
 [9 3 2 8 5 7 6 1 0 4]
 [8 3 1 0 5 6 2 4 7 9]
 [4 7 9 5 3 0 6 2 8 1]
 [0 1 7 2 3 8 5 6 4 9]
 [0 1 9 3 6 4 7 5 2 8]
 [3 0 8 6 7 2 5 1 9 4]
 [0 3 7 9 5 2 1 8 4 6]]
vm  [-0.9 -0.2  1.8 23.6 -1.1 -0.2 -0.3 -0.1  0.7 -0.   7.5 -0.4 -0.  -0.3 -4.1  1.8  0.  -0.4  0.2 -1.5 -0.8 -0.2  1.8 -0.  -0.3  3.4 -0.2 -0.  -1.1 -2.9 -1.5 -0.6 -0.4 -3.  -0.   0.4  2.4  7.  16.4 -0.1  0.5  1.5 -0.2 -0.7 -0.2  0.3  9.9 -0.3 -0.   4.9 -0.4 -0.2  1.  -0.1  0.3  4.3 -0.3  6.9  1.6  5.4 -1.1 -0.1  0.3  0.3 -0.2  0.2 -0.  -0.2 -0.5 -0.  -0.1  2.1  0.4  0.5  6.8 -0.  -0.2  0.  -0.2 -0.  14.4 -0.3 -0.3 -0.2 -0.4  2.1 -1.9 -0.2 -0.1  0.4 -0.2 -0.1  0.3 -0.7 -0.1 -0.5  0.3  0.  -0.1  0.7  0.4 -0.8 -0.2 -0.  -0.1 -0.   3.8 -0.8  1.1 -2.3 -0.4 -0.1 -0.  -0.1  2.2 -0.9  1.3 -1.1 -0.3  0.1 -0.1  9.2  0.6  0.9 -0.1 -5.  -0.2  2.8  1.7 -2.9 -0.6  0.4 -0.1 -0.2  5.  -1.6 -0.2 -0.1 -0.1 -0.3 -0.7 -1.  -1.2 -0.2 -0.1 -0.2  0.3 -0.   4.9 -0.  -2.  -0.2  0.7 -0.2  0.1 -0.1 -0.  -0.2  2.4 -0.4 -0.1 -1.1 -0.  -0.  -0.2 -0.3  0.4 -0.1 -0.1 -0.2  0.1 -0.1 -0.2  0.7 -0.2 -0.9 -0.1  0.9 -1.8  0.2 -0.7 -0.1 -0.4 -1.2 -0.2 -0.2 -0.3  0.1 -0.2  8.5  0.5 -0.3 -0.4 -0.4  8.3 -0.4  4.1 -0.5 -0.2  0.1 -0.2 -0.   0.2 -0.3  1.   7.4  0.1 -0.2  2.5 -0.3 -0.3 -0.9 -0.   1.9 -0.3 -0.5  3.5 -0.7 -0.8 -0.6 -0.2 -0.1  0.  -0.4 -0.  -0.4  2.3  1.6 -0.4 -0.3 -0.5 -1.7  0.5  1.8  1.8 -0.  -0.2  4.4  1.  15.8 -0.1  5.5  0.  -0.3 -2.7 -3.   0.2  1.2 -1.   0.  -3.8 -0.  10.5 -0.1 -1.1 11.8]
vy_50sample [[9 2 0 8 1 5 3 6 7 4]
 [9 8 0 2 4 7 5 1 3 6]
 [5 8 0 4 7 2 1 9 3 6]
 [5 7 2 4 0 9 3 6 1 8]
 [6 8 3 9 1 4 5 0 2 7]
 [7 0 4 8 2 5 5 6 1 3]
 [0 1 4 6 2 7 9 3 8 5]
 [9 5 3 6 0 4 4 2 1 7]
 [2 8 0 0 5 1 3 9 4 6]
 [9 0 2 5 3 4 1 8 7 6]]
vt_50sample [[9 2 0 8 1 5 3 6 7 4]
 [9 8 0 2 4 7 1 5 3 6]
 [5 8 0 4 7 2 1 9 3 6]
 [5 7 2 4 0 9 3 6 1 8]
 [6 8 3 1 9 4 5 0 2 7]
 [7 0 4 8 2 5 9 6 1 3]
 [0 1 4 6 2 7 9 3 8 5]
 [9 5 3 6 0 8 4 2 7 1]
 [2 8 0 7 1 5 3 9 4 6]
 [9 0 2 5 3 4 1 8 7 6]]
Epoch 35110: Training cost= 0.2212, Training acc= 0.8462, Validation cost= 0.2874, Validation acc= 0.8462
Epoch 35120: Training cost= 0.3337, Training acc= 0.8462, Validation cost= 0.3051, Validation acc= 0.8463
Epoch 35130: Training cost= 0.2810, Training acc= 0.8462, Validation cost= 0.2344, Validation acc= 0.8463
Epoch 35140: Training cost= 0.2786, Training acc= 0.8462, Validation cost= 0.2910, Validation acc= 0.8463
Epoch 35150: Training cost= 0.2752, Training acc= 0.8462, Validation cost= 0.2991, Validation acc= 0.8463
Epoch 35160: Training cost= 0.2533, Training acc= 0.8463, Validation cost= 0.2700, Validation acc= 0.8463
Epoch 35170: Training cost= 0.2627, Training acc= 0.8463, Validation cost= 0.2387, Validation acc= 0.8463
Epoch 35180: Training cost= 0.2707, Training acc= 0.8463, Validation cost= 0.2390, Validation acc= 0.8463
Epoch 35190: Training cost= 0.2831, Training acc= 0.8463, Validation cost= 0.2260, Validation acc= 0.8464
Epoch 35200: Training cost= 0.2965, Training acc= 0.8463, Validation cost= 0.2419, Validation acc= 0.8464
tm  [-0.7 -0.5 -4.3 -2.  -0.9  0.5 -0.1 -0.3 -0.4 -0.1  7.  -0.4 -0.1 -0.2 -2.2 -1.1 -0.  -0.5 -0.2 -1.4 -1.4 -0.4 -0.9 -0.3 -0.6  1.5 -0.2 -0.3 -1.5 -3.1  5.  -0.5 -0.7 -1.7  0.9  0.1  2.8  5.1 11.7 -0.7 -0.2 -3.2 -1.3  4.2 -0.5 -0.2  5.7 -0.4 -0.3 -2.  -0.7 -0.1 -0.6  5.2  0.4  2.5 -0.6 -3.7  5.9 -2.1  1.   0.7 -0.9 -0.4  0.1 -0.5  0.1  0.5 -0.2  0.6  0.2  6.3 -0.5 -0.  -2.5  0.3 -0.4 -0.2 -0.1 -0.3  8.1 -0.1 -0.7 -0.9 -0.5 -3.2  4.  -0.2  1.1 -0.4 -0.8 -0.3 -0.2 -0.  -0.6  0.2 -0.7 -1.8 -0.4 -0.3 -0.3 -2.  -0.5 -0.1 -0.3 -0.1 -1.7  3.4  0.7 -2.  -0.2 -0.4 -0.4 -0.3  5.6 -3.2  1.5  0.6 -0.3  0.9  0.5  7.  -0.  -0.3 -0.5 -2.7 -0.5 -0.8  2.2  3.2 -0.3  0.2 -0.5  1.1  0.8 -1.5 -0.4 -0.2 -0.3 -0.6 -1.1 -0.6 -0.6 -0.1 -0.2 -0.2 -0.1 -0.  -0.4 -0.4  0.9 -0.2 -0.6 -0.1 -0.  -0.3  0.3  0.7  0.7 -0.8 -0.5 -2.2  0.5 -0.1 -0.  -0.3 -0.6  0.4 -0.2 -0.1 -0.2 -0.1 -0.3 -0.1  0.1  1.2  1.2 -1.  -1.1 -0.2  0.6 -0.2 -0.4 -1.3  0.5  1.5 -0.3 -0.1  0.7  8.2 -0.1 -0.1 -0.7 -0.8  1.1 -0.2 -1.1 -1.1  0.4  0.1 -0.5 -0.1 -0.4 -0.1  0.1 -1.1  0.1 -0.   6.2 -0.3 -0.7 -2.5 -0.5 -0.1  2.3  0.6 -2.3 -1.1 -0.7 -0.2 -0.  -0.4 -0.2 -1.3 -1.4 -1.5 -0.3 -0.9 -0.2  1.1 -1.5  0.8 -0.2  2.3  2.6  6.5  0.6 -0.9 -0.7 17.1 -0.2  5.6  0.2  0.9 -1.4 -0.7  1.6 -0.7 -0.8 -0.4 -2.4 -0.1  7.5 -0.1  0.5 -0.3]
ty_50sample [[0 4 2 3 9 9 8 7 6 5]
 [6 3 2 8 1 4 0 5 9 9]
 [0 5 6 2 7 3 9 1 4 8]
 [8 3 9 5 0 6 7 2 4 4]
 [0 8 4 6 2 1 9 7 5 3]
 [1 7 5 0 8 2 3 9 6 4]
 [8 6 5 3 3 1 4 7 2 0]
 [3 8 8 7 0 9 9 1 5 4]
 [8 3 1 7 4 5 9 2 6 0]
 [5 6 0 2 8 7 9 1 4 3]]
tt_50sample [[0 4 3 2 9 1 8 7 6 5]
 [6 3 2 8 1 4 0 5 9 7]
 [0 5 6 2 7 3 9 1 4 8]
 [8 3 9 5 0 6 7 2 1 4]
 [0 8 4 6 2 1 9 7 5 3]
 [1 7 5 0 8 2 3 9 6 4]
 [8 6 5 1 3 9 4 7 2 0]
 [3 8 6 7 0 2 9 1 5 4]
 [8 3 1 7 4 5 9 2 6 0]
 [5 6 0 2 8 7 9 1 4 3]]
vm  [-1.  -0.4  6.3 16.4 -1.9 -0.2 -0.2 -0.3  2.6 -0.6 -2.4 -0.4  0.4 -0.2 -1.2 -1.  -0.1 -0.4  0.9 -0.8 -0.8 -0.4  2.5 -0.1 -0.3  2.8 -0.2 -0.1 -0.8 -3.2 -1.2 -0.2 -0.5 -0.9 -0.1 -0.1 -0.3  2.  13.5 -0.2  1.7  2.7 -0.2 -0.1  0.5  1.5  4.8  0.4  4.3  3.7 -0.6 -0.2  0.6 -2.   0.6  1.8 -0.5  9.6  5.6  5.6 -1.  -0.1  0.7  0.5 -0.8 -0.1 -0.1 -0.9  1.6  0.5 -0.   0.3  0.2  2.1 -0.3 -0.  -0.4 -0.  -0.2  0.3  6.3 -0.2  0.5 -0.1 -0.8  4.  -1.1  0.  -0.3 -0.3 -0.5 -0.1  0.2 -1.4 -0.4 -0.2  2.5 -2.2 -0.7  0.6  1.9  0.3 -0.6 -0.1 -0.4 -0.4  1.4 -0.9 -0.9 -1.8 -0.8 -0.2 -0.2 -0.7  4.5 -0.2  1.   1.2 -0.4 -0.3 -0.1  7.  -0.  -0.1 -0.3 -1.6 -0.3  9.3  7.9 -1.1 -0.5 -0.8 -0.7 -0.8 -2.4 -2.9 -0.2 -0.2 -0.2 -0.2  1.2 -1.   0.3  0.2 -0.3 -0.   0.2 -0.2  4.4 -0.1 -1.5 -0.1  2.8  0.  -0.2  0.  -0.4  0.5  4.7 -0.1 -0.1 -1.3 -0.2 -0.1 -0.5 -0.4  0.9 -0.  -0.2 -0.1  0.2 -0.1 -0.3 -0.1  0.1 -0.5  0.3  0.6 -1.3 -0.1 -1.9 -0.  -0.7 -1.5 -0.2 -0.3  1.7 -0.3  0.   8.7  0.2 -0.1 -0.4 -0.1  8.1 -2.5  2.2 -1.4  0.1 -0.2 -0.1  0.2 -0.2 -0.3 -0.   1.4 -0.2 -0.1 -0.4  0.2 -0.4  0.2 -0.1 -0.4 -1.  -0.3  1.1 -0.5  0.2 -0.8 -0.2 -0.3 -0.2 -0.9 -1.1  0.9 -1.8  0.1 -0.4  3.7 -0.3 -1.5  0.2 -0.3  2.7 -1.3 -0.3  3.2  3.9  3.7 -0.3  1.   0.5  0.2 -0.8 -2.  -0.3  0.2 -1.2 -0.1 -1.9 -0.   8.6 -0.3  4.8  6. ]
vy_50sample [[9 5 8 0 3 7 1 2 6 4]
 [3 2 6 8 7 0 1 5 9 4]
 [0 8 1 3 9 2 5 6 4 7]
 [1 7 7 6 2 3 8 0 5 4]
 [5 5 7 0 8 4 2 3 9 6]
 [8 4 3 9 2 0 5 7 1 6]
 [5 4 7 1 9 3 6 2 8 0]
 [0 1 5 7 3 4 6 9 2 8]
 [6 3 4 5 9 2 2 1 0 7]
 [1 3 6 2 0 9 4 8 7 5]]
vt_50sample [[9 5 8 0 3 7 1 2 6 4]
 [3 2 6 8 7 0 1 5 9 4]
 [0 8 1 3 9 2 5 6 4 7]
 [7 1 9 6 2 3 8 0 5 4]
 [5 7 1 0 8 4 2 3 9 6]
 [8 4 3 9 2 0 5 7 1 6]
 [5 4 7 1 9 3 6 2 8 0]
 [0 1 5 7 3 4 9 6 2 8]
 [6 3 4 5 9 2 8 1 0 7]
 [1 3 6 2 0 9 4 8 7 5]]
Epoch 35210: Training cost= 0.2933, Training acc= 0.8463, Validation cost= 0.3116, Validation acc= 0.8464
Epoch 35220: Training cost= 0.2568, Training acc= 0.8463, Validation cost= 0.2537, Validation acc= 0.8464
Epoch 35230: Training cost= 0.2471, Training acc= 0.8464, Validation cost= 0.2572, Validation acc= 0.8464
Epoch 35240: Training cost= 0.2510, Training acc= 0.8464, Validation cost= 0.2591, Validation acc= 0.8464
Epoch 35250: Training cost= 0.2235, Training acc= 0.8464, Validation cost= 0.3448, Validation acc= 0.8464
Epoch 35260: Training cost= 0.2639, Training acc= 0.8464, Validation cost= 0.2582, Validation acc= 0.8465
Epoch 35270: Training cost= 0.3143, Training acc= 0.8464, Validation cost= 0.2975, Validation acc= 0.8465
Epoch 35280: Training cost= 0.2449, Training acc= 0.8464, Validation cost= 0.2344, Validation acc= 0.8465
Epoch 35290: Training cost= 0.2651, Training acc= 0.8464, Validation cost= 0.2902, Validation acc= 0.8465
Epoch 35300: Training cost= 0.2985, Training acc= 0.8465, Validation cost= 0.2786, Validation acc= 0.8465
tm  [-1.6  1.8  5.3  3.9 -1.4 -0.2  0.  -0.2 -1.4 -0.7  6.7  1.1 -0.5  0.   5.4  5.6  0.4  0.2 -0.4 -0.5 -0.8 -0.3 -0.6  0.2 -1.2  1.1 -0.2 -0.2 -0.2  1.1 -0.2 -0.1 -0.4  6.9 -0.3  0.3  4.   4.   3.1 -0.5  2.2 -4.   0.8  0.2 -0.1 -0.   0.7 -0.5 -2.  -2.  -0.4 -0.   1.7  6.3 -1.8 -0.5 -0.4 -1.7 -1.4  1.6  5.3  0.4 -0.1 -1.1 -0.7 -0.4 -0.3 -0.3 -0.7  0.3 -0.2 -1.1 -0.6 -0.1 -2.7 -0.2  1.5 -0.2 -0.6 -0.3  2.9  0.  -0.2 -0.6  0.8 -3.8 -1.2  0.1  0.3 -0.4 -0.3 -0.2 -0.   4.7 -0.6 -0.3 -0.3 -1.1 -0.2 -0.3  2.5 -0.5  1.8 -0.  -0.2  1.  -1.6  0.1  0.5 -1.4  0.  -0.3 -0.1 -0.2 -1.2  7.5  0.5 -1.4 -0.1 -0.2 -0.2  3.7 -0.6 -0.3  0.   6.3 -0.1 -1.  -2.   6.8 -0.7  0.1 -0.6  2.2 -2.3  0.7 -0.4 -0.1  0.  -0.6 -0.9 -0.4 -0.7 -0.2 -0.2 -0.4 -0.1  0.1 -2.4 -0.  -0.7 -0.  -0.8 -0.3 -0.4 -0.4 -0.6  0.2  0.3 -0.6 -0.7 -1.3 -0.2  0.1 -0.   1.4 -0.  -0.2 -0.2 -0.  -0.1 -0.4  0.4 -0.2  0.1  4.  -0.3 -0.3  0.1 -0.1  3.8  2.8  0.3 -1.4 -0.4 -0.8 -1.1 -0.9 -0.5 -0.3 -0.2 -0.2 -0.2 -1.3 -1.6  7.2 -0.4  3.1 -0.2 -0.4 -0.   0.  -0.1  0.2 -0.3 -0.1 -0.2 -0.2  8.2 -0.2 -0.3  3.3 -0.2  7.6  0.7 -0.2 -0.2 -0.6 -0.6 -0.3 -0.2  0.2 -0.  -0.8 -1.3  3.4 -0.4 -0.5 -0.1 -1.5 -0.5  1.6 -0.8  3.1 -1.2 -0.8 -1.  -0.8 -0.9 17.5 -0.2  6.4 -0.3 -0.3  0.  -0.7 -1.  -0.5 -0.6 -0.3 -0.9 -0.2  1.8 -0.2  2.4 -1.3]
ty_50sample [[1 1 2 7 9 8 4 6 0 5]
 [3 6 7 5 8 9 4 2 1 0]
 [6 3 4 7 9 1 8 2 5 0]
 [5 4 0 2 6 9 7 1 8 3]
 [1 4 9 7 0 8 3 6 2 5]
 [9 0 6 7 5 4 8 2 1 3]
 [1 0 5 7 4 2 9 3 6 8]
 [8 4 3 5 9 0 6 7 1 2]
 [4 5 2 3 6 7 8 0 9 1]
 [8 6 5 0 2 1 9 3 7 4]]
tt_50sample [[3 1 2 7 9 4 8 6 0 5]
 [3 6 7 5 8 9 4 2 1 0]
 [6 3 4 7 9 1 8 2 5 0]
 [5 0 4 6 2 9 7 1 8 3]
 [1 4 9 7 0 8 3 6 2 5]
 [9 0 6 7 5 4 8 2 1 3]
 [1 0 5 7 4 2 9 3 6 8]
 [8 4 3 5 9 0 6 7 1 2]
 [4 5 2 3 6 7 8 0 9 1]
 [8 6 5 0 2 1 3 9 7 4]]
vm  [-0.7 -0.4 -0.5 -2.5 -1.7 -0.2 -0.3 -0.1  0.3 -0.7 -0.8 -0.1 -0.2 -0.   5.7  1.4 -0.6 -0.   0.  -0.5 -1.6 -0.1  0.3 -0.1 -0.8  1.2 -0.2 -0.3  0.3 -0.6  3.6 -0.4  0.6  6.5 -0.  -0.1 -0.1  3.   7.1 -0.5  0.6 -2.5 -0.8  5.3 -0.5  0.1  0.4 -0.3  1.3  0.  -0.5 -0.2 -0.2 -0.4 -1.2 -0.5 -0.7 -3.8  4.3 -1.4  1.7 -0.1 -0.1 -0.1 -0.  -0.8  0.1  0.1  0.9 -0.1 -0.  -1.1 -0.2  1.4 -3.  -0.  -0.5 -0.8 -0.1  0.1  0.3 -0.3 -0.2  1.4 -0.6 -2.5  4.6 -0.1 -0.2 -0.5 -0.3 -0.1 -0.2 -0.9 -0.1 -0.4 -0.6 -2.4 -0.5 -0.1  1.9  2.9 -0.4  0.4 -0.2 -0.2 -1.3  3.4 -0.2 -0.9 -0.5 -0.3 -0.1 -1.1  2.6  6.3  0.5  0.5 -0.3 -0.1 -0.3  2.2 -0.  -0.1 -0.3  6.9 -0.   3.7  3.3  2.7 -0.5 -0.4 -0.1 -0.5 -4.4 -2.1 -0.1 -0.  -0.2 -0.6 -0.  -0.2 -0.2 -0.2 -0.2  0.  -0.3 -0.1 -2.6 -0.2  0.5 -0.1  1.8 -0.4 -0.1  0.2 -0.2 -0.1  3.9 -0.3 -0.2 -1.6 -0.1 -0.1 -0.2 -0.3 -0.   2.7 -0.1 -0.2 -0.2 -0.3 -0.3 -0.2 -0.2  5.2  0.1 -0.2 -0.5  0.1  2.4 -0.  -0.4 -1.2 -0.3 -0.3  1.1 -0.7 -0.2  2.2  0.3 -0.1 -0.7 -1.   1.3 -1.  -0.5 -0.5  0.5 -0.2 -0.2 -0.1 -0.3 -0.4 -0.2 -1.5 -0.3 -0.2  7.5 -0.4 -0.5  3.3 -1.   1.4 -0.1 -0.4 -2.3 -0.9 -0.1  0.4 -0.1 -0.2 -0.3 -1.1 -1.4  3.  -1.4 -0.1  0.2  2.3 -0.2 -0.1 -0.1  3.4 -0.6  2.1  0.8 -0.4  3.1 11.7 -0.   4.1 -0.2 -0.1  2.1 -0.7 -0.3 -0.1 -1.2  0.2 -0.3 -0.1  5.  -0.   4.  -0. ]
vy_50sample [[4 7 3 8 1 1 2 0 6 5]
 [0 4 1 3 5 7 2 9 8 6]
 [0 5 3 6 7 8 4 2 9 1]
 [7 4 6 1 2 2 5 0 3 3]
 [9 6 3 8 2 7 1 0 5 4]
 [4 8 5 6 0 3 1 7 9 2]
 [6 3 4 1 5 2 7 9 0 8]
 [1 0 6 8 2 4 9 7 3 5]
 [3 8 6 9 0 1 4 5 7 2]
 [0 1 7 3 6 8 9 4 5 5]]
vt_50sample [[4 7 3 8 9 1 2 0 6 5]
 [0 4 1 3 5 7 2 9 8 6]
 [0 5 3 6 7 8 4 2 9 1]
 [7 4 6 1 9 2 5 0 3 8]
 [9 6 3 2 8 7 1 0 5 4]
 [4 8 5 6 0 3 1 7 9 2]
 [6 3 4 1 5 2 7 9 0 8]
 [1 0 6 8 2 4 9 7 3 5]
 [3 8 6 9 0 1 4 5 7 2]
 [0 1 7 3 6 8 9 4 5 2]]
Epoch 35310: Training cost= 0.3087, Training acc= 0.8465, Validation cost= 0.2411, Validation acc= 0.8465
Epoch 35320: Training cost= 0.2394, Training acc= 0.8465, Validation cost= 0.2629, Validation acc= 0.8465
Epoch 35330: Training cost= 0.2490, Training acc= 0.8465, Validation cost= 0.2397, Validation acc= 0.8466
Epoch 35340: Training cost= 0.2934, Training acc= 0.8465, Validation cost= 0.2485, Validation acc= 0.8466
Epoch 35350: Training cost= 0.2628, Training acc= 0.8465, Validation cost= 0.3341, Validation acc= 0.8466
Epoch 35360: Training cost= 0.2601, Training acc= 0.8465, Validation cost= 0.2901, Validation acc= 0.8466
Epoch 35370: Training cost= 0.2950, Training acc= 0.8466, Validation cost= 0.2404, Validation acc= 0.8466
Epoch 35380: Training cost= 0.2405, Training acc= 0.8466, Validation cost= 0.2821, Validation acc= 0.8466
Epoch 35390: Training cost= 0.2460, Training acc= 0.8466, Validation cost= 0.2329, Validation acc= 0.8466
Epoch 35400: Training cost= 0.2267, Training acc= 0.8466, Validation cost= 0.2830, Validation acc= 0.8467
tm  [-0.6  1.6  4.4  9.6 -1.5 -0.2 -0.3 -0.2 -1.6 -0.8  9.4 -0.2 -0.1 -0.2 -0.1  0.1 -0.1 -0.2  1.3 -0.5 -0.7 -0.2 -0.6  0.7 -1.5  4.  -0.3 -0.2 -2.  -0.7 -0.1 -0.3  0.2  4.  -0.1 -0.2  7.1  2.5 -0.5 -0.4 -0.1 -1.8  2.  -1.2 -0.2 -0.3  3.  -0.7 -0.1 -2.  -0.5  0.3 -0.   5.2  1.9  0.4 -0.5  3.3 -1.8  2.4  0.9 -0.3 -0.6 -0.  -0.   0.2 -0.  -0.5 -0.2 -0.3 -0.3  7.9 -0.1 -0.5 -0.7  1.  -0.5 -0.7 -0.3  0.   8.1 -0.2 -0.2 -0.5 -0.1 -1.3 -0.9 -0.2 -0.   0.4 -0.  -0.2 -0.3  3.8  0.2 -0.1  0.  -0.9 -0.1 -0.1  3.3 -0.7 -0.6 -0.2 -0.1 -0.3 -1.2  0.   1.  -0.5 -0.3 -0.   0.4  2.3 -0.3 -3.1 -0.1 -1.8 -0.1 -0.  -0.2  2.5 -0.1  1.2 -0.  -0.2 -0.2 -0.9 -2.4  2.8 -0.1  0.7 -0.1 -0.2  5.5  9.4  0.3 -0.   0.8 -0.5 -1.1 -1.3 -1.  -0.3  0.1 -0.  -0.2 -0.1 -0.4 -0.2 -1.1  0.1 -0.5 -0.6 -0.3  0.   0.1 -0.4 -0.6 -0.4 -0.2 -0.2  0.2 -0.1  0.2 -0.4 -0.1 -0.6 -0.4 -0.   0.1 -0.2  0.1 -0.2 -0.2  1.5 -0.8  0.5  1.8 -0.3 -0.3 -0.2  0.5 -1.7 -0.1  0.  -0.2 -0.6 -0.   1.6 -0.4 -0.3 -0.2 -1.1  1.5  9.1 -0.6  0.3 -0.2 -0.  -0.4 -0.2 -0.2 -0.5 -0.1 -0.7  0.2  0.1  0.2 -0.2 -0.1 -2.7 -0.1  2.1 -0.2 -0.3  5.6 -0.9 -0.5  0.3 -0.2 -0.1  0.8 -0.8  0.8 -1.7  2.7  1.7  1.1 -0.8 -0.6 -0.1 -0.1  0.1  3.5 -0.9  1.1 -0.2 -0.8  6.9  0.   2.9 -0.1 -0.3 -1.4 -0.9  0.6 -0.2 -0.6 -0.2 -2.3  0.2 -0.4 -0.2 -0.3 -0.1]
ty_50sample [[0 2 6 3 1 1 7 5 8 4]
 [0 3 4 8 2 5 7 9 9 1]
 [5 8 7 6 2 9 1 4 4 3]
 [9 2 5 8 1 3 6 7 0 4]
 [4 2 7 6 9 1 8 0 5 3]
 [4 5 8 7 0 1 2 9 6 3]
 [2 5 1 0 3 9 6 4 7 8]
 [8 5 7 3 9 2 6 0 1 4]
 [9 7 4 6 2 3 0 1 8 5]
 [8 6 5 4 1 0 2 7 3 9]]
tt_50sample [[0 2 6 3 1 9 7 5 8 4]
 [0 3 4 8 2 5 7 6 9 1]
 [5 8 7 6 2 9 1 0 4 3]
 [9 2 5 8 1 3 6 7 0 4]
 [4 2 7 6 9 8 1 0 5 3]
 [4 5 8 7 0 1 2 9 6 3]
 [2 5 1 0 3 9 6 4 7 8]
 [8 7 5 3 9 2 6 0 1 4]
 [9 7 4 6 2 3 0 1 8 5]
 [8 6 5 4 1 0 2 7 3 9]]
vm  [-0.9 -0.6 -1.7  9.  -1.5 -0.1 -0.2 -0.1  0.4  0.5  4.  -0.2 -0.1 -0.2 -2.9 -1.  -0.5 -0.3 -0.3 -1.3 -1.1 -0.2  1.4 -0.2 -0.7  2.9  0.5 -0.2 -1.1 -3.4  2.6  0.  -0.3 -1.   0.1 -0.2  1.4  4.4 17.2 -0.3  1.8  5.7 -0.2  3.7 -0.  -0.1  8.3 -0.5 -0.5  3.4 -0.5 -0.1  0.9 -1.4 -0.   3.4 -0.6  3.9  4.2 -0.5  0.  -0.5  0.3 -0.1  1.4 -0.6 -0.3 -0.  -0.  -0.2 -0.1  3.1 -0.2 -0.4 -0.3 -0.4 -0.  -0.5 -0.1 -0.1 14.7  0.7 -0.2 -0.4 -0.1  5.8 -0.6  0.1 -0.1 -0.4  0.3 -0.3 -0.3 -0.7 -0.4 -0.2 -0.2 -1.3 -0.1 -0.4 -0.1 -0.1 -0.1 -0.1 -0.1 -0.3 -0.4  1.2  1.2 -1.8 -0.5 -0.2 -0.  -0.6  4.9 -1.8  0.7 -0.2 -0.1  0.2 -0.1  6.1 -0.  -0.  -0.3 -3.3 -0.3  7.5  5.8 -2.1 -0.6 -0.  -0.2 -0.1 -0.8 -1.9 -0.1  0.1 -0.3 -0.6  0.5 -0.7 -0.2 -0.3 -0.1 -0.3 -0.2  0.   7.4 -0.4 -0.7 -0.1 -0.7 -0.1 -0.2 -0.1  0.1  0.6  4.1 -0.2  0.6 -1.9 -0.3 -0.2 -0.1 -0.5 -0.  -0.1 -0.   0.5  0.1 -0.1  0.2  0.5 -0.2 -1.5  0.2 -0.4 -1.7 -0.1 -1.5 -0.3 -0.4 -1.3 -0.1 -0.4 -0.4 -0.3 -0.   9.6 -0.4 -0.4 -0.6 -1.   3.  -1.3  0.2 -1.2 -0.2  0.   0.2 -0.2 -0.3 -0.4 -0.4  1.5 -0.  -0.2 -3.2  0.  -0.4 -1.2 -0.4  3.6 -0.6 -0.3 -1.3 -1.2 -0.2 -0.  -0.3 -0.2  0.3 -0.8 -0.6 -1.1 -1.1  0.1 -0.3 -0.1 -0.8 -0.8 -0.1 -1.7  1.8  3.5  2.   1.2  2.1  1.5 -0.1 -0.1 -0.2  0.1 -2.8 -2.3 -0.3 -0.3 -1.4 -0.  -4.  -0.1 11.3 -0.   0.1 10.1]
vy_50sample [[0 0 1 1 4 2 8 3 7 6]
 [0 7 5 4 9 2 1 1 6 3]
 [4 8 9 3 7 5 1 2 0 6]
 [6 2 7 4 9 0 3 8 1 5]
 [7 1 2 5 4 8 3 0 6 9]
 [5 6 4 9 2 7 3 0 1 1]
 [6 1 3 5 4 0 9 2 8 7]
 [6 7 5 9 3 0 8 4 2 1]
 [4 9 5 8 2 7 0 6 3 1]
 [3 2 8 9 6 0 4 7 5 1]]
vt_50sample [[5 0 9 1 4 2 8 3 7 6]
 [0 7 5 9 4 8 2 1 6 3]
 [4 8 9 3 7 5 1 2 0 6]
 [6 2 7 4 9 0 3 8 1 5]
 [7 1 2 5 4 3 8 0 6 9]
 [5 6 4 9 2 7 3 0 1 8]
 [6 1 3 5 4 0 9 2 8 7]
 [6 7 5 9 3 0 8 4 2 1]
 [4 9 5 2 8 7 0 6 3 1]
 [3 2 8 9 6 0 4 7 5 1]]
Epoch 35410: Training cost= 0.2683, Training acc= 0.8466, Validation cost= 0.2735, Validation acc= 0.8467
Epoch 35420: Training cost= 0.2662, Training acc= 0.8466, Validation cost= 0.2294, Validation acc= 0.8467
Epoch 35430: Training cost= 0.2479, Training acc= 0.8466, Validation cost= 0.2709, Validation acc= 0.8467
Epoch 35440: Training cost= 0.2848, Training acc= 0.8467, Validation cost= 0.2834, Validation acc= 0.8467
Epoch 35450: Training cost= 0.2846, Training acc= 0.8467, Validation cost= 0.2730, Validation acc= 0.8467
Epoch 35460: Training cost= 0.2958, Training acc= 0.8467, Validation cost= 0.2654, Validation acc= 0.8467
Epoch 35470: Training cost= 0.3117, Training acc= 0.8467, Validation cost= 0.2814, Validation acc= 0.8468
Epoch 35480: Training cost= 0.2566, Training acc= 0.8467, Validation cost= 0.2780, Validation acc= 0.8468
Epoch 35490: Training cost= 0.2422, Training acc= 0.8467, Validation cost= 0.3161, Validation acc= 0.8468
Epoch 35500: Training cost= 0.2864, Training acc= 0.8467, Validation cost= 0.3101, Validation acc= 0.8468
tm  [-0.9  1.5 -2.2 -1.6 -0.5 -0.2 -0.3 -0.2 -1.3 -0.6 -0.1 -0.2 -0.4 -0.6 -0.6  2.5  0.1 -0.   0.6  1.2 -1.  -0.2  1.6 -0.2 -1.4  2.4 -0.  -0.1 -1.4 -1.  -1.  -0.3 -0.5 -6.6 -0.2  0.5  4.6  5.3 -0.8 -0.8 -0.2  2.9  4.   1.5 -0.  -0.  -1.8 -0.2  0.1  5.9 -0.5 -0.2 -0.6 11.6 -0.4 -0.1 -1.2  8.3 -1.3  5.9  6.8 -0.5 -0.2 -0.2 -1.2  0.1 -0.2 -0.8 -0.1  0.8 -0.3  4.  -0.2 -0.4 -4.7  1.  -0.3 -0.1 -0.4  0.6 -5.6 -0.4 -0.1  0.4 -0.3  4.5 -0.1 -0.3  0.6  0.2 -1.2 -0.1 -0.3  5.6 -0.6 -0.1  1.9 -2.4 -0.7  0.6  3.2 -2.1 -0.3 -0.  -0.1 -0.4 -2.8 -0.7 -0.  -0.3 -0.6 -0.4 -0.4 -0.3 -0.8 -1.1  1.6 -1.3 -0.1 -0.6 -0.3 -0.1 -0.3 -0.1 -0.3 -0.6 -0.4 -2.8 -0.7  9.8 -0.5 -0.3 -0.2 -0.1  6.5 -4.2 -0.3 -0.1 -0.8  1.1 -1.1 -0.9 -1.2 -0.2 -0.5 -0.  -0.3 -0.4  9.7 -0.   0.2 -0.1  2.6 -0.8 -0.4 -0.2 -0.  -1.1  2.  -0.9 -0.2 -1.2 -0.1 -0.2 -0.2  0.2 -0.3 -1.1 -0.5 -0.  -0.   0.2 -0.4 -0.6 -0.4 -2.4 -0.2 -0.7  2.2 -0.1 -2.4  0.4 -0.2 -1.3 -0.2  1.  -0.3  2.  -0.3  2.8 -0.3 -0.3  0.1 -1.  -2.   3.5 -1.3  1.9 -0.2 -0.4  0.5 -0.1 -0.1 -0.2 -0.1 -3.7 -0.1  0.3  2.  -0.4 -0.5 -1.9  0.1  0.8  1.3 -0.1 -0.3 -0.6 -0.4 -0.5 -0.  -0.3 -0.4 -0.8 -1.   0.3  1.6 -0.7 -0.5 -0.3 -0.8  2.8 -0.5  0.8  1.9  2.2  0.5 -1.4 -0.4 -4.7 -0.3 -1.9 -0.1 -0.5 18.2  4.8  0.1 -0.  -0.4 -0.2 14.7 -0.4 -0.5 -0.1 -0.1 -2.2]
ty_50sample [[8 5 2 0 3 1 4 6 9 7]
 [4 4 6 6 2 8 3 1 0 5]
 [7 4 3 0 5 2 8 8 6 1]
 [0 9 8 1 3 5 6 2 4 7]
 [4 2 3 7 5 1 8 9 6 0]
 [5 1 6 3 4 8 2 2 0 7]
 [8 1 3 7 5 0 9 4 6 2]
 [2 4 8 5 6 1 3 3 0 9]
 [3 4 7 5 5 6 2 0 9 1]
 [7 5 9 4 6 2 1 0 8 3]]
tt_50sample [[8 5 2 0 3 1 4 6 9 7]
 [4 9 7 6 8 2 3 1 0 5]
 [7 4 3 0 5 2 8 9 1 6]
 [0 9 8 1 3 5 6 2 4 7]
 [4 2 3 7 1 5 8 9 6 0]
 [5 1 6 3 4 8 2 9 0 7]
 [8 1 3 7 0 5 9 4 6 2]
 [2 4 8 5 6 1 3 7 0 9]
 [3 4 7 8 5 2 6 0 9 1]
 [7 5 9 4 2 6 1 0 8 3]]
vm  [-1.4  0.1  0.7 14.3 -1.6 -0.2  0.5 -0.3 -0.6 -0.7 -1.6  0.2 -0.4 -0.1 -2.3  0.3 -0.7 -0.2  0.3 -0.6 -1.1 -0.2  1.6 -0.  -0.8  2.4 -0.1 -0.7 -0.1  1.   0.  -0.5  1.3 -0.3 -0.1  0.1  1.7 -1.2  4.  -0.3  2.6 -1.2  0.3 -0.3 -0.5 -0.4  7.8 -0.2 -1.2  4.9 -0.6 -0.2  3.2 -2.7 -1.5  2.8 -0.3 -1.8 -0.7  2.   1.1 -0.6 -0.1 -0.7  0.6 -0.9  0.   0.5  1.7 -0.3 -0.2 -1.1  2.5 -0.3  5.1 -0.5  0.9 -0.9  0.5 -0.4 13.1  1.7  0.2 -0.2  0.5 -1.1 -0.9 -0.3 -0.3 -0.6  1.6 -0.1 -0.2 -0.3 -0.5 -0.3 -1.1 -0.2 -0.6 -0.   2.   3.3  0.4 -0.2 -0.1 -0.1  3.2  0.3 -0.4 -1.3 -0.8 -0.6 -0.1 -0.2 -0.4  5.8  0.8 -1.1 -0.1  1.2 -0.1  4.5 -0.4 -0.4 -0.2 -2.8 -0.1 11.3 -1.2 -2.5 -0.5  0.   1.4 -0.1  7.3  8.2 -0.3  0.1 -0.1 -0.9  2.7 -0.5  1.1 -0.1 -0.1 -0.2 -0.2 -0.  -1.5 -0.1 -1.  -0.  -0.6  1.7  0.2  0.   0.2  0.6 -0.6 -0.3 -0.2  1.2  0.4 -0.1 -0.4 -0.8  0.4  1.5  0.  -0.2 -0.2 -0.4  0.1  1.6 -0.5  3.5 -1.2  1.1 -0.1 -0.2  2.7 -0.4  0.4 -2.  -0.2  0.6 -0.9 -0.1  0.4 -0.1 -0.1 -0.5 -0.2 -1.4  1.5  4.3  2.9  1.4 -0.  -0.1 -0.  -0.3 -0.9 -0.4 -0.2  7.3 -0.2 -0.3  6.8 -0.5 -0.4  2.4 -1.   8.7 -0.8 -0.1  2.5 -0.5  1.3  3.8 -0.2 -0.1  0.6 -0.9  2.6  2.9 -2.  -0.  -0.1 -0.8  1.5 -1.3  0.2  3.4 -0.7  0.4 -0.   3.4  2.6 20.6 -0.3  6.9 -0.3  0.4 -2.4 -3.4  0.1  0.1 -1.1 -0.2 -3.5 -0.1  2.4  0.4  3.4 10.8]
vy_50sample [[9 1 6 8 8 4 3 0 2 5]
 [0 9 6 5 4 2 1 3 8 7]
 [6 0 9 1 4 3 8 2 7 5]
 [7 9 3 5 4 1 2 6 0 0]
 [0 2 7 4 3 9 6 6 5 1]
 [0 4 1 3 8 6 2 5 9 7]
 [0 8 3 2 9 6 1 5 7 4]
 [2 3 1 6 8 5 7 9 4 0]
 [1 3 2 5 6 7 9 4 8 0]
 [6 0 1 7 5 8 9 4 3 2]]
vt_50sample [[9 1 6 8 4 7 0 3 2 5]
 [0 9 6 5 4 2 1 3 8 7]
 [6 0 9 1 4 3 8 2 7 5]
 [7 3 9 5 4 1 2 6 0 8]
 [0 2 7 4 3 9 8 6 5 1]
 [0 1 4 3 8 6 2 5 9 7]
 [0 8 3 2 9 6 1 5 7 4]
 [2 3 1 6 8 5 7 9 4 0]
 [1 2 3 6 5 7 4 9 8 0]
 [6 0 1 7 5 8 9 4 3 2]]
Epoch 35510: Training cost= 0.2675, Training acc= 0.8468, Validation cost= 0.2852, Validation acc= 0.8468
Epoch 35520: Training cost= 0.2799, Training acc= 0.8468, Validation cost= 0.2453, Validation acc= 0.8468
Epoch 35530: Training cost= 0.2882, Training acc= 0.8468, Validation cost= 0.2762, Validation acc= 0.8468
Epoch 35540: Training cost= 0.3400, Training acc= 0.8468, Validation cost= 0.2210, Validation acc= 0.8468
Epoch 35550: Training cost= 0.2430, Training acc= 0.8468, Validation cost= 0.2352, Validation acc= 0.8469
Epoch 35560: Training cost= 0.3033, Training acc= 0.8468, Validation cost= 0.2683, Validation acc= 0.8469
Epoch 35570: Training cost= 0.3559, Training acc= 0.8468, Validation cost= 0.2938, Validation acc= 0.8469
Epoch 35580: Training cost= 0.2786, Training acc= 0.8468, Validation cost= 0.2663, Validation acc= 0.8469
Epoch 35590: Training cost= 0.2605, Training acc= 0.8469, Validation cost= 0.2564, Validation acc= 0.8469
Epoch 35600: Training cost= 0.2596, Training acc= 0.8469, Validation cost= 0.2945, Validation acc= 0.8469
tm  [ 1.5  0.4  3.3 -0.4 -1.1  0.7 -0.3 -0.1 -0.9 -0.3  4.3  0.4 -0.4 -0.   4.3  0.   0.3 -0.1 -0.2 -1.3 -0.9 -0.2 -0.5 -0.  -0.8 -0.3 -0.3 -0.1 -0.4  9.2  5.  -0.1  2.5 16.1 -0.2 -0.4  1.1 -1.7 -1.1 -0.1 -0.3  0.9  2.9 -1.  -0.5 -0.4  6.8 -0.2  3.1 -1.5 -0.2 -0.1  0.3 -2.5 -1.3 -0.4 -0.9 -0.4 -1.6 -3.3 -2.4 -0.5  1.3 -0.5  0.5 -0.7 -0.3 -0.8 -0.1 -0.3 -0.2 -1.2 -0.8 -0.4 -1.5 -0.3 -0.4  0.1 -0.8 -0.4 21.3 -0.8 -0.3 -0.6 -2.   1.2  7.2 -0.1 -0.4  0.2 -1.2 -0.5 -0.3  3.5 -0.  -0.3 -0.  -0.5 -0.4 -0.1  1.7  5.8 -0.5 -0.  -0.2 -0.9 -0.9  2.8  1.  -2.5  0.1 -0.  -0.2 -0.8 -0.1  4.3  0.6 -0.6  0.3 -0.2 -0.6  6.8 -0.4 -0.2 -0.6  5.4  0.2 10.4 -1.7 -2.  -0.2 -0.1 -0.6  1.2  0.9 21.1 -0.  -0.3 -0.3 -0.8  0.2 -0.5 -0.3 -0.3 -0.2 -0.5 -0.3 -0.1 -1.4 -0.3 -0.3 -0.6  2.2 -0.3 -0.5 -0.  -0.8 -0.5 -1.8 -0.2 -0.9 -0.3 -0.2 -0.1 -0.2  3.4 -0.2 -0.8 -0.7 -0.2 -0.1 -0.5 -0.5 -0.8 -0.2  1.7 -1.6  0.1  2.1 -0.2 -1.2  2.   1.7 -0.6 -0.4 -0.7  2.9 -1.1 -0.5 -2.4 -0.4  0.  -0.4 -1.1 16.5  5.4  0.5 -0.2 -0.4 -0.1  0.4 -0.4  1.5 -0.2 -0.9  3.6 -0.1  0.1 -2.4 -0.2 -0.8  1.9  1.7 -2.   3.5  0.3  1.7 -0.7 -1.  -0.9  0.3 -0.2 -0.3 -0.7  1.7 -0.2 -2.6 -0.9 -1.9  2.3  0.3  1.4 -0.7 -1.1 -1.4 -0.3 -1.1 -0.2 -0.6  9.6 -0.1  3.3 -0.3 -0.3 -4.5 -2.3 -1.1 -1.  -0.6  2.1 -5.6  0.4 -0.9  0.1  4.1  8.7]
ty_50sample [[6 6 4 9 5 3 0 2 8 1]
 [1 3 0 9 4 7 6 2 8 5]
 [4 1 0 2 9 7 5 8 3 6]
 [9 7 6 5 2 1 0 8 3 3]
 [2 2 6 4 4 5 7 1 0 3]
 [2 1 5 3 9 8 4 6 7 0]
 [1 3 4 2 2 0 0 9 5 8]
 [4 6 0 0 8 5 7 3 1 2]
 [2 1 7 6 6 5 8 0 4 3]
 [4 1 7 2 9 6 8 0 5 3]]
tt_50sample [[7 6 4 9 5 3 0 2 8 1]
 [1 3 9 0 4 7 6 2 8 5]
 [4 1 0 2 9 7 5 8 3 6]
 [9 7 6 5 2 1 0 8 4 3]
 [2 9 6 4 8 5 7 1 0 3]
 [2 1 5 3 9 8 4 6 7 0]
 [1 3 4 7 2 6 0 9 5 8]
 [4 6 0 9 8 7 5 3 1 2]
 [2 1 7 9 6 5 8 0 4 3]
 [4 1 7 2 9 6 8 0 5 3]]
vm  [-0.1  0.9  0.2 -4.1 -1.8  0.2 -0.1 -0.1 -1.3 -1.2 -2.5 -0.3 -0.2 -0.3 10.6 -0.1 -0.  -0.3 -0.2  3.1 -0.7 -0.   1.4  1.  -1.9  2.2 -0.1 -0.3 -0.9  6.2  1.1  1.1 -0.3  0.6 -0.3  0.3  2.9 -0.4 -3.  -0.5  2.1  7.4  5.   2.4  0.3 -0.3 -2.3 -0.3  3.4 10.2 -0.5  0.3 -0.1  6.8 -0.4 -0.9 -1.   2.6 -1.6  0.7  4.2 -0.3 -0.4 -0.3 -0.8  1.2 -0.1 -0.3  0.8 -0.1 -0.5 -0.2 -0.1 -0.7 -4.7  1.4 -0.2  0.2 -0.2 -0.1 -5.1 -0.1 -0.1  0.9 -1.   8.5  6.7 -0.  -0.1 -0.4 -0.6 -0.1 -0.2  2.9 -0.4 -0.2  1.7 -2.5 -0.6 -0.3  3.8  6.  -0.8 -0.4 -0.1 -0.4 -2.8  0.2 -0.8  2.4 -0.9 -0.3 -0.1 -0.1 -0.9  1.8 -0.2 -1.  -0.2 -0.5 -0.3 -1.1 -0.3 -0.6 -0.3 13.3 -0.2 -1.1 -1.   3.5  1.4 -0.9 -0.4 -0.4 -0.8 -0.6 -0.3 -0.  -0.5 -0.3  0.8 -0.9  1.1  0.5 -0.4  0.5 -0.1 -0.2  3.4  0.5  1.7 -0.2  3.5 -0.1 -0.5  0.3 -0.4  1.1 -0.7 -0.5 -0.1  0.3 -0.4  0.  -0.3 -0.4 -0.3 -0.9  0.3 -0.   0.5 -0.1 -0.2 -0.3 -0.2 -0.3 -1.1 -0.6  5.3 -0.1 -2.1 -0.4 -0.4 -2.2 -0.4 -0.5  0.  -0.6 -0.3 -1.7 -0.2 -0.   0.7 -0.9 -0.8  3.7 -1.2  0.9  0.4 -0.3 -0.3 -0.3 -0.3 -0.3 -0.  -3.8 -0.1 -0.2 -0.4 -0.2 -0.3 -0.5 -0.2 -0.3 -0.7  0.1 -0.6 -0.5  1.1 -0.7  0.   0.1 -0.4 -1.2  3.5  3.1 -0.9 -0.8  1.3  2.6 -0.6  1.3 -0.2 -0.2  0.5  0.8  0.  -1.3  1.9 -5.2 -0.  -2.1  0.   0.4 15.9  4.2 -0.1 -0.4 -0.4 -0.9 13.5  0.1 -2.1 -0.  -0.1 -0.3]
vy_50sample [[5 8 8 7 6 0 2 1 3 9]
 [6 7 8 1 4 0 9 2 3 5]
 [0 9 4 3 6 5 1 8 7 2]
 [2 7 6 0 4 5 8 3 1 9]
 [6 1 3 8 0 2 5 9 4 7]
 [2 8 9 0 3 7 5 6 4 1]
 [3 9 4 5 2 2 8 0 1 7]
 [2 7 0 3 1 4 8 6 9 5]
 [1 3 4 2 8 7 9 0 5 6]
 [7 2 6 3 4 1 9 5 0 8]]
vt_50sample [[5 8 4 7 6 0 2 1 3 9]
 [6 7 8 1 4 0 9 2 3 5]
 [0 9 4 3 6 5 1 8 7 2]
 [2 7 6 0 4 5 8 3 1 9]
 [6 1 3 8 0 2 5 9 4 7]
 [2 8 9 0 3 7 5 6 4 1]
 [3 9 4 5 6 2 8 0 1 7]
 [2 7 0 3 1 4 8 6 9 5]
 [1 3 4 2 8 9 7 0 5 6]
 [7 2 6 3 4 1 9 5 0 8]]
Epoch 35610: Training cost= 0.2745, Training acc= 0.8469, Validation cost= 0.2462, Validation acc= 0.8469
Epoch 35620: Training cost= 0.2810, Training acc= 0.8469, Validation cost= 0.2422, Validation acc= 0.8470
Epoch 35630: Training cost= 0.2174, Training acc= 0.8469, Validation cost= 0.2884, Validation acc= 0.8470
Epoch 35640: Training cost= 0.2383, Training acc= 0.8469, Validation cost= 0.2853, Validation acc= 0.8470
Epoch 35650: Training cost= 0.2563, Training acc= 0.8469, Validation cost= 0.2379, Validation acc= 0.8470
Epoch 35660: Training cost= 0.2581, Training acc= 0.8470, Validation cost= 0.3013, Validation acc= 0.8470
Epoch 35670: Training cost= 0.2692, Training acc= 0.8470, Validation cost= 0.2880, Validation acc= 0.8470
Epoch 35680: Training cost= 0.2198, Training acc= 0.8470, Validation cost= 0.2588, Validation acc= 0.8470
Epoch 35690: Training cost= 0.2505, Training acc= 0.8470, Validation cost= 0.2218, Validation acc= 0.8471
Epoch 35700: Training cost= 0.1974, Training acc= 0.8470, Validation cost= 0.2253, Validation acc= 0.8471
tm  [-0.8 -0.2  4.1 18.1 -1.7 -0.1  0.3 -0.  -0.2 -0.4 -4.2 -0.5  0.   0.1 -2.3 -2.1 -0.3 -0.5 -0.  -1.4 -0.8 -0.4  2.1 -0.1 -0.6  3.4 -0.2  0.7 -1.4 -1.6 -1.3 -0.3 -0.3 -2.3  0.1 -0.2  2.6 -1.8  4.2 -0.3  0.3 -0.9 -0.  -1.1 -0.   0.  10.1  0.3 -0.1  4.3 -0.6 -0.1  0.3 -3.1  1.5  2.7 -0.4  3.   0.7  5.4 -0.8 -0.3 -0.8 -0.2 -0.5  1.2 -0.1 -0.5  2.3 -0.  -0.1  3.4  1.3 -0.5  5.3  0.5 -0.   0.3 -0.1  0.2  5.8 -0.  -0.4  2.6  0.1 -0.9 -1.1 -0.  -0.2 -0.2 -0.1 -0.1 -0.1 -0.7 -0.7 -0.2  1.  -0.9 -0.3 -0.4  1.3 -0.4 -0.3 -0.4 -0.1 -0.2  0.9 -1.  -1.2 -1.5 -0.2  0.2 -0.1  0.   3.5 -1.8 -0.4 -0.5 -0.2 -0.2 -0.4  7.4 -0.   0.4 -0.2 -2.9 -0.5 13.1 -0.3 -1.3  0.9 -0.5 -0.4 -0.6  8.8  3.2 -0.3 -0.1 -0.3 -0.2  2.1 -1.2  1.8  0.2  0.2 -0.1 -0.1  0.2 -0.1 -0.2 -1.2 -0.2  2.   1.5 -0.2  0.2  0.2 -0.2 -1.1 -0.1 -0.3  1.3 -0.1 -0.1  0.3 -0.6 -0.2  0.3 -0.2 -0.2 -0.1 -0.2  0.5  0.4 -0.2  1.1 -0.8  0.5 -0.2 -0.  -0.1 -0.1 -0.5 -1.8 -0.1  1.6 -0.1 -0.1  0.9  4.3 -0.3 -0.3 -0.6 -0.8  6.5  1.8  0.9 -0.8 -0.2  0.2 -0.2 -0.1 -0.4 -0.2 -0.1  2.  -0.2  0.1  7.5 -0.1 -0.7 -1.4 -0.4  2.  -0.8 -0.2  6.3 -0.8 -0.2 -0.3 -0.2 -0.2 -0.2 -1.1  2.9 -0.2 -1.7  0.2 -0.2  1.  -0.3 -1.3  0.   2.5  3.1 -0.6  0.5  3.2  3.3 17.6 -0.1  5.6 -0.  -0.  -0.7 -2.4  0.5 -0.3 -1.1 -0.2 -1.8 -0.   2.7 -0.3  6.3  6.5]
ty_50sample [[9 0 6 8 1 3 7 5 4 2]
 [0 1 8 5 2 6 7 9 4 3]
 [1 7 2 5 9 9 4 8 3 6]
 [0 7 3 2 8 9 4 5 1 6]
 [7 3 8 2 9 4 6 1 5 0]
 [6 9 8 5 2 0 3 4 1 7]
 [1 2 4 4 8 5 3 0 6 9]
 [1 7 2 5 6 8 8 9 4 0]
 [3 9 8 0 4 6 1 7 5 2]
 [0 4 7 3 9 1 6 5 8 8]]
tt_50sample [[9 0 6 8 1 3 7 5 4 2]
 [0 1 8 5 2 6 9 7 4 3]
 [1 7 2 5 9 0 4 8 3 6]
 [0 7 3 2 8 9 4 5 1 6]
 [7 3 8 2 9 4 6 1 5 0]
 [6 9 8 5 2 0 3 4 1 7]
 [1 2 7 4 8 5 3 6 0 9]
 [1 7 2 5 6 3 8 9 4 0]
 [3 9 8 0 4 6 1 7 5 2]
 [0 4 7 3 9 1 6 5 8 2]]
vm  [-1.2  0.7  3.6 19.7 -1.2 -0.4  0.6 -0.5 -0.8 -0.7  6.   0.8 -0.6 -0.5 -2.8  2.9 -0.5 -0.3  0.6 -1.  -0.8 -0.4 -0.7  0.3 -0.7  0.5 -0.2  0.2 -0.4 -2.2 -0.7 -0.4 -0.3 -0.7 -0.2 -0.3  2.5  5.2 17.1 -0.3  1.3  1.3  1.7 -0.3 -0.5 -0.5  9.  -0.5 -1.5 -2.4 -1.  -0.   1.2 -0.  -1.8  3.1 -0.1 11.2 -1.   4.2  0.3 -0.3 -0.4 -1.2  0.  -1.2 -0.3  1.  -0.1 -0.2 -0.5 -0.5 -0.  -1.   1.2 -0.3  1.2 -0.2 -0.6 -0.5 15.1 -0.2 -0.6 -0.6 -0.2  1.3 -2.2 -0.4 -0.  -0.1 -0.4 -0.2 -0.3  3.9 -0.8 -0.6 -0.6  0.4 -0.4 -0.4  3.  -1.9  0.2 -0.3 -0.5 -0.3 -0.9 -0.5  0.3 -2.1  0.1 -0.5 -0.3 -0.3 -1.3  2.5  2.6 -1.2 -0.1  2.5  0.1  6.4 -0.4 -0.5 -0.5 -3.4 -0.3  2.4 -0.   1.3 -0.7  0.4 -0.3  1.1 -1.2 -1.5 -0.3 -0.2 -0.4 -0.9 -0.5  0.6 -0.3  0.1 -0.2 -0.1 -0.  -0.1  7.5 -0.3 -1.6 -0.  -0.9  0.4 -0.4 -0.5 -0.   0.5  2.2 -0.7 -0.6 -1.9 -0.2 -0.3 -0.3 -0.3 -0.3 -0.4 -0.5  0.2 -0.1 -0.4 -0.6 -0.3 -0.2 -2.  -0.2 -0.8 -1.7 -0.1 -2.  -0.1  0.3 -1.9 -0.   1.1 -0.9 -0.3 -0.   6.1 -0.3 -0.3 -0.7 -1.4  1.6  1.6  0.4  3.3 -0.2 -0.5 -0.2 -0.2 -0.5 -0.1 -0.2  3.   1.1 -0.2 -3.9 -0.4 -0.7 -0.2 -0.4  4.6  0.3  1.2  0.7 -0.6 -0.1  1.1  0.  -0.4  1.5 -0.4 -2.   0.8 -0.4 -0.7 -0.  -0.7 -1.1 -0.  -0.1 -1.8 -0.9 -0.7 -0.3  0.3 -0.9 -0.2 -0.2 -0.2 -0.3 -0.3 -3.  -2.5  0.  -0.5 -0.5 -0.1 -4.2 -0.3 10.7 -0.2  2.7  0.6]
vy_50sample [[5 5 9 2 2 8 0 7 6 4]
 [7 9 8 1 6 3 2 5 4 0]
 [1 3 9 7 4 5 0 6 2 8]
 [2 6 3 7 5 9 0 8 1 4]
 [5 8 4 6 9 7 1 0 3 2]
 [3 0 6 6 4 8 2 9 5 1]
 [7 1 9 8 6 2 4 3 5 0]
 [8 4 4 1 6 9 0 5 2 3]
 [4 2 1 5 6 3 0 8 7 9]
 [5 7 6 4 2 0 1 3 9 8]]
vt_50sample [[5 3 9 1 2 8 0 7 6 4]
 [7 9 8 1 6 3 2 5 0 4]
 [1 3 9 7 4 5 0 6 2 8]
 [2 6 3 7 5 9 8 0 1 4]
 [5 8 4 6 9 7 1 0 3 2]
 [3 0 6 7 4 8 2 9 5 1]
 [7 1 9 8 6 2 4 3 5 0]
 [8 7 4 6 1 9 0 5 2 3]
 [4 2 1 5 6 3 0 8 7 9]
 [5 7 6 4 2 0 1 3 9 8]]
Epoch 35710: Training cost= 0.2713, Training acc= 0.8470, Validation cost= 0.2350, Validation acc= 0.8471
Epoch 35720: Training cost= 0.2445, Training acc= 0.8471, Validation cost= 0.2515, Validation acc= 0.8471
Epoch 35730: Training cost= 0.2383, Training acc= 0.8471, Validation cost= 0.2439, Validation acc= 0.8471
Epoch 35740: Training cost= 0.2822, Training acc= 0.8471, Validation cost= 0.2512, Validation acc= 0.8471
Epoch 35750: Training cost= 0.2101, Training acc= 0.8471, Validation cost= 0.2596, Validation acc= 0.8471
Epoch 35760: Training cost= 0.2279, Training acc= 0.8471, Validation cost= 0.2559, Validation acc= 0.8472
Epoch 35770: Training cost= 0.2566, Training acc= 0.8471, Validation cost= 0.2420, Validation acc= 0.8472
Epoch 35780: Training cost= 0.2792, Training acc= 0.8471, Validation cost= 0.2928, Validation acc= 0.8472
Epoch 35790: Training cost= 0.2783, Training acc= 0.8471, Validation cost= 0.2400, Validation acc= 0.8472
Epoch 35800: Training cost= 0.3120, Training acc= 0.8472, Validation cost= 0.3137, Validation acc= 0.8472
tm  [-1.2 -0.4  6.7  9.6 -1.6 -0.3  0.1 -0.2 -0.4  1.1  6.1 -0.2 -0.3  0.1  3.6 -0.8 -0.3 -0.3 -0.3 -1.4 -1.2 -0.3 -1.1 -0.3 -0.6 -0.3  1.  -0.1 -1.2 -2.8  1.3 -0.2 -0.5 11.1  0.3 -0.4  2.4  4.  11.2 -0.1  1.3  4.6  0.7  2.3 -0.4 -0.   4.1 -0.1 -2.  -3.2 -0.7 -0.  -0.6  0.7 -0.6 -0.4 -0.5 10.4  2.1 -0.   6.3 -0.4 -0.7 -0.5  2.  -0.7 -0.3 -0.1 -0.1 -0.4 -0.2  3.4 -0.6 -0.7 -3.1 -0.7  0.4  0.  -0.1 -0.6 13.1  0.4 -0.7 -0.4  1.2  3.5 -1.9  0.1 -0.3 -0.4 -0.3 -0.   0.3  1.7 -0.7 -0.3 -0.7 -1.9  0.5 -0.6  0.3 -0.4  1.8 -0.1 -0.2 -0.2 -2.4  0.2 -0.  -1.4  0.3 -0.5 -0.2 -0.7  2.4 -1.6 -0.4  0.5 -0.1 -0.5  0.1  5.1 -0.1 -0.3 -0.1  4.2 -0.3  2.   4.3  5.5 -0.8 -0.2 -0.2  0.9 -4.5  0.  -0.5 -0.1 -0.2 -0.6 -0.2  0.2  0.7 -0.  -0.3 -0.2 -0.5  0.2  6.3 -0.3 -0.8 -0.1 -1.9 -0.4 -0.1 -0.4  0.  -0.1  1.7 -0.4 -0.3 -2.  -0.3 -0.4 -0.1  1.3 -0.6 -0.2 -0.2 -0.  -0.  -0.5  0.  -0.  -0.1 -1.   1.  -1.3 -1.1 -0.2 -2.7 -0.3 -0.4 -1.3 -0.  -0.2 -1.1 -0.9 -0.2  8.1 -0.1 -0.4 -0.9 -1.  -1.7 -0.6 -1.1 -0.4 -0.2 -0.3 -0.3  1.   0.4 -0.3  0.2 -2.5 -0.1 -0.3 -6.4  0.2 -0.9 -1.5 -0.6  5.5 -0.4  0.4 -0.5 -1.3 -0.1 -0.  -0.2 -0.   1.5 -0.6 -1.5 -1.3 -0.7 -0.4 -1.2 -0.4 -1.2  2.8 -0.2 -3.3  0.7 -1.2  2.3 -1.   1.3 -3.8 -0.2 -1.6 -0.2  0.1 -2.7  1.7 -0.5 -0.5 -1.1 -0.2 -3.7 -0.3  7.7 -0.2  3.4 -0.7]
ty_50sample [[5 1 0 3 7 9 2 4 8 6]
 [1 0 8 6 7 5 4 9 2 3]
 [2 5 0 4 7 3 8 1 1 6]
 [2 1 6 9 5 7 3 4 0 0]
 [2 7 9 1 8 4 3 5 0 6]
 [0 9 2 4 8 5 1 7 3 6]
 [9 7 8 8 5 6 2 3 0 4]
 [5 6 3 0 7 8 2 9 1 4]
 [2 1 6 4 8 3 0 5 7 9]
 [8 3 1 7 0 6 4 9 2 5]]
tt_50sample [[5 1 0 3 7 2 9 4 8 6]
 [1 0 8 6 7 5 9 4 2 3]
 [2 5 0 4 7 3 8 9 1 6]
 [2 1 6 9 5 7 3 4 0 8]
 [2 7 9 1 8 4 3 0 5 6]
 [0 9 2 4 8 5 1 3 7 6]
 [9 7 1 8 5 6 2 3 0 4]
 [5 6 3 0 7 8 2 9 1 4]
 [2 1 6 4 8 3 0 5 7 9]
 [8 3 1 7 0 6 4 9 2 5]]
vm  [-0.1 -0.3 -0.5 -4.5 -1.4  0.1 -0.4 -0.3 -0.   1.3 -7.2 -0.5 -0.2 -0.3 10.1 -0.8 -0.1 -0.6 -0.1 -0.5 -1.1 -0.3  0.1 -0.3 -0.7 -0.8 -0.5  0.1 -0.  -0.3 -0.5 -0.1  1.3 -2.2 -0.2 -0.4 -0.5  2.5  1.3 -0.4 -0.3  8.1 -0.6  4.9 -0.6 -0.5 -1.  -0.5  0.7 15.7 -0.5 -0.5 -1.6  1.2 -0.9 -1.1 -0.9  2.1  2.9  3.   1.9 -0.5 -0.5 -0.3 -0.6 -0.4 -0.2 -0.   0.6 -0.2 -0.4 -0.9 -0.6 -1.  -5.8  1.7 -0.8  0.5 -0.1 -0.2 -7.5 -0.7 -0.   0.3 -0.9  8.6  4.2 -0.3 -0.3 -0.3 -0.  -0.2 -0.2 -0.4 -0.4 -0.3  1.4 -3.2 -0.3 -0.5 -0.3  5.5 -0.3 -0.3  0.  -0.9 -3.1 -0.5 -2.   1.8  1.4  0.4 -0.2 -0.9  2.7  1.4 -0.2  1.9  0.1 -0.3 -0.9 -0.7 -0.  -0.4 -0.4 12.2 -0.1  0.9  3.6  1.1 -0.1 -1.  -0.  -0.4 -4.2 -7.2 -0.  -0.1  0.3 -0.   1.7 -0.3  0.5 -0.2 -0.   0.  -0.6 -0.2  3.9 -0.   2.7 -0.   2.4 -0.3 -0.3 -0.3 -0.2  0.2  1.4 -0.5 -0.  -1.7 -0.4 -0.1 -0.6  1.4 -0.1  0.7 -0.5 -0.   0.   0.6 -0.1 -0.1 -0.3 -0.3 -0.2 -1.2 -0.3 -0.3 -1.8 -0.6  0.1 -0.4 -0.3 -0.5  0.6 -0.5 -0.6  1.  -0.1 -0.2 -0.2 -0.7 -0.4 -1.2 -1.7 -0.8 -0.4 -0.2 -0.4 -0.2  0.2 -0.8 -0.2 -3.8 -0.2  0.2  3.8 -0.3 -0.6 -0.2 -0.6 -0.5  0.6 -0.  -1.6 -0.6 -0.2 -0.9 -0.1 -0.4 -0.3 -1.   0.9  1.2 -1.1  0.8 -0.   3.2 -0.9  2.9 -0.5  1.5 -0.6  1.2  1.8 -2.1  0.4 -5.4 -0.2 -2.  -0.4 -0.1 21.6  4.3 -0.2 -0.8 -0.8  0.3 19.8 -0.4  1.3 -0.1 -0.   0.8]
vy_50sample [[8 5 4 7 0 1 2 9 6 6]
 [6 1 7 9 8 2 4 5 0 3]
 [1 3 4 6 5 8 9 2 7 0]
 [5 0 1 9 3 6 7 2 4 8]
 [6 1 5 0 7 2 3 9 4 8]
 [3 5 0 4 1 6 2 9 9 7]
 [9 8 2 1 0 5 7 6 4 3]
 [3 5 1 0 4 7 6 8 2 9]
 [6 0 8 4 9 5 1 7 3 2]
 [5 6 0 4 8 1 2 7 9 3]]
vt_50sample [[8 5 4 7 0 1 2 9 6 3]
 [6 1 7 9 8 2 4 5 0 3]
 [1 3 4 5 6 8 9 2 7 0]
 [0 5 1 9 3 6 7 2 4 8]
 [6 1 5 0 7 2 3 9 4 8]
 [3 5 4 0 1 6 2 9 8 7]
 [9 8 2 1 0 5 7 6 4 3]
 [3 5 1 0 4 7 6 8 2 9]
 [6 0 8 9 4 5 1 7 3 2]
 [5 6 0 4 8 1 2 7 9 3]]
Epoch 35810: Training cost= 0.2714, Training acc= 0.8472, Validation cost= 0.3268, Validation acc= 0.8472
Epoch 35820: Training cost= 0.2471, Training acc= 0.8472, Validation cost= 0.2140, Validation acc= 0.8472
Epoch 35830: Training cost= 0.3267, Training acc= 0.8472, Validation cost= 0.2483, Validation acc= 0.8473
Epoch 35840: Training cost= 0.2508, Training acc= 0.8472, Validation cost= 0.2554, Validation acc= 0.8473
Epoch 35850: Training cost= 0.2176, Training acc= 0.8472, Validation cost= 0.2715, Validation acc= 0.8473
Epoch 35860: Training cost= 0.2594, Training acc= 0.8472, Validation cost= 0.3110, Validation acc= 0.8473
Epoch 35870: Training cost= 0.2377, Training acc= 0.8473, Validation cost= 0.2637, Validation acc= 0.8473
Epoch 35880: Training cost= 0.2348, Training acc= 0.8473, Validation cost= 0.2797, Validation acc= 0.8473
Epoch 35890: Training cost= 0.2460, Training acc= 0.8473, Validation cost= 0.2890, Validation acc= 0.8473
Epoch 35900: Training cost= 0.2828, Training acc= 0.8473, Validation cost= 0.2275, Validation acc= 0.8473
tm  [-0.1  0.1 11.4 21.9 -0.5 -0.3 -0.5 -0.1 -0.6 -0.1 10.2 -0.3 -0.4  1.  -0.1  4.  -0.4 -0.5 -0.2 -2.1 -0.9  0.5 -0.8 -0.5  0.2 -0.3 -0.  -0.4 -0.3  2.8  0.4 -0.4  1.1 15.1 -0.1 -0.2  2.1 -0.4  0.7 -0.1  0.9 -0.1  0.6 -2.  -0.1 -0.2 10.4 -0.1  2.7 -2.8 -0.2 -0.1 -0.2 -1.  -0.7 -0.  -0.2  7.2 -0.9  1.5 -2.  -0.4 -0.3  0.9  2.  -0.5 -0.3 -0.5 -0.1 -0.4 -0.1 -0.6 -0.5 -0.5  2.7 -0.7 -0.5 -0.4 -0.1 -0.2 25.4 -0.1 -0.4  0.1 -0.8  0.4 -0.4 -0.2 -0.3  0.2 -0.2 -0.1 -0.3  0.5 -0.3 -0.  -0.4 -0.4  0.7 -0.2  1.6  4.  -0.1 -0.  -0.2 -0.5 -0.1 -0.1  0.6 -2.7  0.4 -0.2 -0.1 -0.7 -0.4  5.  -0.4 -0.5 -0.1 -0.5 -0.3 10.2  1.2 -0.   0.1 -0.1 -0.   5.1 -0.6 -1.3 -0.  -0.3  0.3 -0.6  4.1 20.4 -0.1 -0.  -0.3 -0.4 -0.9  1.3 -0.2  0.2 -0.1 -0.1 -0.3 -0.1 -0.9 -0.1 -1.9 -0.2  0.3 -0.5 -0.  -0.2 -0.1 -0.4 -1.5 -0.4 -0.1  2.4 -0.3 -0.  -0.2  2.6 -0.1 -0.1 -0.2 -0.2 -0.2 -0.2  0.7 -0.2 -0.1  1.9 -1.2 -0.3  0.2 -0.2 -1.5 -0.4 -0.1 -0.9 -0.3 -0.2  1.3 -1.  -0.1 -0.4 -0.1 -0.1 -0.5 -0.4 13.8  2.1  1.8 -0.  -0.2 -0.  -0.2 -0.1  0.6 -0.7 -0.4  2.2  0.6  1.  -2.9  0.5 -0.3  1.3 -0.4 -1.2  0.  -0.1  8.6 -1.   0.4  0.1 -0.2 -0.3  1.6 -0.4  3.3 -0.4  0.6  0.5 -1.2  3.1  0.1 -0.5  0.4 -1.5 -0.5 -2.5 -0.2  1.7  0.8 10.2 -0.3  3.6 -0.2 -0.  -5.6 -1.7 -0.4 -0.1 -0.9 -0.1 -6.6 -0.3  0.3 -0.3 -0.2  6.3]
ty_50sample [[6 9 7 2 3 5 0 1 4 8]
 [7 3 9 1 4 0 2 5 8 6]
 [4 6 0 3 8 1 5 9 7 7]
 [6 1 2 0 8 7 9 4 3 5]
 [9 1 0 5 7 8 2 4 3 6]
 [6 9 1 4 0 3 8 5 7 2]
 [9 4 8 5 7 2 6 0 1 3]
 [4 5 9 7 0 3 1 8 6 2]
 [1 4 0 3 6 7 5 8 2 9]
 [3 4 0 1 9 6 5 8 7 2]]
tt_50sample [[6 9 7 2 3 5 0 1 4 8]
 [7 3 1 9 4 0 2 5 8 6]
 [4 6 0 3 8 1 5 9 2 7]
 [6 1 2 0 8 7 9 4 3 5]
 [9 1 0 5 7 8 2 4 3 6]
 [6 9 1 4 0 3 8 5 7 2]
 [9 4 8 7 5 6 2 0 1 3]
 [4 5 9 7 0 3 1 6 8 2]
 [1 4 0 3 6 7 5 8 2 9]
 [3 4 0 1 9 6 5 8 2 7]]
vm  [-1.7  1.6  0.1  7.9 -1.4 -0.1 -0.1 -0.3 -0.8 -0.4 11.5 -0.4 -0.1 -0.2 -1.1  4.1  1.9 -0.1 -0.  -1.2 -1.  -0.4 -0.9 -0.3 -0.9  2.  -0.3  0.4 -1.3 -0.8  2.4 -0.5 -0.4  9.4  0.2  0.8  3.6  2.6  5.2 -0.1 -0.7 -1.9 -0.4 -0.6 -0.2  0.2  5.3  0.1 -1.9 -2.9 -0.2 -0.3 -0.4  1.  -0.4  1.1  0.3 -0.7 -0.2 -2.   2.8 -0.1 -0.4 -0.1 -0.7 -0.2  0.3 -0.9 -1.4  0.6  0.4  2.  -0.1  1.3  1.9 -0.   2.3 -0.3 -0.1 -0.4 23.6 -0.2 -0.5 -1.   3.5 -1.1 -1.7 -0.4  1.2  0.4 -0.1 -0.2  0.2  0.9 -0.7 -0.2  0.6 -0.4  1.2  0.7  2.3 -0.4  2.9 -0.3 -0.3 -0.4 -0.1  0.6 -0.1 -2.2 -0.4 -0.  -0.   0.1  1.6  0.2 -0.4 -1.2 -0.2 -0.9 -0.4  9.8 -0.1 -0.3 -0.  -1.5 -0.1  1.1 -1.2 -1.1 -0.7  0.3 -0.3 -0.3  6.6 14.6 -0.9 -0.2  1.6 -0.2 -0.7 -0.4 -1.2  0.  -0.1 -0.1 -0.1 -0.3 -1.1 -0.  -0.8 -0.3 -2.5 -0.5 -0.3 -0.1 -0.9 -0.3 -0.6 -0.2  0.6  0.8 -0.3 -0.1  0.7  2.8 -0.2  1.4 -0.  -0.5 -0.1  0.  -0.3 -0.4 -0.2  2.3 -0.3 -0.  -0.3  0.3  0.2  1.2 -0.1 -1.  -0.3 -1.  -1.5 -0.9 -0.2  3.  -0.   0.3  0.  -0.3 -0.3  4.9  2.1 -0.4 -0.5  0.3 -0.3  1.2  0.2 -0.4  0.2  2.9 -0.1  0.6 -0.   1.  -0.9 -0.9 -0.1 10.5  1.9 -0.2  3.  -0.9 -0.6 -0.5 -0.1  0.5  0.4 -0.7  3.7 -1.2  1.8  1.9 -0.8 -1.  -0.6 -1.4 -0.4 -0.1  2.   1.5 -0.7  2.1 -0.3 21.3 -0.2  8.  -0.1 -0.3 -5.2 -1.2 -0.6 -0.4 -1.3 -0.3 -6.1 -0.1  2.6 -0.4 -0.7  5.5]
vy_50sample [[1 9 2 6 0 3 4 7 5 8]
 [3 4 0 5 2 8 9 7 6 1]
 [7 5 0 6 1 1 9 2 3 4]
 [2 8 4 3 6 1 5 9 0 7]
 [6 7 2 5 4 8 0 9 3 1]
 [8 6 4 1 2 0 7 3 9 5]
 [6 5 2 7 4 0 9 1 8 3]
 [8 3 9 5 7 2 0 4 1 6]
 [1 5 8 2 0 9 3 7 6 4]
 [1 4 3 9 7 6 0 8 5 2]]
vt_50sample [[1 9 2 6 0 3 4 7 5 8]
 [3 4 0 5 2 8 9 7 6 1]
 [7 5 0 6 8 1 9 2 3 4]
 [2 8 4 3 6 1 5 9 0 7]
 [6 7 2 5 8 4 0 9 3 1]
 [8 6 4 1 2 0 7 3 9 5]
 [6 5 2 7 4 0 9 1 8 3]
 [8 3 9 5 7 2 0 4 1 6]
 [1 5 8 0 2 9 3 7 6 4]
 [1 4 3 9 7 6 0 8 5 2]]
Epoch 35910: Training cost= 0.2781, Training acc= 0.8473, Validation cost= 0.2184, Validation acc= 0.8474
Epoch 35920: Training cost= 0.2647, Training acc= 0.8473, Validation cost= 0.2401, Validation acc= 0.8474
Epoch 35930: Training cost= 0.2281, Training acc= 0.8473, Validation cost= 0.3162, Validation acc= 0.8474
Epoch 35940: Training cost= 0.2515, Training acc= 0.8473, Validation cost= 0.2880, Validation acc= 0.8474
Epoch 35950: Training cost= 0.2379, Training acc= 0.8474, Validation cost= 0.2873, Validation acc= 0.8474
Epoch 35960: Training cost= 0.2560, Training acc= 0.8474, Validation cost= 0.3253, Validation acc= 0.8474
Epoch 35970: Training cost= 0.3554, Training acc= 0.8474, Validation cost= 0.2866, Validation acc= 0.8474
Epoch 35980: Training cost= 0.3136, Training acc= 0.8474, Validation cost= 0.3227, Validation acc= 0.8474
Epoch 35990: Training cost= 0.2883, Training acc= 0.8474, Validation cost= 0.2519, Validation acc= 0.8475
Epoch 36000: Training cost= 0.2413, Training acc= 0.8474, Validation cost= 0.2926, Validation acc= 0.8475
tm  [-1.1  0.1 -0.9 12.2 -0.8 -0.4 -0.2 -0.1  0.3 -0.4 12.7 -0.5 -0.3 -0.2 -2.9  5.3 -0.2 -0.2 -0.2 -1.3 -1.2 -0.2 -1.   0.2 -0.5  0.6 -0.3 -0.3 -0.6 -1.5  3.3 -0.5  1.7  5.3 -0.  -0.5  0.6  0.8  1.6 -0.3  1.4 -2.  -1.1 -1.  -0.2 -0.3  8.2 -0.6 -0.3 -3.  -0.3 -0.2  0.5  1.1 -1.1  3.4 -0.2 -0.9  3.1 -1.7 -0.7 -0.7 -0.3 -0.2 -0.3 -0.8 -0.2  0.7 -0.4 -0.2 -0.3 -0.9  0.7 -0.2  1.2 -0.2 -0.4 -0.3 -0.2 -0.4 24.2 -0.1 -0.2 -0.3 -0.2 -1.6 -0.5 -0.1 -0.3 -0.3  0.9 -0.2 -0.  -0.5 -0.4  0.1 -0.6 -0.8 -0.3 -0.5  2.2 -1.2 -0.  -0.2 -0.  -0.6 -0.2  2.   0.8 -2.2 -0.1 -0.1 -0.1 -0.4  1.7  5.9  1.6 -0.6 -0.1 -0.2 -0.5  6.9 -0.3 -0.1 -0.3 -3.6  0.4  0.7  1.9 -1.3 -0.6 -0.3  0.  -0.2 13.1 19.2 -0.1  0.1 -0.1 -0.6 -0.6 -0.2 -0.9 -0.  -0.  -0.3 -0.4 -0.1 -0.1 -0.2 -1.2 -0.2 -1.2 -0.3 -0.2 -0.  -0.3 -0.3 -0.8  0.1 -0.3  1.3 -0.2 -0.1 -0.3  0.4 -0.1  2.1 -0.4  0.7 -0.2 -0.1 -0.2 -0.2 -0.2  1.1 -1.   0.5 -0.  -0.2  1.1 -0.4 -0.  -1.2 -0.2 -0.2 -0.2 -0.2 -0.2  4.8 -0.3 -0.3 -0.4 -0.8  6.1 -0.6  2.1 -0.2 -0.2  0.2  0.1 -0.1 -0.4 -0.6 -0.5  2.8 -0.3 -0.1 -0.8 -0.4 -0.5  2.1 -0.9  3.3 -0.3 -0.3  4.4 -1.2 -0.4  0.9 -0.2 -0.1 -0.3 -0.7  2.5 -0.3  0.6  0.7  1.5  0.6 -0.  -0.8 -0.3 -0.5 -0.4  1.7 -0.1  0.8  0.6 19.6 -0.2  6.9 -0.  -0.4 -5.2 -2.6 -0.  -0.5 -1.4 -0.1 -6.2 -0.1  0.9 -0.4 -0.3  6.5]
ty_50sample [[2 6 9 1 3 4 0 7 5 8]
 [3 8 6 9 7 5 0 2 1 4]
 [2 3 1 1 0 0 7 9 4 6]
 [9 7 3 8 5 4 6 1 2 0]
 [3 6 7 1 8 9 4 0 2 5]
 [9 2 7 3 0 5 6 8 4 1]
 [7 0 2 6 3 8 5 1 4 9]
 [6 7 2 4 1 9 3 8 0 5]
 [4 9 6 8 2 7 1 5 3 0]
 [3 2 6 8 5 9 7 4 1 0]]
tt_50sample [[2 6 9 1 3 4 0 7 5 8]
 [3 8 6 9 7 5 0 2 1 4]
 [2 3 1 5 0 8 7 9 4 6]
 [9 7 3 8 5 4 6 1 2 0]
 [3 7 6 1 8 9 4 0 2 5]
 [9 2 7 3 0 5 6 8 4 1]
 [7 0 2 6 3 8 5 1 4 9]
 [6 7 2 4 1 9 3 8 0 5]
 [4 9 6 8 2 7 1 5 3 0]
 [3 2 6 8 5 9 7 4 1 0]]
vm  [ 1.9 -0.4  6.6  3.5 -1.6 -0.  -0.6 -0.4 -0.5  2.5 -6.2 -0.1 -0.1 -0.3  6.6 -2.1 -0.1 -0.6 -0.1 -0.8 -0.7 -0.2  0.  -0.5 -0.4 -0.5 -0.1  0.  -1.2 -1.2 -2.1 -0.7 -0.8 -2.  -0.2 -0.2  0.1 -0.3  0.1 -0.6 -0.7  4.7 -0.3 -0.4 -0.5 -0.  -0.7  0.7  5.4  4.7 -0.4 -0.5 -1.4 -0.3 -0.5 -0.8 -0.8 10.6  1.4  5.9 -0.2 -0.8 -1.  -0.3 -0.3 -1.  -0.1  0.7  0.6 -0.3 -0.1  3.7 -0.8 -0.5 -5.9 -0.9 -1.1 -0.6  0.2  0.5 -5.5  0.5 -0.6 -0.3 -2.1  3.3  2.8 -0.3  0.  -1.1 -0.4 -0.1 -0.2  0.4 -0.6  0.5 -0.4 -3.  -0.1 -0.6 -1.  -0.2 -1.1 -0.1 -0.  -0.  -2.5 -1.2 -1.9 -0.5  1.7 -0.4 -0.1 -0.4  2.  -2.2 -0.8  2.4 -0.1 -0.2 -0.1  1.6  0.1 -0.9 -0.5  8.  -0.5  3.9  2.7  8.4  3.5 -0.3  0.5 -0.3 -2.  -4.3 -0.5  0.1 -0.1 -0.7  0.2 -0.7  0.2 -0.4 -0.1 -0.4 -0.4 -0.1  5.8 -0.2 -0.7 -0.1  3.3 -0.6 -0.1 -0.3  0.   1.  -0.5 -0.7 -0.2 -1.5 -0.1 -0.3 -0.2  2.  -0.5 -0.7 -0.2 -0.5 -0.2  0.7 -0.8  0.1 -0.1 -1.1 -0.  -0.9  0.6 -0.2 -3.2 -0.6 -0.4 -1.  -0.2  1.2  3.  -0.3 -0.4  3.5 -0.3 -0.1 -0.4 -0.6  4.4 -0.6 -1.7 -0.6 -0.2 -0.2 -0.3 -0.1 -0.2 -0.1 -0.5 -2.8 -0.1 -0.6 -1.3 -0.4 -1.3 -2.1 -0.9 -2.7  0.3 -0.4  2.8 -0.6 -0.3 -0.8  0.1 -0.1 -0.2 -1.3 -0.8 -0.9 -1.7 -0.6  0.2  3.8 -0.9  2.3 -0.4 -0.7 -0.6 -1.3  0.9 -1.8 -0.1 -6.5 -0.2 -2.4 -0.2  0.7 16.5  3.6  0.1 -0.3 -0.5 -0.3 14.6 -0.1  0.2  0.3  5.4 -1.7]
vy_50sample [[5 0 8 3 7 6 9 4 2 1]
 [6 2 4 8 5 1 3 9 0 7]
 [9 2 4 8 8 7 1 6 5 3]
 [7 6 1 5 3 4 8 9 0 2]
 [5 7 3 0 1 4 6 9 2 8]
 [7 2 3 3 0 6 9 9 1 4]
 [3 8 4 7 5 6 1 0 2 9]
 [5 6 0 7 9 8 4 1 3 2]
 [9 2 6 4 7 0 5 1 3 8]
 [5 4 0 2 1 6 9 3 8 7]]
vt_50sample [[5 0 8 3 7 6 9 4 1 2]
 [6 2 4 8 5 1 3 0 9 7]
 [9 2 4 0 8 7 1 6 5 3]
 [7 6 1 5 3 4 8 9 0 2]
 [5 7 3 0 1 4 6 9 2 8]
 [7 2 3 8 0 6 5 9 1 4]
 [3 8 4 7 5 6 1 0 2 9]
 [5 6 0 7 9 8 4 1 3 2]
 [9 2 6 4 7 0 5 1 3 8]
 [5 4 0 2 1 6 9 3 8 7]]
Epoch 36010: Training cost= 0.2447, Training acc= 0.8474, Validation cost= 0.2261, Validation acc= 0.8475
Epoch 36020: Training cost= 0.2138, Training acc= 0.8475, Validation cost= 0.2287, Validation acc= 0.8475
Epoch 36030: Training cost= 0.2505, Training acc= 0.8475, Validation cost= 0.2179, Validation acc= 0.8475
Epoch 36040: Training cost= 0.2581, Training acc= 0.8475, Validation cost= 0.2725, Validation acc= 0.8475
Epoch 36050: Training cost= 0.2400, Training acc= 0.8475, Validation cost= 0.3355, Validation acc= 0.8476
Epoch 36060: Training cost= 0.2718, Training acc= 0.8475, Validation cost= 0.2305, Validation acc= 0.8476
Epoch 36070: Training cost= 0.2926, Training acc= 0.8475, Validation cost= 0.2611, Validation acc= 0.8476
Epoch 36080: Training cost= 0.2399, Training acc= 0.8475, Validation cost= 0.2665, Validation acc= 0.8476
Epoch 36090: Training cost= 0.2699, Training acc= 0.8476, Validation cost= 0.3139, Validation acc= 0.8476
Epoch 36100: Training cost= 0.3060, Training acc= 0.8476, Validation cost= 0.3150, Validation acc= 0.8476
tm  [ 1.3  0.8 -1.8  2.8 -1.1 -0.2 -0.1 -0.2 -0.8 -0.8  4.7 -0.  -0.2 -0.1 -1.8  3.8 -0.4 -0.1 -0.2 -0.7 -1.  -0.2  1.8 -0.  -1.3  1.1 -0.  -0.3 -0.6 -0.5  1.7 -0.3 -0.1 -2.  -0.1  0.1  2.7  6.  11.2 -0.7  1.   5.8  3.6  3.1 -0.2 -0.   5.2 -0.5  6.   5.1 -0.6 -0.2  0.6  1.5 -1.1  2.3 -0.4  3.7 -1.  -0.3 -1.5 -0.5 -0.2 -0.2  0.2 -0.7 -0.2  0.6 -0.2 -0.1 -0.  -0.3  0.7 -0.2 -0.6 -0.6 -0.5 -0.7  0.4 -0.2  5.4 -0.  -0.3 -0.  -1.5  5.5  6.8 -0.2 -0.  -0.2 -0.2 -0.  -0.3  1.6 -0.4 -0.1 -0.3 -1.1 -0.4 -0.2  2.9 -0.2 -1.2 -0.3 -0.1 -0.1 -0.5  1.2  1.  -1.2 -0.5 -0.4 -0.1 -0.5 -0.9  2.6  0.  -1.2 -0.4  0.4 -0.2  3.9  0.  -0.5 -0.4 -2.2 -0.3  0.8 -0.1 -1.3  0.7 -0.2 -0.  -0.2 -0.4 -2.2 -0.3 -0.1  0.  -0.6 -0.7 -0.5 -0.6  0.6 -0.1 -0.2 -0.3 -0.1  7.4 -0.1 -0.4 -0.2  3.9 -0.5 -0.  -0.1 -0.3 -0.1  2.2 -0.2  0.4 -1.2 -0.3 -0.1 -0.2 -0.4 -0.2 -0.8  0.3 -0.1 -0.2 -0.2 -0.2 -0.2 -0.4 -1.5 -0.5 -0.3 -1.  -0.2 -1.9 -0.5 -0.4 -1.6 -0.2 -0.2  2.6 -0.1 -0.4  1.7 -0.2 -0.4 -0.5 -1.2 11.2  0.8  1.4  1.8 -0.1 -0.1 -0.1 -0.1 -0.5 -0.3 -0.2 -0.  -0.2 -0.1 -2.9 -0.  -0.7 -0.2 -0.9 -1.1 -0.2 -0.4 -1.1 -0.9 -0.4 -0.3 -0.2 -0.1  0.2 -0.7 -0.7  1.8 -0.  -0.3 -0.4  2.5 -0.9 -0.6 -0.2 -1.3 -0.2  3.2  0.7  0.9  0.5 -1.4 -0.2 -0.6 -0.2  0.3 -0.6 -2.  -0.1 -0.2 -1.1 -0.1 -1.7 -0.2  7.3 -0.1 -0.5  6.5]
ty_50sample [[5 9 2 4 8 0 3 7 6 1]
 [4 1 7 5 9 0 8 6 2 3]
 [3 2 5 6 7 8 0 1 9 4]
 [9 7 5 8 3 6 2 4 0 1]
 [0 3 9 6 1 8 2 7 5 4]
 [9 5 1 8 6 3 0 4 7 2]
 [7 1 2 9 3 8 5 4 6 0]
 [2 6 3 8 0 4 5 1 7 9]
 [4 7 3 8 0 1 5 2 9 6]
 [2 9 1 7 0 3 8 5 6 4]]
tt_50sample [[5 9 2 4 8 0 3 7 6 1]
 [4 1 7 5 9 0 8 6 2 3]
 [3 2 5 6 7 8 0 1 9 4]
 [9 7 5 8 3 6 2 4 0 1]
 [0 9 3 6 1 8 2 7 5 4]
 [9 5 1 8 6 3 0 4 2 7]
 [7 1 2 9 3 8 5 4 6 0]
 [2 6 3 8 0 4 5 1 7 9]
 [4 7 8 3 0 5 1 2 9 6]
 [2 9 1 7 0 3 8 5 6 4]]
vm  [ 0.7  0.5 -0.  -0.5 -1.4 -0.2 -0.  -0.3 -1.2  0.4 -4.4 -0.3 -0.2 -0.1  2.5 -0.5 -0.2 -0.3 -0.2 -1.4 -0.9 -0.5  0.2 -0.2 -1.  -0.1 -0.1 -0.2 -1.   5.5 -0.6 -0.1  1.4 -2.3 -0.2  0.2  2.8 -0.9 -2.2 -0.3 -0.1  2.8  2.5 -0.5 -0.4 -0.2  4.6 -0.1  3.3 16.5 -0.4 -0.2 -0.9 -0.3 -0.  -0.2 -0.5 -1.6 -1.   3.6 -0.6 -0.1 -0.7 -0.1 -0.8 -0.1 -0.2 -0.6 -0.1 -0.   0.1  3.  -0.3 -0.4 -2.1  1.9 -0.1  0.1 -0.2 -0.2 -3.1 -0.3 -0.7  0.5 -1.5  2.8  5.5 -0.1 -0.1 -0.2 -0.8 -0.3 -0.2  1.7 -0.5 -0.2  1.1 -2.1 -0.5 -0.7 -0.2  6.2 -0.6 -0.1 -0.2 -0.6 -1.4 -0.6 -1.5 -1.3 -0.2 -0.3 -0.1 -0.1  0.2 -1.3 -0.6 -0.6 -0.1 -0.2 -0.4  5.3  0.2 -0.7 -0.4  2.9 -0.1  3.6 -1.9 -1.8  0.5 -0.1 -0.6 -0.2  6.5 -0.1 -0.2 -0.1 -0.2  1.4 -1.  -0.9 -0.1 -0.5 -0.1 -0.  -0.3 -0.1 -1.1 -0.3 -0.2 -0.2  3.  -0.5 -0.3  0.1 -0.6  0.4 -1.7 -0.5  0.1  1.7 -0.1 -0.   0.   0.3 -0.6 -0.7 -0.3 -0.3 -0.3 -0.1 -0.3 -0.5 -0.4  1.8 -1.4 -0.3  3.9 -0.2 -0.2 -0.3 -0.1 -0.7  0.1 -0.4  1.3 -0.9 -0.4 -1.5 -0.1 -0.  -0.6 -0.4  7.1  6.4 -0.5 -0.6 -0.1 -0.2 -0.4 -0.2  0.1  0.  -0.4 -1.5 -0.1 -0.2 10.9  0.2 -0.3 -1.3 -0.2 -1.1  0.  -0.1  2.7 -0.3 -0.3 -0.9 -0.1 -0.2 -0.3 -1.   6.1 -0.1 -0.8 -0.3 -0.3  1.7  0.5  0.9 -0.3  3.7  0.4  0.7 -0.2 -0.6 -0.2 11.2 -0.2  3.8 -0.  -0.2 10.  -0.6 -0.5 -0.8 -1.  -0.4  7.8 -0.3 -1.2 -0.1 -0.9  8.9]
vy_50sample [[8 6 0 4 7 9 2 5 1 3]
 [9 0 8 1 3 6 4 5 2 7]
 [5 5 0 4 7 1 8 3 9 6]
 [6 8 3 0 2 4 1 5 9 7]
 [7 5 8 2 9 4 6 1 0 3]
 [1 6 5 9 9 4 4 0 2 2]
 [1 9 2 7 6 3 8 5 0 4]
 [1 1 5 0 6 8 2 7 3 4]
 [1 7 8 2 3 9 4 0 6 5]
 [8 4 5 7 2 1 0 9 6 3]]
vt_50sample [[8 6 0 4 7 9 2 5 1 3]
 [9 0 8 1 3 6 4 5 2 7]
 [5 2 0 4 7 1 8 3 9 6]
 [6 8 3 0 2 1 4 9 5 7]
 [7 5 8 2 9 4 6 1 0 3]
 [1 6 5 8 9 3 4 7 2 0]
 [1 9 2 7 6 3 8 5 0 4]
 [9 1 5 6 0 8 2 7 3 4]
 [1 7 8 2 3 9 4 0 6 5]
 [8 4 5 7 2 1 0 9 6 3]]
Epoch 36110: Training cost= 0.2848, Training acc= 0.8476, Validation cost= 0.2203, Validation acc= 0.8476
Epoch 36120: Training cost= 0.2533, Training acc= 0.8476, Validation cost= 0.2640, Validation acc= 0.8476
Epoch 36130: Training cost= 0.2585, Training acc= 0.8476, Validation cost= 0.2716, Validation acc= 0.8477
Epoch 36140: Training cost= 0.3142, Training acc= 0.8476, Validation cost= 0.2448, Validation acc= 0.8477
Epoch 36150: Training cost= 0.2752, Training acc= 0.8476, Validation cost= 0.2757, Validation acc= 0.8477
Epoch 36160: Training cost= 0.3189, Training acc= 0.8476, Validation cost= 0.2406, Validation acc= 0.8477
Epoch 36170: Training cost= 0.2680, Training acc= 0.8476, Validation cost= 0.3169, Validation acc= 0.8477
Epoch 36180: Training cost= 0.3170, Training acc= 0.8477, Validation cost= 0.2523, Validation acc= 0.8477
Epoch 36190: Training cost= 0.2471, Training acc= 0.8477, Validation cost= 0.2712, Validation acc= 0.8477
Epoch 36200: Training cost= 0.2339, Training acc= 0.8477, Validation cost= 0.2211, Validation acc= 0.8477
tm  [-1.1 -0.7 -1.3 -0.5 -1.4  0.6  0.  -0.1 -0.1  0.1 10.6 -0.6 -0.1 -0.2  0.3 -0.1  0.  -0.5 -0.2 -0.2 -1.3 -0.3 -0.4 -0.1 -1.1  1.2 -0.2 -0.5 -2.1 -2.2  3.8 -0.5 -0.2  8.6 -0.1  0.7  2.9  4.2  0.9 -0.6  2.3  2.6 -0.2  3.2 -0.3 -0.3 -0.3 -0.5 -0.9 -1.4 -0.1 -0.3 -0.7  4.5  1.2 -0.2 -0.7 -0.3  5.2 -2.9  4.5 -0.2 -0.2  2.6 -1.  -0.1  0.1 -0.5 -0.3 -0.3  0.3  5.1  0.7  0.6 -1.9 -0.5  0.1 -0.4 -0.  -0.3 15.1 -0.2 -0.5 -0.4  1.   4.1 -0.4 -0.3  0.1 -0.1  0.4 -0.2 -0.2 -0.9 -0.2 -0.3  0.  -2.2  1.3 -0.3  1.1  3.1  0.7  0.2 -0.4 -0.6 -1.2  1.7 -0.2 -0.8 -1.2  0.6 -0.2  0.4  5.9 -2.  -0.2 -0.5 -0.1 -0.6 -0.   3.9  0.  -0.5 -0.2  0.1  0.  -0.6  4.6 -0.9 -0.5 -0.3 -0.3 -0.5  3.1 10.7 -0.4 -0.1 -0.1 -0.1 -0.3 -1.1 -0.9 -0.5 -0.1 -0.1 -0.4 -0.1  3.2 -0.3 -0.1  0.1 -2.  -0.8 -0.3 -0.2 -0.1 -0.1  1.3  3.1  1.7 -0.6 -0.1 -0.1 -0.4 -0.4 -0.4  0.7 -0.2 -0.4 -0.2 -0.  -0.2 -0.2 -0.2 -0.2 -0.4 -0.2  1.2 -0.  -0.7 -0.3 -0.7 -1.2  0.4 -0.7 -0.8 -0.5 -0.2  5.9  0.5 -0.2 -0.  -0.3 -1.1 -1.  -0.6 -1.3 -0.1 -0.  -0.4 -0.1  0.4 -0.8  0.3 -1.8 -0.6 -0.1 -3.6 -0.2 -0.3 -1.6 -0.7  6.7 -0.7 -0.7 -0.7 -0.9 -0.8 -0.4 -0.2  0.2 -0.4 -1.4  2.2 -1.7  1.7  1.3 -0.7 -0.3 -0.6 -0.3 -0.1 -1.6  5.2  3.9  1.8 -0.3  1.9  0.1 -0.1  0.3 -0.1 -0.2 -3.1 -0.  -0.7 -0.1 -1.4 -0.3 -4.  -0.1  0.5  0.3 -1.4  5.4]
ty_50sample [[0 1 2 4 5 5 9 7 3 8]
 [5 9 8 7 1 6 4 2 0 3]
 [4 2 9 0 7 5 8 3 6 1]
 [2 4 1 5 8 6 9 7 0 3]
 [1 6 0 2 4 9 8 7 3 5]
 [2 8 1 3 6 4 0 5 9 7]
 [4 7 2 9 3 1 5 6 8 0]
 [0 5 2 4 3 8 1 1 6 7]
 [2 0 8 4 1 5 3 7 9 6]
 [2 1 4 3 8 9 0 5 7 7]]
tt_50sample [[0 1 2 4 5 9 6 7 3 8]
 [5 9 8 1 7 6 4 2 0 3]
 [4 2 9 0 7 5 8 3 6 1]
 [2 4 1 5 8 6 9 7 0 3]
 [1 6 0 2 4 9 8 7 3 5]
 [2 8 1 3 6 4 0 5 9 7]
 [4 7 2 9 3 1 5 6 8 0]
 [0 5 2 4 3 8 1 9 6 7]
 [2 0 8 4 1 5 3 7 9 6]
 [2 1 4 3 8 9 5 6 0 7]]
vm  [-0.2 -0.3  4.8  1.7 -2.  -0.1  0.4 -0.2 -0.9 -0.   4.5 -0.5 -0.1 -0.1  6.3 -0.7 -0.1 -0.5 -0.2 -0.5 -0.6 -0.3  1.1 -0.1 -1.2  2.9 -0.1 -0.3 -1.5 -0.3  0.1  0.2 -0.7  5.9 -0.1 -0.2  3.9  4.5  6.9 -0.5 -0.2  6.5  3.1  1.6 -0.  -0.3  1.8 -0.4  2.3  8.3 -0.5 -0.2 -0.2  5.1  1.8 -0.7 -0.4  4.1 -0.8  1.9 -0.1 -0.  -0.6 -0.  -0.1  0.2  0.2 -0.4  1.   0.1 -0.1  5.6 -0.4 -0.5 -2.  -0.1 -0.4 -0.1 -0.  -0.2 -0.1  0.1 -0.4 -0.  -0.9  7.1  2.3 -0.1 -0.2 -0.1 -0.3 -0.2 -0.   0.2 -0.3 -0.1  0.7 -1.8 -0.2 -0.3  0.1  6.6 -1.  -0.1 -0.4 -0.3 -1.6 -0.2  0.7 -0.7 -0.3 -0.2  0.1  0.1  1.1 -2.9 -0.8 -0.7 -0.2 -0.1 -0.1  2.2 -0.  -0.4 -0.4  7.8 -0.2 -0.7 -0.7 -1.1  0.1 -0.3 -0.5 -0.2 -4.4 -2.1 -0.2 -0.1 -0.2 -0.5 -0.3 -1.6  0.2 -0.2 -0.   0.3 -0.2 -0.1  1.8 -0.2 -0.2 -0.   1.9  0.4 -0.3 -0.  -0.1 -0.2  0.8 -0.3 -0.1 -1.3 -0.1 -0.2 -0.1 -0.6 -0.4 -0.9 -0.2  0.3 -0.  -0.1  0.1 -0.3 -0.1  0.4  0.4 -0.5 -0.5  0.2 -1.6 -0.5 -0.6 -1.7 -0.  -0.3  0.5 -0.8  0.6 -0.  -0.1 -0.2 -0.4 -0.6  3.6  3.4 -1.  -0.4  0.  -0.1 -0.1 -0.2 -0.4 -0.1 -0.2 -1.8 -0.  -0.1 -1.7 -0.1 -0.  -2.  -0.3 -0.3 -0.8 -0.  -0.5 -0.9 -0.2 -0.4 -0.2 -0.3  0.3 -1.   2.3 -1.3 -0.2 -0.2 -0.2  1.1 -0.9  1.2 -0.4 -0.9  3.8 -0.8  1.5 -0.5  0.7 -2.2  0.2 -0.7  0.3  0.3  2.4 -0.3 -0.5 -0.5 -0.5 -0.2 -0.2 -0.1  4.2 -0.5 -1.3  6.5]
vy_50sample [[0 5 7 2 8 4 9 1 6 3]
 [2 9 7 3 0 4 8 5 6 1]
 [9 7 2 1 0 8 6 5 3 4]
 [9 3 0 6 7 2 5 8 1 4]
 [3 2 9 4 1 1 7 5 6 0]
 [5 9 2 8 6 4 7 0 1 3]
 [0 5 7 3 1 6 4 9 2 8]
 [7 4 0 6 3 5 2 8 1 9]
 [2 1 4 7 5 0 0 8 3 9]
 [4 0 9 5 5 1 7 6 2 3]]
vt_50sample [[0 5 7 2 8 4 9 1 6 3]
 [2 9 7 3 0 4 8 5 6 1]
 [9 7 2 1 0 8 6 5 3 4]
 [9 3 0 6 7 2 5 8 1 4]
 [3 2 9 4 8 1 7 5 6 0]
 [5 9 2 8 6 4 7 0 1 3]
 [0 5 7 3 6 1 4 9 2 8]
 [7 4 0 6 3 5 2 8 9 1]
 [2 1 4 7 5 6 0 8 3 9]
 [4 0 9 8 5 1 7 6 2 3]]
Epoch 36210: Training cost= 0.2510, Training acc= 0.8477, Validation cost= 0.2383, Validation acc= 0.8478
Epoch 36220: Training cost= 0.3005, Training acc= 0.8477, Validation cost= 0.2557, Validation acc= 0.8478
Epoch 36230: Training cost= 0.3151, Training acc= 0.8477, Validation cost= 0.2568, Validation acc= 0.8478
Epoch 36240: Training cost= 0.3030, Training acc= 0.8477, Validation cost= 0.3029, Validation acc= 0.8478
Epoch 36250: Training cost= 0.2970, Training acc= 0.8477, Validation cost= 0.3373, Validation acc= 0.8478
Epoch 36260: Training cost= 0.2861, Training acc= 0.8478, Validation cost= 0.3159, Validation acc= 0.8478
Epoch 36270: Training cost= 0.2777, Training acc= 0.8478, Validation cost= 0.2335, Validation acc= 0.8478
Epoch 36280: Training cost= 0.2865, Training acc= 0.8478, Validation cost= 0.2523, Validation acc= 0.8478
Epoch 36290: Training cost= 0.2259, Training acc= 0.8478, Validation cost= 0.2303, Validation acc= 0.8479
Epoch 36300: Training cost= 0.2313, Training acc= 0.8478, Validation cost= 0.2662, Validation acc= 0.8479
tm  [-1.6 -0.1 -1.  11.  -0.9 -0.2 -0.   0.5 -0.6 -0.4 -1.8 -0.4 -0.1  0.2 -2.7  1.3 -0.2 -0.1  1.1 -1.1 -1.3 -0.2  2.1 -0.4 -0.7  2.6 -0.4  0.2 -1.1 -1.8 -1.4 -0.4 -0.2 -5.3 -0.1 -0.   4.3  2.9  6.7 -0.4  0.2 -2.   0.1 -0.2 -0.1 -0.   6.   0.  -1.2  8.  -0.4 -0.2 -0.3 -0.4 -0.4  3.7 -0.5 -1.  -0.1  5.8  1.5  0.6 -0.4 -0.2 -1.2  0.4 -0.1 -0.9  0.1  0.5  0.   2.5  1.2  0.3  2.7 -0.   1.2 -0.1 -0.2  0.5 -0.4 -0.4 -0.2  1.1  1.9 -2.  -1.7 -0.1  0.3 -0.  -0.4 -0.4 -0.1  0.5 -0.5 -0.1  0.1 -1.2 -0.3  0.4  2.1 -0.9  1.5  0.5 -0.3 -0.3 -0.1 -1.2 -0.5 -2.  -0.6 -0.4 -0.1  0.2  1.6 -0.5 -0.  -1.1 -0.3 -0.2 -0.2  9.   0.3 -0.1 -0.3 -3.4  0.4  4.1 -0.6 -0.8 -0.9 -0.2 -0.3 -0.6  7.6 -2.8 -0.4 -0.2 -0.5  1.5 -0.6 -0.9 -0.9 -0.2 -0.3 -0.2 -0.2 -0.2 -0.6 -0.3 -0.9 -0.1  1.4 -0.4 -0.1 -0.2 -0.1 -0.8  0.8 -0.4  1.  -0.1 -0.3 -0.1 -0.1 -0.4 -0.5  0.5 -0.2 -0.4 -0.2 -0.3  0.7 -0.3  0.4  0.9 -0.4 -0.2 -0.4  0.3  2.9  1.2 -0.2 -0.7  0.8 -0.1 -0.9  0.3 -0.2  5.4 -0.2 -0.3 -0.2 -0.1  1.2  3.   1.  -0.4 -0.  -0.   0.6 -0.1 -0.  -0.3 -0.1  0.2 -0.1  0.3 13.5 -0.1 -0.5 -1.1 -0.2  7.6 -0.1  0.1  2.1 -0.6 -0.1 -0.3 -0.  -0.2 -0.2 -0.6  0.5 -0.1 -0.1  0.8 -0.6 -0.7 -0.3 -0.9  0.1  4.5  2.2  0.9 -0.3  2.2  0.5 22.6 -0.1  8.3  0.2 -0.5  3.6 -1.5 -0.2 -0.1 -1.2 -0.3  0.4 -0.1  4.5 -0.2  0.4  4.7]
ty_50sample [[8 1 9 0 2 3 6 4 7 5]
 [6 2 9 3 1 7 0 4 8 5]
 [1 4 3 2 0 5 7 6 8 9]
 [1 4 0 5 6 8 2 2 3 9]
 [4 2 1 9 5 0 8 6 7 3]
 [7 6 0 5 8 1 3 2 4 9]
 [5 2 4 8 3 9 9 0 6 1]
 [3 4 5 1 9 8 7 0 2 6]
 [3 1 8 9 6 0 7 4 5 2]
 [9 4 8 6 3 2 1 0 5 7]]
tt_50sample [[8 1 9 0 2 3 6 4 7 5]
 [6 2 9 3 1 7 0 4 8 5]
 [1 4 3 2 0 5 7 6 8 9]
 [1 4 5 0 6 8 7 2 3 9]
 [4 2 1 9 5 0 8 6 7 3]
 [7 6 0 5 8 1 2 3 4 9]
 [5 2 4 8 3 9 7 0 6 1]
 [3 4 5 1 9 8 7 0 2 6]
 [3 1 8 9 6 0 7 4 5 2]
 [9 4 8 6 3 2 1 0 5 7]]
vm  [-0.8  1.3 -3.9  6.5 -0.8  0.3 -0.7 -0.2 -1.1 -0.9 -1.  -0.4 -0.4  0.1 -4.4 -1.  -0.9 -0.2  1.  -2.  -0.8 -0.4 -0.7  0.6 -0.7 -0.2 -0.4  0.8 -1.4 -2.8  3.  -0.2 -0.7 -2.8 -0.3 -0.3  5.1  2.7 20.2 -0.1 -0.4 -1.8 -0.5  2.8 -0.6 -0.1 12.   0.6 -0.5 -2.3 -0.6 -0.1 -0.2 -3.3 -0.2  3.9 -0.4 -0.6  0.4 -1.2 -0.7 -0.8 -0.5 -0.1  0.3  1.  -0.1 -0.5  0.9 -0.5 -0.2  2.8 -0.7 -0.6 10.  -0.9 -0.8 -1.2 -0.2 -0.1 16.6 -0.2 -0.3 -0.1  0.3 -1.5  1.1 -0.1 -0.4 -0.3  1.3 -0.2 -0.5  0.2 -0.2  0.7 -0.7  0.1  0.8  0.5  4.6 -3.4  0.7  0.   0.2 -0.5  1.8  2.8 -0.4 -2.3 -0.3 -0.3 -0.1 -0.1  1.  -1.3 -0.5 -1.  -0.5 -0.5 -0.1 10.8  0.1  0.3 -0.5 -5.4 -0.3 13.1  2.4 -0.8 -0.1 -0.6  0.9 -0.6  3.9 -1.9  0.2 -0.   2.  -0.6  0.2 -0.5 -0.7 -0.4  0.1 -0.2 -0.5  0.   5.5 -0.2 -0.8  0.1 -0.3 -0.4  0.2 -0.2  1.6 -0.3  2.  -0.3 -0.7 -1.1 -0.2 -0.3 -0.3 -0.   1.3  2.3 -0.  -0.1 -0.3 -0.2 -0.1  1.3 -0.4 -1.4  1.7 -0.7 -2.2 -0.2 -1.3 -0.6 -0.1 -1.2 -0.   0.4 -0.6  0.8 -0.1  7.6 -0.2 -0.1 -0.4 -1.2  5.7  0.7  2.1  0.3 -0.3  0.1 -0.6 -0.2 -0.3 -0.6 -0.1  1.4 -0.4 -0.1 -1.2  0.3 -0.  -1.8 -1.3  1.7  1.7 -0.7 -1.7 -0.9 -0.7  1.8 -0.3 -0.2  0.1 -0.9 -2.4 -0.5 -0.9  1.6  0.   1.  -1.5 -1.2 -0.3 -0.6  3.1  5.5  0.4  3.5  1.3  9.4 -0.   3.  -0.4  0.6 -3.2 -2.1  0.2  0.1 -1.1  0.8 -4.4 -0.  12.5  0.3  7.2  4.6]
vy_50sample [[9 3 0 4 1 5 8 2 6 7]
 [5 6 8 3 3 9 2 0 4 7]
 [0 1 6 6 3 2 9 4 8 5]
 [8 4 2 3 6 7 0 0 5 1]
 [8 7 5 9 4 3 1 6 2 0]
 [3 2 9 7 6 8 0 4 5 1]
 [6 3 8 7 1 9 5 0 2 4]
 [0 5 8 3 6 4 7 2 2 9]
 [0 1 5 6 2 4 7 3 8 9]
 [2 4 5 1 3 8 9 7 6 0]]
vt_50sample [[9 3 0 4 1 5 8 2 6 7]
 [5 6 8 3 9 1 0 2 4 7]
 [0 1 7 6 3 2 9 8 4 5]
 [8 4 2 3 6 7 9 0 5 1]
 [8 7 5 9 4 3 1 6 2 0]
 [3 2 9 7 6 0 8 4 5 1]
 [6 8 3 7 1 9 5 0 2 4]
 [0 5 8 3 6 4 7 1 2 9]
 [0 1 5 6 2 4 7 3 8 9]
 [2 4 5 1 3 8 9 7 6 0]]
Epoch 36310: Training cost= 0.2772, Training acc= 0.8478, Validation cost= 0.2554, Validation acc= 0.8479
Epoch 36320: Training cost= 0.2595, Training acc= 0.8478, Validation cost= 0.2890, Validation acc= 0.8479
Epoch 36330: Training cost= 0.2217, Training acc= 0.8479, Validation cost= 0.2595, Validation acc= 0.8479
Epoch 36340: Training cost= 0.2576, Training acc= 0.8479, Validation cost= 0.2414, Validation acc= 0.8479
Epoch 36350: Training cost= 0.2543, Training acc= 0.8479, Validation cost= 0.2374, Validation acc= 0.8479
Epoch 36360: Training cost= 0.3292, Training acc= 0.8479, Validation cost= 0.3259, Validation acc= 0.8479
Epoch 36370: Training cost= 0.3205, Training acc= 0.8479, Validation cost= 0.2329, Validation acc= 0.8480
Epoch 36380: Training cost= 0.2354, Training acc= 0.8479, Validation cost= 0.2357, Validation acc= 0.8480
Epoch 36390: Training cost= 0.2514, Training acc= 0.8479, Validation cost= 0.2731, Validation acc= 0.8480
Epoch 36400: Training cost= 0.2243, Training acc= 0.8479, Validation cost= 0.2327, Validation acc= 0.8480
tm  [-1.   1.3  4.5 15.8 -1.5 -0.4 -0.1  0.1 -1.2 -0.4 -1.9 -0.  -0.3  1.2 -1.7  0.9 -0.2  0.3  0.3 -0.9 -0.9 -0.3  2.2  0.1 -0.8  2.8 -0.1 -0.  -0.8  3.6 -1.5 -0.4 -0.  -2.5 -0.1 -0.   4.  -1.1 -0.4 -0.2 -0.4 -1.1  1.7 -1.5 -0.3  0.1  6.4  0.3 -0.5  8.  -0.4 -0.2  0.3 -1.2 -0.5  2.2 -0.1 -0.  -2.   6.1 -0.4 -0.1 -0.3 -0.2 -0.7 -0.3 -0.3 -0.3  0.3 -0.3 -0.   1.7  1.6  0.1  2.6 -0.1  1.1 -0.6 -0.   0.2  2.9 -0.   0.2  1.  -0.1 -0.9 -1.4 -0.2 -0.3 -0.1  0.3 -0.1  0.2  1.5 -0.3 -0.1 -0.4 -0.4 -0.1 -0.2  1.4  1.9 -0.2 -0.2 -0.1 -0.2  1.7 -0.9 -0.6 -1.4 -0.6 -0.3 -0.   0.9 -0.6 -0.5 -0.6 -1.5 -0.2 -0.5 -0.   6.  -0.3  1.1  0.1 -2.1  0.2  6.4 -2.6 -1.7 -0.3  0.2 -0.1 -0.4 11.2  6.2 -0.3 -0.1  1.5 -0.4 -0.3 -1.  -0.4 -0.  -0.2 -0.3 -0.3 -0.1 -1.1 -0.3 -1.4 -0.1  1.1 -0.3  0.2  0.4 -0.4 -0.3 -1.4 -0.3  1.1  3.4 -0.3 -0.   0.5 -0.4 -0.3 -0.   0.8 -0.2 -0.3 -0.3  1.1  0.5 -0.3  2.2 -1.   1.4  1.6  0.4  2.2 -0.3 -0.1 -1.2 -0.1  0.5 -0.5 -0.5 -0.1 -0.8  0.  -0.4 -0.  -0.5  4.6  9.4  2.4  1.5  0.4 -0.2 -0.1 -0.2 -0.  -0.1  1.   3.5 -0.2 -0.1 10.1  0.4 -0.7 -0.8 -0.7  6.5 -0.3 -0.1  7.6 -0.3 -0.3  1.1 -0.2  0.3 -0.1 -0.4  4.5  0.6 -1.   0.1 -0.5 -0.7  3.1 -1.   0.2  3.8  0.1 -0.7 -0.1  3.6  1.  18.8 -0.1  6.5 -0.  -0.4 -0.1 -2.3 -0.3  0.  -0.9 -0.7 -0.9 -0.1 -0.3 -0.3  0.4  7.2]
ty_50sample [[6 9 8 1 0 2 7 3 4 5]
 [5 8 1 3 7 4 0 0 2 9]
 [3 2 9 8 6 7 5 5 4 0]
 [4 1 8 8 5 9 6 0 3 7]
 [6 2 8 9 7 5 1 4 0 3]
 [4 3 8 5 2 9 1 7 6 0]
 [8 4 9 6 5 1 7 2 3 0]
 [8 5 0 4 1 6 3 7 2 9]
 [9 4 0 2 7 8 3 6 1 5]
 [0 4 7 3 2 6 9 1 8 5]]
tt_50sample [[6 9 8 0 1 2 7 3 4 5]
 [5 8 3 1 7 4 6 0 2 9]
 [3 2 9 8 6 7 5 1 4 0]
 [4 1 8 2 5 9 6 0 3 7]
 [6 2 8 9 7 5 1 4 0 3]
 [4 3 8 5 9 2 1 7 6 0]
 [8 4 6 9 5 1 7 2 3 0]
 [8 5 0 4 1 6 3 7 2 9]
 [9 4 0 2 7 8 6 3 1 5]
 [0 4 7 3 2 6 9 1 8 5]]
vm  [-1.2 -0.1  5.5 10.6 -1.8 -0.2 -0.4 -0.2 -0.3 -0.5 -1.9 -0.1  0.5 -0.3  0.5  2.2 -0.4 -0.2 -0.1 -1.8 -0.9 -0.1  1.3 -0.1 -0.6 -0.1 -0.3  0.1  0.6  2.5  1.4 -0.2 -0.2 10.5 -0.1 -0.   1.   2.8 22.7 -0.6  1.1  0.5  0.4  4.2 -0.2  0.6 10.7  0.7 -0.8  4.3 -0.3 -0.2  0.2 -3.7 -1.2  0.3 -0.7 -0.7 -0.4 -0.6 -0.7 -0.3  0.7 -0.3 -0.4 -0.4 -0.3 -0.7 -0.1 -0.3 -0.1 -2.1 -0.2  0.5  6.8 -0.1 -0.2 -0.3 -0.4 -0.  16.1 -0.2 -0.3 -0.5  0.6  2.  -0.4 -0.2 -0.3 -0.5 -0.1  0.1 -0.  -0.4  1.5 -0.2 -0.4  0.1 -0.3  1.6  2.   6.9  0.5 -0.1 -0.1 -0.1  4.3  2.4 -0.3 -2.4 -0.1 -0.3 -0.1 -0.7 -0.6 11.2 -0.1 -1.  -0.2 -0.7 -0.4  9.3 -0.4  0.2 -0.1  0.1 -0.2 13.9 -0.3 -3.3 -1.2  0.7 -0.3 -0.2 -7.7 -3.1 -0.1 -0.2 -0.4 -0.7  1.5 -0.5 -0.2 -0.3  0.2 -0.4 -0.2 -0.2 -1.9 -0.1 -0.9 -0.1 -0.6 -0.3  0.6 -0.2 -0.1 -0.3  5.  -0.1 -0.6 -2.2 -0.1 -0.1 -0.2  0.7 -0.   1.  -0.2 -0.1 -0.1 -0.1 -0.3  0.3 -0.1  3.1  0.2  1.4 -2.5 -0.3 -0.8  0.4  0.2 -0.9 -0.5 -0.4 -0.5 -0.8 -0.2 -0.6 -0.2 -0.2 -0.4 -0.5  5.6  1.6  3.8  2.  -0.2  0.1 -0.  -0.2 -0.1  0.2 -0.   8.4 -0.3 -0.2  1.8  0.  -0.2  4.4 -0.3  4.8 -0.  -0.6 -1.9 -0.5 -0.7 -0.5  0.1  0.1 -0.1 -0.1 -1.3  3.6 -1.6 -0.  -0.8 -0.6 -0.4 -1.2 -0.2  1.3 -1.  -0.8 -0.5  3.8  0.7 16.7 -0.2  5.2 -0.  -0.  -3.2 -3.  -0.5 -0.4 -0.7  1.  -4.2 -0.2 14.6 -0.2  3.  12.9]
vy_50sample [[9 1 1 4 8 5 3 2 0 6]
 [7 9 2 5 3 4 0 1 6 8]
 [8 5 5 4 7 6 3 1 2 0]
 [9 6 2 1 0 3 4 8 5 7]
 [3 7 1 8 4 2 6 0 9 5]
 [2 4 8 0 1 5 9 7 6 3]
 [4 9 5 2 0 1 7 6 8 3]
 [6 9 4 2 0 8 1 7 3 5]
 [1 8 3 9 0 6 5 2 4 7]
 [2 6 5 3 1 0 0 9 7 4]]
vt_50sample [[9 7 1 4 8 5 3 2 0 6]
 [7 9 2 5 3 4 0 6 1 8]
 [8 5 9 4 7 6 3 1 2 0]
 [9 6 2 1 0 3 4 8 5 7]
 [3 7 1 8 4 2 6 0 9 5]
 [2 4 8 0 1 5 9 7 6 3]
 [4 9 5 2 0 1 7 6 8 3]
 [6 9 4 2 0 8 1 7 3 5]
 [1 8 3 9 0 6 5 2 4 7]
 [2 6 5 3 1 0 8 9 7 4]]
Epoch 36410: Training cost= 0.2769, Training acc= 0.8480, Validation cost= 0.2450, Validation acc= 0.8480
Epoch 36420: Training cost= 0.2716, Training acc= 0.8480, Validation cost= 0.2885, Validation acc= 0.8480
Epoch 36430: Training cost= 0.2744, Training acc= 0.8480, Validation cost= 0.2253, Validation acc= 0.8480
Epoch 36440: Training cost= 0.2571, Training acc= 0.8480, Validation cost= 0.2379, Validation acc= 0.8480
Epoch 36450: Training cost= 0.2297, Training acc= 0.8480, Validation cost= 0.3049, Validation acc= 0.8481
Epoch 36460: Training cost= 0.2514, Training acc= 0.8480, Validation cost= 0.2360, Validation acc= 0.8481
Epoch 36470: Training cost= 0.2484, Training acc= 0.8480, Validation cost= 0.2756, Validation acc= 0.8481
Epoch 36480: Training cost= 0.2835, Training acc= 0.8481, Validation cost= 0.2969, Validation acc= 0.8481
Epoch 36490: Training cost= 0.2732, Training acc= 0.8481, Validation cost= 0.2716, Validation acc= 0.8481
Epoch 36500: Training cost= 0.2233, Training acc= 0.8481, Validation cost= 0.2550, Validation acc= 0.8481
tm  [ 2.2  0.5  8.3  8.5 -1.4 -0.2 -0.2  0.2 -0.8 -0.4 -2.6 -0.2 -0.3 -0.2  3.7  1.7 -0.  -0.   0.8 -0.9 -0.7 -0.2 -0.1 -0.1 -0.8  1.8 -0.5  0.9 -0.6  3.7 -1.9 -0.3 -0.2 -1.6 -0.1 -0.1  0.6  3.5  5.  -0.6 -0.9 -0.2  1.8 -0.8  0.2 -0.3  3.9 -0.2  7.4 12.7 -0.3 -0.  -0.5  2.1 -0.8 -0.2 -0.2  2.3 -1.5  7.1 -1.6 -0.3 -0.4 -0.4 -0.9 -0.7 -0.2 -0.2  1.  -0.3 -0.3  2.5  0.6  0.  -1.1  0.1 -0.5 -0.1 -0.3 -0.3 -3.  -0.7 -0.  -0.2 -2.5  0.6  2.9 -0.3 -0.3 -0.2 -0.6 -0.  -0.4  1.5 -0.7  0.2  0.5 -1.9 -0.1 -0.6  1.6  5.8 -1.1  0.2 -0.1 -0.1 -0.7 -1.6 -0.6 -1.3 -0.  -0.2 -0.  -0.1 -0.6  0.1 -0.6 -0.8  0.2 -0.1 -0.3  4.6  0.2 -0.6 -0.3  5.  -0.3 -0.  -1.7 -0.9  3.2 -0.  -0.3 -0.2 -2.6 -4.7 -0.2 -0.1 -0.1  4.  -1.  -0.9 -0.4  0.4  0.3  0.2 -0.2 -0.2 -2.  -0.2 -0.6 -0.1  3.  -0.4 -0.  -0.2 -0.  -0.2 -0.3 -0.   0.5 -0.4 -0.1 -0.1 -0.3  0.2 -0.2 -0.5 -0.2 -0.2 -0.3 -0.3 -0.1 -0.5 -0.4  2.8 -0.4  0.4 -0.4  0.3 -0.4 -0.3 -0.  -0.8 -0.1 -0.2  3.3 -0.3 -0.2 -0.7 -0.4 -0.4 -0.2 -0.2 12.2  6.4  0.6 -0.1 -0.2 -0.1 -0.4 -0.1  0.5 -0.4 -0.2 -0.4 -0.1  0.2 10.8 -0.2 -0.4 -0.6 -0.3 -1.9  0.5 -0.2  4.5 -0.3  0.5 -0.5 -0.3 -0.2 -0.5 -1.   2.9 -0.2 -0.1  0.2 -0.3  3.5 -0.7 -0.7  0.   3.6 -0.1 -2.1 -0.2 -0.1 -0.3  9.8 -0.1  3.2 -0.2 -0.2  9.5 -1.4 -0.8 -0.5 -0.8 -0.4  6.9 -0.1  3.4 -0.  -0.8  5.4]
ty_50sample [[8 7 2 0 9 6 3 5 4 1]
 [6 0 8 4 7 2 9 5 3 1]
 [3 5 1 0 4 6 2 7 8 9]
 [9 2 3 6 0 5 1 8 4 7]
 [2 4 0 7 5 1 6 9 3 8]
 [7 1 9 8 0 2 5 3 4 6]
 [7 9 3 2 6 4 0 5 8 1]
 [2 7 4 6 3 5 8 0 1 9]
 [0 0 8 5 1 4 3 2 6 9]
 [0 2 5 7 3 1 8 9 4 6]]
tt_50sample [[8 7 2 0 9 6 5 3 4 1]
 [6 0 8 4 7 2 9 5 3 1]
 [3 5 1 0 4 6 2 7 8 9]
 [9 2 6 3 0 5 1 8 4 7]
 [2 4 0 7 1 5 6 9 3 8]
 [7 1 9 8 0 2 5 3 4 6]
 [7 9 3 2 6 4 0 5 8 1]
 [2 7 4 6 3 5 8 0 1 9]
 [0 7 8 5 1 4 3 2 6 9]
 [0 2 7 5 3 1 8 9 4 6]]
vm  [-0.5  0.8 -1.9 -4.7 -1.2 -0.1  0.4 -0.1 -0.2 -0.8  8.8 -0.2 -0.3 -0.   8.1  3.9 -0.1 -0.4 -0.4  4.4 -1.5 -0.4 -1.7  0.2 -0.8 -0.2 -0.2 -0.4 -1.  -1.5  5.  -0.3 -0.5  9.1 -0.2 -0.1 -0.4  1.2 -3.2 -0.3 -0.1 -3.1 -1.1  1.3 -0.6 -0.4 -3.5 -0.5  1.9 -5.5 -0.1 -0.4 -0.3  9.5 -1.2 -1.  -0.2 -1.7  6.1 -3.7  5.5 -0.7 -0.1  0.5 -0.5 -0.5 -0.1  1.  -0.7 -0.3 -0.1 -0.8  1.   0.4 -6.2 -0.7 -0.5 -0.8 -0.  -0.4  1.9 -0.2 -0.2 -0.5 -0.6 -2.5  4.2 -0.2  0.  -0.6  1.7 -0.1  0.1 -0.5 -0.5 -0.3 -0.6 -3.4  1.3 -0.7  2.8 -2.2 -0.2 -0.3 -0.  -0.3 -2.4  3.   0.8  3.1 -0.2 -0.2 -0.2 -0.8  2.5  6.  -0.9  1.7 -0.  -0.7 -0.3 -1.7 -0.2  0.4 -0.3  9.6 -0.  -2.   6.1 14.9  1.7 -0.4  1.1 -0.1  6.7 13.4 -0.  -0.1  1.3 -0.4  0.3 -0.6 -0.8 -0.4 -0.  -0.2 -0.6 -0.1  0.1 -0.1  2.4 -0.1 -1.  -0.3 -0.1 -0.2 -0.5 -0.2 -0.3  2.6 -0.2  0.1 -0.1 -0.1 -0.1  0.1  0.1  3.3 -0.1 -0.1 -0.2  0.7 -0.3  0.3 -0.2  2.1 -0.1 -0.8  5.4 -0.4  0.1 -0.6 -0.6 -1.9 -0.2 -0.2  0.2 -0.7 -0.3  4.4 -0.2 -0.1  0.6 -1.3 -1.9 -1.9 -0.9 -0.3 -0.3 -0.  -0.5  0.  -0.3 -0.9 -0.4 -3.2 -0.7 -0.2 -2.1 -0.2 -0.4  2.  -1.6  2.4 -0.3 -0.6 -0.3 -1.  -0.9  0.7 -0.3  0.5 -0.4 -1.6 -0.7 -0.6 -0.8  1.4 -0.5  2.4 -0.3 -0.3 -0.4 -1.   0.   5.5  0.7 -1.7  2.6 -2.3 -0.3 -0.9 -0.1 -0.1  0.2  4.9 -0.4  0.2 -1.7 -0.3 -0.7 -0.2 -2.  -0.1  4.9 -3.8]
vy_50sample [[3 4 6 2 1 7 5 5 9 8]
 [2 5 8 4 1 9 0 7 3 6]
 [0 4 7 2 1 5 3 8 9 6]
 [7 9 3 0 5 2 8 4 6 1]
 [6 7 1 4 8 8 0 9 5 2]
 [2 0 1 4 3 8 5 7 9 6]
 [1 2 8 4 7 9 0 3 6 5]
 [3 5 7 2 0 9 1 4 6 8]
 [3 6 7 2 4 1 8 0 9 5]
 [5 4 9 8 2 0 7 3 6 1]]
vt_50sample [[3 4 6 2 1 7 0 5 9 8]
 [2 5 8 4 1 9 0 7 3 6]
 [0 4 7 2 1 5 3 8 9 6]
 [7 9 3 0 5 2 8 4 6 1]
 [6 7 1 4 8 0 3 9 5 2]
 [2 0 1 4 3 8 5 7 9 6]
 [1 2 8 4 7 0 9 3 6 5]
 [3 5 2 7 0 9 1 4 8 6]
 [3 6 7 2 4 1 8 0 9 5]
 [5 4 9 8 2 0 7 3 6 1]]
Epoch 36510: Training cost= 0.3052, Training acc= 0.8481, Validation cost= 0.3018, Validation acc= 0.8481
Epoch 36520: Training cost= 0.3213, Training acc= 0.8481, Validation cost= 0.2634, Validation acc= 0.8481
Epoch 36530: Training cost= 0.2422, Training acc= 0.8481, Validation cost= 0.2881, Validation acc= 0.8482
Epoch 36540: Training cost= 0.2406, Training acc= 0.8481, Validation cost= 0.2851, Validation acc= 0.8482
Epoch 36550: Training cost= 0.2354, Training acc= 0.8481, Validation cost= 0.2377, Validation acc= 0.8482
Epoch 36560: Training cost= 0.2569, Training acc= 0.8482, Validation cost= 0.2983, Validation acc= 0.8482
Epoch 36570: Training cost= 0.2529, Training acc= 0.8482, Validation cost= 0.2995, Validation acc= 0.8482
Epoch 36580: Training cost= 0.3036, Training acc= 0.8482, Validation cost= 0.2969, Validation acc= 0.8482
Epoch 36590: Training cost= 0.2625, Training acc= 0.8482, Validation cost= 0.2992, Validation acc= 0.8482
Epoch 36600: Training cost= 0.2619, Training acc= 0.8482, Validation cost= 0.2331, Validation acc= 0.8482
tm  [-0.8 -0.7  2.2  2.5 -1.4 -0.2 -0.4  0.2  1.   0.4  3.9 -0.4 -0.2 -0.3  1.1 -1.5 -0.  -0.4  1.4  1.6 -0.9 -0.2 -0.4 -0.3 -0.8  3.7 -0.5  0.6 -1.7 -3.5 -0.4 -0.1 -0.5 -1.  -0.1 -0.1  0.3 -1.  -3.5 -0.5 -0.5  2.8 -0.7 -1.2 -0.2  0.1 -1.8 -0.2 -0.1 -1.3 -0.4 -0.1 -0.3  5.7  3.3 -0.1 -0.7  8.   7.3  3.4  5.9 -0.4 -0.2  1.1 -0.   0.8  0.7 -0.2  1.2 -0.2 -0.   5.8 -0.2 -0.2 -4.9 -0.2 -0.5 -0.2 -0.1 -0.2 -1.  -0.3 -0.1  0.2 -0.1  2.4 -1.4 -0.2 -0.2 -0.4 -0.2 -0.2 -0.  -0.9 -0.7 -0.2  0.7 -3.4 -0.2 -0.2 -0.  -1.  -0.1 -0.  -0.3 -0.4 -2.2 -0.5  0.8  0.4 -0.5 -0.  -0.1 -0.5  7.  -2.6 -0.1  1.9 -0.2  0.7 -0.2 -0.4  0.5  0.8 -0.   1.  -0.2 -0.7  7.4  7.6  0.6 -0.5 -0.4 -0.6 12.3 11.1 -0.2 -0.2 -0.4 -0.4  1.  -0.9 -0.  -0.3  0.2 -0.  -0.2 -0.1  5.5 -0.1 -0.2 -0.1 -0.5  0.9 -0.1 -0.2  0.5  0.3 -0.8 -0.4  0.2  0.3  0.2 -0.1  0.2 -0.8 -0.2  0.3 -0.3 -0.3  0.1  0.2 -0.3 -0.4 -0.1 -1.2 -0.7 -0.4  5.6  0.2 -1.5 -0.3 -0.7 -1.8 -0.1  0.5 -0.4  0.1  0.2  9.9 -0.   0.  -0.1 -0.8 -1.8 -2.1 -1.5 -1.7 -0.1  0.5 -0.3 -0.  -0.4 -0.2  0.  -3.3  0.1  0.  -2.7 -0.1 -0.7 -2.1 -0.7  1.9 -0.8 -0.   7.  -1.  -0.3 -0.3 -0.1 -0.2  1.1 -1.   3.6 -1.8 -1.1  0.7 -0.2  1.6 -0.2 -0.  -0.1 -1.4  4.  -0.2  2.6 -1.1  3.2 -3.9 -0.1 -1.4 -0.1 -0.2  4.3  4.7  0.7 -0.2 -1.5 -0.4  1.9 -0.1 -2.2 -0.3  2.3 -1.6]
ty_50sample [[0 6 5 1 3 2 8 7 4 4]
 [3 2 9 8 0 7 5 4 1 6]
 [3 6 9 4 8 2 0 7 1 5]
 [9 5 7 6 1 4 2 8 3 0]
 [9 4 1 7 0 8 6 3 5 2]
 [9 7 7 0 5 3 2 1 4 6]
 [2 7 5 0 6 4 4 8 3 1]
 [7 3 1 5 0 4 8 6 2 9]
 [1 6 8 4 9 3 5 0 2 7]
 [5 2 2 6 8 9 3 4 0 1]]
tt_50sample [[0 6 5 1 3 2 8 9 7 4]
 [3 2 9 8 0 7 5 4 1 6]
 [3 6 9 4 8 2 0 7 1 5]
 [9 5 7 1 6 4 2 8 3 0]
 [9 4 1 7 0 8 6 3 5 2]
 [9 8 7 0 5 3 2 1 4 6]
 [2 7 5 0 6 9 4 8 3 1]
 [7 3 1 5 4 0 8 6 2 9]
 [1 6 8 4 9 3 5 0 2 7]
 [5 7 2 6 8 9 3 4 0 1]]
vm  [ 0.4 -0.6  3.7 12.6 -1.4 -0.2 -0.2 -0.3 -0.3 -0.2 -2.6  0.  -0.4 -0.1 -1.3 -0.3 -0.1  0.3  0.5 -1.1 -1.1 -0.2  0.2  1.2 -0.4  2.2 -0.1 -0.3 -1.  -1.3 -1.7 -0.1 -0.2 -4.3 -0.1 -0.2  0.5  4.4 11.1 -0.4  0.6 -2.4 -0.3 -0.1 -0.2 -0.6  6.8 -0.6  5.8  9.4 -0.4 -0.2 -0.4 -0.  -0.2  2.3 -0.3 -1.4  0.4  5.9 -1.3 -0.2 -0.2 -0.2 -1.  -0.9 -0.3 -0.1  1.2 -0.5 -0.2  4.7  0.2  0.1 -0.6 -0.2 -0.6 -0.6 -0.2 -0.3 -1.5  0.3 -0.2 -0.4 -2.2 -2.6  3.  -0.1 -0.2 -0.1  0.  -0.1 -0.4 -0.3 -0.4 -0.2 -0.5 -1.7 -0.  -1.1 -0.  -0.  -1.2 -0.  -0.1 -0.3 -0.1 -1.4 -0.6 -1.7 -0.1 -0.3 -0.2 -0.   2.1 -1.7 -0.1 -0.5 -0.   0.6 -0.2  5.  -0.4 -0.4 -0.4 -1.7 -0.4  2.1 -0.4 -1.1  2.  -0.  -0.3  0.5 -1.1 -5.4  0.2 -0.1  0.   2.7 -0.6 -1.3 -0.6 -0.1 -0.2 -0.3 -0.1 -0.1 -1.8 -0.3 -1.1 -0.2  2.7 -0.2 -0.1 -0.2 -0.1 -0.9  0.3 -0.  -0.4 -1.4  1.  -0.2 -0.3 -0.5 -0.2 -0.3 -0.3 -0.  -0.4 -0.4 -0.1  0.3 -0.2  3.5 -0.5  0.4 -0.9  0.2  2.7 -0.2  0.4 -1.  -0.1  0.6  3.2 -0.2 -0.3  3.7 -0.5 -0.4 -0.3 -0.5 11.   2.4  0.6 -0.7 -0.1 -0.1 -0.3 -0.2 -0.2 -0.2 -0.6  2.4 -0.4 -0.4 13.5 -0.3 -0.3 -1.2 -0.9 -1.6 -0.5 -0.6  1.2 -0.6 -0.4 -0.  -0.3 -0.1 -0.3 -1.  -0.4 -0.7 -0.7 -0.2 -0.6  2.5 -0.5 -0.8  0.1  4.5  0.2 -0.7  1.5  1.   0.4 20.5 -0.2  7.4 -0.4 -0.   5.9 -2.7 -0.  -0.7 -1.  -0.1  3.1 -0.   7.1  0.1  0.8  5.9]
vy_50sample [[8 0 9 2 3 7 4 6 1 5]
 [3 7 6 2 2 8 5 0 4 1]
 [5 3 4 6 7 8 1 9 2 0]
 [1 5 4 8 0 7 3 2 6 9]
 [1 9 5 0 3 6 8 7 4 4]
 [6 9 1 1 3 4 5 5 8 0]
 [6 5 1 2 3 9 4 7 8 0]
 [4 6 1 7 9 0 8 5 2 3]
 [7 1 6 9 0 2 5 8 4 4]
 [1 2 5 6 3 0 8 9 4 7]]
vt_50sample [[8 0 9 2 3 7 6 4 1 5]
 [3 7 6 9 2 8 5 0 4 1]
 [5 3 4 6 8 7 1 9 2 0]
 [1 5 4 8 0 7 3 2 6 9]
 [1 9 5 0 3 6 8 7 2 4]
 [6 9 7 1 3 2 4 5 8 0]
 [6 5 1 2 3 9 4 7 8 0]
 [4 6 7 1 9 0 8 5 2 3]
 [7 1 6 9 0 2 5 8 3 4]
 [1 2 5 6 3 0 8 9 4 7]]
Epoch 36610: Training cost= 0.2955, Training acc= 0.8482, Validation cost= 0.2580, Validation acc= 0.8483
Epoch 36620: Training cost= 0.3128, Training acc= 0.8482, Validation cost= 0.2253, Validation acc= 0.8483
Epoch 36630: Training cost= 0.2891, Training acc= 0.8482, Validation cost= 0.2442, Validation acc= 0.8483
Epoch 36640: Training cost= 0.3203, Training acc= 0.8482, Validation cost= 0.2938, Validation acc= 0.8483
Epoch 36650: Training cost= 0.2867, Training acc= 0.8483, Validation cost= 0.2665, Validation acc= 0.8483
Epoch 36660: Training cost= 0.2767, Training acc= 0.8483, Validation cost= 0.2863, Validation acc= 0.8483
Epoch 36670: Training cost= 0.2266, Training acc= 0.8483, Validation cost= 0.3048, Validation acc= 0.8483
Epoch 36680: Training cost= 0.2373, Training acc= 0.8483, Validation cost= 0.2533, Validation acc= 0.8483
Epoch 36690: Training cost= 0.2811, Training acc= 0.8483, Validation cost= 0.2781, Validation acc= 0.8484
Epoch 36700: Training cost= 0.2458, Training acc= 0.8483, Validation cost= 0.3280, Validation acc= 0.8484
tm  [-0.8 -0.5 10.2 -0.4 -1.9 -0.3 -0.1 -0.1  0.4 -0.5 -1.3 -0.5 -0.1 -0.2 14.9  2.  -0.5 -0.2 -0.5  1.6 -1.2 -0.3  1.2 -0.1 -0.7 -0.2 -0.6  0.3 -0.4 -0.9 -1.7 -0.1 -0.3  3.2 -0.4 -0.1 -0.4  5.  -0.3 -0.5  1.4  3.8 -0.3  1.  -0.2 -0.1 -2.  -0.2  0.4 10.5 -0.6 -0.  -0.6 10.6 -0.6 -1.4 -0.8  8.3  3.4  6.4  5.5 -0.2 -0.4 -0.1 -0.9 -0.7 -0.2 -0.1  1.  -0.2 -0.2 -0.9 -0.1 -0.7 -5.4  0.4 -0.3  0.3 -0.1 -0.2 -6.2 -0.2  0.   0.7 -0.2  6.3 -1.3 -0.  -0.3 -0.4  0.2 -0.2 -0.  -0.6 -0.3 -0.4  0.9 -3.4 -0.3 -0.4  1.9  8.  -0.3 -0.2  0.1 -0.8 -2.7 -1.  -0.2  2.5 -0.3 -0.1  0.1 -1.3  1.2  4.4  0.1  1.7 -0.  -0.8 -0.3 -1.  -0.1 -0.2  0.1 18.7 -0.3 -2.3  4.5  4.2 -0.7 -0.9 -0.2 -0.6 -6.4 -5.  -0.1 -0.  -0.6 -0.2 -0.3 -0.4 -0.2 -0.2 -0.1 -0.2 -0.3  0.3 -0.7 -0.3 -0.2  0.2  2.3 -0.3 -0.2 -0.1  0.2 -0.3  3.4 -0.4 -0.1 -1.6 -0.  -0.2 -0.3 -0.2  0.2 -0.  -0.4 -0.3  0.7 -0.3 -0.   0.2 -0.1  1.5 -0.1 -0.4  1.4 -0.1 -1.4 -0.4 -0.3 -1.  -0.2 -0.4 -0.3 -0.6 -0.1  2.3 -0.1 -0.3 -0.1 -0.5 -1.8 -1.4 -1.5 -0.4 -0.2 -0.2 -0.3 -0.1 -0.3 -0.4 -0.1 -4.  -0.3 -0.2  3.4  0.5 -0.2  0.5 -0.1  0.4 -0.4 -0.2 -0.  -0.9 -0.  -0.4 -0.2 -0.4 -0.4 -1.1 -0.5  2.3 -0.3 -0.   1.8  2.6 -0.6  1.3 -0.2  1.2 -0.  -2.6  1.6 -1.8  2.9 -4.8 -0.1 -1.8 -0.2 -0.2 18.5  5.2 -0.1 -0.1 -0.8 -0.3 16.5 -0.1 -0.  -0.1 -0.5 -0.8]
ty_50sample [[7 8 5 2 1 0 3 4 6 9]
 [5 3 1 2 0 7 4 6 9 8]
 [5 7 8 3 6 6 1 2 4 0]
 [6 9 8 5 0 7 1 4 3 2]
 [0 1 4 8 3 7 9 6 2 5]
 [6 5 7 1 4 0 9 8 3 2]
 [2 8 7 0 5 9 4 3 6 1]
 [0 9 4 1 7 6 5 8 3 2]
 [8 1 9 7 5 6 3 4 0 2]
 [2 3 9 7 6 4 8 5 0 1]]
tt_50sample [[7 8 5 2 1 0 3 4 6 9]
 [5 3 1 2 0 7 4 6 9 8]
 [5 7 8 3 6 9 1 2 4 0]
 [6 8 9 5 0 1 7 4 3 2]
 [0 1 4 8 3 7 9 6 2 5]
 [6 5 7 1 4 0 9 8 3 2]
 [2 8 7 0 5 9 4 3 6 1]
 [0 4 9 1 7 6 5 8 3 2]
 [8 1 9 7 5 6 3 4 0 2]
 [2 3 9 7 6 4 8 5 0 1]]
vm  [-0.8 -0.2 -2.3 -1.  -1.9 -0.1  0.4 -0.1 -1.  -0.2 -0.5 -0.7  0.2 -0.  -0.4 -1.3  0.8 -0.4 -0.6  1.8 -0.9 -0.2  2.4 -0.  -1.5  6.1 -0.2 -0.1 -1.9 -0.7  1.  -0.4 -1.3 -2.6 -0.1  0.2  4.4 -0.6 -1.3 -0.6 -0.6  2.9  2.4  0.4 -0.   0.4 -1.4 -0.3  2.   6.1 -0.3 -0.2  0.6  3.1  2.9  0.3 -0.4 -0.3 -0.4  1.2  2.4  0.5 -0.1  0.9 -0.5  2.1  0.1 -0.4  0.4  0.3  0.1  6.9  0.   1.  -2.6 -0.5 -0.  -0.3 -0.1  0.4 -1.5  1.2 -0.1  0.5 -0.5  3.7  3.  -0.1  0.5 -0.3 -0.2 -0.   0.1 -0.2 -0.4 -0.  -0.1 -2.3  0.9  0.4 -0.3 -0.2 -0.7  0.3 -0.2  1.6 -1.1  0.6 -0.4 -0.3 -0.6 -0.  -0.1  0.4  2.2 -3.  -1.3 -0.8 -0.2 -0.3  0.8  0.4 -0.3  0.3 -0.  -0.4 -0.1  0.1 -0.7  2.9  2.7 -0.1 -0.3 -0.2 10.4  3.6 -0.2 -0.2  0.  -0.1  1.8 -1.9  0.4 -0.4 -0.  -0.1 -0.2 -0.1  4.3 -0.2  0.5  0.   2.3  2.2 -0.1 -0.2 -0.1 -0.2 -0.9 -0.4  1.6  1.   0.3 -0.1  1.6 -1.  -0.7 -0.5 -0.2 -0.  -0.1 -0.1  0.   0.2  0.2 -0.5  0.2  0.5  2.4 -0.  -0.8 -0.1 -0.8 -2.5 -0.1 -0.4 -0.2  0.3  0.6  2.1  0.5 -0.4 -0.1 -0.8 -0.   3.2 -0.5 -0.5  0.2  0.  -0.1 -0.  -0.4 -0.4  1.3 -1.8 -0.   0.3  2.3  1.3 -0.4 -2.1 -0.9  3.8 -1.2 -0.1  1.2 -0.9 -0.8  0.2 -0.1 -0.2 -0.  -1.3  5.6 -1.  -1.1  0.4 -0.5 -0.1 -0.4 -0.5 -0.4  1.6  5.2  4.6  2.4 -0.2  4.1 -0.9 -0.2 -0.4 -0.  -0.2  6.4  0.4 -0.5  0.9 -1.5 -1.   3.3 -0.2 -0.8 -0.3  0.2  0.4]
vy_50sample [[0 6 8 4 5 1 2 3 9 7]
 [0 4 7 8 2 3 9 9 5 6]
 [9 3 0 7 5 2 1 6 4 8]
 [7 8 3 6 5 0 1 4 2 9]
 [8 5 7 6 0 0 4 9 2 3]
 [1 9 8 4 0 3 2 6 7 5]
 [8 5 6 2 4 4 3 0 1 7]
 [7 8 2 4 5 6 9 9 3 0]
 [2 1 0 6 7 5 9 4 3 8]
 [7 2 3 5 9 0 8 6 1 4]]
vt_50sample [[0 6 8 4 5 1 2 3 9 7]
 [0 4 7 8 2 3 1 9 5 6]
 [9 3 0 7 5 2 1 6 4 8]
 [7 3 8 6 5 0 1 4 2 9]
 [8 5 7 6 0 4 1 9 3 2]
 [1 9 8 4 0 3 2 6 7 5]
 [8 5 6 2 9 4 3 0 1 7]
 [7 8 2 4 5 6 9 1 3 0]
 [2 1 0 6 7 5 9 4 3 8]
 [7 2 3 5 9 0 8 6 1 4]]
Epoch 36710: Training cost= 0.2486, Training acc= 0.8483, Validation cost= 0.3138, Validation acc= 0.8484
Epoch 36720: Training cost= 0.2306, Training acc= 0.8484, Validation cost= 0.2606, Validation acc= 0.8484
Epoch 36730: Training cost= 0.1995, Training acc= 0.8484, Validation cost= 0.2760, Validation acc= 0.8484
Epoch 36740: Training cost= 0.3288, Training acc= 0.8484, Validation cost= 0.2548, Validation acc= 0.8484
Epoch 36750: Training cost= 0.2576, Training acc= 0.8484, Validation cost= 0.2663, Validation acc= 0.8484
Epoch 36760: Training cost= 0.2301, Training acc= 0.8484, Validation cost= 0.2363, Validation acc= 0.8485
Epoch 36770: Training cost= 0.2899, Training acc= 0.8484, Validation cost= 0.2377, Validation acc= 0.8485
Epoch 36780: Training cost= 0.2820, Training acc= 0.8484, Validation cost= 0.2386, Validation acc= 0.8485
Epoch 36790: Training cost= 0.2737, Training acc= 0.8484, Validation cost= 0.2473, Validation acc= 0.8485
Epoch 36800: Training cost= 0.2421, Training acc= 0.8485, Validation cost= 0.2793, Validation acc= 0.8485
tm  [-1.2 -0.1  6.5  9.5 -0.8 -0.2 -0.2 -0.1  0.5  0.6 12.9 -0.4 -0.3 -0.1  2.3  2.4  0.3 -0.3 -0.  -0.6 -0.8 -0.2  0.2 -0.2 -1.1  1.3 -0.1 -0.1 -0.8 -3.2 -0.1 -0.2 -0.6  7.9 -0.  -0.2  0.5  7.   4.9 -0.3 -0.7  4.1 -0.9 -0.8 -0.3 -0.2  0.1 -0.3 -0.9  0.2 -0.5  0.  -0.6 11.1 -0.4 -0.2 -0.4  7.5  6.2  2.7  5.4 -0.2 -0.4 -0.3  2.7 -0.4  0.1  0.8 -0.3 -0.1 -0.1  2.5 -0.1  0.7 -3.6 -0.6 -0.4 -0.1 -0.2 -0.3  8.2 -0.4 -0.3 -0.3 -0.   4.1 -2.1 -0.1 -0.1 -0.2 -0.2 -0.1 -0.4 -1.1 -0.3 -0.2 -0.4 -2.5 -0.4 -0.7 -0.1  4.7  0.8 -0.1 -0.1  1.2 -1.8 -0.3  0.2 -1.1  0.1 -0.1 -0.2 -0.5  3.7 -0.6 -0.3  0.5 -0.2  0.6 -0.3  3.6 -0.1  0.4  0.6  2.9 -0.2 -2.6  6.2 -0.7 -0.1 -0.5 -0.4  0.6 -1.7  4.  -0.2 -0.1 -0.1 -0.3 -1.1 -0.5 -0.7 -0.3 -0.1  0.6 -0.1 -0.2  2.1 -0.2 -0.9  0.3 -1.1 -0.4 -0.2  0.3 -0.1 -0.2  1.  -0.5  0.2 -0.9  0.3 -0.  -0.3 -0.1 -0.1  0.8  0.1 -0.2 -0.3 -0.1 -0.3 -0.1 -0.2 -0.2  0.2 -0.6 -0.3  0.1 -1.4 -0.6 -0.3 -1.5 -0.3 -0.4 -0.7 -0.6  0.3  9.8 -0.1 -0.4 -0.3 -0.5 -1.4 -1.8 -0.4 -1.2  0.2 -0.2 -0.1 -0.1 -0.1 -0.4  0.6 -2.1 -0.2 -0.2 -3.1 -0.1 -0.4 -0.9 -0.5  3.6 -0.2 -0.3  3.8 -0.9 -0.4 -0.4 -0.  -0.1  1.1 -1.2  2.4 -0.9  4.   1.6 -0.3  0.1 -0.9  0.7 -0.2 -1.5  0.8 -1.4  0.9 -0.8  0.4 -1.7 -0.1 -0.6 -0.  -0.1 -1.4  0.9 -0.1 -0.2 -1.   0.1 -2.2 -0.   2.8 -0.3 -1.7  4.9]
ty_50sample [[2 1 0 5 7 9 6 3 8 4]
 [0 7 2 5 3 6 1 9 8 4]
 [1 5 6 3 8 0 4 2 7 9]
 [3 0 5 7 7 6 2 2 8 4]
 [9 8 3 2 5 4 7 1 6 0]
 [7 6 5 2 0 4 3 9 1 8]
 [6 2 4 3 1 8 9 5 0 7]
 [6 5 3 9 8 8 0 1 2 4]
 [7 1 4 3 5 9 8 2 6 0]
 [3 7 8 6 2 5 9 0 1 4]]
tt_50sample [[2 1 0 5 7 9 6 3 8 4]
 [0 7 2 5 3 6 1 9 8 4]
 [1 5 6 3 8 0 4 2 7 9]
 [3 0 5 7 9 6 1 2 8 4]
 [9 8 3 2 5 4 7 1 6 0]
 [7 6 5 2 0 4 3 1 9 8]
 [6 2 4 3 1 8 9 5 0 7]
 [6 5 3 9 8 7 0 1 2 4]
 [7 1 3 4 5 9 8 2 6 0]
 [3 8 7 6 2 5 9 0 1 4]]
vm  [-1.5  0.2  3.3  7.1 -1.6 -0.  -0.4 -0.  -0.  -1.  -2.5 -0.1 -0.3 -0.2 -0.2 -0.1  0.4 -0.5  1.  -0.4 -0.9 -0.3 -0.5 -0.3 -0.9  3.2 -0.3  0.   0.6 -0.9  0.4 -0.3 -0.5  4.  -0.3 -0.5 -0.1 -2.  -0.6 -0.3 -1.1 -1.2 -0.4 -1.5 -0.1  0.1  0.3 -0.   1.  -1.5 -0.2 -0.1  1.5 -2.5 -1.   1.2 -0.4  4.1  2.1  1.6  1.1 -0.4 -0.  -0.1 -0.5  0.3 -0.1 -0.4  0.9  0.9 -0.  -1.1 -0.   1.8 -1.4  0.8 -0.7 -0.4 -0.2  0.6  6.4 -0.4  1.1 -0.2 -0.1 -0.5 -0.9 -0.2 -0.2 -0.4 -0.2 -0.  -0.3 -1.2 -0.4  0.   0.1 -2.1 -0.5 -0.2  4.1 -0.7 -0.3 -0.2 -0.4  1.  -0.4  0.7 -0.7 -1.7  0.1 -0.1 -0.1 -0.9  0.3 11.2 -0.4 -0.2  0.7 -0.2 -0.3  5.9  0.1  1.5 -0.4 -0.3 -0.1 11.3  2.6  1.9  1.3 -0.5 -0.2 -0.7  7.2  9.7  0.8 -0.1 -0.1 -0.3  3.3 -0.2  1.4 -0.  -0.1 -0.  -0.  -0.3  0.6 -0.1 -0.5 -0.  -0.   0.9  0.  -0.1 -0.5 -0.4 -0.7 -0.2 -0.5  2.1  0.3 -0.1 -0.  -0.   0.7  2.1 -0.3  0.5 -0.1 -0.3 -0.1 -0.5 -0.2  0.8 -0.2  0.8  1.9  0.  -1.   1.  -0.5 -2.  -0.1  0.   0.2 -0.8  0.7  2.8 -0.4  0.3 -0.1 -0.9  1.7 -0.8  1.3 -0.2 -0.1 -0.  -0.  -0.1 -0.1 -0.3 -0.2 -0.3  0.3 -0.  -0.3 -0.1 -0.5  4.7 -0.7  4.2 -0.5 -0.3  5.8 -0.7 -0.1 -0.4 -0.2 -0.3 -0.2 -0.8  2.6  2.7 -2.3  0.2  3.1  2.6  0.4 -1.  -0.3 -0.2 -0.4 -0.7 -0.3  0.8  2.5  4.8 -0.1  1.5  0.2 -0.2 -0.8 -1.4 -0.3 -0.1 -1.4 -0.4 -1.8  0.1 -0.5 -0.   7.6  0.5]
vy_50sample [[6 3 9 1 7 5 8 8 0 2]
 [3 7 6 6 2 9 9 5 4 0]
 [6 2 3 1 9 4 8 5 0 7]
 [2 5 4 8 0 1 9 7 3 6]
 [2 6 3 4 1 5 9 9 7 8]
 [9 8 7 1 3 2 0 6 5 4]
 [9 3 0 1 4 7 2 8 5 6]
 [2 9 4 1 7 5 6 0 8 3]
 [8 0 5 4 2 9 7 6 6 3]
 [2 5 4 0 9 9 6 1 3 8]]
vt_50sample [[6 3 9 1 7 5 8 4 0 2]
 [3 7 2 1 6 8 9 5 4 0]
 [6 2 3 1 9 4 8 5 0 7]
 [2 5 4 8 0 1 9 7 3 6]
 [2 6 3 4 1 5 0 9 7 8]
 [9 8 7 1 3 2 0 6 5 4]
 [9 3 0 1 4 7 2 8 5 6]
 [2 9 4 1 7 5 6 0 8 3]
 [8 0 5 4 2 9 7 6 1 3]
 [2 5 4 0 7 9 6 1 3 8]]
Epoch 36810: Training cost= 0.2486, Training acc= 0.8485, Validation cost= 0.2993, Validation acc= 0.8485
Epoch 36820: Training cost= 0.2749, Training acc= 0.8485, Validation cost= 0.2331, Validation acc= 0.8485
Epoch 36830: Training cost= 0.2569, Training acc= 0.8485, Validation cost= 0.2354, Validation acc= 0.8486
Epoch 36840: Training cost= 0.2846, Training acc= 0.8485, Validation cost= 0.3168, Validation acc= 0.8486
Epoch 36850: Training cost= 0.2786, Training acc= 0.8485, Validation cost= 0.2151, Validation acc= 0.8486
Epoch 36860: Training cost= 0.2783, Training acc= 0.8485, Validation cost= 0.2710, Validation acc= 0.8486
Epoch 36870: Training cost= 0.2808, Training acc= 0.8486, Validation cost= 0.2170, Validation acc= 0.8486
Epoch 36880: Training cost= 0.3307, Training acc= 0.8486, Validation cost= 0.3210, Validation acc= 0.8486
Epoch 36890: Training cost= 0.3388, Training acc= 0.8486, Validation cost= 0.3214, Validation acc= 0.8486
Epoch 36900: Training cost= 0.2755, Training acc= 0.8486, Validation cost= 0.2657, Validation acc= 0.8486
tm  [-0.   0.8 -1.5  1.9 -0.3 -0.1 -0.   0.3 -1.7 -0.6  5.2 -0.3 -0.3 -0.2 -1.4  9.2 -0.1 -0.4  0.7 -1.6 -0.5 -0.   1.4 -0.1 -1.1 -0.3 -0.2 -0.3  0.2  9.3 -0.1 -0.1 -0.1 -2.9 -0.2 -0.3  4.3  2.2 -0.6 -0.6  1.  -1.8  3.6 -0.2 -0.1 -0.2  7.1 -0.6  0.2  5.  -0.1 -0.2 -0.4  4.7 -1.7  2.3 -0.8 -2.4 -2.7  3.6 -1.5  1.  -0.8 -0.6 -0.5  1.  -0.   0.  -0.3 -0.1 -0.4 -1.9 -0.5 -0.7  0.3  0.8 -0.1  1.6 -0.6  1.1 -0.4  0.3 -0.6  1.3 -0.8 -1.4  5.  -0.  -0.3 -0.4 -0.6 -0.1 -0.5  5.5 -0.2 -0.  -0.  -0.3 -0.3 -0.1  2.2 -0.3 -0.2 -0.1  1.1 -0.2 -1.4 -0.1  1.8 -1.8 -0.1 -0.  -0.   0.5 -2.2 10.8  0.4 -1.6 -0.  -0.4 -0.   6.  -0.3 -0.4  0.1 -1.6 -0.2 -0.7 -3.5  0.7 -0.2 -0.1 -0.5  0.2  9.3  3.6 -0.6 -0.2 -0.8 -0.5 -1.8  0.  -0.8 -0.2 -0.1 -0.1 -0.2 -0.2 -0.6 -0.4 -0.4 -0.   1.8 -0.6 -0.3 -0.2 -0.1 -0.2 -1.7 -0.5  1.4  1.9 -0.6  0.7 -0.   1.6 -0.7 -0.5 -0.4  0.1 -0.2 -0.2  0.9 -0.5  0.2  1.8 -1.4 -0.2  1.1 -0.3  0.8  1.3  2.3 -1.1  0.2 -0.2  0.2 -0.4 -0.1 -2.5  1.1 -0.2 -0.2 -0.7 10.3 10.5  0.3  4.6  0.4 -0.2  0.8  0.5  1.5 -0.3 -0.2 -0.   0.1 -0.1 10.1  0.4 -0.8  2.3 -0.2 -0.4  0.1  0.1  0.6 -0.  -0.2 -0.2 -0.3 -0.2  0.8 -0.5  2.6  5.3  2.6 -0.6 -0.3 -0.3 -0.5  1.2 -0.4  2.7 -1.5  2.4 -0.5 -0.1 -1.  19.  -0.2  7.  -0.1 -0.3  2.9 -1.3  1.  -0.3 -0.4 -0.7  0.9 -0.  -0.5 -0.1 -1.3  1.6]
ty_50sample [[2 6 8 4 9 3 7 1 5 0]
 [3 2 8 8 9 7 4 0 1 6]
 [1 1 7 2 9 4 5 6 3 0]
 [6 1 0 3 7 5 5 4 9 8]
 [6 2 7 5 3 0 1 9 8 4]
 [7 2 5 6 1 4 8 3 0 9]
 [7 2 1 4 0 3 8 6 5 5]
 [7 7 4 0 6 2 9 1 1 3]
 [2 7 1 4 6 5 9 3 0 8]
 [9 0 2 4 7 6 3 8 1 5]]
tt_50sample [[2 6 8 4 9 3 7 1 5 0]
 [3 2 8 5 9 7 4 0 1 6]
 [1 7 8 2 9 4 5 6 3 0]
 [6 1 0 3 7 5 2 9 4 8]
 [6 2 7 5 3 0 1 9 8 4]
 [7 2 5 6 1 4 8 3 0 9]
 [7 2 1 4 0 3 8 6 5 9]
 [5 7 4 0 6 2 9 8 1 3]
 [7 2 1 4 6 5 9 3 8 0]
 [9 0 2 4 7 6 3 8 1 5]]
vm  [-0.3 -0.1 11.5 -0.4 -2.1 -0.2 -0.2 -0.1 -0.6 -0.9 -0.9 -0.3 -0.1 -0.1 15.  -0.8 -0.1  0.1 -0.2  2.7 -0.7 -0.2 -0.2  0.7 -1.4  3.1 -0.4  0.1 -0.7 -0.8 -0.8  0.2 -0.4  9.6 -0.2 -0.1  0.3 -0.  -1.6 -0.4 -0.5 -0.2  1.1 -0.8 -0.1 -0.1 -2.6  0.6  3.4 -1.1 -0.7  0.4 -0.   5.8 -0.3 -1.5 -0.7  8.3 -0.2  4.7  3.4 -0.1 -0.1 -0.3 -0.2 -0.4 -0.1 -0.2  0.9 -0.4  0.3  0.7  0.  -0.2 -5.4 -0.3 -0.1 -0.2 -0.2 -0.3 -3.  -0.3 -0.1 -0.2 -1.1 -0.1 -0.6 -0.1 -0.1 -0.4 -0.4 -0.  -0.   0.4 -0.3 -0.1  0.9 -3.  -0.3 -0.3  2.8  3.9 -0.8 -0.1 -0.3  0.5 -2.4 -0.4 -0.2  3.1  0.3 -0.3 -0.2 -0.8  0.4 -0.2 -0.6 -0.1 -0.2 -0.2 -0.3 -1.5 -0.1  0.3 -0.1 18.6 -0.1 -0.8  1.2 11.   1.2 -0.4 -0.5 -0.3 -4.5 -0.5 -0.1 -0.3 -0.1 -0.2  0.8 -1.1  0.6  0.1 -0.1  0.4 -0.1 -0.2 -0.9 -0.1 -0.3 -0.3  2.5  1.5 -0.2 -0.1 -0.3 -0.2  1.  -0.3 -0.5 -1.1  0.2 -0.1 -0.2 -0.5 -0.  -0.2 -0.1 -0.3 -0.1 -0.2 -0.4 -0.4 -0.1  1.9 -0.4 -0.1  3.1  0.2 -1.3 -0.3 -0.3 -1.9 -0.3 -0.3  0.3 -0.7 -0.   1.9 -0.1 -0.1 -0.1 -0.9 -0.6 -0.2 -1.  -0.3  0.2 -0.1 -0.4 -0.3 -0.3 -0.1 -0.3 -3.2 -0.1 -0.2 -0.8 -0.1 -0.4 -0.8 -0.3 -0.4 -0.3 -0.2  3.6 -0.8 -0.2 -0.4 -0.1 -0.1  0.1 -0.9 -0.9 -0.1 -1.6 -0.2 -0.5  2.1 -0.3  0.3 -0.4 -0.5  0.8 -2.6  0.1 -1.1  1.6 -4.4 -0.1 -1.5 -0.1 -0.1 10.6  3.2 -0.4 -0.1 -0.9 -0.1  7.8 -0.2 -1.  -0.3  6.7 -2.9]
vy_50sample [[7 3 5 0 8 6 1 2 4 9]
 [5 4 6 8 9 0 2 7 1 3]
 [8 5 9 3 7 0 2 6 6 4]
 [0 2 8 1 4 5 6 3 7 9]
 [1 5 3 6 8 2 9 0 7 4]
 [0 5 4 7 2 6 9 1 3 8]
 [0 4 5 3 9 6 1 7 7 8]
 [8 6 4 1 5 7 9 0 3 2]
 [9 3 6 7 8 2 4 4 1 1]
 [2 5 8 8 7 6 3 9 0 4]]
vt_50sample [[7 3 5 0 8 6 1 2 4 9]
 [5 4 6 8 9 2 0 7 1 3]
 [8 5 9 3 7 0 6 2 1 4]
 [0 2 8 1 4 5 6 7 3 9]
 [1 5 3 6 8 9 2 0 7 4]
 [0 5 4 7 2 6 9 1 8 3]
 [0 4 5 3 9 6 1 7 2 8]
 [8 6 4 1 5 7 9 0 3 2]
 [9 3 6 7 8 2 4 5 0 1]
 [2 5 8 7 1 6 3 9 0 4]]
Epoch 36910: Training cost= 0.2876, Training acc= 0.8486, Validation cost= 0.2543, Validation acc= 0.8487
Epoch 36920: Training cost= 0.2395, Training acc= 0.8486, Validation cost= 0.2327, Validation acc= 0.8487
Epoch 36930: Training cost= 0.2443, Training acc= 0.8486, Validation cost= 0.2382, Validation acc= 0.8487
Epoch 36940: Training cost= 0.2330, Training acc= 0.8486, Validation cost= 0.2690, Validation acc= 0.8487
Epoch 36950: Training cost= 0.2601, Training acc= 0.8487, Validation cost= 0.2898, Validation acc= 0.8487
Epoch 36960: Training cost= 0.2264, Training acc= 0.8487, Validation cost= 0.2416, Validation acc= 0.8487
Epoch 36970: Training cost= 0.2656, Training acc= 0.8487, Validation cost= 0.2554, Validation acc= 0.8487
Epoch 36980: Training cost= 0.2392, Training acc= 0.8487, Validation cost= 0.2313, Validation acc= 0.8488
Epoch 36990: Training cost= 0.2231, Training acc= 0.8487, Validation cost= 0.2663, Validation acc= 0.8488
Epoch 37000: Training cost= 0.2552, Training acc= 0.8487, Validation cost= 0.3049, Validation acc= 0.8488
tm  [-1.3  0.1 -3.1 11.1 -0.5 -0.1 -0.1 -0.2 -0.8 -0.8 -5.3 -0.5 -0.  -0.5 -4.4  0.1 -0.1 -0.3 -0.2 -1.  -0.6  0.2  1.6 -0.3 -0.6  1.3 -0.6 -0.2 -0.5 -0.4 -0.6 -0.3 -0.6 -6.3 -0.3  0.4  3.2 -0.9  9.7 -0.6 -0.1  3.2  1.6 -0.1  0.1 -0.   7.3  0.7 -0.9  7.7 -0.6 -0.1 -0.  -3.6 -1.1  5.  -0.6  4.6 -0.8  3.9 -0.4 -0.2 -0.7 -0.3 -1.2  0.  -0.2 -1.  -0.1  1.  -0.3 -0.9 -0.2 -0.2  6.7  0.9  0.6 -0.1 -0.4  1.6  3.9 -0.1 -0.2  1.5  0.9  5.3 -0.9 -0.3 -0.1 -0.2 -0.4 -0.2 -0.2 -0.  -0.4 -0.3  1.2 -0.1 -0.3  1.2  3.8 -1.5  1.5 -0.  -0.4 -0.1  1.7 -0.5 -1.6 -2.5 -0.4 -0.1 -0.3 -0.2 -0.6  8.1 -0.2 -1.2 -0.  -1.   0.  10.1 -0.1  0.  -0.  -5.3  0.9 14.1 -0.3 -1.8 -0.2 -0.2 -0.2 -0.6 11.7 -1.9  0.2 -0.1 -0.7  0.   2.9 -0.3 -0.2 -0.1 -0.1 -0.4  0.8 -0.2  7.8 -0.5 -0.8 -0.4  1.5 -0.1 -0.1 -0.1 -0.1 -1.1 -0.1 -0.6  0.3  0.3 -0.1 -0.1  0.1  0.1 -0.2  0.1 -0.4 -0.3  0.1  0.1 -0.3 -0.   0.2 -1.7 -0.4  0.8 -0.9 -0.  -1.8  0.1 -0.4 -1.4 -0.3  0.2 -0.8  2.4  1.   1.5 -0.3 -0.5 -0.3 -0.2  4.5  2.5  3.8  1.5  0.1 -0.1  0.2 -0.2  0.3 -0.1  0.1  4.6 -0.   0.4  2.6 -0.2 -0.9  0.8 -0.   6.2 -0.1 -0.2  1.  -0.3 -0.1 -0.4 -0.1 -0.3 -0.3 -0.4  2.4  2.9 -1.2 -0.2 -0.7 -0.2 -0.8 -1.4 -0.4  1.9 -0.1  3.8 -0.5  3.1  0.8  7.1 -0.   2.3  0.1 -0.5 -0.2 -2.3 -0.1 -0.1 -1.  -0.4 -1.1 -0.4  6.1 -0.3  3.6  8.4]
ty_50sample [[9 8 5 1 6 4 3 0 2 7]
 [3 5 0 4 2 6 9 8 7 7]
 [4 1 2 3 5 0 8 9 6 7]
 [2 5 3 0 8 6 7 9 4 1]
 [6 1 5 9 0 3 8 4 7 2]
 [6 8 0 7 4 5 1 3 2 9]
 [1 2 8 5 3 0 0 4 4 7]
 [6 1 5 0 2 4 8 9 3 7]
 [9 7 6 4 1 2 3 8 8 5]
 [3 4 0 7 2 9 9 1 6 8]]
tt_50sample [[9 8 5 1 6 4 3 0 2 7]
 [3 5 0 4 2 6 9 8 1 7]
 [4 1 2 3 5 0 8 9 6 7]
 [5 2 3 0 8 6 7 9 4 1]
 [6 1 5 0 9 3 8 4 7 2]
 [6 8 0 7 4 5 3 1 2 9]
 [1 2 8 3 5 0 6 9 4 7]
 [6 1 5 0 2 4 8 3 9 7]
 [9 7 6 4 1 2 3 8 0 5]
 [3 4 0 7 2 9 5 1 6 8]]
vm  [ 0.1  0.3 10.1  3.  -1.4 -0.1 -0.2 -0.1 -0.8 -0.3 -4.5 -0.3 -0.3 -0.4 11.7  4.4 -0.   0.6 -0.7 -0.1 -0.6 -0.7 -0.3 -0.1 -1.3  0.7 -0.3 -0.1  3.3  7.1 -1.8 -0.2 -0.6  1.6 -0.1 -0.3 -0.7  0.1 -0.7 -0.5 -0.9  0.9  2.1 -1.  -0.1 -0.4 -1.1 -0.2  6.  11.  -0.2 -0.1 -0.6  3.3 -1.2 -1.  -0.1  5.  -1.2  6.2  0.1 -0.7 -0.2 -0.2 -1.  -1.2 -0.3 -0.1 -0.7 -0.6 -0.2 -2.  -0.1  2.5 -4.3 -0.  -0.7  0.2 -0.3 -0.3 -4.9  0.1 -0.1 -0.9 -1.9  3.2  1.  -0.1 -0.  -1.  -0.1 -0.1 -0.2  0.4 -0.3 -0.3  0.3 -2.8 -0.1 -0.8  0.9  5.8 -1.  -0.1 -0.4  0.1 -1.  -1.3 -1.2 -0.5  3.1 -0.1 -0.2 -0.6 -1.1 13.1 -1.3 -0.5  1.4 -0.9 -0.2 -0.1 -0.1 -0.2 -0.2 14.9 -0.  -0.2 -1.2  1.2  2.9 -0.1 -0.6  1.1 -3.  -3.5 -0.1 -0.1  0.3  3.2 -0.1 -0.7 -0.5 -0.4 -0.3 -0.1 -0.4 -0.2 -1.5 -0.3 -0.3 -0.2  2.   0.2 -0.2 -0.3 -0.8 -0.1 -0.4  0.6 -0.3 -0.8  0.9 -0.1 -0.   0.5 -0.4 -0.4 -0.3 -0.1 -0.  -0.  -0.4 -0.2 -0.1  1.1 -0.5  1.4  1.7  0.1 -0.8 -0.1 -0.3 -1.3 -0.4 -0.7  1.8 -0.6 -0.2 -2.1 -0.4 -0.3 -0.2 -0.6  4.4  4.1 -0.1  2.  -0.4 -0.  -0.4 -0.3  0.8  1.5 -0.3 -0.7  0.2 -0.3  6.8  0.  -0.5  5.3 -0.4 -1.1 -0.3 -0.5  4.8 -0.1 -0.7 -1.2 -0.3 -0.3 -0.4 -0.9  2.7  3.7 -1.3 -0.1 -0.   1.6  0.3 -0.3 -0.9  2.5 -1.3 -2.1 -0.9 -0.6  0.4 -0.7 -0.  -0.1 -0.1 -0.3 14.8 -0.5 -1.1 -0.9 -0.6 -0.5 13.4 -0.1 -0.4  0.1  0.2  1.6]
vy_50sample [[7 8 6 5 2 3 9 4 1 0]
 [7 1 2 5 9 0 3 6 4 8]
 [3 4 5 2 2 7 8 8 9 6]
 [0 2 1 8 5 6 3 4 9 7]
 [4 0 2 8 5 9 7 3 1 6]
 [0 7 6 1 2 3 8 4 9 5]
 [2 5 0 8 3 3 7 6 4 1]
 [5 3 7 4 0 9 8 6 2 1]
 [8 6 5 9 7 2 4 3 1 0]
 [2 8 1 5 3 0 4 7 6 9]]
vt_50sample [[7 8 6 5 2 9 3 4 1 0]
 [7 1 2 5 9 0 3 6 4 8]
 [3 4 5 2 7 1 8 0 9 6]
 [0 2 1 8 5 6 3 9 4 7]
 [4 0 2 8 5 9 7 3 1 6]
 [0 7 6 1 2 3 8 4 9 5]
 [5 2 0 8 9 3 7 6 4 1]
 [5 3 7 4 9 0 8 6 2 1]
 [8 6 9 5 7 2 4 3 1 0]
 [2 8 1 5 3 0 4 7 6 9]]
Epoch 37010: Training cost= 0.3190, Training acc= 0.8487, Validation cost= 0.2845, Validation acc= 0.8488
Epoch 37020: Training cost= 0.2484, Training acc= 0.8488, Validation cost= 0.2696, Validation acc= 0.8488
Epoch 37030: Training cost= 0.3189, Training acc= 0.8488, Validation cost= 0.2918, Validation acc= 0.8488
Epoch 37040: Training cost= 0.2763, Training acc= 0.8488, Validation cost= 0.2866, Validation acc= 0.8488
Epoch 37050: Training cost= 0.2934, Training acc= 0.8488, Validation cost= 0.3136, Validation acc= 0.8488
Epoch 37060: Training cost= 0.2649, Training acc= 0.8488, Validation cost= 0.3464, Validation acc= 0.8488
Epoch 37070: Training cost= 0.3123, Training acc= 0.8488, Validation cost= 0.2662, Validation acc= 0.8489
Epoch 37080: Training cost= 0.2661, Training acc= 0.8488, Validation cost= 0.2474, Validation acc= 0.8489
Epoch 37090: Training cost= 0.2563, Training acc= 0.8488, Validation cost= 0.2435, Validation acc= 0.8489
Epoch 37100: Training cost= 0.3029, Training acc= 0.8488, Validation cost= 0.2745, Validation acc= 0.8489
tm  [ 0.6  0.5  8.1 18.7 -0.9 -0.3 -0.2 -0.1 -0.3 -0.4 11.9 -0.3 -0.4  0.3 -1.   0.6  0.2 -0.3  0.4 -1.6 -0.9 -0.  -1.4 -0.2 -0.6  0.8 -0.5  0.7 -1.1 -2.4  0.4 -0.2 -0.3 10.2 -0.3 -0.3  2.7  5.2 12.  -0.  -0.  -1.9 -0.4 -1.1  0.1 -0.5  8.7 -0.4  2.7 -4.9 -0.4 -0.2 -0.1  2.9 -0.4  1.1 -0.3  6.4  0.3  0.7 -1.7 -0.2 -0.9 -0.4  0.7 -0.4  0.3 -0.  -0.  -0.4 -0.4  2.3 -0.  -0.5 -0.4 -0.2 -0.6 -0.3 -0.1 -0.3 21.6 -0.1 -0.6 -0.3 -1.4 -2.  -0.6 -0.2 -0.4 -0.2 -0.4 -0.  -0.   1.3 -0.6 -0.3 -0.2 -0.9 -0.4 -0.6  1.4 -1.3 -0.6  0.1 -0.2 -0.2 -0.7  0.1 -0.  -2.   1.6 -0.2 -0.1 -0.1  0.3 -1.3  0.  -0.3  0.2  0.8 -0.5  7.   0.   0.8  0.2 -1.2 -0.2 -0.2  0.8  3.1  1.3 -0.4 -0.2  1.3 -1.8  6.6 -0.1 -0.1 -0.  -0.5 -0.7 -0.4 -0.6  0.1 -0.1 -0.1 -0.2 -0.1 -0.1 -0.2 -1.3 -0.2  0.7 -0.1 -0.2 -0.3  0.4 -0.3  0.3 -0.2 -0.4 -1.3 -0.1 -0.2  0.3  0.3  0.2 -0.3 -0.2 -0.2 -0.2 -0.1 -0.   0.2 -0.2  0.7 -0.2 -0.8 -1.2 -0.  -1.  -0.4 -0.1 -1.3 -0.2  0.1  2.  -0.3  0.   7.4 -0.3  0.5 -0.4 -0.8 12.1 -0.3  0.  -0.3 -0.1 -0.3 -0.3 -0.2 -0.4  0.3 -0.1  1.5 -0.1 -0.1 -2.5  0.3 -0.1 -1.  -0.7 -1.4  1.4  0.6  4.5 -1.2 -0.3 -0.1 -0.1 -0.3  1.2 -0.6 -1.6 -1.3  0.9 -0.1 -0.2  2.1 -1.  -0.3 -0.2 -1.3 -0.1 -1.8  0.3 -0.1 -0.3  9.7  0.1  2.7 -0.1 -0.3 -4.7 -2.1  0.2 -0.5 -0.9 -0.1 -5.6 -0.   7.9 -0.2  2.6 -0.2]
ty_50sample [[3 2 0 0 7 5 6 1 8 4]
 [8 3 0 2 7 9 1 5 4 6]
 [6 9 3 7 2 8 1 4 0 5]
 [2 9 6 0 5 7 1 4 8 3]
 [3 2 4 7 9 9 1 0 6 5]
 [5 1 2 0 9 4 6 3 8 7]
 [0 1 4 8 2 6 5 5 7 3]
 [3 2 0 5 7 4 9 6 8 1]
 [7 3 0 6 4 8 8 9 2 1]
 [8 1 6 9 7 0 5 3 2 4]]
tt_50sample [[3 2 0 9 7 5 6 1 4 8]
 [8 3 0 2 7 9 1 5 4 6]
 [6 9 3 7 8 2 1 4 0 5]
 [2 9 6 0 5 7 1 4 3 8]
 [3 2 4 7 8 9 1 0 6 5]
 [5 1 2 0 9 4 6 3 8 7]
 [0 1 4 2 8 6 9 5 3 7]
 [3 2 0 5 7 4 9 6 8 1]
 [7 3 0 6 4 8 5 9 2 1]
 [8 1 6 9 7 0 5 3 2 4]]
vm  [-0.2 -0.9  4.1 10.9 -1.9  0.1 -0.4 -0.1  1.7  0.  -3.8 -0.3  0.9 -0.2 -0.9 -2.1  0.6 -0.4  1.3 -1.2 -1.2  0.4  1.3 -0.2 -0.5  2.9 -0.2 -0.  -1.2 -2.9 -0.2  0.1 -0.1 -0.2 -0.  -0.2 -0.2  1.3 15.3 -0.5  2.6  3.3 -0.4  3.4  0.5 -0.   5.8  0.3  5.6  4.9 -0.5 -0.2 -0.  -2.7  2.9  1.3 -1.2  3.5  5.9  3.5 -1.2 -0.4  0.4  0.9 -0.6 -0.1  0.5 -0.7  1.8  0.2 -0.2  3.8 -0.2  0.3 -0.8 -0.2 -0.7  0.  -0.2 -0.1  5.6 -0.1 -0.2 -0.5 -1.2  3.5  1.8 -0.  -0.3 -0.3 -0.3 -0.1 -0.2 -1.4 -0.2 -0.1 -0.1 -2.2 -0.3 -0.3 -0.   2.9 -0.3 -0.2 -0.3 -0.3  0.7 -0.3 -1.4 -2.  -0.6  0.  -0.2 -0.6  6.4 -1.9  2.   0.9 -0.3 -0.1 -0.4  7.  -0.1 -0.7 -0.2 -1.1 -0.5 11.2  7.4 -1.4 -0.3 -0.6 -0.3 -0.5 -3.8 -3.7 -0.5 -0.1 -0.7 -0.2  2.8 -1.   0.6 -0.1 -0.1 -0.1 -0.1 -0.   2.5 -0.1 -0.8 -0.   3.2  0.2 -0.3 -0.1  0.1  0.8  4.5 -0.2 -0.2 -2.1 -0.  -0.2 -0.4 -0.3 -0.  -0.4 -0.1 -0.2 -0.   0.3 -0.2 -0.2 -0.  -0.1  0.8 -0.1 -1.5 -0.1 -1.6 -0.3 -0.6 -0.9 -0.1 -0.1  2.3 -0.2 -0.3  8.4  0.3  0.1 -0.3 -0.4  9.7 -2.3  0.  -1.6 -0.2  0.3 -0.3  0.8 -0.1 -0.  -0.4  0.7 -0.3 -0.3  0.1 -0.2 -0.4 -1.1 -0.2 -1.4 -0.7 -0.5 -1.  -1.1  0.1 -0.6 -0.2 -0.1  0.4 -1.2 -1.5 -0.9 -2.1 -0.4 -0.1  3.4 -0.2 -1.   0.6 -0.1  3.6 -0.5  1.1  1.5  5.   4.9 -0.1  0.6 -0.1 -0.1 -0.6 -1.8 -0.3 -0.3 -1.4 -0.1 -1.8 -0.2 10.  -0.2  5.9  7.8]
vy_50sample [[0 9 5 8 7 3 4 1 2 6]
 [1 8 7 3 9 5 6 4 0 2]
 [0 4 3 8 5 2 1 9 6 7]
 [1 8 7 7 6 9 5 3 4 0]
 [7 9 8 0 1 4 3 5 2 6]
 [1 7 8 2 0 3 4 5 6 9]
 [3 7 2 4 9 8 0 1 5 6]
 [1 1 8 3 0 7 4 6 2 5]
 [8 2 1 3 3 7 4 6 5 0]
 [8 4 4 7 0 1 2 3 5 6]]
vt_50sample [[0 9 5 8 7 3 4 1 2 6]
 [1 8 7 3 9 5 6 4 0 2]
 [0 4 3 8 5 2 1 9 6 7]
 [1 8 7 2 6 9 5 3 4 0]
 [7 9 8 0 1 4 3 5 2 6]
 [1 7 8 0 2 3 4 5 6 9]
 [3 7 2 4 9 8 0 1 5 6]
 [1 9 8 3 0 7 4 6 2 5]
 [8 2 1 3 9 7 4 6 5 0]
 [8 9 4 7 0 1 2 3 5 6]]
Epoch 37110: Training cost= 0.2743, Training acc= 0.8489, Validation cost= 0.2537, Validation acc= 0.8489
Epoch 37120: Training cost= 0.2689, Training acc= 0.8489, Validation cost= 0.2282, Validation acc= 0.8489
Epoch 37130: Training cost= 0.2504, Training acc= 0.8489, Validation cost= 0.2141, Validation acc= 0.8489
Epoch 37140: Training cost= 0.2237, Training acc= 0.8489, Validation cost= 0.2378, Validation acc= 0.8490
Epoch 37150: Training cost= 0.2582, Training acc= 0.8489, Validation cost= 0.2458, Validation acc= 0.8490
Epoch 37160: Training cost= 0.2655, Training acc= 0.8489, Validation cost= 0.2909, Validation acc= 0.8490
Epoch 37170: Training cost= 0.2085, Training acc= 0.8489, Validation cost= 0.2847, Validation acc= 0.8490
Epoch 37180: Training cost= 0.2444, Training acc= 0.8489, Validation cost= 0.2590, Validation acc= 0.8490
Epoch 37190: Training cost= 0.2842, Training acc= 0.8490, Validation cost= 0.2227, Validation acc= 0.8490
Epoch 37200: Training cost= 0.2425, Training acc= 0.8490, Validation cost= 0.2667, Validation acc= 0.8490
tm  [-0.3  0.2 -2.  -2.4 -0.6 -0.2 -0.3  0.2 -0.9 -0.7 -0.1 -0.2 -0.5  0.7  0.7  3.9 -0.2  0.1  0.  -0.1 -1.2 -0.2 -0.4 -0.4 -0.9 -0.  -0.3 -0.3  0.3 -0.2 -0.2  0.   0.2 -3.8 -0.2 -0.4  1.1 -0.6 -4.1 -0.7 -0.  -3.7 -0.4 -0.6 -0.2 -0.1 -1.1 -0.4  0.3 -0.6 -0.6 -0.2 -0.6  8.7 -1.5 -0.1 -0.6 -2.2  0.2  3.2  1.5  0.5 -0.7 -0.5 -0.6 -0.2 -0.1  0.1  0.8 -0.2  0.6 -1.3  0.4 -0.3 -4.6  0.9 -0.1  0.3 -0.4 -0.4 -4.2 -0.1 -0.   1.9 -0.9 -3.8  2.7 -0.2 -0.3 -0.3 -0.1 -0.  -0.2  0.4 -0.3 -0.3  0.  -2.5 -0.3 -0.5  2.7 -1.8 -0.3 -0.2 -0.1 -0.2 -2.6 -0.1  0.1 -0.2 -0.1 -0.2 -0.1 -0.8 -0.2  7.2 -0.2 -0.2  0.3 -0.4 -0.4 -0.4 -0.3 -0.2 -0.1  1.1  0.2 -1.7 -0.5 12.3  0.2 -0.8 -0.3 -0.4 13.2  5.8 -0.  -0.2 -0.2 -0.3 -0.6 -0.3 -0.5 -0.2 -0.3  0.4 -0.3 -0.3 -0.6 -0.2  1.1 -0.1  2.8 -0.  -0.3 -0.1 -0.5 -0.6 -1.5 -0.6 -0.1  2.  -0.1 -0.3 -0.1 -0.5 -0.1  0.8 -0.   0.1 -0.3 -0.1 -0.1 -0.4  0.1  2.4 -1.4 -0.5  6.2 -0.1  2.7  0.3 -0.2 -1.4 -0.4  0.1 -0.2 -0.2 -0.1  1.  -0.2 -0.2 -0.5 -1.3  0.8  1.4 -0.9  0.2 -0.1 -0.3 -0.3 -0.3 -0.3 -0.3 -0.3 -3.2 -0.3 -0.2 10.4 -0.3 -0.7  0.8 -0.9  0.2 -0.3 -0.2  3.1 -0.6 -0.4  0.4 -0.2 -0.2  0.9 -0.8  0.7  3.9 -0.6 -0.1 -0.2  1.5  0.   2.4 -0.5  3.1 -0.9  2.6  0.  -1.1 -0.   6.6 -0.1  2.9 -0.1 -0.1 13.2  2.4  0.6 -0.5 -1.1 -0.2 10.9 -0.2 -2.6 -0.3  3.4 -2.9]
ty_50sample [[6 3 8 2 4 1 9 0 0 5]
 [7 2 9 6 0 1 5 3 4 8]
 [5 8 0 4 7 7 1 2 6 3]
 [7 8 2 5 6 9 1 4 3 0]
 [8 4 7 1 3 9 6 2 5 0]
 [6 3 7 1 4 5 0 2 9 8]
 [5 6 1 7 8 2 9 4 3 3]
 [5 7 1 1 0 2 8 9 6 3]
 [2 9 1 3 8 0 7 6 5 4]
 [0 5 3 6 7 9 8 1 2 4]]
tt_50sample [[6 3 8 2 4 1 9 7 0 5]
 [7 2 9 0 6 1 3 5 4 8]
 [5 8 0 4 9 7 1 2 6 3]
 [7 8 2 5 6 9 1 4 3 0]
 [8 4 7 1 3 9 6 2 5 0]
 [6 3 7 1 4 5 0 2 9 8]
 [5 6 1 7 8 2 9 4 0 3]
 [5 7 1 4 0 2 8 9 6 3]
 [2 9 3 1 8 0 7 6 5 4]
 [0 5 3 6 7 9 8 1 2 4]]
vm  [-0.1 -0.   6.  19.7 -1.   0.5  0.4 -0.2 -0.8  0.   7.2 -0.6 -0.2  1.  -1.1  6.7 -0.7 -0.5 -0.6 -2.  -0.6  0.5  1.9 -0.2 -0.8 -0.5 -0.2 -0.4  1.3  7.5 -0.1 -0.2  0.3  7.3 -0.1 -0.1  1.5 -0.1  3.9 -0.3  2.   4.1  1.7 -0.9 -0.2 -0.2 11.4 -0.1  1.   6.9 -0.3 -0.1  1.  -0.7 -1.5  0.9 -0.1  3.2 -2.   3.1 -2.3 -0.5 -0.5 -0.2  2.  -0.6  0.2  0.5 -0.2 -0.4 -0.5 -2.1 -0.5 -0.7  8.4 -1.  -0.3 -0.6 -0.3 -0.5 18.5  1.7 -0.4  0.3 -1.1  6.1  1.5  0.4 -0.2  0.   0.9 -0.1 -0.2  0.3 -0.3  0.  -0.9  2.2  1.1  1.1 -0.1  6.1 -0.6  0.2 -0.1 -0.6  1.2 -0.1  0.8 -2.1 -0.  -0.2 -0.3 -0.4 -1.6 10.7 -0.6 -1.4 -0.1 -0.3 -0.   7.  -0.5 -0.2 -0.2 -1.2  1.2  3.6 -1.8 -3.8 -0.  -0.   0.4  0.4  5.4 12.3 -0.2 -0.2 -0.5 -0.8 -0.4  0.4 -0.4  0.  -0.2 -0.3 -0.6  0.7 -0.3 -0.4 -1.5 -0.1  1.3 -0.1 -0.  -0.1 -0.2 -0.  -1.6 -0.5 -0.6  1.5 -0.3 -0.2  0.4  0.2 -0.6 -0.2 -0.2 -0.2  0.3 -0.2  0.8  1.4 -0.1  1.2 -1.3  1.1 -0.4 -0.3 -1.1 -0.1 -0.  -1.4 -0.  -0.2  0.5 -0.9  0.4 -1.8 -0.3 -0.5 -0.3 -0.8 14.6  5.5  2.   4.6 -0.  -0.2  0.2 -0.2 -0.4 -0.7 -0.1  5.3 -0.1  0.1 -1.4  0.2  0.7  4.3 -0.6 -0.5 -0.9 -0.2  4.5 -0.8 -0.   1.7 -0.  -0.5  1.7 -1.   5.2  3.9 -0.1 -0.  -0.5  1.7 -0.  -0.8 -0.1 -0.7 -1.1 -1.2 -0.   3.1  2.6  9.6 -0.3  2.8 -0.3 -0.1 -3.8 -3.1 -0.1 -0.2 -0.6 -0.  -4.8  0.   2.6 -0.2 -1.4 15.5]
vy_50sample [[9 6 2 7 5 8 4 1 3 0]
 [3 8 0 4 2 1 7 5 9 6]
 [9 0 1 3 3 5 6 2 4 7]
 [4 0 2 1 3 5 5 6 7 8]
 [9 6 7 3 3 5 2 1 4 8]
 [1 7 3 4 6 8 2 5 0 9]
 [2 6 4 5 8 9 3 0 7 1]
 [7 5 9 6 8 3 3 0 2 1]
 [9 0 8 4 2 7 3 1 6 5]
 [8 6 9 7 2 0 1 5 3 4]]
vt_50sample [[9 6 2 7 5 8 4 1 3 0]
 [3 8 0 4 2 1 7 5 9 6]
 [9 0 1 8 3 5 6 2 4 7]
 [4 0 2 1 3 5 9 6 7 8]
 [9 6 7 0 3 5 2 1 4 8]
 [1 7 3 4 6 8 2 5 0 9]
 [2 6 4 5 8 9 3 0 7 1]
 [7 5 9 6 8 3 4 0 2 1]
 [9 0 8 4 2 7 3 1 6 5]
 [8 6 9 7 2 0 1 5 3 4]]
Epoch 37210: Training cost= 0.2474, Training acc= 0.8490, Validation cost= 0.2598, Validation acc= 0.8490
Epoch 37220: Training cost= 0.2239, Training acc= 0.8490, Validation cost= 0.2190, Validation acc= 0.8491
Epoch 37230: Training cost= 0.2618, Training acc= 0.8490, Validation cost= 0.2575, Validation acc= 0.8491
Epoch 37240: Training cost= 0.2337, Training acc= 0.8490, Validation cost= 0.1977, Validation acc= 0.8491
Epoch 37250: Training cost= 0.2980, Training acc= 0.8490, Validation cost= 0.2509, Validation acc= 0.8491
Epoch 37260: Training cost= 0.2765, Training acc= 0.8491, Validation cost= 0.2536, Validation acc= 0.8491
Epoch 37270: Training cost= 0.2330, Training acc= 0.8491, Validation cost= 0.2217, Validation acc= 0.8491
Epoch 37280: Training cost= 0.2234, Training acc= 0.8491, Validation cost= 0.2287, Validation acc= 0.8491
Epoch 37290: Training cost= 0.2219, Training acc= 0.8491, Validation cost= 0.2301, Validation acc= 0.8492
Epoch 37300: Training cost= 0.2464, Training acc= 0.8491, Validation cost= 0.2320, Validation acc= 0.8492
tm  [-1.2 -0.9  3.9  3.3 -1.4 -0.1  0.1 -0.2  0.9  2.3 -1.7 -0.  -0.5 -0.5  2.6 -1.3 -0.3 -0.1  1.2 -0.3 -0.9 -0.1  1.1 -0.1 -1.   1.3 -0.1 -0.  -0.8 -2.9 -0.4 -0.3 -0.4 -0.7 -0.  -0.3 -0.1  0.8  1.6 -0.2 -0.2  8.4 -0.9 -0.1 -0.6 -0.5 -0.3 -0.5 -1.7  9.8 -0.6  0.  -0.6  0.6 -0.4 -0.3 -0.6  7.9  6.2  3.9  8.2 -0.6 -0.6 -0.4  1.1 -1.1  0.3  1.5  2.  -0.4 -0.1  2.3 -0.5 -0.9 -4.6 -0.6 -0.4 -1.  -0.1 -0.3 -1.4 -0.1 -0.3 -0.3  1.3  9.1 -2.1 -0.2 -0.3 -0.1  0.3 -0.2 -0.3 -1.5 -0.6 -0.4 -0.6 -2.8 -0.3 -0.5 -0.5  6.   0.1 -0.2 -0.2 -0.3 -2.3 -0.3 -0.6 -0.5  0.3 -0.2 -0.2 -0.6  5.8 -1.5 -0.2  1.8 -0.3  1.8 -0.2 -0.1  0.1 -0.2 -0.2  2.8 -0.4  2.1  6.3 -0.7 -0.3 -0.3 -0.2 -0.2 -0.8 -1.5 -0.   0.  -0.4 -0.6  0.3 -0.6  1.1 -0.2  0.   0.  -0.4  0.4  4.6 -0.3 -0.2 -0.1 -0.8 -0.1 -0.1 -0.1 -0.1  0.9 -0.  -0.2  0.7 -1.1 -0.1 -0.1 -0.1 -0.7 -0.3  1.7 -0.1 -0.1 -0.  -0.  -0.2 -0.1 -0.3 -1.1 -0.5 -0.8  0.  -0.2 -1.8 -0.5 -0.3 -1.8 -0.1 -0.  -1.1 -0.6  0.4  8.3 -0.2 -0.3 -0.4 -0.9 -2.7 -1.7 -1.3 -1.4 -0.2 -0.2 -0.  -0.3 -0.3 -0.3 -0.3 -2.3 -0.1 -0.1 -2.9 -0.4 -0.1 -1.3 -0.6  5.7 -0.4  0.3  1.6 -0.9  0.4  0.2 -0.1 -0.3  0.8 -1.3  4.5 -0.9 -1.4  0.  -0.2 -0.3 -0.7  2.2 -0.1 -1.5 -0.1 -0.7  2.9 -1.4  1.8 -5.  -0.1 -1.8 -0.2  0.3  5.8  0.4  0.5 -0.3 -1.1 -0.2  2.9 -0.3  1.4  0.4 -0.5  5.7]
ty_50sample [[5 0 0 8 7 9 6 2 4 3]
 [1 8 5 9 4 6 2 7 7 0]
 [2 3 6 6 4 1 7 5 8 0]
 [7 6 4 5 9 1 3 2 0 0]
 [9 0 3 4 2 8 6 7 1 5]
 [3 4 5 6 0 2 7 1 8 9]
 [1 2 7 0 6 5 3 4 9 8]
 [9 3 1 8 7 7 2 0 5 4]
 [2 9 1 5 4 0 3 6 7 8]
 [0 4 2 3 7 5 9 6 8 1]]
tt_50sample [[5 1 0 8 7 9 6 2 4 3]
 [1 8 5 9 4 6 2 7 3 0]
 [2 3 9 6 4 1 7 5 8 0]
 [7 6 4 5 9 1 3 2 8 0]
 [9 0 3 4 2 8 6 7 1 5]
 [3 4 5 6 0 2 7 1 8 9]
 [1 2 7 0 6 5 3 4 9 8]
 [9 3 1 8 7 6 2 0 5 4]
 [2 9 1 5 4 0 3 6 7 8]
 [0 4 2 3 7 5 9 6 8 1]]
vm  [ 0.3 -0.2 -2.6  9.3 -0.7 -0.1 -0.4  0.2  0.2 -0.2 -0.8 -0.5 -0.1  0.1 -3.4  3.8 -0.3  0.5 -0.4 -1.2 -0.9 -0.1  1.8 -0.1 -0.7  1.9 -0.2 -0.  -0.6 -0.8 -0.2 -0.6 -0.2 -5.  -0.3 -0.1  1.2 -0.   3.  -0.8 -0.2  0.9 -0.3 -0.8 -0.2 -0.1  6.9 -0.2  6.1  9.1 -0.2  0.1  0.1 -1.2 -0.7  3.7 -0.3 -0.6  2.1  3.4 -1.7 -0.1  0.6  1.2 -0.5 -0.  -0.  -0.5 -0.5 -0.1 -0.1 -0.4  0.2 -0.1  2.2 -0.  -0.6  0.  -0.1  0.3  4.3 -0.   0.4  1.6 -1.4  2.4  4.2 -0.1 -0.1 -0.3 -0.   0.  -0.3 -1.1  0.1 -0.5  0.6 -1.4  0.1 -0.2  0.4 -0.8 -1.   0.  -0.  -0.2  1.1 -0.3 -0.3 -1.9 -0.5  0.6  0.3 -0.5  1.1  3.4 -1.1 -0.6  0.  -1.1 -0.3  6.8 -0.3 -0.2  0.1 -4.2 -0.3  5.9  0.9 -2.3  1.9 -0.6 -0.3 -0.6 14.7  3.   0.1 -0.2  0.4 -0.1 -0.6 -0.6 -1.1 -0.4 -0.   0.1 -0.  -0.2  4.7 -0.  -0.8 -0.   3.4 -0.8  0.3  0.  -0.4 -0.8 -1.1  0.2  1.9  1.9 -0.3 -0.   1.3 -0.3 -0.  -0.  -0.1 -0.1 -0.1 -0.2 -0.2 -0.1 -0.  -0.7 -1.   1.2 -0.1 -0.1 -0.6 -0.4 -0.4 -1.4 -0.3 -0.3  2.3  0.8 -0.2  2.   0.1 -0.3 -0.3 -0.4 12.5 -0.2  2.7 -0.7 -0.3  0.3 -0.5 -0.1  0.8 -0.3  0.   2.3 -0.2 -0.   6.3  0.2 -0.7  0.4 -0.7 -1.  -0.9 -0.4  3.  -0.6 -0.5 -0.  -0.2 -0.1  0.6 -1.2  4.4  1.9 -0.2  2.2 -1.   3.5 -0.1 -1.5  0.2  2.8  0.   4.2  0.7  2.6  2.7 14.6 -0.   4.6  0.3 -0.3 -0.3 -2.6 -0.3 -0.  -1.3 -0.5 -1.4 -0.   1.8  0.3 -0.8 10.2]
vy_50sample [[9 6 8 2 4 0 5 3 1 7]
 [6 5 8 9 0 7 1 4 2 3]
 [3 7 8 1 4 0 5 6 9 9]
 [5 0 7 1 4 2 9 9 8 6]
 [4 7 5 1 6 2 8 0 9 3]
 [6 1 7 8 0 4 2 9 5 3]
 [8 7 5 6 3 0 1 9 9 4]
 [5 1 9 0 2 7 4 6 3 8]
 [1 7 8 6 4 3 2 5 9 0]
 [8 9 0 1 1 4 5 3 2 6]]
vt_50sample [[9 6 8 2 4 0 5 3 1 7]
 [6 5 8 9 0 7 1 4 2 3]
 [3 7 8 1 4 0 5 6 9 2]
 [5 0 7 1 4 2 9 3 8 6]
 [4 7 5 1 6 2 8 0 9 3]
 [6 1 7 8 0 4 2 9 5 3]
 [8 7 5 6 3 0 1 9 4 2]
 [5 1 9 0 7 2 4 6 3 8]
 [1 7 8 6 4 3 2 5 9 0]
 [8 9 0 7 1 4 5 3 2 6]]
Epoch 37310: Training cost= 0.2293, Training acc= 0.8491, Validation cost= 0.2303, Validation acc= 0.8492
Epoch 37320: Training cost= 0.2426, Training acc= 0.8491, Validation cost= 0.2590, Validation acc= 0.8492
Epoch 37330: Training cost= 0.3081, Training acc= 0.8492, Validation cost= 0.2296, Validation acc= 0.8492
Epoch 37340: Training cost= 0.3143, Training acc= 0.8492, Validation cost= 0.3316, Validation acc= 0.8492
Epoch 37350: Training cost= 0.3414, Training acc= 0.8492, Validation cost= 0.3165, Validation acc= 0.8492
Epoch 37360: Training cost= 0.3310, Training acc= 0.8492, Validation cost= 0.2925, Validation acc= 0.8492
Epoch 37370: Training cost= 0.2695, Training acc= 0.8492, Validation cost= 0.2744, Validation acc= 0.8493
Epoch 37380: Training cost= 0.2754, Training acc= 0.8492, Validation cost= 0.2696, Validation acc= 0.8493
Epoch 37390: Training cost= 0.2128, Training acc= 0.8492, Validation cost= 0.2028, Validation acc= 0.8493
Epoch 37400: Training cost= 0.2763, Training acc= 0.8492, Validation cost= 0.2967, Validation acc= 0.8493
tm  [-0.8  0.8 -2.7 -0.2 -1.1 -0.2  0.5 -0.2 -1.2 -0.8  9.1 -0.3  0.1 -0.3 -1.9  0.5 -0.3 -0.5 -0.3 -1.3 -0.9 -0.4 -0.2 -0.1 -1.  -0.1 -0.3 -0.1 -0.9  0.2  5.4 -0.3 -0.3  7.8 -0.2  0.4  4.8  3.9 14.2 -0.2  1.3  6.2  2.5  6.4 -0.1 -0.3  8.6 -0.  -1.4 -1.1 -0.5 -0.  -0.2 -0.2 -1.2  1.1 -0.4 -0.  -1.5 -3.7  0.7 -0.3 -0.8 -0.7 -0.1 -0.8 -0.2 -0.1  0.8 -0.1 -0.1  1.2 -0.2 -0.8  1.2 -0.6  1.1 -0.4 -0.1 -0.3 22.6  0.1 -0.5 -0.3 -0.   5.6  3.3 -0.3 -0.3 -0.2  0.1 -0.1 -0.2  4.3 -0.7 -0.3 -0.4  0.3  0.6 -0.5  3.2  2.9  1.5 -0.2 -0.1 -0.4 -1.1  3.5 -0.1 -1.9 -0.6  0.  -0.2  0.2 -0.6 -0.4  0.3 -1.1 -0.2 -0.   0.1  6.9  0.5  0.1 -0.2 -2.  -0.3  2.5 -0.6 -2.  -0.3  0.5 -0.3 -0.2 -1.5  4.5 -0.1 -0.2  0.7 -0.8 -0.2 -0.2 -0.1  0.1 -0.2 -0.2 -0.2 -0.   5.9 -0.3 -0.3 -0.2 -1.9 -0.1 -0.4  0.1 -0.3 -0.5  0.8 -0.2 -0.2 -1.  -0.2  0.1 -0.2  0.2 -0.3 -0.3 -0.1 -0.  -0.3  0.  -0.1 -0.  -0.  -1.1 -0.  -0.5 -1.4 -0.1 -1.6 -0.4 -0.1 -1.  -0.3 -0.1 -0.8 -0.4 -0.   0.3 -0.3 -0.4 -0.5 -0.8  1.8  4.1  0.1  2.2 -0.3 -0.  -0.3 -0.2 -0.  -0.3 -0.1 -0.3  0.1 -0.3 -5.5 -0.3 -0.5 -1.  -0.5  5.7  2.1 -0.5 -2.2 -0.9 -0.3 -0.1 -0.2 -0.3 -0.3 -0.9 -0.4 -1.1  0.2 -0.8 -0.3 -0.5 -1.5 -0.1 -0.3 -2.5  1.4  5.1  0.1  0.6 -0.4 -0.1  0.2 -0.1  0.1 -0.1 -5.  -1.5  0.1 -0.6 -1.1  0.5 -5.8 -0.2  8.6 -0.4 -0.4  9. ]
ty_50sample [[4 5 9 1 2 0 7 3 6 8]
 [3 9 4 8 5 6 2 1 0 7]
 [5 6 1 4 8 3 0 9 7 2]
 [2 6 8 9 0 5 7 1 3 4]
 [6 8 3 0 4 5 1 7 9 2]
 [6 5 4 1 2 8 0 0 9 3]
 [1 6 8 9 5 0 2 3 4 7]
 [6 5 8 0 3 4 1 9 2 7]
 [6 9 5 1 0 2 7 8 4 3]
 [2 8 3 7 4 6 1 5 0 9]]
tt_50sample [[4 5 9 1 2 0 7 3 6 8]
 [3 9 4 8 2 6 5 1 0 7]
 [5 6 1 4 8 3 0 9 7 2]
 [2 6 8 9 0 5 7 3 1 4]
 [6 8 3 0 4 5 1 7 9 2]
 [6 5 4 1 2 8 0 7 9 3]
 [1 6 8 9 5 0 2 3 4 7]
 [6 5 0 8 3 4 1 9 2 7]
 [6 9 5 1 0 2 7 8 4 3]
 [2 8 7 3 4 6 1 5 0 9]]
vm  [-0.6 -0.3 -0.2 -0.7 -1.8 -0.1 -0.1 -0.1 -0.9 -0.5  3.8 -0.4 -0.2 -0.4  3.  -0.5 -0.2 -0.4 -0.2  0.3 -1.3 -0.1  1.3 -0.3 -1.4  5.3 -0.2 -0.7 -0.8  5.3  2.8 -0.2 -0.7  7.3 -0.  -0.   2.7 -1.4 -2.5 -0.3  0.7  3.3  2.9  0.1 -0.2  0.4 -0.5  0.2  3.   2.4 -0.6 -0.2  0.5  0.5 -0.4 -0.3 -0.6 -1.  -0.8 -1.7  1.1 -0.1 -0.2 -0.2 -0.1 -0.1 -0.1 -0.1  2.9  0.1 -0.2  0.7  0.8  1.6 -2.  -0.3 -0.2 -0.1  0.5  0.1  5.1  2.  -0.1  1.2 -0.4  4.3  4.7  0.1 -0.1 -0.8 -0.2 -0.1 -0.1 -0.3 -0.4  0.4 -0.1 -2.3 -0.3 -0.6  1.8  6.6 -0.4 -0.1 -0.4  0.4 -0.8  3.   1.8 -0.5 -0.8 -0.3 -0.1 -0.2 -0.   0.5 -0.3 -0.9 -0.1 -0.2  1.4  1.4  0.8  0.4 -0.2  3.9 -0.   3.  -0.7 -0.4 -0.   0.2 -0.  -0.5  6.8 14.5 -0.3  0.1 -0.2 -0.4  2.9 -1.1  2.5  0.6 -0.2 -0.1  0.2  0.  -0.8  0.   0.4 -0.1 -0.2  2.4 -0.1 -0.  -0.2 -0.3 -1.2 -0.4  1.1  3.  -0.2 -0.1 -0.2 -1.  -0.5 -0.2 -0.  -0.2 -0.1 -0.   0.  -0.2 -0.3  2.4 -0.6  0.6  3.9 -0.1 -0.4 -0.5 -0.7 -1.9 -0.2  1.3  0.9 -0.4 -0.4 -1.2 -0.1 -0.3 -0.3 -1.   1.9  2.7  0.4  0.2  1.  -0.2  0.8 -0.1 -0.8 -0.1  0.1 -1.3  0.8 -0.2 -0.8  0.  -0.5 -0.2 -1.   3.1 -1.2  0.1  1.5 -1.   0.6 -0.2  0.2 -0.2 -0.5 -0.9  6.2 -0.6 -1.5 -0.6  1.1  1.3  2.8 -0.7 -0.3 -0.5  1.5  1.2  0.6  0.7  4.4  1.6 -0.1  0.9 -0.2  0.2 -0.5 -0.9 -0.1  0.7 -1.1 -0.5 -1.4 -0.1 -1.6 -0.3  1.1  4.5]
vy_50sample [[6 4 7 0 9 1 1 2 8 3]
 [7 4 5 8 3 1 2 0 9 6]
 [2 3 4 6 8 0 7 9 1 5]
 [1 9 5 2 4 7 6 0 3 8]
 [8 4 6 7 1 2 0 3 5 9]
 [2 9 5 4 6 1 0 3 7 8]
 [7 9 3 6 1 0 8 4 2 5]
 [7 0 0 6 8 9 1 3 5 4]
 [8 5 3 1 9 9 7 2 2 6]
 [8 3 4 6 1 5 7 0 9 2]]
vt_50sample [[6 4 7 0 9 1 5 2 8 3]
 [7 4 5 8 3 1 2 0 9 6]
 [2 3 4 6 8 7 0 9 1 5]
 [1 9 2 5 4 7 6 0 3 8]
 [8 4 6 7 2 1 0 3 5 9]
 [2 9 5 4 6 1 0 3 7 8]
 [7 9 3 1 6 0 8 4 2 5]
 [7 2 0 8 6 9 1 3 5 4]
 [8 5 3 1 4 9 7 2 0 6]
 [8 3 4 6 1 5 7 0 9 2]]
Epoch 37410: Training cost= 0.2081, Training acc= 0.8493, Validation cost= 0.2260, Validation acc= 0.8493
Epoch 37420: Training cost= 0.2421, Training acc= 0.8493, Validation cost= 0.2570, Validation acc= 0.8493
Epoch 37430: Training cost= 0.2534, Training acc= 0.8493, Validation cost= 0.3474, Validation acc= 0.8493
Epoch 37440: Training cost= 0.3137, Training acc= 0.8493, Validation cost= 0.2923, Validation acc= 0.8494
Epoch 37450: Training cost= 0.2279, Training acc= 0.8493, Validation cost= 0.3223, Validation acc= 0.8494
Epoch 37460: Training cost= 0.2444, Training acc= 0.8493, Validation cost= 0.2544, Validation acc= 0.8494
Epoch 37470: Training cost= 0.2056, Training acc= 0.8493, Validation cost= 0.2198, Validation acc= 0.8494
Epoch 37480: Training cost= 0.2749, Training acc= 0.8494, Validation cost= 0.2877, Validation acc= 0.8494
Epoch 37490: Training cost= 0.2336, Training acc= 0.8494, Validation cost= 0.2869, Validation acc= 0.8494
Epoch 37500: Training cost= 0.2803, Training acc= 0.8494, Validation cost= 0.3312, Validation acc= 0.8494
tm  [-1.6  0.3 11.5  0.1 -1.6  0.3 -0.1  0.  -1.2 -1.  -0.3  0.4 -0.2 -0.1 15.5  2.8 -0.5 -0.2 -0.4  4.4 -1.  -0.2 -0.5  0.8 -0.9  0.3 -0.4 -0.6 -0.4 -0.5 -1.9 -0.1 -0.4  4.5 -0.2 -0.2  1.6  2.1 -3.1 -0.3  0.6 -2.9  1.1 -0.7 -0.1 -0.1 -3.6  0.1 -0.9 -1.1 -0.4 -0.2  0.3 12.2 -1.2 -1.8 -0.8  4.8 -0.7  6.9  9.4 -0.6 -0.3 -0.5 -1.   0.5  0.6 -0.2  1.3 -0.3 -0.2 -0.7 -0.1 -0.1 -6.5 -0.9 -0.2 -0.5 -0.2 -0.  -6.  -0.6 -0.1 -0.3 -0.  -2.6 -2.1  0.2 -0.3 -0.2 -0.1 -0.2  0.1  2.  -0.3 -0.3 -0.7 -2.9 -0.  -0.1  3.8 -0.3  1.2  0.1 -0.1  0.2 -3.1 -1.  -0.   1.6 -0.2 -0.3 -0.2 -0.8 -0.7  5.4 -0.3 -0.3 -0.1 -0.2  1.6 -1.1 -0.2  0.5 -0.  19.4 -0.1 -2.6 -0.5 16.5 -0.3 -0.3  0.2 -0.1 -2.8 -1.8 -0.1 -0.2 -0.2 -0.5 -0.4 -0.3 -0.2 -0.1 -0.   0.1 -0.3 -0.1 -1.7 -0.2 -0.7 -0.   0.6  0.3 -0.2 -0.1 -0.1 -0.1  0.8 -0.3 -0.8 -0.4 -0.1 -0.2 -0.5  0.3 -0.   1.3  0.2 -0.2 -0.1 -0.2 -0.  -0.   0.6  3.3 -0.3 -0.5  5.2 -0.2 -0.6 -0.2  0.  -1.7 -0.1 -0.4 -0.9 -0.7 -0.2  1.3 -0.2 -0.2  0.8 -1.3 -3.5  1.7 -1.2  2.7  0.  -0.   0.5 -0.1 -0.4 -0.4  0.3 -4.1 -0.5 -0.1  6.5 -0.3  0.4  1.3 -0.6  4.9 -0.4 -0.6  4.2 -0.6 -0.6 -0.  -0.2 -0.2 -0.7 -0.8 -1.5  3.2 -0.8 -0.4  1.5 -0.1 -0.4  1.  -0.3  2.3 -0.3 -2.6 -0.3 -1.9  1.3 -3.1  0.  -1.2  0.3 -0.1 18.5  7.4 -0.6  1.5 -0.8 -0.2 16.4 -0.1 -1.9 -0.1  5.5 -4.4]
ty_50sample [[3 7 1 8 2 6 5 0 4 9]
 [7 4 1 8 2 9 5 3 6 0]
 [5 0 4 2 8 1 3 7 6 9]
 [8 7 4 6 2 5 3 9 1 1]
 [5 4 3 0 6 8 9 2 7 1]
 [4 1 7 8 2 3 3 9 6 6]
 [1 3 5 4 8 6 9 7 2 0]
 [4 9 8 6 1 0 7 2 5 3]
 [9 3 4 7 8 2 0 6 5 1]
 [7 9 1 0 6 8 2 5 4 3]]
tt_50sample [[3 7 1 8 2 6 5 0 4 9]
 [7 4 1 8 2 9 5 3 0 6]
 [5 0 4 8 2 1 3 7 6 9]
 [8 7 4 2 6 5 3 9 1 0]
 [5 4 3 0 6 8 9 2 7 1]
 [4 1 7 8 2 3 5 9 0 6]
 [1 3 5 4 8 6 9 7 2 0]
 [4 8 9 6 1 0 7 2 5 3]
 [9 3 4 7 8 2 0 6 1 5]
 [7 9 1 0 6 8 2 5 4 3]]
vm  [ 1.7  0.9  6.5  6.4 -1.1 -0.  -0.2  0.1 -0.7 -0.9  8.8 -0.2 -0.2 -0.   3.9  4.7 -0.1 -0.1 -0.1 -0.6 -1.1  0.4 -0.5 -0.1 -1.1  1.9 -0.3 -0.4 -0.2 -0.4 -0.4 -0.3  0.1  5.1 -0.1 -0.   2.4  4.6 -0.  -0.5 -0.1 -2.7  1.  -0.7  0.2  0.1  0.9 -0.3  5.9 -1.7 -0.5 -0.1  0.3  8.1 -1.  -0.2 -0.6 -0.2 -0.8  3.4 -0.9 -0.1 -0.3  0.1  0.4 -0.2  0.   0.2 -0.1  0.2 -0.  -0.   1.2  0.7 -2.3 -0.2 -0.5 -0.2 -0.1 -0.2  2.  -0.3 -0.3  0.4 -1.9 -2.6  3.7 -0.  -0.1 -0.3 -0.3 -0.1  0.   1.2 -0.2 -0.2 -0.3 -1.8 -0.4 -0.2  3.  -0.4 -1.   0.1 -0.2  1.3 -1.4 -0.2  1.1 -0.9 -0.1 -0.4  0.3 -0.6 -0.6  3.1 -0.3 -0.8 -0.  -0.1 -0.2  2.6 -0.2 -0.4 -0.2  4.7 -0.2 -1.7 -0.8  6.7  2.  -0.3  0.6  0.6 -1.   3.5 -0.2 -0.1  0.5 -0.4 -1.4 -0.5 -0.7 -0.1 -0.1  0.2 -0.  -0.1 -1.7 -0.1 -0.6 -0.   3.7 -0.3 -0.1  0.3 -0.1 -0.2 -0.3 -0.4 -0.1 -0.2 -0.1 -0.1 -0.  -0.  -0.1 -0.2 -0.1 -0.1 -0.2 -0.2 -0.2 -0.1 -0.1  3.5 -0.7 -0.2  1.4 -0.1  0.  -0.2 -0.3 -1.5 -0.2 -0.3  3.1 -0.6 -0.3  1.7 -0.1 -0.1 -0.5 -0.9  8.6  3.  -0.2  0.8 -0.2 -0.1 -0.  -0.1 -0.3 -0.2 -0.1 -1.5 -0.3  0.1  5.4 -0.2 -0.2 -0.1 -0.8 -1.5 -0.3 -0.2  3.7 -1.  -0.5 -0.1 -0.1 -0.1  0.  -0.9 -0.7  1.6  2.5  0.   0.6  3.6 -0.6 -0.1 -0.1  2.5 -0.2 -1.2  0.9 -0.5  0.4  9.2 -0.   3.1  0.  -0.2  0.7 -0.7 -0.2 -0.2 -1.2 -0.4 -0.7  0.1  0.2 -0.2  0.4 -1.3]
vy_50sample [[2 3 7 6 9 8 0 4 5 1]
 [9 5 4 8 1 7 2 0 6 3]
 [5 4 1 3 8 6 0 2 7 9]
 [2 4 1 8 6 5 3 9 0 7]
 [6 9 1 5 3 4 0 7 2 8]
 [8 4 2 6 1 9 3 0 5 7]
 [5 1 4 7 0 2 3 6 6 8]
 [7 4 0 1 3 6 9 8 5 2]
 [9 3 8 6 0 5 7 1 4 2]
 [3 3 0 6 9 4 7 8 5 2]]
vt_50sample [[2 3 7 6 9 0 8 4 5 1]
 [9 5 4 8 1 7 2 0 6 3]
 [5 4 1 3 8 0 6 2 7 9]
 [2 4 1 8 6 5 3 9 0 7]
 [6 9 1 5 3 0 4 7 2 8]
 [8 4 2 6 1 9 3 0 5 7]
 [5 1 4 7 0 2 3 9 6 8]
 [7 4 0 1 3 9 6 8 5 2]
 [9 3 8 6 0 5 7 1 4 2]
 [3 1 0 6 9 4 7 8 5 2]]
Epoch 37510: Training cost= 0.2517, Training acc= 0.8494, Validation cost= 0.2874, Validation acc= 0.8494
Epoch 37520: Training cost= 0.3096, Training acc= 0.8494, Validation cost= 0.2678, Validation acc= 0.8495
Epoch 37530: Training cost= 0.3440, Training acc= 0.8494, Validation cost= 0.2489, Validation acc= 0.8495
Epoch 37540: Training cost= 0.2773, Training acc= 0.8494, Validation cost= 0.2995, Validation acc= 0.8495
Epoch 37550: Training cost= 0.2615, Training acc= 0.8494, Validation cost= 0.2366, Validation acc= 0.8495
Epoch 37560: Training cost= 0.2587, Training acc= 0.8494, Validation cost= 0.2148, Validation acc= 0.8495
Epoch 37570: Training cost= 0.2608, Training acc= 0.8495, Validation cost= 0.2986, Validation acc= 0.8495
Epoch 37580: Training cost= 0.2753, Training acc= 0.8495, Validation cost= 0.2532, Validation acc= 0.8495
Epoch 37590: Training cost= 0.2359, Training acc= 0.8495, Validation cost= 0.2597, Validation acc= 0.8495
Epoch 37600: Training cost= 0.2856, Training acc= 0.8495, Validation cost= 0.2854, Validation acc= 0.8496
tm  [-0.7 -0.2 -3.  -3.  -0.8 -0.4 -0.4  0.   0.5 -0.3 12.6 -0.1 -0.4 -0.2 -0.3  6.3 -0.4 -0.4 -0.5 -0.4 -1.5 -0.3 -0.8 -0.4 -1.1 -0.1 -0.2 -0.4  1.4 -2.9  5.1 -0.5 -0.7  2.8  0.6 -0.3 -0.5  7.   4.6 -0.4 -0.1 -0.6 -1.1  4.1 -0.3 -0.2 -1.1 -0.6  0.8 -2.7 -0.5 -0.1 -0.4 14.1 -1.8  0.7 -0.5 -1.   8.1 -2.6  3.3 -0.4 -0.7 -0.3  1.2 -0.8 -0.1  1.6 -0.2 -0.3 -0.3 -1.4 -0.2  0.6 -5.2 -0.3 -0.4 -0.3 -0.2 -0.4  5.3 -0.2 -0.5 -0.5 -1.1 -0.2  3.4 -0.1 -0.1 -0.6 -0.5 -0.1  0.  -0.9 -0.6 -0.3 -0.8 -2.9 -0.5 -0.4  1.  -1.4 -0.5 -0.1 -0.4  0.4 -2.4  2.6  0.7 -0.8 -0.2 -0.4 -0.2 -1.   1.  10.3  2.   2.1 -0.3  1.4 -0.   1.1 -0.2 -0.2 -0.2 -0.3 -0.1 -3.3  9.9  7.1 -0.2 -0.2 -0.3  0.2 -0.4  1.  -0.3 -0.2 -0.5 -0.7 -0.9  0.7 -0.7 -0.2 -0.1 -0.3 -0.1 -0.1  3.9 -0.3  1.1 -0.1 -0.5 -0.6 -0.1 -0.1  0.4 -0.2  2.  -0.5 -0.4 -1.9 -0.  -0.1  0.3 -0.1 -0.7  1.7  0.  -0.2 -0.5 -0.3 -0.3 -0.2 -0.1 -1.1  0.  -0.7 -0.3 -0.1 -1.2 -0.2 -0.4 -1.8 -0.2 -0.  -0.  -0.3 -0.2  8.1 -0.1 -0.1 -0.4 -1.3 -0.7 -3.2 -0.5 -0.2 -0.1 -0.1 -0.  -0.3 -0.1 -0.5 -0.1 -2.7  0.2 -0.5 -2.7 -0.3 -0.5  3.  -0.9 -0.1  0.  -0.  -1.8 -0.9 -0.4  0.3 -0.2 -0.1 -0.2 -1.4 -1.3  1.   1.5 -0.5  2.8  2.6 -1.1  0.3 -0.2 -1.3 -0.9  5.3 -0.  -1.1  0.2 -1.9 -0.1 -0.7 -0.2 -0.  -0.6  2.4 -0.1 -0.4 -1.4 -0.2 -1.5  0.5  3.1 -0.4 -0.8 -1.5]
ty_50sample [[2 4 3 5 1 9 7 8 0 0]
 [2 5 6 3 1 4 8 9 7 0]
 [6 9 0 1 8 3 4 5 2 7]
 [5 1 8 3 4 0 6 2 9 7]
 [8 5 7 4 3 1 6 9 2 0]
 [9 3 4 0 8 2 6 7 5 1]
 [5 9 6 8 7 3 1 0 4 2]
 [4 6 1 7 5 3 8 2 9 0]
 [7 5 3 0 6 2 9 1 8 4]
 [5 3 9 4 0 1 7 6 8 2]]
tt_50sample [[2 4 3 5 1 9 7 8 6 0]
 [2 5 6 1 3 4 8 9 7 0]
 [6 9 0 1 3 8 4 5 2 7]
 [5 1 8 3 4 0 6 2 9 7]
 [8 5 4 7 1 3 6 9 2 0]
 [9 3 4 0 8 2 6 7 5 1]
 [5 6 9 8 7 3 1 0 4 2]
 [4 6 1 7 5 3 8 2 9 0]
 [7 5 3 0 6 2 1 9 8 4]
 [3 5 9 4 0 1 7 8 6 2]]
vm  [-1.1  0.4 -1.1 -1.4 -1.7  0.5 -0.1 -0.1 -0.4 -0.6  3.4 -0.3 -0.3 -0.4  2.1  0.2  0.1 -0.5 -0.5 -0.3 -0.9 -0.2 -0.4 -0.3 -1.2  3.2 -0.1 -0.4  0.5  3.   5.  -0.6 -0.8 10.6 -0.3 -0.2  0.7 -0.6  6.6 -0.2 -0.5 -0.1 -0.1  2.1 -0.3 -0.3  3.3 -0.2 -0.9 -0.9 -0.3 -0.2  2.2 -1.5 -1.6 -0.2 -0.1 -1.8 -0.3 -3.   2.3 -0.3  1.5 -0.7  2.8 -0.5 -0.4  0.4  0.3 -0.  -0.3 -1.6 -0.  -0.3 -2.   0.8  0.1  0.8 -0.1 -0.5 12.6  0.9  0.3  0.1 -0.3  1.8  2.  -0.1  0.4 -0.6 -0.4 -0.3 -0.1 -0.3 -0.8  0.3 -0.2 -1.2 -0.3 -0.7  0.8  4.6 -0.4 -0.2 -0.3  1.  -0.4  4.6  1.6 -0.8  0.7 -0.1 -0.1 -0.4 -0.3  7.9 -0.5 -0.6  0.1 -0.1 -0.2  1.4 -0.2  0.2 -0.3  2.4 -0.2  7.7 -0.8 -1.2  0.5 -0.1 -0.5  0.5 -1.6  7.  -0.1 -0.1  1.1 -0.7  2.6 -0.9  1.  -0.1  0.1 -0.3  0.8  0.3 -0.9 -0.2  0.6 -0.1 -1.4  2.5 -0.2  0.1 -0.8 -0.3 -0.4  0.9 -0.3 -0.7  0.9 -0.1 -0.1 -0.4 -0.4  0.7 -0.1 -0.1 -0.3 -0.1 -0.3 -0.6 -0.1  2.4 -0.1  0.5 -0.6 -0.1 -0.  -0.2 -0.4 -2.3 -0.4  0.5 -0.4 -0.3 -0.2 -0.8 -0.4 -0.2 -0.2 -1.2 -0.4  3.4  0.8  0.7 -0.2 -0.2 -0.3 -0.1 -0.5 -0.1 -0.5  2.9  0.2 -0.4 -0.7 -0.4 -0.4  4.3 -0.3  7.   1.  -0.2 -1.2 -0.8 -0.3 -0.5 -0.3 -0.  -0.7 -1.2  2.2  0.1 -2.5 -0.3 -0.4 -0.5 -0.5 -0.3 -0.6 -0.2 -1.2  3.2 -0.6 -0.6  1.   9.2 -0.1  3.2 -0.2 -0.1 -2.6 -2.3 -0.5 -0.5 -0.9 -0.1 -3.5 -0.1  3.7 -0.   4.   6.3]
vy_50sample [[4 1 7 9 6 5 3 0 8 8]
 [9 6 2 1 7 4 5 0 3 8]
 [3 8 7 0 6 9 5 2 4 1]
 [9 4 6 2 7 3 8 5 1 0]
 [8 9 0 7 5 6 2 4 3 1]
 [4 8 5 0 7 3 1 6 2 9]
 [1 3 4 2 5 0 7 6 8 8]
 [0 9 2 5 1 3 6 4 8 7]
 [9 1 6 7 7 4 4 8 3 5]
 [5 6 8 7 9 3 4 2 0 0]]
vt_50sample [[4 1 7 9 6 5 3 0 2 8]
 [9 6 2 1 7 4 5 0 3 8]
 [3 8 7 0 6 9 5 2 1 4]
 [9 4 6 2 7 3 8 5 1 0]
 [8 0 9 7 5 6 2 4 3 1]
 [4 8 5 0 7 3 1 6 2 9]
 [1 3 4 2 5 0 7 6 9 8]
 [0 9 2 5 1 3 6 4 8 7]
 [9 1 6 7 0 2 4 8 3 5]
 [5 6 8 7 9 3 4 2 0 1]]
Epoch 37610: Training cost= 0.2594, Training acc= 0.8495, Validation cost= 0.2806, Validation acc= 0.8496
Epoch 37620: Training cost= 0.2703, Training acc= 0.8495, Validation cost= 0.3000, Validation acc= 0.8496
Epoch 37630: Training cost= 0.2682, Training acc= 0.8495, Validation cost= 0.2671, Validation acc= 0.8496
Epoch 37640: Training cost= 0.2765, Training acc= 0.8496, Validation cost= 0.2232, Validation acc= 0.8496
Epoch 37650: Training cost= 0.2518, Training acc= 0.8496, Validation cost= 0.2758, Validation acc= 0.8496
Epoch 37660: Training cost= 0.2615, Training acc= 0.8496, Validation cost= 0.2659, Validation acc= 0.8496
Epoch 37670: Training cost= 0.1952, Training acc= 0.8496, Validation cost= 0.2661, Validation acc= 0.8496
Epoch 37680: Training cost= 0.2210, Training acc= 0.8496, Validation cost= 0.2027, Validation acc= 0.8497
Epoch 37690: Training cost= 0.2779, Training acc= 0.8496, Validation cost= 0.2366, Validation acc= 0.8497
Epoch 37700: Training cost= 0.1919, Training acc= 0.8496, Validation cost= 0.2277, Validation acc= 0.8497
tm  [-1.2 -0.2  6.  -1.3 -1.7 -0.1  2.2 -0.3 -0.9 -1.   8.9 -0.2 -0.3  0.2 10.6 -0.4  0.8 -0.4  0.8  1.6 -1.1 -0.7 -0.9 -0.3 -1.3 -0.   0.4  0.3 -1.6 -0.9  2.7  0.1 -0.2 15.3  0.1 -0.3  2.8  3.3 -0.4 -0.3  2.4  6.   3.9  2.1 -0.2 -0.2 -1.5 -0.3 -1.4 -2.9 -0.4 -0.2 -0.7  9.7 -0.2 -1.2 -0.8  8.8 -0.4 -2.   6.1 -0.1 -0.7 -0.4 -1.3 -0.5  0.1 -0.8  1.7 -0.  -0.1  3.   0.8 -0.5 -4.5 -0.   2.3  0.3 -0.3 -0.6  8.  -0.5 -0.6 -0.5  1.1  5.3 -1.2  0.2 -0.5  0.1 -0.8 -0.2 -0.   3.3 -0.7 -0.6  2.  -2.4 -0.  -0.5  3.3  4.6  2.1 -0.2 -0.2 -0.5 -3.1 -0.  -0.2 -0.5 -0.6 -0.1 -0.2 -0.5  1.  -1.1  0.9 -0.4  0.8 -0.3 -0.2 -0.1 -0.3 -0.2 -0.1 13.1  0.3 -1.9  1.8  5.7 -0.8 -0.5 -1.  -0.3 -4.1  7.1 -0.5 -0.1 -0.5 -0.5 -0.  -0.7  0.6 -0.2 -0.2 -0.  -0.4 -0.1  4.3 -0.3  1.4 -0.2 -2.   0.5 -0.3 -0.3 -0.7 -0.4  2.1  0.9 -0.2 -1.1 -0.1 -0.1 -0.3 -0.1 -0.2 -0.5 -0.4 -0.2 -0.2 -0.3 -0.2 -0.8  0.2 -0.2  0.5 -0.9  2.2  0.  -2.  -0.1 -0.2 -1.  -0.2 -0.5 -1.3 -0.7 -0.1  2.7 -0.1 -0.4 -0.  -0.6 -2.2  0.1 -1.2 -0.2 -0.2 -0.4 -0.2 -0.1 -0.  -0.2 -0.2 -3.1 -0.3 -0.  -6.5 -0.  -0.9 -1.   0.7  6.9 -0.2 -0.1 -0.4 -0.8 -0.1 -0.6 -0.1 -0.2 -0.3 -1.4 -0.7 -1.8 -0.4 -0.5 -1.7 -0.4 -0.5  2.1 -0.5 -3.1  2.7 -1.2 -0.  -1.2  0.8 -5.  -0.2 -2.  -0.4 -0.1 -1.5  3.5 -0.6 -0.7 -0.8 -0.1 -2.4 -0.3 -0.2 -0.5  0.9 -1.1]
ty_50sample [[5 1 7 0 2 3 4 6 9 8]
 [6 8 2 9 4 0 5 1 3 7]
 [2 5 3 0 6 6 8 8 9 4]
 [3 8 9 6 0 4 5 1 7 2]
 [2 6 9 8 7 4 5 0 1 3]
 [9 0 6 3 5 1 4 8 2 7]
 [3 0 9 7 2 8 6 5 1 4]
 [7 4 3 1 5 0 9 2 6 8]
 [4 2 0 3 5 8 7 1 6 9]
 [1 8 5 2 0 9 6 7 4 3]]
tt_50sample [[5 1 7 0 2 3 4 6 9 8]
 [6 8 2 9 4 0 5 1 3 7]
 [2 3 5 0 6 1 7 8 9 4]
 [3 8 9 6 4 0 5 1 7 2]
 [2 6 9 8 7 4 5 0 1 3]
 [9 0 6 3 5 1 4 2 8 7]
 [3 0 9 7 2 8 6 5 1 4]
 [7 4 1 3 5 0 9 2 6 8]
 [4 2 0 3 5 8 7 1 6 9]
 [1 8 5 2 0 9 6 7 4 3]]
vm  [-1.2  0.3  5.3 12.6 -1.4 -0.1 -0.  -0.1 -0.4 -0.3  9.  -0.2 -0.2 -0.3 -0.2  5.  -0.1 -0.1 -0.  -1.1 -1.  -0.4  0.7 -0.4 -0.9  0.8 -0.  -0.2 -0.3 -0.3 -0.5 -0.5 -0.7  4.2 -0.  -0.1  2.2  8.1 14.8 -0.1 -0.   6.3  1.   0.6 -0.2  0.1  5.1 -0.2 -0.3  8.9 -0.5 -0.1  0.3  6.  -1.  -0.1 -0.2  6.4 -0.8  3.1  0.  -0.2 -0.4 -0.2 -0.5 -0.4  0.2  0.2 -0.5 -0.  -0.  -0.7  0.5  0.4 -1.  -0.1 -0.2 -0.4 -0.1 -0.2  8.  -0.2 -0.2 -0.4 -0.2  7.8 -1.  -0.2 -0.2 -0.3 -0.  -0.3  0.5 -0.2 -0.1 -0.1 -0.3 -0.8 -0.6 -0.1  0.9  6.3 -0.4 -0.2 -0.3  0.  -0.5 -0.4  1.2 -1.9  0.5 -0.2  0.3 -0.4 -0.7  4.3 -0.1 -1.  -0.1  0.2 -0.1  6.2 -0.1  0.5 -0.  -0.3 -0.1 -1.1 -0.5 -2.9 -0.6  0.  -0.2  0.2 -3.8 -2.7 -0.4 -0.1 -0.  -1.  -0.8 -0.3 -0.6 -0.1  0.2 -0.2  0.3 -0.2  2.6  0.  -1.  -0.1 -0.1  0.1 -0.   0.1 -0.4 -0.1  3.6 -0.3 -0.4 -1.5  0.4 -0.1 -0.2 -0.2 -0.1 -0.  -0.2 -0.2  0.4 -0.1 -0.3 -0.1 -0.  -0.2  1.4 -0.1 -1.5 -0.1 -1.6  0.  -0.  -0.9 -0.2 -0.2 -0.2 -0.6 -0.2  1.3 -0.3 -0.2 -0.5 -0.6  2.9  2.2  1.2  2.5  0.2 -0.3  0.8 -0.  -0.  -0.3 -0.2  2.  -0.2 -0.1 -1.8 -0.3 -0.   1.2 -0.2  3.8 -0.1 -0.4 -0.3 -0.8 -0.5 -0.  -0.2 -0.  -0.  -0.7  2.1  1.8  3.2  0.4  0.6 -0.3 -0.6 -0.7 -0.1 -0.8 -0.3 -1.1 -0.3  0.8  0.2  0.4 -0.2  0.1 -0.1 -0.2 -1.3 -1.8 -0.4 -0.2 -0.6 -0.2 -2.2 -0.3  8.9 -0.3 -2.3 12.7]
vy_50sample [[2 5 9 7 1 8 0 4 6 3]
 [2 1 8 9 7 6 3 4 0 5]
 [9 5 0 1 7 2 4 3 6 8]
 [5 4 1 7 8 6 3 0 9 2]
 [7 5 4 2 3 1 9 8 6 0]
 [5 7 2 3 1 9 4 8 6 0]
 [0 1 4 5 9 6 2 3 7 8]
 [6 1 4 8 7 5 9 2 3 0]
 [4 3 9 5 0 1 7 2 8 6]
 [4 1 8 7 6 2 9 0 5 3]]
vt_50sample [[2 5 9 7 1 8 0 4 6 3]
 [2 1 8 9 7 6 3 4 0 5]
 [9 5 0 1 7 2 4 3 6 8]
 [5 4 1 7 8 6 3 0 9 2]
 [7 5 4 2 3 1 9 8 6 0]
 [5 7 2 3 1 9 4 8 6 0]
 [0 1 4 5 9 6 2 3 7 8]
 [6 1 4 8 7 5 2 3 9 0]
 [4 3 9 5 0 1 7 2 8 6]
 [4 1 8 7 6 2 9 0 3 5]]
Epoch 37710: Training cost= 0.2888, Training acc= 0.8497, Validation cost= 0.2656, Validation acc= 0.8497
Epoch 37720: Training cost= 0.3589, Training acc= 0.8497, Validation cost= 0.2758, Validation acc= 0.8497
Epoch 37730: Training cost= 0.2996, Training acc= 0.8497, Validation cost= 0.2735, Validation acc= 0.8497
Epoch 37740: Training cost= 0.2665, Training acc= 0.8497, Validation cost= 0.2684, Validation acc= 0.8497
Epoch 37750: Training cost= 0.3031, Training acc= 0.8497, Validation cost= 0.2379, Validation acc= 0.8497
Epoch 37760: Training cost= 0.2509, Training acc= 0.8497, Validation cost= 0.2110, Validation acc= 0.8498
Epoch 37770: Training cost= 0.2781, Training acc= 0.8497, Validation cost= 0.2673, Validation acc= 0.8498
Epoch 37780: Training cost= 0.2919, Training acc= 0.8497, Validation cost= 0.2465, Validation acc= 0.8498
Epoch 37790: Training cost= 0.2225, Training acc= 0.8497, Validation cost= 0.2518, Validation acc= 0.8498
Epoch 37800: Training cost= 0.2509, Training acc= 0.8498, Validation cost= 0.3075, Validation acc= 0.8498
tm  [-0.1 -0.   2.8 -1.1 -1.2 -0.1 -0.4 -0.  -0.6 -0.8  9.5 -0.6 -0.   0.4  5.6  7.1 -0.4 -0.3  1.5 -1.5 -0.8 -0.2  1.7 -0.5 -1.1 -0.7 -0.4  0.7  2.4  4.2  3.5  0.2  0.1  9.7  0.1 -0.1  1.1  3.5 -0.4 -0.4 -0.   3.   0.1  0.7 -0.4  0.2  3.2 -0.3  2.1  5.8 -0.5  0.3 -0.6  8.2 -1.4 -0.5 -0.7 -0.8 -0.5 -1.6 -1.  -0.3 -0.7  0.4  0.5 -0.4 -0.2 -0.4  0.4 -0.4 -0.1 -1.8 -0.3  0.2 -1.9 -0.4 -0.4 -0.4 -0.3 -0.4  7.2 -0.8 -0.6 -0.4 -1.2  4.   4.9  0.  -0.5 -0.2 -0.5 -0.2 -0.2 -0.3 -0.1  0.3 -0.3 -1.7 -0.2  1.   3.3  6.8 -0.4 -0.1 -0.  -0.1 -1.7  1.2  0.2 -1.7 -0.7 -0.2 -0.1 -0.9 -0.7 12.2  0.1 -0.6 -0.2  0.  -0.4  5.6 -0.3 -0.5 -0.2  7.   0.2 -1.8 -0.3 -1.9 -0.1 -0.3 -0.1 -0.1 -1.5  8.4 -0.4 -0.1 -0.5 -0.5 -1.3  0.4 -0.7  0.2 -0.1 -0.2 -0.5  0.7 -1.2 -0.1  0.8 -0.   2.  -0.9 -0.2 -0.3 -0.1 -0.3 -0.6 -0.3 -0.7 -0.4 -0.2 -0.1 -0.4  0.6 -0.2  0.3 -0.4 -0.2 -0.2 -0.4 -0.2 -0.3 -0.2  2.3 -1.2 -0.1  1.6 -0.1 -1.4  1.4 -0.2 -1.2  0.8 -0.1  1.  -0.9  0.3 -1.1 -0.3 -0.3 -0.2 -0.8  8.   0.4 -0.4  1.7 -0.2 -0.1 -0.4 -0.2 -0.5 -0.5 -0.3 -1.9  0.2 -0.1 -0.9 -0.1  0.4  3.  -0.3 -1.2 -0.  -0.6 -0.4 -0.8 -0.3  0.4 -0.1  0.2 -0.4 -1.5  2.8  3.6  3.4  0.6 -0.9  3.2 -1.   0.9 -0.2 -0.4 -0.8 -0.1 -0.2 -0.4  1.   1.2 -0.1  0.2 -0.4 -0.  -1.1 -0.1 -0.3 -0.1 -1.1  0.4 -2.   0.  -0.2 -0.5 -2.2  9.1]
ty_50sample [[2 7 4 6 5 9 8 1 3 0]
 [9 4 7 2 3 6 0 1 5 8]
 [6 0 3 7 9 4 5 1 2 8]
 [1 8 4 9 6 9 2 7 3 5]
 [8 5 1 9 3 2 6 7 4 0]
 [5 0 9 7 2 1 4 3 8 6]
 [4 5 0 8 2 7 6 1 9 3]
 [1 0 7 9 9 2 4 5 8 3]
 [2 9 0 3 1 5 6 8 4 7]
 [1 7 8 2 6 3 3 4 0 0]]
tt_50sample [[2 7 4 6 5 9 8 1 3 0]
 [9 4 7 2 3 6 0 1 5 8]
 [6 0 3 7 9 4 5 1 2 8]
 [1 8 4 9 6 0 2 7 3 5]
 [8 5 1 9 3 2 6 7 4 0]
 [5 0 9 7 2 1 4 3 8 6]
 [5 4 0 8 2 7 6 1 9 3]
 [1 0 7 6 9 2 4 5 8 3]
 [2 9 0 3 1 5 6 8 4 7]
 [1 7 8 2 6 3 5 4 9 0]]
vm  [-1.  -0.  -2.8 -3.3 -1.2  0.1 -0.4 -0.1 -0.8 -1.1 -1.2 -0.4  0.1 -0.1  0.6  2.2 -0.1 -0.7 -0.6  0.4 -0.9 -0.2  1.4 -0.3 -1.6  1.  -0.3 -0.   0.9  2.   1.8 -0.  -0.7 -2.7 -0.1 -0.1  1.3 -1.  -2.7 -0.2  0.9  4.7  2.4  1.8  0.4  0.9 -1.8 -0.  -0.   4.7 -0.5 -0.1 -0.3  4.4 -1.  -0.2 -1.   2.3 -0.4 -0.3  4.8 -0.2 -0.5 -0.2 -0.6  1.4 -0.2 -0.2  0.8  0.2 -0.  -1.9 -0.5  0.7 -4.2 -0.3 -0.1  0.5 -0.2 -0.  -2.9  0.2 -0.   0.5 -0.   5.9  2.8 -0.2 -0.1 -0.4 -0.3 -0.2 -0.2  1.1 -0.5  0.5 -0.1 -2.6 -0.2  0.3  3.8 -0.5 -0.1  0.  -0.3  1.  -2.1  1.4 -0.2 -0.5 -0.4 -0.2 -0.1 -0.9 -0.9 13.7 -0.3 -0.6  0.2 -0.4 -0.2  0.6 -0.3 -0.1 -0.   1.8  0.2 -0.4  1.5  5.1 -0.1 -0.5 -0.6 -0.2  9.3  4.  -0.3 -0.  -0.7 -0.4  2.3 -0.2  0.7  0.1 -0.1 -0.4 -0.2 -0.1  7.8 -0.1  2.5 -0.2  1.3  0.6 -0.4 -0.2 -0.5 -0.2 -0.6 -0.6 -0.5  1.2 -0.3 -0.   0.1 -0.2 -0.4 -0.5  0.6 -0.1 -0.2 -0.1 -0.  -0.3  0.3 -1.4 -1.  -0.4  4.6 -0.2 -2.2  1.6 -0.6 -2.1 -0.3  0.3 -0.5 -0.2 -0.1 -0.4 -0.1 -0.2  0.4 -1.  -1.4 -0.7 -0.6  2.3  0.  -0.1  0.5 -0.1 -0.5 -0.2  0.5 -3.  -0.4 -0.3 -1.6  0.9 -0.4  3.6 -0.3  3.  -0.8 -0.2 -0.5 -0.7 -0.3 -0.7 -0.2 -0.  -0.3 -1.   2.1  5.5 -1.5 -0.7 -0.3  0.9 -0.4  0.7 -0.5 -1.  -0.4  3.8 -0.4 -0.9  2.9 -4.7 -0.1 -1.6 -0.1 -0.1 10.7  4.4 -0.1 -0.2 -0.9 -0.5  8.2 -0.1 -1.7 -0.3  3.1 -0.7]
vy_50sample [[5 4 6 1 1 3 2 9 9 0]
 [3 3 5 6 0 2 8 4 7 1]
 [6 8 1 2 7 9 3 5 0 4]
 [9 7 6 3 1 2 4 0 5 8]
 [4 7 2 3 8 0 6 1 9 5]
 [2 4 4 0 7 3 8 6 1 5]
 [7 7 2 2 3 1 6 8 5 0]
 [9 1 7 2 3 0 6 5 4 8]
 [9 4 7 2 5 1 0 8 6 3]
 [2 4 5 8 7 9 3 0 6 1]]
vt_50sample [[5 4 6 1 8 3 2 7 9 0]
 [3 9 5 6 0 2 8 4 7 1]
 [6 8 1 2 7 9 3 5 0 4]
 [9 7 6 3 1 2 4 0 5 8]
 [4 2 7 3 8 0 6 1 9 5]
 [2 9 4 0 7 3 8 6 1 5]
 [7 9 4 2 3 1 6 8 5 0]
 [9 1 7 2 3 6 0 5 4 8]
 [9 4 7 2 5 1 0 8 3 6]
 [2 4 5 8 7 9 3 0 6 1]]
Epoch 37810: Training cost= 0.2564, Training acc= 0.8498, Validation cost= 0.2677, Validation acc= 0.8498
Epoch 37820: Training cost= 0.2479, Training acc= 0.8498, Validation cost= 0.2401, Validation acc= 0.8498
Epoch 37830: Training cost= 0.2504, Training acc= 0.8498, Validation cost= 0.2404, Validation acc= 0.8498
Epoch 37840: Training cost= 0.2412, Training acc= 0.8498, Validation cost= 0.2364, Validation acc= 0.8499
Epoch 37850: Training cost= 0.2522, Training acc= 0.8498, Validation cost= 0.3175, Validation acc= 0.8499
Epoch 37860: Training cost= 0.2823, Training acc= 0.8498, Validation cost= 0.2695, Validation acc= 0.8499
Epoch 37870: Training cost= 0.2583, Training acc= 0.8499, Validation cost= 0.2641, Validation acc= 0.8499
Epoch 37880: Training cost= 0.2477, Training acc= 0.8499, Validation cost= 0.2909, Validation acc= 0.8499
Epoch 37890: Training cost= 0.2724, Training acc= 0.8499, Validation cost= 0.2435, Validation acc= 0.8499
Epoch 37900: Training cost= 0.2196, Training acc= 0.8499, Validation cost= 0.2203, Validation acc= 0.8499
tm  [-1.5  0.1 -2.6 -0.4 -1.5 -0.  -0.2 -0.1 -0.4 -0.4  1.7 -0.2 -0.3  0.2 -1.2  2.8 -0.3 -0.1 -0.4 -0.2 -1.2 -0.1  1.8 -0.3 -1.3  2.9 -0.2 -0.4 -0.8 -0.6  1.5 -0.4 -0.4 -2.1 -0.1  0.2  3.4  4.1  6.5 -0.4  1.4 -0.7 -0.3  2.8 -0.3  0.5  2.8 -0.5 -1.7  7.7 -0.5 -0.2  0.   0.9 -1.   1.2 -0.4 -2.8 -0.  -0.3  4.1  0.1  0.9 -0.2 -0.2 -0.1 -0.1 -0.2 -0.5 -0.   0.3 -0.   1.1  0.4 -0.9 -0.3  0.9 -0.5 -0.  -0.3  1.8 -0.1 -0.   0.1  2.4 -0.3 -0.5 -0.1 -0.2 -0.2 -0.1 -0.1  0.2 -0.5 -0.5 -0.2 -0.6 -1.4  0.4  0.2  1.4  1.2  0.6  0.  -0.4  0.  -0.5  1.9  0.4 -0.8 -0.3 -0.2 -0.1 -0.3  1.1  2.  -0.5 -1.3 -0.2 -0.2 -0.2  3.1 -0.1 -0.2 -0.1 -1.5  0.3  1.9 -0.8 -1.4 -0.7 -0.1  0.  -0.3  3.8 -1.6 -0.3 -0.1  0.5 -0.3 -0.2 -0.9 -0.6  0.  -0.2 -0.1 -0.3 -0.2 -0.3 -0.2 -0.1 -0.  -0.5 -0.2 -0.  -0.  -0.4 -0.1  1.4 -0.1  1.  -0.6 -0.2  0.3 -0.1 -0.5 -0.2  1.2  0.1 -0.1 -0.2 -0.3  0.2 -0.  -0.2  1.2 -0.1  0.1 -0.5 -0.1  2.2 -0.  -0.3 -1.8 -0.  -0.5 -1.  -0.2 -0.3  2.6 -0.1 -0.3 -0.3 -1.1 -1.   3.2  0.7 -0.3 -0.1 -0.2  0.4  0.1 -0.3 -0.5 -0.1 -0.1 -0.   0.2  8.5 -0.1 -0.5 -0.2 -0.7 10.8 -0.3 -0.1 -1.1 -1.  -0.5 -0.1 -0.1 -0.2  0.2 -0.8  2.7  2.  -0.3  0.7 -0.5 -1.  -0.3 -0.5 -0.1  3.8  0.2  5.2  0.2  0.2  1.4 14.7  0.3  5.  -0.2  0.1  0.7 -1.6 -0.4  1.  -1.3 -0.6 -0.8 -0.1  4.2 -0.2 -0.8  6.8]
ty_50sample [[1 4 9 8 2 0 6 7 3 5]
 [5 1 6 2 2 3 0 4 9 7]
 [3 8 1 6 0 2 2 9 5 7]
 [8 3 7 1 2 4 0 9 6 5]
 [3 9 8 4 6 7 2 1 0 5]
 [4 5 9 0 2 7 6 3 8 1]
 [9 4 4 3 5 6 8 2 7 1]
 [5 1 3 9 6 0 2 8 4 7]
 [6 7 4 5 1 3 9 0 8 2]
 [1 2 5 8 0 7 3 6 4 9]]
tt_50sample [[1 4 9 8 2 0 6 7 3 5]
 [5 1 6 2 8 3 0 4 9 7]
 [3 8 1 6 0 2 9 4 5 7]
 [8 3 7 1 2 4 0 9 6 5]
 [3 9 8 4 6 7 2 1 0 5]
 [4 5 9 0 2 7 6 3 8 1]
 [9 0 4 3 5 6 8 2 7 1]
 [5 1 3 9 6 0 8 2 4 7]
 [6 7 4 1 5 3 9 0 8 2]
 [1 2 5 8 0 7 3 6 9 4]]
vm  [-1.6 -0.6 -0.   9.2 -0.5 -0.4 -0.2  0.4  0.6  0.2 -0.2 -0.5 -0.1 -0.1 -1.5  3.3 -0.4 -0.5 -0.2 -1.1 -1.  -0.2  1.2 -0.6 -0.4 -0.4 -0.5 -0.3 -0.4 -1.6 -2.  -0.3 -0.1 -5.6  0.2 -0.4  0.6 -0.8 -3.3 -0.8  1.2 -2.1 -1.2 -1.6 -0.3 -0.3  2.7 -0.2 -1.9  6.3 -0.7 -0.3 -0.9  6.3 -1.3  1.5 -0.8 -0.5  5.1  6.8  6.4 -0.1 -0.9 -0.6 -0.7  0.8 -0.4  0.1  0.6 -0.2 -0.1 -1.   0.3 -0.3 -3.4 -0.2  0.4  2.  -0.1 -0.2 -3.2  0.2 -0.3  2.4  3.1 -2.2 -2.3 -0.1 -0.3 -0.8 -0.5 -0.2 -0.4 -0.4 -0.6 -0.1 -0.4 -2.4 -0.7 -0.5  0.1 -1.4  0.6 -0.3 -0.3 -0.3 -2.1 -1.1  0.1 -1.7 -0.2 -0.4 -0.2 -0.7  1.9  4.4  0.3 -0.2 -0.4 -0.5 -0.1  4.5 -0.5 -0.1 -0.3 -1.9 -0.3 -1.1  1.7  3.3 -0.6 -0.7 -0.5 -0.3 16.8  5.4 -0.2 -0.1 -0.5 -0.8 -0.9 -0.  -0.4 -0.3 -0.1 -0.2 -0.1 -0.2  0.3 -0.3 -0.9 -0.  -0.2 -0.5 -0.2 -0.2 -0.1 -1.1 -1.7 -0.5 -0.6  2.4 -0.2 -0.1 -0.2 -0.1 -0.4  1.4 -0.1  0.3 -0.1 -0.3 -0.2 -0.4 -0.1  1.1 -1.5 -0.8  4.6 -0.2  1.5 -0.2 -0.3 -1.1  0.1  2.2 -0.9 -0.  -0.4  4.9 -0.2 -0.2 -0.7 -0.8 -2.1 -0.9 -1.  -0.4 -0.2 -0.2 -0.   0.  -0.5 -0.1  0.  -2.5 -0.4 -0.2 11.8 -0.2 -1.3  0.1 -0.8  4.8 -0.4 -0.3  7.4 -0.7 -0.4 -0.1 -0.2 -0.2 -0.4 -0.5  3.3  3.3 -0.2 -0.8 -0.1 -0.2  0.2  2.7 -0.2  3.3 -0.6 -0.1  0.1 -1.3  0.6 11.8 -0.1  4.  -0.2  0.3 11.   0.4  2.5 -0.  -1.  -0.1  8.2 -0.  -2.  -0.2 -0.3 -0.3]
vy_50sample [[6 1 8 2 3 9 0 4 7 5]
 [6 3 4 1 5 0 7 9 2 8]
 [4 0 5 1 2 8 6 3 9 7]
 [3 1 4 2 9 9 5 8 7 0]
 [2 9 6 5 8 4 3 1 0 7]
 [8 4 9 1 3 7 6 5 2 0]
 [7 8 0 1 4 5 3 9 2 6]
 [4 0 8 1 3 6 9 7 5 2]
 [2 4 6 0 7 5 3 3 8 1]
 [5 7 9 4 9 2 0 8 3 1]]
vt_50sample [[6 1 8 2 3 9 0 4 5 7]
 [6 3 4 1 5 0 7 2 9 8]
 [4 0 5 1 2 8 6 3 9 7]
 [3 1 4 2 9 6 5 8 0 7]
 [2 9 6 5 8 4 3 1 0 7]
 [8 4 9 1 7 3 6 5 2 0]
 [7 8 0 1 4 5 3 9 2 6]
 [4 0 8 1 3 6 9 7 5 2]
 [2 4 6 0 7 9 5 3 8 1]
 [5 7 9 6 4 2 0 8 3 1]]
Epoch 37910: Training cost= 0.2640, Training acc= 0.8499, Validation cost= 0.2155, Validation acc= 0.8500
Epoch 37920: Training cost= 0.2576, Training acc= 0.8499, Validation cost= 0.2450, Validation acc= 0.8500
Epoch 37930: Training cost= 0.3157, Training acc= 0.8499, Validation cost= 0.3388, Validation acc= 0.8500
Epoch 37940: Training cost= 0.2533, Training acc= 0.8499, Validation cost= 0.2761, Validation acc= 0.8500
Epoch 37950: Training cost= 0.3075, Training acc= 0.8500, Validation cost= 0.3185, Validation acc= 0.8500
Epoch 37960: Training cost= 0.2591, Training acc= 0.8500, Validation cost= 0.3038, Validation acc= 0.8500
Epoch 37970: Training cost= 0.2184, Training acc= 0.8500, Validation cost= 0.2876, Validation acc= 0.8500
Epoch 37980: Training cost= 0.2595, Training acc= 0.8500, Validation cost= 0.2481, Validation acc= 0.8500
Epoch 37990: Training cost= 0.2621, Training acc= 0.8500, Validation cost= 0.2729, Validation acc= 0.8501
Epoch 38000: Training cost= 0.2289, Training acc= 0.8500, Validation cost= 0.2843, Validation acc= 0.8501
tm  [-1.9 -0.3 -3.1 -2.5 -1.1  0.4 -0.1 -0.1  0.8 -0.3 -2.2 -0.4 -0.1  0.1 -0.   1.6 -0.2 -0.3 -0.8  2.7 -1.4 -0.1  1.9 -0.1 -1.2  1.3 -0.4 -0.4 -0.4 -3.2 -0.3 -0.4 -0.4 -5.  -0.1 -0.1 -0.3  3.3  1.3 -0.4  1.6 -0.9 -1.   3.2 -0.1  0.3 -2.2 -0.1 -1.2  5.3 -0.5 -0.1 -0.2  6.5 -1.  -0.1 -0.7 -0.5  8.   3.2  8.7 -0.4  0.2  0.3 -0.8 -0.3  0.2 -0.4  0.3 -0.2 -0.2 -1.3 -0.   1.2 -5.2 -0.6 -0.3 -0.3 -0.1 -0.5 -4.7  0.6 -0.1 -0.1  1.3 -0.4 -0.9 -0.3  0.1 -0.3 -0.1 -0.  -0.  -1.  -0.6 -0.2 -0.5 -3.3  0.1  1.   1.6 -2.1  2.4 -0.1 -0.4 -0.6 -2.1 -0.3 -0.9  0.1 -0.3  0.1 -0.2 -1.2  3.5  8.3 -0.3  0.7 -0.  -0.6 -0.2 -0.7  0.1 -0.1 -0.3  0.2 -0.  -0.8  9.5  7.2 -0.5 -0.6 -0.2 -0.2  4.1 -4.6  0.1 -0.2 -0.1 -0.3  2.4 -0.5 -0.5  0.1  0.4 -0.2  0.4  0.4  5.9 -0.1  1.  -0.1  0.4  0.3 -0.2  0.2 -0.4 -0.4  3.9  0.1 -0.5 -1.3 -0.3  0.  -0.1  0.3  0.2  1.8  0.4 -0.1  0.3  0.  -0.1  1.1 -0.  -0.9  1.  -0.5  0.5 -0.2 -0.6 -0.1 -0.7 -1.6 -0.2 -0.3 -0.9  0.1 -0.4  9.4 -0.1 -0.3 -0.3 -0.9 -3.3 -3.  -0.8 -0.5  0.3  0.3  0.6 -0.1 -0.3 -0.6 -0.1 -2.9 -0.1 -0.   5.   0.1 -0.5  3.3 -0.4  7.6 -0.6 -0.5 -1.5 -1.  -0.9 -0.2 -0.2 -0.1  0.8 -1.2 -1.6  3.3 -1.3  0.3 -0.9 -0.  -0.3 -0.2 -0.2  2.2 -0.2  5.1 -0.1 -1.1  4.1 -2.5 -0.  -0.9  0.2 -0.2 15.4  3.5 -0.3 -0.1 -1.3 -0.  12.2  0.2  0.8 -0.2  4.  -1.4]
ty_50sample [[1 8 4 3 5 2 0 6 9 7]
 [1 2 3 0 8 5 4 9 9 6]
 [2 4 3 7 6 1 8 5 9 9]
 [5 9 6 0 0 8 3 2 1 4]
 [1 6 2 8 0 7 9 5 3 4]
 [1 1 0 7 6 5 2 4 9 3]
 [2 8 9 7 5 4 0 6 3 1]
 [2 8 3 6 0 7 5 4 9 1]
 [6 1 7 5 9 2 4 8 3 0]
 [9 0 8 4 6 3 7 5 1 2]]
tt_50sample [[1 8 4 3 5 2 0 6 9 7]
 [1 2 3 0 8 5 4 9 7 6]
 [2 4 3 7 6 1 8 5 9 0]
 [5 9 6 7 0 8 3 2 1 4]
 [1 6 2 8 0 7 9 5 3 4]
 [8 1 0 7 6 5 2 4 9 3]
 [2 8 9 7 5 4 6 0 3 1]
 [2 8 3 6 0 7 5 4 9 1]
 [6 1 7 5 9 2 4 8 3 0]
 [9 0 8 4 6 3 7 5 1 2]]
vm  [-0.8 -0.1 -0.6  5.7 -1.9 -0.5 -0.3 -0.2  0.4 -0.6 -2.5  0.3 -0.5  0.8 -1.  -0.4 -0.5 -0.2 -0.4 -0.2 -0.8  0.1 -0.   0.7 -1.2  0.8 -0.1 -0.5  1.7 -2.1  1.4  0.4  0.  -0.2  0.2 -0.4 -0.8 -0.4  6.6  0.2  3.2  3.4  1.   2.4 -0.2  0.6  1.4 -0.4  4.  -0.3 -0.5 -0.2  2.  -2.  -1.8  1.5 -0.3  4.9  2.7  0.8 -0.5 -1.1  0.5 -0.4  0.7 -1.3 -0.4  1.6  1.4 -0.2  0.8 -2.   0.5  2.1 -3.2 -1.5 -0.6 -1.  -0.2 -0.6  6.3 -0.2 -0.1 -1.  -1.8  2.4  2.9 -0.2 -0.1 -0.6  1.8 -0.2 -0.1 -0.9 -0.5 -0.1 -1.3 -2.3 -0.4 -0.1  0.5 -0.9 -0.6 -0.2 -0.3 -0.  -0.5  0.8 -0.9 -1.  -0.1 -0.5 -0.3 -0.9  0.3 11.7  1.6  0.7 -0.4  2.  -0.4  1.5 -0.3  0.  -0.4 -1.2 -0.4  9.8  8.  -0.2 -0.1 -0.3 -0.5  0.9 -0.1 -0.5 -0.  -0.1 -0.4 -0.8  4.1 -0.2  0.8  0.2  0.  -0.4 -0.5  0.2  6.1 -0.1 -0.6 -0.1  2.5  1.4 -0.  -0.4 -0.3  1.6  3.4 -0.2 -0.9 -1.7 -0.3 -0.  -0.4 -0.4 -0.  -0.1  1.3  1.1 -0.3 -0.1  0.3 -0.2 -0.4 -1.3 -1.1  0.  -0.4 -0.2 -1.8  0.2 -0.5 -2.3 -0.3 -0.1  1.8 -0.6 -0.1  5.2 -0.2 -0.1 -0.2 -1.5  6.  -2.3  1.5 -0.2  0.4 -0.1 -0.2 -0.1 -0.8 -0.5 -0.2  1.5 -0.6 -0.2 -3.5  0.1 -0.3  6.4 -1.  -0.1 -0.8 -0.8 -0.9 -0.7 -0.4  1.  -0.2  0.7  1.5 -1.5 -1.3  4.2 -3.3 -0.6 -0.2  2.1 -0.2 -0.7 -0.2 -1.6 -1.4  1.1 -0.2  0.1  3.1 -2.5 -0.3 -1.2  0.2  0.2 -0.8 -1.9 -0.7 -0.2 -1.5  1.1 -2.   0.1  4.4 -0.5  9.1  3.3]
vy_50sample [[5 9 3 8 4 1 7 6 0 2]
 [8 9 7 2 4 5 0 1 6 3]
 [7 7 6 0 1 2 8 5 4 3]
 [5 1 7 4 2 3 9 9 8 8]
 [5 8 4 6 3 3 2 9 1 1]
 [7 9 3 5 6 8 1 4 2 0]
 [8 6 4 9 3 7 1 5 0 2]
 [5 0 0 3 3 4 2 1 8 6]
 [4 0 1 7 6 2 5 3 8 9]
 [0 8 4 5 7 1 2 3 9 6]]
vt_50sample [[5 9 3 4 8 7 1 6 0 2]
 [8 9 7 2 4 0 5 1 6 3]
 [7 6 9 0 1 2 8 5 4 3]
 [5 1 7 4 2 3 9 6 0 8]
 [5 4 8 6 3 7 2 0 1 9]
 [7 9 3 5 6 8 1 4 2 0]
 [8 4 6 9 3 1 7 5 0 2]
 [5 7 9 0 3 4 2 1 8 6]
 [4 0 1 7 6 2 5 3 8 9]
 [0 8 4 5 7 1 2 3 9 6]]
Epoch 38010: Training cost= 0.2190, Training acc= 0.8500, Validation cost= 0.2289, Validation acc= 0.8501
Epoch 38020: Training cost= 0.2610, Training acc= 0.8500, Validation cost= 0.2253, Validation acc= 0.8501
Epoch 38030: Training cost= 0.2681, Training acc= 0.8501, Validation cost= 0.2970, Validation acc= 0.8501
Epoch 38040: Training cost= 0.2349, Training acc= 0.8501, Validation cost= 0.1997, Validation acc= 0.8501
Epoch 38050: Training cost= 0.2670, Training acc= 0.8501, Validation cost= 0.2707, Validation acc= 0.8501
Epoch 38060: Training cost= 0.2543, Training acc= 0.8501, Validation cost= 0.2315, Validation acc= 0.8502
Epoch 38070: Training cost= 0.3113, Training acc= 0.8501, Validation cost= 0.2894, Validation acc= 0.8502
Epoch 38080: Training cost= 0.2112, Training acc= 0.8501, Validation cost= 0.2421, Validation acc= 0.8502
Epoch 38090: Training cost= 0.2336, Training acc= 0.8501, Validation cost= 0.2431, Validation acc= 0.8502
Epoch 38100: Training cost= 0.2827, Training acc= 0.8501, Validation cost= 0.2620, Validation acc= 0.8502
tm  [-0.2  0.6  3.8  2.9 -1.4 -0.2 -0.2  0.  -1.  -1.4  6.3 -0.2 -0.2 -0.   2.2  5.9 -0.1 -0.4  0.  -0.9 -1.   0.  -0.5 -0.2 -1.2  1.1 -0.2 -0.2  0.6  0.5  1.2 -0.2 -0.6  5.3 -0.1 -0.2  2.8  5.5 11.1 -0.4  0.6 -2.3  1.2  2.2  0.1 -0.1  3.6 -0.7  2.6 -2.1 -0.5 -0.   0.3  3.2 -1.  -0.1 -0.5 -0.2 -1.  -0.  -1.1 -0.1 -0.5  0.1 -0.4  0.2 -0.2 -0.1  0.2 -0.2 -0.1 -1.6 -0.1  0.1 -0.6  0.9 -0.4 -0.2 -0.3 -0.2  5.  -0.4 -0.3  0.9 -1.  -1.7  3.4 -0.2 -0.2 -0.3 -0.3 -0.   0.1  1.  -0.3 -0.2  0.2 -1.5 -0.5 -0.1  5.5 -0.4 -0.7  0.1 -0.2 -0.2 -0.8  1.2  1.8 -1.1 -0.3 -0.4 -0.1 -0.5 -1.3 12.   0.3 -1.2 -0.1 -0.4 -0.2  4.3 -0.2 -0.4  0.   2.8 -0.1 -0.2 -0.4  5.4 -0.1 -0.4 -0.1 -0.6 -3.9 -2.  -0.3 -0.1 -0.1 -0.2 -0.6 -0.2 -0.4 -0.1 -0.  -0.2 -0.3 -0.1 -0.8 -0.1 -0.4 -0.1  2.1 -0.4 -0.1 -0.  -0.2 -0.1  2.5 -0.1 -0.4 -1.4 -0.2  0.2 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.2 -0.  -0.1 -0.1  2.3  0.6 -0.5 -1.  -0.1 -0.7  0.6 -0.5 -1.7 -0.1 -0.2  1.5 -0.7 -0.1 -0.  -0.1  0.2 -0.4 -1.   8.4  1.5  0.2  3.3 -0.  -0.1 -0.1 -0.1 -0.4 -0.5 -0.2 -0.6 -0.1  0.1  2.5 -0.1 -0.2  3.4 -0.5 -0.6 -0.4 -0.2 -1.  -0.7 -0.2 -0.2 -0.1 -0.2 -0.2 -0.8 -2.   4.8  0.3 -0.2  0.6  2.3 -0.6 -0.5 -0.2  1.6 -0.6 -0.4 -0.1  0.1  0.8  7.5 -0.1  2.4 -0.1 -0.1 -0.4 -1.1  0.3 -0.1 -0.9 -0.5 -1.4 -0.1  7.1 -0.2  2.4 -0.9]
ty_50sample [[3 2 7 9 4 8 5 1 6 0]
 [7 4 6 5 1 8 9 3 2 0]
 [8 0 7 9 5 4 3 2 6 1]
 [2 3 4 9 0 8 1 6 6 5]
 [2 1 5 8 6 7 4 0 0 3]
 [0 7 4 5 6 3 2 2 8 1]
 [0 1 4 3 7 6 8 5 5 9]
 [5 8 3 4 9 2 6 0 1 7]
 [9 0 4 6 8 7 1 5 2 2]
 [1 0 4 3 9 2 7 6 8 5]]
tt_50sample [[3 7 2 9 4 8 5 1 6 0]
 [7 4 6 5 1 8 9 3 2 0]
 [8 0 9 7 5 4 3 2 1 6]
 [2 3 4 9 0 8 1 7 6 5]
 [2 1 5 8 6 7 4 0 9 3]
 [0 7 4 5 6 3 2 9 1 8]
 [0 1 4 3 7 6 8 2 5 9]
 [5 8 3 4 2 9 6 0 7 1]
 [9 0 4 6 8 7 1 5 2 3]
 [1 0 4 3 9 2 7 6 8 5]]
vm  [-0.3 -0.1 -2.7  2.6 -0.3 -0.4 -0.3  0.4 -1.5 -0.7  3.3 -0.5 -0.2 -0.1 -2.9  5.9 -0.3 -0.3  0.3 -1.5 -0.7 -0.2  1.1 -0.1 -1.2 -0.4 -0.5  0.5  1.3  6.3 -0.4  0.4 -0.1 -5.  -0.2 -0.4  3.2 -0.2 -1.2 -0.7  0.1  5.2  2.8 -0.6 -0.3 -0.1  5.7 -0.5  0.3  5.6 -0.5 -0.2 -0.5  4.6 -1.7  3.1 -0.6  5.8 -2.4  3.1 -1.5 -0.2 -1.1 -0.9 -0.7  0.1 -0.2  0.4  1.3 -0.2 -0.4 -2.  -0.7 -0.4 -1.5  0.  -0.2  0.5 -0.6 -0.1 -0.6 -0.1 -0.2 -0.3 -0.7  5.7  2.8  0.4 -0.2 -0.4 -0.5 -0.4 -0.2  5.3 -0.4  0.8 -0.1 -1.  -0.7  0.   2.2 -1.  -0.3  0.7 -0.2 -0.3 -1.9 -0.2  1.1 -2.  -0.2 -0.1 -0.1 -0.3 -2.2 11.   1.9 -1.4 -0.2 -0.1 -0.5  5.9 -0.6 -0.5 -0.1 -3.3  1.  -0.6 -1.9 -0.4 -0.4 -0.6 -0.7  0.7 14.6  5.6 -0.4 -0.2 -0.6 -1.4 -1.  -0.1 -0.6 -0.1 -0.4 -0.2 -0.4 -0.2  8.7 -0.5 -0.2 -0.1  2.4 -0.1 -0.2 -0.1  0.1 -0.8 -1.4 -0.8 -0.7  0.9 -0.3 -0.2 -0.3  0.9 -0.4 -0.7 -0.5 -0.  -0.1 -0.2 -0.  -0.6  0.4 -2.4 -1.8 -0.2  1.2 -0.3 -2.3  2.1  1.3 -0.9 -0.2 -0.   0.4  1.  -0.  -1.5 -0.  -0.4 -0.2 -0.8 10.6  6.4 -0.5  5.5 -0.4 -0.1 -0.1 -0.2 -0.2 -0.2 -0.2 -0.8 -0.1  0.4 -1.3  0.8 -0.6  1.8 -0.4 -0.9  1.2  0.1  2.2 -0.2 -0.2 -0.5 -0.2 -0.2  0.2 -0.7  2.5  4.9 -0.1 -0.6 -0.2 -0.1 -0.3  3.  -0.7 -1.1 -1.4  2.3 -0.4 -0.6 -0.7 -1.9 -0.1 -0.7 -0.3  0.2  3.7 -0.8  1.9 -0.7 -0.5 -0.2  1.3 -0.  -0.9 -0.6 -0.5  4.4]
vy_50sample [[5 6 2 8 9 9 3 1 7 0]
 [3 7 1 9 0 4 6 8 5 2]
 [1 8 9 4 7 6 2 3 0 5]
 [6 8 4 5 9 1 0 3 7 2]
 [1 0 7 4 6 6 3 5 9 2]
 [3 6 4 2 0 7 1 8 9 5]
 [8 8 4 0 7 2 9 6 5 3]
 [1 8 0 7 9 4 2 5 3 6]
 [9 7 1 8 5 0 2 6 4 3]
 [7 6 9 3 2 5 8 1 0 4]]
vt_50sample [[5 6 2 8 9 4 3 1 7 0]
 [3 7 1 9 0 4 6 8 5 2]
 [1 8 9 7 4 6 3 2 0 5]
 [6 8 4 5 9 1 0 3 7 2]
 [1 0 7 4 8 6 3 5 9 2]
 [3 6 4 2 0 7 1 8 5 9]
 [8 1 4 0 7 2 9 6 5 3]
 [1 8 0 7 9 4 2 5 3 6]
 [9 7 1 8 5 0 2 6 4 3]
 [7 6 9 3 2 5 8 1 0 4]]
Epoch 38110: Training cost= 0.2654, Training acc= 0.8502, Validation cost= 0.2424, Validation acc= 0.8502
Epoch 38120: Training cost= 0.2421, Training acc= 0.8502, Validation cost= 0.2669, Validation acc= 0.8502
Epoch 38130: Training cost= 0.2586, Training acc= 0.8502, Validation cost= 0.2667, Validation acc= 0.8502
Epoch 38140: Training cost= 0.2190, Training acc= 0.8502, Validation cost= 0.2522, Validation acc= 0.8503
Epoch 38150: Training cost= 0.2600, Training acc= 0.8502, Validation cost= 0.2361, Validation acc= 0.8503
Epoch 38160: Training cost= 0.2464, Training acc= 0.8502, Validation cost= 0.2335, Validation acc= 0.8503
Epoch 38170: Training cost= 0.2350, Training acc= 0.8502, Validation cost= 0.2459, Validation acc= 0.8503
Epoch 38180: Training cost= 0.2449, Training acc= 0.8503, Validation cost= 0.2435, Validation acc= 0.8503
Epoch 38190: Training cost= 0.2354, Training acc= 0.8503, Validation cost= 0.2581, Validation acc= 0.8503
Epoch 38200: Training cost= 0.2914, Training acc= 0.8503, Validation cost= 0.2791, Validation acc= 0.8503
tm  [-1.2  1.5  3.5  3.3 -1.5 -0.3 -0.2 -0.2 -1.3 -1.5 -5.1 -0.3 -0.4 -0.1  1.7 -0.4  1.1 -0.3  1.4 -0.2 -0.9 -0.1 -0.4 -0.3 -1.2  0.8 -0.1 -0.2 -0.2  1.7 -0.6 -0.4 -0.4 -1.1 -0.1 -0.4  3.  -1.8 -1.4 -0.4 -0.3 -2.2  1.8 -1.  -0.1 -0.2 -0.4 -0.2 -0.2 -1.3 -0.4 -0.1  0.  -1.9 -1.4 -0.2 -0.6  3.8 -1.6  4.3  2.4 -0.5 -0.2 -0.4 -0.8  0.1 -0.1 -0.6 -0.   0.1 -0.2 -0.8  1.2  0.6 -2.3 -0.  -0.6 -0.5 -0.5 -0.1 -1.4 -0.8 -0.2 -0.5 -0.6 -1.8 -0.8 -0.1 -0.2 -0.2 -0.4 -0.3  0.3  1.8 -0.2 -0.3 -0.2 -1.8 -0.6 -0.2  5.2 -1.6 -0.2 -0.3 -0.1  1.5 -1.2 -0.3 -1.7 -1.1 -0.2 -0.1 -0.1 -0.4 -1.2  9.  -0.1 -1.1  0.1 -0.6 -0.2  3.7 -0.4  0.5 -0.1  2.1 -0.1  8.5 -1.2  8.7  0.6 -0.7 -0.4 -0.2  6.1  3.7 -0.2  0.3  0.5 -0.2  2.1 -0.3  0.5 -0.1 -0.2  0.5 -0.  -0.1  1.  -0.  -0.2 -0.   1.6 -0.2 -0.5 -0.2 -0.7 -0.  -0.7 -0.4 -0.6  1.3  0.4 -0.  -0.1  1.   0.6  0.3 -0.1 -0.3 -0.2 -0.3 -0.3 -0.2 -0.3  1.4 -0.7 -0.4  2.8 -0.1 -1.1  1.5 -0.3 -1.9 -0.2 -0.  -0.3 -0.4 -0.2 -0.4 -0.2  1.  -0.  -1.3 -0.1  4.7  0.1  2.3 -0.2 -0.1 -0.3 -0.2 -0.1 -0.4 -0.4 -1.1 -0.4  0.2  4.9 -0.3 -0.1  2.6 -0.4  4.   0.2 -0.4  4.6 -0.6 -0.3 -0.4 -0.1  0.1  0.  -0.8 -0.6  3.9 -1.8  0.1 -0.3 -0.  -0.3 -0.3 -0.5  1.9 -0.4 -0.6 -0.7 -0.4  0.3  1.4 -0.   0.5 -0.3 -0.3  6.1 -0.6 -0.3  0.  -0.8 -0.5  3.2 -0.1 -1.  -0.1 10.1 -1.8]
ty_50sample [[3 6 8 1 7 5 9 4 0 2]
 [8 1 0 6 6 3 5 2 4 7]
 [2 4 3 8 7 6 9 1 5 0]
 [7 1 8 4 9 3 0 5 2 6]
 [9 1 8 6 2 3 7 4 5 0]
 [2 2 6 6 3 4 7 8 1 0]
 [8 5 1 4 3 6 7 9 2 0]
 [1 6 3 5 0 0 2 8 8 7]
 [7 4 0 8 9 2 2 5 3 1]
 [0 6 2 8 9 4 7 5 3 1]]
tt_50sample [[3 6 8 1 7 5 9 4 0 2]
 [8 1 0 9 6 3 5 2 4 7]
 [2 4 8 3 7 9 6 1 5 0]
 [7 1 8 4 9 3 0 5 2 6]
 [9 1 8 6 2 3 7 4 5 0]
 [2 9 5 6 3 4 7 8 1 0]
 [8 5 1 4 3 6 7 9 2 0]
 [1 3 6 5 0 2 9 4 8 7]
 [7 4 0 8 9 6 2 5 3 1]
 [0 6 2 8 9 4 7 5 3 1]]
vm  [-0.3  0.3 10.9 17.  -1.7 -0.3 -0.2 -0.1 -1.2 -0.9 -2.4 -0.3 -0.4 -0.1  2.  -1.  -0.3 -0.1  0.1 -1.2 -0.7 -0.1 -0.6 -0.1 -0.5  1.3 -0.5 -0.1 -1.   0.9 -1.1 -0.2  0.1  6.8 -0.1 -0.2  3.8 -1.1  3.3 -0.2 -0.  -1.9  1.8 -1.5 -0.  -0.1  6.1  0.2  2.7 -2.  -0.3  0.1  0.1 -2.5 -0.6 -0.3 -0.6  6.3 -1.7  5.4 -1.2 -0.3 -0.3 -0.3 -0.6 -0.1  0.1 -0.3  0.6 -0.1 -0.1  1.3 -0.2 -0.2 -0.3 -0.1 -0.5 -0.4 -0.1 -0.1  7.2 -0.4 -0.3 -0.2 -1.  -1.8 -0.6 -0.2 -0.3 -0.3 -0.  -0.1  0.1  2.1 -0.  -0.2 -0.  -0.8 -0.2 -0.2  2.7 -0.4 -0.6  0.  -0.2  0.7 -0.5 -0.4 -0.8 -1.6 -0.1 -0.1  0.4 -0.3 -0.5 -0.5 -0.4 -0.9 -0.1 -0.6 -0.   6.8 -0.1  0.2 -0.1  2.5 -0.1 10.3 -1.7  4.1  0.7 -0.3 -0.1 -0.4 -1.3  4.5 -0.1  0.1  0.8 -0.4 -0.  -0.6  0.3 -0.2 -0.1  0.4 -0.1 -0.1 -1.1 -0.  -1.5 -0.2  1.8  0.1 -0.3  0.1 -0.3 -0.5 -0.4 -0.4 -0.3 -0.1 -0.   0.3 -0.1  1.   0.1 -0.2 -0.1 -0.2 -0.2 -0.2 -0.4 -0.1 -0.   2.7 -0.7 -0.1 -0.2  0.1 -0.9 -0.1 -0.1 -1.3 -0.3 -0.5  1.1 -0.6 -0.2  0.2 -0.1  0.6 -0.4 -1.   9.7  6.3  0.5  1.2 -0.1 -0.1 -0.3 -0.3 -0.2 -0.3 -0.2  0.6 -0.3 -0.2  3.1 -0.3 -0.  -0.9 -0.4 -0.5  0.2 -0.3  6.7 -0.9 -0.2 -0.3 -0.3  0.2 -0.1 -0.5 -0.7 -0.  -1.4 -0.1  0.3  0.9 -0.4 -0.6 -0.2  1.6 -0.1 -2.5 -0.   0.6  0.2  9.2  0.   3.  -0.2 -0.2 -1.1 -1.6 -0.5 -0.1 -1.  -0.3 -1.9 -0.1  2.1 -0.4  8.4 -0.5]
vy_50sample [[3 7 9 6 0 8 5 1 2 4]
 [2 4 9 7 1 8 6 5 3 0]
 [1 5 0 6 4 9 3 7 8 2]
 [5 9 6 7 0 4 2 2 1 3]
 [3 7 7 6 9 4 1 8 5 0]
 [3 6 8 4 9 1 2 5 0 7]
 [2 0 6 5 1 3 7 4 8 9]
 [6 5 4 3 8 7 2 0 9 1]
 [0 0 5 8 1 3 4 7 2 6]
 [1 9 6 7 0 2 4 3 3 5]]
vt_50sample [[3 7 9 6 0 8 5 1 2 4]
 [2 4 9 7 1 8 6 5 3 0]
 [1 5 0 6 4 9 3 7 8 2]
 [5 9 6 7 4 0 2 8 1 3]
 [3 7 2 6 9 4 1 8 5 0]
 [3 6 4 8 9 1 2 5 0 7]
 [2 0 6 5 1 3 7 4 8 9]
 [6 5 4 3 8 7 2 0 9 1]
 [9 0 5 8 1 3 4 7 6 2]
 [1 9 6 7 0 2 4 8 3 5]]
Epoch 38210: Training cost= 0.2006, Training acc= 0.8503, Validation cost= 0.3076, Validation acc= 0.8503
Epoch 38220: Training cost= 0.3096, Training acc= 0.8503, Validation cost= 0.2553, Validation acc= 0.8504
Epoch 38230: Training cost= 0.3290, Training acc= 0.8503, Validation cost= 0.3829, Validation acc= 0.8504
Epoch 38240: Training cost= 0.2696, Training acc= 0.8503, Validation cost= 0.3543, Validation acc= 0.8504
Epoch 38250: Training cost= 0.2931, Training acc= 0.8503, Validation cost= 0.2380, Validation acc= 0.8504
Epoch 38260: Training cost= 0.2581, Training acc= 0.8503, Validation cost= 0.2481, Validation acc= 0.8504
Epoch 38270: Training cost= 0.2673, Training acc= 0.8504, Validation cost= 0.2908, Validation acc= 0.8504
Epoch 38280: Training cost= 0.3064, Training acc= 0.8504, Validation cost= 0.2806, Validation acc= 0.8504
Epoch 38290: Training cost= 0.3420, Training acc= 0.8504, Validation cost= 0.2446, Validation acc= 0.8504
Epoch 38300: Training cost= 0.2452, Training acc= 0.8504, Validation cost= 0.2381, Validation acc= 0.8505
tm  [-0.2 -0.7 -1.9 -4.  -2.1 -0.1 -0.4 -0.3 -0.8  1.5 -6.4 -0.2 -0.  -0.2  5.  -3.   1.2 -0.6 -0.   0.2 -1.1 -0.2  1.1 -0.3 -1.2  1.3 -0.4 -0.2 -1.7 -1.8  0.3 -0.1 -0.7 -3.1 -0.2 -0.2  2.   0.2  4.4 -0.8 -0.4  2.7 -0.2  4.5 -0.6 -0.3 -1.4 -0.1  1.6  7.1 -0.1 -0.2 -1.  -0.3  2.1 -0.7 -1.2 -0.6  2.7  1.9  1.5 -0.2 -0.5  0.4 -0.9 -0.3 -0.1 -0.3  2.1 -0.1 -0.3  6.8 -0.5 -0.6 -5.4 -0.5 -0.6 -0.5 -0.1 -0.1 -5.6 -0.1 -0.5 -0.8 -1.3  1.9  5.1 -0.1 -0.1 -0.3 -0.4 -0.1 -0.1 -0.1 -0.4 -0.2 -0.2 -3.  -0.4 -0.1 -0.8  0.4 -0.4 -0.2 -0.3 -0.3 -2.7  0.1 -1.9 -0.5  0.2 -0.2 -0.2 -0.2  5.3 -4.  -0.1  1.5 -0.   0.5 -0.1  0.2 -0.2 -0.8 -0.2  6.7 -0.2  3.1  2.7  7.4 -0.2 -0.3 -0.2 -0.2 -3.1 -6.2 -0.2  0.1 -0.5 -0.4  2.6 -1.3  1.  -0.6  0.2 -0.3 -0.4  0.1  3.7 -0.4  2.6 -0.   3.1  0.3 -0.5 -0.4 -0.1 -0.   1.9 -0.7 -0.3 -2.2  0.5 -0.2 -0.4  0.4 -0.5 -0.5 -0.4 -0.3 -0.2 -0.  -0.3 -0.3  0.  -0.5  3.  -0.7 -0.5 -0.4 -1.6 -0.5 -0.2 -0.9  0.  -0.   0.2 -0.1  0.1  4.3 -0.2 -0.4 -0.2 -1.3  0.2 -0.6 -1.6 -1.  -0.3  0.3  0.1 -0.3 -0.1 -0.2 -0.2 -3.1 -0.2 -0.4  3.4 -0.2 -0.7 -2.7 -0.5 -0.7 -0.   0.2 -1.9 -0.8 -0.4 -0.4 -0.2 -0.3 -0.1 -1.4 -1.2 -1.6 -2.3 -0.4 -0.4  1.1 -0.8  1.9 -0.3  0.9  1.5  2.6  2.1 -1.6  1.6 -3.8 -0.2 -1.3 -0.2 -0.3 17.2  4.3 -0.1 -0.4 -0.8 -0.2 14.7 -0.4  3.1 -0.1  5.5 -1.5]
ty_50sample [[0 8 4 5 3 7 1 9 6 2]
 [0 7 4 2 6 3 8 5 1 9]
 [7 8 6 3 9 2 1 5 4 0]
 [3 7 9 6 2 0 1 4 8 5]
 [6 5 0 0 9 1 7 7 3 8]
 [5 9 8 3 0 7 2 2 1 6]
 [0 4 9 1 8 5 7 3 2 6]
 [1 9 7 3 5 8 2 6 4 0]
 [0 7 5 4 3 2 2 1 9 6]
 [3 7 1 9 8 0 6 5 2 4]]
tt_50sample [[0 8 4 5 3 7 1 9 2 6]
 [0 7 4 2 6 3 8 5 1 9]
 [7 8 6 3 9 2 1 5 4 0]
 [3 7 9 6 2 0 1 4 8 5]
 [6 5 0 2 9 1 4 7 3 8]
 [5 9 8 3 0 7 2 4 1 6]
 [0 4 9 1 8 5 7 3 2 6]
 [1 9 7 3 5 8 2 6 4 0]
 [0 7 5 4 3 2 8 1 9 6]
 [3 7 1 9 0 8 6 2 5 4]]
vm  [-0.8  1.2  4.1  5.6 -1.1 -0.2 -0.1 -0.  -0.8 -0.6 10.8 -0.3 -0.1 -0.1  2.3  4.7 -0.1  0.  -0.1 -0.  -1.1 -0.1 -1.  -0.1 -1.1  0.8 -0.3 -0.3 -0.6 -1.4  1.  -0.5 -0.   5.9  0.1 -0.3  3.1  1.2 -3.2 -0.4 -0.6 -1.7 -0.4 -1.8 -0.3 -0.3 -0.6 -0.4 -0.6 -3.4 -0.3 -0.1 -0.8  9.5 -0.8 -0.3 -0.3  4.2  0.3  0.3  5.1 -0.4  0.   0.1  0.5 -0.4 -0.1 -0.2 -0.8 -0.1 -0.1  0.7  0.4  0.4 -3.4 -0.3 -0.4 -0.7  0.2 -0.5  6.8 -0.2 -0.2 -0.5 -0.1 -1.3 -1.2 -0.2 -0.2 -0.2 -0.1  0.  -0.3  0.4 -0.  -0.1 -0.4 -2.2  0.2 -0.5  4.1 -1.5 -0.2 -0.4 -0.1 -0.7 -2.3 -0.1  0.1 -0.5 -0.  -0.  -0.  -0.5 -0.1  2.5 -0.3 -0.8 -0.1 -0.2 -0.3  1.4 -0.1 -0.1 -0.1  2.  -0.1 -2.2 -0.1  8.  -0.2 -0.3 -0.  -0.2 11.2 17.3 -0.1 -0.   0.6 -0.2 -0.9 -0.2 -0.9  0.5 -0.1  0.1 -0.1 -0.3  2.3  0.5 -0.9 -0.3 -1.  -0.8 -0.   0.4 -0.  -0.3 -1.3 -0.4 -0.1  1.9 -0.1 -0.1  0.3 -0.1 -0.   0.9 -0.2  0.2 -0.   0.1 -0.3 -0.1 -0.4 -0.1 -1.  -0.6  4.9  0.1 -0.9 -0.6 -0.4 -1.7 -0.3 -0.4 -0.5 -0.6 -0.5  3.7 -0.1 -0.3 -0.3 -0.9 -1.4  0.3 -0.5 -0.  -0.3 -0.1 -0.3  0.3 -0.2 -0.6 -0.4 -2.7 -0.  -0.1 -2.  -0.1 -0.9 -0.5 -1.   3.7 -0.6 -0.2  8.3 -1.1 -0.5  0.1  0.  -0.   0.7 -0.9  2.4 -0.5  2.9  2.  -0.   1.1 -0.1  1.1 -0.2 -0.8  0.1 -0.6  0.3 -1.  -0.3 -0.7  0.1 -0.3  0.2 -0.2 -1.1  1.4 -0.1 -0.1 -1.2 -0.4 -2.1  0.4 -2.  -0.  -0.2 -1.8]
vy_50sample [[6 2 3 1 0 5 7 9 4 8]
 [7 1 5 0 3 6 2 4 9 8]
 [3 1 8 0 5 9 7 4 2 6]
 [3 1 0 4 5 6 9 2 7 8]
 [8 6 5 3 2 0 7 1 4 9]
 [3 8 6 1 0 2 5 7 4 9]
 [1 3 0 5 4 6 8 9 2 7]
 [4 0 5 2 8 1 7 9 3 6]
 [5 9 2 3 8 1 0 7 6 6]
 [0 6 9 3 1 1 5 2 7 4]]
vt_50sample [[6 2 3 1 0 5 7 9 4 8]
 [7 1 5 0 3 6 2 4 9 8]
 [3 1 8 0 5 9 7 4 2 6]
 [3 0 1 4 5 6 9 2 7 8]
 [8 6 5 3 2 0 7 1 4 9]
 [3 8 6 1 0 2 5 7 4 9]
 [1 0 3 5 4 6 8 9 2 7]
 [4 0 5 2 8 1 9 7 3 6]
 [5 9 2 3 8 1 0 7 4 6]
 [0 6 9 8 3 1 5 2 7 4]]
Epoch 38310: Training cost= 0.2733, Training acc= 0.8504, Validation cost= 0.3142, Validation acc= 0.8505
Epoch 38320: Training cost= 0.2278, Training acc= 0.8504, Validation cost= 0.2299, Validation acc= 0.8505
Epoch 38330: Training cost= 0.2582, Training acc= 0.8504, Validation cost= 0.2786, Validation acc= 0.8505
Epoch 38340: Training cost= 0.3273, Training acc= 0.8504, Validation cost= 0.2161, Validation acc= 0.8505
Epoch 38350: Training cost= 0.2835, Training acc= 0.8504, Validation cost= 0.3184, Validation acc= 0.8505
Epoch 38360: Training cost= 0.2551, Training acc= 0.8505, Validation cost= 0.2571, Validation acc= 0.8505
Epoch 38370: Training cost= 0.2921, Training acc= 0.8505, Validation cost= 0.2604, Validation acc= 0.8505
Epoch 38380: Training cost= 0.3481, Training acc= 0.8505, Validation cost= 0.3395, Validation acc= 0.8505
Epoch 38390: Training cost= 0.2316, Training acc= 0.8505, Validation cost= 0.2799, Validation acc= 0.8506
Epoch 38400: Training cost= 0.2301, Training acc= 0.8505, Validation cost= 0.2216, Validation acc= 0.8506
tm  [-0.4 -0.1  5.7  8.2 -1.1 -0.2  0.3  0.  -1.2 -0.8 -4.1 -0.4 -0.3 -0.2  2.   0.8 -0.2 -0.2 -0.2 -1.1 -0.9 -0.2  1.4 -0.2 -0.9 -0.1  0.2 -0.6  0.2  7.7 -0.8 -0.3  0.4  1.2 -0.2 -0.2  2.8 -1.5 -0.9 -0.2  0.  -2.7  1.3 -0.7  0.1 -0.3  6.2 -0.3 -0.1  3.2 -0.4 -0.1 -0.  -1.9 -1.6 -0.1 -0.2 -1.7 -1.9  3.8 -0.7 -0.4 -0.6 -0.5 -0.7 -0.3  0.3  0.5  0.6 -0.1 -0.3 -1.2  0.2 -0.6 -0.3 -0.1 -0.  -0.3 -0.2  0.3 -0.4  1.5 -0.5  1.5 -0.5 -2.5  1.3 -0.1 -0.2 -0.4  0.7 -0.2 -0.1  1.  -0.4 -0.3 -0.5 -0.8 -0.2 -0.7  2.4  2.8 -0.1  0.2 -0.3  0.3 -0.6 -0.4 -1.2 -1.3 -0.3 -0.2 -0.2 -0.  -1.1  7.5 -0.7 -0.9 -0.1 -0.6 -0.1  4.6 -0.1 -0.2  0.5  2.5 -0.1  8.  -2.3  1.1  1.3 -0.3 -0.1 -0.4  4.5  4.5 -0.3 -0.2  0.2 -0.4  0.8 -0.4  0.1 -0.1 -0.3  0.1 -0.1 -0.1 -2.4 -0.4 -1.  -0.   2.2 -0.2 -0.4  0.2 -0.2  0.7 -1.4 -0.3 -0.2  3.  -0.2 -0.1  0.3 -0.  -0.4  0.4 -0.1 -0.1  0.1 -0.1  0.7  0.7 -0.   3.9 -0.9  0.2  1.8 -0.   2.9 -0.3 -0.  -1.4 -0.1 -0.6 -0.  -0.7 -0.  -1.9  0.  -0.2 -0.7 -1.2  6.5  8.  -0.   2.  -0.  -0.1 -0.  -0.  -0.  -0.5 -0.1 -0.4 -0.  -0.1 10.3 -0.2 -0.6  3.1 -0.6  1.3 -0.6 -0.3  3.9 -0.5 -0.3  0.3 -0.1 -0.2 -0.1 -0.9  1.9  4.1 -1.1 -0.1  1.3  0.5  0.3 -0.4 -0.3  3.2 -1.  -0.9  0.3 -0.   1.5 17.5  0.   5.9 -0.2 -0.2  3.  -1.7 -0.2 -0.5 -0.8 -0.6  0.2 -0.2 -0.6 -0.1  5.2  1.5]
ty_50sample [[6 8 7 3 9 4 1 2 5 5]
 [5 3 7 2 8 0 1 6 9 4]
 [1 5 5 6 8 8 9 4 7 3]
 [2 2 5 1 1 6 8 3 0 7]
 [7 9 5 2 0 4 6 1 8 3]
 [2 8 1 4 5 9 6 7 0 3]
 [7 5 9 3 4 8 1 0 6 2]
 [8 6 4 1 2 3 9 0 5 7]
 [8 5 6 2 0 3 1 7 4 9]
 [9 6 8 3 5 7 4 2 1 0]]
tt_50sample [[6 8 7 3 9 4 1 2 0 5]
 [5 3 2 7 8 0 1 6 4 9]
 [1 5 0 6 2 8 9 4 7 3]
 [2 4 5 1 9 6 8 3 0 7]
 [7 9 5 2 0 4 6 1 8 3]
 [2 8 1 4 5 9 6 7 0 3]
 [7 5 9 3 4 8 1 0 6 2]
 [8 6 4 1 2 3 9 0 5 7]
 [8 5 6 2 0 3 1 7 4 9]
 [9 6 8 3 5 7 4 2 1 0]]
vm  [-0.1  1.9  4.5 -0.1 -1.4 -0.1 -0.1 -0.2 -1.8 -1.5  3.7  0.3 -0.1 -0.2  5.2  4.3  0.6 -0.3  0.4 -0.2 -0.9  0.1 -0.6  0.4 -1.6  1.8  0.8 -0.4 -0.1  4.5  0.4 -0.2 -0.6  4.7 -0.1 -0.2  3.9  2.6  2.4 -0.4  0.7  1.2  6.7  1.4  0.5  0.3 -0.5 -0.1  3.7 -1.6 -0.3 -0.1  1.2  4.2 -0.9 -0.4 -0.7  7.  -2.9  2.1 -0.3 -0.3 -0.3 -0.2 -0.5  1.4  0.1 -0.6  0.9  0.5  0.2 -0.8  0.9  0.4 -2.3  0.4 -0.3 -0.5 -0.1 -0.4 -0.6 -0.7 -0.1  0.1 -1.1  2.2  4.1  0.1 -0.1 -0.2 -0.7 -0.1  0.3  4.7 -0.2 -0.   0.4 -1.5 -0.4 -0.1  5.8 -0.4 -0.6  0.1 -0.1  0.9 -1.4  0.4  1.4 -0.4 -0.2 -0.2  0.  -0.2 -2.3  9.3  0.3 -1.6 -0.2 -0.3 -0.   1.2 -0.3 -0.6 -0.1  6.4 -0.2 -0.6 -1.7  8.5  0.5 -0.5 -0.2 -0.3 -2.3 -1.  -0.2 -0.1 -0.4 -0.4 -0.4 -0.3  0.1 -0.  -0.1 -0.1  0.6 -0.3  4.5  0.4 -0.2 -0.1  2.9 -0.2 -0.3 -0.2 -0.4 -0.1  1.3 -0.1 -0.4 -0.8 -0.3 -0.  -0.3 -0.1 -0.1 -1.  -0.   0.4  0.4 -0.3 -0.1 -0.4  0.5 -0.5 -0.1 -0.3 -0.  -0.1 -2.3  0.1 -0.3 -2.1 -0.3 -0.2  1.  -0.6 -0.2 -1.2 -0.3  0.1  0.  -1.1  4.6  6.5 -0.1  5.6 -0.1 -0.2 -0.2  0.1 -0.1 -0.1 -0.4 -1.8 -0.2 -0.2 -2.1 -0.3 -0.2  1.3 -0.2 -0.6 -0.3 -0.3 -0.3 -0.6  0.2 -0.6 -0.   0.1  0.5 -0.6 -1.3  3.6 -0.4 -0.6  1.9  1.1 -0.4 -0.1 -0.2 -1.1 -0.3 -0.7 -0.5 -0.4 -0.  -3.2  0.2 -1.2  0.2 -0.1  3.8 -0.1 -0.1 -0.1 -0.6 -0.7  0.9  0.1  0.8 -0.1  4.3 -1.8]
vy_50sample [[5 3 7 2 8 4 6 6 1 0]
 [8 0 9 5 4 3 6 7 2 1]
 [7 8 5 3 6 6 1 9 4 0]
 [4 9 1 2 0 5 8 7 3 6]
 [8 7 2 0 4 3 6 5 9 1]
 [7 9 1 2 4 5 3 0 8 6]
 [6 5 1 2 7 9 3 4 8 0]
 [3 0 4 5 1 6 2 7 9 8]
 [1 4 3 6 5 0 9 7 7 2]
 [7 9 8 6 5 4 3 1 2 0]]
vt_50sample [[5 3 7 2 8 4 9 6 1 0]
 [8 0 9 5 4 3 6 7 2 1]
 [7 8 5 3 6 2 1 9 4 0]
 [4 9 1 2 0 5 7 8 3 6]
 [8 7 2 0 4 3 6 5 9 1]
 [7 9 1 2 4 5 3 0 8 6]
 [6 5 1 2 7 9 4 3 8 0]
 [0 3 4 1 5 6 2 7 9 8]
 [1 4 3 6 5 0 9 7 8 2]
 [7 9 8 6 5 4 3 1 2 0]]
Epoch 38410: Training cost= 0.2626, Training acc= 0.8505, Validation cost= 0.2052, Validation acc= 0.8506
Epoch 38420: Training cost= 0.2405, Training acc= 0.8505, Validation cost= 0.2642, Validation acc= 0.8506
Epoch 38430: Training cost= 0.2891, Training acc= 0.8505, Validation cost= 0.2161, Validation acc= 0.8506
Epoch 38440: Training cost= 0.2941, Training acc= 0.8506, Validation cost= 0.2493, Validation acc= 0.8506
Epoch 38450: Training cost= 0.2807, Training acc= 0.8506, Validation cost= 0.2463, Validation acc= 0.8506
Epoch 38460: Training cost= 0.2344, Training acc= 0.8506, Validation cost= 0.2550, Validation acc= 0.8506
Epoch 38470: Training cost= 0.2555, Training acc= 0.8506, Validation cost= 0.2572, Validation acc= 0.8507
Epoch 38480: Training cost= 0.2469, Training acc= 0.8506, Validation cost= 0.2485, Validation acc= 0.8507
Epoch 38490: Training cost= 0.2881, Training acc= 0.8506, Validation cost= 0.2194, Validation acc= 0.8507
Epoch 38500: Training cost= 0.2446, Training acc= 0.8506, Validation cost= 0.2361, Validation acc= 0.8507
tm  [-1.2 -0.3 -0.9  1.9 -1.4 -0.  -0.3 -0.1 -0.2 -0.1  5.9 -0.3 -0.1 -0.1 -0.4  3.1 -0.3  0.  -0.2  0.5 -1.1 -0.3  2.1 -0.  -1.4  4.2 -0.3 -0.2 -0.6 -1.2  1.1 -0.4  0.6 -0.9 -0.1 -0.2  2.2 -0.2 -2.5 -0.5 -0.3  1.7 -0.6 -1.1 -0.3 -0.1 -0.7 -0.5 -0.7  5.  -0.3 -0.3  0.3  3.5 -0.6  0.8 -0.2 -0.   2.6  0.8  3.6 -0.3  2.   0.6  1.  -0.4 -0.1 -0.2 -0.4 -0.1  0.1  0.1  0.5  1.2 -2.9 -0.3 -0.3 -0.7  0.  -0.1  2.   0.1 -0.  -0.2  0.5  3.3 -0.9  0.1  0.  -0.3 -0.1 -0.1  0.4 -1.1  0.1 -0.1 -0.3 -2.6 -0.  -0.3  0.4  1.3 -0.2 -0.1 -0.2 -0.2 -1.1  0.7  1.  -0.2 -0.4  0.  -0.  -0.6  2.5  1.  -0.7 -0.7 -0.2 -0.2 -0.2  0.2 -0.1  0.7 -0.1 -0.7 -0.  -0.3  0.5 -0.5 -0.4 -0.2 -0.1 -0.3 13.6 12.7 -0.2 -0.1  1.2 -0.6 -0.2 -0.9 -0.9  0.   0.2 -0.  -0.1 -0.1  3.  -0.1 -0.3 -0.1 -0.5 -0.4  0.2 -0.  -0.6  0.9 -0.9 -0.3  2.6  1.5 -0.2  0.1  0.4 -0.8 -0.3  1.6 -0.1  0.1 -0.1  0.2 -0.1 -0.1 -0.2 -0.2 -0.9  0.9  3.8 -0.2 -0.1 -0.4 -0.6 -1.7 -0.2 -0.6 -0.5 -0.4 -0.3  3.5  0.5 -0.2 -0.2 -1.  -0.7 -0.2 -0.1 -0.8 -0.   0.1 -0.2 -0.1 -0.2 -0.6 -0.  -1.2 -0.2 -0.1  1.2 -0.  -0.6 -0.  -0.9  7.8 -1.  -0.1  5.  -0.8 -0.7  0.  -0.3 -0.1 -0.1 -1.1  6.1 -0.1 -0.3  2.9 -0.2 -0.2  3.1 -0.6 -0.2  1.2  0.6  2.7  1.4 -0.2  2.8  2.2  0.   1.  -0.1 -0.   0.7 -0.9 -0.3  0.6 -1.6 -0.3 -0.9 -0.2 -1.4  0.3 -1.2  4.6]
ty_50sample [[6 1 2 0 9 4 5 5 3 7]
 [1 7 8 5 0 4 6 9 3 2]
 [2 7 1 0 8 3 9 5 6 4]
 [8 8 7 3 9 6 5 1 0 2]
 [7 5 8 0 9 1 6 4 2 3]
 [8 2 5 0 9 6 4 7 3 1]
 [5 4 1 6 9 3 0 2 7 8]
 [2 5 6 1 1 7 3 4 4 9]
 [7 0 8 2 9 4 5 3 1 6]
 [2 6 3 9 9 7 4 0 1 5]]
tt_50sample [[6 1 2 0 9 4 8 5 3 7]
 [1 7 8 5 0 4 6 9 3 2]
 [2 7 1 0 8 3 9 5 6 4]
 [8 4 7 3 9 6 5 1 0 2]
 [7 5 8 0 9 1 6 4 2 3]
 [8 2 5 0 9 6 4 7 3 1]
 [5 4 1 6 9 3 0 2 7 8]
 [2 6 5 1 8 7 3 0 4 9]
 [7 0 8 2 9 4 5 3 1 6]
 [2 3 6 8 9 7 4 0 1 5]]
vm  [-1.5 -0.   7.1  8.4 -1.3  0.  -0.2  0.2 -0.8 -0.6  9.2 -0.1 -0.3 -0.1  3.9  3.2 -0.1 -0.1  0.9 -0.  -1.3 -0.2 -0.7 -0.2 -1.4  2.1 -0.3 -0.4 -0.8 -1.3 -0.  -0.2 -0.4  9.7 -0.   0.3  3.8  2.1 -1.1 -0.4 -0.5 -0.9 -0.4 -1.2 -0.5 -0.2 -0.5 -0.3 -2.  -2.  -0.3 -0.2 -0.5  6.1 -0.7 -0.4 -0.2  3.6 -0.   0.1  7.3 -0.3 -0.3 -0.1 -0.1 -0.2  0.1 -0.2 -0.1  0.   0.   0.8  0.9  1.1 -2.7 -0.5 -0.2 -1.   0.4 -0.6  9.3 -0.1 -0.3 -0.4  3.2 -0.2 -2.6 -0.  -0.1 -0.3 -0.3 -0.  -0.1 -0.2 -0.4 -0.1 -0.3 -2.  -0.2 -0.4  3.8  3.2  2.3 -0.2 -0.1 -0.  -1.4 -0.  -0.  -0.8 -0.3 -0.2 -0.  -0.1  0.1  2.3 -0.6 -1.   0.  -0.1 -0.   2.9  1.1 -0.6  0.4  4.6 -0.1 -1.1 -0.4  2.3 -0.4 -0.2  0.3 -0.3  3.7 12.7 -0.5 -0.1  0.5 -0.2 -0.7 -0.5 -0.6  0.  -0.2 -0.  -0.5 -0.3 -1.  -0.1 -0.9 -0.1 -2.3 -0.5 -0.3  0.3 -0.4 -0.2 -0.6  0.2  1.1  0.5 -0.1  0.3 -0.3 -0.1  0.   1.4 -0.1 -0.2 -0.2 -0.  -0.4 -0.2 -0.3  2.3 -0.4 -0.1  2.9 -0.1 -0.4 -0.5 -0.5 -1.5 -0.1 -0.3 -1.2 -0.5 -0.1  4.   0.3 -0.3 -0.3 -0.9 -2.4  2.3 -0.2  0.1 -0.2  0.2 -0.   0.4 -0.  -0.3 -0.3 -1.5 -0.2 -0.3 -1.4 -0.2 -0.8 -0.5 -0.8  9.7 -0.5 -0.2  6.6 -0.9 -0.3 -0.  -0.1 -0.1  0.7 -1.3  3.1 -0.8  1.9  1.9 -0.6 -0.7 -0.2 -0.3 -0.2 -0.6  0.7 -1.5 -0.2 -0.5  0.3  2.5  0.1  1.2 -0.2  0.4 -1.7 -0.1 -0.2  0.5 -1.1 -0.4 -2.6 -0.2 -0.6 -0.  -0.5  0.1]
vy_50sample [[1 2 6 7 3 0 9 5 4 8]
 [6 1 8 4 0 7 3 2 5 9]
 [9 3 4 5 8 8 6 0 1 7]
 [1 0 3 5 8 7 9 4 2 6]
 [4 1 5 0 7 2 8 6 6 3]
 [2 4 1 1 3 5 9 6 8 0]
 [6 4 8 0 3 1 2 5 9 7]
 [1 2 5 9 3 3 0 4 8 6]
 [7 7 5 9 6 3 2 1 4 8]
 [4 1 9 2 6 8 3 7 0 5]]
vt_50sample [[1 2 6 7 0 3 9 5 4 8]
 [6 1 4 8 0 7 3 2 5 9]
 [9 3 4 5 2 8 6 0 1 7]
 [1 0 3 5 8 7 9 4 2 6]
 [4 1 5 0 7 2 8 6 9 3]
 [2 4 1 7 3 5 9 6 8 0]
 [6 4 8 0 3 1 2 5 9 7]
 [1 5 2 9 3 7 0 4 8 6]
 [0 7 9 5 6 3 2 1 4 8]
 [4 1 9 2 6 8 3 7 0 5]]
Epoch 38510: Training cost= 0.2828, Training acc= 0.8506, Validation cost= 0.2940, Validation acc= 0.8507
Epoch 38520: Training cost= 0.2604, Training acc= 0.8507, Validation cost= 0.2989, Validation acc= 0.8507
Epoch 38530: Training cost= 0.2453, Training acc= 0.8507, Validation cost= 0.2533, Validation acc= 0.8507
Epoch 38540: Training cost= 0.2756, Training acc= 0.8507, Validation cost= 0.2791, Validation acc= 0.8507
Epoch 38550: Training cost= 0.2254, Training acc= 0.8507, Validation cost= 0.2375, Validation acc= 0.8508
Epoch 38560: Training cost= 0.2320, Training acc= 0.8507, Validation cost= 0.2655, Validation acc= 0.8508
Epoch 38570: Training cost= 0.2226, Training acc= 0.8507, Validation cost= 0.2499, Validation acc= 0.8508
Epoch 38580: Training cost= 0.2735, Training acc= 0.8507, Validation cost= 0.2322, Validation acc= 0.8508
Epoch 38590: Training cost= 0.2730, Training acc= 0.8507, Validation cost= 0.2574, Validation acc= 0.8508
Epoch 38600: Training cost= 0.2297, Training acc= 0.8508, Validation cost= 0.2672, Validation acc= 0.8508
tm  [-1.  -0.3 -0.7 14.4 -0.7 -0.1  0.3 -0.1  2.   0.7  9.2 -0.3 -0.1 -0.3 -2.8  1.9 -0.1 -0.4 -0.5 -1.4 -1.4 -0.1 -0.2 -0.  -0.5  1.1 -0.  -0.3 -0.6 -4.3 -0.5 -0.1 -0.2 -2.6  0.5 -0.1  0.8  8.1 13.7 -0.   3.8 -1.5 -1.4  1.  -0.2 -0.   7.9 -0.3 -1.4 -0.3 -0.6 -0.2 -0.2  6.2 -0.4  2.8 -0.5 -0.1  7.5  3.3  1.7 -0.4 -0.1 -0.3  1.3 -0.4  0.3  1.1 -0.6 -0.1 -0.3 -0.1 -0.2 -0.4 -0.8 -0.3 -0.2  0.7 -0.1 -0.4  9.3  1.2 -0.5 -0.   1.2 -1.3 -1.6  0.4 -0.1 -0.4  0.2 -0.  -0.2 -1.3 -0.4 -0.3 -0.2 -1.6 -0.3 -0.3  0.  -1.7  0.6 -0.1  0.  -0.3 -1.2 -0.2 -0.  -1.7  0.3 -0.1 -0.2 -0.6  4.9 -0.4  0.5 -0.4 -0.3  0.  -0.4  5.7  0.9 -0.4 -0.1 -3.4 -0.3 -1.2  6.9 -0.6 -0.9 -0.4 -0.3 -0.1  3.  -2.  -0.2 -0.2  0.3 -0.4 -0.8 -0.4 -1.   0.5  0.3 -0.2  0.3 -0.2  3.3 -0.2 -1.2 -0.4 -0.8 -0.2  0.1 -0.3 -0.3  0.   2.5 -0.2 -0.4 -1.3 -0.1  0.  -0.  -0.1 -0.3  1.5 -0.  -0.1 -0.3 -0.  -0.2  0.6 -0.3 -0.2 -0.3 -0.5 -1.2 -0.1 -0.1 -0.4 -0.5 -1.2 -0.1 -0.3 -0.7 -0.5 -0.5 13.4 -0.1 -0.1 -0.5 -0.6  0.4 -2.1 -0.1 -1.  -0.1  0.2 -0.2 -0.2 -0.6 -0.5 -0.2 -0.4 -0.2 -0.5  5.  -0.1 -0.6 -0.1 -0.4  4.  -0.9 -0.1 -0.2 -1.3 -0.7 -0.1 -0.2 -0.1  0.2 -1.  -1.1 -0.2  2.5  0.3 -0.3 -0.2 -0.9 -0.4 -0.2  2.3  0.   2.2  0.7 -0.3  2.3 15.7 -0.2  4.8 -0.2  0.3 -1.5 -1.8  0.2 -0.4 -1.4 -0.1 -2.6 -0.1  8.6 -0.3 -0.5  4.6]
ty_50sample [[2 1 9 0 3 8 4 5 6 7]
 [1 4 5 3 9 7 8 2 0 6]
 [6 8 2 4 7 5 0 9 3 1]
 [8 7 0 5 9 9 1 4 6 3]
 [3 4 4 2 5 9 6 1 7 8]
 [6 4 7 1 3 8 2 5 0 0]
 [0 3 7 1 2 4 5 6 8 9]
 [6 1 4 8 0 2 3 9 7 5]
 [4 1 6 0 9 8 3 2 5 7]
 [9 6 3 2 5 1 1 7 8 8]]
tt_50sample [[2 1 9 0 3 8 4 5 6 7]
 [1 4 5 3 9 7 8 2 0 6]
 [6 8 2 4 7 5 9 0 3 1]
 [8 7 0 5 9 2 1 4 6 3]
 [3 0 4 2 5 9 6 1 7 8]
 [6 4 7 1 3 8 2 5 9 0]
 [0 3 7 1 2 4 5 6 8 9]
 [1 6 4 8 0 2 3 9 7 5]
 [4 1 6 0 9 8 3 2 5 7]
 [9 6 3 2 5 4 1 7 8 0]]
vm  [-0.4 -0.1 -0.8  8.7 -0.7  0.1 -0.1 -0.3 -0.3 -0.7 11.8 -0.4  1.  -0.2 -2.3  7.7 -0.4 -0.4  0.5 -1.9 -0.9  0.4 -0.4 -0.3 -0.4 -0.2 -0.1  0.1  2.5  3.9  4.7 -0.6  1.9 10.   0.1 -0.1  1.8  1.9  6.5 -0.1 -0.  -0.1 -0.3 -0.2 -0.  -0.4 11.4 -0.2 -0.2 -1.  -0.5 -0.3  0.2 -0.3 -1.6  2.9 -0.2 -1.6 -0.4 -3.  -1.7 -0.6 -0.4 -0.2  1.8 -0.7 -0.  -0.3 -0.1 -0.2 -0.3 -2.2 -0.3 -0.6  8.8  0.2 -0.4  0.5 -0.2 -0.1 28.9 -0.2 -0.5 -0.  -0.6  1.7  3.2 -0.2 -0.2 -0.2 -0.  -0.  -0.3 -0.2 -0.3 -0.2 -0.3  1.7 -0.2  0.5  2.6  3.5 -0.3  0.2 -0.3 -0.7  1.5  2.3 -0.  -2.4 -0.5 -0.1 -0.3 -0.6 -0.8 12.5  1.1 -1.1  0.1  0.  -0.   9.1  0.1 -0.1 -0.1 -2.9  0.2  2.6 -0.9 -3.6 -0.2  0.4 -0.1 -0.4  6.4 17.  -0.2 -0.1 -0.4 -0.5 -0.8  0.  -0.6  0.   0.3  0.2 -0.1 -0.1 -0.9 -0.4 -0.9 -0.  -0.7 -0.5 -0.2 -0.2 -0.1 -0.3 -1.1 -0.1 -0.3  0.8 -0.3 -0.2 -0.2 -0.1 -0.4  0.4 -0.2 -0.3 -0.2 -0.4 -0.3 -0.3 -0.1  1.5 -1.3  0.7 -0.6 -0.1 -0.2  0.6  0.5 -1.1 -0.1  0.1 -0.1 -0.6  0.1 -0.9 -0.4 -0.2 -0.3 -0.6 10.8  2.6  2.2  1.7  0.7 -0.  -0.3 -0.1 -0.2 -0.5 -0.6  5.   0.6 -0.1 -1.2 -0.4 -0.3  4.2 -0.4  0.9 -0.  -0.   1.2 -0.7 -0.1 -0.  -0.1 -0.4 -0.3 -0.8  3.8  2.   2.2 -0.  -0.5  0.4 -0.5 -0.9 -0.1 -0.5 -0.8  2.7 -0.5  3.5 -0.2 21.6 -0.3  7.  -0.3 -0.1 -6.4 -2.9 -0.  -0.5 -1.   0.6 -7.4 -0.   3.8 -0.1 -1.7 13.7]
vy_50sample [[9 2 6 4 7 1 5 5 8 0]
 [4 9 8 8 0 6 7 5 1 3]
 [7 4 4 9 9 6 5 0 3 2]
 [7 8 1 6 0 9 3 2 5 4]
 [9 0 1 4 7 6 2 5 3 8]
 [0 7 5 8 6 2 1 9 4 3]
 [2 6 3 8 7 5 0 4 1 9]
 [2 6 1 0 5 3 4 8 8 7]
 [0 7 1 4 5 2 3 9 6 8]
 [0 5 9 4 6 3 1 8 7 2]]
vt_50sample [[9 2 6 4 7 1 5 3 8 0]
 [4 9 8 2 0 6 7 5 1 3]
 [7 4 8 9 1 6 5 0 3 2]
 [7 8 1 6 0 9 3 2 5 4]
 [9 0 1 4 7 6 2 5 3 8]
 [0 7 5 8 6 2 1 9 4 3]
 [2 6 3 8 5 7 4 0 1 9]
 [2 6 1 0 5 3 4 9 8 7]
 [0 7 1 4 5 2 3 9 6 8]
 [0 5 9 4 6 3 1 8 7 2]]
Epoch 38610: Training cost= 0.2349, Training acc= 0.8508, Validation cost= 0.2792, Validation acc= 0.8508
Epoch 38620: Training cost= 0.2193, Training acc= 0.8508, Validation cost= 0.2889, Validation acc= 0.8509
Epoch 38630: Training cost= 0.2435, Training acc= 0.8508, Validation cost= 0.2721, Validation acc= 0.8509
Epoch 38640: Training cost= 0.2202, Training acc= 0.8508, Validation cost= 0.2238, Validation acc= 0.8509
Epoch 38650: Training cost= 0.3007, Training acc= 0.8508, Validation cost= 0.2419, Validation acc= 0.8509
Epoch 38660: Training cost= 0.2358, Training acc= 0.8508, Validation cost= 0.2658, Validation acc= 0.8509
Epoch 38670: Training cost= 0.2380, Training acc= 0.8509, Validation cost= 0.3145, Validation acc= 0.8509
Epoch 38680: Training cost= 0.2564, Training acc= 0.8509, Validation cost= 0.2508, Validation acc= 0.8509
Epoch 38690: Training cost= 0.2793, Training acc= 0.8509, Validation cost= 0.2535, Validation acc= 0.8509
Epoch 38700: Training cost= 0.2426, Training acc= 0.8509, Validation cost= 0.3337, Validation acc= 0.8509
tm  [-1.  -0.3 -1.6  9.6 -1.  -0.2 -0.3 -0.1  0.1  0.2 -2.8  0.1 -0.3 -0.2 -3.4 -0.1 -0.7 -0.2  1.3 -2.1 -0.9 -0.   1.3 -0.2 -0.3  0.2 -0.4 -0.1 -0.2  2.5  2.3 -0.2  2.6 -1.3 -0.1 -0.3  1.7 -1.7  3.6 -0.5 -0.2 -0.  -0.9 -0.7 -0.4 -0.3 13.   1.1 -1.3  9.2 -0.4 -0.3 -0.2 -4.2 -1.2  3.7 -0.6 -2.6  0.8 -0.5 -0.3 -0.3 -0.6 -0.5 -0.  -0.5 -0.3 -0.2  1.6 -0.1 -0.2 -0.8  1.  -0.6  6.4  0.5 -0.3 -0.3 -0.2 -0.1 15.3 -0.4 -0.2  0.2  1.  -0.1 -0.6 -0.1 -0.5 -0.3 -0.4  0.4 -0.1 -0.7 -0.5 -0.3 -0.7  0.8 -0.5 -0.5  0.2  5.   0.6 -0.4  0.4 -0.4  2.4  1.4 -0.8 -2.6 -0.4 -0.2  0.2 -0.4  1.5  2.9  1.  -0.6 -0.1 -0.2 -0.4 10.2 -0.1  0.4 -0.2 -4.  -0.2 15.3 -1.  -4.3 -0.5 -0.  -0.1 -0.3 11.  11.1 -0.   0.1 -0.1 -0.7 -0.  -0.2  0.3 -0.2  0.   0.3 -0.3 -0.1 -1.4  0.3 -0.9  0.1 -0.8 -0.3 -0.2  0.1 -0.1  0.4 -1.4 -0.4 -0.   1.8 -0.1 -0.1 -0.3 -0.1  0.2  1.6 -0.3 -0.3 -0.2 -0.3 -0.4 -0.1 -0.5  3.1 -1.   0.  -0.4 -0.3  2.3 -0.2  1.7 -0.9 -0.1  0.5 -0.7 -0.2 -0.  -0.4 -0.  -0.3 -0.5 -0.9  4.2  3.5  2.1 -0.2 -0.1 -0.2 -0.  -0.2 -0.2 -0.1 -0.3  6.4 -0.1 -0.4  8.1 -0.  -0.3  0.5 -0.6  4.9  1.5 -0.2  2.5 -0.6  0.7  0.6 -0.4 -0.2  0.3 -0.6  5.6  1.8 -1.7 -0.3 -0.1 -0.6  0.8 -0.8 -0.1  2.8 -0.5  2.3 -0.   2.1  0.1 27.9 -0.1  9.1 -0.3  0.2 -3.1 -3.2  0.5 -0.2 -1.1 -0.1 -4.1 -0.1  2.4 -0.  -0.1 17. ]
ty_50sample [[9 6 1 4 8 0 7 2 3 5]
 [8 3 2 6 1 0 7 9 5 4]
 [7 9 3 0 8 2 5 6 1 4]
 [3 9 4 0 5 8 1 2 6 7]
 [2 7 4 5 1 6 3 0 9 8]
 [1 6 9 2 4 8 5 0 7 3]
 [5 1 4 0 2 8 6 7 3 9]
 [2 7 4 0 1 9 8 3 5 6]
 [9 4 8 5 1 3 2 6 7 0]
 [8 5 4 6 6 2 9 0 1 1]]
tt_50sample [[9 6 1 4 8 0 7 2 3 5]
 [8 3 6 2 1 0 7 9 5 4]
 [7 9 3 0 8 2 5 6 1 4]
 [3 9 4 0 5 8 1 2 6 7]
 [7 2 4 5 1 6 3 0 9 8]
 [1 6 9 2 4 8 5 0 7 3]
 [5 1 4 8 0 2 6 7 3 9]
 [2 7 4 0 1 9 8 3 5 6]
 [9 4 8 5 1 3 2 6 7 0]
 [8 5 4 3 6 2 9 0 1 7]]
vm  [ 0.9  0.4  2.1 -0.9 -0.6 -0.1 -0.1 -0.  -1.  -0.6 -0.3  0.8 -0.3 -0.2  4.   8.  -0.  -0.   1.   1.6 -1.1  0.1  0.   0.9 -1.8  1.6 -0.1 -0.3  1.   5.8 -1.4 -0.3  0.3 -4.2 -0.1 -0.1  0.7  3.4 -3.4 -0.3  1.   3.1  3.4 -0.4 -0.2 -0.7 -1.6 -0.8  4.2 11.5 -0.4 -0.1 -0.5 13.2 -1.5 -0.2 -0.6  4.1 -2.1  6.6  2.4 -0.6 -0.3 -0.3 -0.1 -0.7  0.8  1.2  0.5 -0.5 -0.6 -1.1 -0.1 -0.1 -4.9 -0.4 -0.4 -0.6  0.4 -0.3 -6.3 -0.1 -0.2 -0.1 -1.8  4.9  3.2 -0.1  0.4 -0.3 -0.2 -0.1 -0.3  2.4 -0.1 -0.3 -0.2 -2.7 -0.4 -0.6  3.1  3.1 -0.9 -0.2  0.6 -0.6 -2.3 -1.   0.8  1.8 -0.2 -0.2 -0.2 -0.4 -1.8  9.9  0.  -1.3 -0.1  0.5 -0.2 -1.3 -0.4 -0.5  0.1  5.5 -0.3 -3.1 -1.7  3.9  1.2  0.6  0.8 -0.1  7.5 -1.9  0.1 -0.2 -0.2  0.  -0.9 -0.3 -0.6 -0.2 -0.1 -0.1 -0.2 -0.2  3.1 -0.2 -0.  -0.1  3.1 -0.4 -0.2 -0.1 -0.1 -0.6 -0.7 -0.3 -0.2 -0.2  0.1  0.1 -0.4 -0.4 -0.1 -0.6 -0.2 -0.1 -0.1  0.3 -0.3 -0.3 -0.2 -0.6 -1.6 -0.3  4.9 -0.1 -1.1 -0.6 -0.  -1.6 -0.4  0.4  1.6 -0.4 -0.4 -1.5 -0.1 -0.2 -0.1 -0.8  0.8  5.8 -0.9  3.7 -0.1 -0.2 -0.1 -0.2  0.8 -0.4 -0.2 -2.6 -0.  -0.2  4.9 -0.4 -0.4  2.9 -0.6 -0.8 -0.2 -0.3  3.2 -0.4 -0.5  0.6 -0.1 -0.1 -0.3 -1.5  3.2  2.4  1.9 -0.4 -0.5  1.5  0.1  2.5 -0.1  2.2 -1.1  0.2  0.3 -1.2 -0.  -3.8 -0.1 -1.3 -0.2  0.1 18.7  1.1  1.7 -0.2 -0.6 -0.5 16.7 -0.2 -2.1  0.2 -1.3 -0.4]
vy_50sample [[8 2 6 5 7 4 3 1 0 9]
 [7 1 3 2 5 9 8 4 6 0]
 [4 1 3 3 2 9 6 7 8 5]
 [0 4 2 7 6 3 9 1 5 8]
 [5 1 0 9 8 2 3 4 6 7]
 [7 4 4 1 9 5 0 6 3 2]
 [4 6 3 0 2 5 9 9 8 7]
 [6 3 2 9 9 1 8 5 7 0]
 [8 6 5 7 4 9 3 2 0 1]
 [1 6 9 4 5 3 2 0 8 7]]
vt_50sample [[8 2 6 5 7 4 3 1 0 9]
 [7 1 3 2 5 9 8 4 6 0]
 [4 1 0 3 2 9 6 7 5 8]
 [0 4 2 7 6 9 3 1 5 8]
 [5 1 0 8 9 2 3 4 6 7]
 [7 8 4 1 9 5 0 6 3 2]
 [4 6 3 0 5 2 9 1 8 7]
 [6 3 2 9 4 1 8 5 7 0]
 [8 6 7 5 4 9 3 2 0 1]
 [1 6 9 4 5 3 2 0 8 7]]
Epoch 38710: Training cost= 0.2988, Training acc= 0.8509, Validation cost= 0.2382, Validation acc= 0.8510
Epoch 38720: Training cost= 0.2422, Training acc= 0.8509, Validation cost= 0.2214, Validation acc= 0.8510
Epoch 38730: Training cost= 0.2313, Training acc= 0.8509, Validation cost= 0.2563, Validation acc= 0.8510
Epoch 38740: Training cost= 0.2465, Training acc= 0.8509, Validation cost= 0.2490, Validation acc= 0.8510
Epoch 38750: Training cost= 0.2433, Training acc= 0.8509, Validation cost= 0.2826, Validation acc= 0.8510
Epoch 38760: Training cost= 0.2397, Training acc= 0.8510, Validation cost= 0.2636, Validation acc= 0.8510
Epoch 38770: Training cost= 0.2302, Training acc= 0.8510, Validation cost= 0.2714, Validation acc= 0.8510
Epoch 38780: Training cost= 0.2636, Training acc= 0.8510, Validation cost= 0.3169, Validation acc= 0.8510
Epoch 38790: Training cost= 0.2739, Training acc= 0.8510, Validation cost= 0.2722, Validation acc= 0.8511
Epoch 38800: Training cost= 0.3086, Training acc= 0.8510, Validation cost= 0.2785, Validation acc= 0.8511
tm  [-2.2 -0.7  8.4 14.8 -2.2  0.  -0.2 -0.2  1.1 -0.2 -2.6 -0.3 -0.1 -0.3  1.7 -1.  -0.1 -0.2 -0.1 -0.1 -1.1 -0.2  1.5 -0.4 -0.4  2.7 -0.2 -0.3 -0.9 -3.  -1.6 -0.5 -0.8 -0.3  0.  -0.2 -0.1  2.6 11.6 -0.4  0.4  1.1 -0.6 -0.4 -0.3  0.6 -0.1 -0.1 -1.2  6.8 -0.3 -0.2 -0.1 -0.7 -0.4 -0.2 -0.5  7.9  5.9  7.   6.4 -0.3  0.1 -0.4 -1.5 -0.3 -0.5 -0.8  1.7 -0.2 -0.1  1.7  0.5  1.7 -2.6 -0.2 -0.   0.1 -0.3 -0.  -0.5 -0.4 -0.1 -1.   1.3  2.4 -3.3  0.5  0.  -0.5 -0.7 -0.   0.  -1.3 -0.6 -0.2 -0.1 -2.4 -0.1 -0.3 -0.1  4.3 -0.  -0.4 -0.1  0.4 -0.7 -1.1 -0.9 -2.  -0.5 -0.3 -0.3 -0.6  4.  -0.6 -0.   0.7  0.3 -0.5  1.1  6.2  0.1 -0.3 -0.2  2.  -0.2  4.7  5.6 -0.4 -0.9 -0.4 -0.8 -0.1 -4.2 -4.3  0.1 -0.1 -0.6  0.3  1.5 -0.8 -0.1 -0.3  0.  -0.1 -0.1 -0.1 -0.3 -0.2 -1.3 -0.1 -0.7  0.9 -0.  -0.4 -0.3  1.4  4.2 -0.5 -0.3 -1.8 -0.1 -0.1 -0.6  0.3 -0.1 -0.   0.2 -0.2 -0.1 -0.  -0.1 -0.1 -0.2  1.   2.5 -0.2 -0.9 -0.1 -1.4  0.1 -0.4 -1.3 -0.  -0.1 -1.1 -0.2 -0.2  8.5 -0.1 -0.2 -0.3 -0.4 -2.1 -1.7  0.7 -1.  -0.1 -0.2 -0.3 -0.2 -0.2 -0.2 -0.1 -0.2 -0.3 -0.4  4.1 -0.1 -0.4 -0.4 -0.1  7.5 -0.6 -0.2  1.3 -0.6  0.1 -0.4 -0.  -0.1 -0.6 -1.  -1.   0.2 -2.  -0.4 -0.2 -0.4 -0.2 -0.7 -0.1  1.8  1.2 -2.3 -0.7 -0.3  2.2  3.1 -0.2  0.9 -0.2 -0.1  4.  -1.  -0.8  1.2 -1.1 -0.3  0.2 -0.2  7.2  0.4  2.9  4.4]
ty_50sample [[1 8 0 7 9 5 3 2 6 4]
 [8 5 2 4 9 0 6 1 7 3]
 [4 8 1 9 0 5 7 2 6 3]
 [6 3 7 2 1 8 4 0 5 9]
 [1 8 7 6 2 4 9 0 3 5]
 [9 5 8 2 0 3 4 7 6 1]
 [3 6 5 2 9 8 0 7 4 1]
 [3 6 5 7 2 1 0 8 9 4]
 [2 9 7 3 5 4 0 1 8 6]
 [7 3 1 9 9 8 6 2 2 4]]
tt_50sample [[1 8 0 7 9 5 3 2 6 4]
 [8 5 2 4 9 0 6 1 7 3]
 [4 8 1 9 0 5 7 2 6 3]
 [6 3 7 2 1 8 4 0 5 9]
 [1 8 7 6 2 4 9 0 3 5]
 [9 5 8 2 0 3 4 7 6 1]
 [3 6 5 2 9 8 0 7 4 1]
 [3 6 5 7 2 1 0 8 9 4]
 [2 9 7 3 5 4 0 1 8 6]
 [7 3 1 9 8 0 6 2 5 4]]
vm  [-1.3  0.5 -4.4  0.2 -0.7  0.  -0.3 -0.2 -1.  -0.8  2.6 -0.1 -0.1 -0.1 -3.4  4.6 -0.4 -0.2 -0.7 -1.  -0.9 -0.1  1.4  1.1 -1.2  1.1 -0.2 -0.5 -0.3 -0.   2.6 -0.1 -0.1 -4.   0.1 -0.2  4.7  5.  15.  -0.   2.  -0.7  0.9  4.8 -0.3 -0.2  8.1 -0.5 -1.8  3.9 -0.3 -0.4 -0.  -0.6 -1.3  3.5 -0.6 -1.9 -1.4 -0.8  1.  -0.3 -0.2 -0.5  0.2 -0.1 -0.1 -0.  -0.4 -0.4 -0.3 -1.2 -0.1 -0.7  4.6  0.3  0.5 -0.1  0.5 -0.4  6.2  0.8 -0.1  0.3  2.7 -0.1  1.1 -0.2  0.1 -0.1  0.2  0.1  0.1  1.8 -0.6 -0.3 -0.6  0.1  0.8 -0.1  3.7 -1.5  0.9 -0.  -0.2 -0.6 -0.4  2.8  1.2 -1.4 -0.1 -0.1  0.  -0.3 -1.1  6.5 -0.3 -1.8  0.3 -0.6  0.   5.2 -0.1 -0.2 -0.3 -4.   0.2  3.9 -1.3 -1.3 -0.3 -0.1 -0.1 -0.3  4.4 -3.   0.2 -0.   0.6 -0.5 -0.2 -0.3 -0.7  0.  -0.1 -0.1 -0.2 -0.   5.2 -0.1 -0.3 -0.3 -0.6  0.3 -0.  -0.2 -0.3 -0.5  1.6 -0.1 -0.1 -1.  -0.2 -0.  -0.2 -0.2 -0.   0.1 -0.  -0.1 -0.1  0.1  0.3  0.9 -0.1 -0.8 -0.1 -0.1 -1.5 -0.4 -0.4 -0.2  0.1 -1.6 -0.2 -0.1 -1.1  0.6 -0.3  1.  -0.1 -0.4 -0.2 -1.2  1.4  5.2  0.9  3.8 -0.2 -0.1 -0.  -0.3 -0.1 -0.7 -0.1  1.9 -0.1 -0.3  4.2  0.7 -0.4  1.4 -0.4  8.2  0.3 -0.5 -2.1 -1.  -0.6 -0.3 -0.2 -0.3 -0.2 -0.8 -0.8  3.3 -0.2 -0.2 -0.3 -0.9 -1.  -0.6 -0.1  2.4 -0.5  7.3 -0.1 -0.1  0.2 12.1 -0.1  3.9 -0.2 -0.1 -0.8 -2.3 -0.1  0.  -0.9 -0.3 -1.8 -0.1  9.  -0.1 -0.1  6.2]
vy_50sample [[4 1 1 2 8 3 5 6 0 7]
 [1 8 7 5 0 4 3 6 2 9]
 [1 7 3 4 6 9 2 2 8 5]
 [5 4 2 0 7 1 3 6 8 9]
 [6 8 7 5 3 0 1 4 9 2]
 [9 2 4 6 7 0 5 1 3 8]
 [6 9 0 8 5 1 4 2 7 3]
 [9 4 1 8 6 2 0 7 3 5]
 [8 1 5 9 3 7 4 0 6 2]
 [0 5 1 2 9 3 4 7 6 8]]
vt_50sample [[4 1 9 2 8 3 5 0 6 7]
 [1 7 8 0 5 4 3 6 2 9]
 [1 7 3 4 6 9 0 2 8 5]
 [5 4 2 0 7 1 3 6 8 9]
 [6 8 7 5 3 0 1 4 9 2]
 [9 2 4 6 7 0 5 1 8 3]
 [6 9 0 8 5 1 4 2 7 3]
 [9 4 8 1 6 2 0 7 3 5]
 [8 1 5 9 3 7 4 0 6 2]
 [0 5 1 9 2 3 4 7 6 8]]
Epoch 38810: Training cost= 0.2786, Training acc= 0.8510, Validation cost= 0.2607, Validation acc= 0.8511
Epoch 38820: Training cost= 0.2891, Training acc= 0.8510, Validation cost= 0.2441, Validation acc= 0.8511
Epoch 38830: Training cost= 0.2567, Training acc= 0.8510, Validation cost= 0.2693, Validation acc= 0.8511
Epoch 38840: Training cost= 0.2456, Training acc= 0.8511, Validation cost= 0.2309, Validation acc= 0.8511
Epoch 38850: Training cost= 0.2416, Training acc= 0.8511, Validation cost= 0.2628, Validation acc= 0.8511
Epoch 38860: Training cost= 0.2246, Training acc= 0.8511, Validation cost= 0.2218, Validation acc= 0.8511
Epoch 38870: Training cost= 0.2272, Training acc= 0.8511, Validation cost= 0.2353, Validation acc= 0.8512
Epoch 38880: Training cost= 0.2340, Training acc= 0.8511, Validation cost= 0.3039, Validation acc= 0.8512
Epoch 38890: Training cost= 0.2280, Training acc= 0.8511, Validation cost= 0.2497, Validation acc= 0.8512
Epoch 38900: Training cost= 0.2647, Training acc= 0.8511, Validation cost= 0.2408, Validation acc= 0.8512
tm  [-0.7  2.2 -0.3  6.6 -0.8 -0.6 -0.  -0.2  0.5 -0.4 14.9 -0.2 -0.4  0.2 -1.   4.7  1.6 -0.1 -0.1 -0.3 -0.8 -0.6 -1.2 -0.1 -1.   0.8 -0.6 -0.1 -0.2 -3.2  1.8 -0.2 -0.8  5.5 -0.3 -0.5 -0.4  5.1  3.   0.2 -0.7 -0.4 -0.7 -1.2 -0.4 -0.2 -0.2 -0.5  2.3 -4.1 -0.2 -0.3 -0.3 10.  -1.3  0.4  1.   7.8  4.6 -1.2 -0.2 -0.4 -0.4 -0.3  0.6 -0.5 -0.1  0.7 -0.9 -0.1 -0.2 -1.1  1.6  1.  -3.8 -0.1 -0.6 -0.3 -0.2 -0.5 14.3 -0.4 -0.4 -0.6 -1.3 -0.  -0.6  0.1 -0.1 -0.6 -0.4 -0.2  0.2 -0.5 -0.7 -0.  -0.  -2.2 -0.4 -0.7  0.8 -2.2 -0.6 -0.2 -0.2  1.1 -1.4  1.4 -0.1 -1.   2.4 -0.1 -0.1 -0.3  0.3  6.  -0.3  0.1 -0.1  0.8 -0.7  1.7 -0.2  1.6  0.3 -1.4  0.5 -2.2  7.   3.6  1.1 -0.1 -0.5  0.6  7.5 10.4  0.1  0.2  0.8 -0.5 -0.8 -0.5 -0.9 -0.  -0.  -0.3  0.5 -0.2  7.2 -0.  -0.7 -0.1 -0.5 -0.1 -0.1 -0.1 -0.4 -0.3  0.4  1.3 -0.6 -0.8  0.  -0.2 -0.2  1.7 -0.2  0.3 -0.3 -0.2 -0.3 -0.1 -0.3 -0.3 -0.4 -1.4  1.  -0.2  0.1  0.4 -1.2 -0.2 -0.3 -1.8 -0.3 -0.3  1.2 -0.2 -0.2  9.5 -0.3 -0.4 -0.5 -1.2  3.7 -2.3  0.7 -0.2 -0.4 -0.3 -0.5 -0.2 -0.5 -0.4  0.5 -0.6 -0.3 -0.2 -4.7  0.5 -0.4  3.  -0.8 -0.   0.5 -0.3  3.9 -1.  -1.  -0.5 -0.2  0.3 -0.2 -1.2 -0.6 -0.5  0.9  1.2  1.3  1.6 -0.7 -0.2 -0.5 -2.3 -0.6  0.4 -0.5 -0.8  0.5 -1.3 -0.3 -0.4  0.  -0.2 -3.  -1.  -0.3 -0.5 -1.2  0.4 -3.9  0.3  1.7 -0.3 -0.  -0.5]
ty_50sample [[2 3 5 9 6 1 0 4 7 8]
 [3 2 5 7 8 0 4 1 9 6]
 [1 4 5 0 3 3 8 7 6 2]
 [0 8 9 6 3 2 1 5 4 7]
 [2 0 0 4 5 8 9 1 7 3]
 [3 1 6 0 8 9 5 7 2 4]
 [3 7 2 4 0 8 1 9 5 6]
 [9 3 2 6 1 4 0 7 5 8]
 [3 8 9 7 0 0 1 6 5 2]
 [1 2 5 8 3 0 4 6 7 9]]
tt_50sample [[2 3 5 9 6 1 0 4 7 8]
 [3 2 5 7 8 0 4 1 9 6]
 [1 4 5 0 9 3 8 7 6 2]
 [0 8 9 3 6 2 1 5 4 7]
 [2 6 0 4 5 8 9 1 7 3]
 [3 1 6 0 8 9 5 2 7 4]
 [3 7 2 4 0 1 8 9 5 6]
 [9 2 3 6 1 0 4 7 5 8]
 [3 8 9 7 0 4 1 6 5 2]
 [1 2 5 8 3 0 4 6 7 9]]
vm  [-0.9 -1.2  9.7  5.8 -1.9 -0.3 -0.  -0.  -0.2  1.8 -5.2 -0.6 -0.4 -0.3 10.5 -1.2 -0.6 -0.3 -0.5  3.4 -1.  -0.1  0.7  0.1 -1.   2.5  0.4 -0.1 -1.3 -0.2 -2.5 -0.2 -0.2 -2.2 -0.1 -0.3  0.4 -0.9 -4.  -0.4  2.   2.3  0.1 -1.1 -0.3 -0.6 -2.2 -0.8  0.7 13.7 -0.3 -0.2 -0.4  6.2 -0.3 -0.9 -0.5  4.9  0.9  8.8  3.5 -0.5  1.6 -0.5 -1.6 -0.7 -0.2 -0.2  1.6 -0.5 -0.9  3.5 -0.4 -0.6 -5.3 -0.2  0.1  1.4 -0.2 -0.1 -7.   1.3 -0.4 -0.2 -1.2  3.2 -1.6  0.5 -0.4 -0.1 -0.1 -0.  -0.2 -0.4 -0.8 -0.3  0.3 -3.2 -0.  -0.6 -0.7  6.2 -0.6 -0.  -0.1 -0.2 -2.6 -1.8 -1.4  0.7 -0.1 -0.1 -0.3 -0.2  3.5 -2.  -0.8  0.8  0.5 -0.4  0.7 -0.9 -0.1 -0.4 -0.3 13.1 -0.2 -0.8 -0.3  4.5  1.4 -0.5 -0.3  0.5  3.6 -1.9 -0.2 -0.2 -0.4  3.   0.7 -1.2  0.5 -0.3 -0.1  0.3 -0.6  0.2 -1.2 -0.5 -0.7 -0.1  0.9  1.  -0.4 -0.2 -0.8  0.6 -1.1 -0.3  1.9 -0.   0.   0.6 -0.1 -0.8 -0.7 -0.4 -0.1 -0.2 -0.5 -0.4  0.6 -0.1 -0.1  1.7 -1.3 -0.1  6.  -0.2 -0.1 -1.1 -0.3 -1.7  0.4 -0.4 -0.5 -0.5 -0.1 -0.2  0.7 -0.5  0.9 -0.4 -0.9  1.6 -1.3 -1.2  1.  -0.1 -0.  -0.2  0.4 -0.6 -0.3 -2.4  0.1 -0.3  9.6 -0.  -0.6 -0.9 -0.6  2.5 -1.7  0.8  7.1 -0.4 -0.3  0.3 -0.1 -0.3 -0.8 -1.7  5.6 -0.5 -1.5 -0.3 -0.5 -0.   0.2  0.4 -0.2  2.6 -0.2 -2.1  1.3 -1.4  1.8 -1.4 -0.1 -0.6 -0.4 -0.3 20.5  1.7 -0.9 -0.4 -0.8 -0.8 18.5 -0.2 -2.4  0.2  0.2 -0.7]
vy_50sample [[8 0 6 7 1 5 5 3 9 4]
 [9 1 6 4 0 8 7 2 2 5]
 [1 7 9 5 8 3 2 6 4 0]
 [6 0 2 4 5 9 3 7 8 1]
 [6 1 8 3 5 4 4 7 0 2]
 [8 8 2 4 4 6 0 7 1 5]
 [1 5 7 8 4 0 6 9 3 2]
 [9 0 8 6 4 5 3 7 1 2]
 [9 7 5 8 4 0 3 1 2 6]
 [7 4 2 1 3 9 6 5 0 8]]
vt_50sample [[8 0 6 7 1 2 5 3 9 4]
 [9 1 6 0 4 8 7 2 3 5]
 [1 7 9 5 8 3 2 6 4 0]
 [6 0 2 4 5 9 3 7 8 1]
 [6 1 8 3 5 9 4 7 0 2]
 [8 3 2 9 4 6 0 1 7 5]
 [1 5 7 8 4 0 6 9 3 2]
 [9 0 8 6 4 5 3 7 1 2]
 [9 7 5 8 4 0 3 1 2 6]
 [7 4 2 1 3 9 6 5 0 8]]
Epoch 38910: Training cost= 0.3013, Training acc= 0.8511, Validation cost= 0.2738, Validation acc= 0.8512
Epoch 38920: Training cost= 0.2341, Training acc= 0.8512, Validation cost= 0.2279, Validation acc= 0.8512
Epoch 38930: Training cost= 0.2767, Training acc= 0.8512, Validation cost= 0.2663, Validation acc= 0.8512
Epoch 38940: Training cost= 0.2614, Training acc= 0.8512, Validation cost= 0.3275, Validation acc= 0.8512
Epoch 38950: Training cost= 0.2622, Training acc= 0.8512, Validation cost= 0.2942, Validation acc= 0.8512
Epoch 38960: Training cost= 0.2729, Training acc= 0.8512, Validation cost= 0.2578, Validation acc= 0.8513
Epoch 38970: Training cost= 0.2190, Training acc= 0.8512, Validation cost= 0.2947, Validation acc= 0.8513
Epoch 38980: Training cost= 0.2852, Training acc= 0.8512, Validation cost= 0.2734, Validation acc= 0.8513
Epoch 38990: Training cost= 0.2335, Training acc= 0.8512, Validation cost= 0.2424, Validation acc= 0.8513
Epoch 39000: Training cost= 0.2451, Training acc= 0.8513, Validation cost= 0.2645, Validation acc= 0.8513
tm  [-1.3  0.1  4.2  5.  -1.2 -0.1 -0.  -0.1  1.7 -0.4 11.2 -0.3 -0.3 -0.5  2.4  5.5  1.4 -0.4 -0.   2.3 -1.  -0.1 -0.1 -0.1 -1.5  4.2 -0.1 -0.2  1.4 -2.6 -0.3 -0.5 -0.7  3.1 -0.3 -0.2 -0.   5.  -0.8  0.2 -0.2  1.4 -0.6 -1.  -0.3 -0.4 -1.7 -0.5 -0.8 -0.6 -0.5 -0.1  0.9 12.1 -1.2 -0.4 -0.2  8.1  5.   3.4  6.7 -0.3  1.1 -0.2  0.7  0.5  0.1 -0.  -0.6 -0.1 -0.3 -1.4 -0.   1.1 -4.8  2.2 -0.4  1.1 -0.  -0.3  0.3 -0.3 -0.1 -0.2 -0.1  4.2 -2.3 -0.1  0.6 -0.2 -0.4 -0.1 -0.  -0.8 -0.7 -0.2  1.2 -2.9 -0.5 -0.6  1.  -0.1 -0.5 -0.2 -0.2  1.  -1.8 -0.   0.8 -0.   1.  -0.1 -0.1 -0.7  0.3  9.2  0.1 -0.2  0.   0.9 -0.3 -0.5  0.1 -0.1 -0.1  3.1  0.1 -2.8  5.   3.6 -0.2 -0.3 -0.8  0.3  4.1  5.2 -0.2 -0.  -0.1 -0.2 -0.5 -0.5 -0.5 -0.  -0.  -0.1  1.1 -0.2  4.2 -0.3 -0.5 -0.  -1.1 -0.1 -0.3  0.4 -0.7 -0.2  0.8 -0.2  0.  -0.5  1.3 -0.1 -0.2 -0.3 -0.2  0.2 -0.2 -0.2 -0.3 -0.1 -0.5 -0.3 -0.2 -0.7 -0.4  0.2  2.4  0.3 -0.7 -0.1 -0.5 -2.1 -0.1 -0.3 -0.5 -0.5 -0.1  7.9 -0.1 -0.2 -0.2 -0.9 -2.4 -1.7 -0.4 -0.4 -0.1 -0.1 -0.2 -0.1 -0.  -0.3 -0.1 -1.3 -0.  -0.3 -1.6 -0.3 -0.5  4.1 -0.1  6.9 -0.7 -0.   4.7 -0.8 -0.4 -0.7 -0.2 -0.  -0.  -1.1  2.1  1.4  1.   0.5  2.5 -0.2 -0.2 -0.2 -0.5 -0.8 -0.6 -0.7 -0.5 -1.1  1.4 -1.9 -0.  -0.4 -0.1 -0.3  1.9 -0.2 -0.4 -0.3 -1.1 -0.1 -0.1 -0.  -0.6  0.  -1.  -0.4]
ty_50sample [[2 1 5 6 3 7 8 8 0 4]
 [6 1 8 9 5 0 4 3 2 7]
 [8 3 6 2 1 4 7 5 9 0]
 [6 7 9 3 0 5 1 8 8 2]
 [9 2 7 5 4 6 1 8 3 0]
 [8 4 5 1 3 7 9 0 6 2]
 [9 6 7 4 2 0 5 3 1 8]
 [7 9 3 1 0 5 8 2 4 6]
 [6 7 1 2 4 9 0 3 8 5]
 [9 2 3 1 6 4 0 8 5 7]]
tt_50sample [[2 1 5 6 3 7 8 0 9 4]
 [6 1 8 9 5 0 4 3 2 7]
 [8 3 2 6 1 4 7 5 9 0]
 [6 7 9 3 0 5 1 8 4 2]
 [9 2 7 5 4 6 1 8 3 0]
 [8 4 5 1 3 7 9 0 6 2]
 [9 6 7 4 2 0 5 3 1 8]
 [7 9 3 1 0 5 8 2 4 6]
 [6 7 1 2 4 9 0 3 8 5]
 [9 2 3 6 1 4 0 8 5 7]]
vm  [ 3.1 -0.7  4.5 -0.3 -1.7 -0.2  0.2  0.4 -0.5  1.9  5.6 -0.5 -0.3 -0.2  7.4 -0.6 -0.3 -0.5 -0.2 -0.  -0.8 -0.1  0.6 -0.3 -1.2  1.2 -0.2 -0.1 -1.4 -1.4 -0.2 -0.2 -0.8  2.7  0.3 -0.   0.8  4.7  0.  -0.4 -0.2  6.8  0.7  0.7 -0.2 -0.4 -0.9 -0.5  6.3  7.3 -0.4  0.2 -0.6 11.7  1.5 -0.8 -0.6  5.3  2.5  2.8 -0.2 -0.5 -0.6  0.3  0.3 -0.4  0.8  0.7  0.2 -0.2 -0.1  5.6 -0.5 -0.7 -4.8 -0.8 -0.6 -0.5  0.3 -0.6 -2.4  0.9 -0.3 -0.3 -2.   6.5  5.6 -0.3  0.5 -0.1 -0.1 -0.  -0.2 -0.4 -0.4 -0.1 -0.6 -2.8  0.1 -0.  -0.8  5.  -1.3 -0.2 -0.2 -0.2 -2.5 -0.3  0.3 -0.2 -0.  -0.4 -0.1 -0.3  3.7 -3.1 -0.6  0.3 -0.3  0.8 -0.2 -0.2  0.1 -0.7 -0.2  8.7 -0.1 -2.6  2.3  1.1  1.9 -0.4  0.3  0.  -2.4 -1.9 -0.2  0.1 -0.5 -0.7 -0.6 -1.3 -0.5  0.1  0.5 -0.4 -0.3  0.   3.8 -0.1 -0.  -0.2  4.  -0.2 -0.1 -0.1  0.5 -0.3 -0.4 -0.2 -0.2 -1.2  0.5 -0.1 -0.  -0.3 -0.5 -1.  -0.1  0.  -0.3  0.2 -0.4  0.1 -0.2 -0.7 -0.4 -0.8  0.6 -0.3 -2.1 -0.5 -0.4 -1.7 -0.2 -0.4  1.5 -0.5  0.1  3.8 -0.3 -0.3 -0.3 -0.9  5.  -0.8 -1.3 -0.9 -0.2  0.1 -0.  -0.1 -0.6 -0.3 -0.3 -3.  -0.2 -0.3 -2.4 -0.1 -0.2 -2.4 -0.8 -2.4 -0.6 -0.3 -0.  -1.  -0.5 -0.2 -0.  -0.2  0.3 -1.1  2.1 -1.6  0.4 -0.2  1.2  4.  -1.   1.8 -0.1 -1.1  0.9 -0.9  2.3 -1.4  1.3 -5.1 -0.  -1.7 -0.  -0.1  8.7  3.1 -0.2 -0.6 -0.9 -0.3  5.8 -0.2  0.1 -0.2 -1.2  1.6]
vy_50sample [[0 5 2 7 8 4 6 9 3 1]
 [9 3 0 2 2 5 6 7 8 4]
 [5 5 2 9 1 3 0 4 7 7]
 [6 4 4 2 0 3 1 8 7 5]
 [2 6 3 9 5 0 1 4 8 7]
 [3 2 1 7 0 9 5 4 8 6]
 [9 5 5 4 1 8 3 6 2 7]
 [1 2 0 5 3 6 4 8 9 7]
 [7 2 6 8 9 5 3 0 4 1]
 [2 3 5 6 8 7 0 1 9 4]]
vt_50sample [[0 5 2 7 8 4 6 9 3 1]
 [9 3 0 1 2 5 6 7 8 4]
 [6 5 2 9 1 3 0 4 8 7]
 [6 4 9 2 0 3 1 8 7 5]
 [2 6 3 9 5 0 1 4 8 7]
 [3 2 1 7 0 9 5 4 8 6]
 [9 0 5 4 1 8 3 6 2 7]
 [1 2 5 0 3 6 4 8 9 7]
 [7 2 6 8 9 5 3 0 4 1]
 [2 3 5 6 8 7 0 1 9 4]]
Epoch 39010: Training cost= 0.2697, Training acc= 0.8513, Validation cost= 0.2705, Validation acc= 0.8513
Epoch 39020: Training cost= 0.2621, Training acc= 0.8513, Validation cost= 0.3052, Validation acc= 0.8513
Epoch 39030: Training cost= 0.2190, Training acc= 0.8513, Validation cost= 0.2886, Validation acc= 0.8513
Epoch 39040: Training cost= 0.2530, Training acc= 0.8513, Validation cost= 0.3068, Validation acc= 0.8513
Epoch 39050: Training cost= 0.2599, Training acc= 0.8513, Validation cost= 0.2562, Validation acc= 0.8514
Epoch 39060: Training cost= 0.2689, Training acc= 0.8513, Validation cost= 0.2790, Validation acc= 0.8514
Epoch 39070: Training cost= 0.2638, Training acc= 0.8513, Validation cost= 0.3231, Validation acc= 0.8514
Epoch 39080: Training cost= 0.2880, Training acc= 0.8513, Validation cost= 0.2742, Validation acc= 0.8514
Epoch 39090: Training cost= 0.2726, Training acc= 0.8513, Validation cost= 0.2612, Validation acc= 0.8514
Epoch 39100: Training cost= 0.2610, Training acc= 0.8514, Validation cost= 0.2622, Validation acc= 0.8514
tm  [ 1.7 -0.3 -1.3  3.9 -1.3 -0.   0.2 -0.1 -0.9 -0.1  8.6 -0.6 -0.1  0.4 -1.5 -0.5  0.2 -0.6 -0.3 -1.3 -1.1  0.4 -0.4 -0.3 -1.   2.1 -0.3 -0.4 -1.7 -0.3  3.8 -0.3  0.9  5.7  0.4  0.4  4.8  2.3  4.8 -0.3  2.7 -1.5  1.7  2.5 -0.1 -0.   8.4 -0.2  4.7 -1.9 -0.4 -0.  -0.3 -0.1  2.3  1.6 -0.6 -2.2 -0.5 -2.2 -2.4 -0.2 -0.5  1.   0.2 -0.1 -0.  -0.5 -0.2 -0.1 -0.1  6.3 -0.5 -0.5  3.  -0.2 -0.1  0.2 -0.  -0.2 19.   0.6 -0.5  0.1 -1.5 -1.3  7.5 -0.2 -0.2 -0.1 -0.1 -0.3  0.   0.6 -0.4  0.5 -0.3 -0.5  0.3  1.7  0.5 -0.2 -0.7 -0.  -0.3 -0.2 -0.2  1.4  0.1 -1.9 -0.7 -0.2 -0.2  0.4  3.  -3.1 -0.  -0.8 -0.3 -0.4 -0.1  8.  -0.2 -0.6  0.2 -1.8  0.1  2.  -1.2 -0.7 -0.2 -0.2 -0.2 -0.1  4.4  9.8 -0.4 -0.1 -0.5 -0.1 -0.9 -0.9 -0.3 -0.2 -0.1 -0.2 -0.4  0.  -0.8 -0.3 -0.4 -0.1  1.9 -0.7 -0.2  0.1 -0.1 -0.2 -0.6 -0.5  0.5 -0.6 -0.1  0.1 -0.  -0.3 -0.6 -0.8 -0.3 -0.3  0.1 -0.4 -0.1 -0.1 -0.1  1.9 -1.2 -0.2 -0.4 -0.2 -0.4 -0.1 -0.2 -1.4 -0.1 -0.4  1.  -0.5  0.2  0.9 -0.2 -0.3 -0.2 -0.8 15.9  3.9 -0.2 -0.7  0.1 -0.2  0.1 -0.1 -0.1 -0.4  0.2  0.9 -0.1  0.4  2.2 -0.  -0.2 -2.5 -0.4 -1.5 -0.4  0.1 -0.7 -1.1 -0.5 -0.1  0.3 -0.3 -0.2 -1.1 -0.  -1.7  0.8 -0.1 -0.3  2.5 -0.7 -0.8  0.3  2.1  4.   3.   1.3  1.3 -0.  19.1 -0.   6.5 -0.2 -0.4 -3.9 -1.7 -0.  -0.1 -1.  -0.7 -5.  -0.1  3.5 -0.2 -0.5  4.1]
ty_50sample [[0 9 4 2 3 7 7 8 5 1]
 [3 4 7 9 5 6 8 2 1 0]
 [8 7 1 6 3 0 2 9 5 4]
 [4 0 2 5 3 1 7 8 6 6]
 [4 3 5 7 0 6 8 1 9 2]
 [9 2 3 1 7 4 6 0 5 8]
 [8 6 7 5 2 1 9 3 4 0]
 [8 8 0 9 5 1 4 2 3 6]
 [6 2 9 3 4 0 5 8 7 1]
 [8 1 2 5 6 4 0 7 7 3]]
tt_50sample [[0 9 4 2 3 6 7 8 5 1]
 [3 4 7 9 5 6 8 2 1 0]
 [7 8 1 6 3 0 2 9 5 4]
 [4 0 2 5 3 1 7 9 8 6]
 [4 3 5 7 0 6 8 1 9 2]
 [9 2 3 1 7 4 6 0 5 8]
 [8 6 7 5 2 1 9 3 4 0]
 [7 8 0 9 5 1 4 2 3 6]
 [6 2 9 3 4 0 5 8 7 1]
 [8 1 2 5 6 4 0 7 9 3]]
vm  [-1.5 -0.1 -3.6  4.5 -1.3  0.2  0.1 -0.  -0.6 -0.2  5.3 -0.7  0.2 -0.3 -2.8 -0.5  0.5 -0.3 -1.  -0.1 -1.3 -0.2 -0.5 -0.1 -0.5  2.7 -0.6 -0.7 -1.2 -0.1  3.1 -0.2 -0.5  1.   0.1  0.   1.7 -1.7 -1.3 -0.4  2.6  1.7  0.2  0.5 -0.3  0.4  0.6  1.   0.9 -2.  -0.2 -0.2  1.7 -1.2 -0.5  3.2 -0.1 -1.4  0.5 -2.7 -0.6 -0.3  0.3 -0.2 -1.  -0.4 -0.5 -0.6 -0.2 -0.3  0.6 -0.3  1.2  3.3 -0.9 -0.9 -0.  -0.2  0.4 -0.6 19.2  0.9 -0.2 -0.6 -0.4  1.3  2.9 -0.4 -0.2 -1.  -0.  -0.2  0.4 -0.1 -0.7  0.2 -0.5 -1.7  0.7 -0.1 -0.1 -1.   1.2  0.4 -0.2 -0.5  1.1  2.1  1.3 -2.2 -1.  -0.1 -0.2  0.8  1.5  0.9 -0.1 -0.6 -0.2 -0.5 -0.   6.3 -0.  -0.1 -0.3 -3.6  0.5  6.9  1.3 -1.4 -0.5 -0.   0.6  0.8 17.8 19.9 -0.3 -0.3 -0.2 -0.8  3.9 -0.7 -0.1  0.2 -0.1 -0.4 -0.1 -0.   4.4 -0.2 -0.4 -0.3 -1.4  2.1 -0.2 -0.1 -0.1  1.  -0.7 -0.2  0.4  1.5 -0.3 -0.2 -0.2 -0.4 -0.2  0.3  0.9 -0.1 -0.3 -0.   0.1 -0.3 -0.1 -0.5 -0.6  1.2  1.7 -0.1 -0.6 -0.2 -0.6 -1.1 -0.2 -0.1 -0.4  1.3 -0.6 -0.1 -0.2 -0.2 -0.1 -0.8  5.7 -0.1  3.1 -0.4  0.3 -0.   0.4  0.6 -0.2 -0.7 -0.1  4.1 -0.4 -0.1 -2.5 -0.3 -0.9  0.1 -1.3  6.2 -1.  -0.6  0.8 -0.6 -0.7  0.9 -0.  -0.2 -0.4 -0.5  4.7 -1.2 -2.4 -0.5  0.2  0.   4.6 -1.7 -0.2 -1.   1.4  6.8 -0.5  2.3  3.7  8.9 -0.2  2.8 -0.3 -0.  -4.  -2.  -0.8  1.5 -1.6 -0.4 -5.1 -0.  -0.7 -0.2  3.5  6.5]
vy_50sample [[6 9 4 1 0 5 3 2 7 8]
 [4 8 0 1 7 2 3 9 5 6]
 [9 3 5 0 6 7 1 2 4 8]
 [5 6 3 8 7 0 2 4 9 1]
 [2 4 1 5 0 9 6 3 7 8]
 [3 7 4 5 2 0 1 6 9 8]
 [7 1 8 6 9 5 3 0 4 2]
 [5 3 0 7 8 6 4 1 2 2]
 [8 0 4 2 9 9 6 7 7 1]
 [2 2 8 9 3 6 5 4 0 1]]
vt_50sample [[6 9 4 0 1 3 5 2 8 7]
 [4 0 8 1 7 2 3 9 5 6]
 [9 3 0 5 6 7 1 2 4 8]
 [5 6 3 8 7 0 2 4 9 1]
 [2 4 1 5 0 9 3 6 7 8]
 [3 4 7 5 2 0 1 6 9 8]
 [7 1 8 6 9 5 3 0 4 2]
 [5 3 0 7 8 6 4 1 2 9]
 [8 0 4 2 9 3 6 5 7 1]
 [2 7 8 3 9 5 6 4 0 1]]
Epoch 39110: Training cost= 0.2137, Training acc= 0.8514, Validation cost= 0.2524, Validation acc= 0.8514
Epoch 39120: Training cost= 0.3030, Training acc= 0.8514, Validation cost= 0.2641, Validation acc= 0.8514
Epoch 39130: Training cost= 0.2758, Training acc= 0.8514, Validation cost= 0.2230, Validation acc= 0.8515
Epoch 39140: Training cost= 0.2453, Training acc= 0.8514, Validation cost= 0.2211, Validation acc= 0.8515
Epoch 39150: Training cost= 0.2777, Training acc= 0.8514, Validation cost= 0.2629, Validation acc= 0.8515
Epoch 39160: Training cost= 0.2557, Training acc= 0.8514, Validation cost= 0.2215, Validation acc= 0.8515
Epoch 39170: Training cost= 0.2722, Training acc= 0.8514, Validation cost= 0.2308, Validation acc= 0.8515
Epoch 39180: Training cost= 0.1896, Training acc= 0.8515, Validation cost= 0.2536, Validation acc= 0.8515
Epoch 39190: Training cost= 0.2532, Training acc= 0.8515, Validation cost= 0.2305, Validation acc= 0.8515
Epoch 39200: Training cost= 0.2774, Training acc= 0.8515, Validation cost= 0.1982, Validation acc= 0.8515
tm  [ 0.6 -0.2 -0.3  1.3 -1.5 -0.2  0.7 -0.2 -1.  -0.7  5.3 -0.6  0.2  0.4 -0.1 -1.  -0.2 -0.6 -0.5 -1.6 -1.2 -0.2 -0.7 -0.  -0.7  1.1 -0.3 -0.4 -1.7  1.9  4.4 -0.1  0.9 10.8 -0.1  0.5  4.8 -0.1  5.6 -0.3  3.2 -2.6  1.8  3.2  0.2 -0.   9.3  0.1  2.3 -2.6 -0.5 -0.1 -0.5 -1.   1.9 -0.  -0.5 -3.4 -0.8 -2.8 -2.  -0.  -0.6 -0.1 -0.1 -0.3  0.5 -0.6  0.9  0.1 -0.1  5.5 -0.5 -0.4  3.1 -0.3  0.4 -0.1  0.4 -0.4 18.7  0.3 -0.6  0.1 -1.  -2.7  7.2 -0.1 -0.3  0.8 -0.1 -0.2  0.   1.6 -0.4 -0.  -0.3 -0.3  0.2  1.5  1.8  2.1 -0.3 -0.1 -0.5 -0.4 -0.6  1.5  0.7 -2.1 -0.9 -0.1 -0.2 -0.   2.8 -2.7  0.1 -0.7 -0.2 -0.3 -0.   7.9  0.2 -0.3 -0.  -0.1 -0.1  5.4 -1.5 -0.1 -0.1 -0.1 -0.4 -0.3 -1.2  9.4 -0.3 -0.2 -0.4 -0.4 -0.4 -0.7  0.2 -0.  -0.1  0.2 -0.3  0.2 -2.4 -0.3 -0.3 -0.3  0.8 -0.1 -0.3  0.8 -0.3 -0.3 -0.8 -0.8 -0.  -0.6 -0.1 -0.1 -0.  -0.  -0.6 -0.6 -0.3 -0.3  0.2 -0.2 -0.1 -0.1 -0.2  5.1 -1.  -0.4 -0.3 -0.1  1.2 -0.3 -0.1 -1.3 -0.1 -0.4 -0.  -0.7  0.7 -0.5 -0.1 -0.4 -0.7 -0.8 13.2  5.5 -0.5 -0.5 -0.  -0.1 -0.3 -0.  -0.5 -0.3  0.1 -0.3 -0.   0.7  4.5  0.5 -0.4 -2.4 -0.1 -1.  -0.3  0.3 -1.1 -1.  -0.2 -0.2  0.9 -0.3 -0.1 -1.1 -0.6 -1.6 -0.4 -0.5 -0.7  1.8 -0.8 -0.5 -0.1  2.5  3.7  1.5  1.   1.  -0.1 23.7 -0.   7.9 -0.1 -0.3 -3.9 -1.3 -0.  -0.2 -0.8 -0.7 -5.  -0.3  3.8 -0.4  2.9  1.9]
ty_50sample [[0 0 9 7 3 6 2 8 1 5]
 [4 5 6 2 9 9 3 7 8 1]
 [2 5 1 4 7 0 3 8 6 9]
 [8 7 0 4 3 9 5 6 2 1]
 [7 9 2 3 0 8 1 6 4 5]
 [2 1 3 4 8 6 5 0 9 7]
 [3 0 8 6 7 4 1 5 9 2]
 [8 9 0 0 2 2 7 1 6 5]
 [3 9 4 2 8 6 6 0 1 7]
 [7 1 2 6 4 5 8 3 9 0]]
tt_50sample [[0 9 4 3 7 6 2 8 1 5]
 [5 4 6 2 9 0 3 7 8 1]
 [2 5 1 4 7 0 3 8 6 9]
 [8 7 0 4 9 3 5 2 6 1]
 [7 2 9 3 0 8 1 6 4 5]
 [2 1 3 4 8 6 5 0 9 7]
 [3 0 8 6 7 4 1 5 9 2]
 [8 9 0 4 3 2 7 1 6 5]
 [3 9 4 2 5 8 6 0 1 7]
 [7 1 2 6 4 5 8 3 9 0]]
vm  [-1.3 -0.3  3.3 -1.7 -2.1 -0.3  0.6 -0.3 -0.2 -0.4  3.  -0.3 -0.3 -0.   8.3 -0.  -0.2 -0.2 -0.1 -0.7 -1.5 -0.2 -0.5 -0.4 -1.2 -0.3 -0.2 -0.2  0.  -1.1  3.8 -0.7  0.3 13.9 -0.2 -0.1  1.2  2.3  7.6 -0.4  0.2  2.7  0.2  4.4 -0.3 -0.2  1.7 -0.1 -2.4 -1.7 -0.4 -0.1 -0.7 -0.7 -1.7 -1.  -0.7  2.9  1.5 -2.1  7.6 -0.4 -0.1 -0.5  3.8 -0.6 -0.5 -0.3  1.2 -0.1 -0.2 -0.9 -0.3 -0.5 -3.5 -0.4 -0.  -0.2 -0.1 -0.2  7.9 -0.3 -0.3 -0.1  2.   3.2 -1.  -0.  -0.1 -0.2 -0.4 -0.  -0.3  0.1 -0.6 -0.2 -0.  -2.  -0.2 -0.3  3.   4.1  1.5 -0.3  0.1 -0.4 -2.8  2.   1.  -0.7 -0.3 -0.1 -0.3 -0.9  0.6  5.  -0.1 -0.1 -0.1 -0.4 -0.1  1.3 -0.4 -0.4 -0.5 10.6 -0.1  4.8  4.7  3.9 -0.7 -0.1 -0.4 -0.1 -6.1 -0.1 -0.  -0.1 -0.  -0.8  0.9  0.3  0.6 -0.3 -0.3 -0.1 -0.4  0.3  0.9 -0.3  0.9  0.2 -1.8 -0.5 -0.1 -0.1 -0.4 -0.2  2.3 -0.5 -0.2 -2.  -0.1 -0.1 -0.1  1.1 -0.2  0.6 -0.4  0.1 -0.2 -0.2 -0.2 -0.1 -0.3  0.7 -0.  -0.8 -0.6 -0.  -1.8 -0.3  0.9 -1.3 -0.1 -0.4 -1.1 -0.6 -0.2  3.3 -0.3 -0.6 -0.6 -1.  -2.5 -1.  -1.  -0.1  0.2 -0.2 -0.3 -0.3 -0.1 -0.5 -0.2 -2.7 -0.2 -0.1 -4.1 -0.1 -0.8  0.7 -0.2  8.1 -0.  -0.  -2.  -1.  -0.2 -0.  -0.1 -0.3 -0.4 -1.3 -1.4 -0.1 -1.4 -0.4 -1.2 -0.3 -0.9  3.9 -0.5 -1.7 -0.7 -0.2  0.  -1.1 -0.  -3.3 -0.1 -1.1  0.1 -0.2 -1.3  0.6 -0.4 -0.5 -0.9  1.1 -2.3 -0.3  5.   0.2  3.4 -0.4]
vy_50sample [[1 7 5 4 3 9 0 2 8 6]
 [1 7 6 5 2 8 3 0 9 4]
 [1 2 0 8 9 3 6 7 5 4]
 [3 3 1 9 9 0 7 8 4 6]
 [6 1 9 4 8 5 5 0 3 2]
 [3 1 6 0 7 8 2 9 5 4]
 [7 1 8 2 3 9 5 6 0 4]
 [8 8 4 5 1 2 9 7 6 0]
 [3 8 1 6 7 2 4 0 5 9]
 [5 8 0 9 6 1 7 4 2 3]]
vt_50sample [[1 7 5 4 3 9 0 2 8 6]
 [1 7 6 2 5 8 3 0 9 4]
 [1 2 0 8 3 9 6 7 5 4]
 [3 2 1 5 9 0 7 8 4 6]
 [6 1 9 4 8 5 0 7 3 2]
 [3 1 6 0 7 8 2 9 5 4]
 [7 1 8 2 3 9 5 6 0 4]
 [3 8 4 5 1 2 9 7 6 0]
 [3 8 1 6 7 2 4 0 5 9]
 [5 8 0 9 6 1 7 4 2 3]]
Epoch 39210: Training cost= 0.2530, Training acc= 0.8515, Validation cost= 0.2385, Validation acc= 0.8516
Epoch 39220: Training cost= 0.2742, Training acc= 0.8515, Validation cost= 0.2815, Validation acc= 0.8516
Epoch 39230: Training cost= 0.3286, Training acc= 0.8515, Validation cost= 0.2815, Validation acc= 0.8516
Epoch 39240: Training cost= 0.2354, Training acc= 0.8515, Validation cost= 0.2573, Validation acc= 0.8516
Epoch 39250: Training cost= 0.2509, Training acc= 0.8515, Validation cost= 0.2450, Validation acc= 0.8516
Epoch 39260: Training cost= 0.2205, Training acc= 0.8516, Validation cost= 0.2319, Validation acc= 0.8516
Epoch 39270: Training cost= 0.2306, Training acc= 0.8516, Validation cost= 0.2422, Validation acc= 0.8516
Epoch 39280: Training cost= 0.2532, Training acc= 0.8516, Validation cost= 0.2441, Validation acc= 0.8516
Epoch 39290: Training cost= 0.2241, Training acc= 0.8516, Validation cost= 0.2533, Validation acc= 0.8516
Epoch 39300: Training cost= 0.2882, Training acc= 0.8516, Validation cost= 0.2273, Validation acc= 0.8517
tm  [-1.5 -0.2  2.9 15.8 -1.1 -0.2 -0.1 -0.1 -0.2 -0.4 -0.6 -0.1 -0.4 -0.1 -2.2  4.9 -0.5  0.   2.  -0.8 -0.9  0.3  1.1 -0.2 -0.7  2.3 -0.1 -0.3 -0.   0.3 -1.  -0.6 -0.4 -2.4 -0.3 -0.1  2.1  3.  12.4 -0.3 -0.6  1.3 -0.5 -0.6 -0.7 -0.4  7.3 -0.6 -1.5 13.8 -0.2 -0.2  1.2 -1.2 -1.1  2.5 -0.1 -0.4 -0.6  4.5  1.1 -0.2 -0.3 -0.3 -0.9 -0.4 -0.3 -0.1  0.4 -0.5 -0.2 -0.9  1.4 -0.2  5.3 -0.1 -0.2 -0.7 -0.1 -0.2  5.9 -0.1 -0.  -0.3  1.5  3.6 -1.8 -0.2 -0.2  0.1  1.4 -0.  -0.  -0.9 -0.3 -0.3 -0.7 -0.  -0.4 -0.3  1.1  6.   0.2 -0.4 -0.1 -0.2  3.6 -0.7 -0.1 -2.2 -0.4 -0.2 -0.1 -0.  -0.4  7.1 -0.2 -1.3 -0.1  0.1 -0.1  7.7 -0.2  0.1  0.6 -2.8 -0.3  5.6 -1.2 -4.1 -0.3 -0.3  0.3 -0.4  1.  -2.4 -0.1 -0.2 -0.2 -0.2 -0.3 -0.4 -0.5 -0.1 -0.  -0.1  0.2 -0.  -1.1 -0.  -1.3  0.  -0.2 -0.1 -0.2 -0.1 -0.1 -0.2 -0.  -0.1  0.5 -0.4 -0.1  0.4 -0.2 -0.5  0.5  2.1 -0.1 -0.1 -0.1 -0.4 -0.1  0.  -0.4  2.3  0.  -0.  -1.1 -0.1  0.4 -0.1  0.1 -1.6 -0.1  1.5 -0.7 -0.2 -0.1 -0.   0.3 -0.1 -0.  -0.9  1.1  4.2  3.1  1.5 -0.1 -0.1 -0.3 -0.1 -0.3 -0.4 -0.2  7.2 -0.1 -0.2  8.4 -0.4  1.1  1.7 -0.7  8.5 -0.4 -0.3  2.8 -0.5 -0.1  1.3 -0.3 -0.2  0.  -0.7  5.3  2.1 -0.2  1.7 -0.4 -0.8 -0.4 -1.5  0.2  3.1 -0.5 -0.3 -0.4  3.2  0.8 19.3 -0.   6.1 -0.2  0.  -1.  -3.   0.8  1.1 -1.1 -0.4 -1.8 -0.3  7.8  0.8 -1.6 16.2]
ty_50sample [[9 1 8 2 7 6 4 0 5 3]
 [8 5 5 7 9 3 0 6 2 4]
 [2 8 4 0 0 1 9 6 7 3]
 [2 7 3 6 1 4 9 0 8 5]
 [8 7 5 6 9 2 0 3 4 1]
 [1 2 4 9 7 0 6 8 3 5]
 [8 7 1 5 4 0 6 2 9 3]
 [4 2 0 6 3 1 7 9 8 5]
 [3 7 6 4 4 9 1 2 0 5]
 [6 2 3 8 9 7 1 0 4 5]]
tt_50sample [[9 1 8 2 7 6 4 0 5 3]
 [1 8 5 7 9 3 0 6 2 4]
 [2 8 4 0 5 1 9 6 7 3]
 [2 7 3 6 4 1 9 0 8 5]
 [8 7 5 6 9 2 0 3 4 1]
 [1 2 4 9 7 0 6 8 3 5]
 [8 7 1 5 4 0 6 2 9 3]
 [4 2 0 6 3 1 9 7 8 5]
 [3 7 6 4 8 9 1 2 0 5]
 [6 2 3 8 9 7 1 0 4 5]]
vm  [-0.9 -0.3  3.7  7.7 -1.1 -0.1 -0.6 -0.   1.2 -0.4 10.4 -0.7  0.   0.   0.   4.1 -0.3 -0.2  1.1 -0.4 -1.1 -0.1  1.3 -0.1 -1.2  3.7 -0.3 -0.2 -0.4 -2.   1.  -0.6 -0.3  5.3 -0.2 -0.3  1.3  2.7 -0.4 -0.6 -0.8  1.9 -1.1 -1.1 -0.2 -0.   0.9 -0.4 -0.1  4.8 -0.3 -0.1 -0.2  5.6 -0.4  0.6 -0.4  2.4  5.8  0.6  2.5 -0.4 -0.1  1.2  1.2 -0.1 -0.1 -0.3 -0.3 -0.2  0.1  0.7  0.9  1.3 -1.6  0.5 -0.5 -0.7  0.1  0.2  8.9 -0.3 -0.   0.1  0.4  4.8 -1.2 -0.1 -0.1 -0.1 -0.2 -0.1 -0.2 -1.6 -0.1  0.2  0.3 -2.5 -0.1 -0.5  1.5  4.8 -0.2 -0.1 -0.1 -0.2 -0.8  0.2  0.7 -1.2 -0.3 -0.1  0.2 -0.5  4.   2.6 -0.4 -0.4 -0.2 -0.3 -0.4  4.5  0.3  0.9 -0.2 -0.1 -0.  -1.   3.8 -1.7  0.5 -0.4  0.1 -0.7  5.7 10.5 -0.1 -0.   0.1 -0.3 -0.6 -0.6 -1.  -0.  -0.1  0.   0.  -0.2 -0.3  0.  -0.6  0.1 -0.7 -0.7  0.2 -0.  -0.4 -0.4 -0.4 -0.2  0.6  1.  -0.  -0.   1.  -0.4  0.1  1.4 -0.1 -0.1 -0.1 -0.2 -0.2 -0.3 -0.3  1.2 -0.5  0.2  1.2 -0.  -0.4 -0.6 -0.7 -1.7 -0.1 -0.1 -0.1 -0.7 -0.2  6.   0.  -0.2 -0.2 -0.8 -0.2 -1.4 -0.  -1.1 -0.2  0.1 -0.2 -0.1 -0.4 -0.5 -0.2 -1.2  0.1 -0.1 -0.6 -0.  -0.2 -0.2 -0.9  4.4 -1.  -0.3  5.5 -1.2 -0.1  0.  -0.1  0.3  0.1 -1.1  6.1 -0.4  2.1  2.6  1.   1.4 -0.2 -0.7 -0.  -0.4  1.6 -0.6  0.4 -0.   2.8  5.3 -0.1  1.7 -0.1 -0.3 -1.5 -0.9  0.7 -0.  -1.5 -0.3 -2.4  0.2 -0.2 -0.1 -1.9  9.4]
vy_50sample [[2 6 1 9 0 7 5 4 8 3]
 [1 5 0 6 7 8 2 3 9 4]
 [2 0 3 6 4 1 7 9 5 8]
 [6 3 7 8 5 1 2 9 4 0]
 [6 9 1 0 4 8 5 7 2 3]
 [2 6 0 3 7 1 5 4 9 8]
 [8 5 6 3 2 0 7 9 1 1]
 [6 8 7 3 4 1 2 9 5 0]
 [7 0 8 9 3 1 4 5 2 6]
 [8 0 2 5 6 6 7 9 4 4]]
vt_50sample [[2 6 1 9 0 7 5 4 8 3]
 [1 5 0 6 7 8 2 3 9 4]
 [2 0 3 6 4 1 7 9 5 8]
 [6 3 7 8 5 1 2 9 4 0]
 [6 9 1 0 4 8 5 7 2 3]
 [2 6 0 3 7 1 5 4 9 8]
 [8 5 6 3 2 0 7 9 1 4]
 [6 8 7 3 4 1 2 9 5 0]
 [7 0 9 8 3 1 4 5 2 6]
 [8 0 2 5 6 1 7 3 9 4]]
Epoch 39310: Training cost= 0.2326, Training acc= 0.8516, Validation cost= 0.3093, Validation acc= 0.8517
Epoch 39320: Training cost= 0.2442, Training acc= 0.8516, Validation cost= 0.3129, Validation acc= 0.8517
Epoch 39330: Training cost= 0.2047, Training acc= 0.8516, Validation cost= 0.2618, Validation acc= 0.8517
Epoch 39340: Training cost= 0.2872, Training acc= 0.8517, Validation cost= 0.2504, Validation acc= 0.8517
Epoch 39350: Training cost= 0.2625, Training acc= 0.8517, Validation cost= 0.2753, Validation acc= 0.8517
Epoch 39360: Training cost= 0.2405, Training acc= 0.8517, Validation cost= 0.3037, Validation acc= 0.8517
Epoch 39370: Training cost= 0.2258, Training acc= 0.8517, Validation cost= 0.3086, Validation acc= 0.8517
Epoch 39380: Training cost= 0.2165, Training acc= 0.8517, Validation cost= 0.2811, Validation acc= 0.8518
Epoch 39390: Training cost= 0.2868, Training acc= 0.8517, Validation cost= 0.3308, Validation acc= 0.8518
Epoch 39400: Training cost= 0.2676, Training acc= 0.8517, Validation cost= 0.2907, Validation acc= 0.8518
tm  [-0.4  0.1 -1.5 -4.3 -1.7 -0.2  0.3 -0.2 -1.7 -0.6  0.4  0.4 -0.2 -0.3  7.5 -0.8 -0.2 -0.5 -0.5  1.8 -1.2 -0.1 -0.1 -0.2 -1.2  2.4  1.6 -0.6 -1.9  0.1  2.6 -0.1 -0.5  1.6 -0.2 -0.1  5.4  2.3 -0.9 -0.5  3.6 -3.3  2.3  5.1  0.2  0.3 -1.7 -0.4  3.2 -1.  -0.3 -0.1 -0.2  6.4  0.7 -0.8 -0.7 -4.  -0.6 -1.2  2.4 -0.   0.1 -0.  -1.3  0.5 -0.2 -0.7 -0.1  0.2 -0.1  5.8 -0.5  0.3 -4.4 -0.4 -0.2 -0.3 -0.2 -0.1 -2.6 -0.2 -0.2 -0.5 -1.1 -3.6  7.3  0.4 -0.  -0.  -0.5 -0.1 -0.2  2.8 -0.3 -0.1 -0.5 -2.3  0.3 -0.1  0.9 -0.6 -0.6 -0.1  0.1  0.3 -2.1  1.7  0.7 -0.8 -0.9 -0.5 -0.3 -0.2  1.7 -2.9  0.5 -0.6 -0.  -0.3  2.   1.6 -0.4 -0.7 -0.1  8.7 -0.1 -1.1 -1.2 11.4 -0.5 -0.3 -0.4  1.5 -1.5 -1.2 -0.2  0.3 -0.6 -0.2 -0.6 -1.2 -0.2 -0.2 -0.1 -0.2 -0.3 -0.2 -1.8 -0.2  2.3  0.3  2.4 -0.5 -0.2  0.  -0.5  0.8  1.2 -0.5  0.3 -1.3 -0.  -0.2 -0.2 -0.4 -0.5 -0.6 -0.  -0.   0.  -0.1 -0.  -0.1 -0.2  3.1 -0.1 -0.6  2.5 -0.3  2.4  0.1 -0.3 -1.6  0.1 -0.5 -0.1 -0.5 -0.3 -0.2 -0.1 -0.1 -0.3 -1.3 -0.1  4.5 -1.1 -0.4 -0.1 -0.2 -0.1 -0.  -0.2 -0.5 -0.3 -2.5 -0.4 -0.2  8.9 -0.2 -0.3 -2.  -0.6 -0.  -0.4 -0.2 -2.1 -0.7 -0.5 -0.6 -0.2 -0.  -0.2 -1.2 -1.4 -0.9 -1.  -0.9  1.   0.1 -0.2  1.2 -0.1  3.6  2.4  3.   0.1 -1.1 -0.1  8.6  0.1  2.6 -0.1 -0.1  9.3  3.  -0.9  0.5 -0.5 -0.7  6.4 -0.3 -0.5  0.1  2.8 -2.7]
ty_50sample [[4 0 3 8 7 2 6 1 9 5]
 [5 9 7 6 2 4 8 3 1 0]
 [5 9 6 7 0 2 8 1 3 4]
 [8 8 1 6 2 3 4 9 0 7]
 [5 9 8 6 3 1 2 7 0 4]
 [2 4 1 7 5 9 3 6 8 0]
 [6 2 8 3 7 4 5 0 1 9]
 [5 2 7 6 0 9 1 3 4 8]
 [9 6 7 1 3 5 8 0 4 2]
 [0 2 1 6 5 7 8 4 3 9]]
tt_50sample [[0 4 3 7 8 2 6 1 9 5]
 [5 9 7 6 2 4 8 3 1 0]
 [5 6 9 7 0 2 8 1 3 4]
 [8 5 1 6 2 3 4 9 0 7]
 [5 6 9 8 3 1 2 7 4 0]
 [2 4 1 7 5 9 3 6 8 0]
 [6 2 8 7 3 4 5 0 1 9]
 [5 2 7 6 0 9 1 3 4 8]
 [9 6 7 1 3 5 8 0 4 2]
 [0 2 1 6 5 7 8 4 3 9]]
vm  [-1.  -0.5  0.8 11.3 -1.4 -0.2 -0.1 -0.2 -0.1 -0.4 -0.4 -0.2 -0.4 -0.1 -1.8  3.2 -0.4  0.2  1.6 -1.  -0.6  0.3  2.5 -0.3 -0.8  0.5 -0.4 -0.2  2.7  1.6  1.1 -0.2  1.8  0.5 -0.1 -0.1 -0.1 -1.4 -0.7 -0.4  0.4  6.5 -0.2 -0.7 -0.3 -0.2  6.3 -0.5 -0.4  7.3 -0.5 -0.2  1.6 -2.2 -1.8  2.8 -0.1  4.  -0.3  1.9 -0.8 -0.5 -0.1 -0.3  0.8 -1.  -0.1  2.1  1.5 -0.4 -0.1 -2.4 -0.3  0.4 -1.2 -0.5 -0.4 -1.2 -0.3 -0.  12.5 -0.1 -0.3 -0.7 -0.9  7.3 -0.5  0.2 -0.3 -0.1  0.1 -0.2 -0.3 -0.8 -0.3 -0.4 -1.  -1.5 -0.3  0.2  0.1  4.8 -0.4  0.1 -0.3 -0.3 -0.3 -0.1 -0.2 -1.5 -0.4 -0.4 -0.2 -0.8 -0.5 13.2  1.4 -0.3 -0.3  1.9 -0.5  4.4 -0.5  0.9 -0.1 -2.2 -0.2  9.6  0.8 -2.6 -0.7  0.6  0.2 -0.5 10.9 13.8 -0.4 -0.3 -0.7 -1.   0.9  0.2  0.3 -0.  -0.1 -0.2 -0.4  0.3  4.  -0.3 -0.7 -0.3  0.7 -0.   0.3 -0.2 -0.1  0.7 -0.8 -0.7 -0.1 -0.3 -0.2 -0.  -0.1 -0.4 -0.5  0.6 -0.3 -0.  -0.  -0.1  0.4 -0.2 -0.3 -1.  -2.   0.7  1.3 -0.1 -1.4  0.9 -0.3 -1.7 -0.2 -0.3  0.2 -0.7  0.8 -0.4  0.4 -0.3 -0.3 -1.1  7.3 -0.4  0.4  0.6 -0.1 -0.3  0.2 -0.  -0.3 -0.7  0.4  3.8 -0.1  0.6 -2.9  0.1  0.6  5.3 -0.6  2.6 -0.5  1.2  3.1 -0.3  0.5  1.8 -0.1 -0.3  0.9 -1.2  5.2  4.6 -1.9 -0.3 -0.2  0.2  1.8 -0.3 -0.1 -1.  -1.6 -0.3  0.5  0.7  1.3 -0.4 -0.2 -0.3 -0.1 -0.1 -2.3 -2.6 -0.2 -0.1 -1.4 -0.3 -3.5 -0.2 -0.4 -0.  -0.6 12.3]
vy_50sample [[6 5 9 1 1 7 2 2 3 0]
 [7 5 5 0 2 9 4 4 6 1]
 [4 6 8 5 0 7 3 1 9 2]
 [2 9 7 4 0 3 6 8 5 1]
 [0 7 7 9 5 3 1 4 6 8]
 [6 8 2 7 3 1 0 4 5 9]
 [9 0 4 5 3 7 6 2 1 8]
 [4 5 2 0 1 3 9 7 8 6]
 [1 9 3 3 4 0 8 5 6 2]
 [1 0 6 5 9 7 2 4 3 8]]
vt_50sample [[6 5 9 1 8 4 7 2 3 0]
 [7 3 5 0 2 9 4 6 8 1]
 [4 6 5 8 0 7 3 1 9 2]
 [2 9 7 4 0 3 6 8 5 1]
 [0 2 7 9 5 3 1 4 6 8]
 [6 8 2 7 3 1 0 4 5 9]
 [9 0 4 5 3 7 6 2 1 8]
 [4 5 2 0 1 3 9 7 8 6]
 [1 9 3 7 4 0 8 5 6 2]
 [1 0 6 5 9 7 2 4 3 8]]
Epoch 39410: Training cost= 0.2799, Training acc= 0.8517, Validation cost= 0.2884, Validation acc= 0.8518
Epoch 39420: Training cost= 0.2721, Training acc= 0.8517, Validation cost= 0.3148, Validation acc= 0.8518
Epoch 39430: Training cost= 0.2594, Training acc= 0.8518, Validation cost= 0.2539, Validation acc= 0.8518
Epoch 39440: Training cost= 0.2443, Training acc= 0.8518, Validation cost= 0.2738, Validation acc= 0.8518
Epoch 39450: Training cost= 0.2484, Training acc= 0.8518, Validation cost= 0.2771, Validation acc= 0.8518
Epoch 39460: Training cost= 0.2224, Training acc= 0.8518, Validation cost= 0.2122, Validation acc= 0.8519
Epoch 39470: Training cost= 0.2962, Training acc= 0.8518, Validation cost= 0.2547, Validation acc= 0.8519
Epoch 39480: Training cost= 0.2508, Training acc= 0.8518, Validation cost= 0.2414, Validation acc= 0.8519
Epoch 39490: Training cost= 0.2938, Training acc= 0.8518, Validation cost= 0.2998, Validation acc= 0.8519
Epoch 39500: Training cost= 0.2782, Training acc= 0.8518, Validation cost= 0.2313, Validation acc= 0.8519
tm  [-0.7 -0.1  3.9 -0.9 -1.5 -0.2 -0.3 -0.2 -0.  -0.1  8.6 -0.3 -0.2 -0.2  6.7 -0.1 -0.2 -0.5  1.6  3.3 -1.2 -0.1  2.1 -0.2 -1.6  4.6 -0.2  0.3 -1.1 -2.6 -0.2 -0.5 -0.4  1.6 -0.  -0.1  1.8  3.8 -2.6 -0.5 -0.7 -1.  -1.1 -0.9 -0.3 -0.3 -2.2 -1.  -0.5  3.4 -0.5 -0.2 -0.  14.  -0.  -0.7 -0.5 -0.3  5.5  3.2  6.5 -0.4 -0.  -0.   1.4 -0.2 -0.3  0.5  0.  -0.3 -0.1  4.4  1.  -0.1 -5.1 -0.3 -0.1 -0.6  0.   0.5 -2.3 -0.3 -0.  -0.3 -0.3 -0.7 -1.2 -0.2 -0.1  1.3 -0.4 -0.2 -0.1 -0.9 -0.4 -0.1 -0.3 -3.3 -0.2 -0.2 -0.   3.2 -0.6  0.  -0.2  1.3 -2.5 -0.1  1.   2.4 -0.  -0.1 -0.1 -0.2  5.4 -2.3 -0.4 -0.2 -0.   1.8 -0.4 -1.3 -0.1  0.5 -0.2  7.8 -0.  -3.4  1.6  4.5  0.6 -0.3 -0.3  0.3  4.   4.9 -0.2 -0.2  0.6 -0.6 -0.5 -1.4 -0.9 -0.2 -0.1 -0.1 -0.3 -0.1 -1.1 -0.2  0.4 -0.1 -0.1 -0.2 -0.2 -0.1 -0.4 -0.  -0.4 -0.2  0.3 -0.4  0.9 -0.   0.3 -1.1 -0.2  1.  -0.3 -0.2 -0.2 -0.  -0.1 -0.1 -0.4  2.6 -0.6 -0.1  4.3 -0.   1.9 -0.3 -0.3 -2.3  0.2 -0.1 -0.3 -0.4  0.3  7.6 -0.1 -0.4 -0.  -1.3 -2.2 -0.7 -1.3 -1.4 -0.1  0.2 -0.2 -0.1 -0.4 -0.5  0.6 -2.8 -0.1 -0.   5.4 -0.3 -0.3 -1.7 -0.7  4.3 -0.6 -0.2  4.2 -0.9 -0.6  1.  -0.1 -0.2  0.3 -1.4  3.8 -0.9  2.   1.6  1.  -0.  -0.4  0.7 -0.2  2.4  2.2 -0.6  1.9 -1.1  1.2 -0.2 -0.1 -0.  -0.  -0.3  8.7  2.2  0.3 -0.1 -1.2 -0.3  5.7 -0.2 -1.6 -0.3 -1.4 -0.7]
ty_50sample [[2 0 1 6 7 8 3 4 5 9]
 [6 2 7 3 4 1 5 8 0 9]
 [2 4 6 1 5 7 0 3 8 9]
 [4 9 3 6 5 7 2 1 8 0]
 [0 6 7 2 9 8 3 4 5 1]
 [3 6 4 8 2 0 7 9 5 1]
 [0 1 4 9 7 6 3 2 5 8]
 [0 3 6 6 1 5 4 4 9 7]
 [0 1 7 5 4 3 9 8 6 2]
 [3 7 0 2 6 4 5 9 1 8]]
tt_50sample [[2 0 1 6 7 8 3 4 5 9]
 [2 6 7 3 4 1 5 8 0 9]
 [2 4 6 1 5 7 0 3 8 9]
 [4 3 9 6 5 7 2 1 8 0]
 [0 6 2 7 9 8 3 4 5 1]
 [3 6 4 8 2 0 7 9 5 1]
 [0 1 4 9 7 6 3 2 5 8]
 [0 3 6 2 1 5 8 4 9 7]
 [0 1 7 5 4 3 9 8 6 2]
 [3 7 0 2 6 4 5 1 9 8]]
vm  [-1.  -0.  -2.3  3.9 -0.7 -0.3 -0.5 -0.2  1.7  1.3 11.1 -0.6  0.2 -0.  -1.9  5.   0.4 -0.1 -0.6 -0.4 -1.2  0.2  2.2 -0.3 -0.8  2.8 -0.1 -0.3  0.1 -2.2  1.7 -0.4 -0.7 -1.5  0.9 -0.4 -0.2  4.3 -0.  -0.3  0.1 -0.7 -1.5 -0.3 -0.1  0.6  0.7 -0.6 -0.3  3.7 -0.2 -0.3  1.3  9.9 -1.4  2.  -0.1 -1.6  5.8 -0.3  0.8 -0.3  1.1 -0.1  1.9 -0.4 -0.4  1.1 -1.  -0.   0.5 -1.   1.1  2.9 -3.3 -0.8 -0.3 -0.1 -0.  -0.2  7.2 -0.1 -0.2 -0.4 -0.5 -0.5 -0.2  0.2 -0.3 -0.4 -0.  -0.2  0.9 -1.4 -0.4  0.1 -0.8 -2.5 -0.2 -0.3 -0.8 -0.5 -0.2  0.4 -0.3  2.1 -0.9  1.7  0.  -1.2  1.3 -0.  -0.1 -0.7  3.4  5.3 -0.3  0.3 -0.3  0.4 -0.3  2.6 -0.3  0.8 -0.3 -2.4 -0.1 -2.   4.  -1.1 -0.1 -0.1 -0.5  1.8 12.2  8.8 -0.3 -0.2  0.8 -0.5 -0.6 -0.4 -1.1  0.1 -0.2 -0.2 -0.2 -0.1  1.9  0.  -0.7 -0.3 -0.2 -0.1 -0.   0.  -0.5  1.1 -0.2 -0.4  0.1 -0.4  0.7 -0.2 -0.1 -0.3 -0.2  2.  -0.  -0.  -0.2  0.2 -0.1  0.8  0.2  0.3 -0.5  1.4  0.7 -0.2  2.1 -0.4 -0.6 -1.8 -0.1 -0.1  0.   0.1 -0.3  7.1 -0.2 -0.4 -0.4 -0.9  2.3 -1.6  0.4 -1.  -0.   0.  -0.1  0.5 -0.4 -0.7  0.9  0.5 -0.4 -0.3  5.  -0.2 -0.4  3.6 -0.9  4.7 -0.5 -0.4  2.1 -1.1 -1.   1.2 -0.1  0.  -0.1 -1.3  4.6  1.9  0.9  1.4 -0.3 -0.1  0.2 -0.6 -0.2  2.  -0.6  4.3 -0.2 -0.6  2.3 13.  -0.2  4.  -0.1 -0.3 -1.1 -1.4 -0.4  0.  -1.5 -0.2 -2.1  0.2 -0.  -0.3 -1.7  7. ]
vy_50sample [[2 6 9 1 4 8 0 3 5 7]
 [7 4 9 8 5 0 3 6 1 2]
 [1 3 6 0 9 2 5 7 4 8]
 [4 1 6 7 9 2 3 5 8 0]
 [6 5 9 4 3 7 0 2 1 8]
 [6 2 3 8 4 1 7 0 9 5]
 [9 3 6 8 2 7 5 1 4 0]
 [0 9 4 2 5 7 8 6 3 1]
 [8 9 1 2 4 5 3 6 0 7]
 [9 2 7 7 4 6 0 3 5 1]]
vt_50sample [[2 6 9 1 4 8 0 3 5 7]
 [7 4 9 8 0 5 3 6 1 2]
 [1 3 6 0 9 2 5 7 4 8]
 [4 1 6 7 9 2 3 5 8 0]
 [6 5 9 4 3 7 0 2 1 8]
 [6 2 3 8 4 1 7 0 9 5]
 [9 3 6 8 2 7 5 1 4 0]
 [0 9 4 2 5 7 8 6 3 1]
 [8 9 1 2 4 5 3 6 0 7]
 [2 9 8 7 4 6 0 3 5 1]]
Epoch 39510: Training cost= 0.2690, Training acc= 0.8519, Validation cost= 0.2248, Validation acc= 0.8519
Epoch 39520: Training cost= 0.2555, Training acc= 0.8519, Validation cost= 0.2425, Validation acc= 0.8519
Epoch 39530: Training cost= 0.1969, Training acc= 0.8519, Validation cost= 0.2599, Validation acc= 0.8519
Epoch 39540: Training cost= 0.3217, Training acc= 0.8519, Validation cost= 0.2691, Validation acc= 0.8520
Epoch 39550: Training cost= 0.2320, Training acc= 0.8519, Validation cost= 0.2078, Validation acc= 0.8520
Epoch 39560: Training cost= 0.2712, Training acc= 0.8519, Validation cost= 0.2481, Validation acc= 0.8520
Epoch 39570: Training cost= 0.2232, Training acc= 0.8519, Validation cost= 0.3330, Validation acc= 0.8520
Epoch 39580: Training cost= 0.2912, Training acc= 0.8520, Validation cost= 0.2672, Validation acc= 0.8520
Epoch 39590: Training cost= 0.2837, Training acc= 0.8520, Validation cost= 0.2399, Validation acc= 0.8520
Epoch 39600: Training cost= 0.2538, Training acc= 0.8520, Validation cost= 0.2427, Validation acc= 0.8520
tm  [-1.3  1.9  3.9 20.7 -1.3  1.  -0.2  0.2 -0.6 -1.4  4.2 -0.4  0.6 -0.1 -2.8  4.3 -0.4 -0.3  0.8 -0.6 -1.  -0.3 -0.1  0.2 -0.7  2.2 -0.5  0.5 -0.2 -1.5 -1.  -0.2 -0.  -2.  -0.2 -0.1  2.9 -0.1  6.6 -0.2 -0.2 -2.2 -0.1 -1.3 -0.2  0.5  6.7 -0.2 -0.4 -1.2 -0.2 -0.1  2.  -1.1 -0.7  2.8 -0.1  5.8 -0.6  5.8 -0.4 -0.4 -0.1  0.2 -0.1  1.4 -0.1 -0.3  0.3 -0.3 -0.1 -1.2  0.6  0.   5.4 -0.5 -0.4 -0.4 -0.1 -0.1 11.  -0.4  0.6  0.3  0.5 -1.8 -2.  -0.1 -0.3 -0.1  0.6 -0.1  0.1 -0.4 -0.2  0.  -0.2 -0.8  0.8  1.2  5.2 -2.2 -0.2 -0.1 -0.1  0.1  2.1 -0.3  2.  -1.8 -0.4 -0.   0.5 -0.3 -0.8  8.9 -0.4 -1.2 -0.5 -0.3 -0.2  7.2  0.2  2.1 -0.1 -3.4 -0.2  6.2 -0.2 -0.4  0.3 -0.5 -0.2 -0.5  9.1  4.7  0.2 -0.1  2.1 -0.5  0.1 -0.3 -0.4 -0.   0.2 -0.1  0.1  0.2  3.3 -0.  -1.8 -0.1  0.2  1.1  0.4 -0.2  0.7 -0.  -0.2  0.3 -0.9  1.2  0.  -0.1  0.1  0.1  1.5  1.6  0.3 -0.2  0.1 -0.1  0.3  0.6 -0.2 -0.1 -0.5 -0.5 -0.5 -0.1 -0.5 -0.4 -0.4 -1.8 -0.1  0.7 -0.5 -0.3 -0.1  5.  -0.1  0.2 -0.1 -0.8  5.4  1.2  2.1  2.5 -0.2  0.1 -0.5 -0.2 -0.7 -0.6  0.4  3.1 -0.3  0.1  3.3  0.4 -0.1  2.3 -0.7  4.9 -0.4 -0.6  6.9 -0.9 -0.6  0.  -0.3  0.  -0.2 -0.8 -0.4  3.3 -0.6  1.8 -0.2  0.8 -0.4 -1.6 -0.   2.   1.3 -0.4 -0.5  3.2  3.6 12.7 -0.1  4.   0.6 -0.2 -1.8 -2.1 -0.1  1.5 -1.4 -0.  -2.9 -0.2  4.4 -0.1  5.3  3.6]
ty_50sample [[9 3 6 1 2 8 5 0 0 4]
 [9 5 6 4 8 0 3 7 1 2]
 [7 4 2 3 5 9 8 1 6 0]
 [9 1 1 2 7 4 0 5 8 3]
 [7 3 0 2 1 8 5 4 9 6]
 [0 6 5 9 4 1 3 2 7 8]
 [9 1 4 7 5 0 6 8 3 2]
 [9 0 3 7 7 6 1 4 2 5]
 [8 3 1 1 2 7 0 4 5 9]
 [9 4 1 2 8 3 5 6 7 0]]
tt_50sample [[9 3 1 6 2 8 5 0 7 4]
 [9 5 6 4 8 0 3 7 1 2]
 [7 4 2 3 5 9 8 1 6 0]
 [6 9 1 2 7 4 0 5 8 3]
 [7 3 0 2 1 8 5 4 9 6]
 [0 6 5 9 4 1 3 2 7 8]
 [1 9 4 7 5 0 6 8 3 2]
 [9 0 3 7 8 6 1 4 2 5]
 [8 3 6 1 2 7 0 4 5 9]
 [9 4 1 2 8 3 5 7 6 0]]
vm  [-0.3  0.7  2.5  4.9 -1.4  0.2 -0.  -0.2 -1.  -1.1 -6.5 -0.3 -0.3 -0.5 -0.2 -0.3  1.4 -0.4  1.9 -0.6 -0.9  0.7  1.6 -0.4 -1.1  0.9  0.7 -0.2 -0.3  6.3 -0.2 -0.8 -0.6 -0.6 -0.3 -0.   1.6 -1.7  2.3 -0.3 -0.9  5.2  3.3 -0.3 -0.3  0.1  1.6  0.3  4.7  5.6 -0.3 -0.3  0.7 -3.5 -1.2  0.2 -0.5  6.6 -1.8  3.3 -0.6 -0.4 -0.3 -0.2 -1.  -0.1  0.6 -0.4 -0.   2.1 -0.  -1.  -0.   0.5 -0.7  0.4 -0.5 -0.6 -0.2  1.4 -0.1 -0.2 -0.  -0.4 -1.2  6.5  2.8 -0.1 -0.2 -0.4 -0.5 -0.2 -0.4  0.5 -0.5 -0.4  0.6 -1.3 -0.5 -0.1  3.7  2.7 -0.7 -0.2 -0.4  2.6 -0.2 -0.2 -2.2 -1.7 -0.2 -0.  -0.3 -0.4 -1.3 10.4 -0.4 -0.9  0.1 -0.1 -0.3  6.9 -0.  -0.4  0.  -0.2 -0.2 13.1 -1.1 -0.5  1.7 -0.2 -0.2 -0.4  3.2 -0.4 -0.3 -0.1 -0.3 -0.3  2.6 -0.3  0.8 -0.  -0.2 -0.2  0.6 -0.2  4.2 -0.1 -0.3 -0.2  2.9 -0.3 -0.3 -0.2 -0.4  0.9 -0.7 -0.5 -0.   1.6 -0.1 -0.2 -0.2  1.5 -0.4 -0.4  0.7 -0.3 -0.2 -0.1 -0.5 -0.3 -0.3 -0.6 -0.  -0.3 -0.1 -0.  -2.5  0.2 -0.4 -1.7  0.1 -0.1  1.3 -0.4  0.3 -1.4 -0.  -0.1 -0.1 -0.6  6.4  4.1  2.1  3.  -0.1  0.7  0.5  0.3 -0.5 -0.1 -0.4  0.2  0.1 -0.1 -1.1 -0.2 -0.7  2.9 -0.6 -0.4 -0.  -0.3  2.3 -0.8 -0.1 -0.3 -0.2 -0.2 -0.1 -0.9  3.1  3.6 -1.7 -0.3 -0.1  2.9 -0.4 -1.1 -0.2 -0.3 -0.6 -0.3 -0.7  0.9  1.  -1.4 -0.1 -0.5 -0.5 -0.2  2.7 -1.3 -0.3 -0.1 -0.8 -0.7 -0.2 -0.2  1.2 -0.   5.8  3.9]
vy_50sample [[5 8 9 6 7 4 3 1 0 2]
 [7 7 6 2 8 3 0 4 5 1]
 [6 1 8 5 4 7 0 2 9 3]
 [5 3 8 0 7 4 6 2 1 9]
 [3 6 6 7 2 2 5 8 0 4]
 [4 7 8 5 0 3 6 9 2 1]
 [5 7 2 3 9 1 0 4 8 6]
 [0 9 7 8 2 3 5 6 1 4]
 [2 6 0 3 9 4 7 8 1 5]
 [7 1 4 3 5 2 0 8 6 9]]
vt_50sample [[5 8 9 6 7 3 4 1 0 2]
 [7 9 6 2 8 3 0 4 5 1]
 [6 1 8 0 5 4 7 2 9 3]
 [5 3 8 0 4 7 6 2 1 9]
 [3 6 1 2 7 9 5 8 0 4]
 [4 7 8 5 0 3 6 9 2 1]
 [5 7 2 3 9 1 0 4 8 6]
 [0 9 7 8 2 3 5 6 1 4]
 [2 6 0 3 9 4 8 7 1 5]
 [7 1 3 4 5 2 0 8 6 9]]
Epoch 39610: Training cost= 0.2860, Training acc= 0.8520, Validation cost= 0.2585, Validation acc= 0.8520
Epoch 39620: Training cost= 0.2621, Training acc= 0.8520, Validation cost= 0.3196, Validation acc= 0.8521
Epoch 39630: Training cost= 0.2258, Training acc= 0.8520, Validation cost= 0.2276, Validation acc= 0.8521
Epoch 39640: Training cost= 0.2296, Training acc= 0.8520, Validation cost= 0.1884, Validation acc= 0.8521
Epoch 39650: Training cost= 0.2691, Training acc= 0.8520, Validation cost= 0.2641, Validation acc= 0.8521
Epoch 39660: Training cost= 0.2669, Training acc= 0.8520, Validation cost= 0.3250, Validation acc= 0.8521
Epoch 39670: Training cost= 0.3615, Training acc= 0.8521, Validation cost= 0.2210, Validation acc= 0.8521
Epoch 39680: Training cost= 0.2602, Training acc= 0.8521, Validation cost= 0.2640, Validation acc= 0.8521
Epoch 39690: Training cost= 0.2610, Training acc= 0.8521, Validation cost= 0.2142, Validation acc= 0.8521
Epoch 39700: Training cost= 0.2355, Training acc= 0.8521, Validation cost= 0.2519, Validation acc= 0.8522
tm  [ 2.  -0.2 10.5  6.  -1.4  0.  -0.4 -0.1 -0.7 -0.2  1.8 -0.1 -0.4 -0.1  9.7 -0.3 -0.2  0.5 -0.2 -0.6 -1.   0.4 -0.6 -0.2 -1.1  2.2 -0.4 -0.  -0.6  0.8 -0.4 -0.1  0.4 11.2 -0.2 -0.1  3.2  0.3 -1.  -0.5  0.9 -2.7  1.2 -0.8  0.3 -0.1  0.1 -0.2  6.2 -2.3 -0.4 -0.1 -0.2  1.2 -0.7 -0.9 -0.2 -0.3 -0.8  4.  -0.7 -0.3 -0.1 -0.2  0.4 -0.6 -0.1 -0.1  0.5 -0.2  0.1  2.3 -0.5  0.  -3.3 -0.3 -0.5 -0.3 -0.1  0.5  1.1 -0.1 -0.1  0.  -2.  -2.7  3.3 -0.  -0.1 -0.3 -0.6 -0.1 -0.1  1.1 -0.  -0.3 -0.2 -2.1 -0.2 -0.2  0.3  2.8 -1.2 -0.  -0.1  0.9 -1.4 -0.3  0.8 -0.7 -0.  -0.1  0.2 -0.4  0.2 -1.  -0.5 -0.2 -0.  -0.3 -0.3  1.4 -0.3 -0.3 -0.3 12.  -0.2  1.  -1.1  9.7  0.8 -0.2 -0.   1.  -3.1  5.2 -0.2 -0.2 -0.1 -0.3 -0.7 -1.  -0.4 -0.4 -0.1 -0.  -0.4 -0.1 -2.8 -0.2 -0.7 -0.1  3.5 -0.3 -0.2 -0.  -0.2 -0.3 -0.4 -0.6 -0.1 -0.6  0.  -0.1  0.4 -0.2 -0.4 -0.4 -0.3  0.1 -0.2 -0.1 -0.2 -0.4 -0.1  4.7 -1.  -0.1  2.3 -0.1 -0.  -0.3 -0.2 -1.6 -0.1 -0.5  2.7 -0.7  0.3 -0.2  0.  -0.1 -0.4 -0.8  8.7  3.9 -0.5 -0.5 -0.2 -0.2 -0.2 -0.1 -0.2 -0.1 -0.2 -1.3 -0.2 -0.2  5.6 -0.2 -0.7 -1.  -0.6 -1.7 -0.5  0.   3.8 -0.7 -0.6 -0.1 -0.2 -0.1  0.4 -0.7 -0.9 -0.4 -0.9 -0.3 -0.5  3.  -0.1  1.1 -0.3  2.6  0.  -2.3  1.2 -0.6  0.6  7.5 -0.   2.5  0.4 -0.2  1.3 -0.5 -0.6 -0.  -0.9 -0.4 -0.5 -0.1 -0.5 -0.1  4.2 -2.1]
ty_50sample [[7 3 0 6 9 2 9 4 5 1]
 [3 5 4 0 9 1 7 2 6 8]
 [6 3 5 9 2 4 7 8 1 0]
 [5 8 0 7 2 4 6 1 3 9]
 [0 2 1 3 5 9 4 7 8 6]
 [5 0 9 2 4 7 6 8 1 3]
 [7 1 4 9 9 3 8 0 5 2]
 [0 7 4 4 8 5 1 3 6 2]
 [7 2 5 1 6 4 9 9 8 3]
 [4 2 0 3 6 9 8 1 5 7]]
tt_50sample [[7 3 0 6 2 8 9 4 5 1]
 [3 5 4 0 9 1 7 2 6 8]
 [6 3 5 9 2 4 7 8 1 0]
 [5 8 0 7 2 4 6 1 3 9]
 [0 2 1 3 5 4 9 7 8 6]
 [0 5 9 2 4 7 6 8 1 3]
 [7 1 4 9 6 3 8 0 5 2]
 [0 7 4 9 8 5 1 3 6 2]
 [7 2 5 1 6 4 9 0 8 3]
 [4 2 0 3 6 9 8 1 5 7]]
vm  [-1.7  0.8  4.4 12.5 -1.4  0.4 -0.1 -0.1 -0.9 -0.5  4.  -0.2 -0.4  0.3 -0.6  3.3 -0.3 -0.1  0.9 -0.6 -1.1 -0.1  1.2 -0.  -1.3  2.2 -0.1  0.1 -1.  -0.7 -1.8 -0.3 -0.2 -2.8 -0.1  0.7  4.6  4.6  3.7 -0.3 -0.  -1.2 -0.1 -0.6 -0.2 -0.1  4.4 -0.6 -2.2  9.  -0.4 -0.2 -0.4  5.3 -0.9  0.5 -0.2  0.7 -1.1  6.2  4.2 -0.3 -0.6 -0.4 -0.3  0.1 -0.2 -0.1  0.5 -0.1 -0.2  1.3  1.  -0.3 -0.6 -0.3  0.7 -0.5 -0.   0.4 -1.2 -0.  -0.2  2.   3.5 -0.9 -2.6 -0.1 -0.1  0.4 -0.4 -0.   0.4  0.3 -0.5  0.1 -0.3 -1.2  0.2 -0.3  2.2  2.3  0.4 -0.2 -0.2 -0.1 -1.1 -0.9  1.8 -0.9 -0.2 -0.3 -0.2  1.  -0.2 -0.3 -0.6 -1.6 -0.2  0.4 -0.1  4.4  0.2 -0.  -0.2 -0.7  0.2 -0.8 -1.7 -1.  -0.4 -0.  -0.1 -0.3  4.  -2.1 -0.2 -0.3  0.9 -0.2 -0.9 -0.7 -0.8  0.1 -0.2 -0.2 -0.2 -0.  -1.  -0.1 -1.2 -0.2 -0.2 -0.2 -0.  -0.1 -0.2  0.  -0.3  0.1 -0.  -0.2 -0.1 -0.   0.3 -0.3 -0.2  0.6 -0.1 -0.1 -0.3 -0.2  0.5 -0.1 -0.2  2.3 -0.3 -0.3 -0.2  0.5  1.2 -0.3 -0.1 -1.6  0.4  0.4 -1.1 -0.5 -0.2  2.3 -0.1 -0.2 -0.1 -0.7 -0.8  6.5 -0.2  0.8  0.9  0.2 -0.1  0.3 -0.2 -0.4 -0.  -0.6  0.1  0.7  9.8 -0.1 -0.7 -1.  -0.6  9.  -0.4 -0.1  4.2 -0.7 -0.4 -0.2 -0.2 -0.3 -0.4 -0.9  2.8  0.7  2.5  0.3 -0.5 -1.  -0.6 -0.3  0.2  3.   0.8 -0.5 -0.2  0.2  0.5 13.4 -0.2  4.5 -0.  -0.2  5.3 -1.1  0.1  0.7 -0.9 -0.5  2.  -0.1  2.5 -0.3 -1.2  5.3]
vy_50sample [[1 2 8 0 9 6 7 3 4 5]
 [9 1 0 0 4 2 7 3 6 8]
 [8 4 1 3 9 7 5 6 2 0]
 [4 7 0 9 5 8 3 6 2 1]
 [8 9 9 2 7 7 3 1 5 4]
 [2 5 4 1 6 3 7 9 0 8]
 [7 2 3 4 5 6 0 8 8 1]
 [7 0 6 8 9 2 4 1 5 3]
 [9 8 6 2 0 1 5 7 3 4]
 [9 2 5 7 4 1 6 3 0 8]]
vt_50sample [[1 2 8 0 9 6 7 3 4 5]
 [9 5 1 0 4 2 7 3 6 8]
 [8 4 1 3 9 7 5 6 2 0]
 [4 7 9 0 5 8 3 6 2 1]
 [8 9 6 2 0 7 3 1 5 4]
 [2 5 4 1 6 3 7 9 0 8]
 [7 2 3 4 5 6 0 9 8 1]
 [7 0 6 8 9 2 4 1 5 3]
 [9 8 6 2 0 1 5 7 3 4]
 [2 9 5 7 4 1 6 3 0 8]]
Epoch 39710: Training cost= 0.2076, Training acc= 0.8521, Validation cost= 0.2392, Validation acc= 0.8522
Epoch 39720: Training cost= 0.1997, Training acc= 0.8521, Validation cost= 0.3036, Validation acc= 0.8522
Epoch 39730: Training cost= 0.2677, Training acc= 0.8521, Validation cost= 0.2734, Validation acc= 0.8522
Epoch 39740: Training cost= 0.2500, Training acc= 0.8521, Validation cost= 0.2138, Validation acc= 0.8522
Epoch 39750: Training cost= 0.2577, Training acc= 0.8522, Validation cost= 0.2576, Validation acc= 0.8522
Epoch 39760: Training cost= 0.3138, Training acc= 0.8522, Validation cost= 0.2743, Validation acc= 0.8522
Epoch 39770: Training cost= 0.2754, Training acc= 0.8522, Validation cost= 0.2781, Validation acc= 0.8522
Epoch 39780: Training cost= 0.3199, Training acc= 0.8522, Validation cost= 0.2328, Validation acc= 0.8523
Epoch 39790: Training cost= 0.2919, Training acc= 0.8522, Validation cost= 0.2410, Validation acc= 0.8523
Epoch 39800: Training cost= 0.2379, Training acc= 0.8522, Validation cost= 0.2540, Validation acc= 0.8523
tm  [-0.6 -0.3 -2.7 -2.2 -1.7  0.1 -0.1 -0.  -0.7 -0.4  7.2 -0.1 -0.1 -0.1 -0.5 -1.2 -0.1 -0.2 -0.4 -0.6 -1.5 -0.4 -1.  -0.  -1.2  1.9 -0.3  0.  -1.9 -3.5  4.  -0.2 -0.2  2.3  0.   0.3  3.8  5.2  7.7 -0.5  0.6 -2.1 -0.4  3.7 -0.3  0.1  0.7 -0.5 -0.2 -3.4 -0.3 -0.1 -0.8  5.6  1.4  0.  -0.8 -1.6  4.6 -2.4  3.5 -0.4 -0.2  0.  -0.  -0.5  0.3 -0.2  0.2 -0.4 -0.1  8.4 -0.4 -0.  -3.  -0.3 -0.6 -0.5  0.1 -0.4  7.4  0.5 -0.5 -0.8 -0.7 -2.1  2.7 -0.3 -0.1 -0.3 -0.5 -0.1 -0.1  0.3 -0.5 -0.1 -0.5 -2.3  0.6 -0.1  1.8 -2.1 -0.5  0.1 -0.3 -0.7 -2.   2.2  0.6 -0.9 -0.7 -0.  -0.1 -0.3  5.1 -4.   0.6 -0.2 -0.   0.8  0.8  2.7 -0.  -0.1 -0.2 -0.7 -0.  -0.7  4.6  7.7 -0.3 -0.2 -0.   0.  -1.1 -0.6 -0.2 -0.2  1.2 -0.5 -0.3 -1.1 -0.4 -0.4  0.2 -0.1 -0.4 -0.2  2.6 -0.3  0.8 -0.2 -1.  -0.2 -0.  -0.   1.6  0.4  2.4  0.2 -0.5 -2.   0.2 -0.2 -0.1 -0.6 -0.3 -0.3 -0.2 -0.2 -0.1 -0.1 -0.4  0.5 -0.1 -0.5  0.8 -0.9 -0.6 -0.2 -0.8 -0.5 -0.4 -1.6 -0.1 -0.2 -0.2 -0.4 -0.1  9.6 -0.1 -0.2 -0.5 -1.2 -0.7 -0.9 -1.1 -1.1 -0.1  0.8 -0.5  0.  -0.1 -0.4  0.6 -2.4 -0.1 -0.1 -1.4 -0.1 -0.4 -2.9 -1.   1.1 -0.1 -0.3 -1.8 -1.2 -1.  -0.   0.4 -0.2 -0.4 -1.3 -2.3 -2.1 -0.7 -0.2  1.5  0.6 -0.9  1.  -0.2 -0.5  4.9  4.6  2.5 -0.8 -0.1  1.2 -0.1  0.3 -0.2  0.2 -1.3  0.7 -0.3 -0.4 -1.2 -0.1 -2.1 -0.   5.  -0.1  3.1 -1.6]
ty_50sample [[0 3 4 2 1 9 5 7 8 6]
 [0 2 4 6 9 8 5 1 7 3]
 [0 1 6 8 5 3 2 4 7 9]
 [9 0 2 7 6 3 4 1 5 8]
 [5 4 1 6 9 3 0 2 7 8]
 [7 3 5 1 6 8 0 2 9 4]
 [3 8 2 0 6 1 7 5 4 9]
 [7 9 2 6 0 3 8 4 1 5]
 [6 7 3 4 8 5 0 1 2 9]
 [5 0 4 1 6 9 7 8 3 2]]
tt_50sample [[0 3 4 2 1 5 9 7 8 6]
 [0 2 4 6 9 8 5 1 7 3]
 [0 1 6 8 5 3 2 4 7 9]
 [9 0 2 7 6 3 4 1 5 8]
 [5 4 1 6 3 9 0 2 7 8]
 [7 3 5 1 6 8 0 2 9 4]
 [3 8 2 0 6 1 7 5 4 9]
 [7 9 2 6 0 3 8 4 1 5]
 [6 3 7 4 8 5 0 1 2 9]
 [5 0 4 1 6 9 7 3 8 2]]
vm  [-0.5  0.3 -3.4 -3.9 -1.2  0.4 -0.2 -0.  -1.1 -1.   5.7 -0.5 -0.1 -0.2  1.1  1.8 -0.2 -0.2 -0.8  0.1 -1.5 -0.4 -0.6  0.3 -1.2  2.8 -0.2 -0.3 -1.1 -0.9  4.1 -0.2 -0.2 -1.  -0.   0.1  4.   1.5 -1.9 -0.2  2.2 -3.4 -0.2  3.4 -0.2  1.1 -1.3 -0.2  3.2 -2.  -0.3 -0.  -0.2  7.3 -0.6 -0.2 -0.3 -3.6  1.8 -1.9  2.4 -0.1 -0.1  0.1 -0.7  0.3 -0.2 -0.4 -0.2  0.1 -0.2  1.2 -0.2  0.7 -3.5 -0.4 -0.4 -0.3  0.3 -0.1 -0.9 -0.1 -0.1  0.7 -0.7 -3.3  7.4 -0.2 -0.2 -0.3 -0.1 -0.1  0.1 -0.2 -0.1 -0.1 -0.4 -2.6  0.8 -0.3  3.5 -1.7 -0.6  0.3  0.4  1.5 -1.9  3.7  1.8 -0.5 -0.8 -0.  -0.1 -0.5  1.7 -0.  -0.5 -0.6 -0.1 -0.5 -0.1  1.4  0.4  0.8 -0.2  1.3  0.3 -1.3  0.8  9.6  0.9 -0.4 -0.1 -0.1  6.9  5.2 -0.2 -0.   1.  -0.3 -0.5 -0.7 -0.7 -0.  -0.2 -0.1 -0.3  0.1 -0.6  0.2  1.9 -0.2  1.3 -0.3 -0.2 -0.  -0.3  1.1 -0.2 -0.2 -0.2 -0.2 -0.3 -0.2 -0.2 -0.1  0.3  0.3  0.4  0.  -0.   0.  -0.1  0.5 -0.2  1.6 -0.6 -0.6  3.8 -0.1  1.5 -0.2 -0.6 -1.9 -0.2 -0.1 -0.1 -0.2 -0.4  2.7 -0.1 -0.1 -0.4 -1.1  0.4 -0.2 -0.4 -0.4 -0.3  0.2 -0.6 -0.1 -0.6 -0.7 -0.1 -2.6 -0.3 -0.2  6.3 -0.1 -0.3 -0.6 -1.2  0.4 -0.5 -0.7 -1.2 -1.1 -0.8 -0.1 -0.1 -0.  -0.4 -1.2 -0.7 -0.3 -0.4 -0.2 -0.   2.4 -0.2 -0.2 -0.3  2.3  1.7  6.  -0.1 -0.7  2.1  8.  -0.1  3.1  0.3 -0.1  5.1  2.2 -0.4  0.1 -1.2 -0.5  1.8 -0.2 -1.  -0.1  3.4 -2.1]
vy_50sample [[4 3 2 6 6 8 1 7 9 5]
 [2 7 6 6 1 9 9 0 0 3]
 [0 9 8 4 5 7 2 1 6 3]
 [3 9 2 5 7 6 8 0 0 4]
 [5 2 8 7 0 3 3 6 1 9]
 [3 4 1 9 5 7 6 8 2 0]
 [5 1 4 2 6 6 3 0 8 9]
 [6 2 7 0 4 9 1 3 8 5]
 [5 8 6 0 2 4 3 7 1 9]
 [6 6 4 9 5 7 8 0 3 1]]
vt_50sample [[4 3 2 6 0 8 1 7 9 5]
 [2 7 6 1 8 4 9 0 3 5]
 [0 9 8 4 5 7 2 1 6 3]
 [3 2 9 5 7 6 8 0 1 4]
 [5 2 8 7 0 4 3 6 1 9]
 [3 4 1 9 5 7 6 8 0 2]
 [5 1 4 2 6 7 3 0 8 9]
 [6 2 0 7 4 9 1 3 8 5]
 [5 8 6 0 2 4 3 7 1 9]
 [6 2 9 4 5 7 8 0 3 1]]
Epoch 39810: Training cost= 0.2782, Training acc= 0.8522, Validation cost= 0.2975, Validation acc= 0.8523
Epoch 39820: Training cost= 0.2254, Training acc= 0.8522, Validation cost= 0.2557, Validation acc= 0.8523
Epoch 39830: Training cost= 0.2570, Training acc= 0.8523, Validation cost= 0.2365, Validation acc= 0.8523
Epoch 39840: Training cost= 0.2205, Training acc= 0.8523, Validation cost= 0.2515, Validation acc= 0.8523
Epoch 39850: Training cost= 0.2873, Training acc= 0.8523, Validation cost= 0.2743, Validation acc= 0.8523
Epoch 39860: Training cost= 0.2480, Training acc= 0.8523, Validation cost= 0.2593, Validation acc= 0.8524
Epoch 39870: Training cost= 0.2510, Training acc= 0.8523, Validation cost= 0.2244, Validation acc= 0.8524
Epoch 39880: Training cost= 0.2895, Training acc= 0.8523, Validation cost= 0.2216, Validation acc= 0.8524
Epoch 39890: Training cost= 0.3199, Training acc= 0.8523, Validation cost= 0.2991, Validation acc= 0.8524
Epoch 39900: Training cost= 0.3031, Training acc= 0.8523, Validation cost= 0.3061, Validation acc= 0.8524
tm  [ 1.4 -0.  -1.5  7.1 -0.9 -0.3 -0.1 -0.2 -0.6  0.4 -3.5  1.2 -0.6  0.5 -2.4 -1.7 -0.2 -0.3 -0.1 -1.4 -1.1 -0.3 -1.1 -0.5 -0.7  0.8  0.1 -0.3 -0.7 -2.2  0.7 -0.3 -0.4 -2.1 -0.  -0.3  0.7 -0.8  7.9 -0.2  1.5 -1.  -0.1  0.6 -0.3  0.2  6.3 -0.   4.6 -3.2 -0.5 -0.2 -0.3 -2.9 -0.9  2.3 -0.5  4.3  0.3  1.4 -1.5 -0.7 -0.4 -0.3 -0.1 -0.6 -0.   0.6  0.8 -0.1  0.2  1.8 -0.4 -0.2 -2.1 -0.4 -0.4 -0.3 -0.  -0.1  7.1  0.2 -0.2 -0.1 -2.  -1.2  4.1 -0.1 -0.1 -0.6 -0.3 -0.2  0.2  0.4 -0.7 -0.2 -0.3 -1.7 -0.5 -0.2 -0.1 -2.9 -0.6 -0.2 -0.1  0.8 -1.1  0.2 -1.2 -1.5  1.  -0.3 -0.4 -0.6  1.7 -0.7  0.3  0.5 -0.2  1.3 -0.5  6.2  0.  -0.6 -0.4 -2.8 -0.2 11.8  3.9  8.4 -0.1 -0.1  0.7  0.4  5.  -0.5 -0.3  0.1 -0.  -0.4  1.1 -0.2  2.1  0.2 -0.1 -0.4 -0.5 -0.2  6.4 -0.2 -0.4 -0.1  2.8 -0.2 -0.2 -0.2 -0.2  0.8  0.5 -0.4 -0.4 -1.3 -0.2 -0.  -0.1 -0.1 -0.2 -0.6  0.1  0.  -0.  -0.3 -0.1 -0.2 -0.5 -1.5 -0.7 -0.8 -0.5 -0.1 -2.  -0.1 -0.4 -1.5 -0.   0.1  1.6 -0.1 -0.1  6.7 -0.2  0.6 -0.6 -1.2 12.5 -1.  -0.  -0.5 -0.2 -0.3 -0.1 -0.  -0.1 -0.3 -0.3 -0.1 -0.  -0.3 -1.7 -0.3 -0.6 -0.6 -0.6 -1.7 -0.1  1.3 -0.2 -0.8 -0.2 -0.1 -0.3 -0.2  1.  -1.1 -1.8 -0.4 -2.5 -0.6 -0.3  2.9 -0.3  0.1 -0.1 -0.7 -0.6  1.9  0.4 -0.3  0.4 -0.3 -0.1 -0.1 -0.2  0.2 -0.9 -1.7 -0.2 -0.5 -1.1 -0.6 -2.1 -0.4  5.5 -0.3  9.8 -1.5]
ty_50sample [[3 5 0 9 8 4 6 7 1 2]
 [1 4 3 6 6 7 2 8 5 0]
 [3 1 6 4 9 5 2 8 7 0]
 [8 3 0 4 7 5 9 6 1 2]
 [1 5 9 8 0 7 6 4 2 3]
 [1 3 2 4 7 0 9 5 6 8]
 [3 4 0 7 1 9 5 2 6 8]
 [5 8 1 0 4 2 9 6 3 7]
 [5 7 6 9 3 2 4 0 1 8]
 [7 1 2 0 8 6 5 5 3 4]]
tt_50sample [[3 5 0 9 8 4 6 7 1 2]
 [1 4 3 6 9 7 2 5 8 0]
 [3 1 6 4 5 9 2 8 7 0]
 [8 3 0 4 7 5 9 6 1 2]
 [1 5 9 8 0 7 6 4 2 3]
 [1 3 2 4 7 0 9 5 6 8]
 [3 4 0 7 1 9 5 2 6 8]
 [5 1 8 0 4 2 9 6 3 7]
 [5 7 6 9 3 2 4 0 8 1]
 [7 1 2 0 8 6 9 5 3 4]]
vm  [-1.1  2.4  3.3 -1.  -1.1 -0.2 -0.3 -0.1 -1.4 -1.4 -0.8 -0.3 -0.3 -0.1  6.3  5.9  0.2  0.4  2.   0.9 -1.  -0.2  0.4  0.4 -1.5  1.1 -0.1 -0.3 -0.3 -0.3 -1.  -0.1 -0.3 -2.3 -0.2 -0.2  2.9  3.5 -1.9 -0.5 -0.2 -4.   0.4 -0.6 -0.3 -0.1 -1.7 -0.5 -0.1 -0.1 -0.4 -0.1 -0.5  8.5 -1.6 -0.6 -0.2 -0.5 -1.1  5.3  5.2 -0.4  0.  -0.1 -0.4 -0.3 -0.1 -0.2 -0.3 -0.2 -0.  -0.8  1.8  0.1 -4.  -0.3 -0.4 -1.  -0.2  0.4 -4.8 -0.9 -0.1 -0.1 -0.7 -3.8 -0.7 -0.1 -0.3 -0.1 -0.4 -0.2  0.2  1.8 -0.3 -0.3 -0.3 -2.6 -0.2 -0.2  5.6 -1.9 -0.3 -0.1  0.1 -0.  -2.  -0.6 -0.2  0.3 -0.2  0.1 -0.1 -0.1 -0.9  7.6 -0.6 -1.2 -0.2 -0.2 -0.3 -0.4 -0.5  0.5 -0.1  7.2 -0.2 -1.7 -1.2 12.3  0.2 -0.4  0.9 -0.1  3.6 -1.9 -0.   0.1  1.3 -0.1 -0.7 -0.5 -1.  -0.1 -0.   0.1 -0.3 -0.  -1.1  0.1 -0.  -0.1  2.5 -0.6 -0.3  0.2 -0.5 -0.  -0.2  0.5 -0.7 -0.1 -0.2 -0.1 -0.3 -0.   0.8  1.5  0.5  0.2  0.1 -0.1 -0.  -0.  -0.5  2.6 -0.2 -0.3  3.5 -0.   1.  -0.  -0.  -2.1 -0.2 -0.3 -0.4 -0.6 -0.4  0.9 -0.  -0.1  0.2 -1.3 -1.3  4.2 -0.6  2.3 -0.3 -0.1 -0.1 -0.1 -0.3 -0.7 -0.2 -2.6 -0.3 -0.  10.7 -0.2 -0.3  2.  -0.9  4.   0.  -0.8  2.8 -0.6 -0.9 -0.  -0.2 -0.2 -0.2 -1.2 -1.1  3.9  0.7  1.2 -0.4 -0.  -0.6  0.8 -0.5  2.9 -0.5 -0.3 -0.5 -0.7 -0.   2.8 -0.   1.  -0.  -0.1 15.3  1.7 -0.2  0.4 -0.9 -0.1 12.1 -0.2 -1.2  0.2  3.2 -2.9]
vy_50sample [[3 8 2 1 6 7 4 0 9 5]
 [6 7 3 2 1 4 5 0 0 8]
 [0 2 9 8 6 7 3 1 5 4]
 [2 8 1 9 7 4 0 5 6 3]
 [4 5 3 2 8 1 7 6 9 0]
 [7 5 2 8 9 4 3 0 1 6]
 [5 2 3 6 0 7 1 9 4 8]
 [2 0 1 9 7 3 5 6 8 4]
 [5 1 4 9 7 2 0 8 3 6]
 [1 4 5 8 2 9 7 6 0 3]]
vt_50sample [[3 8 2 6 1 7 4 0 9 5]
 [6 7 3 2 1 4 5 9 0 8]
 [2 0 9 8 6 7 3 5 1 4]
 [2 8 1 9 7 4 0 5 6 3]
 [4 5 3 2 8 1 7 6 9 0]
 [7 5 8 2 9 4 3 0 1 6]
 [5 2 3 6 0 7 1 9 4 8]
 [2 0 1 9 7 3 5 6 8 4]
 [5 1 4 9 7 2 0 8 6 3]
 [1 4 5 8 2 9 7 6 0 3]]
Epoch 39910: Training cost= 0.3047, Training acc= 0.8523, Validation cost= 0.2960, Validation acc= 0.8524
Epoch 39920: Training cost= 0.2996, Training acc= 0.8524, Validation cost= 0.2555, Validation acc= 0.8524
Epoch 39930: Training cost= 0.2910, Training acc= 0.8524, Validation cost= 0.2563, Validation acc= 0.8524
Epoch 39940: Training cost= 0.2557, Training acc= 0.8524, Validation cost= 0.2923, Validation acc= 0.8524
Epoch 39950: Training cost= 0.3134, Training acc= 0.8524, Validation cost= 0.3229, Validation acc= 0.8524
Epoch 39960: Training cost= 0.2286, Training acc= 0.8524, Validation cost= 0.2172, Validation acc= 0.8525
Epoch 39970: Training cost= 0.2442, Training acc= 0.8524, Validation cost= 0.2743, Validation acc= 0.8525
Epoch 39980: Training cost= 0.3071, Training acc= 0.8524, Validation cost= 0.2636, Validation acc= 0.8525
Epoch 39990: Training cost= 0.2866, Training acc= 0.8524, Validation cost= 0.2224, Validation acc= 0.8525
Epoch 40000: Training cost= 0.2152, Training acc= 0.8524, Validation cost= 0.2477, Validation acc= 0.8525
tm  [-0.5 -0.  -2.3 11.6 -1.  -0.3 -0.1 -0.  -0.1 -0.5 -0.6  0.1 -0.5 -0.1 -4.1 -0.3 -0.3 -0.4 -0.4 -2.  -0.9 -0.1 -1.4 -0.3 -0.1 -0.1 -0.3 -0.2  0.7 -0.8  3.3 -0.2 -0.   3.6 -0.1 -0.  -0.2 -1.9  8.6 -0.1 -0.  -2.  -0.3 -0.2  0.6 -0.1 12.1  0.8  1.3 -4.5 -0.3 -0.2  0.5 -4.9 -1.5  4.3 -0.1 -0.4 -0.  -2.3 -1.5 -0.6 -0.4 -0.6  0.7 -0.5  0.   0.3  0.1 -0.3 -0.1 -1.3 -0.6 -0.3  5.8 -0.2 -0.2 -0.3 -0.1 -0.4 28.  -0.  -0.5 -0.3 -1.  -1.7  2.3 -0.4 -0.4 -0.6 -0.1 -0.1 -0.  -0.1 -0.6 -0.3 -0.7  0.3 -0.3 -0.1  2.4 -2.5 -0.1 -0.1 -0.3 -0.3  2.4  2.1 -0.  -2.7 -0.  -0.5 -0.1 -0.5  0.   8.7  1.  -0.1 -0.2  0.7 -0.3 10.7 -0.1 -0.  -0.1 -5.  -0.2 17.8  2.  -0.1 -0.3  0.1  1.  -0.4 11.3 14.5 -0.2 -0.1 -0.3 -0.7  1.5  0.8  0.8 -0.2 -0.  -0.2 -0.3 -0.1  4.1 -0.  -1.  -0.2 -0.4 -0.1 -0.1 -0.2  1.  -0.  -0.7 -0.6 -0.5 -0.1 -0.3 -0.1 -0.1  0.4 -0.2  0.5 -0.2 -0.1 -0.2 -0.3 -0.1 -0.1 -0.2 -0.8 -1.1 -0.4 -0.9 -0.1 -1.2  0.2 -0.2 -1.5 -0.2  0.1 -0.  -0.5 -0.1  2.3 -0.2  0.2 -0.4 -1.1 11.7 -0.5  3.1  0.6  0.1 -0.2 -0.  -0.1 -0.  -0.5 -0.2  5.3 -0.1 -0.4 -2.7 -0.4 -0.4  2.1 -0.9  0.1  0.5  0.8  0.9 -0.6 -0.1  0.3 -0.4 -0.1 -0.3 -0.8 -0.6  1.  -3.  -0.8  2.4  1.5 -0.2 -1.1 -0.  -1.2 -1.   3.4 -0.2  2.8  0.4 15.  -0.1  4.1  0.2  0.  -6.  -3.  -0.5 -0.2 -1.2 -0.5 -7.1 -0.3  5.3 -0.4  9.3  2.4]
ty_50sample [[9 3 6 4 5 1 7 0 8 2]
 [9 2 8 5 7 6 3 0 1 4]
 [8 1 0 9 7 3 4 5 6 2]
 [4 2 1 9 3 7 6 0 0 8]
 [7 9 4 0 3 1 1 8 5 2]
 [4 9 7 2 0 0 5 3 8 6]
 [7 5 0 6 1 2 9 4 3 8]
 [9 5 4 6 0 7 1 8 3 2]
 [6 5 9 7 2 8 3 4 0 1]
 [3 6 7 4 8 2 0 9 1 5]]
tt_50sample [[9 3 6 4 5 1 7 0 8 2]
 [9 2 8 5 7 6 3 0 1 4]
 [8 1 0 9 7 3 4 5 6 2]
 [4 2 1 9 3 7 6 5 0 8]
 [7 9 4 0 3 1 6 8 5 2]
 [4 9 7 2 1 0 5 3 8 6]
 [7 5 0 6 1 2 9 4 3 8]
 [9 5 4 6 0 1 7 8 3 2]
 [6 5 9 7 2 8 3 4 0 1]
 [3 6 7 4 8 2 0 9 1 5]]
vm  [-1.7 -0.2  1.8 27.2 -1.3  0.3 -0.1 -0.1  0.2  1.5 -1.8 -0.  -0.2 -0.2 -4.9 -0.9  0.3 -0.2  1.9 -1.6 -1.  -0.1  1.3 -0.2  0.1  1.9 -0.2  0.6 -1.1 -4.  -1.9 -0.4  0.  -5.3 -0.4  0.4  1.9  3.1 17.8 -0.2  1.  -1.1 -1.4 -1.1 -0.6 -0.3 12.1 -0.3 -2.   5.4 -0.2 -0.1 -0.1 -3.  -0.1  5.  -0.6  4.9  3.1  5.9  1.2 -0.7  0.7 -0.3 -0.4 -0.   0.8 -0.7 -0.2 -0.1 -0.6  2.  -0.4 -0.5  4.3 -0.1 -0.4 -0.4 -0.3 -0.4 11.8  0.4 -0.5 -0.8  1.7 -1.  -3.6 -0.3 -0.4 -0.5  0.6 -0.2 -0.1 -0.6 -0.2 -0.5 -0.2  0.5 -0.3 -0.  -0.5 -1.9  0.5 -0.5  0.8 -0.6  3.4 -0.8 -0.3 -2.3  1.2 -0.3  0.  -0.   4.9 -2.4  0.2 -0.5 -0.1 -0.2  0.1  8.9 -0.4 -0.1 -0.3 -6.1 -0.1 12.3  0.5 -3.  -0.8 -0.2 -0.  -0.   7.7 -2.8 -0.4 -0.1  0.7 -0.5 -0.4 -1.  -0.9 -0.4  0.2 -0.2  0.   0.7  3.6 -0.1 -2.4 -0.2 -1.  -0.3 -0.1 -0.   0.2 -0.6  0.8  1.4 -0.4 -1.5 -0.3 -0.1 -0.1 -0.2  0.2  0.3 -0.4 -0.1 -0.  -0.3 -0.5  0.  -0.1 -0.6 -0.5 -0.1 -1.7 -0.2 -0.6 -0.3  0.9 -1.  -0.2  0.5 -1.   0.6 -0.3 11.6 -0.2 -0.2  0.  -0.8  1.  -0.   1.2 -0.9 -0.2  0.4 -0.1 -0.  -0.1 -0.1 -0.5 10.6 -0.2 -0.5  6.7 -0.3 -0.3 -1.6 -0.4  5.9  0.4 -0.6  5.1 -0.7 -0.7 -0.5 -0.3 -0.1 -0.4 -0.7 -0.6 -1.2 -1.2  1.3 -0.7 -1.4 -0.4 -1.2  0.2  1.9 -0.1 -0.2 -0.4  1.7  1.1 22.1 -0.2  6.6 -0.3 -0.1 -2.1 -3.7 -0.1 -0.1 -0.8  2.5 -3.1  0.  10.5  0.9  2.3 11.8]
vy_50sample [[1 0 0 8 3 2 6 5 7 4]
 [4 5 9 6 2 1 8 0 3 7]
 [5 8 2 4 9 1 1 3 0 7]
 [1 7 6 8 5 9 2 3 0 4]
 [5 1 2 2 0 6 9 4 8 3]
 [8 7 9 4 0 1 5 6 3 2]
 [9 9 8 8 4 5 2 6 0 3]
 [3 8 7 0 9 1 2 5 4 6]
 [4 5 2 0 3 6 7 9 8 1]
 [7 3 5 5 6 2 8 4 9 0]]
vt_50sample [[1 9 0 8 3 2 6 5 7 4]
 [4 5 9 6 2 1 8 0 3 7]
 [5 8 2 4 9 6 1 3 7 0]
 [1 7 6 8 5 9 2 3 0 4]
 [5 1 7 2 0 6 9 4 8 3]
 [8 7 9 4 0 5 1 6 3 2]
 [9 1 7 8 4 5 2 6 0 3]
 [3 8 7 9 0 1 2 5 4 6]
 [4 5 2 0 3 6 7 8 9 1]
 [7 3 5 6 1 2 8 4 9 0]]
Epoch 40010: Training cost= 0.2473, Training acc= 0.8525, Validation cost= 0.2677, Validation acc= 0.8525
Epoch 40020: Training cost= 0.3319, Training acc= 0.8525, Validation cost= 0.2507, Validation acc= 0.8525
Epoch 40030: Training cost= 0.2168, Training acc= 0.8525, Validation cost= 0.2568, Validation acc= 0.8525
Epoch 40040: Training cost= 0.2266, Training acc= 0.8525, Validation cost= 0.2962, Validation acc= 0.8526
Epoch 40050: Training cost= 0.3185, Training acc= 0.8525, Validation cost= 0.2347, Validation acc= 0.8526
Epoch 40060: Training cost= 0.2308, Training acc= 0.8525, Validation cost= 0.2516, Validation acc= 0.8526
Epoch 40070: Training cost= 0.2985, Training acc= 0.8525, Validation cost= 0.2439, Validation acc= 0.8526
Epoch 40080: Training cost= 0.2145, Training acc= 0.8525, Validation cost= 0.2285, Validation acc= 0.8526
Epoch 40090: Training cost= 0.2688, Training acc= 0.8525, Validation cost= 0.2410, Validation acc= 0.8526
Epoch 40100: Training cost= 0.2448, Training acc= 0.8526, Validation cost= 0.2137, Validation acc= 0.8526
tm  [-1.4 -0.6  0.5 -1.9 -1.  -0.1 -0.2 -0.2 -0.1 -0.2  4.3 -0.  -0.  -0.3  6.6  7.2 -0.1 -0.3 -0.2  1.  -1.3  0.5  0.2 -0.1 -1.1  1.  -0.  -0.5  1.4 -1.2 -1.  -0.1 -0.1 -2.9 -0.2 -0.1 -0.   8.2  2.3 -0.5  3.3 -0.9 -0.4  3.5 -0.  -0.5 -1.7 -0.5 -0.8  9.1 -0.5 -0.  -0.7 15.  -1.3 -0.4 -0.6 -1.3  4.   4.1  7.9  0.3 -0.4 -0.2 -0.9 -0.5 -0.3  0.9  0.5 -0.3 -0.4 -1.7  0.1 -0.1 -5.5  0.  -0.1  1.4 -0.1 -0.3 -6.   0.5 -0.1 -0.  -0.  -0.7 -0.5 -0.1  0.7 -0.5 -0.4 -0.1 -0.3 -0.3 -0.7 -0.4 -0.2 -3.  -0.2 -0.7  1.   3.1  0.3  0.5 -0.1 -0.8 -2.4 -0.6  1.9  0.1 -0.3 -0.1 -0.3 -0.8 -0.1  9.   2.3 -0.4  0.4  0.1  0.4 -0.8 -0.5 -0.2  0.1  7.9 -0.2 -3.4  3.2  5.7 -0.6 -0.3 -0.6 -0.1 -3.3 -5.9 -0.4 -0.1 -0.3 -0.4 -0.4 -0.4 -0.6 -0.1 -0.3 -0.4 -0.1 -0.  -0.9 -0.3  1.  -0.   1.3  0.  -0.3 -0.1 -0.4 -0.1  3.9  0.3 -0.  -2.1  0.  -0.2 -0.2 -0.6 -0.5  0.3 -0.3 -0.2 -0.  -0.2 -0.1 -0.1  0.3  1.6 -0.  -0.4 -0.1 -0.2  0.1 -0.1 -0.2 -1.3 -0.2  0.2 -0.4 -0.4 -0.5  3.6 -0.1 -0.4 -0.1 -0.9 -2.9 -1.1 -1.2  0.1 -0.1 -0.2 -0.3 -0.1 -0.3 -0.1 -0.3 -2.6 -0.3 -0.2  9.3 -0.3 -0.5  3.7 -0.3  4.6 -0.8 -0.1 -1.5 -0.7 -0.6 -0.6 -0.2 -0.2 -0.3 -1.  -1.1  3.5  0.9 -0.5 -0.2 -0.3 -0.2  2.2 -0.3  2.5 -1.3  0.4  0.1 -1.5  1.6  0.5 -0.2  0.6 -0.4  0.  17.8  2.4  0.4 -0.3 -0.8 -0.2 15.4 -0.1  1.5 -0.2 -1.2 -0.8]
ty_50sample [[2 8 1 4 7 3 5 0 0 6]
 [7 2 4 5 0 8 3 6 9 1]
 [4 0 2 3 8 5 1 7 9 6]
 [9 6 4 7 5 2 0 1 3 8]
 [3 0 0 8 5 7 2 1 4 4]
 [9 4 7 5 0 6 2 8 3 1]
 [8 3 9 6 5 4 2 7 1 0]
 [7 2 5 1 9 3 0 4 8 6]
 [1 3 4 7 6 8 2 5 0 9]
 [9 8 1 3 7 0 4 5 2 6]]
tt_50sample [[2 1 8 4 7 3 5 0 9 6]
 [7 2 4 5 0 8 3 6 9 1]
 [4 0 2 3 8 5 1 7 9 6]
 [9 6 4 7 5 2 0 1 3 8]
 [3 6 0 8 5 7 2 1 9 4]
 [9 4 7 5 0 6 2 8 3 1]
 [8 3 9 6 5 4 2 7 1 0]
 [7 2 5 1 9 3 0 4 8 6]
 [1 3 4 7 6 8 2 5 0 9]
 [9 8 1 3 7 0 4 5 2 6]]
vm  [-0.1 -0.7  7.3  3.5 -1.7 -0.3 -0.  -0.3 -0.1  0.7 -5.1 -0.3 -0.2 -0.5  4.8 -2.  -0.2 -0.5  1.6  0.5 -1.1 -0.4  0.8  0.4 -0.9  2.5 -0.4 -0.1 -1.2 -1.9 -1.6 -0.2  2.  -2.7 -0.2 -0.3  0.4 -1.6 -4.3 -0.5  1.6 -1.1 -0.9 -1.5 -0.5 -0.8 -1.1 -0.6  3.7  5.2 -0.6 -0.3 -0.9  1.1  0.8 -0.5 -0.7  3.4  3.9  6.9  1.3 -0.6 -0.2 -0.2 -0.7 -0.2 -0.  -0.2  3.5 -0.2 -0.6  5.6 -0.3 -0.9 -5.5  0.2 -0.4  0.7 -0.3 -0.1 -5.3 -0.2 -0.3 -0.3 -1.3 -1.5 -0.7  0.  -0.1 -0.7 -0.3 -0.2 -0.2 -0.4 -0.6 -0.4  0.9 -3.4 -0.7 -1.  -0.2 -0.  -0.8 -0.3 -0.1 -0.3 -2.4 -0.9 -1.3  0.6  0.4  0.4 -0.1 -0.3  6.2 -3.4 -0.   2.6  1.2  0.4 -0.  -0.8 -0.6 -0.3 -0.2  6.  -0.4  1.8  1.2  7.6  0.3 -0.5 -0.6 -0.2  7.8  2.8 -0.2 -0.1 -0.1 -0.3  0.5 -1.2  1.6 -0.4 -0.2 -0.2 -0.4  0.  -0.8 -0.5 -0.4  0.5  2.8 -0.1 -0.6 -0.2 -0.4 -0.4 -1.1  1.3 -0.  -0.3 -0.1 -0.1 -0.5 -0.8 -0.4 -0.4 -0.6 -0.1 -0.1  0.1 -0.3 -0.4 -0.3  2.5 -1.7 -0.4  6.1 -0.2  0.5 -0.4  0.7 -1.4 -0.2  0.4  1.2 -0.1 -0.   5.3 -0.1 -0.2 -0.3 -1.1  0.6 -0.3 -1.5 -1.7 -0.1 -0.3 -0.  -0.1  0.8  0.1 -0.5 -2.2 -0.2 -0.1  8.8 -0.4 -0.8 -2.1 -0.8 -1.1 -0.5 -0.4  8.1 -0.7 -0.5 -0.5 -0.2 -0.3 -0.7 -1.5  2.3 -1.6 -1.7 -0.1  0.4  1.6  1.   2.2 -0.5  2.1 -0.  -1.5  2.1 -1.5  0.9  0.3 -0.1  0.1 -0.2 -0.2 16.2  0.2  1.3 -0.6 -0.9  1.  14.4 -0.1 -2.6 -0.   5.2 -1.6]
vy_50sample [[0 6 8 3 7 1 1 2 4 4]
 [0 7 5 3 2 1 9 6 4 8]
 [9 9 2 3 0 7 5 4 8 6]
 [7 2 4 6 0 3 5 1 1 8]
 [6 5 1 2 3 9 4 7 0 8]
 [5 3 6 7 9 0 4 2 1 8]
 [5 9 2 8 6 7 3 1 4 0]
 [7 1 2 4 8 6 9 0 3 5]
 [8 0 3 1 2 6 9 5 7 4]
 [8 2 7 5 1 6 4 9 3 0]]
vt_50sample [[0 6 8 3 7 5 1 2 9 4]
 [0 7 5 3 2 9 1 6 4 8]
 [9 1 2 3 0 7 5 4 8 6]
 [7 2 4 6 0 3 5 9 1 8]
 [6 5 1 2 3 9 4 7 0 8]
 [5 3 6 7 9 4 0 2 1 8]
 [5 9 2 8 6 7 3 1 4 0]
 [1 7 2 4 8 6 9 0 3 5]
 [8 0 3 1 2 6 9 5 7 4]
 [8 7 2 5 1 6 4 9 3 0]]
Epoch 40110: Training cost= 0.3182, Training acc= 0.8526, Validation cost= 0.2837, Validation acc= 0.8526
Epoch 40120: Training cost= 0.2902, Training acc= 0.8526, Validation cost= 0.2716, Validation acc= 0.8527
Epoch 40130: Training cost= 0.2264, Training acc= 0.8526, Validation cost= 0.2678, Validation acc= 0.8527
Epoch 40140: Training cost= 0.3038, Training acc= 0.8526, Validation cost= 0.2730, Validation acc= 0.8527
Epoch 40150: Training cost= 0.3068, Training acc= 0.8526, Validation cost= 0.2639, Validation acc= 0.8527
Epoch 40160: Training cost= 0.2767, Training acc= 0.8526, Validation cost= 0.2784, Validation acc= 0.8527
Epoch 40170: Training cost= 0.2682, Training acc= 0.8526, Validation cost= 0.2597, Validation acc= 0.8527
Epoch 40180: Training cost= 0.2406, Training acc= 0.8527, Validation cost= 0.2661, Validation acc= 0.8527
Epoch 40190: Training cost= 0.2500, Training acc= 0.8527, Validation cost= 0.2761, Validation acc= 0.8527
Epoch 40200: Training cost= 0.2534, Training acc= 0.8527, Validation cost= 0.3050, Validation acc= 0.8527
tm  [-0.2  0.3 -2.1  5.5 -0.3 -0.2 -0.2 -0.1 -0.2 -0.5  3.8 -0.7 -0.  -0.1 -2.7  5.4  0.4 -0.4 -0.  -1.1 -0.9 -0.3  1.8 -0.3 -0.6 -0.1 -0.4 -0.  -0.4 -1.1 -0.8 -0.3 -0.4 -5.7 -0.2 -0.3  0.9  2.5  0.6 -0.7 -0.6 -2.  -0.4 -1.  -0.   0.6  4.3 -0.3  6.   4.9 -0.3 -0.2 -0.3  4.5 -1.2  2.7 -0.2 -0.8  1.   5.2 -1.6  0.9 -0.6  0.5 -0.7  0.1  0.4 -0.6 -0.4  1.   0.4 -0.4  0.3  0.3 -0.9 -0.1 -0.4  0.3 -0.2 -0.3 -1.  -0.6 -0.2  1.6 -1.5 -1.9  4.5 -0.2 -0.1 -0.  -0.7 -0.  -0.1 -0.4 -0.4 -0.2  0.6 -1.7 -0.4 -0.1  2.3 -1.9 -0.6 -0.1 -0.3 -0.1 -0.8 -0.6  1.1 -2.1 -0.2  0.2 -0.  -0.4 -0.2  5.1 -0.4 -0.5 -0.1 -0.5 -0.3  7.7 -0.2 -0.7 -0.4 -3.4 -0.1 -0.7  0.1  0.8  1.  -0.7 -0.1 -0.2 12.7 -0.4 -0.1 -0.1 -0.2 -0.3 -1.1 -0.5 -1.1  0.  -0.2 -0.1 -0.1 -0.2  2.5 -0.1 -0.4 -0.   4.4 -0.7  0.2 -0.2 -0.2 -0.7 -0.9 -0.4  0.   2.2 -0.4 -0.1 -0.1  0.6 -0.  -0.  -0.1 -0.1 -0.1  0.1 -0.3 -0.2  0.2 -0.4 -0.6 -0.6  0.6  0.1 -0.4 -0.1 -0.6 -1.   0.2 -0.1  1.3  0.8 -0.1  3.1 -0.  -0.5 -0.7 -0.3 12.3 -0.   0.6 -0.1 -0.2 -0.2  0.3  0.2  0.  -0.4 -0.2 -0.9 -0.3 -0.1  9.5 -0.1 -1.   0.3 -0.8 -1.4 -0.1 -0.2  3.5 -0.5 -0.5 -0.2  0.2 -0.3  0.3 -1.2  2.1  3.7  2.1  0.6 -0.7  5.  -0.5 -0.6 -0.1  3.3  0.7  2.6 -0.2  0.4  0.7 13.9 -0.2  4.4  0.5 -0.4  4.6 -1.   0.4 -0.1 -1.2 -0.4  1.2 -0.2  0.1 -0.4 -0.6  1.4]
ty_50sample [[2 8 6 9 3 4 0 5 1 1]
 [4 5 6 1 7 3 0 9 8 2]
 [2 3 7 4 5 0 8 1 6 9]
 [7 4 5 9 1 3 6 8 2 0]
 [0 6 8 2 4 9 3 7 5 1]
 [6 4 9 3 7 5 2 0 1 8]
 [6 7 4 8 0 3 5 9 2 1]
 [1 6 4 8 0 2 5 7 3 9]
 [0 8 6 3 1 2 5 9 4 7]
 [9 2 6 1 0 4 8 3 7 5]]
tt_50sample [[2 8 6 3 9 4 0 5 1 7]
 [4 5 6 1 7 3 0 9 8 2]
 [2 3 7 4 0 5 8 1 6 9]
 [7 4 5 9 1 3 6 8 2 0]
 [0 6 8 2 4 9 3 7 5 1]
 [6 4 9 3 7 5 2 0 1 8]
 [6 7 4 8 0 3 5 9 2 1]
 [1 6 4 8 0 2 5 7 3 9]
 [0 8 6 3 1 2 5 9 4 7]
 [9 2 6 1 0 4 8 3 7 5]]
vm  [-1.4 -0.4  3.2 -0.9 -2.1 -0.3 -0.5  0.4  2.5  1.  -1.9  0.2 -0.4 -0.   5.8 -2.  -0.5 -0.2  1.4  1.9 -1.4 -0.   0.2 -0.3 -1.1  4.2 -0.3  0.1 -0.6 -4.5  0.2 -0.4 -0.9  2.3 -0.2  0.2 -0.9 -0.6 -1.  -0.4 -0.3 -1.6 -2.1 -0.5 -0.5 -0.1 -2.3 -0.1 -1.3 -0.2 -0.3 -0.2  0.7  0.8 -0.7 -0.5 -0.7 -0.7 11.7  2.2 11.  -0.7  0.8 -0.6  1.4 -0.7 -0.1  1.2  1.6 -0.3 -0.   1.1  0.5  1.8 -6.7 -0.6 -0.5 -0.8  0.5 -0.6 -1.8 -0.   1.1 -0.9 -0.1 -1.5 -2.2 -0.3 -0.3 -0.7 -0.3 -0.1 -0.3 -1.7 -0.6 -0.2 -1.  -4.  -0.7 -0.1 -0.5 -0.   0.1 -0.4 -0.   1.  -1.5  0.2 -0.6  2.2  0.4 -0.3 -0.  -0.8  8.7 -1.2  1.3  4.4 -0.5  2.3 -0.1 -1.2 -0.1 -0.4 -0.2  6.9 -0.4  2.5  9.1  6.2 -0.6 -0.4 -0.2  0.1 -0.5  0.5 -0.2 -0.1 -0.  -0.5  3.7 -1.1  0.9 -0.3  0.5 -0.4 -0.1 -0.1 -1.1 -0.  -0.  -0.2 -1.4  2.6  0.   0.2  0.6 -0.1  0.8 -0.2 -0.3 -1.5  0.8 -0.2 -0.3 -0.9  0.   2.5  0.2  0.1 -0.3 -0.  -0.8 -0.2 -0.3  2.6 -0.6 -0.4  2.9 -0.1 -0.  -0.3 -0.2 -2.4 -0.3  0.3 -0.9 -0.1 -0.  12.4 -0.2 -0.2 -0.1 -1.5 -4.4 -3.  -0.7 -2.  -0.3 -0.  -0.1 -0.1 -0.7  0.1 -0.3 -1.6 -0.2 -0.4  5.1 -0.6 -0.3 -1.2 -1.1  7.1 -0.5 -0.1  1.7 -0.9 -0.1  1.1 -0.3  0.1  0.1 -0.9 -0.1 -0.8 -3.  -0.   1.9 -0.5  0.1 -0.4 -0.1  2.  -0.3 -0.6 -0.1 -1.2  2.5 -0.4 -0.1 -0.3 -0.1 -0.   7.7  1.4 -0.3  0.7 -1.3  1.2  4.5 -0.2 -0.7 -0.1  6.8 -1.3]
vy_50sample [[1 0 3 7 8 6 4 5 2 9]
 [5 8 9 9 2 1 7 3 0 6]
 [0 1 8 5 4 6 3 7 9 2]
 [1 7 9 8 2 6 3 0 4 5]
 [4 1 7 3 5 6 0 8 9 2]
 [8 3 9 0 6 1 5 7 4 2]
 [2 9 7 7 0 1 4 8 5 6]
 [1 2 4 6 9 7 3 8 5 0]
 [7 0 4 2 1 1 8 9 5 6]
 [6 7 2 0 4 1 9 3 5 8]]
vt_50sample [[1 0 3 7 8 4 6 5 2 9]
 [5 8 9 4 2 1 7 3 0 6]
 [0 1 8 5 4 6 3 7 9 2]
 [1 7 9 2 8 3 6 0 4 5]
 [4 1 7 3 5 0 6 8 9 2]
 [8 3 9 0 6 1 5 7 2 4]
 [2 9 3 7 0 1 4 8 5 6]
 [1 2 4 6 9 3 7 8 0 5]
 [7 0 4 2 1 3 8 9 5 6]
 [6 7 2 0 4 1 9 3 8 5]]
Epoch 40210: Training cost= 0.2321, Training acc= 0.8527, Validation cost= 0.2187, Validation acc= 0.8527
Epoch 40220: Training cost= 0.2118, Training acc= 0.8527, Validation cost= 0.2678, Validation acc= 0.8528
Epoch 40230: Training cost= 0.2452, Training acc= 0.8527, Validation cost= 0.2406, Validation acc= 0.8528
Epoch 40240: Training cost= 0.2396, Training acc= 0.8527, Validation cost= 0.2619, Validation acc= 0.8528
Epoch 40250: Training cost= 0.2706, Training acc= 0.8527, Validation cost= 0.2563, Validation acc= 0.8528
Epoch 40260: Training cost= 0.2776, Training acc= 0.8527, Validation cost= 0.2649, Validation acc= 0.8528
Epoch 40270: Training cost= 0.2940, Training acc= 0.8528, Validation cost= 0.2568, Validation acc= 0.8528
Epoch 40280: Training cost= 0.2540, Training acc= 0.8528, Validation cost= 0.2849, Validation acc= 0.8528
Epoch 40290: Training cost= 0.2108, Training acc= 0.8528, Validation cost= 0.2459, Validation acc= 0.8528
Epoch 40300: Training cost= 0.2071, Training acc= 0.8528, Validation cost= 0.2237, Validation acc= 0.8529
tm  [-1.4  0.6  5.4 16.4 -1.7 -0.   0.9 -0.1 -0.9 -0.6  5.4 -0.1 -0.4 -0.2 -1.6 -0.2 -0.  -0.4  1.5 -0.7 -0.7 -0.4  1.7 -0.1 -0.8  4.  -0.   0.2 -1.7 -0.9 -0.9 -0.2 -0.4 -0.5 -0.1  0.1  4.9  4.1 12.7 -0.4 -0.2 -1.7  0.1 -0.8 -0.  -0.1  7.1 -0.5 -0.9  6.9 -0.1 -0.   0.8 -0.1  1.5  1.6 -0.2 -0.7 -1.   4.3 -0.3  1.5 -0.1 -0.3 -1.2  1.  -0.2 -0.8 -0.1  0.6 -0.3  5.9 -0.3 -0.4  7.  -0.3  0.7  0.  -0.3  0.4  9.8 -0.2 -0.4 -0.6 -0.  -1.7 -1.7 -0.3 -0.   1.8 -0.4 -0.1 -0.1  0.6 -0.3 -0.4  0.5  1.6 -0.4  0.9  1.1  3.8 -0.2 -0.2 -0.1  0.4  2.1 -0.6  1.  -2.4 -0.4 -0.1 -0.1  1.4  2.  -3.1 -0.1 -1.5 -0.   0.8  0.4  8.6 -0.4  0.1 -0.1 -2.1 -0.3  2.2 -2.1 -2.6 -0.2 -0.2 -0.4 -0.1 -0.8 -1.4 -0.5 -0.1 -0.3 -0.5 -0.5 -1.5 -0.5 -0.1 -0.1 -0.3 -0.1  0.1 -2.2 -0.3 -1.4 -0.1  0.3  0.3 -0.4  0.1 -0.4  1.3 -0.2 -0.5  0.3 -0.7 -0.  -0.1  0.1 -0.1 -0.2 -0.3 -0.2 -0.1 -0.4 -0.3 -0.   0.1 -0.1  2.7  0.7  0.3 -0.9 -0.   2.7  1.9  1.  -1.2 -0.1 -0.3 -0.9 -0.1  0.9  2.8 -0.3 -0.3 -0.1 -0.7  3.6  8.1  0.9 -0.4 -0.  -0.1  0.1 -0.1 -0.  -0.1 -0.   5.9 -0.2 -0.1 10.  -0.1 -0.2 -2.2 -0.1  5.   0.3 -0.1  3.8 -0.6 -0.6 -0.5 -0.2 -0.  -0.2 -0.7  2.2 -1.   1.7  0.1 -0.1 -0.6 -0.6 -1.4 -0.3  3.1  3.4 -1.3 -0.4  3.1 -0.3 27.8 -0.2  9.  -0.2 -0.2 -1.7 -2.4 -0.5 -0.1 -0.7 -0.1 -2.7 -0.2  7.5 -0.1 -1.1 10.2]
ty_50sample [[9 0 2 1 8 7 6 3 4 5]
 [7 3 9 8 0 4 1 2 6 5]
 [6 2 3 8 8 4 0 1 5 9]
 [1 7 5 0 0 8 4 9 3 2]
 [6 6 2 2 4 3 9 1 0 7]
 [1 2 6 0 7 3 5 4 8 9]
 [0 0 7 3 3 8 2 1 6 5]
 [5 8 4 4 3 2 6 0 1 7]
 [5 8 7 2 3 4 6 9 9 0]
 [3 0 9 4 2 1 5 8 6 7]]
tt_50sample [[9 0 2 1 8 7 6 3 4 5]
 [7 3 9 8 0 4 1 2 6 5]
 [6 2 3 8 7 4 0 1 5 9]
 [1 7 5 6 0 8 4 9 3 2]
 [6 8 5 2 4 3 9 1 0 7]
 [1 2 6 0 7 3 5 4 8 9]
 [4 0 7 3 8 9 2 1 6 5]
 [5 8 4 9 3 2 6 0 1 7]
 [5 8 7 2 3 4 6 9 1 0]
 [3 0 9 4 2 1 5 8 6 7]]
vm  [-1.2 -0.6 -0.5 -0.3 -1.5 -0.2  0.7 -0.1  1.  -0.5  6.3  0.9 -0.5 -0.4  0.4  0.6 -0.3 -0.3 -0.5 -0.  -1.6 -0.2 -1.2 -0.3 -1.3  2.1 -0.1 -0.5 -0.  -2.5  3.6 -0.4 -0.4  8.8 -0.3 -0.1 -0.1  2.1  8.  -0.7  3.9 -1.7 -0.7  4.2 -0.2 -0.5  0.2 -0.4 -1.2 -4.3 -0.4 -0.2  0.1 -0.2 -1.6  0.7 -0.5 -0.8  6.6 -2.3  6.3 -0.2  0.7 -0.4 -0.4 -0.6 -0.2 -0.2  1.8 -0.2 -0.4 -1.3  0.5 -0.2 -3.3  1.4 -0.   0.5 -0.2 -0.4 11.9  0.1 -0.1 -0.2 -0.1 -1.2 -0.6  0.2 -0.1 -0.8 -0.7 -0.1  0.2 -0.4 -0.8 -0.2 -0.2 -2.5 -0.9 -0.9  1.5 -0.8  0.5 -0.3 -0.1 -0.2 -1.7  2.   1.7 -1.  -0.6 -0.2 -0.1 -0.8  1.6  6.3  2.   1.2  0.1 -0.3 -0.   1.3 -0.3 -0.3 -0.4  0.4 -0.2  3.8  7.7  8.8 -0.9 -0.2 -0.3  0.1 -3.1  3.1 -0.5 -0.  -0.4 -0.5  0.8 -0.3  1.8 -0.2 -0.2 -0.1  0.2 -0.1 -0.3 -0.3  0.3  0.1 -2.   0.2 -0.1 -0.1 -0.4 -0.3  3.6  1.   0.2 -2.  -0.2 -0.1 -0.2 -0.6 -0.3  0.4 -0.3 -0.1 -0.1 -0.2 -0.2 -0.4 -0.2  1.  -0.1 -0.6 -0.6 -0.1 -0.4 -0.4 -0.1 -1.7 -0.1  0.3 -0.5 -0.1 -0.4  7.2 -0.  -0.1 -0.1 -1.1 -1.9 -2.4 -0.6 -0.4 -0.1 -0.2  0.  -0.2  0.1 -0.1 -0.3 -0.8 -0.3 -0.3 -1.9 -0.3 -0.6  2.7 -0.5  6.5 -0.7  1.  -1.7 -1.   0.5  0.3 -0.2 -0.1 -0.5 -1.3 -2.1 -0.3 -2.2 -0.8  0.4 -0.3 -0.2  2.  -0.1 -0.8 -1.   0.8 -0.  -1.   0.6  3.8 -0.2  1.3 -0.2 -0.2 -2.2 -1.2 -0.2 -0.3 -1.  -0.5 -3.1 -0.   4.7  1.   5.5 -1.7]
vy_50sample [[1 3 4 9 7 5 2 0 6 8]
 [0 4 9 8 2 5 7 3 1 6]
 [6 7 2 5 9 8 0 4 1 3]
 [4 1 7 5 8 9 6 3 0 2]
 [8 8 6 5 3 0 2 7 4 1]
 [9 4 5 5 2 7 1 1 6 0]
 [0 0 8 9 5 6 7 3 1 4]
 [7 0 1 4 3 3 8 2 5 6]
 [8 4 1 3 9 7 6 2 0 5]
 [1 8 0 9 7 4 2 6 5 3]]
vt_50sample [[1 3 4 9 7 5 2 0 6 8]
 [0 4 9 8 2 5 7 3 1 6]
 [6 7 2 5 9 8 0 4 1 3]
 [4 1 7 5 8 9 6 3 0 2]
 [8 9 6 3 5 0 2 7 1 4]
 [9 4 5 8 2 3 7 1 6 0]
 [2 0 8 9 5 6 7 3 1 4]
 [7 0 9 1 4 3 8 2 5 6]
 [8 4 1 3 9 7 6 2 0 5]
 [1 8 0 9 7 4 2 6 5 3]]
Epoch 40310: Training cost= 0.2470, Training acc= 0.8528, Validation cost= 0.2006, Validation acc= 0.8529
Epoch 40320: Training cost= 0.2430, Training acc= 0.8528, Validation cost= 0.2667, Validation acc= 0.8529
Epoch 40330: Training cost= 0.2088, Training acc= 0.8528, Validation cost= 0.2331, Validation acc= 0.8529
Epoch 40340: Training cost= 0.2682, Training acc= 0.8528, Validation cost= 0.3003, Validation acc= 0.8529
Epoch 40350: Training cost= 0.2543, Training acc= 0.8529, Validation cost= 0.2855, Validation acc= 0.8529
Epoch 40360: Training cost= 0.2336, Training acc= 0.8529, Validation cost= 0.2868, Validation acc= 0.8529
Epoch 40370: Training cost= 0.2746, Training acc= 0.8529, Validation cost= 0.2643, Validation acc= 0.8529
Epoch 40380: Training cost= 0.2600, Training acc= 0.8529, Validation cost= 0.2732, Validation acc= 0.8530
Epoch 40390: Training cost= 0.3096, Training acc= 0.8529, Validation cost= 0.3074, Validation acc= 0.8530
Epoch 40400: Training cost= 0.2712, Training acc= 0.8529, Validation cost= 0.2487, Validation acc= 0.8530
tm  [-1.  -0.1 12.6 10.8 -1.  -0.3 -0.4 -0.1  0.4 -0.3  9.8 -0.2 -0.1  0.6  8.6  3.7 -0.3  0.   0.6 -0.9 -1.5 -0.3 -0.7 -0.5 -0.7  0.3 -0.4  0.6  0.2 -2.3  0.5 -0.2 -0.6 17.3  0.  -0.2 -0.4  5.5  7.9 -0.7 -0.2 -0.5 -0.9 -0.3 -0.3  1.2  0.5  0.5 -0.3 -2.6 -0.2 -0.2 -0.6  4.5 -1.  -0.9 -0.6  6.5  6.1  1.4  4.6 -0.3 -0.4  0.2  1.8 -0.6 -0.3 -0.2  0.8 -0.6  0.6 -0.8  0.1  2.3 -2.9 -0.7 -0.4 -0.5 -0.  -0.4 12.1 -0.4 -0.  -0.1 -0.  -0.2 -2.2 -0.  -0.5 -0.9 -0.1 -0.1 -0.  -1.1 -0.3 -0.2 -0.3 -2.8 -0.5 -0.2  3.3  5.9  1.3 -0.3 -0.2  0.9 -1.3 -0.1  0.3 -1.4 -0.2 -0.2 -0.2 -1.   1.4  7.9 -0.5  1.6 -0.2 -0.3 -0.2  4.5  1.6  0.9  0.3 11.  -0.2 -0.6  8.7  4.4 -0.3 -0.3 -0.3 -0.3 -6.5  4.3 -0.2 -0.1 -0.4 -0.2 -0.4 -0.  -0.1 -0.3 -0.1  0.9 -0.1 -0.  -1.8 -0.1 -1.   0.3 -1.4 -0.4  0.6  0.2  1.  -0.4  2.8 -0.4 -0.4 -1.2  0.1 -0.  -0.2  0.1  0.1  2.2  0.3 -0.3 -0.2 -0.  -0.3 -0.1  0.2  2.9  0.6 -0.6 -0.7 -0.  -1.3 -0.6 -0.6 -1.3 -0.2 -0.1 -0.8 -0.7 -0.   7.   0.  -0.1 -0.4 -0.5 -0.9 -2.6 -0.3 -0.5 -0.1 -0.2 -0.3 -0.2  0.2 -0.   0.9 -2.2 -0.2 -0.2 -2.7 -0.  -0.7  2.1 -0.9  4.  -0.3 -0.2  2.5 -1.  -0.1 -0.3 -0.3  0.   1.7 -0.6 -0.9  0.4 -0.1  2.  -1.3  1.2 -0.5 -0.3 -0.  -1.1  0.7 -2.8  0.  -0.2  3.3 -0.4 -0.2 -0.2  0.5  0.3 -2.2  1.2 -0.4  0.9 -1.3 -0.3 -3.3 -0.2  5.5 -0.1  0.4 -0.3]
ty_50sample [[7 1 2 3 5 9 0 6 8 8]
 [4 2 0 7 8 5 6 1 3 9]
 [4 9 2 1 7 6 8 5 3 0]
 [7 8 5 9 3 0 2 6 4 1]
 [0 9 6 2 1 5 8 4 7 7]
 [8 2 9 3 7 1 5 6 0 4]
 [9 5 8 4 3 6 0 2 1 7]
 [0 0 5 5 1 1 3 2 6 8]
 [4 8 7 0 2 5 3 1 9 6]
 [2 1 7 9 3 0 6 6 4 5]]
tt_50sample [[7 1 2 3 5 9 0 6 4 8]
 [4 2 0 7 8 5 6 1 3 9]
 [4 9 2 1 7 6 8 5 3 0]
 [7 8 5 9 3 0 2 6 4 1]
 [0 9 6 2 1 5 8 4 3 7]
 [8 2 9 3 1 7 5 6 0 4]
 [9 5 8 4 3 0 6 2 1 7]
 [4 0 7 5 9 1 3 2 6 8]
 [4 8 7 0 2 5 3 1 9 6]
 [2 1 7 9 3 0 6 8 4 5]]
vm  [-0.1 -0.1  2.9  4.4 -0.8 -0.2 -0.5 -0.2 -1.1 -0.9  5.1 -0.2 -0.2 -0.3  1.4  7.7 -0.1 -0.3  0.1 -0.2 -0.6 -0.1  1.1  0.5 -1.3 -0.1 -0.2 -0.5  1.6  1.9 -1.6  0.2  0.6 -3.3 -0.2 -0.3  2.   3.4 -2.3 -0.3  0.7  2.6  2.  -1.  -0.3 -0.5 -0.6 -0.6  2.5  5.5 -0.6 -0.1 -0.5 12.3 -1.5 -0.1 -0.5  7.9 -1.6  6.3  0.9 -0.7 -0.4 -0.2 -0.3 -0.2 -0.1  0.4  0.2 -0.5 -0.3 -1.7 -0.1 -0.1 -3.8 -0.5 -0.4 -0.4 -0.1 -0.3 -3.8 -0.4 -0.1 -0.3 -1.4  3.2 -0.  -0.2  0.4 -0.5 -0.2 -0.1 -0.4  2.2 -0.3  0.  -0.1 -2.1 -0.4 -0.3  3.  -0.6 -0.7 -0.2  0.9 -0.4 -2.3 -0.6  1.2 -0.4 -0.2 -0.2 -0.2  0.  -2.  11.4 -0.1 -1.1 -0.   0.3  0.  -0.2 -0.5 -0.7 -0.4  1.7  0.3 -2.9 -0.9  4.   0.4 -0.4 -0.4 -0.1  8.  -0.1  0.1 -0.3 -0.2 -0.8 -1.1 -0.4 -0.8  0.1 -0.1 -0.2 -0.2 -0.2  5.  -0.3 -0.6  0.4  2.9 -0.2 -0.4 -0.3  0.1 -0.2 -0.8 -0.2 -0.8  0.2 -0.2 -0.2 -0.5 -0.1 -0.1 -0.6 -0.3  0.3 -0.1  0.2 -0.2 -0.3 -0.3 -1.1 -1.7 -0.2  3.3 -0.  -2.  -0.1  0.  -1.9 -0.2 -0.1  0.7 -0.4 -0.6 -0.7 -0.1 -0.2 -0.1 -1.   2.1  3.  -0.7  4.6  0.6 -0.1 -0.3 -0.3 -0.1 -0.2 -0.3 -2.2 -0.1 -0.3 -0.3 -0.5 -0.5  3.1 -0.4 -1.  -0.4 -0.6  4.7 -0.3 -0.5 -0.4 -0.1 -0.4 -0.2 -1.4  1.1  5.1  2.4 -0.3 -0.3  1.2 -0.6  2.9 -0.3 -0.2 -1.2 -0.3 -0.2 -1.  -0.3 -3.9 -0.  -1.3 -0.3  0.5 12.   0.3  1.4 -0.1 -0.4 -0.2  9.6  0.3 -1.6  0.  -1.  -0.4]
vy_50sample [[2 5 8 6 3 7 9 1 4 0]
 [1 9 2 5 0 8 4 3 7 6]
 [9 6 5 2 3 4 7 0 0 1]
 [2 0 4 5 3 9 7 6 1 8]
 [5 2 0 3 4 1 7 8 6 9]
 [3 8 9 0 6 4 5 2 7 1]
 [9 6 5 5 2 8 7 1 0 4]
 [6 1 8 2 9 0 5 4 7 3]
 [5 2 9 3 9 6 0 7 1 1]
 [7 8 5 0 3 1 2 6 4 9]]
vt_50sample [[2 5 8 6 3 7 9 1 4 0]
 [1 9 2 5 0 8 4 3 7 6]
 [9 6 5 2 4 3 7 0 8 1]
 [2 0 4 5 3 9 7 6 1 8]
 [5 2 0 3 4 1 7 8 6 9]
 [3 8 9 0 6 4 5 2 7 1]
 [9 6 5 3 2 8 1 7 0 4]
 [6 1 8 2 9 0 5 4 7 3]
 [5 2 9 4 3 0 6 7 8 1]
 [7 8 5 0 3 1 2 6 4 9]]
Epoch 40410: Training cost= 0.2333, Training acc= 0.8529, Validation cost= 0.2270, Validation acc= 0.8530
Epoch 40420: Training cost= 0.2440, Training acc= 0.8529, Validation cost= 0.2275, Validation acc= 0.8530
Epoch 40430: Training cost= 0.2148, Training acc= 0.8529, Validation cost= 0.2345, Validation acc= 0.8530
Epoch 40440: Training cost= 0.2720, Training acc= 0.8530, Validation cost= 0.2230, Validation acc= 0.8530
Epoch 40450: Training cost= 0.2450, Training acc= 0.8530, Validation cost= 0.2658, Validation acc= 0.8530
Epoch 40460: Training cost= 0.2498, Training acc= 0.8530, Validation cost= 0.2771, Validation acc= 0.8530
Epoch 40470: Training cost= 0.2231, Training acc= 0.8530, Validation cost= 0.2202, Validation acc= 0.8531
Epoch 40480: Training cost= 0.2599, Training acc= 0.8530, Validation cost= 0.2875, Validation acc= 0.8531
Epoch 40490: Training cost= 0.3096, Training acc= 0.8530, Validation cost= 0.2908, Validation acc= 0.8531
Epoch 40500: Training cost= 0.2634, Training acc= 0.8530, Validation cost= 0.2613, Validation acc= 0.8531
tm  [-1.  -0.5 -0.6 -3.3 -1.8 -0.3 -0.  -0.2  1.  -0.4 -2.4  0.1 -0.3 -0.5  7.1 -0.6  0.2 -0.4 -0.6 -0.9 -1.5  0.2 -0.4 -0.3 -1.1  0.6 -0.2 -0.   0.9 -0.3  4.  -0.5 -0.2 10.6 -0.  -0.1 -0.2 -0.1  8.9 -0.4 -0.2 -1.1 -0.4  5.4 -0.3 -0.3  2.1  0.8 -0.7 -1.1 -0.7 -0.2 -0.5 -1.7 -1.5 -0.9 -0.7 -2.5  4.3 -2.8  3.8  0.3 -0.1 -0.3  0.4 -0.7 -0.2 -0.1  0.2  0.3 -0.5 -1.1 -0.4 -0.4 -3.1  2.2  0.2  1.5 -0.3  0.4  4.4 -0.3 -0.2  0.4 -0.3 -0.8  3.1 -0.1 -0.2 -0.2 -0.6 -0.2 -0.2 -0.6 -0.5 -0.4  0.1 -2.3 -0.6 -0.3  1.4  3.8 -0.  -0.1 -0.4 -0.1 -2.1  2.7 -0.7 -1.4 -0.3 -0.3 -0.3 -1.   2.7  5.  -0.1  0.6 -0.1 -0.3 -0.4  3.7  0.1 -0.1 -0.3  8.9 -0.3  7.9  3.8  4.1 -0.5 -0.1 -0.5 -0.1 -5.5 -1.6 -0.1 -0.1 -0.5 -0.4  2.4 -0.2  1.2 -0.2 -0.2 -0.1 -0.1 -0.2 -1.9 -0.1  2.5 -0.2 -0.6  0.2 -0.2 -0.3 -0.3 -0.4  2.  -0.7 -0.4 -1.6 -0.1 -0.2 -0.   0.4 -0.6  1.3 -0.4 -0.2 -0.3 -0.3 -0.4 -0.5 -0.2  3.1 -0.  -0.5 -0.9  0.1 -0.2 -0.2 -0.4 -1.6 -0.2 -0.5 -0.1 -0.6 -0.2  1.2 -0.2 -0.2 -0.6 -0.7 -0.9 -1.2 -0.7 -0.8 -0.1 -0.2 -0.1 -0.2 -0.3 -0.2 -0.3 -1.6  0.4 -0.1  2.7 -0.5 -0.8  2.5 -0.2  3.5  0.9  1.7 -2.6 -1.  -0.2 -0.5 -0.1 -0.3 -0.5 -0.8 -1.2  1.9 -2.1 -0.7 -0.5  0.3 -0.9  1.7 -0.3  1.8 -0.8  2.1 -0.2 -1.   1.4  7.4 -0.1  2.5 -0.1 -0.2 -0.5 -0.6 -0.5 -0.6 -0.9 -0.2 -1.4 -0.3  6.  -0.2  5.9 -0.5]
ty_50sample [[4 7 1 3 9 8 0 5 6 2]
 [7 6 4 9 0 3 8 2 5 1]
 [5 0 7 1 8 2 6 4 9 3]
 [3 1 4 2 5 0 8 7 6 9]
 [3 1 0 7 2 5 6 4 9 8]
 [4 8 7 1 0 2 3 5 9 6]
 [3 7 1 2 5 4 6 9 0 8]
 [6 4 3 0 1 7 5 8 9 2]
 [7 8 4 3 2 5 1 9 0 6]
 [7 9 8 3 5 0 4 2 1 6]]
tt_50sample [[4 7 1 3 9 8 0 5 6 2]
 [7 6 4 9 0 3 8 2 5 1]
 [0 5 7 1 8 2 6 4 9 3]
 [3 1 4 2 5 0 8 7 6 9]
 [3 0 1 2 7 5 6 4 9 8]
 [4 8 7 1 0 2 3 5 9 6]
 [3 7 1 2 5 4 6 9 0 8]
 [6 4 0 3 1 7 5 8 9 2]
 [7 8 4 3 2 5 9 1 0 6]
 [7 9 8 3 5 0 4 2 1 6]]
vm  [ 2.  -1.   9.8 -0.5 -2.1 -0.   0.  -0.4 -0.7  4.9 -1.  -0.2 -0.4 -0.1 16.7 -1.4 -0.9 -0.6 -0.5  0.5 -1.   0.4 -0.9 -0.5 -1.2 -0.6 -0.4 -0.1 -1.9 -1.9 -0.9 -0.6 -0.5  8.  -0.3 -0.3  1.1  4.8  1.7 -0.9  2.1 -0.5 -0.7  0.9 -0.4 -0.6 -1.7 -0.8  3.  -1.9 -0.3 -0.5 -0.7  5.7 -0.2 -2.  -0.4  4.7  2.9  4.3  0.3 -0.5 -0.1 -0.1 -0.4 -1.3 -0.4  0.  -0.1 -0.2 -0.4  5.8 -1.3 -1.8 -6.8 -1.3 -0.5 -0.7 -0.4  1.7 -4.1  1.6 -0.3 -0.4 -2.  -0.6  2.4 -0.  -0.4 -0.5  0.8 -0.2 -0.4  0.5 -0.2 -0.  -1.2 -3.   2.2 -0.4 -1.9 -0.3 -0.9 -0.4 -0.  -0.3 -3.8 -0.6 -0.5  0.6  0.8 -0.3 -0.5 -0.4  2.9 -4.7 -1.1  3.1 -0.2 -0.5 -0.2 -1.3 -0.8 -0.7 -0.3 19.4  0.3 -1.   2.3 16.9  0.4 -0.2  0.   0.9 -6.8 -3.8 -0.3  0.1 -0.4 -0.6 -0.4 -1.2 -0.1 -0.4 -0.1 -0.6 -1.  -0.1 -0.1 -0.8 -0.1  0.2  1.6 -1.3 -0.2 -0.4 -0.7 -0.4  0.3 -0.4 -0.  -2.9  0.  -0.3  1.1  1.5 -1.2 -0.6 -0.6 -0.3 -0.4 -0.2  0.6 -0.1 -0.2  1.4  0.2 -0.8  0.2 -0.5 -2.  -0.8  2.  -1.4 -0.1 -0.5 -0.  -0.7 -0.2  4.5 -0.4 -0.5  0.1 -1.4  1.8 -0.6 -2.2 -0.7 -0.4 -0.6  0.3 -0.1 -0.4 -1.1 -0.4 -3.3 -0.2  0.  -1.5 -0.3 -1.  -3.  -1.  -2.  -1.   1.7 -0.7 -1.3 -0.7  2.3 -0.4 -0.2  0.4 -1.4 -2.2 -2.1 -1.2  0.4 -0.5  1.9 -1.1  6.1 -0.5 -0.6 -0.8 -1.8  3.5 -2.4 -0.1 -6.2 -0.2 -2.1 -0.4  0.2 12.5  5.2 -0.4  0.  -0.5 -0.7 10.5 -0.6  1.   0.2  2.4 -4.5]
vy_50sample [[0 3 7 5 8 2 4 9 6 6]
 [7 1 9 4 6 0 5 8 2 3]
 [1 2 3 5 0 0 8 4 7 6]
 [0 6 2 5 8 7 1 9 4 3]
 [6 8 7 0 5 4 3 9 2 1]
 [5 1 8 7 9 4 0 2 6 3]
 [2 6 3 5 9 7 1 4 0 8]
 [0 3 7 2 9 1 6 4 8 5]
 [1 9 3 8 2 6 7 4 0 5]
 [3 9 0 1 4 5 6 2 8 7]]
vt_50sample [[0 3 7 5 8 2 4 1 6 9]
 [7 1 9 4 6 0 5 8 2 3]
 [1 2 3 5 9 0 8 4 7 6]
 [0 6 2 5 8 7 1 9 4 3]
 [6 8 7 0 5 3 4 9 2 1]
 [5 1 8 7 9 4 0 2 6 3]
 [2 6 3 5 9 7 1 4 0 8]
 [0 3 7 2 9 6 1 4 8 5]
 [1 9 3 8 2 6 4 7 0 5]
 [3 9 0 1 4 5 6 2 8 7]]
Epoch 40510: Training cost= 0.2194, Training acc= 0.8530, Validation cost= 0.2875, Validation acc= 0.8531
Epoch 40520: Training cost= 0.2155, Training acc= 0.8531, Validation cost= 0.2979, Validation acc= 0.8531
Epoch 40530: Training cost= 0.2882, Training acc= 0.8531, Validation cost= 0.2814, Validation acc= 0.8531
Epoch 40540: Training cost= 0.3064, Training acc= 0.8531, Validation cost= 0.2399, Validation acc= 0.8531
Epoch 40550: Training cost= 0.2144, Training acc= 0.8531, Validation cost= 0.2748, Validation acc= 0.8532
Epoch 40560: Training cost= 0.2764, Training acc= 0.8531, Validation cost= 0.2515, Validation acc= 0.8532
Epoch 40570: Training cost= 0.2657, Training acc= 0.8531, Validation cost= 0.2546, Validation acc= 0.8532
Epoch 40580: Training cost= 0.2594, Training acc= 0.8531, Validation cost= 0.2617, Validation acc= 0.8532
Epoch 40590: Training cost= 0.2128, Training acc= 0.8531, Validation cost= 0.2519, Validation acc= 0.8532
Epoch 40600: Training cost= 0.2105, Training acc= 0.8532, Validation cost= 0.2366, Validation acc= 0.8532
tm  [-1.3 -0.2 -3.2 -0.8 -1.7 -0.1 -0.4 -0.2 -0.6 -0.2 -6.7 -0.  -0.2 -0.3 -1.7 -1.2  0.2 -0.4 -0.4 -1.5 -0.9 -0.4  0.6 -0.2 -0.9 -0.1 -0.  -0.1 -0.8 -0.1  2.  -0.4 -0.1 -2.7 -0.  -0.3  2.6 -0.1 18.1 -0.2 -0.3  3.4 -0.1  5.  -0.4  0.1  7.9  0.6 -1.1 10.4 -0.3 -0.2 -0.4 -3.9 -0.9  1.4 -0.7 -1.9 -0.2 -0.7  0.1 -0.1 -0.5 -0.1 -0.8 -0.3 -0.2 -0.5  0.2 -0.2 -0.2 -0.2 -0.4 -0.2 -0.3  0.5  0.  -0.2 -0.   0.   1.3 -0.3 -0.2 -0.1  1.6  3.6  2.  -0.1 -0.3 -0.3 -0.2 -0.1 -0.  -0.5 -0.4 -0.3 -0.4 -0.8 -0.3  0.1  0.9  3.1  1.6 -0.  -0.5 -0.3 -0.4  2.5 -1.9 -2.3  0.2  0.2 -0.1 -0.4  1.7  1.  -0.5 -0.7 -0.1 -0.5 -0.4  9.3  0.3 -0.1 -0.1 -2.  -0.3 14.8 -0.3 -2.7 -0.6 -0.2  0.  -0.5 -2.4 -5.5 -0.1  0.   0.2 -0.2  2.5 -0.4  1.  -0.2 -0.  -0.  -0.3 -0.1  2.7  0.7 -0.1 -0.2  0.7 -0.1 -0.1 -0.1 -0.1 -0.5  2.8 -0.3 -0.  -1.6 -0.2  0.3 -0.3  0.7 -0.1  0.9  0.  -0.2 -0.1 -0.1 -0.2 -0.3 -0.  -0.   1.8 -0.4 -1.8 -0.2 -1.1 -0.2 -0.3 -1.  -0.3 -0.1 -0.7 -0.3 -0.2  0.7 -0.2 -0.2 -0.5 -0.8  2.7  2.2  0.9 -0.2 -0.2 -0.1 -0.  -0.  -0.2 -0.5 -0.2  1.5 -0.3 -0.2  4.8 -0.2 -0.7 -0.3 -0.5  5.7  1.6 -0.1 -2.6 -0.9 -0.5 -0.3 -0.1 -0.  -0.5 -0.8 -0.   0.9 -2.  -0.1 -0.4 -0.4 -0.6 -0.6  0.5  2.3 -0.6  4.3 -0.2 -0.1  1.1  9.3 -0.1  2.6 -0.1 -0.2  1.3 -2.  -0.2 -0.2 -0.8 -0.2 -0.6  0.2 10.9 -0.2  3.3 10.9]
ty_50sample [[4 9 8 1 0 5 7 3 6 2]
 [0 5 7 1 2 4 6 3 9 8]
 [2 2 6 1 1 3 5 8 9 4]
 [0 4 5 7 3 2 6 1 8 9]
 [7 0 6 9 4 5 8 1 2 3]
 [9 0 5 1 4 2 8 3 6 7]
 [3 1 0 9 2 7 4 6 5 8]
 [8 4 7 1 6 2 5 0 3 9]
 [2 0 5 7 6 9 9 4 1 8]
 [3 8 9 0 6 4 1 7 2 5]]
tt_50sample [[4 9 8 1 0 5 7 3 6 2]
 [0 5 7 1 2 4 6 3 9 8]
 [2 0 6 1 7 3 5 8 9 4]
 [0 4 5 7 3 2 6 1 8 9]
 [7 0 6 9 4 5 8 1 2 3]
 [9 0 5 1 4 2 8 3 6 7]
 [3 1 0 9 2 7 4 6 5 8]
 [8 4 7 1 6 2 5 0 3 9]
 [2 0 5 7 6 3 9 4 1 8]
 [3 8 9 0 4 6 1 7 2 5]]
vm  [-0.7 -0.5 -0.5 -0.7 -1.1 -0.2 -0.1 -0.2  1.4  0.4  9.8 -0.1 -0.2 -0.2  1.6  1.8 -0.2 -0.3  0.3  0.9 -1.6 -0.2  0.3 -0.3 -1.   2.5  0.3 -0.3 -0.6 -3.1  2.6 -0.3 -0.6  4.4 -0.2 -0.2 -0.2  4.9 -0.2 -0.5  1.1  7.9 -0.9  1.9 -0.3  0.5 -1.2 -0.5 -0.6  1.3 -0.1 -0.2 -0.4  7.4 -0.9 -0.2 -0.7  6.3  7.5 -1.2  6.2 -0.6 -0.1  0.1  0.9 -0.7 -0.2  0.9 -0.3  0.3  0.5 -0.1 -0.2  0.2 -5.  -0.4 -0.4 -0.4 -0.2 -0.1  4.   0.6 -0.1 -0.1  0.4  8.2 -0.8 -0.1 -0.1 -0.4  0.7 -0.  -0.2 -1.2 -0.5 -0.5 -0.1 -3.3 -0.4 -0.7  0.8  3.8  0.3 -0.2 -0.1  0.6 -2.1  1.4  0.8 -0.1 -0.3 -0.1 -0.2 -0.9  5.1  1.4  0.2  2.  -0.1  0.3 -0.  -0.4  0.1 -0.1  0.4  2.3 -0.1 -1.3  9.9  0.5 -0.4 -0.2 -0.2 -0.4  1.8  5.7 -0.3 -0.1 -0.3 -0.3 -0.2 -0.5 -0.3 -0.1  0.2 -0.3 -0.2 -0.1  7.2 -0.3 -0.1  0.1 -1.4 -0.5 -0.2 -0.1 -0.3 -0.4  2.2  0.1  1.7 -0.9  0.1 -0.  -0.2 -0.6 -0.3  1.   0.5 -0.1 -0.3 -0.  -0.5 -0.1 -0.1 -1.3 -0.6 -0.4  1.3 -0.2 -1.4 -0.4 -0.3 -1.8 -0.1 -0.3 -0.4 -0.5 -0.1  9.8  0.4 -0.3 -0.1 -1.1 -2.  -3.1 -0.7 -1.3 -0.   0.2  0.8 -0.  -0.  -0.5 -0.3 -2.5 -0.3 -0.5 -5.4 -0.4 -0.3 -0.  -1.   6.  -0.7 -0.6 -0.2 -1.2 -0.4 -0.2 -0.2 -0.1 -0.3 -1.   3.1 -0.6 -0.1  1.4  1.5  0.2 -0.6 -0.1 -0.2 -2.2 -0.   1.7  1.6 -0.9  2.7 -5.  -0.1 -1.7 -0.2  0.1 -0.3  1.1  0.2 -0.1 -1.5 -0.2 -1.1 -0.1 -0.1  0.5 -1.2  3.1]
vy_50sample [[5 1 2 0 4 6 7 9 3 8]
 [2 3 1 7 8 4 9 5 0 6]
 [8 9 2 6 1 0 5 4 3 7]
 [9 6 3 2 2 5 0 1 4 7]
 [2 6 0 9 9 3 4 8 1 1]
 [5 7 3 9 4 6 1 8 2 0]
 [8 7 9 6 1 5 3 4 0 2]
 [3 0 1 6 5 8 7 9 4 2]
 [8 5 9 0 1 6 7 2 3 4]
 [8 9 2 5 4 6 0 7 3 1]]
vt_50sample [[5 1 2 0 4 7 6 9 3 8]
 [2 3 1 7 8 4 9 5 0 6]
 [8 9 6 2 1 0 4 5 3 7]
 [9 6 3 8 2 5 0 1 4 7]
 [2 6 0 9 5 3 4 8 1 7]
 [5 7 3 9 4 6 1 8 2 0]
 [8 7 9 6 1 5 3 4 0 2]
 [3 0 1 6 5 8 7 9 4 2]
 [8 5 9 0 1 6 7 2 3 4]
 [8 9 2 5 4 6 0 7 3 1]]
Epoch 40610: Training cost= 0.2573, Training acc= 0.8532, Validation cost= 0.2229, Validation acc= 0.8532
Epoch 40620: Training cost= 0.2384, Training acc= 0.8532, Validation cost= 0.2529, Validation acc= 0.8532
Epoch 40630: Training cost= 0.2687, Training acc= 0.8532, Validation cost= 0.2524, Validation acc= 0.8532
Epoch 40640: Training cost= 0.2757, Training acc= 0.8532, Validation cost= 0.2590, Validation acc= 0.8533
Epoch 40650: Training cost= 0.2847, Training acc= 0.8532, Validation cost= 0.2891, Validation acc= 0.8533
Epoch 40660: Training cost= 0.2921, Training acc= 0.8532, Validation cost= 0.2527, Validation acc= 0.8533
Epoch 40670: Training cost= 0.3047, Training acc= 0.8532, Validation cost= 0.2384, Validation acc= 0.8533
Epoch 40680: Training cost= 0.2167, Training acc= 0.8532, Validation cost= 0.2746, Validation acc= 0.8533
Epoch 40690: Training cost= 0.2393, Training acc= 0.8532, Validation cost= 0.2369, Validation acc= 0.8533
Epoch 40700: Training cost= 0.2029, Training acc= 0.8533, Validation cost= 0.2273, Validation acc= 0.8533
tm  [-0.1 -0.6 -3.5 -4.3 -0.9 -0.3 -0.5  0.1 -1.   1.  -5.7 -0.3  0.5 -0.5  1.  -1.7 -0.7 -0.1 -0.4  1.2 -1.  -0.4 -0.1 -0.2 -1.5 -0.3 -0.7 -0.1 -1.6 -1.1 -0.6 -0.3  2.7 -7.8 -0.2 -0.1  0.5 -1.4 -6.1 -0.7  1.5  4.9 -0.5 -0.7 -0.3 -0.7 -2.  -0.6  1.  14.  -0.5 -0.3 -1.1  5.3 -0.3 -0.4 -1.2  0.9  2.4  4.9  3.9 -0.4 -0.3 -0.4 -0.8 -0.4 -0.3 -0.4  1.2 -0.5 -0.4  5.3 -1.  -0.8 -7.1 -0.2 -0.4 -0.  -0.3  0.5 -8.5 -0.2 -0.1 -0.  -1.2  4.5  1.5 -0.1 -0.1 -0.4 -0.6  0.  -0.1  0.9 -0.5 -0.  -0.4 -3.5 -0.5 -0.3 -0.5 -0.2 -0.7 -0.2  0.1 -0.6 -3.5 -0.5 -1.4  2.7 -0.3 -0.1  0.1 -0.5  4.5 -3.5 -0.   1.   0.3 -0.  -0.3 -1.6 -0.5 -0.5 -0.2  1.4 -0.2 -0.7  0.7  3.6 -0.6  0.5 -0.1 -0.4 16.8 -0.4 -0.1 -0.1 -0.4 -0.3 -0.2 -0.9 -0.3 -0.8 -0.  -0.4 -1.2  0.   6.5 -0.3  3.   0.5  2.2 -0.9 -0.3 -0.3  0.4 -1.3 -1.1 -0.5 -0.1 -0.4 -0.2  0.2 -0.2 -0.3 -0.3 -0.6 -0.8 -0.1 -0.2 -0.1 -0.1 -0.4 -0.1 -1.6 -2.  -0.   7.5 -0.2 -1.1 -0.6  1.5 -1.  -0.2 -0.  -0.1  1.1 -0.5  2.5  0.8 -0.3 -0.3 -1.  -1.3 -0.1 -1.8 -1.2 -0.1 -0.1 -0.4 -0.1  1.  -0.5 -0.2 -3.9 -0.2 -0.   6.  -0.2 -0.2 -2.4 -0.6 -0.6  0.6 -0.1  2.7 -0.2 -0.7 -0.2 -0.2 -0.2 -0.7 -1.4  4.4 -1.1 -1.7 -0.1 -0.6  0.2 -0.1  3.7 -0.3  1.9 -0.2  3.9  2.3 -1.9 -0.4 -5.2 -0.  -1.8 -0.3 -0.3 24.8  3.9  0.8 -0.8 -0.9 -0.1 22.7 -0.  -3.7  0.1 -0.3 -0.8]
ty_50sample [[8 0 6 5 4 1 2 3 7 9]
 [1 3 8 8 5 2 9 0 7 6]
 [3 8 0 9 4 2 6 1 5 7]
 [4 6 1 8 7 3 5 0 2 9]
 [0 8 9 4 5 1 3 2 7 6]
 [7 2 0 4 8 3 6 1 9 5]
 [8 2 9 7 3 0 1 4 5 6]
 [1 5 4 6 7 9 2 0 8 3]
 [9 5 3 6 1 8 0 2 7 4]
 [7 5 1 2 3 0 9 8 6 4]]
tt_50sample [[0 8 6 5 4 1 2 3 7 9]
 [3 1 4 8 5 2 9 0 7 6]
 [3 8 0 9 4 2 6 1 5 7]
 [4 6 8 1 7 3 5 0 2 9]
 [0 8 9 4 5 1 3 2 7 6]
 [7 2 0 4 8 3 6 1 9 5]
 [8 2 9 7 3 0 1 4 5 6]
 [1 5 4 6 7 9 2 0 8 3]
 [9 5 3 6 8 1 0 2 7 4]
 [7 5 1 2 3 0 9 8 6 4]]
vm  [-1.6 -0.   7.1  7.8 -1.5 -0.1 -0.2 -0.1 -0.9 -0.8 -5.   0.2 -0.1 -0.1  5.5  2.2 -0.3  1.3 -0.8 -0.6 -0.7  0.2 -0.   0.1 -1.4  0.4 -0.2 -0.2 -0.3  4.7 -1.5 -0.2  1.  -0.8  0.5 -0.1  2.4  0.8  2.5 -0.3  0.6  4.9  2.1 -0.3 -0.4 -0.4  2.3 -0.4 -1.6 15.3 -0.3 -0.3 -0.2 -0.8 -1.5 -0.5 -0.5  5.2 -1.9  6.3  4.6 -0.5 -0.5 -0.5 -0.8 -0.8 -0.  -0.2  0.2 -0.3 -0.2 -1.   0.1 -0.4 -1.8 -0.1 -0.1 -0.4 -0.2  0.6 -3.2 -0.1  0.  -0.4  1.6  7.1 -2.2  0.3 -0.2 -0.2 -0.1 -0.4 -0.   0.3 -0.3 -0.4 -0.4 -1.6 -0.3 -0.3  2.1  7.3  0.5 -0.1  0.  -0.6 -1.4 -0.8 -1.5 -0.9  0.3 -0.1 -0.2 -0.1 -1.   6.2 -0.9 -1.1 -0.  -0.6 -0.2  2.4 -0.3  0.9  0.5  7.  -0.2  4.5 -1.8 -1.9 -0.1  0.1 -0.1 -0.1 -2.  -3.6  0.  -0.2 -0.2  0.6 -0.  -0.4 -0.2 -0.2 -0.2 -0.1 -0.2  0.4 -0.6 -0.4 -0.9 -0.1  0.3 -0.5 -0.1 -0.3 -0.4  1.6 -0.1 -0.1 -0.  -0.7 -0.3 -0.  -0.1 -0.1 -0.3  0.3 -0.4  0.2  0.4  0.3 -0.1 -0.3 -0.3  0.8 -0.8  0.3 -0.1 -0.1 -0.9 -0.5 -0.1 -1.5 -0.1 -0.4 -0.8 -0.5 -0.2 -1.3  0.2 -0.2 -0.1 -0.7 -1.3  6.8 -0.3  2.3 -0.2  0.1 -0.3 -0.1 -0.2 -0.7 -0.1 -0.6 -0.1  0.4  6.  -0.  -0.1  2.8  0.3  8.  -0.3  0.2  2.2 -0.4 -0.1 -0.1  0.1 -0.  -0.7 -1.   3.5  2.7 -0.9 -0.2 -0.2 -0.8 -0.6  0.4 -0.2  2.  -1.  -1.4 -0.5 -0.9 -0.2 -0.4 -0.2 -0.2 -0.1 -0.2 10.  -1.4 -0.5 -0.3 -0.5 -0.6  7.3 -0.1  1.6  1.  -0.8  8.6]
vy_50sample [[8 1 7 5 9 6 2 0 4 3]
 [2 6 8 5 1 4 7 9 0 3]
 [0 7 2 9 3 8 5 1 6 4]
 [6 8 5 2 1 3 4 0 9 7]
 [9 0 2 7 6 8 4 3 1 1]
 [6 8 0 7 4 3 2 1 5 9]
 [3 2 6 5 1 9 4 0 7 8]
 [5 3 9 7 0 1 6 8 2 4]
 [9 4 7 0 6 8 2 5 1 3]
 [5 1 4 6 2 7 0 0 9 3]]
vt_50sample [[8 1 7 5 9 6 2 0 4 3]
 [2 6 8 5 1 4 7 9 0 3]
 [0 7 2 9 3 8 5 1 6 4]
 [6 8 5 2 1 3 4 0 9 7]
 [9 0 2 7 6 8 4 3 1 5]
 [6 8 0 7 4 3 2 1 5 9]
 [3 2 6 5 1 9 4 0 7 8]
 [5 9 3 7 0 1 6 8 2 4]
 [9 4 7 0 6 8 2 5 1 3]
 [5 1 4 6 2 7 0 8 9 3]]
Epoch 40710: Training cost= 0.2094, Training acc= 0.8533, Validation cost= 0.2100, Validation acc= 0.8533
Epoch 40720: Training cost= 0.1971, Training acc= 0.8533, Validation cost= 0.2177, Validation acc= 0.8533
Epoch 40730: Training cost= 0.2275, Training acc= 0.8533, Validation cost= 0.2173, Validation acc= 0.8534
Epoch 40740: Training cost= 0.2357, Training acc= 0.8533, Validation cost= 0.2364, Validation acc= 0.8534
Epoch 40750: Training cost= 0.2148, Training acc= 0.8533, Validation cost= 0.2301, Validation acc= 0.8534
Epoch 40760: Training cost= 0.2167, Training acc= 0.8533, Validation cost= 0.2603, Validation acc= 0.8534
Epoch 40770: Training cost= 0.2530, Training acc= 0.8533, Validation cost= 0.2426, Validation acc= 0.8534
Epoch 40780: Training cost= 0.2755, Training acc= 0.8534, Validation cost= 0.2498, Validation acc= 0.8534
Epoch 40790: Training cost= 0.2393, Training acc= 0.8534, Validation cost= 0.2418, Validation acc= 0.8534
Epoch 40800: Training cost= 0.2430, Training acc= 0.8534, Validation cost= 0.1966, Validation acc= 0.8534
tm  [-1.9 -0.1  7.5  0.4 -1.7  0.3  0.5 -0.1 -1.2 -1.3 -2.3 -0.1 -0.3 -0.2 10.2  3.1 -0.1 -0.1 -0.5  2.1 -0.9  0.2  2.1  0.1 -1.3  2.2 -0.1 -0.3 -0.4  3.1 -1.7  0.  -0.2 -1.4 -0.1  1.   3.1  0.3 -3.1 -0.3  2.4  3.3  3.8 -0.3 -0.1 -0.2 -2.2 -0.2 -2.3  8.1 -0.3 -0.1 -0.5  8.6 -1.  -1.  -1.1  9.1 -1.9  7.5 11.3 -0.2 -0.3 -0.1 -0.8  0.7  0.4 -0.7  1.3 -0.2 -0.3 -0.7 -0.1 -0.6 -4.2 -0.2  1.1 -0.  -0.3  0.6 -5.9 -0.2 -0.2  0.5  4.2  5.2 -2.9  0.  -0.2 -0.  -0.5 -0.1 -0.1  2.7 -0.6 -0.2  1.3 -2.8 -0.2  0.2  5.4  4.3  1.1 -0.2 -0.2 -0.5 -2.7 -0.7 -0.4  1.6 -0.6 -0.1 -0.1 -0.3 -1.4  8.1 -0.3 -1.2 -0.4 -0.4  0.4 -0.6 -0.1 -0.1 -0.  12.7 -0.1 -1.7 -1.5  8.4 -0.3 -0.4 -0.6 -0.5 -0.4 -1.5 -0.3  0.2 -0.8 -0.1  0.  -0.4  0.1 -0.  -0.1 -0.2  0.1  0.1  2.6 -0.3 -0.5 -0.2 -0.3  0.4 -0.2 -0.1 -0.1  1.3 -0.5 -0.5  0.4  0.9 -0.1 -0.2 -0.3 -0.3 -0.2 -0.1 -0.3  0.1 -0.3  0.3 -0.1 -0.4  0.5 -0.1 -0.8 -0.5  5.3  0.1 -1.7 -0.2 -0.5 -2.2 -0.2 -0.1 -1.6 -0.4 -0.2 -0.7 -0.2 -0.3 -0.  -0.7 -4.3  5.4 -0.9  3.3  0.3 -0.1 -0.1 -0.2  0.1 -0.3  0.2 -4.   0.1 -0.1  3.2 -0.4 -0.6  0.2  1.5 10.2 -0.5  0.4  4.  -0.7  0.1 -0.2 -0.2 -0.2 -0.6 -1.3  1.3  3.4 -0.2 -0.5 -0.4 -0.7 -0.8  2.  -0.2  1.6  0.6 -1.3 -0.4 -1.4  1.4 -4.7 -0.  -1.6 -0.1 -0.2 17.8  5.8 -0.2  1.9 -0.6 -0.8 15.2  0.1 -1.9  0.2  0.  -1.7]
ty_50sample [[1 8 5 7 6 2 3 0 4 9]
 [5 0 9 7 2 1 3 4 6 8]
 [0 7 5 8 2 6 4 1 3 9]
 [4 9 3 1 8 7 6 5 0 2]
 [2 9 6 1 0 5 4 3 7 8]
 [8 0 3 1 5 2 9 4 6 7]
 [0 7 8 3 4 5 1 6 2 9]
 [0 5 4 2 7 7 9 6 1 8]
 [8 7 5 0 2 9 1 6 4 3]
 [2 8 3 1 5 7 6 9 4 0]]
tt_50sample [[1 8 5 7 6 2 3 0 4 9]
 [5 0 9 7 2 1 3 4 6 8]
 [7 0 5 8 2 6 4 1 3 9]
 [4 9 3 8 1 7 6 5 0 2]
 [2 9 6 1 0 5 4 3 7 8]
 [8 0 3 1 5 2 9 6 4 7]
 [0 7 8 3 4 5 1 6 2 9]
 [0 5 4 2 7 3 9 6 1 8]
 [8 7 5 0 2 1 9 6 4 3]
 [2 8 3 1 5 7 6 9 4 0]]
vm  [-0.3 -0.3  7.7 11.4 -1.8 -0.1 -0.3 -0.1 -0.3 -0.2  6.6  0.7 -0.2 -0.   2.  -1.  -0.4 -0.3  1.6 -0.7 -1.3 -0.2 -1.  -0.5 -0.9  3.1 -0.1 -0.1 -1.6 -3.2  0.4 -0.4 -0.4  9.9 -0.1 -0.2  2.6  5.  13.8 -0.8  1.6 -1.7 -0.3  0.2 -0.4  0.1  2.2 -0.7  2.6 -3.7 -0.2 -0.2  0.  -0.1  2.  -0.2 -0.6  4.2  3.4  1.6 -0.  -0.4  0.7  0.2 -0.3 -0.4 -0.1 -0.7  0.9 -0.1  0.   6.4 -0.3  0.6 -2.2 -0.3 -0.5 -0.5 -0.1 -0.  12.1 -0.2 -0.2 -0.6 -1.1 -1.5 -0.6 -0.1 -0.3 -0.3 -0.3 -0.1 -0.1 -0.1 -0.2 -0.3 -0.3 -2.  -0.6 -0.4 -0.1 -0.5 -0.6 -0.2 -0.1 -0.  -0.8 -0.1  1.2 -1.6 -0.3 -0.1  0.2 -0.2  3.8 -3.3 -0.   0.2  0.1 -0.1 -0.1  4.7 -0.2  0.5 -0.2  2.4 -0.3  2.6  3.8  6.1 -0.3 -0.2  0.3 -0.2 -5.3 -1.1 -0.1 -0.1 -0.  -0.2 -0.4 -0.9 -0.1 -0.3 -0.3 -0.3 -0.5 -0.2 -0.6 -0.3 -0.8  0.1 -0.4 -0.6 -0.1 -0.2 -0.2 -0.3  3.7 -0.2 -0.1 -2.5 -0.  -0.2  0.3 -0.5 -0.4 -0.5 -0.2 -0.1 -0.1 -0.3 -0.  -0.2 -0.2  1.6  2.6 -0.4 -1.2 -0.1 -1.2 -0.  -0.3 -1.4 -0.3  0.5  0.5 -0.3 -0.   8.5 -0.1  0.4 -0.1 -1.1  3.3 -1.1 -0.4 -1.  -0.1 -0.  -0.1 -0.1 -0.1 -0.1 -0.3 -0.4 -0.1 -0.2 -1.5  0.2 -0.4 -2.1 -0.8 -0.3 -0.6  0.5 -0.4 -1.3 -0.3  0.6  0.1 -0.2  0.3 -0.9 -2.3 -1.8 -1.   0.7 -0.3  1.6 -0.1 -0.4  0.1 -0.5  2.2 -1.9  1.5 -0.3  0.9  4.  -0.1  1.  -0.3 -0.  -2.1 -1.2 -0.4 -0.1 -1.1 -0.6 -3.2  0.   8.6  0.1  2.8 -1.1]
vy_50sample [[0 3 7 9 2 5 1 8 4 6]
 [2 8 7 1 4 0 3 6 9 5]
 [2 0 3 7 7 1 4 6 5 9]
 [2 5 4 0 1 6 8 9 3 7]
 [1 5 4 8 2 9 6 3 0 7]
 [9 7 1 4 4 2 5 0 6 3]
 [2 0 7 4 9 8 6 5 1 1]
 [7 2 1 3 9 5 8 6 4 0]
 [3 2 9 1 0 7 6 4 8 5]
 [0 5 8 1 3 7 6 4 9 2]]
vt_50sample [[0 3 7 9 2 5 1 4 8 6]
 [2 8 7 1 4 0 3 6 9 5]
 [2 0 3 8 7 1 4 6 5 9]
 [2 5 4 0 1 6 8 9 3 7]
 [1 5 4 8 2 9 6 3 0 7]
 [9 7 1 8 4 2 5 0 6 3]
 [2 0 7 4 9 8 6 5 3 1]
 [7 2 1 9 3 5 8 6 4 0]
 [3 2 9 1 0 7 6 4 8 5]
 [0 5 8 1 3 7 6 4 9 2]]
Epoch 40810: Training cost= 0.2913, Training acc= 0.8534, Validation cost= 0.2169, Validation acc= 0.8535
Epoch 40820: Training cost= 0.2474, Training acc= 0.8534, Validation cost= 0.2750, Validation acc= 0.8535
Epoch 40830: Training cost= 0.2404, Training acc= 0.8534, Validation cost= 0.2523, Validation acc= 0.8535
Epoch 40840: Training cost= 0.2378, Training acc= 0.8534, Validation cost= 0.1581, Validation acc= 0.8535
Epoch 40850: Training cost= 0.2192, Training acc= 0.8534, Validation cost= 0.2208, Validation acc= 0.8535
Epoch 40860: Training cost= 0.2089, Training acc= 0.8535, Validation cost= 0.2322, Validation acc= 0.8535
Epoch 40870: Training cost= 0.2278, Training acc= 0.8535, Validation cost= 0.2225, Validation acc= 0.8535
Epoch 40880: Training cost= 0.2072, Training acc= 0.8535, Validation cost= 0.2477, Validation acc= 0.8536
Epoch 40890: Training cost= 0.2503, Training acc= 0.8535, Validation cost= 0.2206, Validation acc= 0.8536
Epoch 40900: Training cost= 0.2482, Training acc= 0.8535, Validation cost= 0.2324, Validation acc= 0.8536
tm  [-0.4 -0.6 -0.8  1.7 -1.4 -0.1 -0.4 -0.   3.1 -0.5  0.5 -0.2 -0.1 -0.1 -0.5  0.6 -0.6 -0.4 -0.6 -0.8 -1.  -0.2 -0.8 -0.2 -0.9  3.7 -0.1 -0.1  3.6 -1.7  3.7 -0.3 -0.9  7.   0.1 -0.1 -1.3 -1.   5.3 -0.   0.4 -2.  -1.   2.1 -0.  -0.   3.  -0.1  5.1 -2.4 -0.3  0.4  1.2 -1.9 -1.2  1.5 -0.3 -1.7  8.4 -2.  -0.9 -0.6 -0.5 -0.1  2.1  0.1 -0.1  1.   3.  -0.4 -0.2 -2.3 -0.3  2.8 -1.8 -0.3 -0.6 -0.1 -0.1 -0.2 12.8 -0.2 -0.1  0.3 -1.1 -1.3  5.5 -0.1  0.1 -0.9  1.1 -0.1 -0.1 -2.2 -0.3  0.8 -0.5 -2.8 -0.5 -0.5  1.1 -0.2 -0.8 -0.1 -0.   0.9  0.   3.2  1.6 -1.2 -0.4 -0.3 -0.2 -1.   2.8 16.   0.8  1.8 -0.4 -0.  -0.1  4.3  0.4  1.1 -0.  -0.7 -0.1  9.2  9.4  1.4  0.4 -0.1 -0.4 -0.6 -0.3  6.8 -0.1 -0.  -0.3 -0.3  3.3 -0.4  1.3 -0.1 -0.1 -0.2 -0.   0.1 -0.9 -0.3 -0.2 -0.   0.9  1.9  0.5 -0.3  0.3 -0.6  0.4 -0.3 -0.6 -0.7  0.6  0.1 -0.3 -0.7 -0.1  1.4 -0.3  0.  -0.3 -0.2 -0.  -0.3 -0.1  2.  -0.8  0.5 -0.3  0.6 -0.2 -0.1 -0.4 -2.5 -0.1  1.9  2.1 -0.6  0.1  4.5 -0.4 -0.1 -0.5 -1.2  8.1 -3.4  1.5 -0.8 -0.1 -0.1 -0.2 -0.1 -0.5 -0.2 -0.2  0.7 -0.2 -0.2 -0.1 -0.2 -0.4  7.2 -0.9 -0.5 -1.4 -0.1 -1.1 -0.7 -0.1 -0.2 -0.2 -0.  -0.6 -1.2 -0.5  3.  -2.9 -0.8  2.1  3.5 -0.2 -1.3 -0.  -0.  -1.1  1.2 -0.1  0.4  5.  10.5 -0.2  3.3 -0.  -0.3 -2.3 -1.8 -0.1 -0.2 -1.8 -0.4 -3.3  0.1  3.8 -0.4  8.2  1.6]
ty_50sample [[9 4 7 7 6 5 1 8 2 0]
 [7 3 9 5 0 8 2 6 1 4]
 [4 6 7 0 9 3 8 5 2 1]
 [3 7 8 2 9 6 0 1 5 4]
 [5 9 4 2 1 3 7 6 8 0]
 [1 9 2 6 6 4 0 3 8 5]
 [6 3 1 2 0 9 5 8 7 4]
 [0 1 3 6 8 5 2 9 4 7]
 [3 1 7 9 0 4 5 2 8 6]
 [2 8 9 1 0 6 6 3 4 5]]
tt_50sample [[9 4 3 7 6 5 1 8 2 0]
 [7 3 9 5 0 8 2 6 1 4]
 [4 6 7 0 9 3 8 5 2 1]
 [3 7 8 2 9 6 0 1 5 4]
 [5 9 4 2 1 3 7 6 8 0]
 [1 9 2 6 7 4 0 3 8 5]
 [6 3 1 2 0 9 5 8 7 4]
 [0 1 3 6 8 5 2 9 4 7]
 [3 1 7 9 0 4 5 2 8 6]
 [2 8 9 1 0 7 6 3 4 5]]
vm  [-0.8  1.4  7.3 -1.  -1.6 -0.1  1.2  0.3 -1.4 -1.5 -2.5 -0.4 -0.1 -0.3 11.7  1.3  0.7 -0.8 -0.7  4.2 -0.5  0.8  1.9 -0.  -1.4  2.1  0.3 -0.1 -0.5  6.3 -1.5  0.9 -0.8 -1.3  0.3  0.   1.  -0.9 -4.8  0.4 -0.1  3.6  5.6 -0.7  0.5 -0.1 -3.2 -0.2  0.2  5.6 -0.2 -0.1 -0.1 11.7 -0.3 -1.4 -0.8 10.5 -2.1  7.9  7.5 -0.2 -0.5 -0.6 -0.6  2.2 -0.1 -0.5  1.2 -0.1 -0.5 -0.7 -0.3 -0.7 -4.5 -0.2  0.2  1.  -0.5 -0.1 -6.9  0.3 -0.2  0.5 -0.1  4.8 -1.   0.5 -0.2 -0.1 -0.7 -0.  -0.   3.6 -0.9 -0.2  1.5 -3.3 -0.2 -0.   5.4  1.5 -0.  -0.1 -0.  -0.3 -2.9 -0.8 -0.6  3.2 -0.3 -0.2 -0.3 -0.4 -1.5  7.9 -0.9 -1.  -0.3 -0.4  0.1 -1.1  0.1 -0.2 -0.3 14.9 -0.  -2.5 -1.5 13.   1.9 -0.9 -0.8 -0.3  4.1 -0.6 -0.2  0.6 -0.7  0.4  2.3 -0.5  1.3  1.1 -0.1 -0.3  0.9 -0.2  4.3  0.4 -0.1 -0.5  3.3  3.9 -0.3 -0.3 -0.1  2.2 -1.3 -0.8 -0.7  3.8  0.1 -0.3 -0.4  0.2 -0.2 -0.4 -0.  -0.1 -0.1  0.3 -0.  -0.3  0.2 -0.3 -0.3 -0.8  6.5 -0.1 -2.  -0.2 -0.7 -2.6 -0.2 -0.1 -1.  -0.9 -0.  -1.4  0.2 -0.   1.  -0.6 -2.7  4.9 -0.8  3.9 -0.1 -0.2  0.4 -0.  -0.3 -0.2 -0.  -4.7  1.  -0.2  3.   0.2 -0.8 -0.2  0.7  3.1 -0.8  0.2  5.5 -0.9  0.1 -0.4 -0.2 -0.  -0.5 -1.4  1.8  3.8 -0.9 -1.1 -0.4  1.4 -0.7  0.6 -0.6  2.   1.4 -1.2 -0.3 -1.4  3.3 -6.1 -0.3 -2.1 -0.  -0.  21.1  8.2 -0.4  0.9 -0.7 -0.8 18.5 -0.1 -2.9 -0.2  4.8 -3.2]
vy_50sample [[8 5 6 7 7 1 2 0 4 9]
 [4 5 9 6 3 2 8 7 1 0]
 [2 9 4 8 6 7 3 0 5 1]
 [9 7 2 3 4 5 0 1 8 6]
 [3 8 2 1 0 9 4 5 5 6]
 [4 6 1 3 8 8 0 5 9 7]
 [4 0 7 1 9 6 3 2 8 5]
 [4 8 0 7 2 6 5 1 9 3]
 [4 3 0 6 7 9 1 5 2 8]
 [2 0 7 8 5 3 4 9 6 6]]
vt_50sample [[8 5 6 3 1 7 2 0 4 9]
 [4 5 9 6 3 2 8 7 1 0]
 [2 9 4 8 6 7 3 0 5 1]
 [9 7 2 4 3 5 0 1 8 6]
 [3 8 2 1 0 4 9 5 7 6]
 [4 6 1 3 8 2 0 5 9 7]
 [4 0 7 1 9 6 3 2 8 5]
 [4 8 0 7 2 6 5 1 9 3]
 [4 3 0 6 7 9 1 5 2 8]
 [2 0 7 8 5 3 4 9 6 1]]
Epoch 40910: Training cost= 0.2294, Training acc= 0.8535, Validation cost= 0.2373, Validation acc= 0.8536
Epoch 40920: Training cost= 0.2219, Training acc= 0.8535, Validation cost= 0.2714, Validation acc= 0.8536
Epoch 40930: Training cost= 0.2491, Training acc= 0.8536, Validation cost= 0.2120, Validation acc= 0.8536
Epoch 40940: Training cost= 0.2015, Training acc= 0.8536, Validation cost= 0.2790, Validation acc= 0.8536
Epoch 40950: Training cost= 0.2485, Training acc= 0.8536, Validation cost= 0.3156, Validation acc= 0.8536
Epoch 40960: Training cost= 0.2834, Training acc= 0.8536, Validation cost= 0.2328, Validation acc= 0.8537
Epoch 40970: Training cost= 0.3207, Training acc= 0.8536, Validation cost= 0.3689, Validation acc= 0.8537
Epoch 40980: Training cost= 0.2083, Training acc= 0.8536, Validation cost= 0.2152, Validation acc= 0.8537
Epoch 40990: Training cost= 0.2505, Training acc= 0.8536, Validation cost= 0.2783, Validation acc= 0.8537
Epoch 41000: Training cost= 0.2474, Training acc= 0.8536, Validation cost= 0.2290, Validation acc= 0.8537
tm  [-0.9 -1.   6.9 -1.2 -2.1 -0.2 -0.3 -0.1  0.4  0.4  7.1  0.3 -0.2 -0.4 13.3  0.6 -0.7  0.3 -0.4  3.2 -1.8 -0.3 -0.3  0.1 -1.2  2.9 -0.6 -0.7 -1.2 -1.6  2.3 -0.1  0.3 15.7 -0.3 -0.1  0.3  3.8 -0.7 -0.6  6.6 -0.3 -0.7  4.3 -0.5 -0.3 -2.4 -0.2 -0.3 -1.1 -0.1 -0.1  0.2  5.6 -0.6 -1.4 -1.  -1.4  6.5 -1.1  5.1 -0.7  0.9  0.8 -0.6 -0.3 -0.  -0.4  1.8 -0.4 -0.1 -0.3  1.4  1.1 -4.9 -0.7 -0.6 -0.6  0.7 -0.2  0.9  1.   0.   0.4  0.2 -0.  -0.4 -0.4 -0.2 -1.   1.6  0.2  0.5 -1.2  0.4  0.3 -0.6 -3.7 -0.4 -0.3 -0.1  8.1  0.7 -0.  -0.  -0.2 -1.5  2.3  2.1  2.6 -0.7  0.  -0.3 -0.6  4.9 -0.2  0.7  0.8  0.3 -0.4 -0.1 -1.3  0.3  0.3 -0.1 16.3  1.  -0.6  6.9  4.2 -1.  -0.1  0.5 -0.8 -5.9  3.9 -0.4 -0.2 -0.2 -0.4  2.  -1.  -0.3 -0.5  0.2  0.3 -0.5 -0.1 -2.7 -0.5  0.1 -0.1 -1.2 -0.3  1.   0.2 -0.2 -0.3  5.4  0.3  1.8 -1.7 -0.1  0.3 -0.3 -0.7 -0.3  1.8 -0.3 -0.1 -0.4 -0.1 -0.4 -0.2 -0.4  4.6 -0.9  0.7  2.5 -0.2  0.1 -0.8  0.1 -1.8 -0.1 -0.3 -0.3  0.3 -0.6  4.2  0.5 -0.1  0.3 -1.  -1.5 -2.2 -0.5 -1.3 -0.1  0.2 -0.1 -0.2 -0.3 -0.8  0.5 -1.9 -0.5 -0.3 -0.6 -0.2 -0.5 -0.1 -1.   6.  -1.8 -0.4 -1.2 -1.  -0.2  1.  -0.1 -0.2 -0.4 -0.8 -0.4 -0.8 -1.2  1.2 -0.8 -0.4  1.4 -0.4 -0.1 -0.3 -0.  -1.1  1.3 -0.9  5.3 -0.9 -0.1 -0.4 -0.2 -0.   1.7  0.7 -0.2  1.5 -1.1 -0.1 -0.3 -0.  -0.2  0.2  0.7 -0.6]
ty_50sample [[7 1 0 4 2 3 5 6 8 9]
 [5 9 8 2 6 3 0 7 4 1]
 [2 7 8 9 1 4 5 0 6 3]
 [8 4 0 1 5 6 2 9 7 3]
 [6 3 9 5 0 4 7 8 1 2]
 [1 2 8 7 9 6 5 3 0 4]
 [3 2 2 0 1 8 5 4 6 7]
 [3 6 7 2 2 5 0 9 1 4]
 [2 0 7 3 1 6 8 4 5 9]
 [2 9 5 3 6 7 0 4 1 8]]
tt_50sample [[7 1 0 4 2 3 5 6 8 9]
 [5 9 8 2 6 3 0 7 4 1]
 [2 7 8 9 1 4 5 0 6 3]
 [8 4 0 1 5 6 2 9 7 3]
 [6 3 9 5 4 0 7 8 1 2]
 [1 2 8 7 9 6 5 3 0 4]
 [3 9 2 0 1 8 4 5 6 7]
 [3 6 7 2 8 5 0 9 1 4]
 [2 0 7 3 1 6 8 4 5 9]
 [2 9 5 3 6 7 0 4 1 8]]
vm  [ 1.6 -0.   3.5 16.8 -0.1 -0.3 -0.1 -0.2 -1.3  0.9  1.7 -0.2 -0.2 -0.3 -2.1  6.9  1.8 -0.6  0.3 -1.7 -0.1  0.3 -0.1 -0.5 -1.1 -0.4  0.8 -0.3  2.1  3.4 -2.  -0.6 -0.8 -4.9  0.3 -0.2 -0.   3.9  9.7 -0.  -0.2 -2.9  0.5 -1.1 -0.4 -0.6  9.6 -0.6  3.5  2.1 -0.5 -0.3 -0.4  3.5 -2.   2.7 -0.   2.1 -2.5  7.2 -2.2 -0.6 -0.9 -0.7 -0.  -0.2 -0.5  1.2 -0.5 -0.4 -0.3 -2.4 -0.4 -0.5 -0.6 -0.2 -0.2  2.8 -0.3 -0.4 -1.   0.4 -0.8 -0.5 -2.1 -2.4  2.4 -0.2  0.2 -0.4 -0.7  0.3 -0.1  5.6 -1.  -0.2 -0.2 -0.5 -0.8 -0.9 -0.2 -2.2 -1.2 -0.2 -0.  -0.3 -0.3 -0.9  1.5 -2.   3.6 -0.7 -0.7 -0.2 -2.6 11.9 -0.2 -1.3 -0.3 -0.3 -0.1  6.5 -0.5 -0.8 -0.3 -2.8 -0.1 -0.5 -3.   3.1  1.1  0.6 -0.4  2.3  4.7 -3.7 -0.5 -0.3 -0.2 -0.2 -1.6 -0.  -0.4 -0.1 -0.4 -0.6 -0.2 -0.1  0.9 -0.2 -1.4  0.6  2.8 -0.2 -0.3 -0.5 -0.2 -1.  -1.  -0.5 -0.7 -0.9 -0.2 -0.1 -0.4  1.1 -0.6 -0.8 -0.4 -0.2 -0.3 -0.4 -0.1 -0.4 -0.2  0.5 -0.9 -0.2 -1.1 -0.4 -0.4  1.5  1.5 -1.2 -0.1  3.4  1.  -0.5  0.  -1.1 -0.4 -0.1 -0.5 -1.1 15.6  9.5  1.6  6.3 -0.1 -0.4  1.6 -0.2  1.4  0.7 -0.8  5.8 -0.2 -0.2 10.1 -0.2 -0.8  3.7 -0.6 -2.   1.6 -0.2  3.9 -0.3 -0.9 -0.5 -0.4 -0.5 -0.3 -0.5 -1.1  2.8 -0.1 -1.  -0.3  0.5 -0.6  0.2 -0.6  2.3 -2.8 -0.7 -0.7 -0.3 -1.2 17.9 -0.5  5.4 -0.6  0.4  4.8 -2.8  1.9 -0.4 -0.4 -0.1  2.1 -0.2  5.7 -0.1  0.  -0.3]
vy_50sample [[8 2 3 9 6 7 5 4 1 0]
 [4 8 5 3 1 9 2 7 0 6]
 [5 9 3 2 1 7 6 8 0 4]
 [2 6 8 5 1 1 0 4 9 3]
 [3 7 2 0 4 1 9 8 6 5]
 [5 4 1 1 2 0 8 7 6 3]
 [5 6 0 0 8 4 7 3 1 2]
 [1 0 7 4 3 2 8 5 9 6]
 [5 1 9 2 7 0 6 4 3 8]
 [8 0 9 1 3 6 2 4 5 7]]
vt_50sample [[8 2 3 9 6 7 5 4 1 0]
 [4 8 5 3 1 9 2 7 0 6]
 [5 9 3 2 1 7 6 8 0 4]
 [2 6 8 5 1 7 0 4 9 3]
 [3 7 2 0 4 1 9 8 6 5]
 [5 4 1 9 2 0 8 7 6 3]
 [5 6 0 9 8 4 7 3 1 2]
 [1 7 0 4 3 2 8 5 9 6]
 [5 9 1 2 7 0 6 4 3 8]
 [8 0 9 1 3 6 2 4 5 7]]
Epoch 41010: Training cost= 0.2401, Training acc= 0.8536, Validation cost= 0.2512, Validation acc= 0.8537
Epoch 41020: Training cost= 0.2506, Training acc= 0.8537, Validation cost= 0.2564, Validation acc= 0.8537
Epoch 41030: Training cost= 0.2540, Training acc= 0.8537, Validation cost= 0.2977, Validation acc= 0.8537
Epoch 41040: Training cost= 0.2509, Training acc= 0.8537, Validation cost= 0.2861, Validation acc= 0.8537
Epoch 41050: Training cost= 0.3156, Training acc= 0.8537, Validation cost= 0.2208, Validation acc= 0.8538
Epoch 41060: Training cost= 0.2231, Training acc= 0.8537, Validation cost= 0.2475, Validation acc= 0.8538
Epoch 41070: Training cost= 0.2220, Training acc= 0.8537, Validation cost= 0.2626, Validation acc= 0.8538
Epoch 41080: Training cost= 0.3068, Training acc= 0.8537, Validation cost= 0.2355, Validation acc= 0.8538
Epoch 41090: Training cost= 0.2187, Training acc= 0.8537, Validation cost= 0.2407, Validation acc= 0.8538
Epoch 41100: Training cost= 0.2425, Training acc= 0.8538, Validation cost= 0.2876, Validation acc= 0.8538
tm  [-0.4  0.8  3.4 -1.1 -1.9 -0.2 -0.6 -0.2 -1.7 -1.3 -2.7  0.9 -0.1 -0.   6.2  2.6 -0.4  0.   0.3 -0.3 -0.6 -0.1  0.1  0.7 -1.9  1.1  0.1 -0.6 -0.1  7.9  1.2 -0.1  1.5  5.  -0.3 -0.4  3.1  3.3  9.3 -0.3  1.7  4.6  6.4  4.4 -0.2 -0.4  2.  -0.4  1.8  5.3 -0.6 -0.2 -0.  -0.8 -1.3 -0.5 -0.8  2.9 -3.4 -0.3 -0.4 -0.8 -0.1 -0.4 -0.6 -0.2 -0.  -0.2  0.2 -0.3 -0.3 -1.1  0.3 -0.2 -2.4 -0.3 -0.4 -0.9 -0.2 -0.2 -1.  -0.4  0.8 -0.7 -0.9  4.9  4.6  0.5 -0.1 -0.1 -0.3 -0.2  0.4  5.1  0.1 -0.  -0.5 -1.2 -0.8 -0.6  4.   4.1 -0.4 -0.2 -0.2 -0.6 -1.3  1.7 -0.6 -0.5 -0.1 -0.4  0.2  0.3 -2.2  8.3  1.7 -1.7 -0.3 -0.4 -0.5  1.1 -0.4  0.1 -0.2  7.8 -0.3  5.  -2.5 -0.8 -0.4 -0.2 -0.4 -0.1 -5.5 -3.5 -0.1  0.3 -0.3 -0.8  0.9 -0.5 -0.2 -0.2 -0.1 -0.1 -0.2 -0.1  2.7 -0.2  0.2  0.3  2.9 -0.5 -0.1 -0.1 -0.3 -0.1  4.   0.2 -0.8 -1.9 -0.1 -0.1 -0.7 -0.2  0.7 -0.8 -0.5 -0.   0.4 -0.2 -0.2 -0.3 -0.3 -0.2 -0.8  0.4 -0.7 -0.1 -1.8 -0.7  0.1 -1.5 -0.4 -0.3  0.5 -0.7 -0.3 -1.9 -0.1 -0.2 -0.1 -1.5  6.1  8.9 -0.1  5.  -0.4 -0.2 -0.  -0.  -0.  -0.1 -0.3 -0.  -0.5 -0.1 -1.6 -0.3 -0.2  2.2 -0.2  0.2  1.2 -0.5 -1.9 -0.5 -0.4 -0.5  0.3 -0.1 -0.4 -0.9 -1.8  3.1 -1.4 -0.8  0.5 -0.3 -0.5  0.5 -0.2 -0.8 -1.5 -0.5 -0.7 -0.7 -0.7 -2.7 -0.1 -1.1 -0.  -0.4  4.5 -1.7 -0.1 -0.4 -0.5  0.3  1.1  0.6  5.   1.3  3.9  4.7]
ty_50sample [[5 7 4 8 9 3 2 1 0 6]
 [1 7 2 3 9 8 5 4 4 6]
 [1 9 3 0 2 4 5 6 8 7]
 [2 9 0 1 7 6 3 5 4 8]
 [1 8 8 0 6 3 2 4 9 7]
 [5 1 1 7 2 8 4 6 3 0]
 [9 1 1 3 5 0 2 7 6 8]
 [2 7 3 9 5 8 4 6 1 0]
 [8 9 6 0 4 4 2 3 1 5]
 [4 1 0 3 2 9 5 8 7 6]]
tt_50sample [[5 7 4 8 9 3 2 1 0 6]
 [1 7 3 2 9 8 5 0 4 6]
 [1 9 3 0 2 4 5 6 8 7]
 [2 9 0 1 7 6 3 5 4 8]
 [1 5 8 0 6 3 2 4 9 7]
 [5 1 9 7 8 2 4 6 3 0]
 [1 9 4 3 5 0 2 7 6 8]
 [2 7 3 9 5 8 4 6 1 0]
 [8 9 6 0 4 7 2 3 1 5]
 [4 1 0 3 2 9 5 8 7 6]]
vm  [ 2.6 -0.7  4.4  3.8 -0.6 -0.1  0.  -0.2  1.6  2.7  6.2 -0.5  0.9 -0.5  0.6 -1.2  0.3 -0.7  0.5 -0.4 -0.7  0.2  1.4  0.4 -0.9  1.2 -0.6  0.2 -1.4 -3.5 -1.3  0.5  3.1 -2.5 -0.2 -0.3 -0.5  1.  -4.1 -0.2  2.6  3.4 -1.2 -1.3 -0.2 -0.5 -0.1 -0.7  2.3  8.3 -0.5 -0.2 -0.8 14.5  2.3  0.1 -1.2  5.2  8.2  6.  -0.4 -0.6 -0.3 -0.5 -0.  -0.3  0.2  0.7  1.4 -0.2 -0.3  4.  -0.4 -1.  -5.7  0.5 -0.5  3.5 -0.4 -0.4 -2.9 -0.3 -0.3 -0.2 -1.8  2.9 -0.5  0.3 -0.2 -0.3 -0.8 -0.1 -0.3 -0.8 -0.7 -0.2  1.4 -3.4 -0.9 -0.6 -1.   2.8 -0.9 -0.1  0.3 -0.5 -3.1 -0.9  0.1  0.4  0.4 -0.2 -0.1 -0.2  8.9 -3.8  4.   3.  -0.3  2.  -0.7 -0.6 -0.5 -0.5 -0.4  0.6 -0.4 -3.4  5.6 -0.  -0.4 -0.4 -1.1  1.9 10.5  7.2 -0.2 -0.3 -0.8 -0.6 -1.4 -1.2 -0.5 -0.1  0.1 -0.3 -0.2  0.3  3.5 -0.3 -0.6 -0.2  2.9  0.2 -0.1 -0.4 -0.  -0.3 -1.  -0.3 -0.8 -1.   0.4 -0.2 -0.2 -0.6 -0.3 -1.1 -0.6 -0.4 -0.1  0.5 -0.3 -0.5 -0.1 -0.4 -2.7 -0.5  5.2 -0.3 -0.8 -0.5 -0.1 -1.4 -0.  -0.2  0.8 -0.4  0.1  8.8 -0.1 -0.2 -0.5 -0.   4.7 -2.1 -1.8 -2.5 -0.2  0.1 -0.  -0.1  0.2  1.  -0.7 -2.4  0.4 -0.2  3.9 -0.1 -0.2 -2.2  1.  -2.8 -0.2 -0.1  7.2 -0.7 -0.6 -0.6 -0.1 -0.3 -0.1 -1.7  3.1 -1.8 -0.  -0.6 -0.2  2.6 -0.3  5.6 -0.3  1.4 -0.  -1.2  1.2 -1.8 -0.5 -0.7 -0.2 -0.2 -0.2 -0.2  9.3  0.5  3.2 -0.9 -0.7  2.1  7.2 -0.3 -2.4 -0.4 -1.3  2.7]
vy_50sample [[0 2 6 8 5 9 9 3 1 4]
 [1 2 7 7 6 5 8 9 9 4]
 [2 4 5 6 9 1 8 3 0 7]
 [9 4 2 7 3 0 6 1 5 8]
 [4 5 0 1 6 3 2 7 9 8]
 [2 9 1 0 5 3 4 6 7 7]
 [9 5 1 7 3 6 0 4 2 8]
 [1 1 3 2 4 0 7 9 6 8]
 [6 8 3 2 9 9 4 1 7 5]
 [8 2 1 0 4 9 6 7 5 3]]
vt_50sample [[0 2 6 8 5 9 7 3 1 4]
 [1 2 0 7 6 5 8 9 3 4]
 [2 4 5 6 9 1 8 3 0 7]
 [9 4 2 7 3 0 6 1 5 8]
 [4 0 5 1 6 3 2 7 9 8]
 [2 1 9 0 5 3 4 6 8 7]
 [9 5 1 7 3 6 0 4 2 8]
 [1 5 3 2 4 0 7 9 6 8]
 [6 8 3 2 0 9 4 1 7 5]
 [8 2 1 0 4 9 6 5 7 3]]
Epoch 41110: Training cost= 0.2818, Training acc= 0.8538, Validation cost= 0.2687, Validation acc= 0.8538
Epoch 41120: Training cost= 0.2515, Training acc= 0.8538, Validation cost= 0.2676, Validation acc= 0.8538
Epoch 41130: Training cost= 0.2236, Training acc= 0.8538, Validation cost= 0.2614, Validation acc= 0.8538
Epoch 41140: Training cost= 0.2205, Training acc= 0.8538, Validation cost= 0.2328, Validation acc= 0.8539
Epoch 41150: Training cost= 0.2481, Training acc= 0.8538, Validation cost= 0.2678, Validation acc= 0.8539
Epoch 41160: Training cost= 0.2695, Training acc= 0.8538, Validation cost= 0.3699, Validation acc= 0.8539
Epoch 41170: Training cost= 0.2942, Training acc= 0.8538, Validation cost= 0.3045, Validation acc= 0.8539
Epoch 41180: Training cost= 0.2161, Training acc= 0.8538, Validation cost= 0.3101, Validation acc= 0.8539
Epoch 41190: Training cost= 0.2692, Training acc= 0.8539, Validation cost= 0.2067, Validation acc= 0.8539
Epoch 41200: Training cost= 0.2690, Training acc= 0.8539, Validation cost= 0.2257, Validation acc= 0.8539
tm  [ 0.9 -0.3  4.6 -1.7 -1.5 -0.1 -0.5 -0.2 -0.6  0.4  6.8 -0.  -0.2  0.2 11.1  3.2 -0.6  0.7 -0.2 -0.9 -0.9 -0.4  1.5 -0.4 -0.8 -0.1 -0.3 -0.  -0.3  4.2  3.  -0.  -0.6 15.2 -0.2 -0.   0.1  5.   5.9 -0.6  0.4  5.2  0.5  3.  -0.4  0.2  1.  -0.   4.3  8.5 -0.2 -0.2 -0.3  4.9 -1.3 -1.2 -0.6 -1.2 -0.1 -2.  -0.9 -0.5 -0.2 -0.1  0.1 -0.6 -0.3 -0.2 -0.5 -0.5  0.5 -0.7 -0.2  0.6 -3.2 -0.9 -0.3 -0.7 -0.2 -0.6  4.5 -0.3 -0.1 -0.3 -1.6  5.5  7.2  0.2 -0.3 -0.7 -0.4 -0.3  0.4 -0.8 -0.   0.2 -0.8 -2.4 -0.3 -0.2 -0.1 10.2 -0.6 -0.4 -0.1  1.2 -1.3  2.1  1.2 -1.5 -0.1 -0.5 -0.  -0.8 -0.1  4.5 -0.6 -0.  -0.4 -0.4 -0.2  3.8 -0.  -0.2 -0.2 13.5 -0.2 -0.6  0.  -2.   0.1 -0.1 -0.1  0.6 -6.3 -0.3 -0.1 -0.  -0.3 -0.4 -0.6 -0.5 -0.3 -0.2 -0.2 -0.1 -0.1 -0.1 -1.8 -0.1  0.4 -0.1  2.6 -0.6  0.4 -0.3 -0.4 -0.1  1.5 -0.4 -0.3 -1.5 -0.  -0.3 -0.   0.7 -0.2 -0.  -0.1 -0.1 -0.  -0.1 -0.2 -0.3 -0.2  2.7 -0.5 -0.4 -0.4 -0.4 -1.1 -0.3 -0.5 -1.4 -0.2 -0.3  0.8 -0.8 -0.2 -1.2 -0.3 -0.  -0.4 -0.9  8.7 -0.  -0.4 -0.3 -0.4 -0.2 -0.2 -0.3 -0.3 -0.1 -0.3 -1.1 -0.2 -0.3 -1.1 -0.2  0.1  1.2 -0.5 -1.2 -0.1 -0.3 -1.6 -1.2 -0.2 -0.2  0.1 -0.3 -0.5 -0.8  3.2  1.  -0.1  0.4 -0.9  2.5 -0.6 -0.  -0.3 -0.5 -0.5 -0.4 -0.3 -0.5  1.  -0.5 -0.1 -0.4 -0.  -0.1 -0.4 -0.5 -0.5  0.3 -0.7 -0.2 -1.4  0.4  3.5 -0.2 -1.9  9.9]
ty_50sample [[7 4 2 5 9 8 0 6 1 3]
 [9 8 6 4 5 5 1 0 7 3]
 [7 6 3 4 1 8 0 2 9 5]
 [3 3 9 1 0 4 2 5 7 6]
 [4 4 6 1 8 7 0 5 2 3]
 [5 8 7 6 0 0 3 9 4 2]
 [5 8 7 0 0 6 3 1 2 4]
 [5 2 3 0 6 9 4 1 8 7]
 [8 0 7 7 5 6 4 2 1 3]
 [7 9 2 8 0 6 3 3 4 5]]
tt_50sample [[7 4 2 5 9 8 0 6 1 3]
 [9 8 6 4 5 2 1 0 7 3]
 [7 6 3 4 1 8 0 2 9 5]
 [3 8 9 1 0 4 2 5 7 6]
 [4 9 6 1 8 7 0 5 2 3]
 [5 8 7 6 1 0 3 9 4 2]
 [5 8 7 0 9 6 3 1 2 4]
 [5 2 3 0 6 9 4 1 8 7]
 [8 0 7 9 5 6 4 2 1 3]
 [7 9 2 8 0 1 6 3 4 5]]
vm  [-1.3 -0.2 -1.1  9.2 -2.  -0.3 -0.7 -0.2 -0.3 -0.3 -2.3  0.6 -0.3 -0.3 -2.3 -0.7 -0.6 -0.3 -0.2 -1.2 -1.4 -0.2 -0.4  0.4 -0.9  2.8 -0.2 -0.5 -0.6 -1.6  3.1 -0.4 -0.2  4.9 -0.1 -0.1  1.9 -0.1 18.9 -0.2  3.4 -1.1 -0.4  3.6 -0.3 -0.1  8.6  0.5 -0.9 -0.9 -0.3 -0.2  1.3 -4.8 -0.9  2.3 -0.7 -1.5  1.4 -1.3 -0.2 -0.4 -0.1 -0.   0.2 -0.3  0.2 -0.4 -0.1  0.1  0.3 -0.3 -0.2  0.6  5.9 -0.1 -0.3 -0.6 -0.1 -0.  19.3 -0.1  0.3 -0.5  1.3 -0.7 -0.4 -0.2  0.1 -0.6  1.  -0.1 -0.1 -0.8 -0.3 -0.2 -0.6 -0.2 -0.2 -0.1  1.8 -0.2  1.2 -0.2 -0.2  0.2  3.8  2.9 -0.5 -2.1 -0.6 -0.1 -0.2 -0.3  2.1  3.2  1.1 -0.8 -0.2 -0.3 -0.1  9.1  0.3 -0.1 -0.1 -2.8 -0.1 17.3  1.8 -2.3 -0.7  0.2 -0.1 -0.5 -1.9 -0.9 -0.  -0.1  0.4 -0.5  3.2 -0.3  0.6 -0.2  0.2 -0.1 -0.1  0.1 -0.4 -0.1 -0.9 -0.2 -1.1 -0.3  0.   0.3 -0.4 -0.3  4.  -0.3 -0.  -1.6 -0.1 -0.1 -0.2  1.3  0.6  1.6  0.5 -0.2 -0.2 -0.  -0.4 -0.1 -0.2  1.7 -0.2 -0.1 -1.7 -0.1 -0.4 -0.3 -0.  -1.3 -0.3 -0.1 -0.7 -0.4 -0.3  4.9 -0.2 -0.2 -0.1 -1.5  4.1 -0.4  3.5 -0.5 -0.1  0.1 -0.1 -0.3 -0.2 -0.5 -0.1  7.1 -0.4 -0.4  1.  -0.3 -0.3  0.2 -0.9  8.  -0.4 -0.6 -1.6 -1.1 -0.1 -0.1 -0.3 -0.  -0.3 -0.5 -1.1 -0.3 -2.1  0.1  2.9 -0.6 -0.1 -2.  -0.1  0.9 -0.4  2.8 -0.4  3.6  2.9 18.5 -0.2  5.5  0.1 -0.1 -3.9 -2.9 -0.4  1.1 -1.3  0.6 -5.  -0.2 11.6 -0.2  6.9  9.1]
vy_50sample [[9 1 4 3 7 0 5 8 6 2]
 [5 4 3 9 2 0 8 7 1 6]
 [1 8 7 3 3 9 2 4 0 5]
 [0 2 1 5 6 3 8 9 7 4]
 [3 1 0 4 7 8 2 9 5 6]
 [0 2 3 1 6 7 4 9 8 5]
 [0 1 8 4 5 7 2 9 3 6]
 [7 7 4 5 5 6 1 3 0 2]
 [2 8 1 3 5 0 6 7 9 4]
 [9 6 2 7 7 0 1 4 5 3]]
vt_50sample [[9 1 4 3 7 0 5 8 6 2]
 [5 4 3 9 2 0 8 7 1 6]
 [1 8 7 6 3 9 2 4 0 5]
 [0 1 2 5 6 8 3 9 7 4]
 [3 1 0 4 7 8 2 9 5 6]
 [2 0 3 1 6 7 4 9 8 5]
 [0 1 8 4 5 7 9 2 3 6]
 [7 8 9 4 5 6 1 3 0 2]
 [2 8 1 3 5 0 6 7 9 4]
 [9 6 2 8 7 0 1 4 5 3]]
Epoch 41210: Training cost= 0.3221, Training acc= 0.8539, Validation cost= 0.2778, Validation acc= 0.8539
Epoch 41220: Training cost= 0.2583, Training acc= 0.8539, Validation cost= 0.2611, Validation acc= 0.8540
Epoch 41230: Training cost= 0.2493, Training acc= 0.8539, Validation cost= 0.2646, Validation acc= 0.8540
Epoch 41240: Training cost= 0.2119, Training acc= 0.8539, Validation cost= 0.2631, Validation acc= 0.8540
Epoch 41250: Training cost= 0.2814, Training acc= 0.8539, Validation cost= 0.2362, Validation acc= 0.8540
Epoch 41260: Training cost= 0.3694, Training acc= 0.8539, Validation cost= 0.2866, Validation acc= 0.8540
Epoch 41270: Training cost= 0.2628, Training acc= 0.8539, Validation cost= 0.2559, Validation acc= 0.8540
Epoch 41280: Training cost= 0.2360, Training acc= 0.8540, Validation cost= 0.2362, Validation acc= 0.8540
Epoch 41290: Training cost= 0.2338, Training acc= 0.8540, Validation cost= 0.3488, Validation acc= 0.8540
Epoch 41300: Training cost= 0.3716, Training acc= 0.8540, Validation cost= 0.2841, Validation acc= 0.8540
tm  [-0.2 -0.6  4.5  4.9 -1.9  0.  -0.4  0.1 -0.4 -0.2  6.1  0.5  0.1 -0.4  4.6  0.4 -0.7 -0.1 -0.4 -0.6 -1.3 -0.1 -0.2 -0.2 -0.9  3.7 -0.  -0.7 -0.8 -0.1  2.3 -0.5 -0.5 13.5 -0.1  0.5  2.8  5.3 14.8 -0.5  3.  -0.8  0.8  4.5 -0.4  1.6  3.7 -0.   4.7 -0.6 -0.3 -0.2  1.7 -0.8 -0.3 -0.3 -0.5 -2.1  0.7 -1.4 -0.4 -0.3 -0.   1.4  0.5 -0.4 -0.1 -0.3  0.5 -0.2  0.3  0.7  0.1  3.2 -0.8 -0.6 -0.7 -0.7 -0.  -0.  13.1  0.6  0.4  0.5 -0.9 -0.6  5.  -0.3 -0.2 -0.8 -0.1  0.3 -0.2 -0.8  0.4 -0.1 -1.  -1.9 -0.2 -0.3  0.3  7.1 -0.7 -0.1  0.4  0.   1.7  2.5  2.6 -1.1 -0.9 -0.3 -0.1 -0.3  1.9 -0.6 -0.4 -0.7 -0.2 -0.4  0.1  4.4  0.8  0.5 -0.1  5.3 -0.2  5.5  0.8 -1.2 -0.4  0.2  0.6 -0.3 -6.8 -1.2 -0.1 -0.4  0.1 -0.4 -0.1 -1.1 -0.3 -0.2 -0.  -0.3 -0.2 -0.3 -2.8 -0.1 -1.  -0.1 -0.2 -0.5  1.1 -0.2 -0.1 -0.5  4.7 -0.2  1.3 -1.9  0.2 -0.   0.  -0.5 -0.2 -0.1 -0.  -0.1 -0.2 -0.1 -0.2 -0.1 -0.2  4.5  0.6  0.2 -1.3 -0.  -0.  -0.6 -0.3 -1.6 -0.1 -0.1  1.8 -0.5 -0.5 -0.1 -0.1 -0.1 -0.4 -0.9  6.9 -0.1  1.8 -0.6 -0.1  0.1 -0.2  0.1 -0.3 -0.1 -0.1  2.2 -0.1 -0.2  1.7 -0.2 -0.6 -0.5 -1.1 -0.2 -1.2 -0.4 -2.1 -1.  -0.4  0.1 -0.1 -0.1 -0.5 -0.3 -0.9 -0.8 -1.  -0.1 -0.6  0.8  0.3 -1.4 -0.1  1.3  1.3 -0.5 -0.1  2.2  3.4 14.1 -0.2  4.3  0.2 -0.2 -2.4 -1.8 -0.1  1.8 -1.  -0.4 -3.5  0.4  9.5 -0.2  0.7  5.8]
ty_50sample [[7 9 4 0 2 3 1 8 5 6]
 [6 4 2 3 5 0 1 9 7 8]
 [5 4 1 0 9 7 2 6 8 3]
 [3 9 1 0 2 5 6 4 4 7]
 [7 3 5 1 0 6 2 4 9 8]
 [5 0 8 1 3 3 2 6 4 7]
 [1 5 6 0 7 4 8 2 9 3]
 [0 2 1 7 4 8 5 6 6 3]
 [6 4 0 7 1 9 8 2 5 3]
 [6 8 7 1 4 2 3 0 5 9]]
tt_50sample [[7 9 4 0 2 3 1 8 5 6]
 [6 4 2 3 5 0 1 9 7 8]
 [5 4 1 0 9 7 2 6 8 3]
 [3 9 2 0 1 5 6 8 4 7]
 [7 3 5 1 0 6 2 4 9 8]
 [5 0 8 1 3 9 2 6 4 7]
 [1 5 6 0 7 4 8 2 9 3]
 [0 2 1 7 4 8 5 6 9 3]
 [6 4 7 0 1 9 8 2 5 3]
 [6 8 7 1 4 2 3 0 5 9]]
vm  [-1.2 -0.3 -1.6 -4.9 -1.8 -0.3 -0.4 -0.  -0.2 -0.9 -4.7 -0.2 -0.3 -0.3  7.2 -0.9 -0.2 -0.5 -0.1  0.5 -0.9 -0.3  0.1 -0.2 -1.3 -0.2  0.4 -0.2 -0.3 -0.7  3.3 -0.2 -0.1 -0.6 -0.1 -0.1 -0.2 -0.9 -1.9 -0.2  0.2  8.4  0.   2.5 -0.2 -0.1 -2.   0.8 -0.8  9.2 -0.8 -0.1 -0.3 -0.  -1.3 -0.8 -0.9  2.5  3.  -1.   7.3 -0.7 -0.4 -0.4 -0.4 -0.4 -0.2  0.4  0.5 -0.1 -0.1 -0.8 -0.2 -0.4 -5.9 -0.1 -0.1 -0.4 -0.1 -0.3 -3.9 -0.2 -0.2 -0.2  0.1  8.1  1.3 -0.2 -0.  -0.6 -0.3  0.3  0.2 -0.3 -0.7 -0.1 -0.4 -3.3 -0.4 -0.4  2.4  4.2  0.4 -0.2 -0.4  0.8 -2.9  1.5 -1.5  0.9 -0.3 -0.1 -0.2 -1.1  2.   5.2  0.1  1.2 -0.2  0.2 -0.2 -0.5  0.1 -0.1 -0.1  9.1 -0.4  2.9  6.2  0.7 -0.5 -0.6 -0.1 -0.4 -0.4 -1.  -0.3  0.2 -0.1 -0.5  3.  -0.3  1.3  0.1 -0.  -0.2 -0.3 -0.2  6.4  0.4  4.  -0.2 -0.2  0.1 -0.5  0.3 -0.3  1.5  0.6 -0.4 -0.5 -0.5 -0.  -0.  -0.3  0.8  0.   0.3  1.6 -0.2 -0.1  0.3 -0.5 -0.1 -0.4 -0.8 -0.8 -0.5  3.  -0.1 -2.3 -0.4 -0.4 -1.7 -0.3 -0.1 -0.6 -0.5 -0.5  2.3 -0.  -0.1 -0.3 -1.3 -3.1 -1.7 -0.9 -0.6 -0.1  0.  -0.2 -0.3 -0.4 -0.3 -0.3 -3.3 -0.3 -0.2 -2.8 -0.2 -0.1  0.7 -0.6  4.6  0.4 -0.6 -1.1 -1.  -0.2 -0.3 -0.1 -0.  -0.4 -1.   1.9  2.8 -1.9 -0.5 -0.3  0.6 -0.8  1.1 -0.3 -1.3 -0.5  2.7 -0.1 -1.4  1.  -7.   0.3 -2.4 -0.1 -0.  12.8  4.4 -0.2 -0.5 -1.   0.3 10.2 -0.1 -1.2 -0.2  3.1  1.4]
vy_50sample [[5 4 1 8 7 6 0 3 3 2]
 [0 5 4 1 8 9 6 6 2 7]
 [9 1 7 7 8 3 4 5 2 6]
 [1 9 7 8 6 5 2 2 3 4]
 [0 0 4 7 3 2 5 8 1 9]
 [4 5 3 8 0 6 1 7 2 9]
 [2 6 3 8 7 1 5 4 9 0]
 [9 5 8 2 3 0 6 1 7 4]
 [9 4 6 1 5 2 7 0 3 8]
 [0 1 4 5 2 6 3 9 8 7]]
vt_50sample [[5 4 1 8 7 6 0 3 9 2]
 [0 5 4 1 8 9 6 3 2 7]
 [9 1 0 7 8 3 4 5 2 6]
 [1 9 7 8 6 5 0 2 3 4]
 [0 6 4 3 7 2 5 8 1 9]
 [4 5 3 8 0 6 7 1 2 9]
 [2 6 3 8 7 1 5 4 9 0]
 [9 5 8 2 3 0 6 1 7 4]
 [9 4 6 1 5 2 7 0 3 8]
 [0 1 4 5 2 3 6 9 8 7]]
Epoch 41310: Training cost= 0.2656, Training acc= 0.8540, Validation cost= 0.2785, Validation acc= 0.8540
Epoch 41320: Training cost= 0.2680, Training acc= 0.8540, Validation cost= 0.2666, Validation acc= 0.8541
Epoch 41330: Training cost= 0.2779, Training acc= 0.8540, Validation cost= 0.2360, Validation acc= 0.8541
Epoch 41340: Training cost= 0.2342, Training acc= 0.8540, Validation cost= 0.2740, Validation acc= 0.8541
Epoch 41350: Training cost= 0.2374, Training acc= 0.8540, Validation cost= 0.2534, Validation acc= 0.8541
Epoch 41360: Training cost= 0.2627, Training acc= 0.8540, Validation cost= 0.2437, Validation acc= 0.8541
Epoch 41370: Training cost= 0.2643, Training acc= 0.8541, Validation cost= 0.2568, Validation acc= 0.8541
Epoch 41380: Training cost= 0.2622, Training acc= 0.8541, Validation cost= 0.2766, Validation acc= 0.8541
Epoch 41390: Training cost= 0.2841, Training acc= 0.8541, Validation cost= 0.2393, Validation acc= 0.8541
Epoch 41400: Training cost= 0.2269, Training acc= 0.8541, Validation cost= 0.2854, Validation acc= 0.8541
tm  [-1.5 -0.2 -1.5  6.8 -0.4 -0.1 -0.4 -0.1  1.1  1.   7.8 -0.3 -0.3 -0.2 -1.7  6.  -0.2 -0.2 -0.2 -0.7 -1.2 -0.2  1.7 -0.5 -0.6 -0.1 -0.3 -0.4  1.2 -2.9 -1.  -0.6 -0.5 -4.2  0.1 -0.1 -0.3  5.1 -0.1 -0.5 -0.1 -2.5 -1.8 -0.7 -0.4 -0.2  0.4 -0.5 -1.4  4.7 -0.3 -0.2 -0.4 10.4 -2.   1.8 -0.4 -1.3  7.4  3.8  6.1 -0.5 -0.4 -0.1 -0.1 -0.6 -0.2  0.4 -0.8 -0.1  0.  -1.6  1.2  1.8 -4.3 -0.8 -0.4 -0.2 -0.1 -0.4 -0.9 -0.  -0.2 -0.6  0.2 -2.2 -1.9 -0.2 -0.2 -0.7 -0.3 -0.2 -0.1 -0.8 -0.6 -0.2 -0.9 -2.5 -0.3 -0.1 -0.5 -1.7 -0.1 -0.2 -0.2  0.9 -1.6 -0.5  0.6 -1.5  1.  -0.4  0.1 -0.7  2.2  8.8 -0.5  0.6 -0.2 -0.1 -0.2  3.3 -0.4 -0.  -0.5 -2.2 -0.1 -2.3  4.3  0.7 -0.  -0.1 -0.4  2.6 11.7  0.  -0.4 -0.2  0.4 -0.6 -1.  -0.2 -1.2 -0.4 -0.1 -0.2 -0.3 -0.4  0.7 -0.2 -0.8  0.1 -0.8 -0.4 -0.1 -0.  -0.4 -0.4 -0.5 -0.2 -0.7 -0.5 -0.1 -0.  -0.2  0.7 -0.2  1.9  0.2  0.3 -0.3 -0.4 -0.5  0.4 -0.2  0.8 -0.7 -0.2  0.2 -0.1  1.1 -0.1 -0.3 -1.7 -0.   0.4 -0.4 -0.1 -0.3  8.7 -0.2 -0.1 -0.3 -1.  -2.  -1.7 -0.3 -0.5  0.1 -0.1 -0.1 -0.1 -0.5 -0.4  0.  -0.7 -0.5 -0.3  9.5 -0.4 -0.5  3.5 -0.9  5.5 -0.3 -0.5  3.2 -0.9 -0.8 -0.  -0.4 -0.2  0.2 -1.1  2.   3.9  1.3  0.9 -0.4 -0.5 -0.1 -0.  -0.1  2.7 -1.   2.3 -0.4 -1.1  1.3 12.5 -0.3  3.5 -0.1 -0.2  4.4 -0.4 -0.3  0.4 -1.1  0.3  1.3 -0.2 -0.1 -0.1 -1.2  2.2]
ty_50sample [[2 1 8 6 9 3 4 0 7 7]
 [5 9 4 2 8 1 7 0 3 6]
 [4 9 6 5 5 7 3 8 2 0]
 [3 3 1 4 0 7 6 2 5 8]
 [8 2 3 4 0 0 9 7 5 6]
 [6 0 1 8 7 2 5 9 3 4]
 [2 5 0 1 4 3 3 9 6 7]
 [5 6 9 3 4 2 0 8 7 1]
 [4 4 7 9 9 6 3 1 5 8]
 [9 1 6 2 0 4 7 5 8 3]]
tt_50sample [[2 1 8 6 9 3 4 0 7 5]
 [5 9 4 2 8 1 7 0 3 6]
 [4 9 6 1 5 7 8 3 2 0]
 [3 9 1 4 0 6 7 2 5 8]
 [8 2 3 4 0 1 9 7 5 6]
 [6 0 1 8 7 2 5 9 3 4]
 [2 5 0 1 4 8 3 9 6 7]
 [5 6 9 3 4 2 0 8 7 1]
 [4 2 7 0 9 6 3 1 5 8]
 [9 1 6 2 0 4 7 5 8 3]]
vm  [ 1.1 -0.3  5.6 18.8 -1.8  0.4 -0.1 -0.2 -0.9  1.4 -5.8 -0.4 -0.1 -0.4 -1.7 -2.9  0.  -0.8  0.  -1.8 -0.9 -0.2  2.  -0.3 -0.7  1.7 -0.1 -0.  -1.6 -0.  -1.1 -0.6 -0.2 -0.7 -0.2 -0.2  3.1 -1.9  6.7 -0.2  1.2 -0.8  0.5 -0.7 -0.3 -0.2 10.7 -0.   4.2  4.1 -0.3 -0.3 -0.2 -4.7  2.5  1.2 -0.8  2.  -1.1  5.3 -2.3 -0.3 -0.6 -0.2 -0.4  0.6  0.  -0.5 -0.1  0.3 -0.3  6.2 -0.7 -0.7  5.5 -0.3 -0.4  0.9 -0.   1.2  7.7  1.4 -0.3 -0.3 -1.4 -1.   1.7 -0.2  0.6 -0.3  0.2 -0.1 -0.3  0.2 -0.5 -0.3  0.   0.3 -0.1 -0.1 -0.7 -0.2 -0.6 -0.2 -0.1  1.   2.1 -0.5 -1.8 -2.1  0.5 -0.  -0.   0.7  2.9 -3.8 -0.9 -0.6 -0.  -0.3 -0.3  9.3 -0.3 -0.5 -0.1 -2.  -0.2 16.7 -1.8 -1.3  1.1  0.   0.2  0.5  5.   1.7 -0.3 -0.   0.3 -0.2  1.3 -1.2  0.9 -0.3  0.1 -0.3 -0.2  0.2 -0.5 -0.2 -1.7  0.   2.7 -0.1 -0.3 -0.2 -0.4  1.3 -1.1 -0.3  0.1 -0.1  0.1 -0.1 -0.   1.2 -0.4 -0.9 -0.2 -0.1 -0.   0.3 -0.1  0.6 -0.1  1.7 -0.8 -0.1 -0.5 -0.2 -0.8  0.1 -0.1 -1.3 -0.1 -0.3  0.3 -0.3  0.6  0.6 -0.3 -0.2 -0.2 -0.7 15.3  6.8  0.3 -0.9 -0.1  0.5  1.  -0.   0.3 -0.1 -0.2  5.3 -0.3 -0.2  6.2  0.4 -0.7 -2.5 -0.3 -1.2 -0.3 -0.5  5.1 -0.9 -0.8 -0.4 -0.3 -0.3 -0.1 -0.9  2.2 -1.4 -1.8  0.2 -0.   2.1 -0.5 -1.2 -0.1  1.6  1.9 -0.9  1.4  2.   1.8 18.4 -0.2  5.2 -0.2 -0.  -1.2 -2.5 -0.3 -0.3 -0.7 -0.4 -2.  -0.1  4.1 -0.1  7.1  6.4]
vy_50sample [[0 0 6 8 3 7 5 4 1 2]
 [3 7 0 2 5 6 9 9 1 4]
 [5 1 8 3 4 2 9 6 0 7]
 [8 4 0 2 2 3 1 9 9 5]
 [1 4 9 8 3 0 7 5 2 6]
 [0 9 6 7 5 8 4 1 2 2]
 [3 9 0 7 4 2 2 1 5 6]
 [2 9 4 1 7 0 6 8 3 5]
 [3 1 5 2 4 6 7 9 8 0]
 [7 3 5 5 6 2 9 0 4 1]]
vt_50sample [[0 9 8 6 3 7 5 4 1 2]
 [7 3 0 2 5 6 8 9 1 4]
 [5 1 8 3 4 2 9 6 0 7]
 [8 4 0 2 6 3 1 7 9 5]
 [1 4 9 8 0 3 7 5 2 6]
 [0 9 6 7 5 8 4 1 3 2]
 [3 9 0 7 4 8 2 1 5 6]
 [2 9 4 1 0 7 6 8 3 5]
 [3 1 5 2 4 6 7 9 8 0]
 [7 3 5 8 6 2 9 0 4 1]]
Epoch 41410: Training cost= 0.3027, Training acc= 0.8541, Validation cost= 0.2549, Validation acc= 0.8542
Epoch 41420: Training cost= 0.2428, Training acc= 0.8541, Validation cost= 0.2355, Validation acc= 0.8542
Epoch 41430: Training cost= 0.2359, Training acc= 0.8541, Validation cost= 0.2390, Validation acc= 0.8542
Epoch 41440: Training cost= 0.2417, Training acc= 0.8541, Validation cost= 0.3126, Validation acc= 0.8542
Epoch 41450: Training cost= 0.2249, Training acc= 0.8541, Validation cost= 0.2676, Validation acc= 0.8542
Epoch 41460: Training cost= 0.2100, Training acc= 0.8542, Validation cost= 0.2537, Validation acc= 0.8542
Epoch 41470: Training cost= 0.2247, Training acc= 0.8542, Validation cost= 0.2164, Validation acc= 0.8542
Epoch 41480: Training cost= 0.2389, Training acc= 0.8542, Validation cost= 0.2541, Validation acc= 0.8542
Epoch 41490: Training cost= 0.2569, Training acc= 0.8542, Validation cost= 0.2569, Validation acc= 0.8542
Epoch 41500: Training cost= 0.2109, Training acc= 0.8542, Validation cost= 0.2552, Validation acc= 0.8543
tm  [-1.4 -0.1 -2.9 -1.1 -1.2 -0.3 -0.  -0.1 -0.6 -0.9 -0.6 -0.1 -0.3 -0.1 -1.3 -0.1 -0.2 -0.1 -0.3 -0.2 -1.1 -0.3  0.5 -0.2 -1.5  1.9  0.3 -0.4 -0.8 -1.2  1.9 -0.3 -0.4 -2.9 -0.2  0.1  3.3  2.5  4.9 -0.2 -0.   8.   1.9  2.5 -0.2  0.2  0.4 -0.3 -1.2  9.1 -0.6 -0.2  0.3  0.9 -0.8  0.9 -0.5  3.9 -0.5 -0.4  5.1 -0.3 -0.2 -0.2 -0.5 -0.5 -0.1 -0.3  0.2  0.2  0.2  0.9  0.4  0.1 -2.6 -0.5  0.1 -0.5 -0.  -0.4 -0.4 -0.2  0.1 -0.1  1.3  8.3 -0.3 -0.2 -0.2 -0.1 -0.1 -0.2 -0.1  0.4 -0.7 -0.2 -0.2 -2.  -0.1 -0.3  2.5  1.2  0.1 -0.2 -0.4 -0.  -1.6  1.2 -0.3 -0.9 -0.3 -0.3 -0.  -0.5 -0.   0.5 -0.3 -0.8 -0.1 -0.1 -0.1  2.8  0.4 -0.1 -0.2 -1.5 -0.2  1.9  0.9 -1.3 -0.4 -0.1 -0.2 -0.3  4.7 -1.8 -0.1  0.  -0.  -0.3  0.4 -0.6 -0.1  0.2 -0.2 -0.2 -0.4 -0.2  8.6 -0.2  0.4 -0.  -0.5  0.6 -0.3  0.  -0.4 -0.2  1.5  0.1 -0.2 -0.7 -0.2  0.  -0.2 -0.3 -0.1 -0.2  0.7 -0.2 -0.1 -0.2 -0.3 -0.3 -0.4 -1.6 -0.2 -0.3 -0.3  0.3 -1.9 -0.3 -0.3 -1.9 -0.  -0.2 -0.5 -0.1 -0.1  3.9 -0.1 -0.1 -0.4 -1.2 -1.5  0.2 -0.4 -0.1  0.  -0.2 -0.  -0.1 -0.6 -0.2 -0.3 -1.4 -0.  -0.  -2.7 -0.2  0.4 -0.4 -0.6  7.9 -0.3 -0.1 -1.2 -0.9 -0.1 -0.2 -0.  -0.  -0.2 -1.   2.4  1.1 -0.9 -0.3 -0.4 -0.4 -0.9 -0.1 -0.2 -1.1  0.8  4.  -0.3 -0.5  1.1 -3.4 -0.1 -1.2 -0.1 -0.2  3.2 -0.8 -0.2 -0.2 -1.1 -0.4 -0.1 -0.1  3.2 -0.1 -0.4  7.2]
ty_50sample [[5 1 4 8 0 9 2 6 7 3]
 [3 5 2 8 7 4 9 0 6 1]
 [9 1 1 7 3 2 6 5 0 4]
 [2 5 1 3 6 4 9 0 8 7]
 [5 6 4 9 7 8 1 2 3 0]
 [4 7 9 8 8 1 3 5 2 0]
 [2 0 8 3 1 7 6 9 5 4]
 [4 9 3 5 6 8 0 7 2 1]
 [2 4 3 0 9 6 5 7 1 8]
 [9 4 8 7 5 6 1 0 2 3]]
tt_50sample [[5 1 4 8 0 9 2 6 3 7]
 [3 5 2 8 7 4 9 0 6 1]
 [9 8 1 7 3 2 6 5 0 4]
 [2 5 1 3 6 4 9 0 8 7]
 [5 6 4 9 7 8 1 2 3 0]
 [4 7 9 6 8 1 3 5 2 0]
 [2 0 8 3 1 7 6 9 5 4]
 [4 9 3 5 6 8 7 0 2 1]
 [2 4 3 0 9 5 6 7 1 8]
 [9 4 8 7 5 6 1 0 2 3]]
vm  [-0.5 -0.5 -1.   6.7 -0.7 -0.4  0.7 -0.1  1.2  1.4  5.7 -0.5 -0.  -0.3 -1.5  2.8  2.8  0.1 -0.2 -0.1 -1.   0.2  0.3 -0.3 -1.1  4.5 -0.2  0.7 -0.5 -2.1 -1.4 -0.5 -1.7 -5.5 -0.2 -0.2 -0.6  5.   4.2 -0.3 -1.5  2.7 -1.  -1.1 -0.  -0.3 -0.1 -0.7  3.8 14.2 -0.5 -0.4  0.3 10.  -0.6  1.5  1.1  2.4  4.6  5.6 -0.3  0.2 -0.2 -0.7 -1.1 -0.6 -0.3 -0.3 -0.6 -0.1 -0.  -0.3  0.5  1.7 -3.5 -0.4 -0.1  1.4 -0.4 -0.5 -2.6  0.6  0.2 -0.3 -1.5  5.7 -0.1  0.9 -0.6 -0.  -0.  -0.2 -0.2 -1.6 -0.7 -0.3 -0.2 -2.5 -0.3 -0.5 -1.1  2.2 -0.8 -0.2 -0.4  0.5 -1.2 -0.7  1.3 -1.1  2.2  0.4  0.7 -0.3  2.9  1.1 -1.   0.2 -0.2 -0.1 -0.3  1.9 -0.4 -0.2  0.4 -1.8 -0.  -1.9  2.2 -1.6  3.3 -0.1 -0.9  0.6  9.6 -3.  -0.2 -0.2  1.5  1.5 -0.7 -1.1 -1.1  0.8 -0.1 -0.  -0.1 -0.2  4.4 -0.3 -0.8 -0.   2.6  1.8 -0.3  0.  -0.9 -0.8 -0.8  0.1  0.8 -0.4  0.3 -0.1  1.4 -0.3 -0.6  0.1 -0.2  0.4 -0.2 -0.5 -0.1 -0.2  0.4 -0.7 -0.3  0.4 -0.3  0.6 -0.3 -0.4 -0.6 -2.1 -0.3 -0.1  1.7 -0.3 -0.2  5.   0.2 -0.3 -0.5 -0.5  4.8 -0.8  0.6 -1.2 -0.  -0.3 -0.2  0.3 -0.4  0.1 -0.3 -0.1 -0.  -0.1  7.2 -0.1 -0.1  1.1 -1.  -0.  -0.9 -0.1  4.  -0.5 -0.8 -0.5 -0.2 -0.2 -0.1 -1.   6.9  0.8 -0.1  0.5 -0.9  1.7 -0.8 -0.7 -0.3  1.9 -0.6  1.7 -0.2 -0.7  2.8  5.6 -0.2  1.4 -0.1 -0.4  8.5 -1.7 -0.1 -0.6 -1.1 -0.8  6.  -0.2  2.7 -0.  -2.3  8.6]
vy_50sample [[2 8 9 0 0 5 1 4 7 3]
 [8 1 0 3 2 4 9 6 5 7]
 [0 5 2 6 8 4 7 3 1 9]
 [2 9 5 6 6 1 3 3 4 0]
 [2 6 0 4 5 3 1 9 7 8]
 [4 3 1 0 5 8 2 7 9 6]
 [1 3 0 6 9 2 8 4 7 5]
 [1 4 5 3 7 0 6 9 8 2]
 [6 8 0 3 9 4 2 2 1 5]
 [6 6 0 5 2 1 9 7 3 8]]
vt_50sample [[2 8 9 6 0 5 1 4 7 3]
 [8 1 0 3 2 4 9 6 5 7]
 [0 5 2 6 8 4 7 3 1 9]
 [2 9 5 6 1 8 7 3 4 0]
 [2 6 0 5 4 3 1 9 7 8]
 [4 3 1 0 5 8 2 7 9 6]
 [1 3 0 6 9 2 8 4 7 5]
 [1 4 3 5 7 0 6 9 8 2]
 [6 8 0 3 9 4 2 7 1 5]
 [4 0 6 5 2 1 9 7 3 8]]
Epoch 41510: Training cost= 0.2428, Training acc= 0.8542, Validation cost= 0.2457, Validation acc= 0.8543
Epoch 41520: Training cost= 0.2724, Training acc= 0.8542, Validation cost= 0.3028, Validation acc= 0.8543
Epoch 41530: Training cost= 0.2183, Training acc= 0.8542, Validation cost= 0.2375, Validation acc= 0.8543
Epoch 41540: Training cost= 0.2432, Training acc= 0.8542, Validation cost= 0.2505, Validation acc= 0.8543
Epoch 41550: Training cost= 0.2087, Training acc= 0.8543, Validation cost= 0.2622, Validation acc= 0.8543
Epoch 41560: Training cost= 0.2472, Training acc= 0.8543, Validation cost= 0.2661, Validation acc= 0.8543
Epoch 41570: Training cost= 0.2088, Training acc= 0.8543, Validation cost= 0.2894, Validation acc= 0.8543
Epoch 41580: Training cost= 0.2218, Training acc= 0.8543, Validation cost= 0.2771, Validation acc= 0.8544
Epoch 41590: Training cost= 0.2616, Training acc= 0.8543, Validation cost= 0.2919, Validation acc= 0.8544
Epoch 41600: Training cost= 0.2760, Training acc= 0.8543, Validation cost= 0.2157, Validation acc= 0.8544
tm  [-1.7 -0.2 10.7 21.  -1.4 -0.1 -0.  -0.  -0.7  0.   1.7 -0.1 -0.3  0.1  0.9 -0.5 -0.1 -0.3 -0.6 -1.  -1.  -0.1 -0.5 -0.3 -0.4  1.7 -0.1 -0.6 -0.5  0.6 -1.1 -0.2 -0.3  7.7 -0.2  0.1  2.6 -1.8 -1.4  0.1  1.2 -1.7  0.1 -1.7 -0.1  0.4  5.4  1.1 -1.3 -0.9 -0.2 -0.1  0.1 -1.4 -0.2 -0.1 -0.3  3.3 -0.5  5.9  3.7 -0.3 -0.3 -0.3 -0.4 -0.3 -0.2 -0.5 -0.1  0.  -0.1  0.2 -0.4  0.6 -1.  -0.5 -0.1  0.1 -0.1 -0.4 11.  -0.  -0.2 -0.4  1.9 -1.4 -2.8 -0.2  0.3 -0.3 -0.4  0.3 -0.3  0.7 -0.4 -0.  -0.  -1.  -0.1 -0.1  0.   3.2  1.2 -0.2 -0.2 -0.  -0.4 -0.4  0.5 -2.2 -0.6 -0.2 -0.1 -0.5  0.7 -0.2 -0.7 -0.8 -0.1 -0.7  0.7  7.7 -0.1 -0.2 -0.   1.1 -0.3  6.2 -1.4 -0.5 -0.1 -0.2 -0.4 -0.   6.7 14.9 -0.1 -0.2  0.6 -0.6  0.  -0.3  0.6  0.1 -0.1 -0.2 -0.1 -0.2 -1.8  0.1 -2.  -0.2 -1.4  1.6 -0.3 -0.1 -0.4 -0.3 -1.5 -0.6 -0.2  2.5 -0.1  0.3 -0.2  1.7 -0.1 -0.   0.4 -0.1 -0.1 -0.2 -0.1  0.2 -0.2  3.7 -0.7 -0.2  2.2 -0.1  0.2  0.3 -0.4 -0.8 -0.1 -0.5 -0.9 -0.7 -0.3  0.6  0.3 -0.1 -0.2 -0.8 -0.8  5.7  0.8 -0.2 -0.1  0.  -0.3 -0.1 -0.3 -0.  -0.3  0.6 -0.1 -0.2  4.8  0.7 -0.8 -0.5 -0.4  7.  -0.6 -0.4  9.  -1.1 -0.4 -0.5 -0.1  0.7 -0.2 -0.3  2.6 -0.5 -1.6 -0.6 -0.  -0.4  2.1 -0.4 -0.2  1.4 -0.1 -2.7 -0.4  0.3  1.6 17.6 -0.3  5.1  0.3 -0.1 -2.  -1.2 -0.5 -0.1 -1.1 -0.2 -2.9 -0.1 -0.8 -0.4  3.7  3.7]
ty_50sample [[6 1 7 9 0 3 8 2 5 4]
 [4 0 9 3 5 5 6 7 8 2]
 [6 5 1 8 2 4 3 7 9 0]
 [3 5 2 4 8 0 7 1 6 9]
 [1 5 0 7 9 8 3 6 4 2]
 [3 9 9 4 6 7 8 5 5 0]
 [9 7 5 2 4 0 8 1 6 3]
 [4 5 7 9 1 1 0 6 2 8]
 [9 2 6 7 0 4 1 5 3 8]
 [1 1 8 5 4 0 6 3 7 9]]
tt_50sample [[6 1 7 9 0 3 2 8 5 4]
 [4 0 9 3 5 6 7 1 8 2]
 [6 5 1 8 4 2 3 7 9 0]
 [3 5 2 8 4 7 0 1 6 9]
 [1 5 0 7 9 8 3 6 4 2]
 [3 2 9 4 6 7 8 5 1 0]
 [9 7 5 2 4 0 8 1 6 3]
 [4 5 7 3 9 1 0 6 2 8]
 [9 2 6 7 0 4 1 5 3 8]
 [8 2 1 5 4 0 6 3 9 7]]
vm  [-0.1 -0.  -0.4  1.  -1.9  0.2 -0.2 -0.1 -0.5 -0.4  6.9  0.1 -0.2 -0.2  0.2 -1.2  1.1 -0.5  0.8  0.6 -1.2 -0.5 -1.  -0.1 -1.6  5.5 -0.2  0.3 -1.8 -2.9  1.5 -0.3 -0.3  2.7 -0.1 -0.3  3.3  0.5 -1.3 -0.2  0.6  1.1  1.4 -0.8 -0.3 -0.2 -1.1 -0.6  4.7 -2.8 -0.2 -0.1 -0.5  3.7  3.4  0.3 -0.5  7.   2.  -0.6  2.  -0.3  1.3  0.2 -0.6  0.4 -0.3 -0.6 -0.4 -0.3  0.3  7.8 -0.2  0.4 -3.9 -0.  -0.6  0.5 -0.2 -0.2  5.3 -0.4 -0.3 -0.9 -1.   1.6  0.4 -0.2  0.2  0.1 -0.5 -0.  -0.2  0.  -0.2 -0.4  1.3 -2.9 -0.4 -0.4  0.3 -1.5 -1.3 -0.1  0.2 -0.1 -1.4  1.3  1.3 -0.1  0.2 -0.  -0.  -0.1  4.8 -3.5 -0.5 -0.4 -0.1 -0.1 -0.5 -0.1 -0.3  0.9  0.1 -0.  -0.1 -0.3  2.5  6.4  0.4 -0.2 -0.5 -0.2  8.5  9.7 -0.2 -0.1  1.1 -0.1 -0.4 -1.6 -0.6 -0.4 -0.1 -0.2 -0.3 -0.1  7.  -0.2 -0.3  0.2 -0.3 -0.2 -0.1 -0.2 -0.6 -0.3 -0.2  0.   0.5 -0.9  0.6  0.2  0.6 -0.6 -0.1 -0.9 -0.3 -0.  -0.2 -0.1 -0.5 -0.3 -0.4 -1.4 -0.5 -0.3  3.  -0.2 -1.5  0.4 -0.3 -2.  -0.2 -0.6  1.1 -0.3  0.1  8.  -0.  -0.1 -0.3 -1.3  0.4 -0.7 -0.6 -1.3 -0.3  0.2 -0.5 -0.1 -0.  -0.   0.3 -1.4 -0.2 -0.2 -3.6  0.3 -0.5 -2.4 -0.3 -0.3 -0.5 -0.5  3.5 -1.1 -1.  -0.9 -0.2  0.1 -0.  -0.9 -0.  -2.1 -0.9  1.   1.5  1.2 -0.2 -0.2 -0.1 -1.5  4.   0.4  0.8 -0.7  1.2 -2.2 -0.2 -0.6 -0.  -0.1 -0.7 -0.2 -0.3 -0.3 -1.3 -0.2 -1.4 -0.1 -0.9  0.2  2.5 -1.2]
vy_50sample [[0 5 3 6 2 1 4 9 7 8]
 [3 1 8 7 5 2 9 9 4 6]
 [3 7 6 4 2 8 1 0 5 9]
 [5 2 3 9 6 1 0 7 8 4]
 [9 1 3 6 7 4 4 5 8 0]
 [4 9 0 1 8 2 5 6 3 7]
 [0 7 4 6 5 8 2 1 9 3]
 [2 2 1 3 4 7 6 8 5 9]
 [5 7 4 3 6 9 8 8 0 2]
 [4 1 5 0 9 6 8 3 7 2]]
vt_50sample [[0 5 3 6 2 1 4 9 7 8]
 [3 8 1 7 5 2 0 4 9 6]
 [3 7 6 4 2 8 1 0 5 9]
 [5 2 3 9 6 1 0 7 8 4]
 [9 1 3 6 7 2 4 5 0 8]
 [4 9 0 8 1 2 5 6 3 7]
 [0 7 4 6 5 8 2 1 9 3]
 [2 0 1 3 4 7 6 8 5 9]
 [5 7 4 3 6 9 8 1 0 2]
 [4 1 0 5 9 6 8 3 7 2]]
Epoch 41610: Training cost= 0.2020, Training acc= 0.8543, Validation cost= 0.2067, Validation acc= 0.8544
Epoch 41620: Training cost= 0.2200, Training acc= 0.8543, Validation cost= 0.2273, Validation acc= 0.8544
Epoch 41630: Training cost= 0.2439, Training acc= 0.8544, Validation cost= 0.1903, Validation acc= 0.8544
Epoch 41640: Training cost= 0.2478, Training acc= 0.8544, Validation cost= 0.2215, Validation acc= 0.8544
Epoch 41650: Training cost= 0.2418, Training acc= 0.8544, Validation cost= 0.3410, Validation acc= 0.8544
Epoch 41660: Training cost= 0.2315, Training acc= 0.8544, Validation cost= 0.2750, Validation acc= 0.8544
Epoch 41670: Training cost= 0.2300, Training acc= 0.8544, Validation cost= 0.2268, Validation acc= 0.8545
Epoch 41680: Training cost= 0.2254, Training acc= 0.8544, Validation cost= 0.2860, Validation acc= 0.8545
Epoch 41690: Training cost= 0.2628, Training acc= 0.8544, Validation cost= 0.2812, Validation acc= 0.8545
Epoch 41700: Training cost= 0.2469, Training acc= 0.8544, Validation cost= 0.2749, Validation acc= 0.8545
tm  [ 1.4 -0.3  4.5 -0.5 -1.4  0.1 -0.1 -0.1  0.2 -0.8 -2.1 -0.3 -0.3 -0.4  6.6  2.2 -0.2 -0.5  1.   1.4 -1.  -0.1  1.4 -0.2 -1.   0.7 -0.2 -0.   0.6 -0.4 -0.6 -0.4 -0.2 -0.8 -0.2 -0.3 -0.7 -1.1 -3.5 -0.7 -0.6 -2.1 -0.5 -1.  -0.3 -0.5 -1.8 -0.2  9.3  2.6 -0.4 -0.  -0.1  4.1 -1.1 -0.6 -0.3 -0.   4.1  5.  -0.2 -0.4 -0.3  0.9 -0.3 -0.1 -0.  -0.1  0.8 -0.3 -0.3 -1.3 -0.   0.6 -4.3 -0.4 -0.5 -0.3 -0.1 -0.4 -3.7 -0.3  0.3 -0.1 -2.2 -1.6  4.2 -0.3 -0.  -0.5  0.4 -0.3 -0.3 -1.  -0.7 -0.2 -0.3 -3.4 -0.5 -0.2  1.6 -0.4 -1.1 -0.4  0.   0.8 -1.5 -0.5 -0.6 -0.2 -0.4 -0.  -0.1 -0.9  0.3 10.5 -0.7  1.4 -0.  -0.3 -0.4 -0.2 -0.2 -0.8 -0.3  8.1 -0.2 -0.4  3.7  7.7  2.7 -0.9  0.4 -0.6  6.1  4.2 -0.2 -0.3  0.7 -0.3  0.2 -0.5  0.1 -0.2 -0.2 -0.  -0.  -0.1 -1.1 -0.2  0.6 -0.1  3.9 -0.4 -0.3  0.1 -0.3  0.5 -0.9 -0.2 -0.3  2.4 -0.1 -0.  -0.4 -0.   0.7  0.2 -0.2 -0.2 -0.3 -0.1 -0.4  0.1 -0.4  3.1 -1.  -0.4  5.2 -0.1 -0.5 -0.2 -0.5 -2.  -0.1  0.2  2.2 -0.4 -0.1  0.9 -0.3 -0.1 -0.3 -1.2  4.8 -1.6 -0.5 -0.3 -0.1 -0.1 -0.1 -0.3 -0.2 -0.3 -0.3 -2.3 -0.2 -0.3  7.1 -0.4 -0.6  3.3 -1.  -1.9 -0.8 -0.6  4.8 -0.8 -0.4  1.  -0.2 -0.4 -0.1 -1.7  1.5  4.2 -1.2  1.4 -0.3  6.6  0.2 -0.6 -0.3  2.3 -0.6 -0.8  0.6 -0.5  4.3 -0.6 -0.  -0.2 -0.1 -0.  12.5  1.7 -0.2 -0.1 -1.1 -0.1  9.2  0.2 -2.2  0.1  4.  -1.5]
ty_50sample [[6 8 3 7 2 4 5 0 9 1]
 [0 8 7 4 1 6 9 5 2 3]
 [7 3 4 6 8 5 1 9 0 2]
 [2 1 9 8 5 6 4 3 0 7]
 [0 8 7 3 4 9 5 1 6 2]
 [9 7 1 5 3 2 6 4 8 0]
 [2 3 7 5 0 9 1 8 6 4]
 [7 5 0 3 4 2 9 1 8 6]
 [5 0 1 6 7 9 8 3 4 2]
 [2 3 7 4 5 0 6 1 8 9]]
tt_50sample [[6 8 3 7 2 4 5 0 9 1]
 [0 8 7 4 1 6 9 5 2 3]
 [7 3 4 6 8 5 1 9 0 2]
 [2 1 9 8 5 6 4 3 0 7]
 [8 0 7 3 4 9 5 1 6 2]
 [9 7 1 5 3 2 6 4 0 8]
 [2 3 7 5 0 9 8 1 6 4]
 [7 5 0 3 4 2 9 1 8 6]
 [5 0 1 6 9 7 8 3 4 2]
 [2 3 7 4 5 0 6 1 8 9]]
vm  [ 1.4 -0.5 -0.4 -3.8 -1.4  0.7 -0.2 -0.  -0.4  1.7  5.4 -0.2 -0.1 -0.2  9.5 -0.8  0.3 -0.2 -0.7 -1.5 -1.2 -0.1  1.6 -0.2 -0.7 -0.2 -0.2 -0.3 -0.7  3.6  4.5 -0.2  4.4 14.3 -0.1 -0.3  0.1 -0.6 -2.  -0.2  2.7  3.  -0.   2.1 -0.2  0.1  4.2  0.   3.   6.  -0.3 -0.1 -0.8  0.3 -0.5 -1.2 -1.2 -3.3  1.2 -3.9 -1.1 -0.6  1.5 -0.1  2.8 -0.5  0.1 -0.6 -0.4 -0.2 -0.2  1.  -1.1 -0.2 -4.3 -0.3  0.7  2.2 -0.4 -0.5  8.2 -0.4 -0.5 -0.1 -1.8  2.2  9.8 -0.  -0.1 -0.1 -1.  -0.2  0.1 -0.1 -0.3  0.1  0.7 -2.1 -0.1  0.4 -0.9  8.2 -0.5 -0.2  0.3 -0.6 -2.4  2.2  1.2 -1.7 -0.3 -0.3 -0.1 -1.1  6.  -1.6  0.7  0.8 -0.3 -0.6 -0.4  4.4 -0.6 -0.4 -0.3 11.7 -0.   2.4 -0.6 -1.7 -0.7 -0.1 -0.7  0.4 -1.4 13.4 -0.2 -0.2 -0.5 -0.6 -0.8 -0.7 -0.  -0.3 -0.1 -0.2 -0.   0.2 -2.  -0.   1.4 -0.2  3.  -0.6 -0.  -0.3 -0.9 -0.2 -0.9 -0.7 -0.5 -0.7 -0.1 -0.3  0.   2.5 -0.6 -0.8 -0.5 -0.2  0.  -0.2 -0.5 -0.5 -0.   3.8 -2.  -0.2  2.4 -0.2 -0.6  0.1  0.3 -1.  -0.  -1.1  1.  -1.2 -0.1 -1.1 -0.2 -0.2 -0.4 -0.7 10.8  1.  -1.1 -2.  -0.4  0.  -0.  -0.2  0.2 -0.2 -0.4 -1.5  0.2 -0.1  3.2 -0.2 -0.3 -0.9  1.9 -2.2  2.7 -0.1 -1.5 -1.1 -0.3 -1.3 -0.  -0.2 -0.8 -1.4  3.2 -1.  -1.4 -0.5 -1.5  1.9 -0.3  3.5 -0.5  1.9 -0.6  2.  -0.3 -1.6 -0.1 11.5  0.   2.8 -0.2 -0.5 -1.2 -0.4 -0.7 -0.7 -0.7  1.6 -2.4  0.2 -1.1  0.  -0.8  9.1]
vy_50sample [[4 7 0 6 9 2 8 5 3 3]
 [2 9 3 0 4 6 1 1 8 5]
 [7 6 1 8 2 2 5 3 9 0]
 [2 7 0 5 9 3 8 6 4 1]
 [4 8 5 1 0 9 6 7 2 3]
 [1 8 3 0 5 6 7 9 4 2]
 [5 6 4 3 0 0 2 9 7 1]
 [4 7 7 0 1 5 2 8 6 9]
 [1 5 2 6 3 3 7 4 0 8]
 [2 7 5 6 9 1 3 8 4 4]]
vt_50sample [[4 7 0 6 9 2 8 5 3 1]
 [2 9 3 0 4 6 1 7 8 5]
 [7 6 1 8 4 2 5 3 9 0]
 [2 7 0 5 9 3 8 6 4 1]
 [4 8 5 1 0 9 6 2 7 3]
 [1 8 3 0 5 6 7 9 4 2]
 [5 6 4 3 0 8 2 9 7 1]
 [4 7 3 0 1 5 2 8 6 9]
 [1 5 2 6 9 3 7 4 0 8]
 [2 7 5 6 1 9 3 8 0 4]]
Epoch 41710: Training cost= 0.2553, Training acc= 0.8544, Validation cost= 0.2571, Validation acc= 0.8545
Epoch 41720: Training cost= 0.2500, Training acc= 0.8544, Validation cost= 0.2491, Validation acc= 0.8545
Epoch 41730: Training cost= 0.2118, Training acc= 0.8545, Validation cost= 0.2660, Validation acc= 0.8545
Epoch 41740: Training cost= 0.2872, Training acc= 0.8545, Validation cost= 0.2826, Validation acc= 0.8545
Epoch 41750: Training cost= 0.2632, Training acc= 0.8545, Validation cost= 0.2849, Validation acc= 0.8545
Epoch 41760: Training cost= 0.2454, Training acc= 0.8545, Validation cost= 0.2907, Validation acc= 0.8545
Epoch 41770: Training cost= 0.2455, Training acc= 0.8545, Validation cost= 0.2442, Validation acc= 0.8546
Epoch 41780: Training cost= 0.2038, Training acc= 0.8545, Validation cost= 0.1950, Validation acc= 0.8546
Epoch 41790: Training cost= 0.2527, Training acc= 0.8545, Validation cost= 0.2393, Validation acc= 0.8546
Epoch 41800: Training cost= 0.2532, Training acc= 0.8545, Validation cost= 0.2509, Validation acc= 0.8546
tm  [ 0.4 -0.4 -3.3 -5.8 -1.  -0.  -0.3  0.  -0.2 -0.6  7.7 -0.3 -0.  -0.3  5.1  1.6 -0.5 -0.4 -0.7  0.6 -1.7 -0.2 -0.9 -0.  -1.2  1.2 -0.5 -0.3 -0.3 -1.4  4.9 -0.5  1.   3.6  0.3 -0.3  0.2 -0.  -3.8 -0.3  0.1 -3.3 -1.1  1.7 -0.2 -0.3 -1.8 -0.5  2.4 -3.1 -0.5 -0.  -0.3 11.2 -1.1 -0.6 -0.5 -3.6  5.8 -3.1  2.9 -0.7 -0.3 -0.1  0.9 -0.4 -0.   0.7  0.4 -0.3  0.  -0.5  0.1 -0.4 -5.4  0.3 -0.4 -0.5  0.1 -0.4 -1.1 -0.2 -0.  -0.  -1.  -3.   7.4 -0.3  0.  -0.4  0.7 -0.1 -0.1 -0.3 -0.5 -0.3 -0.5 -3.3  0.1 -0.6  2.9 -1.4 -0.9 -0.3 -0.1 -0.2 -3.2  3.2  1.2  1.4 -0.3 -0.2 -0.  -1.   3.5  2.   1.1  0.2 -0.2 -0.2 -0.2 -1.2  0.3  1.3 -0.4  6.4 -0.2 -2.4  4.5 12.6  1.  -0.4  0.6 -0.6  7.6 10.8  0.4 -0.1 -0.1 -0.8 -0.4 -0.3 -0.3 -0.2  0.1 -0.  -0.  -0.  -0.8 -0.2  3.9 -0.2  0.5 -0.1 -0.1 -0.2 -0.2 -0.5 -0.7 -0.2 -0.5 -0.1 -0.  -0.  -0.2 -0.5  0.2  1.1 -0.2 -0.4 -0.1 -0.1 -0.2 -0.  -0.4  2.9 -1.4 -0.5  5.4 -0.1  1.4 -0.6 -0.2 -2.1 -0.1  0.6  0.7 -0.5 -0.2  3.7 -0.2 -0.1 -0.3 -1.6 -0.7 -1.7 -1.  -0.7 -0.1  0.  -0.4 -0.4 -0.7 -0.5 -0.3 -3.9  0.3  0.   3.7 -0.6 -0.4 -0.2 -0.9 -0.5  0.1  0.5 -0.9 -1.4 -0.3  1.3 -0.  -0.2 -0.6 -1.3 -0.5 -0.5 -0.6 -0.1  2.6  2.9 -0.5  1.  -0.4  1.8 -0.2  5.   1.6 -1.6  1.7  0.6 -0.2 -0.   0.3 -0.2  5.1  3.1  0.5 -0.4 -1.4 -0.3  2.2 -0.  -2.1 -0.2  2.7 -3.1]
ty_50sample [[4 3 6 2 0 7 1 8 5 9]
 [3 0 5 4 1 6 2 7 9 8]
 [2 5 8 9 1 6 3 0 4 7]
 [9 2 3 8 1 6 5 4 0 7]
 [2 5 7 0 6 3 4 9 8 1]
 [2 0 3 8 9 5 7 4 6 1]
 [5 5 8 9 3 0 6 1 4 2]
 [2 6 4 7 1 8 0 3 5 9]
 [2 7 1 6 0 8 4 3 5 9]
 [5 3 0 2 8 1 9 4 7 6]]
tt_50sample [[4 3 6 2 0 7 1 8 5 9]
 [3 0 5 4 1 6 2 7 9 8]
 [2 5 8 9 1 6 3 0 4 7]
 [2 9 3 8 1 6 5 4 0 7]
 [2 5 7 0 6 3 4 9 8 1]
 [2 0 3 8 9 5 7 4 6 1]
 [7 5 8 9 3 0 6 1 4 2]
 [2 6 4 7 1 8 0 3 5 9]
 [2 7 1 6 0 8 4 3 5 9]
 [5 3 0 2 8 1 9 4 7 6]]
vm  [-0.7 -0.8  2.4 -1.1 -2.2 -0.4  1.4 -0.2 -1.4 -0.3  6.  -0.8  0.6  0.   5.5 -2.4 -0.2 -0.6  1.1 -0.8 -1.3 -0.4 -0.7 -0.5 -1.  -0.2 -0.6  0.7 -2.2 -0.4  4.5 -0.2 -1.5 17.3  0.4 -0.   3.4  2.6 15.2 -0.7 -0.5 -0.4  2.5  6.1 -0.3 -0.2  4.  -0.3 -0.9 -3.8 -0.5 -0.  -0.6  2.2  2.5 -0.7 -1.  -0.9 -0.6 -4.   0.3  1.8 -1.5 -0.5 -0.6 -0.8 -0.5 -0.6  3.2 -0.3 -0.4  8.2  1.6 -0.4 -1.  -1.4  0.8 -0.4 -0.1 -0.8 18.   0.2 -0.9 -0.5 -0.4 -0.6  3.9  0.1 -0.4 -0.4 -0.4  0.1 -0.3  2.9 -0.8 -0.3 -0.7 -1.3 -0.  -0.1  1.   5.   0.8 -0.2 -0.1 -0.7 -1.9 -0.1 -0.3 -2.1 -0.9 -0.4 -0.4  0.7  0.6 -4.4 -0.  -0.5 -0.1 -0.2  1.3  6.9 -0.5 -0.2 -0.2  7.2 -0.4  0.6 -0.1  4.6  1.  -0.2 -0.2  0.4 -7.6  0.4 -0.3 -0.4 -0.9 -0.5  2.3 -1.1  1.9  0.2 -0.2 -0.1  0.2  0.7 -1.6 -0.4  1.2 -0.3 -1.7  2.7 -0.1 -0.3  2.9 -0.4 -0.  -0.6 -0.4 -1.9 -0.1  0.2 -0.3 -0.3 -0.3 -0.6 -0.3 -0.2 -0.1 -0.4 -0.1  1.2  0.9  1.6  4.5 -0.9 -1.4 -0.4 -1.8 -0.5 -0.3 -1.5 -0.1  1.8 -0.9 -0.5  1.9 -0.2  0.1 -0.4 -0.5 -0.4  0.9  3.1 -0.9 -0.1 -0.1 -0.1 -0.6  0.6 -0.6  0.2  1.8 -2.2  0.5  1.3 -4.  -0.2 -0.7 -3.8 -0.8  1.8 -0.2  0.1 -2.6 -1.2 -0.3  2.5  0.7 -0.3 -0.3 -1.3 -1.8 -2.5 -0.8 -0.8 -1.9 -0.  -1.7  0.2  0.2 -1.5  6.1 -0.5  0.8 -0.5 -0.1 -0.1 -0.2 -0.4 -0.1 -0.1 -4.   1.   1.  -0.2 -0.5 -0.7 -5.1 -0.2  9.6 -0.4  4.4 -0.7]
vy_50sample [[0 7 4 3 5 1 2 9 8 6]
 [1 0 3 9 5 4 6 8 7 7]
 [6 3 0 4 1 8 5 2 7 9]
 [1 4 2 3 7 6 8 9 0 5]
 [1 0 8 3 6 9 7 4 2 5]
 [7 1 9 3 6 2 5 8 4 0]
 [7 5 0 4 8 2 9 3 6 1]
 [1 1 4 5 9 2 6 7 3 8]
 [8 2 5 4 1 3 6 9 0 0]
 [0 2 9 9 8 7 4 5 3 6]]
vt_50sample [[0 7 4 3 5 1 2 9 8 6]
 [1 0 3 9 5 4 6 8 2 7]
 [6 3 0 4 1 8 5 2 7 9]
 [1 4 2 3 7 6 8 9 0 5]
 [1 0 8 3 6 9 7 4 2 5]
 [7 1 9 3 6 2 5 8 4 0]
 [7 5 0 4 2 8 9 3 6 1]
 [1 0 4 5 9 2 6 7 3 8]
 [8 2 5 4 3 1 6 9 0 7]
 [0 2 1 9 8 7 4 5 3 6]]
Epoch 41810: Training cost= 0.2005, Training acc= 0.8545, Validation cost= 0.2156, Validation acc= 0.8546
Epoch 41820: Training cost= 0.2061, Training acc= 0.8546, Validation cost= 0.2355, Validation acc= 0.8546
Epoch 41830: Training cost= 0.2411, Training acc= 0.8546, Validation cost= 0.2479, Validation acc= 0.8546
Epoch 41840: Training cost= 0.3732, Training acc= 0.8546, Validation cost= 0.2862, Validation acc= 0.8546
Epoch 41850: Training cost= 0.3207, Training acc= 0.8546, Validation cost= 0.3635, Validation acc= 0.8546
Epoch 41860: Training cost= 0.2970, Training acc= 0.8546, Validation cost= 0.2303, Validation acc= 0.8547
Epoch 41870: Training cost= 0.3194, Training acc= 0.8546, Validation cost= 0.2960, Validation acc= 0.8547
Epoch 41880: Training cost= 0.2389, Training acc= 0.8546, Validation cost= 0.2410, Validation acc= 0.8547
Epoch 41890: Training cost= 0.2457, Training acc= 0.8546, Validation cost= 0.2020, Validation acc= 0.8547
Epoch 41900: Training cost= 0.2389, Training acc= 0.8546, Validation cost= 0.2164, Validation acc= 0.8547
tm  [-0.7  0.   9.5 17.3 -1.2 -0.4 -0.2  0.4  2.2 -0.7 -0.2 -0.6 -0.3 -0.  -0.3 -1.2  0.2 -0.5  0.7 -1.3 -0.8 -0.2 -0.8 -0.1 -0.5  4.  -0.3  1.1  0.9 -2.   0.5 -0.1 -1.  12.6 -0.3 -0.3 -0.9 -1.6 11.5  0.5 -0.7 -1.3 -0.8 -1.4  0.3 -0.1  8.4  0.3  2.4 -2.5 -0.2  0.   2.6 -3.4 -0.4  0.4 -0.3  5.   4.5  0.7 -1.6 -0.1 -0.3 -0.6  1.4  1.3 -0.1 -0.3  1.2 -0.1 -0.1 -1.5 -0.2  0.1  1.6  1.2 -0.2  2.8 -0.3 -0.2 20.4 -0.4 -0.   1.3 -0.6 -0.6 -1.1  0.3 -0.4 -0.6 -0.3 -0.4  0.8 -1.7 -0.7  0.3  1.7 -1.6 -1.2 -0.3  1.5  2.8 -0.1 -0.  -0.3  1.   2.5  0.9 -0.1 -1.7  2.7  0.4  0.1 -0.6  3.2  8.8 -0.5  1.6 -0.4  0.1 -0.8  6.3 -0.   2.2 -0.2 -0.4  0.8 14.5  5.2 -1.3  0.1 -0.7 -0.9 -0.2 -2.4  7.3 -0.1 -0.2 -0.2 -0.4  4.3 -0.4  1.9  0.6 -0.1  0.   0.5 -0.1 -1.4 -0.6 -1.1 -0.2  0.1  4.8 -0.1 -0.  -0.5 -0.4 -0.2  0.1 -1.  -0.3  0.7 -0.2 -0.1 -0.4  0.1  1.2 -0.2 -0.3 -0.3 -0.  -0.1 -0.7  0.7  2.2 -0.3  0.2 -1.   0.4 -0.4  0.6 -0.1 -1.9 -0.3  0.5  0.  -0.2  0.8  5.3 -0.2  0.1 -0.6 -0.9 11.9 -1.8  2.1 -1.  -0.1  0.  -0.3 -0.  -0.5  0.5 -0.4  5.8  0.2 -0.1 -0.9 -0.1 -0.3  5.2 -0.3  0.3 -0.6  0.2  4.6 -1.  -0.5 -1.   0.  -0.1  0.  -0.5 -0.1  0.4 -3.2 -0.3 -0.2  2.1 -0.5 -1.6 -0.4 -0.5 -0.9 -2.3 -0.9  2.   3.8 17.1 -0.   4.7 -0.  -0.5 -4.1 -3.2 -0.4 -1.  -1.5  0.1 -5.3 -0.1  7.6 -0.6 11.2  6. ]
ty_50sample [[9 7 3 6 5 1 0 4 8 2]
 [2 4 8 5 9 7 3 0 1 6]
 [6 4 1 3 7 0 8 9 5 2]
 [7 1 2 0 8 3 4 5 6 9]
 [4 9 0 5 3 6 2 7 8 1]
 [0 7 5 9 1 3 2 8 4 6]
 [2 0 4 1 8 6 9 5 7 3]
 [0 2 4 8 1 6 5 9 3 7]
 [3 6 2 1 8 0 5 7 9 4]
 [9 3 7 0 1 5 2 8 4 6]]
tt_50sample [[9 7 3 6 5 1 0 4 8 2]
 [2 4 8 5 7 9 3 0 1 6]
 [6 4 1 3 7 0 8 9 5 2]
 [7 1 2 0 8 3 4 5 6 9]
 [4 9 0 5 3 6 2 7 8 1]
 [0 7 5 9 1 3 2 8 4 6]
 [2 0 4 1 8 6 9 5 7 3]
 [0 2 4 8 1 6 5 9 3 7]
 [3 6 2 1 8 0 5 7 9 4]
 [9 3 7 0 1 2 5 8 4 6]]
vm  [-1.1 -0.2 -3.  -2.  -1.3 -0.3 -0.2 -0.2 -0.5 -0.9  6.9  0.4 -0.2 -0.1 -0.9  1.8 -0.1 -0.4 -0.1 -0.3 -1.3 -0.5 -0.6  0.1 -1.   0.3 -0.2 -0.2 -0.5 -0.8  6.1 -0.2 -0.3  9.  -0.3 -0.1  1.5  2.7 12.9 -0.2  0.5  2.8  0.7  5.6 -0.3 -0.3  3.5 -0.2 -1.  -2.4 -0.2 -0.2 -0.1 -1.1 -1.5  0.2 -0.4 -0.8 -0.1 -4.4  2.  -0.5 -0.3 -0.3  0.1 -0.8 -0.2 -0.2  1.4 -0.1 -0.2 -1.2  0.5 -0.1 -1.7 -0.4 -0.1 -0.3 -0.1 -0.2 19.4 -0.3 -0.1 -0.5 -0.2  3.2  3.  -0.1 -0.1 -0.6 -0.4 -0.1  0.2  1.3 -0.6 -0.3 -0.4 -1.4 -0.2 -0.5  2.7  0.6  0.3  0.  -0.  -0.3 -1.1  4.   0.7 -1.3 -0.6 -0.2  0.2 -0.4 -0.3  7.8  0.8 -0.4 -0.4 -0.1  0.5  4.1 -0.3  0.7 -0.2 -1.1 -0.1  5.9  2.8 -0.7 -0.5  0.1  0.1 -0.2 -2.4  4.1 -0.1 -0.2 -0.2 -1.   0.7 -0.4  0.9 -0.2 -0.2 -0.2 -0.2  0.3  4.  -0.2  1.4  0.1 -1.8 -0.  -0.2 -0.1 -0.2 -0.2  3.5  1.4 -0.  -1.5 -0.1 -0.2 -0.3 -0.2  0.4  0.9 -0.1 -0.3 -0.2 -0.  -0.1  0.1 -0.1 -0.7  0.4 -0.3 -1.1 -0.1 -1.2 -0.4 -0.  -1.4 -0.2 -0.1 -0.6 -0.3 -0.1  1.7 -0.2 -0.1 -0.  -1.3  0.1 -0.5  0.7  1.1 -0.3 -0.1 -0.4 -0.   0.5 -0.2 -0.1  0.2 -0.5 -0.1 -4.8 -0.1 -0.5  2.2 -1.   6.5  2.6 -0.4 -2.5 -0.8 -0.2 -0.1 -0.3 -0.  -0.8 -0.9 -1.  -0.3 -1.5 -0.4 -0.3 -0.4 -0.6 -0.3 -0.4 -1.9 -0.7  5.  -0.2 -0.3 -0.  -0.3 -0.2 -0.3  0.1 -0.2 -4.1 -1.7 -0.4 -0.1 -0.9 -0.1 -5.1 -0.4  7.6 -0.1  2.6  4.5]
vy_50sample [[4 1 5 9 3 7 2 0 6 8]
 [6 5 2 7 0 1 8 4 9 3]
 [2 5 6 8 0 4 7 9 1 3]
 [7 2 3 9 4 8 1 6 0 5]
 [2 6 4 5 3 0 9 7 8 1]
 [6 9 3 7 1 5 0 4 2 8]
 [3 8 9 7 2 5 0 6 4 1]
 [0 0 8 8 6 2 7 4 5 1]
 [3 8 6 2 9 0 1 7 5 4]
 [0 4 6 1 9 2 3 5 7 8]]
vt_50sample [[4 1 5 9 3 7 2 0 6 8]
 [6 5 2 7 0 1 8 4 9 3]
 [2 5 6 8 0 4 7 1 9 3]
 [7 2 3 9 4 8 1 6 0 5]
 [2 6 4 5 3 9 0 7 8 1]
 [6 9 3 1 7 5 0 4 2 8]
 [3 8 9 7 2 5 0 6 4 1]
 [0 3 8 9 6 2 7 4 5 1]
 [3 8 6 2 9 0 1 7 5 4]
 [0 4 6 1 9 2 3 5 7 8]]
Epoch 41910: Training cost= 0.2684, Training acc= 0.8546, Validation cost= 0.2323, Validation acc= 0.8547
Epoch 41920: Training cost= 0.2636, Training acc= 0.8547, Validation cost= 0.2961, Validation acc= 0.8547
Epoch 41930: Training cost= 0.2069, Training acc= 0.8547, Validation cost= 0.2835, Validation acc= 0.8547
Epoch 41940: Training cost= 0.2448, Training acc= 0.8547, Validation cost= 0.2298, Validation acc= 0.8547
Epoch 41950: Training cost= 0.2733, Training acc= 0.8547, Validation cost= 0.2418, Validation acc= 0.8547
Epoch 41960: Training cost= 0.2446, Training acc= 0.8547, Validation cost= 0.2631, Validation acc= 0.8548
Epoch 41970: Training cost= 0.2162, Training acc= 0.8547, Validation cost= 0.2444, Validation acc= 0.8548
Epoch 41980: Training cost= 0.2939, Training acc= 0.8547, Validation cost= 0.2042, Validation acc= 0.8548
Epoch 41990: Training cost= 0.2397, Training acc= 0.8547, Validation cost= 0.2570, Validation acc= 0.8548
Epoch 42000: Training cost= 0.2282, Training acc= 0.8548, Validation cost= 0.2396, Validation acc= 0.8548
tm  [-0.  -0.3 -0.3  6.1 -0.9 -0.3 -0.1 -0.3 -1.  -0.7  6.8  0.4 -0.3 -0.1 -1.1  5.5 -0.2 -0.1 -0.2 -0.5 -0.9  0.1  2.4  0.1 -1.3  0.6 -0.1 -0.3  1.8  5.6  1.8 -0.   1.5  1.8  0.1 -0.1  1.3 -0.5 -1.9 -0.3  1.5  5.4  3.3 -0.6 -0.3 -0.2  3.9 -0.8  3.5  3.8 -0.4 -0.3  1.3  2.4 -1.8  1.1 -0.3  3.4 -1.8 -0.2 -1.2 -0.4 -0.1 -0.5  2.6 -1.3 -0.2  2.1  0.  -0.3 -0.2 -2.  -0.4 -0.3 -1.7 -0.7  0.1 -0.7 -0.2 -0.2  9.7  1.  -0.3 -0.5 -1.5  4.9  4.1  0.2 -0.2 -0.3  1.1 -0.2 -0.2  1.3 -0.3 -0.3 -0.8 -1.3 -0.4 -0.1  2.   3.  -1.1 -0.1 -0.2 -0.3 -0.9  1.   0.8 -0.9 -0.2 -0.5 -0.2 -0.4 -1.7 11.   1.2 -1.1 -0.3  1.5 -0.1  1.4 -0.2 -0.2 -0.3 -1.4 -0.2  0.4 -1.2 -1.5 -0.2  0.7 -0.2  0.4 12.1 15.8  0.4 -0.1 -0.7 -1.2 -0.4 -0.3 -0.4 -0.1 -0.  -0.5 -0.2 -0.1  5.  -0.3 -0.7 -0.4  2.6  0.4 -0.1 -0.3 -0.1  0.4 -1.4 -0.5 -0.7 -0.1 -0.1 -0.1 -0.  -0.6 -0.5 -0.5 -0.1  0.5 -0.1 -0.   0.3 -0.3 -0.2 -1.3 -2.2 -0.   2.2 -0.1 -1.5 -0.3 -0.2 -1.6 -0.1 -0.3  0.9 -0.5 -0.1 -1.5 -0.2 -0.4 -0.3 -1.4  9.7  4.1 -0.   3.6 -0.1 -0.1  0.1 -0.2 -0.3 -0.2 -0.6  0.5 -0.1 -0.2 -3.5  0.1 -0.6  4.5 -0.7 -0.9 -0.4 -0.1  2.8 -0.6 -0.2  1.  -0.1 -0.2 -0.3 -0.9  3.   3.7 -0.6 -0.8  1.5  1.6  2.8 -0.1 -0.5 -1.1 -1.6 -0.2  0.1 -0.1 -0.  -1.6 -0.2 -0.6 -0.3 -0.1 -1.7 -2.1 -0.1 -0.2 -0.7  0.  -2.8 -0.3 -1.2 -0.  -0.7  7. ]
ty_50sample [[6 5 2 9 4 8 7 3 1 0]
 [5 6 3 7 8 0 2 1 4 9]
 [9 6 7 2 0 8 5 3 1 4]
 [8 2 9 3 7 5 1 4 6 0]
 [6 5 3 2 7 0 1 9 4 8]
 [2 6 6 4 1 3 8 9 9 5]
 [4 3 5 2 8 9 1 6 7 0]
 [4 1 7 5 0 2 9 6 3 8]
 [4 5 3 9 8 0 6 7 1 2]
 [7 3 8 2 6 0 1 4 9 5]]
tt_50sample [[6 5 2 9 4 7 8 3 1 0]
 [5 6 3 7 8 0 2 1 4 9]
 [9 6 7 2 8 0 5 3 1 4]
 [8 2 9 3 7 5 1 4 6 0]
 [6 5 3 2 7 0 9 1 4 8]
 [2 7 6 4 3 1 8 0 9 5]
 [4 3 5 2 8 9 1 6 7 0]
 [4 1 7 5 0 2 9 6 3 8]
 [5 4 3 9 8 0 6 7 1 2]
 [7 3 8 2 6 0 1 4 9 5]]
vm  [ 1.3 -0.1 -1.6 -4.6 -1.8 -0.1 -0.2 -0.2 -0.5 -0.4  5.  -0.3 -0.4  0.3  7.1 -0.6 -0.4 -0.4 -0.1  1.1 -1.4 -0.3 -0.8 -0.1 -1.1  0.3 -0.5  0.6 -1.3 -3.2  2.5 -0.2 -0.5  1.7 -0.2 -0.1  0.3  5.   2.5 -0.5 -0.5 -2.6 -1.   2.5 -0.4 -0.2 -2.  -0.4  5.9 -2.7 -0.5 -0.1 -0.5 10.1  0.8 -0.8 -0.7 -1.3  6.5 -1.3  0.1 -0.3 -0.2  0.2 -0.2 -0.2 -0.1 -0.2  0.5 -0.3 -0.2  3.9 -0.4 -0.2 -5.2 -0.4 -0.7 -0.5 -0.2 -0.3 -2.8 -0.2 -0.1 -0.5 -1.7 -2.6  7.1 -0.1 -0.  -0.5 -0.3 -0.2  0.1 -0.4 -0.6  0.3 -0.5 -3.6 -0.1 -0.2  1.5 -1.9 -0.8 -0.5 -0.1 -0.5 -2.7  1.3  1.2  0.1 -0.2 -0.1 -0.1 -0.7  4.6 -1.9  0.5  1.8 -0.  -0.1 -0.3 -0.3 -0.2 -0.5 -0.5  8.8 -0.1 -2.1  7.8 14.1  0.1 -0.8  0.3 -0.6 -3.  -3.  -0.2 -0.1  0.4 -0.4 -0.2 -0.8 -0.3 -0.3 -0.  -0.1 -0.4  0.1  0.9 -0.2  3.1 -0.   2.9 -0.2 -0.2 -0.2  0.5 -0.   2.8 -0.1 -0.6 -1.8 -0.1 -0.1 -0.2  0.2  0.5 -0.2 -0.1 -0.3 -0.2 -0.2 -0.2 -0.  -0.2  0.5  1.5 -0.7 -0.1 -0.3 -1.1 -0.3 -0.4 -1.7 -0.2 -0.1  0.2 -0.5  0.4  8.6 -0.3 -0.  -0.2 -1.3  3.1 -2.4 -1.2 -0.9 -0.  -0.  -0.5 -0.2 -0.6 -0.5 -0.3 -3.7 -0.1  0.   0.4 -0.1 -0.3 -1.7 -0.9 -1.8  0.2 -0.4 -1.9 -1.3 -0.6  0.2 -0.1 -0.3 -0.2 -1.3 -2.6 -0.9 -0.9  0.6  1.4  4.  -0.9  0.3 -0.5  0.4  1.8  2.4 -0.1 -1.1  1.8 -2.7 -0.1 -1.  -0.  -0.1  9.8  5.2 -0.2 -0.1 -1.  -0.3  7.  -0.1  2.  -0.2  4.6 -3.6]
vy_50sample [[3 0 4 2 7 8 8 9 9 6]
 [5 4 7 0 1 6 9 3 8 2]
 [4 1 3 8 0 6 9 9 5 2]
 [0 5 6 1 3 9 7 2 8 4]
 [1 3 5 7 8 6 4 0 2 9]
 [9 1 0 8 6 5 2 4 3 7]
 [2 9 6 1 1 3 5 7 7 4]
 [8 9 2 3 7 5 1 6 4 0]
 [4 7 0 2 6 1 8 3 5 9]
 [5 6 9 3 0 4 7 2 1 8]]
vt_50sample [[3 0 4 2 5 8 7 9 6 1]
 [5 4 7 0 1 6 9 3 8 2]
 [4 1 3 8 0 6 9 7 5 2]
 [0 5 6 1 3 9 7 2 8 4]
 [1 3 5 7 8 6 4 0 2 9]
 [9 1 0 8 6 5 2 4 3 7]
 [2 9 6 1 8 3 5 7 0 4]
 [8 9 2 3 7 5 6 1 4 0]
 [4 7 0 2 6 1 8 3 5 9]
 [5 6 9 3 0 4 7 2 1 8]]
Epoch 42010: Training cost= 0.2673, Training acc= 0.8548, Validation cost= 0.2964, Validation acc= 0.8548
Epoch 42020: Training cost= 0.2762, Training acc= 0.8548, Validation cost= 0.2691, Validation acc= 0.8548
Epoch 42030: Training cost= 0.2076, Training acc= 0.8548, Validation cost= 0.2151, Validation acc= 0.8548
Epoch 42040: Training cost= 0.2282, Training acc= 0.8548, Validation cost= 0.2293, Validation acc= 0.8549
Epoch 42050: Training cost= 0.2431, Training acc= 0.8548, Validation cost= 0.2775, Validation acc= 0.8549
Epoch 42060: Training cost= 0.2673, Training acc= 0.8548, Validation cost= 0.2544, Validation acc= 0.8549
Epoch 42070: Training cost= 0.2108, Training acc= 0.8548, Validation cost= 0.2487, Validation acc= 0.8549
Epoch 42080: Training cost= 0.2292, Training acc= 0.8548, Validation cost= 0.1826, Validation acc= 0.8549
Epoch 42090: Training cost= 0.2362, Training acc= 0.8549, Validation cost= 0.2394, Validation acc= 0.8549
Epoch 42100: Training cost= 0.2508, Training acc= 0.8549, Validation cost= 0.2446, Validation acc= 0.8549
tm  [-0.7  0.2 -1.4  5.7 -1.3  0.3 -0.8 -0.1  0.2 -1.2  7.5 -0.6  0.2  0.3 -1.2  7.1 -0.4 -0.3 -0.6 -0.5 -1.2 -0.2 -0.8  0.2 -1.   1.5 -0.1 -0.1  1.7 -2.4  2.2 -0.4 -0.1  0.3  0.2 -0.4  0.4  3.7  6.3 -0.2  1.1 -2.5 -1.   0.4 -0.2  0.7  2.  -0.6  3.6 -1.8  0.5 -0.   1.1 -0.1 -1.1  1.1 -0.2 -0.9  5.4 -0.4 -0.3 -0.8  0.2  2.6  1.6  1.7 -0.1 -0.2 -0.7 -0.5  0.4 -2.2 -0.7  3.4 -0.9 -0.8 -0.6 -0.9 -0.2  0.7 10.  -0.  -0.  -0.5 -0.3 -1.8  0.8 -0.2 -0.2 -0.6  2.7 -0.  -0.1 -1.8 -0.1  0.6 -0.6 -2.3  1.   0.5  3.5 -2.  -0.8 -0.  -0.   1.1  0.7  2.3  1.9 -1.1 -0.3 -0.1 -0.2 -0.8  0.6 15.1 -1.2 -0.4 -0.1 -0.4 -0.5  4.3  0.2  2.4 -0.2 -1.7 -0.2  3.1  6.4 -0.2  0.5 -0.5  0.4 -0.6  5.   4.4 -0.  -0.1  2.5 -0.4 -0.3 -0.3 -1.3 -0.4 -0.1 -0.2 -0.5 -0.2  2.2  0.7 -0.9 -0.   0.4 -0.7 -0.3 -0.1 -0.6 -0.1  1.9  0.7 -0.8 -0.5  0.3  0.4  0.2  0.4  0.5  2.1  0.4  0.1 -0.  -0.1  0.4 -0.1 -0.3  0.3 -0.3  0.2 -0.3 -0.2 -0.3 -0.4 -0.4 -2.3  0.  -0.5  1.1 -0.8 -0.3  6.2  0.2  0.9  0.1 -1.6  5.1 -2.5  2.   0.1 -0.3  0.7 -0.5 -0.1 -0.4 -1.1  0.   0.5 -0.4 -0.3  0.6  0.5 -0.1  7.5 -1.4  0.9 -1.2 -0.8 -0.4 -1.1 -1.1 -0.  -0.1  0.3 -0.3 -1.4 -0.9  4.4 -0.6  3.3  0.9  2.9 -0.3 -1.7 -0.2  1.2 -0.5  3.3 -0.3  1.5  5.3  8.7  0.   2.4  0.1 -0.1 -1.6 -1.5 -0.6  1.7 -1.5  0.1 -2.6  0.1  4.  -0.   2.3  2.8]
ty_50sample [[9 3 2 4 1 1 5 7 7 0]
 [7 6 4 5 8 9 0 2 3 3]
 [1 8 4 2 7 7 6 5 9 3]
 [1 9 0 7 5 6 8 4 3 2]
 [8 2 7 3 4 5 9 1 0 6]
 [0 8 4 7 5 1 2 3 6 9]
 [3 8 5 5 1 4 7 7 2 9]
 [5 3 8 9 6 4 0 1 2 7]
 [1 8 7 4 5 6 0 2 9 3]
 [1 4 0 3 7 8 5 2 9 6]]
tt_50sample [[9 3 2 4 1 6 5 8 7 0]
 [7 6 4 8 5 0 9 2 1 3]
 [1 8 4 2 7 0 6 5 9 3]
 [1 9 0 7 5 6 8 4 3 2]
 [8 2 7 3 4 5 9 1 0 6]
 [8 0 4 5 7 1 2 3 6 9]
 [3 8 5 0 1 4 7 6 2 9]
 [5 3 8 9 6 4 0 1 2 7]
 [1 8 7 4 5 6 0 9 2 3]
 [1 4 0 3 7 5 8 2 9 6]]
vm  [-1.2 -0.2 -1.6 -1.1 -1.6 -0.1 -0.1 -0.1  0.7 -0.5 -1.4 -0.2 -0.5 -0.1 -0.  -0.5 -0.2 -0.3 -0.4 -0.1 -1.1 -0.  -0.7 -0.2 -1.4  1.3 -0.3  0.3  0.7 -3.2  1.9 -0.1 -0.1 -0.3 -0.2 -0.4 -0.4 -1.1 -1.2 -0.2  0.4 -0.7 -0.8 -0.   0.2 -0.4 -0.7 -0.1 -1.9 -2.6 -0.4 -0.  -0.1 -0.5 -1.5 -0.1 -0.5  3.8  6.5 -0.5  7.9 -0.6 -0.3 -0.6  2.9 -0.6 -0.1  1.   0.8 -0.4 -0.3 -1.4 -0.2 -0.6 -4.3  0.1 -0.  -0.  -0.3 -0.4  0.1  0.1 -0.1  0.3  0.9 -0.3 -1.7  0.4 -0.2 -0.5 -0.1 -0.2 -0.2 -0.6 -1.2 -0.2 -0.2 -3.  -0.4 -0.   2.5 -2.1  1.1 -0.  -0.2 -0.1 -2.7  1.1 -0.5 -0.   0.7 -0.1 -0.3 -1.   2.5  7.5 -0.   1.1 -0.1  0.9 -0.6 -0.3 -0.2 -0.1 -0.1  0.1 -0.2  4.1  8.7 10.2 -0.2 -0.5 -0.2 -0.2  7.1  6.1  0.1 -0.1 -0.2 -0.5  2.1  0.1  1.8 -0.1 -0.2  0.1 -0.3 -0.   5.8 -0.1  0.5 -0.2 -1.2  1.7 -0.2 -0.1 -0.3  1.1 -0.3 -0.3 -0.5 -0.5 -0.  -0.1 -0.1 -0.4 -0.3  1.  -0.3 -0.3  0.1 -0.2 -0.  -0.  -0.3 -1.2 -1.2 -0.6  2.3 -0.2 -1.5 -0.4 -0.2 -2.5 -0.1 -0.5 -1.  -0.3 -0.1  8.8 -0.2 -0.3 -0.3 -1.4 -3.  -2.7 -0.7 -0.6 -0.1 -0.2 -0.4 -0.2 -0.5 -0.2  0.1 -2.6 -0.1  0.  -2.4 -0.2 -0.7  2.6 -0.6  7.3 -0.4  2.  -0.  -1.  -0.2 -0.  -0.1 -0.2 -0.  -1.3 -0.7  2.3 -2.5 -0.3  0.2 -0.1 -0.8  1.5 -0.1 -0.9 -0.9  2.3  0.2 -1.1  1.7 -3.1 -0.2 -1.1 -0.2 -0.2  2.   0.3 -0.4 -0.7 -1.4 -0.2 -0.4 -0.3 -0.6 -0.3  8.1 -2.4]
vy_50sample [[1 3 5 6 4 8 9 0 7 2]
 [6 3 9 2 0 7 1 8 5 4]
 [1 7 5 8 2 4 6 9 0 3]
 [9 8 2 1 5 0 4 7 3 6]
 [5 1 0 4 2 8 3 6 7 9]
 [2 7 8 4 0 3 1 9 5 6]
 [1 2 3 7 4 5 0 0 9 8]
 [5 8 6 2 4 3 7 1 0 9]
 [9 8 7 3 2 4 0 1 6 5]
 [2 4 6 9 5 7 0 8 3 1]]
vt_50sample [[1 3 5 6 4 8 9 0 7 2]
 [6 3 9 2 0 7 1 8 5 4]
 [1 7 5 8 2 4 6 9 0 3]
 [9 8 2 1 5 0 4 7 3 6]
 [5 1 0 4 2 8 3 6 7 9]
 [7 2 8 4 0 3 1 9 5 6]
 [1 2 3 7 4 5 0 6 9 8]
 [5 8 6 2 4 3 7 1 0 9]
 [9 8 7 3 2 4 0 1 6 5]
 [2 6 4 9 5 7 0 8 3 1]]
Epoch 42110: Training cost= 0.2637, Training acc= 0.8549, Validation cost= 0.3255, Validation acc= 0.8549
Epoch 42120: Training cost= 0.2659, Training acc= 0.8549, Validation cost= 0.2731, Validation acc= 0.8550
Epoch 42130: Training cost= 0.2873, Training acc= 0.8549, Validation cost= 0.2699, Validation acc= 0.8550
Epoch 42140: Training cost= 0.2700, Training acc= 0.8549, Validation cost= 0.2795, Validation acc= 0.8550
Epoch 42150: Training cost= 0.2378, Training acc= 0.8549, Validation cost= 0.2678, Validation acc= 0.8550
Epoch 42160: Training cost= 0.2368, Training acc= 0.8549, Validation cost= 0.2478, Validation acc= 0.8550
Epoch 42170: Training cost= 0.2471, Training acc= 0.8550, Validation cost= 0.2174, Validation acc= 0.8550
Epoch 42180: Training cost= 0.2478, Training acc= 0.8550, Validation cost= 0.2333, Validation acc= 0.8550
Epoch 42190: Training cost= 0.3033, Training acc= 0.8550, Validation cost= 0.2770, Validation acc= 0.8550
Epoch 42200: Training cost= 0.2520, Training acc= 0.8550, Validation cost= 0.2885, Validation acc= 0.8550
tm  [-0.3 -0.3 10.5 26.4 -0.9 -0.4 -0.2 -0.  -1.1  0.6  8.9 -0.5 -0.2 -0.  -0.8  6.8 -0.2 -0.5 -0.7 -2.5 -0.6 -0.3 -1.  -0.3 -0.2 -0.9 -0.8  1.  -0.1  0.5 -1.7 -0.5 -0.9  5.7 -0.  -0.4  1.7  7.9 23.3 -0.3 -0.  -1.3  0.5 -0.4 -0.2 -0.2 13.   0.  -0.3 -2.  -0.4 -0.1 -0.2  1.8 -2.1 -0.   0.3  8.1 -2.   5.9 -2.5 -0.5 -1.3 -0.8 -0.3 -0.5 -0.3  0.7 -0.2 -0.8  0.  -2.4 -0.5 -0.6  4.1 -0.8  0.3  0.6 -0.2 -0.4 13.1  0.6 -0.6  0.7 -1.1 -1.  -0.9 -0.3 -0.4 -0.7 -0.1 -0.1  2.   2.1 -0.5  1.3 -0.7  2.7  0.4 -0.1 -0.3 -0.8 -0.2 -0.1 -0.4 -0.  -0.5 -0.4  0.9 -2.6  3.3 -0.1 -0.1 -0.  -2.2 10.4 -0.8 -0.9 -0.4 -0.4 -0.1  8.8 -0.4 -0.4 -0.3 -1.   0.6  0.3 -1.5 -0.  -0.   0.1 -0.1  0.3 -5.2 -3.4 -0.5 -0.2 -0.3 -0.9 -0.8 -0.  -0.3 -0.2 -0.  -0.  -0.4 -0.3 -0.3 -0.4 -2.5 -0.   0.9  0.8 -0.2  0.1 -0.3 -0.4  0.4 -0.5 -0.5 -1.7 -0.2 -0.2  0.2  2.5 -0.6 -0.1 -0.3 -0.3 -0.1 -0.3  0.1 -0.3  0.3  0.3  1.4 -0.  -2.5 -0.3 -1.8 -0.3  0.1 -1.4 -0.1  1.  -0.6 -0.6 -0.  -0.1 -0.1  0.5 -0.6 -1.1 15.9  5.5  1.5  6.1 -0.  -0.3 -0.   0.  -0.5 -0.4  0.9  4.5 -0.   0.  -0.6  0.5 -0.7  1.8 -0.7 -0.5 -0.2  0.9  1.4 -0.7 -0.6  0.3 -0.  -0.2  0.2 -0.5 -1.8  4.8  0.8 -0.1  0.3 -0.  -1.2  0.5 -0.1 -0.6 -2.  -2.1 -0.5  1.1 -0.5  9.8 -0.3  2.9 -0.1 -0.2 -2.7 -2.4 -0.4 -0.1 -0.3 -0.6 -3.4  0.1 13.8 -0.8  0.1  1.6]
ty_50sample [[9 2 3 7 5 8 1 6 4 4]
 [4 0 5 8 7 3 9 2 1 6]
 [9 0 6 1 3 8 7 5 4 2]
 [4 6 8 0 0 2 7 5 1 3]
 [9 0 4 2 8 3 5 6 1 7]
 [6 8 5 9 7 4 1 0 2 3]
 [2 0 4 5 8 1 9 3 7 6]
 [6 0 7 1 3 8 4 2 9 5]
 [6 4 5 9 0 3 8 2 1 1]
 [0 8 1 6 3 9 5 7 2 4]]
tt_50sample [[9 2 3 7 5 8 1 6 0 4]
 [0 4 5 8 7 3 9 2 1 6]
 [9 0 6 1 3 8 7 5 4 2]
 [4 6 8 0 9 2 7 5 1 3]
 [9 0 4 2 8 3 5 6 1 7]
 [6 8 5 9 7 4 1 0 2 3]
 [2 0 4 5 8 1 9 3 7 6]
 [6 0 7 1 8 3 4 9 2 5]
 [6 4 5 9 0 3 8 2 7 1]
 [0 8 1 6 9 3 5 7 2 4]]
vm  [-0.9  0.9 -0.5  7.9 -0.7 -0.2 -0.6  0.4 -1.4 -0.3 -2.9  0.1 -0.3  0.4 -1.4  6.3  0.9  0.2  0.2 -1.2 -1.1 -0.4 -1.  -0.1 -0.9 -0.6 -0.3 -0.3 -0.2  8.4 -1.5 -0.1 -0.1 -4.9  0.1 -0.2  1.5 -0.3 -1.4 -0.7  0.7  6.5  2.7 -1.2 -0.6 -0.2  3.5 -0.2  0.5 16.8 -0.1 -0.  -0.1 -0.3 -1.6  1.2 -0.5  5.3 -2.9  6.7 -0.5 -0.7 -0.3 -0.2 -1.  -0.6 -0.4 -0.2 -0.9 -0.5  0.  -1.5 -1.   2.1 -2.1 -1.3 -0.4 -1.3 -0.3 -0.1 -2.3 -0.1 -0.  -1.8 -1.   7.5 -0.4 -0.4 -0.4 -0.5  0.5 -0.2 -0.   2.1  0.2  0.1 -0.4 -1.2 -0.2  1.1  0.6  2.1 -0.1 -0.  -0.1 -0.4 -0.3 -0.5 -0.4 -2.4 -0.4 -0.2 -0.2 -0.4 -2.  12.  -0.7 -1.1 -0.2 -0.4 -0.1  6.6 -0.4 -0.1 -0.  -1.7  0.7  3.2 -2.7 -3.6 -0.2  1.1  0.8  1.  13.2 -0.2 -0.1 -0.2  1.7 -0.2 -0.5 -0.2 -0.6 -0.7 -0.2 -0.2 -0.9 -0.3  5.8 -0.3 -0.8  0.5  0.9 -0.5 -0.2 -0.2 -0.6 -0.5 -0.7  0.1 -0.6 -0.2 -0.5 -0.   0.5  2.4 -0.1 -0.1 -0.2 -0.3  0.2 -0.6 -0.2 -0.4 -0.4 -0.8 -1.4 -0.1  1.8 -0.5 -2.   0.9  0.6 -0.5  0.3 -0.1  0.2 -0.7 -0.3 -2.   0.6  1.5 -0.3 -1.2  5.4  9.4  0.7  5.  -0.4 -0.1 -0.7 -0.3  0.9 -0.7  0.3  1.8 -0.4 -0.1  3.5  0.9  3.4  4.4 -0.7  1.5  0.9 -0.3  4.4 -0.5 -0.7  0.5  0.  -0.2 -0.2 -0.7  4.6  4.3 -0.6  1.7 -0.6 -0.4  1.9 -0.3 -0.4  1.7 -1.2  0.5 -0.7  0.9 -0.1 -1.1  0.1 -0.6 -0.4 -0.1  7.6 -1.5 -0.7  0.  -0.8 -0.6  6.1 -0.  -0.6 -0.3 -1.8 14.6]
vy_50sample [[8 6 5 9 2 1 4 7 0 0]
 [9 8 6 4 7 2 0 5 1 3]
 [2 1 8 5 7 6 0 4 9 3]
 [3 5 9 2 0 8 1 4 7 6]
 [7 6 8 5 9 3 2 4 1 0]
 [7 5 1 3 9 4 8 0 6 2]
 [2 3 0 5 4 7 8 1 6 9]
 [2 6 7 4 3 8 8 5 1 9]
 [4 4 9 5 6 3 8 1 2 7]
 [2 3 3 7 7 6 6 5 1 4]]
vt_50sample [[8 6 5 9 2 1 4 7 0 3]
 [9 8 6 4 7 2 0 5 1 3]
 [2 1 8 5 7 6 0 4 9 3]
 [3 5 9 2 0 8 1 4 7 6]
 [7 6 8 5 9 3 2 4 1 0]
 [7 5 1 3 9 4 8 0 6 2]
 [2 3 0 5 4 8 7 6 1 9]
 [2 6 7 4 3 8 0 5 1 9]
 [4 0 9 5 6 3 8 1 2 7]
 [2 8 3 7 9 6 0 5 1 4]]
Epoch 42210: Training cost= 0.3290, Training acc= 0.8550, Validation cost= 0.2330, Validation acc= 0.8551
Epoch 42220: Training cost= 0.2373, Training acc= 0.8550, Validation cost= 0.2659, Validation acc= 0.8551
Epoch 42230: Training cost= 0.2862, Training acc= 0.8550, Validation cost= 0.2630, Validation acc= 0.8551
Epoch 42240: Training cost= 0.2622, Training acc= 0.8550, Validation cost= 0.2333, Validation acc= 0.8551
Epoch 42250: Training cost= 0.2817, Training acc= 0.8550, Validation cost= 0.2956, Validation acc= 0.8551
Epoch 42260: Training cost= 0.2768, Training acc= 0.8550, Validation cost= 0.2815, Validation acc= 0.8551
Epoch 42270: Training cost= 0.2474, Training acc= 0.8550, Validation cost= 0.2458, Validation acc= 0.8551
Epoch 42280: Training cost= 0.2365, Training acc= 0.8551, Validation cost= 0.2958, Validation acc= 0.8551
Epoch 42290: Training cost= 0.2349, Training acc= 0.8551, Validation cost= 0.2371, Validation acc= 0.8551
Epoch 42300: Training cost= 0.2340, Training acc= 0.8551, Validation cost= 0.2564, Validation acc= 0.8551
tm  [ 1.8 -0.3 -3.5 -1.2 -0.6 -0.2 -0.7 -0.2 -0.1  0.6 -6.1 -0.1 -0.1 -0.1 -1.7 -0.4 -0.6 -0.1 -0.3 -0.7 -1.2 -0.   0.1 -0.2 -1.1 -0.2 -0.4 -0.1 -0.3 -2.6 -0.7 -0.2  0.6 -7.2 -0.1 -0.3 -0.3  3.2  8.3 -0.7  1.6  3.1 -0.7  2.8 -0.6 -0.2  2.7 -0.3  3.4 11.1 -0.4 -0.2 -1.  -0.9 -1.1  1.4 -0.8  2.1  4.7  3.8 -0.6 -0.7 -0.2 -0.2 -0.6 -1.1 -0.   0.7  0.1 -0.3 -0.1 -0.2 -0.4 -0.1 -3.7 -0.6 -0.6 -0.8 -0.1 -0.4 -4.7 -0.2  0.  -0.4 -1.7  3.8  4.5 -0.   0.   0.1  0.2 -0.1 -0.5 -0.9 -0.5 -0.2 -0.3 -2.7 -0.1 -0.7  0.1 -1.3 -0.6 -0.3  0.1 -1.2 -1.6 -0.6 -1.8 -0.8 -0.2  0.6 -0.  -0.9  3.5  1.3 -0.1  0.9 -0.4 -0.5 -0.4  1.5  0.  -0.7 -0.1 -2.  -0.3  4.8  6.1 -0.  -0.   0.2  0.9 -0.4  3.6 -7.2 -0.2 -0.   1.2  0.5 -0.  -0.5 -0.9 -0.4 -0.  -0.4 -0.8 -0.1  8.3 -0.2 -0.  -0.1  4.2 -0.5 -0.1 -0.3 -0.3 -1.1  2.8  1.3 -0.2 -2.  -0.3 -0.2 -0.1  0.7  0.1 -0.2 -0.4 -0.1 -0.1 -0.2 -0.2 -0.2 -0.4 -1.8 -0.7 -0.2 -0.8 -0.4 -2.  -0.8 -0.  -1.2 -0.1 -0.2  1.8 -0.  -0.4  7.5  0.2 -0.4 -0.3 -1.   7.1 -2.  -0.6 -0.9 -0.4  0.2 -0.3 -0.1 -0.1 -0.6 -0.5 -1.6 -0.4 -0.1  3.5 -0.1 -0.7 -0.1 -0.8 -1.5 -0.1 -0.4 -1.4 -0.9 -0.4 -0.1 -0.2 -0.2 -0.2 -1.7 -1.4  0.7 -1.4  1.4 -0.8  2.1 -0.6  1.4 -0.5  0.9 -1.   3.5  1.2 -0.7  1.7 -2.9 -0.1 -1.  -0.2 -0.  14.7 -0.9  0.5 -0.4 -1.3  0.8 11.9 -0.1  5.2 -0.   2.5  2.7]
ty_50sample [[8 5 4 0 9 3 2 1 6 7]
 [4 9 5 3 2 7 6 0 8 1]
 [6 2 0 7 3 5 8 9 1 4]
 [8 3 1 2 5 0 4 6 9 7]
 [8 3 7 1 6 2 0 4 4 5]
 [8 5 4 2 9 3 1 6 7 0]
 [4 5 9 6 1 7 2 8 0 3]
 [4 3 8 7 1 6 2 0 9 5]
 [3 7 4 5 1 8 9 2 0 0]
 [4 2 0 9 1 5 3 6 8 7]]
tt_50sample [[8 5 4 0 9 3 2 1 6 7]
 [4 9 5 3 2 7 6 0 8 1]
 [6 2 0 7 3 5 8 9 1 4]
 [8 3 1 2 5 0 4 6 9 7]
 [8 3 7 1 6 2 0 9 4 5]
 [8 5 4 2 9 1 3 6 7 0]
 [4 5 9 6 1 7 2 8 0 3]
 [4 3 8 7 1 6 2 0 9 5]
 [3 7 4 5 8 1 9 2 0 6]
 [4 2 0 9 1 5 3 6 8 7]]
vm  [-0.3  1.2 -1.8 13.3 -0.5 -0.4  0.3 -0.2 -0.6 -0.2 12.4 -0.1 -0.4 -0.3 -4.2  0.8 -0.4 -0.  -0.1 -1.  -1.1 -0.7 -0.4 -0.1 -0.6  1.  -0.6 -0.2 -1.2 -3.   1.8 -0.2 -0.2 -0.4 -0.  -0.3  2.6  5.8 11.9 -0.2 -0.1  4.3  1.2 -0.3 -0.5 -0.3  7.5 -0.4 -0.  -2.9 -0.3 -0.  -0.3  3.3 -1.   3.7 -0.1  8.7 -0.7 -1.2 -1.3 -0.5 -0.4 -0.5  0.4 -1.3 -0.4  0.7 -0.6 -0.3 -0.3  2.5  0.8 -0.4 -0.9 -1.1 -0.2 -0.7 -0.3 -0.2 24.  -0.3 -0.3 -1.  -1.1  3.  -0.4 -0.2 -0.3 -0.3 -0.1 -0.1  0.1  2.4 -0.7 -0.6 -0.5 -0.7 -0.4 -0.5  0.6 -1.9 -0.2 -0.1 -0.   1.2 -1.   0.7 -0.1 -2.1  1.6 -0.3 -0.3  0.2 -0.1 -1.2  1.5 -0.6 -0.2  1.9 -0.4  6.7  0.   1.8 -0.2 -5.  -0.1 -0.3  2.7 -0.9 -0.2 -0.1  0.3  1.9  9.   7.8 -0.2 -0.1 -0.4 -1.  -0.9 -0.3 -0.8 -0.1 -0.2 -0.2 -0.3  0.   9.2 -0.3 -1.1  0.4 -0.6 -0.5 -0.2 -0.4 -0.   1.2  1.  -0.7 -0.6 -1.3 -0.1 -0.1 -0.2  0.7  0.1 -0.3 -0.1 -0.2 -0.1 -0.2 -0.1  0.7 -0.5 -2.6 -0.5 -0.5 -1.  -0.1 -2.1 -0.1  0.2 -1.1 -0.1 -0.2 -0.3  1.1  0.3  8.2 -0.1 -0.2 -0.5 -1.1  9.3 -0.4  0.5  0.6 -0.6 -0.  -0.5  0.  -0.3 -0.1 -0.1  2.8 -0.2  0.1 -6.4 -0.1 -0.5 -1.1 -0.7  0.4  2.8 -0.4  1.1 -1.  -0.6  0.6 -0.  -0.2  0.3 -0.6 -0.7 -1.3  1.9 -0.  -0.4 -0.1 -0.8 -0.5 -0.3 -2.6 -0.2  2.1 -0.  -0.1 -0.6 -0.9 -0.4 -0.4 -0.1 -0.2 -5.3 -2.1 -0.5 -0.4 -1.   0.2 -6.4 -0.3  7.4 -0.4 -0.4  5.2]
vy_50sample [[2 5 9 0 3 1 6 4 8 7]
 [3 6 0 2 7 9 9 5 4 1]
 [3 3 2 7 9 4 6 1 5 8]
 [2 4 9 7 3 6 5 5 8 1]
 [4 2 0 1 3 3 7 8 6 5]
 [0 4 1 2 3 7 5 8 6 9]
 [9 2 7 5 3 8 0 4 6 1]
 [4 8 3 9 5 7 0 2 1 6]
 [1 7 6 2 4 9 5 8 0 3]
 [2 0 1 1 7 3 4 6 9 8]]
vt_50sample [[2 5 9 0 3 1 6 4 8 7]
 [3 6 0 2 7 9 8 5 4 1]
 [0 3 2 7 9 4 6 1 5 8]
 [2 4 7 9 0 3 6 5 8 1]
 [4 2 0 1 9 3 7 8 6 5]
 [0 4 1 2 3 7 5 8 6 9]
 [9 7 2 5 3 8 0 4 6 1]
 [4 8 3 9 5 7 0 2 1 6]
 [1 7 6 2 4 9 5 8 0 3]
 [2 0 1 5 7 3 4 6 9 8]]
Epoch 42310: Training cost= 0.2319, Training acc= 0.8551, Validation cost= 0.2844, Validation acc= 0.8552
Epoch 42320: Training cost= 0.2748, Training acc= 0.8551, Validation cost= 0.2370, Validation acc= 0.8552
Epoch 42330: Training cost= 0.2307, Training acc= 0.8551, Validation cost= 0.2519, Validation acc= 0.8552
Epoch 42340: Training cost= 0.2789, Training acc= 0.8551, Validation cost= 0.2527, Validation acc= 0.8552
Epoch 42350: Training cost= 0.2376, Training acc= 0.8551, Validation cost= 0.2387, Validation acc= 0.8552
Epoch 42360: Training cost= 0.2206, Training acc= 0.8552, Validation cost= 0.2415, Validation acc= 0.8552
Epoch 42370: Training cost= 0.2230, Training acc= 0.8552, Validation cost= 0.1841, Validation acc= 0.8552
Epoch 42380: Training cost= 0.2740, Training acc= 0.8552, Validation cost= 0.2897, Validation acc= 0.8552
Epoch 42390: Training cost= 0.2870, Training acc= 0.8552, Validation cost= 0.2277, Validation acc= 0.8553
Epoch 42400: Training cost= 0.2330, Training acc= 0.8552, Validation cost= 0.2246, Validation acc= 0.8553
tm  [-0.9 -1.   9.4  3.  -2.1 -0.1  0.6 -0.1 -0.2  4.3 -1.2 -0.5 -0.3  0.3 12.5 -3.2 -0.6 -0.4 -0.7  0.  -0.5 -0.3  2.  -0.4 -1.   3.1 -0.6  0.4 -1.6 -1.9 -0.  -0.1 -0.7 13.9 -0.1 -0.5 -0.3 -0.9 -0.5 -0.3 -0.3  6.2 -0.9 -0.4 -0.3 -0.5 -0.8 -0.5 -0.6  4.6 -0.4 -0.1  0.1 -0.3  0.8 -1.5 -0.6  5.5  5.4  2.4  2.3 -0.6  0.2 -0.4  3.3 -1.  -0.2  0.2  1.1 -0.6 -0.5  5.5 -0.4 -0.9 -5.2 -1.1 -0.2 -0.3 -0.1 -0.2  0.7  1.3 -0.2 -0.4 -0.9  6.1 -0.9 -0.3  0.4 -0.   0.7 -0.1 -0.2 -1.  -0.6 -0.1 -0.9 -3.1 -0.  -0.2 -1.9  7.8 -0.3 -0.2 -0.2 -0.1 -2.4 -0.1 -0.3 -0.3  2.3 -0.2 -0.1 -0.3  8.6 -4.3 -1.   3.2  0.1 -0.1 -0.5 -0.5 -0.7  0.9 -0.2 15.   0.5  4.1  4.6  0.4  1.  -0.1 -0.5  2.6 -4.2  4.2 -0.2 -0.  -0.5 -0.9  4.  -1.3  0.7 -0.2 -0.2 -0.3 -0.4 -0.  -0.6 -0.4 -0.3 -0.1 -0.4  2.9  0.   0.1 -0.4 -0.3 -0.5 -0.9 -0.4 -1.3  0.2 -0.3  0.7 -0.3 -0.8 -0.3 -0.6 -0.  -0.1 -0.1  0.2 -0.1 -0.1  0.6 -0.7 -0.2  0.9 -0.3 -1.4 -0.6  0.5 -2.1 -0.2 -0.2 -0.6 -0.4  1.7  4.9 -0.2 -0.7 -0.2 -0.9 -0.2 -1.6 -1.3 -2.2  0.3 -0.1  0.6 -0.2 -0.3 -0.5 -0.1 -1.8  0.   0.4 -3.  -0.3 -0.2 -2.2 -0.6  1.8 -1.2  0.4  1.8 -1.2 -0.5  1.  -0.1 -0.4  1.  -1.4  3.8 -2.3 -2.9 -0.2 -1.2 -0.2 -0.8  2.8 -0.3 -1.3  0.3 -2.3  1.9 -1.5  1.9 -4.2 -0.1 -1.4 -0.3 -0.   1.5 -0.2 -0.5 -0.5 -0.8 -0.1 -0.6 -0.2 -0.2 -0.3  2.6  2.7]
ty_50sample [[0 7 5 1 6 8 9 4 3 2]
 [4 2 7 3 6 5 1 1 9 8]
 [8 3 9 4 1 7 6 2 0 5]
 [2 6 7 0 9 3 8 1 5 4]
 [7 4 2 6 8 1 3 5 0 9]
 [7 1 3 5 6 9 8 8 2 4]
 [6 8 7 4 5 3 9 9 2 0]
 [2 7 3 3 5 9 6 0 8 4]
 [9 9 3 2 7 0 6 1 8 5]
 [3 2 8 9 4 4 7 1 6 6]]
tt_50sample [[0 7 5 1 6 8 9 4 3 2]
 [4 2 7 3 6 5 1 0 9 8]
 [8 3 9 4 1 7 6 2 0 5]
 [2 6 7 0 9 3 8 1 5 4]
 [7 4 2 6 8 1 3 5 0 9]
 [7 1 3 5 6 9 8 0 2 4]
 [6 8 7 4 5 3 1 9 2 0]
 [2 7 3 1 5 9 6 0 8 4]
 [4 9 3 2 7 0 6 1 8 5]
 [3 2 8 9 4 0 1 7 5 6]]
vm  [-0.1  1.2 -0.7 -4.3 -1.8  0.1  0.2  0.6 -1.1 -1.1  7.8 -0.3 -0.  -0.3  9.8  0.9 -0.2 -0.3 -0.1  4.1 -1.1 -0.4 -1.1  1.4 -1.6  3.1 -0.4  1.2 -1.2 -1.5  2.4 -0.  -0.4  3.9 -0.1 -0.1  2.2  0.3 -5.5 -0.5 -0.9 -1.9 -0.1 -1.3 -0.1 -0.3 -3.9 -0.6  4.3 -3.7 -0.2  0.6 -0.3 14.3 -0.  -1.  -0.4  2.9  1.6 -1.   6.5 -0.3  0.   0.2 -0.5  0.5 -0.3 -0.6 -0.5 -0.5 -0.2  2.8 -0.2 -0.3 -6.  -0.2 -0.4 -0.6 -0.4 -0.2 -2.8 -0.1 -0.2 -0.4 -0.7 -1.4  2.  -0.2 -0.  -0.2  0.3  0.5 -0.3  1.2 -0.3 -0.3  0.1 -3.8  0.8 -0.3  3.8 -2.1 -1.  -0.1  0.6 -0.4 -3.3  1.1  0.9  5.7  0.3  0.9  0.5 -0.5  1.5 -0.9 -0.8 -0.6  0.3 -0.3 -0.5 -2.1 -0.2  1.9 -0.3 11.8 -0.3 -3.1  1.5 16.9  2.3 -0.5 -0.1 -0.5 10.7 12.4 -0.3 -0.   0.9 -0.1 -0.4 -1.2 -0.7 -0.2 -0.  -0.  -0.4 -0.1  4.4  0.   2.9 -0.2 -0.5 -0.2 -0.3 -0.2 -0.5 -0.2 -1.3  0.2 -0.6  1.2 -0.1 -0.   0.  -0.   0.7 -0.  -0.  -0.1 -0.1  0.1 -0.2 -0.2 -0.1 -0.4 -0.5 -0.5  7.2 -0.1 -0.9 -0.4 -0.1 -2.3 -0.3 -0.2  0.3 -0.8 -0.3  4.6 -0.1  0.3  0.5 -1.5 -2.5 -0.6 -1.  -0.1 -0.5  0.3 -0.5 -0.2 -0.4 -0.5 -0.4 -4.4 -0.1 -0.1 -2.   0.   0.1 -1.2 -1.  -0.1 -0.3 -0.6  4.7 -1.2 -0.9 -0.3 -0.2  0.3 -0.1 -0.9 -0.1 -0.9 -0.4  1.8  1.5  2.  -0.3 -0.1 -0.5 -0.8  1.6  1.2  0.4 -1.3  1.6 -5.2 -0.1 -1.6 -0.2 -0.   9.8  6.4 -0.5 -0.1 -1.3 -0.2  7.2  0.4 -3.3 -0.   4.3 -4.5]
vy_50sample [[3 6 0 2 5 4 1 7 8 9]
 [7 2 5 6 3 1 4 4 8 0]
 [0 3 5 4 6 9 1 2 7 8]
 [1 8 2 0 9 4 6 5 7 3]
 [3 3 5 0 4 2 6 1 7 9]
 [6 4 3 5 2 1 7 0 8 9]
 [7 1 4 6 8 9 0 2 5 3]
 [6 3 7 4 1 2 9 5 8 8]
 [7 3 8 2 9 1 6 4 0 5]
 [1 5 3 7 0 6 4 8 2 9]]
vt_50sample [[3 6 0 2 5 4 1 7 8 9]
 [7 2 5 6 3 1 4 9 8 0]
 [0 3 5 4 6 9 1 2 7 8]
 [1 8 2 0 9 4 6 5 7 3]
 [3 8 5 0 4 2 6 1 7 9]
 [4 6 3 5 2 1 0 7 8 9]
 [7 1 4 6 8 9 0 2 5 3]
 [6 3 7 4 1 2 9 5 0 8]
 [7 3 8 2 9 1 6 4 0 5]
 [1 5 3 7 0 6 4 8 2 9]]
Epoch 42410: Training cost= 0.2174, Training acc= 0.8552, Validation cost= 0.2255, Validation acc= 0.8553
Epoch 42420: Training cost= 0.2527, Training acc= 0.8552, Validation cost= 0.2243, Validation acc= 0.8553
Epoch 42430: Training cost= 0.2545, Training acc= 0.8552, Validation cost= 0.3124, Validation acc= 0.8553
Epoch 42440: Training cost= 0.2571, Training acc= 0.8552, Validation cost= 0.3068, Validation acc= 0.8553
Epoch 42450: Training cost= 0.2879, Training acc= 0.8553, Validation cost= 0.2762, Validation acc= 0.8553
Epoch 42460: Training cost= 0.2019, Training acc= 0.8553, Validation cost= 0.2622, Validation acc= 0.8553
Epoch 42470: Training cost= 0.2604, Training acc= 0.8553, Validation cost= 0.1719, Validation acc= 0.8553
Epoch 42480: Training cost= 0.2106, Training acc= 0.8553, Validation cost= 0.2642, Validation acc= 0.8554
Epoch 42490: Training cost= 0.3182, Training acc= 0.8553, Validation cost= 0.2804, Validation acc= 0.8554
Epoch 42500: Training cost= 0.2754, Training acc= 0.8553, Validation cost= 0.2514, Validation acc= 0.8554
tm  [-1.1 -0.4 -4.2 -0.9 -0.8 -0.2 -0.  -0.2  0.3 -0.5 -3.1 -0.2 -0.4 -0.3 -2.9 -1.4 -0.3 -0.3 -0.3 -2.  -1.1 -0.3 -0.8 -0.1 -0.7 -0.1 -0.2  0.3 -0.7 -3.3  3.3 -0.2 -0.3 -2.7 -0.2 -0.2  0.9 -0.8  9.8 -0.2 -0.4 -3.3 -1.7  1.2 -0.1 -0.3  8.8  0.4 -2.1 -2.2 -0.6 -0.2 -0.6 -2.9 -0.8  3.  -0.6 -2.5  7.5 -1.5  3.6 -0.3 -0.6 -0.3  1.2 -0.  -0.1 -0.2  1.4 -0.1 -0.3 -0.3 -0.4 -0.7 -0.8  1.1 -0.1  1.2 -0.1 -0.4  7.7 -0.3 -0.2  0.1  3.  -2.8 -0.5 -0.2 -0.  -0.1 -1.  -0.2 -0.6 -0.6 -1.  -0.3  0.7 -1.7 -0.3 -0.4  2.9 -2.9  1.9 -0.4 -0.2 -0.4 -1.7  1.  -1.  -1.9  0.6 -0.  -0.2 -0.4  5.8 -0.2 -0.3  1.  -0.2 -0.3 -0.4  7.6 -0.  -0.1 -0.5 -3.4 -0.3 11.2  6.1  3.9  0.6 -0.6 -0.2 -0.6  6.7 -0.7 -0.1 -0.1  0.4 -0.4  0.6 -0.1  0.8  0.8 -0.2  0.  -0.3 -0.1  2.1 -0.3  0.6 -0.2 -1.2  0.2 -0.3 -0.2 -0.4 -0.1 -0.5 -0.  -0.4 -0.5 -0.2 -0.2  0.2  0.2 -0.3  2.4 -0.2 -0.1 -0.1 -0.1 -0.2 -0.2 -0.3  0.2 -0.5 -0.8 -1.  -0.2  0.4 -0.4 -0.3 -1.6 -0.  -0.1 -0.8 -0.6 -0.1  8.9 -0.2 -0.3 -0.8 -1.1 -1.  -1.8 -0.4 -1.3 -0.5 -0.1 -0.4  0.  -0.2 -0.4 -0.5 -1.5 -0.1 -0.   6.3 -0.  -0.8 -0.6 -0.5  4.4  0.5 -0.1 -1.4 -1.  -0.1 -0.5 -0.2 -0.2 -0.2 -1.4 -1.2 -0.4 -2.1 -0.4 -0.2  0.7 -1.5  0.2 -0.3  1.5 -0.1  5.3 -0.4 -0.7 -0.  17.5 -0.   5.  -0.2  0.3 -1.2 -1.2  0.5 -1.  -0.9 -0.1 -2.2 -0.1  5.5 -0.1  8.2 -0.5]
ty_50sample [[1 3 4 0 9 8 6 5 7 2]
 [3 1 5 0 9 6 8 4 2 7]
 [8 5 2 3 7 1 4 9 6 0]
 [3 8 7 4 1 0 9 6 5 2]
 [4 1 9 8 7 2 6 3 0 5]
 [9 8 4 3 1 2 0 6 5 7]
 [5 4 1 0 2 3 9 8 6 7]
 [8 1 7 3 6 2 0 0 5 4]
 [7 3 0 5 8 1 9 2 6 4]
 [3 5 2 4 9 8 1 0 6 7]]
tt_50sample [[1 3 4 0 9 8 6 5 7 2]
 [3 1 5 0 9 6 8 4 2 7]
 [8 5 2 3 7 1 4 9 6 0]
 [3 8 7 4 1 0 9 6 5 2]
 [4 1 9 8 7 2 6 3 0 5]
 [9 8 4 3 1 2 0 6 5 7]
 [5 4 1 0 2 3 9 8 6 7]
 [8 1 7 3 6 2 9 0 5 4]
 [7 3 0 8 5 1 9 2 6 4]
 [3 5 2 4 9 8 1 0 6 7]]
vm  [-0.  -0.3 -1.7  7.9 -0.8  0.3  0.  -0.1 -0.2 -0.2  4.4 -0.4 -0.1 -0.3 -2.2  3.  -0.1 -0.4 -0.5 -0.8 -0.8 -0.2  0.5 -0.1 -1.1  2.  -0.  -0.4 -0.4 -0.8 -0.3 -0.5 -0.8 -3.5 -0.1 -0.1  0.9  4.7  9.9 -0.4  1.2  6.9  0.1  1.  -0.1 -0.   5.9 -0.3  3.5 11.5 -0.5 -0.1  1.2  2.6 -0.8  2.8 -0.1  3.3  0.1  3.1 -1.3 -0.1 -0.2 -0.3 -0.4 -0.1  0.   0.5 -0.3 -0.  -0.2 -0.9 -0.3 -0.3 -0.5 -0.4 -0.2 -0.2 -0.1 -0.1  1.7  1.5 -0.   1.3 -1.1  8.8  4.1 -0.1 -0.1  0.1  0.  -0.1 -0.1 -0.8 -0.5 -0.  -0.2 -1.4 -0.1 -0.1 -0.2  2.8 -0.7 -0.1 -0.1 -0.3 -0.6 -0.2  0.7 -1.4 -0.1  0.1 -0.1 -0.5 -0.2  3.9 -0.7 -0.6 -0.2 -0.2 -0.3  4.9 -0.2 -0.7 -0.2 -2.8 -0.  -0.   0.7 -2.5  1.4 -0.5 -0.1 -0.3  5.5 -2.4 -0.1 -0.1  0.2 -0.3 -0.5 -0.6 -0.8 -0.  -0.2 -0.3 -0.1 -0.3  6.8 -0.2 -1.  -0.1  3.3  0.4 -0.3  0.1 -0.5 -0.4 -0.3 -0.4  0.4 -0.5 -0.2 -0.2 -0.  -0.2 -0.6 -0.3 -0.1  0.  -0.1 -0.2 -0.1 -0.4 -0.1 -1.2 -0.4 -0.1 -0.8  0.2 -1.6 -0.4 -0.4 -2.  -0.  -0.3  1.3 -0.4 -0.2  1.9 -0.  -0.1 -0.3 -0.7 10.4 -0.3  0.6 -0.  -0.  -0.2 -0.1 -0.  -0.5 -0.3 -0.3 -0.  -0.   0.2 -0.8  0.2 -0.4  1.5 -0.6 -0.6 -1.3  0.4 -0.4 -0.8 -0.5 -0.1 -0.1 -0.2  0.1 -0.9  4.5  3.   0.  -0.2 -0.3  3.  -1.  -0.7 -0.3 -0.3 -0.4  2.5  0.9  0.   2.8 -0.1  0.  -0.1 -0.1 -0.1  0.8 -2.2  1.  -0.3 -1.2 -0.9 -0.7 -0.1  6.  -0.2 -1.8 11. ]
vy_50sample [[5 2 9 8 4 0 6 1 7 3]
 [2 9 9 5 8 3 6 1 4 0]
 [1 9 5 2 0 8 4 3 7 6]
 [2 6 9 4 4 3 0 1 1 8]
 [9 3 5 8 7 1 6 0 4 2]
 [0 2 4 8 7 3 6 1 5 9]
 [8 4 5 2 0 9 3 7 1 6]
 [9 3 1 4 2 6 0 7 5 8]
 [0 4 6 9 7 3 1 2 8 8]
 [0 1 8 2 7 4 4 5 6 3]]
vt_50sample [[5 2 9 8 4 6 0 7 1 3]
 [2 7 9 5 8 3 6 1 4 0]
 [1 9 5 2 0 4 3 8 7 6]
 [2 6 9 4 5 3 7 0 1 8]
 [9 3 5 8 7 1 6 0 4 2]
 [0 2 4 8 7 3 6 1 5 9]
 [8 4 5 2 0 9 3 7 1 6]
 [9 3 1 4 2 6 7 0 5 8]
 [0 4 6 9 7 3 1 2 5 8]
 [0 1 2 8 7 4 9 5 6 3]]
Epoch 42510: Training cost= 0.2664, Training acc= 0.8553, Validation cost= 0.2415, Validation acc= 0.8554
Epoch 42520: Training cost= 0.2239, Training acc= 0.8553, Validation cost= 0.2700, Validation acc= 0.8554
Epoch 42530: Training cost= 0.2220, Training acc= 0.8553, Validation cost= 0.2703, Validation acc= 0.8554
Epoch 42540: Training cost= 0.2070, Training acc= 0.8554, Validation cost= 0.2477, Validation acc= 0.8554
Epoch 42550: Training cost= 0.2354, Training acc= 0.8554, Validation cost= 0.2603, Validation acc= 0.8554
Epoch 42560: Training cost= 0.2216, Training acc= 0.8554, Validation cost= 0.2116, Validation acc= 0.8554
Epoch 42570: Training cost= 0.3673, Training acc= 0.8554, Validation cost= 0.2673, Validation acc= 0.8554
Epoch 42580: Training cost= 0.2812, Training acc= 0.8554, Validation cost= 0.2467, Validation acc= 0.8555
Epoch 42590: Training cost= 0.2420, Training acc= 0.8554, Validation cost= 0.2790, Validation acc= 0.8555
Epoch 42600: Training cost= 0.3181, Training acc= 0.8554, Validation cost= 0.2139, Validation acc= 0.8555
tm  [-1.  -0.2  3.4  9.  -1.3 -0.   0.  -0.1 -0.3 -0.3 -5.2 -0.2  0.3 -0.4 -0.3 -0.5 -0.1  0.3 -0.   0.6 -1.2 -0.3  0.8 -0.1 -0.6  2.4 -0.4 -0.1 -0.8 -2.7 -2.4 -0.2 -0.6 -6.  -0.2 -0.3  0.6 -0.4 -1.1 -0.6 -0.7 -2.6 -0.4 -1.4  0.2 -0.2 -1.2 -0.4  0.4  2.  -0.4 -0.  -0.2  1.5 -0.7 -0.2 -0.4  6.   2.4  8.2  3.2 -0.  -0.1  0.4 -1.2 -0.6 -0.2 -0.6 -0.  -0.3 -0.1  0.2  0.9  1.7 -4.2 -0.5 -0.1 -0.5 -0.1 -0.1 -5.2 -0.3 -0.2 -0.2 -0.9 -2.4 -1.9 -0.1 -0.3 -0.4 -0.1 -0.2  0.7 -0.4 -0.5 -0.3 -0.2 -3.  -0.  -0.4  1.  -2.8 -0.2  0.4 -0.5 -0.2 -1.7 -1.2 -1.5 -0.7  0.6  0.1 -0.  -0.2  2.1 -0.1 -0.7  0.6 -0.1 -0.3 -0.2  0.7 -0.2  0.1  0.2 -0.4  0.4  1.5  2.3 11.1  0.8 -0.2 -0.2 -0.3  9.3 -3.1 -0.1 -0.2  1.7  1.7  1.  -1.1 -0.2 -0.2 -0.1 -0.  -0.1  0.4  3.5 -0.1 -1.1 -0.2  1.9  0.7 -0.1 -0.1 -0.7 -1.1 -0.2 -0.1 -0.1 -0.3  0.8 -0.2 -0.3 -0.3 -0.3  0.5  0.  -0.  -0.2 -0.2 -0.  -0.2  0.4 -0.2 -0.4  0.6  2.   0.3 -0.3 -0.4 -0.4 -2.  -0.3 -0.  -0.2 -0.2 -0.   7.2 -0.2 -0.4 -0.  -0.7 -0.5 -0.8 -0.3 -0.6 -0.2 -0.1 -0.1 -0.2 -0.3 -0.2 -0.1 -1.6 -0.1 -0.4  8.9 -0.1 -0.7 -0.3 -0.9  3.5 -0.4 -0.5  6.4 -0.6 -0.7 -0.3  0.1 -0.2 -1.1 -1.4 -0.7  0.3 -1.7  0.9 -0.8  0.1 -0.4 -0.  -0.5  1.9 -0.5 -0.5 -0.6 -0.6  1.1 -0.4 -0.2 -0.3  0.1 -0.3 15.7 -0.1 -0.2  0.4 -0.8 -0.3 13.4 -0.1 -0.8 -0.2  7.2 -2.5]
ty_50sample [[8 3 0 6 1 5 9 2 7 4]
 [2 0 4 1 5 9 6 8 3 7]
 [6 2 3 4 0 8 7 9 5 1]
 [8 6 7 5 2 3 9 0 1 1]
 [3 2 5 4 1 8 7 6 9 0]
 [0 8 9 1 7 2 5 3 6 4]
 [4 5 2 0 7 1 8 6 3 9]
 [3 8 9 7 0 1 4 6 2 5]
 [4 0 1 8 6 2 5 7 3 9]
 [9 4 5 2 3 1 6 0 8 7]]
tt_50sample [[8 3 0 6 1 5 9 2 7 4]
 [2 0 4 1 5 9 6 8 3 7]
 [6 2 3 4 0 8 7 9 5 1]
 [8 6 7 5 2 3 9 0 4 1]
 [3 2 5 4 8 1 7 9 6 0]
 [0 8 9 1 2 7 5 3 6 4]
 [4 5 2 0 7 1 8 6 3 9]
 [3 8 9 7 0 1 4 6 2 5]
 [4 1 0 8 6 2 5 7 9 3]
 [4 9 5 2 3 1 6 0 7 8]]
vm  [-0.4 -0.6 -0.3 -3.  -1.4 -0.2 -0.  -0.2  0.8 -0.2 -0.8 -0.3 -0.2 -0.3  7.7  2.5 -0.3 -0.4 -0.2  1.1 -1.1 -0.   1.9 -0.  -1.3  1.2 -0.2 -0.2  0.8  1.2  2.5 -0.3  0.1  4.2 -0.1 -0.3 -0.6 -1.1 -3.8 -0.6 -0.2  1.8 -0.9 -0.2 -0.2  0.  -1.2 -0.3  2.1  8.9 -0.4 -0.2 -0.1  3.3 -1.3 -0.8 -0.3 -1.9  6.1 -0.9  1.7 -0.3 -0.2  0.2 -0.2 -0.4  0.5  0.6  2.1 -0.2 -0.2 -1.9 -0.1 -0.3 -4.   0.5 -0.3 -0.1 -0.  -0.1 -2.   0.6 -0.2  1.5 -0.8  4.5  4.  -0.  -0.2 -0.3 -0.1  0.1 -0.1 -1.7 -0.6 -0.2 -0.2 -3.5 -0.5 -0.2  0.4  7.3 -0.5 -0.  -0.3 -0.1 -1.8  0.9 -0.1  1.6 -0.5 -0.2 -0.1 -1.   2.4  9.9 -0.4  1.3 -0.1 -0.1 -0.3 -0.6 -0.  -0.2  0.   8.8 -0.1 -0.1  4.2  0.5  0.1 -0.2  0.6 -0.8  5.5  9.5 -0.2 -0.1 -0.6 -0.4  0.8 -0.7  0.2 -0.1  0.1  0.1 -0.1  0.4 -1.4 -0.2  2.4 -0.1  1.5 -0.1  0.5  0.3 -0.4 -0.4 -1.  -0.2  1.7  2.2 -0.1 -0.1 -0.1 -0.9 -0.6  1.9 -0.2 -0.1 -0.2 -0.1 -0.  -0.2 -0.3  2.5 -1.  -0.1  4.9 -0.1  0.9 -0.4 -0.6 -2.2 -0.  -0.4  0.2 -0.5 -0.  -0.3  0.7 -0.2 -0.5 -0.9 -0.2 -1.7 -0.6 -0.9 -0.  -0.2  0.1 -0.1 -0.3 -0.7  0.3 -2.6  0.3 -0.   4.3 -0.3 -0.2  4.2 -1.1  1.8 -1.1  0.9  0.8 -0.7  1.1 -0.  -0.2 -0.2 -0.2 -1.5  6.9  3.8 -1.1  0.   1.4  2.9 -0.  -0.3 -0.1  1.5 -0.8  0.6  2.  -0.7  4.4 -0.1 -0.1 -0.2 -0.1  0.3  7.7  0.   0.1 -0.1 -1.4 -0.9  4.9 -0.2 -2.1 -0.  -0.9  2.4]
vy_50sample [[6 4 7 8 1 2 5 0 9 3]
 [3 1 5 6 7 4 8 9 9 0]
 [1 3 5 8 9 2 4 0 7 6]
 [0 2 2 1 8 5 9 4 7 7]
 [9 4 0 5 8 1 3 7 6 2]
 [6 2 7 4 5 1 8 9 3 0]
 [7 9 1 6 5 0 4 3 8 2]
 [5 8 3 0 9 9 6 1 4 2]
 [9 7 4 4 5 8 8 3 1 6]
 [9 4 6 1 0 5 3 2 8 7]]
vt_50sample [[6 4 7 8 1 2 5 0 9 3]
 [3 1 5 6 7 4 8 9 2 0]
 [1 3 5 8 9 2 4 7 0 6]
 [0 2 6 1 8 5 9 4 7 3]
 [9 4 0 5 8 1 3 7 6 2]
 [6 2 7 4 5 1 8 9 3 0]
 [7 9 1 6 5 0 4 3 8 2]
 [5 8 3 0 7 9 6 1 4 2]
 [9 7 4 2 5 0 8 3 1 6]
 [9 4 6 1 0 5 3 2 8 7]]
Epoch 42610: Training cost= 0.2948, Training acc= 0.8554, Validation cost= 0.2665, Validation acc= 0.8555
Epoch 42620: Training cost= 0.2875, Training acc= 0.8554, Validation cost= 0.4138, Validation acc= 0.8555
Epoch 42630: Training cost= 0.3028, Training acc= 0.8554, Validation cost= 0.2718, Validation acc= 0.8555
Epoch 42640: Training cost= 0.2318, Training acc= 0.8554, Validation cost= 0.2538, Validation acc= 0.8555
Epoch 42650: Training cost= 0.2134, Training acc= 0.8555, Validation cost= 0.2738, Validation acc= 0.8555
Epoch 42660: Training cost= 0.2342, Training acc= 0.8555, Validation cost= 0.2282, Validation acc= 0.8555
Epoch 42670: Training cost= 0.2129, Training acc= 0.8555, Validation cost= 0.2048, Validation acc= 0.8556
Epoch 42680: Training cost= 0.2321, Training acc= 0.8555, Validation cost= 0.2129, Validation acc= 0.8556
Epoch 42690: Training cost= 0.2666, Training acc= 0.8555, Validation cost= 0.2766, Validation acc= 0.8556
Epoch 42700: Training cost= 0.2692, Training acc= 0.8555, Validation cost= 0.2185, Validation acc= 0.8556
tm  [-0.4 -0.3 -1.3 -2.9 -1.9 -0.3 -0.1 -0.2 -0.5 -1.2 -2.5 -0.3 -0.1 -0.2  3.9  0.5 -0.1 -0.5 -0.3 -0.1 -1.4 -0.1 -0.3 -0.2 -1.7  1.4 -0.  -0.4  0.8 -0.3  2.7 -0.4 -0.1  0.9 -0.2 -0.3  0.9 -0.   3.3 -0.2  0.4  3.2  1.8  4.   0.5 -0.1 -0.7  0.1  1.9 -0.5 -0.6 -0.  -0.2 -0.2 -1.3 -0.5 -0.8  2.5 -0.1 -1.   1.4 -0.5 -0.3 -0.1 -0.1 -0.1 -0.1  0.2  1.3 -0.  -0.2 -1.6 -0.3 -0.3 -3.4 -0.  -0.1  0.5 -0.  -0.4 -1.4 -0.1 -0.3  0.6 -0.8  3.9  4.7 -0.   0.6 -0.4 -0.2 -0.2 -0.1 -0.  -0.8 -0.3  0.9 -2.6 -0.6 -0.1  3.6 -0.4 -0.4 -0.1 -0.4 -0.2 -2.2  1.2 -0.8 -0.1 -0.2 -0.3 -0.3 -0.9 -0.5  9.9  0.2 -0.5 -0.  -0.  -0.2 -0.1 -0.  -0.3 -0.1  5.2 -0.2  3.4  3.8  6.8 -0.1 -0.5 -0.4 -0.8 -2.  -2.  -0.2 -0.1 -0.3 -0.5  2.4 -0.4  1.7 -0.1 -0.1  0.4 -0.3 -0.2  5.3 -0.1  2.3 -0.   2.2  0.8 -0.2 -0.  -0.5  1.   2.3 -0.4 -0.3 -1.1  0.2 -0.2 -0.3 -0.6 -0.4 -0.3 -0.1 -0.1 -0.2 -0.1 -0.2 -0.2 -0.1 -0.8 -0.4 -0.5 -0.1 -0.1 -2.  -0.3 -0.4 -2.2 -0.2 -0.2 -0.1 -0.6 -0.1  1.4 -0.1 -0.1 -0.4 -1.4  0.1 -1.1 -0.6  1.5  0.4 -0.2 -0.1 -0.1 -0.2 -0.4  0.  -2.5 -0.2 -0.3 -2.3 -0.1 -0.5  2.7 -0.5  1.  -0.6 -0.1 -1.7 -1.  -0.  -0.5 -0.1 -0.2 -0.2 -1.2 -1.1  3.8 -1.8 -0.5  0.2  2.3 -0.7  0.1 -0.4 -1.  -0.6  2.2  0.1 -0.5  2.8 -4.   0.2 -1.4 -0.2  0.   6.3 -0.1 -0.3 -0.4 -1.  -0.1  3.  -0.2  2.  -0.2  6.5 -1.3]
ty_50sample [[5 4 3 8 7 1 9 6 0 0]
 [4 9 7 5 0 2 8 6 1 3]
 [0 5 6 8 4 7 9 2 3 1]
 [2 3 0 9 5 4 6 8 7 1]
 [1 4 5 3 2 0 6 7 9 9]
 [0 2 1 6 5 7 4 3 9 8]
 [7 1 9 8 5 4 3 0 2 6]
 [1 3 7 8 8 6 5 2 4 9]
 [1 2 3 8 9 6 5 4 7 0]
 [4 5 2 1 6 3 8 9 7 0]]
tt_50sample [[5 4 3 8 7 1 9 6 0 2]
 [4 9 7 5 0 2 8 6 1 3]
 [0 5 8 6 4 7 9 2 3 1]
 [2 3 0 9 5 4 6 8 7 1]
 [1 4 5 3 2 0 6 7 8 9]
 [0 2 1 6 5 7 4 3 9 8]
 [7 1 9 8 5 4 3 0 2 6]
 [1 3 7 0 8 6 5 2 4 9]
 [1 2 3 8 9 6 5 4 7 0]
 [4 5 2 1 6 3 8 9 7 0]]
vm  [-1.  -0.3  8.6 10.8 -1.5 -0.4  0.  -0.2 -0.3 -0.8 -5.  -0.4 -0.3 -0.4  2.8 -0.2 -0.2 -0.   0.4  0.9 -1.1 -0.4  1.1 -0.1 -0.6  2.6 -0.3 -0.2 -0.4 -1.  -1.9 -0.4 -0.7 -2.5 -0.2 -0.2  0.3 -0.8 -0.2 -0.6 -0.6 -2.8 -0.2 -1.2 -0.2 -0.3 -0.8 -0.3  2.3  1.7 -0.6 -0.2 -0.2 -0.2 -1.2 -0.3 -0.3  4.   0.4  7.7  1.3 -0.2 -0.3 -0.1 -1.3 -0.8 -0.2 -0.4  2.7 -0.3 -0.2 -0.5  1.   1.4 -2.8 -0.3 -0.1 -0.7 -0.  -0.3 -3.6 -0.2 -0.1 -0.3 -1.  -2.7 -1.4 -0.1 -0.1 -0.5 -0.1 -0.2 -0.2 -0.4 -0.7 -0.2 -0.1 -2.7 -0.8 -0.6  2.9 -0.8 -0.2 -0.2 -0.3  0.5 -1.1 -1.  -1.3 -1.1 -0.  -0.2 -0.2 -0.3 -0.   5.  -0.4  0.3  0.  -0.2  0.3  2.4 -0.2 -0.1 -0.2  3.7 -0.2  3.8  0.3  8.7  1.5 -0.4 -0.3 -0.4 -0.2 -2.7 -0.4 -0.2  0.1  1.   1.4 -0.7  0.6  0.1 -0.3 -0.1 -0.2  0.1 -1.6 -0.  -1.1 -0.1  2.   2.1 -0.2 -0.1 -0.5 -0.2 -0.2 -0.4 -0.  -0.1  0.8 -0.2 -0.3 -0.6 -0.2  0.8 -0.1 -0.1 -0.2 -0.2 -0.2 -0.2 -0.1  3.1 -0.1 -0.   1.1 -0.  -0.1 -0.4 -0.3 -1.9 -0.2  1.  -0.  -0.2  0.7  2.7 -0.1 -0.3 -0.4 -1.   1.1 -0.1 -0.2 -0.1  0.3 -0.1  0.6 -0.1 -0.3 -0.3 -0.1 -0.9 -0.3 -0.3 10.1 -0.2 -0.7  1.8 -1.   2.5 -0.4 -0.5  6.4 -0.7 -0.1 -0.3 -0.1 -0.3 -0.8 -1.3 -0.6  1.5 -2.  -0.3 -0.3  1.8 -0.4 -0.6 -0.4  2.3 -0.6 -2.1 -0.2 -0.3  1.5  5.6 -0.1  1.4 -0.2 -0.2 11.8 -0.8 -0.5  0.1 -0.8 -0.5  8.8 -0.  -0.2  0.2  7.9 -1.8]
vy_50sample [[8 3 7 6 1 9 0 5 2 4]
 [8 3 7 2 4 0 6 1 5 9]
 [3 9 0 7 1 6 2 8 5 4]
 [2 9 5 0 3 6 8 7 1 4]
 [5 9 8 3 2 1 6 4 7 0]
 [4 1 9 3 7 6 0 8 5 2]
 [1 6 2 8 0 3 7 9 5 4]
 [5 7 1 1 8 6 4 3 9 9]
 [3 5 1 2 4 0 8 7 6 9]
 [3 7 5 8 0 1 6 9 4 2]]
vt_50sample [[8 3 7 6 1 9 0 5 2 4]
 [8 3 7 2 4 0 6 1 5 9]
 [3 9 7 0 1 6 2 8 5 4]
 [9 2 5 0 3 6 8 7 1 4]
 [5 9 8 3 2 6 1 4 7 0]
 [4 1 9 3 7 6 0 8 5 2]
 [1 6 2 8 0 3 9 7 5 4]
 [5 7 0 1 8 6 4 3 9 2]
 [3 5 1 2 4 0 8 7 6 9]
 [3 7 5 8 0 1 6 9 4 2]]
Epoch 42710: Training cost= 0.2924, Training acc= 0.8555, Validation cost= 0.2377, Validation acc= 0.8556
Epoch 42720: Training cost= 0.2530, Training acc= 0.8555, Validation cost= 0.2711, Validation acc= 0.8556
Epoch 42730: Training cost= 0.2377, Training acc= 0.8556, Validation cost= 0.2380, Validation acc= 0.8556
Epoch 42740: Training cost= 0.2427, Training acc= 0.8556, Validation cost= 0.2594, Validation acc= 0.8556
Epoch 42750: Training cost= 0.2659, Training acc= 0.8556, Validation cost= 0.2813, Validation acc= 0.8556
Epoch 42760: Training cost= 0.2845, Training acc= 0.8556, Validation cost= 0.2905, Validation acc= 0.8557
Epoch 42770: Training cost= 0.3274, Training acc= 0.8556, Validation cost= 0.3146, Validation acc= 0.8557
Epoch 42780: Training cost= 0.2772, Training acc= 0.8556, Validation cost= 0.2453, Validation acc= 0.8557
Epoch 42790: Training cost= 0.2155, Training acc= 0.8556, Validation cost= 0.3034, Validation acc= 0.8557
Epoch 42800: Training cost= 0.2349, Training acc= 0.8556, Validation cost= 0.2585, Validation acc= 0.8557
tm  [-0.9 -0.4 -4.2 -4.1 -1.1 -0.  -0.2 -0.1 -0.3  1.4  1.4 -0.4  0.2 -0.1 -0.2 -0.9 -0.  -0.5 -0.3  0.8 -1.5 -0.3  0.9 -0.2 -0.8  1.4 -0.2  0.4 -1.5 -3.6  1.6 -0.1 -0.5 -5.6 -0.2 -0.2  1.2  4.7 -0.6 -0.2  0.1 -1.1 -1.3  1.8 -0.2 -0.  -1.5 -0.7 -0.3  7.9 -0.4 -0.2 -0.5 12.3  2.5 -0.3 -0.6 -2.9  8.   2.   4.9 -0.  -0.3  0.5 -0.5  0.3  0.2 -0.3 -0.  -0.  -0.4  5.4 -0.1 -0.4 -5.2 -0.3 -0.2 -0.1 -0.1 -0.2 -5.3 -0.  -0.1  0.2 -0.1 -1.2  2.5 -0.2 -0.1 -0.1 -0.2 -0.3 -0.2 -0.7 -0.4 -0.3 -0.4 -3.5 -0.1  0.3 -0.4 -1.1 -0.4 -0.1 -0.3 -0.5 -2.9  0.1  0.8  0.9  0.3 -0.2 -0.2 -0.4  7.7 -3.7 -0.2  1.  -0.2  0.5  0.  -0.7 -0.2 -0.1 -0.2 -0.2 -0.1 -2.6  5.1  5.  -0.3 -0.5 -0.3 -0.3  5.9 -3.9 -0.1  0.1 -0.1 -0.6 -0.4 -1.1 -0.7 -0.3 -0.1 -0.2 -0.3 -0.2  2.5 -0.   3.8 -0.3  2.4 -0.  -0.2 -0.2 -0.1 -0.8  0.5 -0.  -0.3 -1.   0.4 -0.3 -0.1 -0.5 -0.3 -0.1 -0.2 -0.1 -0.  -0.1 -0.1 -0.1  0.1 -0.1  0.3 -0.4  1.  -0.1  0.8 -0.2 -0.1 -1.6  0.2  0.6 -0.6 -0.1  0.2  9.8 -0.2 -0.2 -0.2 -0.6 -1.6 -1.6 -1.3 -1.7 -0.2 -0.  -0.1 -0.  -0.4 -0.3 -0.3 -3.6 -0.2 -0.2  9.2 -0.1 -0.6 -2.6 -0.7  1.4 -0.5 -0.2 -1.4 -1.1 -0.7 -0.2 -0.1 -0.3 -0.  -1.2 -0.1 -1.2 -0.1  0.7 -0.3  0.6 -0.8  1.  -0.4  1.9  3.   5.3  2.  -1.3  3.3 -0.  -0.2 -0.1 -0.1 -0.2 16.6  3.9 -0.  -0.3 -1.3 -0.1 14.  -0.2 -0.3 -0.2 -0.6 -1. ]
ty_50sample [[0 8 4 2 1 3 6 5 9 7]
 [3 2 0 5 6 8 1 9 7 4]
 [5 2 1 1 6 9 3 7 4 0]
 [4 1 2 8 9 5 6 0 7 3]
 [8 1 6 0 4 3 5 2 7 9]
 [0 1 9 6 8 7 3 4 5 2]
 [8 2 4 1 3 5 6 9 7 0]
 [2 3 0 6 4 7 8 1 5 9]
 [2 8 9 1 0 3 4 7 5 6]
 [0 3 5 1 9 8 7 6 2 4]]
tt_50sample [[0 8 4 2 1 3 6 5 9 7]
 [3 2 0 5 6 8 1 9 7 4]
 [5 2 8 1 6 9 3 7 4 0]
 [4 1 2 8 9 5 6 0 7 3]
 [8 1 0 6 4 3 5 2 7 9]
 [0 1 9 6 8 7 3 4 5 2]
 [8 2 4 1 3 5 6 9 7 0]
 [2 3 0 6 4 7 8 1 5 9]
 [2 8 9 1 0 3 4 7 5 6]
 [0 3 5 1 9 8 7 6 2 4]]
vm  [-1.2 -0.4  7.  15.5 -1.  -0.  -0.4 -0.1  0.2 -0.1 10.  -0.5 -0.1 -0.1 -0.3  2.9 -0.2 -0.2  0.3 -0.4 -1.3 -0.1 -0.3 -0.1 -0.7  2.8 -0.5 -0.2 -0.7 -2.1 -0.2 -0.3 -0.1  6.1  0.  -0.3  0.9  0.7 -1.9 -0.5 -0.  -0.6 -0.9 -1.8 -0.3 -0.   1.2 -0.3 -0.2 -0.7 -0.2 -0.2 -0.1  5.2 -0.6  0.6 -0.3  3.6  4.9  3.7  2.  -0.3 -0.1  0.4 -0.1 -0.9  0.1 -0.2  0.3 -0.1  0.3  0.4  1.2  1.5 -2.  -0.3 -0.5 -0.7 -0.  -0.2 11.1 -0.3 -0.2 -0.2 -0.2 -0.2 -1.9 -0.2 -0.2 -0.2 -0.  -0.  -0.3 -1.1 -0.2  0.2 -0.3 -2.4 -0.3 -0.6  0.7  3.4 -0.3 -0.1 -0.3 -0.3 -0.9 -0.4  0.6 -1.4 -0.6  0.1 -0.1 -0.6  3.6  2.   0.1 -0.2 -0.1 -0.1 -0.1  4.3 -0.   0.4 -0.3 -0.5 -0.  -0.8  3.2 -0.6 -0.1 -0.2 -0.1 -0.4  9.3 16.1 -0.  -0.1 -0.2 -0.3 -0.5 -0.4 -0.7 -0.2 -0.1 -0.1 -0.3 -0.2 -0.7 -0.  -1.6 -0.2 -1.  -0.6 -0.1 -0.  -0.4 -0.5 -0.8 -0.2  0.5  0.9 -0.1 -0.1 -0.  -0.1 -0.2  1.2 -0.1 -0.1 -0.1 -0.1 -0.2 -0.2 -0.2  2.2 -0.8  1.1  2.9 -0.  -0.1 -0.1 -0.3 -1.4  0.2  0.2 -0.1 -0.4 -0.1  6.1 -0.2 -0.3 -0.2 -0.8  0.1 -1.3 -0.1 -1.  -0.1 -0.  -0.3 -0.1 -0.3 -0.5 -0.4 -0.9 -0.  -0.1 -0.5 -0.3 -0.6 -0.  -1.1  4.3 -0.9 -0.2  8.9 -1.3 -0.2  0.5 -0.2  0.2  0.8 -0.9  4.6 -0.6  0.2  1.1  1.5  0.8  1.3 -0.5 -0.2 -0.3 -0.  -1.6  0.8 -0.2  2.3  8.1 -0.   2.5 -0.1 -0.2 -2.  -1.1  0.8  0.6 -1.4 -0.1 -2.9  0.  -1.1 -0.1 -1.   4.6]
vy_50sample [[6 2 1 9 0 7 3 5 8 4]
 [8 0 6 9 3 2 5 4 1 7]
 [6 3 0 4 5 8 9 7 2 1]
 [3 6 5 9 4 1 0 7 7 2]
 [4 6 8 5 3 0 9 2 1 7]
 [9 1 2 3 0 4 5 8 6 7]
 [6 1 7 0 3 2 5 9 8 4]
 [7 8 3 6 4 5 5 9 2 0]
 [3 0 2 9 1 7 8 6 5 4]
 [5 3 0 6 9 8 1 4 7 2]]
vt_50sample [[6 2 1 9 0 7 3 5 8 4]
 [8 0 6 9 3 2 5 4 1 7]
 [6 3 0 4 5 8 9 7 2 1]
 [3 6 5 9 4 8 1 0 7 2]
 [4 6 8 5 3 0 9 2 1 7]
 [9 1 2 3 0 4 5 8 6 7]
 [6 1 7 0 3 5 2 9 8 4]
 [7 8 3 6 4 5 9 1 2 0]
 [3 0 2 9 1 7 8 6 5 4]
 [5 3 0 6 9 8 1 4 7 2]]
Epoch 42810: Training cost= 0.2197, Training acc= 0.8556, Validation cost= 0.2778, Validation acc= 0.8557
Epoch 42820: Training cost= 0.2470, Training acc= 0.8556, Validation cost= 0.2719, Validation acc= 0.8557
Epoch 42830: Training cost= 0.3406, Training acc= 0.8557, Validation cost= 0.2691, Validation acc= 0.8557
Epoch 42840: Training cost= 0.2719, Training acc= 0.8557, Validation cost= 0.3964, Validation acc= 0.8557
Epoch 42850: Training cost= 0.2384, Training acc= 0.8557, Validation cost= 0.2672, Validation acc= 0.8557
Epoch 42860: Training cost= 0.2724, Training acc= 0.8557, Validation cost= 0.2242, Validation acc= 0.8557
Epoch 42870: Training cost= 0.2464, Training acc= 0.8557, Validation cost= 0.2131, Validation acc= 0.8558
Epoch 42880: Training cost= 0.2214, Training acc= 0.8557, Validation cost= 0.2832, Validation acc= 0.8558
Epoch 42890: Training cost= 0.2246, Training acc= 0.8557, Validation cost= 0.2833, Validation acc= 0.8558
Epoch 42900: Training cost= 0.2823, Training acc= 0.8557, Validation cost= 0.2651, Validation acc= 0.8558
tm  [-0.9 -0.3 12.4 17.6 -1.7 -0.1 -0.3 -0.   1.2 -0.2 -0.3 -0.3  0.5  0.   4.5 -1.1 -0.6  0.9  0.7 -0.9 -1.2 -0.1  2.1 -0.  -0.5  2.8 -0.5  1.4 -1.2 -2.3 -0.8  0.   0.5 10.5 -0.1 -0.2  0.7  3.2 12.2 -0.3 -0.1 -1.1 -1.1 -0.8 -0.1 -0.   6.1 -0.5 -0.6  3.8 -0.3  0.1 -0.2 -1.7 -0.1 -0.7 -0.5  2.6  4.1  4.9 -0.1 -0.2  1.6 -0.2  0.2 -0.5 -0.  -0.4 -0.  -0.2 -0.1  2.6 -0.1 -0.2 -0.8 -0.2 -0.3 -0.6 -0.1  0.5  9.4 -0.3 -0.3 -0.6 -0.1 -0.9 -2.4 -0.2 -0.2  1.1 -0.1 -0.1 -0.2 -1.1 -0.1 -0.3  0.3 -1.9 -0.3  0.8 -0.1  6.2 -0.6 -0.  -0.1 -0.3 -0.2 -0.3 -0.1 -1.4  0.4 -0.2 -0.1 -0.5  6.7 -2.4 -0.8 -0.  -0.2 -0.4 -0.4  3.9 -0.1  0.9 -0.2  5.5  0.1  6.9  1.4 -1.6 -0.4 -0.3 -0.2 -0.  -5.  -1.4 -0.1 -0.1  0.8 -0.5  0.  -1.3 -0.6 -0.1 -0.1  0.  -0.4 -0.1 -2.8 -0.2 -1.6 -0.1 -0.  -0.2  0.2 -0.1 -0.1 -0.2  2.1 -0.1 -0.4 -1.3 -0.1 -0.1  0.1 -0.5 -0.2  1.  -0.3 -0.2  0.8 -0.3  0.1  0.5 -0.1  3.9 -0.2  0.3 -1.2 -0.1  0.5 -0.2  0.4 -1.3 -0.2 -0.9 -0.1 -0.3  0.5  6.9 -0.2 -0.2 -0.2 -0.7  3.8 -0.5 -0.3 -1.9 -0.2 -0.1 -0.2 -0.1 -0.4 -0.3 -0.1  2.1 -0.2  0.4  6.5 -0.1 -0.3 -1.  -0.4  2.6 -0.6 -0.3  3.1 -1.1 -0.4 -0.1 -0.1 -0.2 -0.1 -0.9 -0.1 -0.7 -1.1  2.5 -0.8 -0.3 -0.3 -0.7 -0.2  2.6  0.8 -2.8 -0.1  0.9  3.3 16.7  0.3  4.6 -0.2  0.2 -1.6 -2.4 -0.9 -0.  -1.1  1.4 -2.6 -0.2  8.  -0.1  1.7  8.3]
ty_50sample [[7 0 9 1 8 2 3 6 5 4]
 [0 4 1 9 9 5 2 6 7 3]
 [4 8 1 3 0 5 7 2 6 9]
 [4 7 6 9 3 8 1 0 5 2]
 [9 2 7 7 0 0 1 3 8 4]
 [6 1 1 9 5 7 2 0 4 3]
 [4 2 3 0 8 1 9 6 7 5]
 [3 4 1 1 5 2 0 6 8 7]
 [6 5 1 9 7 2 4 8 3 0]
 [8 0 1 3 5 7 2 9 4 6]]
tt_50sample [[7 0 9 1 8 2 3 6 5 4]
 [4 0 1 8 9 5 2 6 7 3]
 [4 8 1 3 0 5 7 2 6 9]
 [4 7 6 9 3 8 1 0 5 2]
 [9 5 2 7 6 0 1 3 8 4]
 [1 6 8 9 5 7 2 0 4 3]
 [2 4 3 0 8 1 9 6 7 5]
 [3 4 9 1 5 2 6 0 8 7]
 [6 5 9 1 7 2 4 8 3 0]
 [8 0 1 3 5 7 2 9 4 6]]
vm  [-0.2 -0.4 -3.5 -2.9 -1.2 -0.2 -0.3  0.4 -0.2  0.5 -7.3 -0.2 -0.2  0.3 -0.6 -1.8 -0.1 -0.4 -0.3 -0.2 -1.1 -0.4 -0.2 -0.2 -1.   0.7 -0.2 -0.2 -0.7 -1.  -0.2 -0.1  0.  -6.1 -0.3  0.1 -0.2 -1.5 -1.5 -0.3 -0.2  3.3 -0.5  0.8 -0.   0.  -0.4 -0.   1.7 13.7 -0.3 -0.  -0.5 -0.9 -0.4 -0.1 -0.7 -1.4  4.   2.8  1.7 -0.6 -0.2 -0.3 -0.9 -0.6 -0.3 -0.1  1.3 -0.4 -0.1  2.5  0.2 -0.3 -4.1 -0.1 -0.1 -0.2 -0.2 -0.2 -5.5 -0.4  0.2  1.4 -1.1  4.   4.2  0.6 -0.4 -0.3 -0.  -0.2 -0.4 -1.  -0.7  0.2 -0.6 -2.9 -0.1 -0.6 -0.2  0.9 -0.2 -0.1 -0.1 -0.4 -2.  -0.3 -2.1 -0.5 -0.   0.2 -0.1 -0.4  5.2 -0.7 -0.4  0.7 -0.1 -0.  -0.4  0.6 -0.1 -0.4 -0.3 -0.5 -0.1  5.2  2.9 -0.3  0.1 -0.2 -0.4 -0.5  9.5 -3.2 -0.2 -0.3  0.1  2.5  2.4 -0.8  0.7  0.  -0.1  0.1 -0.4 -0.3  4.7  0.1  1.9 -0.3  3.4  0.2 -0.3 -0.  -0.5 -1.  -0.3 -0.1 -0.1 -0.3  0.  -0.2 -0.1 -0.4  0.2 -0.  -0.  -0.2 -0.3 -0.1 -0.1 -0.7 -0.2 -0.4 -1.  -0.1  2.   0.6 -1.1 -0.7 -0.1 -1.8 -0.2  0.8 -0.3 -0.2 -0.2  3.4 -0.2 -0.1 -0.2 -0.6  0.6 -0.9 -0.6 -1.2 -0.4 -0.3 -0.6  0.2 -0.4 -0.3 -0.2 -2.5 -0.1 -0.2  8.4 -0.5 -0.2 -0.7 -0.7 -0.  -0.6 -0.3 -0.6 -0.7 -0.3  0.1 -0.2 -0.  -0.2 -1.8  3.5 -0.  -2.1 -0.1 -0.7  1.6 -0.4  1.4 -0.4  1.7 -0.4  3.7  1.  -0.7  2.9 -1.3 -0.1 -0.5  0.2 -0.1 16.4  0.5 -0.2 -0.5 -1.3 -0.4 14.2 -0.2 -0.8 -0.6  3.4  3.4]
vy_50sample [[8 4 0 6 5 1 9 3 7 2]
 [8 6 5 2 7 3 4 0 9 1]
 [9 5 3 7 4 6 8 0 0 2]
 [4 3 6 5 2 0 7 9 1 8]
 [3 2 7 5 4 0 8 9 1 6]
 [7 5 0 3 8 9 4 1 2 6]
 [1 5 2 8 7 4 3 6 0 9]
 [6 0 0 1 2 4 3 8 7 5]
 [1 8 4 0 7 9 2 3 6 5]
 [2 4 6 8 1 9 3 5 0 7]]
vt_50sample [[8 4 0 6 5 1 9 3 7 2]
 [8 6 5 2 7 3 4 0 9 1]
 [9 5 3 7 4 6 1 8 0 2]
 [4 3 6 5 2 0 7 9 1 8]
 [3 2 7 4 5 0 8 1 9 6]
 [7 0 5 3 8 4 9 1 2 6]
 [1 5 2 8 7 4 3 6 9 0]
 [6 0 9 1 2 4 3 8 7 5]
 [1 8 4 0 7 9 2 3 6 5]
 [2 4 8 6 1 9 3 5 0 7]]
Epoch 42910: Training cost= 0.2651, Training acc= 0.8557, Validation cost= 0.2288, Validation acc= 0.8558
Epoch 42920: Training cost= 0.1886, Training acc= 0.8557, Validation cost= 0.2114, Validation acc= 0.8558
Epoch 42930: Training cost= 0.2872, Training acc= 0.8558, Validation cost= 0.2403, Validation acc= 0.8558
Epoch 42940: Training cost= 0.2809, Training acc= 0.8558, Validation cost= 0.2825, Validation acc= 0.8558
Epoch 42950: Training cost= 0.2415, Training acc= 0.8558, Validation cost= 0.2667, Validation acc= 0.8559
Epoch 42960: Training cost= 0.2300, Training acc= 0.8558, Validation cost= 0.2805, Validation acc= 0.8559
Epoch 42970: Training cost= 0.2386, Training acc= 0.8558, Validation cost= 0.2504, Validation acc= 0.8559
Epoch 42980: Training cost= 0.3019, Training acc= 0.8558, Validation cost= 0.2306, Validation acc= 0.8559
Epoch 42990: Training cost= 0.1990, Training acc= 0.8558, Validation cost= 0.2614, Validation acc= 0.8559
Epoch 43000: Training cost= 0.2547, Training acc= 0.8558, Validation cost= 0.2136, Validation acc= 0.8559
tm  [-1.4 -0.5 -2.8 -1.5 -1.9  0.5 -0.4  0.1  0.1  0.4  2.5 -0.  -0.2 -0.1 -0.6 -0.7 -0.3 -0.2 -0.9  0.1 -1.5 -0.2  0.5 -0.2 -1.4  3.5 -0.1 -0.5 -0.7 -3.6  3.2 -0.2 -0.2 -0.6 -0.1  0.   1.4  3.2  7.5 -0.3  4.1  2.2 -0.7  4.4 -0.1  0.1 -0.8 -0.1 -1.6  0.3 -0.3 -0.1  1.   0.5 -0.9  0.1 -0.8 -1.   6.4 -1.3  7.6 -0.5  2.4 -0.2  0.8 -0.3 -0.2  0.1 -0.4 -0.1 -0.   0.5 -0.2  1.4 -3.8 -0.6 -0.   0.2 -0.1 -0.6  3.   0.6 -0.  -0.6  1.1  2.5 -0.5 -0.2 -0.1 -0.5 -0.2  0.1 -0.2 -0.6 -0.8 -0.1 -0.4 -2.7 -0.  -0.4 -0.4 -0.6 -0.1 -0.3 -0.2  0.  -1.5  2.6  1.  -0.5 -0.5 -0.2 -0.2 -0.6  4.7 -0.5  0.2 -0.1 -0.  -0.2  0.5  0.5 -0.2 -0.4 -0.2 -0.6 -0.   2.4  7.   1.2 -0.7 -0.2 -0.2  0.7 -0.6 -1.5 -0.2 -0.1  0.7 -0.4  1.5 -0.7 -0.1 -0.3 -0.  -0.3 -0.3 -0.2  5.  -0.1  0.4 -0.2 -1.6 -0.  -0.2  0.5 -0.5  1.5  3.5 -0.3  0.6 -1.9 -0.1 -0.  -0.2 -0.3 -0.1 -0.1  0.1 -0.  -0.2 -0.1 -0.3 -0.1 -0.3 -0.7 -0.3  0.2 -0.5 -0.1 -0.9 -0.3 -0.3 -1.7 -0.2 -0.5 -0.8 -0.1 -0.5 10.1 -0.2 -0.5 -0.4 -1.5 -2.8 -2.2 -0.3 -1.2 -0.1 -0.1 -0.1 -0.1 -0.3 -0.4 -0.3 -1.1 -0.3 -0.2 -1.1 -0.1 -0.4 -0.5 -0.9  9.3 -0.9 -0.5 -2.2 -1.3 -0.1 -0.1 -0.2 -0.2 -0.4 -1.1 -0.9 -0.4 -1.9 -0.2  0.  -0.7 -0.  -0.  -0.2 -0.4 -0.1  5.5 -0.2 -0.9  3.3 -0.6 -0.1 -0.4 -0.2 -0.1  0.3 -0.8 -0.8  0.7 -1.2 -0.  -1.  -0.2  4.3  0.2  2.8  1.4]
ty_50sample [[1 4 0 5 9 3 8 8 7 6]
 [3 2 2 0 9 8 8 5 7 4]
 [2 3 7 0 5 4 6 9 1 8]
 [3 4 7 0 5 9 8 1 2 6]
 [9 2 5 7 1 0 6 4 8 8]
 [8 4 5 6 0 7 3 1 9 2]
 [1 2 7 9 5 8 6 0 3 4]
 [5 2 6 1 9 4 3 7 0 8]
 [6 9 7 4 0 8 5 1 3 2]
 [6 0 8 5 5 4 9 7 3 3]]
tt_50sample [[1 4 0 5 9 3 8 2 7 6]
 [3 6 2 0 9 1 8 5 7 4]
 [2 3 7 0 5 4 6 9 1 8]
 [3 4 7 0 5 9 8 1 2 6]
 [9 2 5 7 1 0 6 4 8 3]
 [8 4 5 6 0 7 3 1 9 2]
 [1 2 9 7 5 8 6 0 3 4]
 [5 2 6 1 9 4 3 7 0 8]
 [6 9 7 4 0 8 5 1 3 2]
 [6 0 8 1 5 4 9 7 2 3]]
vm  [ 2.4 -0.4 -1.6  4.2 -0.5 -0.2 -0.   0.  -0.8 -0.5  3.1 -0.3  0.4 -0.4 -1.9  6.3  0.7 -0.1 -0.2 -1.3 -0.8  0.4  0.6  0.2 -1.4  0.6 -0.2 -0.1  1.4  3.4 -0.6 -0.2  1.3 -4.4 -0.1 -0.2  2.1 -0.  -1.6 -0.6 -0.3 -1.8  1.7 -1.1  0.1 -0.4  7.  -0.5  4.1  2.3 -0.5 -0.3 -0.4  4.3 -1.7  2.5 -0.2 -0.6 -1.3  4.  -1.4 -0.  -0.7 -0.4  0.   0.2  0.1  0.7 -0.1 -0.3 -0.3 -1.6 -0.2 -0.8 -1.1  1.2 -0.3  2.4 -0.4  0.5 -1.3 -0.  -0.4  3.3 -1.5 -1.4  5.4 -0.1  0.7 -0.3 -0.7 -0.  -0.4  1.5 -0.3 -0.3  0.5 -1.5 -0.6 -0.6  2.2 -1.3 -0.7 -0.1  0.5 -0.5 -1.6 -0.5  1.3 -1.   0.2 -0.1 -0.  -0.3 -1.4  8.8 -0.1 -1.2 -0.2 -0.3 -0.4  3.2 -0.5 -0.6 -0.2 -2.5 -0.5 -0.5 -1.8  3.7  0.8 -0.5 -0.5 -0.2 13.5  5.   0.3 -0.2 -0.4 -0.6 -1.5 -0.2 -0.6 -0.1 -0.  -0.1 -0.1 -0.1  2.8 -0.2 -0.6  0.7  3.4 -0.3 -0.1 -0.3  0.1 -0.7 -1.8 -0.2  0.3  1.8 -0.2 -0.  -0.1 -0.4 -0.5 -0.5 -0.5 -0.1 -0.1 -0.1 -0.1 -0.5  0.9 -0.3 -1.9 -0.5  1.4 -0.2 -0.2 -0.4  0.  -1.3 -0.1  0.1  1.5 -0.3 -0.3 -0.9  0.5 -0.  -0.6 -0.5 11.9  6.  -0.2  2.9 -0.1 -0.2  0.5  0.3  0.7 -0.1 -0.2 -1.1  0.2 -0.1  7.5  0.2 -1.   1.4 -0.6 -1.9 -0.1  0.6  4.1 -0.3 -0.4 -0.7 -0.1 -0.3 -0.  -0.8  1.8  4.3  1.3 -0.4 -0.   4.  -0.1  1.7 -0.3  1.5 -1.2  1.   1.3 -0.6 -0.3 11.4 -0.2  3.7 -0.3 -0.   5.3 -1.7  2.  -0.5 -1.  -0.3  2.4 -0.2 -0.9 -0.1 -0.5 -0.4]
vy_50sample [[6 2 8 3 9 4 5 7 0 1]
 [7 5 6 6 3 8 2 1 0 4]
 [6 8 7 7 2 4 9 1 0 3]
 [3 9 1 4 6 8 7 2 0 5]
 [6 7 2 3 1 9 8 0 5 4]
 [9 5 1 0 4 6 3 2 7 8]
 [9 0 6 5 3 7 1 4 2 8]
 [5 0 1 7 8 4 3 2 9 6]
 [2 1 0 4 6 3 7 9 8 5]
 [3 1 8 2 7 5 9 6 4 0]]
vt_50sample [[6 2 8 3 9 4 5 7 0 1]
 [5 7 9 6 3 8 2 1 0 4]
 [6 8 5 7 2 4 9 1 0 3]
 [3 9 1 4 6 8 7 2 5 0]
 [6 7 2 3 9 1 8 0 5 4]
 [9 5 1 0 4 6 3 2 7 8]
 [9 0 6 5 3 7 1 4 2 8]
 [5 0 1 7 8 4 3 2 9 6]
 [2 1 0 4 6 3 7 9 8 5]
 [3 1 8 2 5 7 9 6 4 0]]
Epoch 43010: Training cost= 0.2611, Training acc= 0.8558, Validation cost= 0.2236, Validation acc= 0.8559
Epoch 43020: Training cost= 0.2348, Training acc= 0.8559, Validation cost= 0.2210, Validation acc= 0.8559
Epoch 43030: Training cost= 0.2501, Training acc= 0.8559, Validation cost= 0.2174, Validation acc= 0.8559
Epoch 43040: Training cost= 0.2354, Training acc= 0.8559, Validation cost= 0.2490, Validation acc= 0.8559
Epoch 43050: Training cost= 0.2778, Training acc= 0.8559, Validation cost= 0.2223, Validation acc= 0.8560
Epoch 43060: Training cost= 0.2142, Training acc= 0.8559, Validation cost= 0.2360, Validation acc= 0.8560
Epoch 43070: Training cost= 0.2706, Training acc= 0.8559, Validation cost= 0.2749, Validation acc= 0.8560
Epoch 43080: Training cost= 0.2372, Training acc= 0.8559, Validation cost= 0.2147, Validation acc= 0.8560
Epoch 43090: Training cost= 0.2353, Training acc= 0.8559, Validation cost= 0.2557, Validation acc= 0.8560
Epoch 43100: Training cost= 0.2558, Training acc= 0.8559, Validation cost= 0.2221, Validation acc= 0.8560
tm  [-0.3 -0.5  2.5 -4.1 -1.9 -0.4 -0.4 -0.2 -1.1 -0.8 -1.3 -0.3 -0.3 -0.  11.5  2.5 -0.2 -0.1  1.3 -0.4 -0.8 -0.  -0.5 -0.1 -1.8 -0.1 -0.5 -0.2  0.9  6.   2.3 -0.2 -0.4  8.7 -0.  -0.3  0.8 -0.2 -0.9 -0.8 -0.2  1.1  2.2  2.9 -0.2 -0.1 -1.2 -0.2  2.9 -0.4 -0.4 -0.2 -0.2  2.2 -1.6 -1.1 -1.1 -0.6 -1.2 -1.3 -0.4 -0.5 -0.8 -0.1 -0.6  0.7 -0.1 -0.3  1.8 -0.2  0.4 -1.7 -0.3  1.  -4.2 -0.3 -0.3 -0.4 -0.2 -0.3 -2.1 -0.5 -0.4 -0.  -1.2  2.4  7.4 -0.1 -0.4 -0.5 -0.6  0.1  0.  -0.1 -0.1  0.9 -0.6 -2.6 -0.8 -0.   2.2  4.9 -0.7 -0.2 -0.1  0.9 -2.   1.6 -0.4 -0.5 -0.2 -0.3 -0.2 -0.7 -1.3 12.7  0.8 -0.5 -0.3 -0.3 -0.2  0.9 -0.3 -0.7 -0.  14.1  0.4  0.4 -0.6  7.7 -0.4 -0.1 -0.1 -0.3 -3.7 -0.3 -0.2 -0.1 -1.1 -0.2  0.7 -0.4 -0.1 -0.4 -0.  -0.1 -0.3 -0.4 -0.8 -0.3  2.8 -0.1  2.  -0.3 -0.  -0.1 -0.5 -0.2  0.3 -0.3  0.2 -1.  -0.2 -0.1 -0.4 -0.4 -0.7 -0.1 -0.3 -0.1 -0.3 -0.1 -0.3 -0.4 -0.1  1.1 -0.8 -0.2  2.2 -0.2 -2.2 -0.  -0.2 -2.1 -0.2  0.6 -0.3 -0.6  0.3 -1.6 -0.1 -0.2 -0.1 -1.3  5.5  1.7 -0.5  3.  -0.1 -0.1 -0.1 -0.3 -0.2 -0.4 -0.2 -2.6 -0.1 -0.3 -0.9 -0.4 -0.6  2.3 -0.6 -0.6 -0.4  0.1 -1.4 -0.8 -0.1  0.2 -0.  -0.3 -0.6 -1.3 -0.3  5.2 -1.4 -0.3  0.4  2.2 -0.8  1.3 -0.  -0.5 -1.4 -0.3 -0.4 -0.6  0.1 -3.4  0.2 -1.  -0.2 -0.1  8.1  2.6  0.   0.5 -0.8 -0.8  5.4  0.7 -0.7 -0.3  2.9 -1.6]
ty_50sample [[7 4 5 3 8 6 2 9 1 0]
 [4 9 8 9 9 5 2 7 3 0]
 [1 7 9 2 3 6 8 0 5 4]
 [1 7 4 9 2 8 0 6 3 5]
 [4 6 1 5 2 0 3 7 9 8]
 [7 4 1 5 6 3 8 8 0 2]
 [0 5 1 3 4 9 8 2 7 6]
 [6 4 8 1 2 5 7 3 9 0]
 [9 6 7 0 0 4 1 2 3 5]
 [0 9 1 4 3 6 5 8 2 7]]
tt_50sample [[7 4 5 3 8 6 2 9 1 0]
 [4 8 9 6 1 5 2 7 3 0]
 [1 7 9 2 6 3 8 0 5 4]
 [1 7 4 9 2 8 0 6 3 5]
 [4 6 1 5 2 0 3 7 9 8]
 [7 4 5 1 6 3 8 9 0 2]
 [0 5 1 4 3 9 8 2 7 6]
 [6 4 8 1 2 5 7 9 3 0]
 [6 9 7 0 8 4 1 2 3 5]
 [9 0 1 4 3 6 5 8 2 7]]
vm  [-0.9 -0.2 -0.4  4.1 -0.6 -0.1 -0.2 -0.1  1.2 -0.1 11.4 -0.5 -0.1 -0.3 -0.6  5.7 -0.3 -0.2 -0.1 -0.6 -1.4 -0.1 -0.7 -0.4 -0.9  2.  -0.1 -0.1  0.2 -1.3  3.2 -0.5 -0.5  9.  -0.1 -0.3 -0.3 -0.  -0.8 -0.5 -0.6 -1.5 -1.2 -0.8 -0.3  0.   2.1 -0.3  0.8 -1.9 -0.1 -0.3 -0.1  3.1 -1.2  0.5  0.3 -1.4  6.7 -2.4  0.6 -0.3 -0.3  0.9  0.1 -0.6 -0.1 -0.2 -0.3  0.1 -0.  -1.4  0.2  1.9 -1.6 -0.3 -0.3 -0.3 -0.   0.  17.5 -0.1 -0.1 -0.2 -0.2 -0.7 -0.1  0.  -0.  -0.7  0.8 -0.1 -0.2 -1.6 -0.1  0.1 -0.3 -2.6 -0.3 -0.6  0.7  1.6 -0.4 -0.1 -0.4 -0.2 -0.6  0.3  0.4 -1.5 -0.1 -0.1 -0.1 -0.7  2.8  9.7 -0.7  0.1 -0.  -0.5 -0.2  4.5  0.4  0.7 -0.2 -0.8 -0.3 -0.2  4.8 -0.6  0.9 -0.1  0.7 -0.6  9.8 18.4  0.1 -0.1 -0.3 -0.3 -0.5 -0.5 -0.8 -0.   0.3  0.  -0.1 -0.2 -1.2 -0.2 -0.4 -0.  -1.2 -0.4 -0.2 -0.1 -0.7 -0.4 -1.   0.8  0.9  1.4 -0.1 -0.1 -0.3 -0.2 -0.4  2.3 -0.2 -0.1 -0.2 -0.1 -0.1 -0.2 -0.   2.6 -0.3  0.3  1.2 -0.   1.7 -0.4 -0.5 -1.5 -0.1  0.2 -0.  -0.4 -0.3  3.2 -0.3 -0.1 -0.3 -0.9  2.1 -1.8  0.3 -1.  -0.1 -0.2 -0.2  0.3 -0.1 -0.6 -0.4 -0.5 -0.2 -0.3 -0.6 -0.2 -0.6  3.8 -1.   4.2 -0.8 -0.1  4.3 -1.1 -0.4 -0.2 -0.3 -0.1 -0.3 -0.9  5.5  0.3 -0.2  1.9  0.6  1.5  0.7 -1.1 -0.1 -0.3 -0.3  1.8 -0.   0.1  2.6 14.4 -0.1  4.4 -0.  -0.2 -3.5 -1.5 -0.  -0.1 -1.6 -0.7 -4.6  0.7 -0.5 -0.1 -1.   4.6]
vy_50sample [[6 2 9 1 4 7 3 0 5 8]
 [6 7 1 5 4 2 0 9 9 3]
 [5 0 6 7 3 8 2 1 4 9]
 [9 8 4 0 3 2 1 5 7 6]
 [3 9 7 8 1 2 5 0 6 4]
 [6 5 3 8 9 7 1 0 4 2]
 [1 6 4 8 3 0 5 2 7 7]
 [2 1 5 8 3 4 7 7 0 9]
 [8 9 0 7 3 6 4 1 2 5]
 [5 8 0 4 1 3 9 6 7 2]]
vt_50sample [[6 2 9 1 4 7 3 0 5 8]
 [6 7 1 5 4 2 0 8 9 3]
 [5 6 0 7 3 8 2 1 4 9]
 [9 8 4 0 3 2 1 5 7 6]
 [3 9 7 8 2 1 5 0 6 4]
 [6 5 3 8 9 7 1 0 4 2]
 [1 6 4 8 3 0 5 2 9 7]
 [2 1 5 8 3 4 6 7 0 9]
 [8 9 0 7 3 6 4 1 2 5]
 [5 8 0 4 1 3 9 6 7 2]]
Epoch 43110: Training cost= 0.1971, Training acc= 0.8560, Validation cost= 0.2281, Validation acc= 0.8560
Epoch 43120: Training cost= 0.2260, Training acc= 0.8560, Validation cost= 0.1854, Validation acc= 0.8560
Epoch 43130: Training cost= 0.2088, Training acc= 0.8560, Validation cost= 0.2115, Validation acc= 0.8561
Epoch 43140: Training cost= 0.2478, Training acc= 0.8560, Validation cost= 0.2362, Validation acc= 0.8561
Epoch 43150: Training cost= 0.2518, Training acc= 0.8560, Validation cost= 0.2242, Validation acc= 0.8561
Epoch 43160: Training cost= 0.2426, Training acc= 0.8560, Validation cost= 0.2626, Validation acc= 0.8561
Epoch 43170: Training cost= 0.2773, Training acc= 0.8560, Validation cost= 0.2687, Validation acc= 0.8561
Epoch 43180: Training cost= 0.2665, Training acc= 0.8560, Validation cost= 0.3092, Validation acc= 0.8561
Epoch 43190: Training cost= 0.2732, Training acc= 0.8560, Validation cost= 0.2946, Validation acc= 0.8561
Epoch 43200: Training cost= 0.2377, Training acc= 0.8561, Validation cost= 0.2660, Validation acc= 0.8561
tm  [ 1.  -0.3  5.8  5.2 -1.9 -0.2 -0.1 -0.  -1.5 -0.7 -4.9 -0.3 -0.2 -0.2  4.2 -1.  -0.1 -0.1 -0.3 -0.5 -1.1 -0.1  2.2 -0.1 -1.2  0.8 -0.3 -0.7 -0.9  4.1 -1.  -0.3  0.1 -0.5  0.   0.1  2.7 -0.2  5.3 -0.7  2.9 -1.6  4.1  2.5 -0.1 -0.1  1.7 -0.1  5.9  3.4 -0.5 -0.2 -0.1 -1.  -0.9 -0.5 -0.9 -0.5 -2.3  4.7 -1.7 -0.1 -0.5 -0.4 -1.1 -0.5 -0.4 -0.5  1.2 -0.1 -0.2  1.1  1.8 -0.  -1.4 -0.7  0.4 -0.2 -0.1  0.1 -2.1  0.1 -0.2 -0.4 -1.8 -1.8  6.1 -0.2 -0.1 -0.4 -0.3 -0.  -0.2  2.  -0.8 -0.1 -0.7 -1.5 -0.1 -0.5  1.3  2.  -0.4 -0.  -0.1  0.2 -0.9 -0.4 -1.5 -1.4 -0.7 -0.3 -0.1 -0.1 -0.9 -0.2  0.8 -1.1  0.9 -0.5 -0.2  4.4 -0.5 -1.  -0.4  5.2 -0.1  5.6 -1.8  4.6 -0.2 -0.2 -0.2  0.5 -3.5 -3.7 -0.2 -0.1 -0.4  0.2  1.8 -0.6  0.6  0.4 -0.3 -0.  -0.1 -0.  -1.5  0.  -0.7 -0.2  4.2  0.9 -0.2 -0.2  0.4  1.3  1.5 -0.2 -0.3 -1.1 -0.1 -0.1 -0.8 -0.2 -0.1 -0.8 -0.  -0.1 -0.   0.   0.2  0.2 -0.1  2.3 -0.6 -0.1 -0.2 -0.2 -1.1 -0.6 -0.3 -1.6 -0.1 -0.3 -0.  -0.1 -0.1 -1.1 -0.3 -0.2 -0.1 -0.8 13.3  7.   0.4  1.7 -0.   0.1  0.9 -0.4 -0.3 -0.4 -0.2 -0.2 -0.2  0.2  7.4 -0.4 -0.2 -0.3 -0.6 -1.3 -0.8 -0.5 -0.8 -0.6 -0.5 -0.1  0.2  0.7 -0.6 -1.3 -1.8  0.4 -1.9 -0.8 -0.4  1.9 -0.3 -0.1  0.1  2.5 -0.7 -1.3 -0.4 -0.2  0.5  6.3 -0.2  1.7 -0.3 -0.4  7.6 -1.2 -0.7  0.4 -0.8 -0.5  4.3 -0.1  3.6 -0.3  8.4 -0.6]
ty_50sample [[8 7 3 9 0 4 5 6 2 1]
 [3 4 1 0 9 2 8 6 5 7]
 [9 2 4 1 5 0 6 3 7 8]
 [1 3 5 6 4 8 0 2 9 7]
 [9 3 0 4 8 6 1 5 7 2]
 [0 2 5 1 8 3 4 9 6 7]
 [4 8 8 3 9 5 6 7 0 0]
 [1 8 0 4 3 2 7 9 5 6]
 [9 2 8 1 5 7 6 4 0 3]
 [9 8 1 5 7 6 3 0 4 2]]
tt_50sample [[8 3 7 9 0 4 5 6 2 1]
 [3 4 1 0 9 8 2 6 5 7]
 [9 2 4 1 5 0 6 3 7 8]
 [1 3 5 6 4 8 0 2 9 7]
 [9 3 0 4 8 6 1 5 7 2]
 [0 2 5 1 8 3 4 9 6 7]
 [4 1 8 3 9 5 6 7 2 0]
 [1 8 0 4 3 2 7 9 5 6]
 [9 2 8 1 5 7 6 4 0 3]
 [9 8 1 5 7 6 3 0 4 2]]
vm  [ 0.8 -0.4 -3.7 -2.5 -0.8 -0.1 -0.1 -0.1 -0.4  0.  -2.8 -0.1 -0.3 -0.3 -1.  -0.  -0.  -0.1 -0.2 -0.6 -1.  -0.1 -0.1 -0.3 -1.2  1.2 -0.1 -0.3 -1.  -0.3 -0.1 -0.3  0.6 -5.3 -0.2 -0.2  1.4  2.2 -0.  -0.2 -0.1  3.3 -0.3  0.6 -0.3  0.1  2.  -0.5  3.4 15.7 -0.3 -0.1 -0.6  2.7 -0.3  0.9 -0.6 -2.3  1.1  2.1 -0.4 -0.3 -0.   0.4 -0.8 -0.3 -0.  -0.2  0.4 -0.3 -0.1  2.2  0.  -0.4 -2.7  1.9 -0.1 -0.1 -0.2 -0.1 -3.9 -0.6 -0.1  1.  -1.3  4.9  7.8 -0.2 -0.3  0.2 -0.6  0.1 -0.4 -0.7 -0.6 -0.4 -0.  -2.4 -0.2 -0.6 -0.1  4.  -0.8 -0.1  0.2 -0.7 -1.8 -0.1 -0.8 -0.9 -0.3  0.2 -0.  -0.2  2.9 -1.1 -0.3 -0.5  0.4 -0.2 -0.4  2.2 -0.2 -0.6 -0.4 -1.3 -0.1 -0.1 -0.5 -1.6  0.7 -0.4 -0.3 -0.6  6.6 -3.5  0.1 -0.2 -0.1  0.9 -0.8 -0.7 -0.6 -0.3 -0.4  0.4 -0.5 -0.2  2.8 -0.2  0.9 -0.2  3.3 -0.6 -0.3  0.1 -0.1 -0.9 -0.4 -0.1  1.5 -0.6  0.1 -0.  -0.2 -0.5 -0.3 -0.4 -0.4 -0.1 -0.2 -0.1 -0.  -0.7 -0.2 -0.4 -0.8  0.1  0.3 -0.1 -0.5 -0.6 -0.1 -1.6 -0.1 -0.1  0.6 -0.3  0.2  0.3 -0.1 -0.1 -0.3 -0.5  6.8  1.5 -0.7 -1.1 -0.2 -0.1 -0.3 -0.1  0.5 -0.3 -0.4 -1.5  0.1  0.4  9.3 -0.2 -0.2 -0.9 -0.7 -1.1 -0.1 -0.1 -1.  -0.4 -0.2 -0.2 -0.1 -0.  -0.1 -1.6  4.7 -0.1 -0.2 -0.1 -0.6  2.6 -0.7  1.3 -0.   3.1 -0.3  4.2  1.1 -0.7 -0.1  4.7  0.3  1.4 -0.1 -0.3 11.5 -0.9 -0.  -0.4 -1.  -0.5  9.4 -0.2  0.2 -0.1 -1.7  8.3]
vy_50sample [[8 4 0 2 6 9 5 7 1 3]
 [0 9 8 6 3 2 7 4 5 1]
 [8 3 5 4 9 1 2 6 0 7]
 [9 5 4 6 7 0 2 8 3 1]
 [0 7 8 1 3 4 9 5 6 2]
 [7 8 6 0 0 9 3 5 4 2]
 [9 3 4 7 2 5 8 6 1 0]
 [1 8 5 6 6 2 2 9 3 4]
 [2 7 9 5 4 8 6 1 0 3]
 [1 3 5 0 6 7 2 9 9 8]]
vt_50sample [[8 4 0 2 6 9 5 7 1 3]
 [0 9 8 6 3 2 7 4 5 1]
 [8 3 5 4 9 1 2 6 0 7]
 [9 5 4 6 7 0 2 8 3 1]
 [7 0 8 1 3 4 9 5 6 2]
 [7 8 6 1 0 9 5 3 4 2]
 [9 3 4 7 2 5 8 1 6 0]
 [1 8 5 6 0 7 2 9 4 3]
 [2 7 9 5 4 8 6 1 0 3]
 [1 5 3 0 6 7 2 9 4 8]]
Epoch 43210: Training cost= 0.2447, Training acc= 0.8561, Validation cost= 0.2399, Validation acc= 0.8561
Epoch 43220: Training cost= 0.2202, Training acc= 0.8561, Validation cost= 0.2604, Validation acc= 0.8561
Epoch 43230: Training cost= 0.2492, Training acc= 0.8561, Validation cost= 0.2082, Validation acc= 0.8562
Epoch 43240: Training cost= 0.2278, Training acc= 0.8561, Validation cost= 0.2210, Validation acc= 0.8562
Epoch 43250: Training cost= 0.2764, Training acc= 0.8561, Validation cost= 0.2573, Validation acc= 0.8562
Epoch 43260: Training cost= 0.2524, Training acc= 0.8561, Validation cost= 0.2578, Validation acc= 0.8562
Epoch 43270: Training cost= 0.2469, Training acc= 0.8561, Validation cost= 0.2466, Validation acc= 0.8562
Epoch 43280: Training cost= 0.2345, Training acc= 0.8561, Validation cost= 0.2212, Validation acc= 0.8562
Epoch 43290: Training cost= 0.2613, Training acc= 0.8562, Validation cost= 0.2406, Validation acc= 0.8562
Epoch 43300: Training cost= 0.3199, Training acc= 0.8562, Validation cost= 0.2611, Validation acc= 0.8562
tm  [-0.3 -0.4  4.6  3.9 -1.6 -0.3 -0.  -0.  -0.4 -0.3 -1.4 -0.4 -0.2 -0.3  2.8 -0.3 -0.4 -0.2  0.5 -1.  -1.2 -0.1  1.2 -0.1 -1.   1.6 -0.3 -0.4 -0.7  4.4  0.8 -0.1 -0.   5.4 -0.2 -0.2  2.1 -0.9 -0.3 -0.4 -0.1  1.3  0.5 -0.3 -0.1  0.4  4.8 -0.1  3.1 10.3 -0.3 -0.   0.1 -1.  -0.6 -0.2 -0.4 -2.1 -0.3  1.3 -0.8  0.1 -0.7 -0.1 -0.6 -0.3 -0.  -0.   2.  -0.2 -0.1  0.   0.8 -0.2 -0.4  1.1 -0.  -0.  -0.  -0.2  3.6  0.2 -0.3  0.9 -1.   2.8  4.6 -0.1 -0.4 -0.4 -0.3 -0.2 -0.1 -0.8 -0.4 -0.3 -0.3 -1.5 -0.5 -0.2  0.5  8.7 -0.4 -0.  -0.1  0.4 -0.5 -0.  -0.5 -1.5 -0.6 -0.3  0.4 -0.4  0.9  0.4 -0.1 -0.5 -0.1 -0.4 -0.3  5.3 -0.2 -0.2 -0.1  3.3 -0.2  5.6 -1.1 -2.3  0.4 -0.5 -0.1 -0.5 -0.6  5.8 -0.2 -0.2 -0.6 -0.6 -0.2 -0.6  0.7 -0.2 -0.   0.6  0.3 -0.  -2.6 -0.  -0.4 -0.1  2.8  0.2 -0.   0.1 -0.  -0.4 -1.  -0.4  1.   2.2 -0.1 -0.1 -0.1 -0.6 -0.3 -0.1 -0.2 -0.2 -0.1 -0.2 -0.1 -0.1 -0.1  4.  -0.7 -0.1  1.  -0.1  0.5 -0.3 -0.3 -1.5 -0.2 -0.1  0.1 -0.4  0.3 -1.   0.1 -0.1 -0.6 -0.5  7.9  3.6  0.2 -0.4  0.2 -0.1 -0.  -0.3 -0.3 -0.1  0.4 -0.6  0.1  0.2  7.6 -0.1  0.  -0.4 -0.9 -0.2 -0.8 -0.   1.7 -0.7  0.8  0.4 -0.1 -0.1 -0.2 -1.   6.3  1.4 -0.8 -0.4  1.4  2.8 -0.3 -0.6  0.3  2.1 -0.2 -0.8  1.5  0.6  3.2 16.  -0.1  4.3 -0.  -0.2 -0.1 -1.6 -0.2 -0.2 -1.3 -0.8 -1.  -0.2 -0.  -0.1 -0.6 10.1]
ty_50sample [[7 6 9 8 4 0 2 1 5 3]
 [4 8 5 6 2 1 7 3 9 0]
 [5 2 7 3 4 6 0 8 1 9]
 [5 2 6 3 0 4 8 7 1 9]
 [7 1 4 2 9 6 3 0 5 5]
 [8 5 9 6 7 2 1 3 0 4]
 [0 0 4 2 8 3 1 5 9 6]
 [9 0 7 2 1 3 8 5 6 4]
 [7 4 1 2 5 6 8 3 9 0]
 [0 5 7 4 3 6 1 8 9 2]]
tt_50sample [[7 6 9 8 4 0 2 1 5 3]
 [4 8 5 6 2 1 7 3 9 0]
 [5 2 7 3 4 6 0 8 1 9]
 [5 2 6 3 0 4 8 7 1 9]
 [7 1 4 2 9 6 3 0 5 8]
 [8 9 5 6 7 2 1 3 0 4]
 [7 0 4 2 8 3 1 5 9 6]
 [9 0 7 2 1 3 8 5 6 4]
 [7 4 1 2 5 6 3 8 9 0]
 [0 5 7 4 3 6 1 8 9 2]]
vm  [-0.1 -0.5 -1.  -0.8 -1.  -0.3 -0.2 -0.2  1.5  0.8 10.5 -0.3 -0.2 -0.6  1.3  2.8 -0.2 -0.5 -0.6  1.3 -1.  -0.2  1.8 -0.2 -1.3  3.4  0.1 -0.5 -0.4 -2.3  3.2 -0.4 -1.1  3.3 -0.  -0.  -0.6  3.3 -1.3 -0.4 -0.1  7.8 -0.9 -0.2 -0.1  0.3 -1.5 -0.3  5.7  3.3 -0.3 -0.   0.7 10.5 -0.9 -0.3 -0.2  4.8  8.5 -1.2  2.7 -0.3 -0.1 -0.   2.1 -0.6 -0.2  0.5 -0.4 -0.  -0.5 -0.8 -0.4 -0.3 -4.6 -0.4 -0.  -0.  -0.2  0.5  3.2  2.6 -0.2  0.4 -1.1  8.5  3.5 -0.   0.  -0.3  0.1 -0.1 -0.1 -1.5 -0.7 -0.2 -0.2 -3.6 -0.4 -0.6 -0.5  3.3 -0.7 -0.1 -0.3  0.7 -1.9  1.6  0.2 -0.   1.4 -0.1 -0.4 -0.6  4.   3.7 -0.9  2.1 -0.3 -0.1 -0.4 -0.5 -0.2  1.2 -0.1  1.4 -0.2 -2.   9.9 -0.2  2.8 -0.2 -0.2 -0.   7.2  9.1 -0.1 -0.1 -0.4 -0.4 -0.5 -0.7 -0.8  0.  -0.2 -0.5  0.  -0.   7.4 -0.1 -0.1 -0.3 -0.2 -0.3 -0.3 -0.2 -0.9 -0.1 -0.4 -0.5  0.3 -0.4  0.5 -0.1  0.8 -0.2 -0.9 -0.1 -0.   0.5 -0.2  0.  -0.1 -0.3 -0.1 -1.4 -0.4 -0.2  1.9 -0.1 -1.4 -0.7 -0.5 -2.6 -0.1 -0.1  1.3 -0.5 -0.4  6.6 -0.1 -0.2 -0.4 -1.  -0.2 -3.6 -0.3 -1.3 -0.1 -0.1  1.2 -0.2 -0.3 -0.4 -0.2 -2.1 -0.1 -0.4 -4.8 -0.1 -0.7  1.9 -1.  -0.6 -1.2 -0.1  0.7 -1.2 -0.6 -0.4 -0.2 -0.2 -0.4 -1.1  5.5 -0.5 -0.5 -0.3  2.2  2.7 -0.7 -0.5 -0.7 -1.8 -0.8  1.9  0.7 -0.8  4.5 -4.5 -0.2 -1.5  0.3 -0.4  0.1 -0.2  0.3 -0.3 -1.1 -0.4 -0.9 -0.1 -0.6  0.2 -1.5  3.7]
vy_50sample [[5 2 6 4 0 1 7 9 8 3]
 [1 3 9 2 0 6 8 5 7 4]
 [2 8 5 4 6 1 0 7 3 9]
 [0 7 1 6 5 3 8 2 9 4]
 [4 5 7 3 8 1 2 6 0 9]
 [2 9 8 4 7 3 1 5 6 0]
 [0 8 3 2 1 4 7 5 9 6]
 [3 1 9 8 2 0 6 5 4 7]
 [2 8 9 9 0 7 4 1 5 3]
 [9 9 0 3 7 6 1 5 4 8]]
vt_50sample [[5 2 6 4 0 1 7 9 8 3]
 [1 3 9 2 0 6 8 5 7 4]
 [2 8 5 4 6 1 0 7 3 9]
 [0 7 1 6 5 3 8 2 9 4]
 [4 5 7 3 8 2 1 6 0 9]
 [2 9 8 4 7 3 1 5 6 0]
 [0 8 3 2 1 7 4 5 9 6]
 [3 1 9 8 2 0 6 5 4 7]
 [2 8 9 6 0 7 1 4 5 3]
 [9 2 0 3 7 6 1 5 4 8]]
Epoch 43310: Training cost= 0.2674, Training acc= 0.8562, Validation cost= 0.2606, Validation acc= 0.8562
Epoch 43320: Training cost= 0.2334, Training acc= 0.8562, Validation cost= 0.3036, Validation acc= 0.8563
Epoch 43330: Training cost= 0.2373, Training acc= 0.8562, Validation cost= 0.2201, Validation acc= 0.8563
Epoch 43340: Training cost= 0.2676, Training acc= 0.8562, Validation cost= 0.2349, Validation acc= 0.8563
Epoch 43350: Training cost= 0.2468, Training acc= 0.8562, Validation cost= 0.2782, Validation acc= 0.8563
Epoch 43360: Training cost= 0.2522, Training acc= 0.8562, Validation cost= 0.2308, Validation acc= 0.8563
Epoch 43370: Training cost= 0.2279, Training acc= 0.8562, Validation cost= 0.2764, Validation acc= 0.8563
Epoch 43380: Training cost= 0.2610, Training acc= 0.8563, Validation cost= 0.2460, Validation acc= 0.8563
Epoch 43390: Training cost= 0.3017, Training acc= 0.8563, Validation cost= 0.2454, Validation acc= 0.8563
Epoch 43400: Training cost= 0.2230, Training acc= 0.8563, Validation cost= 0.2501, Validation acc= 0.8563
tm  [-0.6 -0.   6.3 17.4 -1.5 -0.  -0.2 -0.3 -1.1 -0.1 -0.8 -0.2 -0.1 -0.4 -1.  -0.9 -0.1 -0.1  0.7 -0.9 -0.5 -0.3  0.1 -0.2 -1.2  2.8  0.4  0.1 -1.7 -0.2 -1.6 -0.1 -0.4 -2.2 -0.1 -0.1  4.4  4.6 13.6 -0.3 -0.1  6.8  2.3 -0.7 -0.3 -0.2  7.7 -0.6 -0.2 10.2 -0.6 -0.6 -0.  -0.7  1.3  0.9 -0.2 10.7 -2.8  6.6 -1.2 -0.7 -0.4 -0.3 -0.7 -0.4 -0.1 -0.   0.4 -0.5 -0.   5.9 -0.1 -0.4 -0.7 -0.2 -0.1 -0.6  0.  -0.  -0.2 -0.3 -0.2 -0.4 -0.7  6.3 -1.3 -0.2 -0.2 -0.2  0.  -0.4  0.4  2.1 -0.1 -0.1 -0.  -0.6 -0.4 -0.7 -0.3  4.  -0.8 -0.3 -0.2 -0.3 -0.5 -0.4  0.1 -1.1  1.2 -0.3 -0.2  1.6 -0.5 -3.6 -0.1 -1.3 -0.3  0.8 -0.2  4.5  0.3 -0.1 -0.1 -1.3 -0.   3.9 -2.7 -2.5 -0.2  0.6 -0.3  0.2 -2.1 -4.2 -0.3 -0.1  1.2 -0.7 -0.6 -1.3 -0.4 -0.1 -0.3 -0.2 -0.3 -0.1  4.3 -0.5 -1.7 -0.1  1.5 -0.1 -0.2 -0.1 -0.4  0.6  0.6 -0.1  0.  -1.6 -0.  -0.3 -0.1 -0.6 -0.4 -0.6 -0.3 -0.4 -0.1 -0.2 -0.1 -0.4 -0.2 -0.8 -0.3  0.7 -1.2 -0.  -1.7 -0.3  0.  -1.2 -0.1 -0.   0.  -0.5 -0.2 -0.1 -0.3 -0.1 -0.2 -0.8  9.  11.7 -0.2  1.  -0.3 -0.3 -0.2  0.6 -0.3 -0.  -0.2  4.2 -0.1 -0.2 -1.  -0.2 -0.5 -2.2 -0.5  1.2  0.9 -0.3  2.5 -0.6 -0.7 -0.5 -0.3 -0.2 -0.2 -0.7  1.8 -1.5 -0.4  0.5 -0.2 -0.7 -0.6 -0.2 -0.2 -0.3  0.7 -1.4  0.3  0.2 -0.7 -0.8 -0.3 -0.5 -0.3 -0.   1.8 -2.3  0.7 -0.2 -0.7 -0.2 -0.3 -0.2  8.2 -0.  -0.9 10.3]
ty_50sample [[5 0 8 9 2 7 1 6 3 4]
 [7 2 6 8 3 9 0 4 1 5]
 [7 5 4 1 3 2 0 0 8 9]
 [3 2 0 4 8 5 7 9 1 6]
 [0 5 7 3 4 2 6 1 9 9]
 [4 3 6 7 8 2 1 5 5 0]
 [0 2 3 9 7 4 1 5 8 6]
 [6 0 8 3 2 1 4 9 7 5]
 [0 6 7 3 1 2 4 9 8 5]
 [6 7 8 2 4 9 1 5 0 3]]
tt_50sample [[5 0 8 9 2 7 1 3 6 4]
 [7 2 6 8 3 9 0 1 4 5]
 [7 5 4 1 3 2 0 6 8 9]
 [3 2 0 4 8 5 7 9 1 6]
 [0 5 7 3 4 2 6 1 8 9]
 [4 3 6 7 2 1 8 9 5 0]
 [0 2 3 9 7 4 1 5 8 6]
 [6 0 8 3 2 1 4 9 7 5]
 [0 6 7 3 1 2 4 9 5 8]
 [6 7 8 2 4 9 1 5 0 3]]
vm  [-2.  -0.1  8.6 11.3 -1.3  0.3 -0.2  0.1 -0.  -0.4 -0.4  0.  -0.3 -0.2  4.1  2.5 -0.3  1.  -0.1 -0.4 -1.  -0.1  0.4 -0.1 -1.   2.3 -0.5 -0.2 -0.1 -0.5 -0.7 -0.4  0.2  6.  -0.3  0.5  0.6 -0.3 -0.1 -0.4 -0.2  2.5 -0.7 -1.2 -0.2 -0.   0.8 -0.1 -2.  11.5 -0.3 -0.2  0.6 -0.4 -1.3 -0.4 -0.5  3.6  2.5  4.8  6.7 -0.4  0.3 -0.1 -0.5 -0.4  0.1 -0.4  0.1 -0.2 -0.  -1.   0.3  0.9 -2.3  0.4 -0.2 -0.5 -0.1 -0.2  2.3 -0.4  0.7 -0.5  1.8  5.9 -3.1  0.1 -0.2 -0.2 -0.5 -0.  -0.1 -1.  -0.4 -0.3 -0.1 -2.1 -0.5 -0.   0.5  7.9  0.4 -0.1 -0.1  0.4 -0.5 -0.3 -0.1 -1.7 -0.4 -0.4  0.7 -0.6  1.2  7.5 -0.4 -0.3 -0.  -0.5 -0.2  4.8 -0.3  0.5 -0.1  4.9 -0.1  3.4 -0.1 -2.6 -0.3 -0.3 -0.1  0.1 -0.9  4.4 -0.1 -0.2  0.1 -0.5 -0.3 -0.4 -0.3 -0.3 -0.2  0.3  0.1  0.3 -1.7  0.  -0.9 -0.1 -0.9 -0.2  0.2  0.  -0.5 -0.2 -0.1 -0.1  0.  -0.3  0.3 -0.1  0.4 -0.3  0.7  1.1 -0.3 -0.1 -0.1 -0.1 -0.2  0.2 -0.2  2.2 -0.6 -0.   0.9 -0.  -0.5  0.3 -0.2 -1.5 -0.1 -0.5 -0.8 -0.4 -0.   1.9 -0.  -0.1 -0.3 -0.8 -2.2 -0.  -0.  -0.5 -0.2 -0.  -0.1 -0.1 -0.2 -0.5  0.6 -0.1 -0.2 -0.1  4.5 -0.3  1.5  2.8 -0.3 10.  -0.3 -0.2  5.  -0.6 -0.1  0.5 -0.2  0.1 -0.  -1.1  5.1  3.3 -0.9  0.4  0.8 -0.6  0.1 -0.4 -0.2  2.  -0.6 -2.1 -0.5 -0.3  1.7  7.1 -0.2  1.7 -0.  -0.3  0.4 -1.4 -0.8  0.9 -1.1 -0.6 -0.8 -0.2 -0.1  1.6 -1.2 12.3]
vy_50sample [[1 7 6 9 8 2 5 0 4 3]
 [0 2 2 9 5 6 4 3 8 1]
 [5 3 6 8 7 9 2 1 0 4]
 [5 3 6 2 7 7 8 4 1 1]
 [4 1 3 5 6 9 0 7 2 8]
 [9 8 3 4 2 1 7 0 5 6]
 [2 6 3 7 9 4 8 5 0 1]
 [9 7 3 3 0 1 2 4 5 8]
 [3 5 6 7 9 1 0 4 2 8]
 [3 2 5 0 8 9 7 4 6 1]]
vt_50sample [[1 7 6 9 8 2 5 0 4 3]
 [0 2 7 9 5 6 4 3 8 1]
 [5 3 6 8 7 9 2 1 0 4]
 [5 3 6 2 7 8 9 4 0 1]
 [4 1 3 5 6 9 0 7 2 8]
 [9 8 3 4 2 1 7 0 5 6]
 [2 6 3 7 9 4 8 5 0 1]
 [9 7 6 3 0 1 2 4 5 8]
 [3 5 6 7 9 1 0 4 2 8]
 [3 2 0 5 8 9 7 4 6 1]]
Epoch 43410: Training cost= 0.2399, Training acc= 0.8563, Validation cost= 0.2018, Validation acc= 0.8564
Epoch 43420: Training cost= 0.2286, Training acc= 0.8563, Validation cost= 0.2150, Validation acc= 0.8564
Epoch 43430: Training cost= 0.2291, Training acc= 0.8563, Validation cost= 0.2557, Validation acc= 0.8564
Epoch 43440: Training cost= 0.2207, Training acc= 0.8563, Validation cost= 0.3269, Validation acc= 0.8564
Epoch 43450: Training cost= 0.2963, Training acc= 0.8563, Validation cost= 0.2802, Validation acc= 0.8564
Epoch 43460: Training cost= 0.2122, Training acc= 0.8563, Validation cost= 0.3010, Validation acc= 0.8564
Epoch 43470: Training cost= 0.2336, Training acc= 0.8564, Validation cost= 0.2521, Validation acc= 0.8564
Epoch 43480: Training cost= 0.2566, Training acc= 0.8564, Validation cost= 0.2707, Validation acc= 0.8564
Epoch 43490: Training cost= 0.2395, Training acc= 0.8564, Validation cost= 0.2547, Validation acc= 0.8564
Epoch 43500: Training cost= 0.2269, Training acc= 0.8564, Validation cost= 0.2140, Validation acc= 0.8565
tm  [-0.2 -0.3  7.5 11.4 -1.1  0.1 -0.2 -0.1 -0.1  0.3  9.2 -0.2 -0.4  0.   4.4  3.7 -0.2  0.2 -1.1 -0.5 -1.3 -0.1 -0.2 -0.1 -0.7  0.7 -0.2 -0.4 -0.4 -1.4 -0.5 -0.3  0.1  8.5 -0.   0.   0.8  9.8 15.2 -0.5  3.9 -2.2 -0.1  1.5  0.  -0.2  3.8 -0.3  3.6 -0.6 -0.3 -0.2  1.8  8.  -1.5 -0.6 -0.4 -1.2  0.9  4.  -1.1 -0.4  0.7 -0.3  0.4 -1.4 -0.2  0.2 -0.4 -0.4 -0.1 -0.8  1.1  0.8 -2.2 -0.7 -0.4 -0.3 -0.2 -0.4  7.  -0.  -0.1 -0.3 -2.1 -2.4  2.  -0.4  0.  -0.5 -0.3 -0.1 -0.  -0.5 -0.4 -0.3 -0.8 -1.6 -0.3 -0.2 -0.5  2.7 -0.7  0.1 -0.4 -0.  -0.9 -0.2  0.2 -1.5 -0.2 -0.2 -0.3 -0.5 -0.2  3.1 -0.1 -0.4 -0.1 -0.1 -0.3  3.3 -0.1 -0.2 -0.4  5.1 -0.1 -1.5  2.  -0.2 -0.3 -0.3 -0.3  2.  -6.2 -3.   0.  -0.1 -0.  -0.5 -0.6 -0.5 -0.7 -0.1  0.  -0.1 -0.3 -0.  -2.3 -0.1 -1.3 -0.1  3.1  0.5 -0.  -0.2 -0.1 -0.   4.3 -0.4 -0.5 -2.3  0.9 -0.3 -0.   0.   0.9 -0.2 -0.1  0.  -0.2 -0.1 -0.1 -0.  -0.2  4.2 -0.  -0.  -1.3 -0.   0.7 -0.4 -0.1 -1.2 -0.1 -0.4  1.4 -0.2 -0.1  4.  -0.4 -0.1 -0.4 -0.9  9.8 -0.5  0.4 -0.3 -0.2 -0.  -0.2  0.1 -0.5 -0.4 -0.   1.2 -0.5 -0.2  5.6 -0.4 -0.6  2.5 -0.6 -1.  -0.7 -0.3 -1.  -1.2 -0.8  1.1 -0.1 -0.1  0.1 -0.8 -2.   2.1  0.3  0.1 -0.5  1.2  0.  -0.1 -0.3  2.1 -1.  -1.6 -0.2 -0.3  2.1 14.6 -0.4  3.5 -0.2 -0.3 -1.1 -2.1 -0.9 -0.2 -1.   0.6 -2.2 -0.1  9.6 -0.3 -0.1  2.4]
ty_50sample [[2 7 9 3 8 0 4 1 5 6]
 [3 5 7 4 6 2 2 0 1 9]
 [2 0 6 3 8 5 9 1 7 4]
 [5 2 6 1 8 4 3 7 0 9]
 [7 1 5 4 6 2 0 0 3 9]
 [2 0 4 9 5 7 1 6 8 3]
 [2 6 8 4 3 5 7 1 9 0]
 [2 0 6 5 1 3 4 8 7 9]
 [3 8 1 6 0 2 4 9 5 7]
 [9 8 3 0 1 5 4 6 6 2]]
tt_50sample [[2 7 9 3 8 0 4 1 5 6]
 [3 5 7 4 6 2 8 0 1 9]
 [2 0 6 3 8 5 9 1 7 4]
 [5 2 6 1 8 3 4 7 0 9]
 [7 1 5 4 6 2 0 3 8 9]
 [2 0 4 9 5 7 1 6 8 3]
 [2 6 8 4 3 5 1 7 9 0]
 [2 0 6 5 1 3 4 8 7 9]
 [3 8 1 6 0 2 4 9 5 7]
 [9 8 3 0 1 5 4 6 7 2]]
vm  [-0.  -0.5  8.7  0.8 -1.5  0.2 -0.7  0.3  3.1  0.   8.2 -0.2 -0.2 -0.3  9.9 -0.6 -0.4 -0.4  1.   0.4 -1.4 -0.2 -0.4 -0.  -0.9  2.9 -0.3 -0.  -0.9 -4.3  1.  -0.1  0.6 11.7  0.4 -0.2 -0.9  5.4  2.2 -0.4  3.2 -0.4 -1.5 -0.2 -0.1 -0.2 -1.1 -0.1  4.9 -1.4 -0.1 -0.1 -0.3  8.4  0.4 -1.  -1.2  3.  12.7  1.3  1.4 -0.6  0.9  0.2  2.5 -0.4 -0.4 -0.2  3.2 -0.6 -0.2  2.  -0.2 -0.1 -4.6  0.4 -0.6  0.8 -0.1 -0.1  1.4 -0.4 -0.3  1.  -1.2 -0.2 -0.1 -0.3 -0.1 -0.3 -0.6 -0.  -0.4 -1.9 -0.5  0.5  1.  -3.9 -0.9 -0.3  0.   5.3 -0.6 -0.2 -0.1 -0.2 -1.9 -0.1  1.   1.5 -0.2  0.  -0.4 -1.1  8.8 -1.4  0.7  3.6 -0.4 -0.2 -0.6 -0.9  1.2  1.8 -0.3 12.3 -0.2 -1.6 13.8  4.6 -0.6 -0.7 -0.7 -0.7 -5.4  0.   0.2  0.  -0.3 -0.3 -0.3 -1.  -0.4 -0.3 -0.2  0.4 -0.2 -0.1 -1.5 -0.  -0.4 -0.2  1.3 -0.1 -0.1 -0.3 -0.  -0.1  3.8 -0.1 -0.4 -1.9  0.6 -0.1 -0.1 -0.7  0.7 -0.2 -0.1 -0.1 -0.3 -0.1 -0.1 -0.2 -0.3  2.6 -0.3 -0.2  0.6 -0.1 -0.9 -0.5 -0.1 -1.8 -0.1  0.1  1.  -0.1  0.  12.  -0.1 -0.  -0.3 -0.6  1.1 -4.6 -0.8 -2.5 -0.2  0.4 -0.4 -0.2 -0.2 -0.2 -0.2 -2.6 -0.1 -0.6 -0.9 -0.2 -0.6 -0.7 -0.4 -1.5 -0.9 -0.3 -0.  -1.6 -0.3 -0.4 -0.2 -0.2 -0.1 -1.2 -1.  -1.1 -0.8  1.  -0.5  3.2 -0.1 -0.3 -0.1 -0.5  0.8 -2.3 -0.  -0.6  4.6 -0.9 -0.2 -0.4 -0.2 -0.   1.6  0.3 -0.2 -0.3 -1.3  0.6 -0.4  0.1  2.2 -0.3  1.1 -0.7]
vy_50sample [[0 7 2 3 5 1 4 8 6 6]
 [2 1 7 0 4 6 3 9 8 5]
 [6 4 1 2 7 8 9 5 0 3]
 [4 6 2 5 8 0 3 7 9 1]
 [1 0 8 6 2 9 5 7 3 4]
 [9 7 3 1 0 5 8 4 2 6]
 [8 6 0 7 3 9 2 2 1 4]
 [4 6 2 0 7 9 1 8 3 5]
 [6 5 7 0 2 9 4 1 3 3]
 [6 7 0 3 5 8 2 1 9 4]]
vt_50sample [[0 7 2 3 5 1 4 9 8 6]
 [2 1 7 0 4 6 3 9 8 5]
 [6 4 1 2 7 8 9 5 0 3]
 [4 6 2 5 8 0 3 7 9 1]
 [1 0 8 6 2 9 5 7 3 4]
 [9 7 3 1 0 5 4 8 2 6]
 [8 6 0 7 3 9 2 5 1 4]
 [4 6 2 7 0 9 1 8 3 5]
 [6 5 7 0 2 9 4 1 3 8]
 [6 0 7 3 5 8 2 9 1 4]]
Epoch 43510: Training cost= 0.2744, Training acc= 0.8564, Validation cost= 0.2727, Validation acc= 0.8565
Epoch 43520: Training cost= 0.2164, Training acc= 0.8564, Validation cost= 0.1931, Validation acc= 0.8565
Epoch 43530: Training cost= 0.2519, Training acc= 0.8564, Validation cost= 0.2176, Validation acc= 0.8565
Epoch 43540: Training cost= 0.2510, Training acc= 0.8564, Validation cost= 0.2055, Validation acc= 0.8565
Epoch 43550: Training cost= 0.2543, Training acc= 0.8564, Validation cost= 0.2151, Validation acc= 0.8565
Epoch 43560: Training cost= 0.2175, Training acc= 0.8565, Validation cost= 0.3113, Validation acc= 0.8565
Epoch 43570: Training cost= 0.2311, Training acc= 0.8565, Validation cost= 0.2673, Validation acc= 0.8565
Epoch 43580: Training cost= 0.1890, Training acc= 0.8565, Validation cost= 0.1967, Validation acc= 0.8565
Epoch 43590: Training cost= 0.2540, Training acc= 0.8565, Validation cost= 0.2757, Validation acc= 0.8566
Epoch 43600: Training cost= 0.2391, Training acc= 0.8565, Validation cost= 0.2290, Validation acc= 0.8566
tm  [-1.2  0.2 -1.   1.5 -1.3 -0.2  0.3 -0.1 -0.8 -0.2  8.6 -0.1 -0.2 -0.4 -0.6 -0.  -0.1 -0.3 -0.  -0.4 -1.4 -0.2 -0.3 -0.1 -1.5  2.3  0.6 -0.4 -1.1 -1.1  2.3 -0.3 -0.5  5.7 -0.1 -0.1  3.3  3.5  4.4 -0.3  0.2  7.9  2.   1.3 -0.2  0.6  1.1 -0.6 -1.1 -0.3 -0.2 -0.1 -0.1  2.  -0.6  0.4 -0.4  6.5 -0.8 -1.8  3.1 -0.5 -0.3 -0.1  0.2 -0.7 -0.2 -0.1 -0.3  0.4  0.5  2.9  0.2  0.7 -2.5 -0.3  0.3 -0.6 -0.3 -0.2 13.5 -0.1 -0.2 -0.5  0.7  7.8 -0.6 -0.2 -0.1 -0.   0.1 -0.2 -0.1  1.2 -0.5 -0.3 -0.1 -1.8 -0.1 -0.5  0.9  2.4 -0.1 -0.1 -0.2  0.4 -1.5  0.7  0.3 -0.9 -0.2 -0.2 -0.2 -0.   1.1 -0.9 -0.4 -0.8  0.6 -0.  -0.1  3.   0.6  0.1  0.4 -0.7 -0.   0.9 -0.  -1.2 -0.2  0.5 -0.1 -0.1  3.6  7.4 -0.3 -0.2  1.3 -0.5 -0.1 -0.9 -0.4 -0.3 -0.2 -0.  -0.4 -0.2  8.3 -0.3 -0.2 -0.1 -1.8 -0.2 -0.3 -0.2 -1.1 -0.2  1.3  1.   1.6 -0.8  0.1  0.4 -0.  -0.3 -0.5 -0.2  0.2 -0.  -0.2 -0.1 -0.1 -0.3 -0.2 -1.4 -0.2 -0.1 -0.1 -0.1 -1.6 -0.1 -0.2 -1.5  0.3 -0.5 -0.3 -0.7 -0.2  4.  -0.  -0.3 -0.3 -1.  -0.6  1.4 -0.2 -0.1 -0.1 -0.1 -0.  -0.1  0.2 -0.3 -0.2 -0.7 -0.3 -0.2 -6.1  0.2 -0.5 -0.8 -0.7  7.5 -0.2 -0.4 -0.4 -1.1 -0.6 -0.3 -0.1 -0.2 -0.2 -0.7  2.5 -1.1 -0.4  0.1 -0.1 -0.6 -0.6 -0.1 -0.4 -2.2  0.7  2.3 -0.  -0.1  0.2 -3.   0.  -0.9 -0.  -0.1 -2.7 -1.1 -0.5 -0.3 -1.  -0.3 -3.5 -0.   2.7 -0.2 -0.9  6.8]
ty_50sample [[5 1 0 2 9 4 6 7 3 8]
 [0 1 8 3 4 2 9 5 6 7]
 [8 4 5 2 3 1 7 6 0 9]
 [7 4 2 5 1 3 9 8 6 0]
 [0 4 1 8 7 9 3 2 5 6]
 [0 4 2 1 6 8 7 9 3 5]
 [5 1 7 3 2 4 6 8 0 9]
 [8 5 0 9 3 2 4 7 6 1]
 [0 8 9 1 6 5 7 2 4 3]
 [0 7 4 1 3 6 2 9 5 8]]
tt_50sample [[5 1 0 2 4 9 6 7 3 8]
 [0 1 8 3 4 2 9 5 6 7]
 [8 4 5 2 3 1 7 6 0 9]
 [7 4 2 5 1 9 3 8 6 0]
 [0 4 8 1 7 9 3 2 5 6]
 [0 4 2 1 6 8 7 9 3 5]
 [5 1 7 3 2 4 6 8 9 0]
 [8 0 5 9 3 2 4 7 6 1]
 [0 8 9 1 6 7 5 2 4 3]
 [0 7 4 1 3 6 2 9 5 8]]
vm  [ 0.4 -0.3  5.6 -2.4 -1.4 -0.1 -0.1 -0.1 -0.3 -0.6 -0.1 -0.2 -0.1 -0.1 13.1  3.4 -0.3 -0.5 -0.   1.9 -1.  -0.3  0.9 -0.2 -1.5  1.2 -0.1  0.   1.8  3.5  0.9 -0.3 -0.2  6.9 -0.1 -0.  -0.6 -1.1 -5.1 -0.1 -0.4  3.   0.2 -0.8 -0.2 -0.1 -2.3 -0.2  6.   5.5 -0.6 -0.2 -0.1  7.9 -1.  -1.4 -0.5  3.2  1.7  2.3  2.1 -0.3 -0.2  0.6  0.3 -0.  -0.1 -0.   0.8 -0.3 -0.1 -1.9 -0.3 -0.1 -5.1  0.  -0.2  1.   0.2 -0.2 -3.6 -0.1 -0.1  0.7 -1.3  5.   4.7 -0.1  0.1 -0.5 -0.3 -0.1 -0.1 -0.7 -0.5 -0.1  0.4 -3.6 -0.4  0.   1.6  5.4 -0.8 -0.2 -0.3 -0.1 -2.   0.1  0.4  2.6 -0.1 -0.4 -0.3 -1.2 -0.5 13.6 -0.6  0.2 -0.4 -0.1 -0.3 -1.2  0.2 -0.5 -0.  16.1  0.  -1.4  1.9  5.1  0.7 -0.4 -0.2 -0.6  2.6  9.6 -0.1 -0.  -0.5 -0.4  0.4 -0.5  0.  -0.2 -0.1 -0.2 -0.1 -0.  -0.5 -0.2  2.3 -0.2  3.  -0.   0.1 -0.  -0.4 -0.5 -1.  -0.2 -0.3  1.8 -0.1 -0.2  0.1 -0.3 -0.3 -0.2 -0.  -0.2 -0.3  0.3 -0.4 -0.1 -0.2  1.2 -1.2 -0.4  6.5 -0.1 -1.5 -0.2 -0.5 -2.1 -0.1 -0.   0.4 -0.8  0.1 -1.  -0.1  0.3 -0.1 -1.   0.  -0.8 -0.7  0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.2 -0.2 -3.2  0.2 -0.3 -0.7 -0.  -0.8  3.7 -0.5 -1.2 -0.9 -0.1  4.2 -0.8  0.1 -0.2 -0.1 -0.2  0.3 -1.2  4.   3.4 -1.1 -0.1  0.2  4.2  0.7 -0.1 -0.3 -0.3 -1.  -1.2  0.2 -0.7  3.7 -4.3 -0.2 -1.3 -0.1  0.  12.2  3.4  0.  -0.4 -1.  -0.3  9.5 -0.1 -2.9 -0.2  0.2 -0.9]
vy_50sample [[6 7 5 8 4 2 3 1 0 9]
 [5 8 6 7 9 3 2 0 1 4]
 [5 4 3 3 8 0 1 7 6 2]
 [6 0 8 2 1 5 9 7 3 4]
 [5 2 1 7 8 0 3 3 4 6]
 [0 8 6 1 4 3 5 9 2 7]
 [5 7 4 1 8 6 0 2 9 3]
 [8 4 1 7 2 0 3 9 6 5]
 [5 3 8 1 2 0 9 4 7 6]
 [1 9 7 5 4 8 6 0 2 3]]
vt_50sample [[6 7 5 8 4 2 3 1 0 9]
 [5 8 6 7 9 3 2 0 1 4]
 [5 4 9 3 8 0 1 7 6 2]
 [6 0 8 2 1 5 9 7 3 4]
 [5 2 1 7 8 9 3 0 4 6]
 [0 8 6 1 4 3 5 9 2 7]
 [5 7 4 1 8 6 0 2 9 3]
 [8 4 1 7 2 0 3 9 6 5]
 [5 3 8 1 2 0 9 4 7 6]
 [1 9 7 5 4 8 6 0 2 3]]
Epoch 43610: Training cost= 0.2886, Training acc= 0.8565, Validation cost= 0.2280, Validation acc= 0.8566
Epoch 43620: Training cost= 0.2382, Training acc= 0.8565, Validation cost= 0.2715, Validation acc= 0.8566
Epoch 43630: Training cost= 0.2423, Training acc= 0.8565, Validation cost= 0.2415, Validation acc= 0.8566
Epoch 43640: Training cost= 0.2761, Training acc= 0.8565, Validation cost= 0.2645, Validation acc= 0.8566
Epoch 43650: Training cost= 0.1810, Training acc= 0.8566, Validation cost= 0.2629, Validation acc= 0.8566
Epoch 43660: Training cost= 0.2776, Training acc= 0.8566, Validation cost= 0.2197, Validation acc= 0.8566
Epoch 43670: Training cost= 0.2395, Training acc= 0.8566, Validation cost= 0.2064, Validation acc= 0.8566
Epoch 43680: Training cost= 0.3015, Training acc= 0.8566, Validation cost= 0.2651, Validation acc= 0.8567
Epoch 43690: Training cost= 0.2554, Training acc= 0.8566, Validation cost= 0.3059, Validation acc= 0.8567
Epoch 43700: Training cost= 0.2792, Training acc= 0.8566, Validation cost= 0.2551, Validation acc= 0.8567
tm  [-0.3  0.2  4.8  6.4 -1.2 -0.1 -0.3 -0.1 -1.1 -0.3  5.2 -0.3 -0.2 -0.2  3.4  3.7 -0.1 -0.3 -0.2  1.  -0.9  0.3  1.9 -0.  -1.1  1.5  0.1 -0.1 -1.   0.2 -2.  -0.1 -0.6 -3.1 -0.1 -0.   3.   4.8 -2.  -0.5  0.2  3.6  3.5 -0.9 -0.1  0.2 -1.1 -0.2  4.   6.8 -0.4 -0.1 -0.3 12.7 -0.4 -0.5 -0.6 10.8 -1.6  8.5  1.  -0.5 -0.1 -0.2 -0.4  0.1  0.1 -0.2 -0.3 -0.1 -0.2  2.6  0.  -0.  -3.7 -0.4 -0.2 -0.2 -0.  -0.2 -4.3 -0.2 -0.1  0.6 -1.2  4.5 -0.3 -0.3 -0.  -0.1 -0.6  0.4 -0.2  1.5 -0.5  0.9  0.7 -2.5  0.1  0.8  1.7 -0.4 -0.6 -0.1 -0.  -0.2 -2.4 -0.8  1.9 -0.3 -0.1 -0.1 -0.3 -0.3 -0.9 -0.1 -0.7 -1.  -0.2 -0.2  0.1  1.  -0.2 -0.9 -0.2  4.2  0.1 -2.7 -1.2  6.4  0.7 -0.4 -0.  -0.1  6.6 -1.3 -0.2 -0.1 -0.3 -0.1 -1.  -0.7 -0.6 -0.  -0.1 -0.1 -0.3 -0.4  6.  -0.1 -0.8  0.1  2.9 -0.3 -0.1  0.  -0.4 -0.2 -0.6 -0.6  0.4  0.5 -0.1 -0.1 -0.2  0.4 -0.4 -0.8 -0.  -0.1 -0.  -0.  -0.2 -0.2 -0.2 -1.1 -0.7 -0.1  3.  -0.1 -2.2 -0.5 -0.4 -2.  -0.1 -0.3 -0.  -0.4 -0.4  0.3 -0.1 -0.3 -0.1 -0.4  2.   4.7 -0.6  2.6  0.1 -0.3  0.  -0.3 -0.3 -0.3 -0.2 -2.9 -0.1 -0.1 -0.  -0.3 -0.6 -1.  -0.1 -0.7 -0.7  0.   5.5 -1.1 -0.4 -0.5 -0.1 -0.1 -0.3 -1.3  2.1  1.1  1.9 -0.  -0.5  2.8 -0.7  1.3 -0.2  0.3  0.3 -0.8 -0.2 -0.7  1.2 -4.3 -0.1 -1.4 -0.1 -0.1 13.6  2.8 -0.3  1.5 -0.9 -0.4 11.2 -0.1 -1.2 -0.3 -0.8 -1. ]
ty_50sample [[2 5 8 6 0 3 7 9 9 4]
 [8 0 5 2 7 1 9 3 4 6]
 [6 7 2 3 4 0 1 9 5 5]
 [3 9 7 4 8 8 6 5 1 2]
 [1 2 9 8 7 3 6 0 4 5]
 [7 8 2 6 5 5 9 3 9 4]
 [7 6 9 1 0 5 8 2 4 3]
 [6 7 4 2 0 9 5 8 1 3]
 [1 9 7 8 6 2 4 3 5 0]
 [8 0 1 2 3 9 6 5 4 7]]
tt_50sample [[2 5 8 6 0 3 7 1 9 4]
 [0 8 5 2 7 1 9 3 4 6]
 [6 7 2 3 4 0 1 9 8 5]
 [3 9 7 4 8 0 6 5 1 2]
 [1 2 9 8 7 3 6 0 4 5]
 [7 8 2 6 1 5 0 3 9 4]
 [7 6 9 1 0 5 8 2 3 4]
 [6 7 4 2 0 9 5 8 1 3]
 [1 9 7 8 6 2 4 3 5 0]
 [8 0 1 2 3 9 6 5 7 4]]
vm  [-2.1 -0.1 11.8 12.9 -2.1 -0.2 -0.5 -0.1 -1.6 -0.5  6.4 -0.1 -0.3  0.4  7.9 -0.9 -0.9 -0.6 -0.2 -0.5 -1.  -0.2  0.5 -0.3 -1.2  1.5 -0.4 -0.6 -1.7 -0.1 -1.6  0.7 -0.6  8.5 -0.1  0.3  5.5  1.7 -0.8 -0.1  4.7  2.7  3.2 -0.4 -0.1  0.2  1.2  0.4 -2.4  6.6 -0.1 -0.2 -0.4  6.6  0.2 -1.1 -1.   6.6 -2.   5.6  6.3 -0.4 -1.2 -0.6 -0.5  1.1 -0.3 -0.7  2.5 -0.2  0.6  6.8  0.3 -0.1 -1.9 -1.  -0.  -0.5  0.6 -0.2 -0.6 -0.2 -0.1 -0.3  4.   2.9 -2.9  0.  -0.2 -0.7 -0.3  0.5 -0.2  0.8 -0.2  2.3 -0.4 -1.8 -0.1  0.2  1.9  7.4  1.8 -0.4  1.3  0.6 -1.5 -0.1  2.3 -1.2 -1.  -0.4 -0.2  1.2 -0.3 -2.8 -0.  -1.  -0.2 -0.4  1.3  5.1  0.5 -0.  -0.1 10.4 -0.1 -1.  -2.1 -0.9 -0.9 -0.  -0.4 -0.1 -3.1  2.7 -0.2  0.2 -0.5 -0.8 -0.6 -1.1  0.  -0.3 -0.3 -0.2 -0.3 -0.2 -1.5 -0.4 -1.3  0.6 -0.8  0.4  0.3 -0.4  1.  -0.3  0.1 -0.4 -0.9 -0.5 -0.  -0.2 -0.4 -0.1  0.6 -0.6 -0.4 -0.2 -0.1 -0.2  0.2 -0.2 -0.4  1.9 -0.8 -0.6  2.7 -0.2 -1.8 -0.4  0.9 -1.3  0.4  0.9 -1.5 -0.1 -0.1 -0.2 -0.2 -0.1 -0.1 -0.8 -1.9  7.9 -0.4  1.4 -0.2 -0.1 -0.  -0.  -0.5 -0.1 -0.2 -2.4 -0.3 -0.1 -0.3 -0.2 -0.1 -2.5 -0.2  8.5 -1.  -0.5  3.3 -0.6 -0.  -0.3 -0.2  0.5 -0.3 -1.1  0.8 -1.4 -0.2 -0.7  1.5 -1.  -0.3  0.7 -0.1 -0.3  3.2 -2.9 -0.7 -0.5  0.3 -1.3 -0.1 -0.3 -0.   0.2  3.8  2.7 -0.4  3.3 -0.6 -0.3  1.2  0.5 -0.5 -0.3 -0.5  5.4]
vy_50sample [[7 0 0 2 5 6 8 9 3 4]
 [9 7 5 0 4 1 2 8 3 6]
 [3 0 7 7 8 2 4 6 5 1]
 [3 0 5 2 9 4 1 6 8 7]
 [8 0 4 9 7 2 1 6 5 3]
 [3 7 0 2 9 1 8 6 5 4]
 [7 4 5 6 3 9 0 8 2 1]
 [7 4 0 3 6 2 2 1 9 5]
 [5 3 4 0 1 6 9 8 7 2]
 [4 7 2 1 6 8 5 9 3 0]]
vt_50sample [[7 1 0 2 5 6 8 9 3 4]
 [9 7 5 0 4 1 2 8 3 6]
 [3 0 9 7 8 2 4 6 5 1]
 [3 5 0 2 9 4 1 6 8 7]
 [8 0 4 9 7 2 1 6 5 3]
 [3 7 0 2 9 1 8 6 5 4]
 [7 4 5 6 3 9 0 1 2 8]
 [7 4 0 3 6 2 8 1 9 5]
 [5 3 4 0 1 6 9 8 2 7]
 [4 7 2 1 6 8 5 9 3 0]]
Epoch 43710: Training cost= 0.2239, Training acc= 0.8566, Validation cost= 0.2579, Validation acc= 0.8567
Epoch 43720: Training cost= 0.2431, Training acc= 0.8566, Validation cost= 0.2694, Validation acc= 0.8567
Epoch 43730: Training cost= 0.2313, Training acc= 0.8566, Validation cost= 0.3033, Validation acc= 0.8567
Epoch 43740: Training cost= 0.2408, Training acc= 0.8566, Validation cost= 0.2308, Validation acc= 0.8567
Epoch 43750: Training cost= 0.2311, Training acc= 0.8567, Validation cost= 0.2425, Validation acc= 0.8567
Epoch 43760: Training cost= 0.2169, Training acc= 0.8567, Validation cost= 0.2244, Validation acc= 0.8567
Epoch 43770: Training cost= 0.2030, Training acc= 0.8567, Validation cost= 0.2058, Validation acc= 0.8567
Epoch 43780: Training cost= 0.2505, Training acc= 0.8567, Validation cost= 0.2225, Validation acc= 0.8568
Epoch 43790: Training cost= 0.2232, Training acc= 0.8567, Validation cost= 0.2442, Validation acc= 0.8568
Epoch 43800: Training cost= 0.2227, Training acc= 0.8567, Validation cost= 0.2426, Validation acc= 0.8568
tm  [-1.5  0.3  2.4  8.9 -1.4 -0.2 -0.1 -0.3 -0.5 -0.6 -7.2 -0.2 -0.3 -0.  -0.9 -0.6 -0.2 -0.2  2.8 -1.6 -0.8 -0.1  0.3 -0.4 -0.6 -0.4 -0.1 -0.  -0.5  4.1 -0.4 -0.4 -0.2 -1.1 -0.1 -0.3  1.6 -2.4  1.  -0.3 -0.5  2.7 -0.2 -0.9 -0.3 -0.1  7.7  0.8 -0.9 13.5 -0.2 -0.1 -0.4 -4.3 -1.   1.1 -0.6 -0.2 -0.7  3.9 -0.2 -0.3 -0.5 -0.1 -1.2 -0.1 -0.5 -0.5  0.6  0.  -0.  -0.9  0.4 -0.   1.7  0.  -0.4 -0.1 -0.   0.9  2.  -0.6 -0.  -0.3 -0.   3.8 -0.7 -0.2 -0.4 -0.4 -0.4 -0.3 -0.2 -0.7 -0.4 -0.3 -0.4 -0.9 -0.4 -0.2  1.4  5.7  1.1 -0.2  0.2  0.6  0.3 -0.3 -2.3 -2.7 -0.5  0.2 -0.3 -0.4 -0.2  7.3 -0.2 -0.6  0.1 -0.4 -0.4 11.  -0.2  0.7  0.1 -1.2 -0.2 15.2 -1.1 -3.7 -0.2 -0.6 -0.1 -0.5  5.8  2.7 -0.   0.  -0.  -0.1  1.9 -0.1  0.2 -0.1 -0.3 -0.1 -0.2 -0.1 -0.8  0.3 -0.7 -0.1  1.9 -0.3 -0.1 -0.1 -0.1  1.1 -1.1 -0.4 -0.2  1.6 -0.2 -0.1 -0.2  1.8  0.8  1.5  0.7 -0.2 -0.2 -0.3 -0.2  0.3 -0.6  2.3 -0.5 -0.2  0.3 -0.2 -0.8  0.2 -0.1 -1.   0.2 -0.2 -0.7 -0.4  0.3 -0.9 -0.1 -0.  -0.1 -0.7  4.3  4.1  1.3  0.1 -0.2 -0.1 -0.6 -0.1 -0.2 -0.8 -0.2  1.5 -0.2  0.2  7.6  0.1  0.6  1.5 -0.6  5.   0.4 -0.5  3.9 -0.6 -0.3 -0.  -0.2  0.1 -0.2 -1.   6.   3.6 -1.5  0.   0.   1.  -0.2 -0.9 -0.1  1.8 -0.6 -0.6 -0.5  1.   1.7 14.1 -0.3  3.4 -0.3  0.3  0.5 -1.4 -0.   0.1 -1.3 -0.6 -0.6 -0.2  0.8 -0.3  2.  14.6]
ty_50sample [[9 6 8 1 7 4 5 0 3 2]
 [0 0 4 6 8 9 3 1 2 5]
 [1 1 5 0 3 4 9 8 2 6]
 [4 1 0 6 7 7 8 3 2 5]
 [5 1 6 2 0 8 9 7 4 3]
 [1 5 0 7 2 3 9 8 4 6]
 [0 8 4 7 5 2 3 3 6 9]
 [9 4 7 1 2 3 5 8 6 0]
 [2 3 1 7 8 0 5 9 4 4]
 [2 9 8 5 1 0 7 6 4 3]]
tt_50sample [[9 6 8 1 7 4 5 0 3 2]
 [7 0 4 6 8 9 3 1 2 5]
 [7 1 0 5 3 4 9 8 2 6]
 [4 1 6 0 9 7 8 3 2 5]
 [5 1 6 2 0 8 9 7 4 3]
 [1 5 0 7 2 3 9 8 4 6]
 [0 8 7 4 5 2 1 3 9 6]
 [9 4 7 1 2 3 5 8 6 0]
 [2 3 1 7 8 0 5 9 4 6]
 [2 9 8 5 0 1 7 6 4 3]]
vm  [-1.4 -0.  -1.3 -3.1 -1.5  0.3 -0.3 -0.2 -0.8 -0.7  2.4  0.2 -0.4 -0.2  5.1  3.1 -0.1 -0.2  0.3  2.3 -1.2  0.   1.5 -0.3 -1.8  3.7  0.2 -0.4  0.2  1.7  2.8 -0.7 -1.3  3.2 -0.  -0.2  1.2 -0.2 -1.7 -0.3 -0.8 -0.8 -0.2  1.  -0.4  0.5 -1.9 -0.4 -1.4  2.8 -0.4 -0.4  0.6  4.5 -1.7 -0.5 -0.3 -1.9 -0.2 -1.2  9.5 -0.2 -0.   0.5  1.4 -0.1 -0.1  0.4  0.8 -0.   0.4 -1.2  0.6  2.8 -4.2 -0.6 -0.1 -0.8  0.9 -0.2 -1.4  0.9  0.8 -0.4  1.9 -0.1 -0.4 -0.1 -0.2 -0.5 -0.  -0.2  0.1 -0.6 -0.5  0.1 -0.9 -3.  -0.4 -0.1  1.4  3.4 -0.2 -0.4  0.1  2.  -1.4  3.   1.7  1.1 -0.1 -0.4  0.  -0.4 -0.6 11.7 -0.7 -0.5 -0.4 -0.1  0.8 -0.5 -0.1 -0.1 -0.1  6.6 -0.1 -0.5 -0.7  3.9  0.7 -0.   0.7 -0.1  4.   5.4 -0.1 -0.   0.1 -0.6  1.1 -0.7  0.1  0.1 -0.  -0.4 -0.2 -0.3 -0.8  0.3  2.5 -0.2 -1.1  0.4 -0.3  0.2 -0.4 -0.2 -0.3 -0.3  0.4 -0.1  0.3 -0.  -0.2 -0.8 -0.1  1.9  1.2 -0.3 -0.2 -0.1 -0.2  0.3 -0.4  2.4 -0.2 -0.3  3.  -0.1 -0.2 -0.3 -0.5 -3.   0.1  0.2 -0.8 -0.5 -0.1 -0.3 -0.2 -0.  -0.2 -1.7 -3.4  2.1 -0.1  1.4 -0.1 -0.1  0.3  0.  -0.5 -0.5 -0.1 -1.8 -0.2 -0.4  3.9 -0.5 -0.5  2.9 -1.2 11.4 -0.4 -0.2 -0.6 -0.7 -0.3  1.7 -0.3  0.2 -0.5 -1.3  3.7  3.6 -1.3  0.   2.1 -0.6 -0.2 -0.4 -0.2  2.2 -0.6  2.6 -0.1 -0.6  1.8 -0.5 -0.2 -0.2 -0.1 -0.   6.2  0.6 -0.2  1.9 -1.  -0.9  3.2 -0.2 -1.   0.6  0.1 -0.4]
vy_50sample [[1 4 6 7 2 8 3 5 9 9]
 [2 4 1 6 0 9 9 7 3 8]
 [7 9 1 8 4 6 5 3 0 2]
 [5 0 7 6 8 2 9 1 3 4]
 [0 5 1 2 9 8 3 7 4 6]
 [8 6 7 3 5 0 4 2 1 9]
 [9 8 6 4 2 3 1 0 5 7]
 [7 3 6 8 9 9 4 0 1 5]
 [5 1 2 0 3 9 6 7 4 8]
 [8 9 6 7 2 4 1 5 3 0]]
vt_50sample [[1 4 6 7 2 8 3 5 9 0]
 [2 4 1 0 6 5 9 7 3 8]
 [7 9 1 8 4 6 5 3 0 2]
 [5 0 7 6 8 2 9 1 3 4]
 [0 5 1 2 9 8 3 7 4 6]
 [8 6 7 0 3 5 2 4 1 9]
 [9 8 6 4 2 3 1 0 5 7]
 [7 3 6 8 2 9 4 0 1 5]
 [5 1 2 0 3 9 6 7 8 4]
 [8 9 6 7 2 4 1 5 3 0]]
Epoch 43810: Training cost= 0.3116, Training acc= 0.8567, Validation cost= 0.2406, Validation acc= 0.8568
Epoch 43820: Training cost= 0.2557, Training acc= 0.8567, Validation cost= 0.2587, Validation acc= 0.8568
Epoch 43830: Training cost= 0.2910, Training acc= 0.8567, Validation cost= 0.2615, Validation acc= 0.8568
Epoch 43840: Training cost= 0.2892, Training acc= 0.8568, Validation cost= 0.2171, Validation acc= 0.8568
Epoch 43850: Training cost= 0.3258, Training acc= 0.8568, Validation cost= 0.2704, Validation acc= 0.8568
Epoch 43860: Training cost= 0.2218, Training acc= 0.8568, Validation cost= 0.2039, Validation acc= 0.8568
Epoch 43870: Training cost= 0.2376, Training acc= 0.8568, Validation cost= 0.2866, Validation acc= 0.8569
Epoch 43880: Training cost= 0.2722, Training acc= 0.8568, Validation cost= 0.2388, Validation acc= 0.8569
Epoch 43890: Training cost= 0.2700, Training acc= 0.8568, Validation cost= 0.2717, Validation acc= 0.8569
Epoch 43900: Training cost= 0.2413, Training acc= 0.8568, Validation cost= 0.2238, Validation acc= 0.8569
tm  [-0.3 -0.5  3.1 -4.  -2.1 -0.1 -0.3 -0.2 -1.4 -0.5 -1.5 -0.1 -0.4 -0.5 11.8 -2.2  0.4 -0.8  2.1  4.4 -1.2  0.2 -0.5  0.6 -1.6  3.8 -0.1 -0.5 -2.   0.6  1.7  0.4  0.2  5.2 -0.2 -0.2  3.5 -1.8 -6.  -0.3  0.2  3.6  2.3 -0.6 -0.2 -0.4 -3.6 -0.4  3.2 -0.8 -0.2 -0.2 -0.1  5.4  2.8 -1.4 -1.3  6.1 -0.8 -0.3  6.9 -0.3 -0.2 -0.  -0.5  0.8 -0.1 -0.1  3.1  0.6 -0.4  7.5 -0.3 -0.5 -6.5 -0.2 -0.3 -0.4 -0.2  0.3 -3.7  0.3 -0.3 -0.3 -0.6  3.9  1.9 -0.3  0.2 -0.1 -0.4 -0.2 -0.5  2.6 -0.2 -0.4  0.1 -3.5 -0.6 -0.4  0.9  2.3 -0.5  0.1 -0.5 -0.1 -3.1  1.4 -0.5  4.2 -0.3 -0.1 -0.1 -0.   2.1 -3.6  0.1 -0.6 -0.1  0.3  0.2 -1.7 -0.   1.   0.5 14.3 -0.2 -0.6 -0.5 11.8 -0.1 -0.4 -0.4 -0.5  6.4 11.4 -0.  -0.1 -0.4 -0.4  2.3 -1.3  1.8 -0.3 -0.1 -0.2  0.3 -0.1  4.2 -0.2  3.6 -0.2 -0.   0.4 -0.4 -0.1 -0.1 -0.3 -0.9 -0.1 -0.4 -0.1  0.  -0.1 -0.2 -0.5 -0.1 -1.  -0.2 -0.3 -0.3 -0.  -0.3 -0.1 -0.2 -0.5 -0.7 -0.4  7.6 -0.1 -1.8 -0.4 -0.1 -2.1 -0.3 -0.2 -0.4 -0.6 -0.3 -0.1 -0.  -0.3 -0.  -1.3 -2.6  2.4 -1.4 -0.4  0.2 -0.1 -0.1 -0.2  0.3 -0.2 -0.2 -4.  -0.1 -0.4 -3.3 -0.3 -0.3 -2.8 -0.5 -0.1 -0.5 -0.3  2.7 -0.9 -0.5 -0.8 -0.2 -0.2 -0.  -0.9  2.2 -1.8 -2.2 -0.5  2.   0.1  0.6  1.9 -0.2 -1.3  2.4 -0.5  0.6 -1.1  0.9 -7.4 -0.1 -2.2 -0.2 -0.1 12.2  6.8  0.3 -0.2 -0.7 -0.4  9.9 -0.2 -3.8 -0.   5.5 -2.9]
ty_50sample [[0 5 6 7 3 4 1 8 2 9]
 [9 7 0 3 1 6 5 8 4 2]
 [0 1 4 2 7 3 6 8 5 9]
 [5 9 7 4 6 2 1 3 8 0]
 [7 9 1 4 2 3 0 5 6 8]
 [4 6 3 5 1 8 0 9 2 7]
 [2 0 1 1 3 7 9 4 8 6]
 [8 1 4 2 0 3 5 7 6 9]
 [4 2 8 3 1 0 7 5 6 9]
 [8 0 5 3 9 2 6 7 4 1]]
tt_50sample [[0 6 5 7 3 4 1 8 2 9]
 [9 7 0 3 1 6 5 8 4 2]
 [0 1 4 2 7 3 6 8 5 9]
 [5 9 7 4 6 2 8 1 3 0]
 [7 9 1 4 2 3 0 5 6 8]
 [4 6 3 5 1 8 0 9 2 7]
 [2 0 5 1 3 7 9 4 8 6]
 [8 1 4 2 0 3 5 7 6 9]
 [4 2 8 3 1 0 7 5 6 9]
 [8 0 5 3 9 6 2 7 4 1]]
vm  [-0.   0.1  8.5 15.  -0.9 -0.2 -0.5 -0.1 -0.5 -0.8 10.6 -0.1 -0.1 -0.1  0.6  3.2 -0.3 -0.2  0.1 -1.  -1.3 -0.1 -1.4 -0.3 -0.7  1.3  0.  -0.3 -0.5 -1.9  0.3 -0.4  0.2 10.3 -0.2 -0.1  2.3  3.7  2.4 -0.4  0.8 -2.9 -0.3 -1.3 -0.  -0.   3.5 -0.2  4.5 -4.8 -0.2 -0.1 -0.2  2.7 -0.5  0.1 -0.4  4.6  0.9  1.7 -0.9 -0.4 -0.1  0.5 -0.1 -0.3 -0.2 -0.4 -0.1 -0.1 -0.   0.7  0.   1.5 -1.5 -0.3 -0.3 -0.6 -0.  -0.2 16.5 -0.2 -0.1 -0.4 -1.1 -2.4 -0.3 -0.3 -0.2 -0.4 -0.7 -0.2  0.2 -0.1 -0.4  0.3 -0.1 -1.9 -0.1 -0.3  3.4 -1.2 -0.3 -0.1 -0.1  0.  -0.7 -0.3  0.4 -1.5 -0.2  0.2  0.2 -0.6  0.1  2.5 -0.2 -0.3 -0.3 -0.  -0.3  5.6  0.3  0.6 -0.1  0.7 -0.1 -0.   2.   6.9  0.2 -0.2  0.3 -0.4 -0.2 11.7 -0.3 -0.1  0.8 -0.2 -0.9 -0.2 -0.4 -0.1 -0.1 -0.1 -0.3 -0.2 -0.7 -0.  -1.5 -0.1  0.  -0.6 -0.3 -0.1 -0.1 -0.4  0.3 -0.1 -0.2 -0.4  0.3  0.2  0.1  0.3 -0.3 -0.1  0.2 -0.3 -0.2 -0.1 -0.1 -0.3 -0.2  1.8 -0.8 -0.5  0.  -0.1 -0.6 -0.3 -0.5 -1.7 -0.2 -0.1  0.8 -0.6 -0.3  6.1  0.   1.3 -0.3 -1.1  8.2 -0.8 -0.1 -0.2 -0.2 -0.2 -0.3 -0.1 -0.3 -0.4 -0.1 -0.6 -0.1 -0.2 -1.3  0.1 -0.1 -0.1 -0.8 -0.7 -0.4 -0.1  5.8 -1.3 -0.4 -0.2 -0.3 -0.   0.6 -0.8 -1.1 -0.6 -0.1  0.2 -0.4  3.1 -0.4 -0.4 -0.1 -0.5  0.3 -1.9 -0.1 -0.2  0.8  8.6 -0.2  2.7 -0.2 -0.1 -3.3 -1.1 -0.2  0.4 -1.3 -0.4 -4.4 -0.1  1.5 -0.1  2.7 -1.2]
vy_50sample [[3 2 9 7 6 0 5 1 8 4]
 [0 6 4 3 9 5 9 2 8 7]
 [4 0 5 6 8 3 2 1 9 7]
 [4 7 1 2 5 9 6 0 3 8]
 [3 1 5 2 4 9 7 8 0 6]
 [4 1 2 5 9 6 0 3 7 8]
 [3 8 5 7 9 6 2 0 1 4]
 [1 4 5 2 7 6 9 9 8 3]
 [8 7 2 1 0 4 3 6 9 5]
 [1 6 4 5 8 9 3 0 2 7]]
vt_50sample [[3 2 9 7 6 0 5 1 8 4]
 [0 6 4 3 5 9 1 2 8 7]
 [4 0 6 5 8 3 2 1 9 7]
 [4 7 1 2 5 9 6 0 8 3]
 [3 1 5 2 4 9 7 8 0 6]
 [4 1 2 5 9 6 0 3 7 8]
 [3 8 5 7 9 6 2 0 1 4]
 [1 4 5 2 7 6 0 9 8 3]
 [8 7 2 1 0 4 3 6 9 5]
 [1 6 4 5 8 9 3 0 2 7]]
Epoch 43910: Training cost= 0.2275, Training acc= 0.8568, Validation cost= 0.2806, Validation acc= 0.8569
Epoch 43920: Training cost= 0.2206, Training acc= 0.8568, Validation cost= 0.2268, Validation acc= 0.8569
Epoch 43930: Training cost= 0.3008, Training acc= 0.8568, Validation cost= 0.2293, Validation acc= 0.8569
Epoch 43940: Training cost= 0.2889, Training acc= 0.8569, Validation cost= 0.2410, Validation acc= 0.8569
Epoch 43950: Training cost= 0.2510, Training acc= 0.8569, Validation cost= 0.2477, Validation acc= 0.8569
Epoch 43960: Training cost= 0.2615, Training acc= 0.8569, Validation cost= 0.2185, Validation acc= 0.8569
Epoch 43970: Training cost= 0.2576, Training acc= 0.8569, Validation cost= 0.2115, Validation acc= 0.8570
Epoch 43980: Training cost= 0.2393, Training acc= 0.8569, Validation cost= 0.2979, Validation acc= 0.8570
Epoch 43990: Training cost= 0.2523, Training acc= 0.8569, Validation cost= 0.3052, Validation acc= 0.8570
Epoch 44000: Training cost= 0.2150, Training acc= 0.8569, Validation cost= 0.2021, Validation acc= 0.8570
tm  [-1.   0.6 -1.  -5.8 -1.4 -0.1  0.4 -0.2 -1.5 -0.7  8.3 -0.3 -0.3  0.1 12.4  5.  -0.3 -0.4 -0.3  5.3 -1.3 -0.  -0.2  0.8 -2.1  2.2 -0.1 -0.1 -0.6  5.4  3.4 -0.1 -0.9  6.7 -0.2 -0.2  2.6 -0.4 -6.1 -0.4 -0.8  1.1  1.3 -0.3 -0.3 -0.2 -3.5 -0.4 -1.1 -0.1 -0.3 -0.1  0.3 15.8 -1.1 -1.5 -0.6 -0.8 -1.  -2.  10.2 -0.1 -0.3 -0.2  0.4  0.  -0.1 -0.1 -0.2 -0.1 -0.2 -0.6 -0.1 -0.5 -5.6 -0.5  0.1 -0.5  0.2 -0.1 -3.2  0.6 -0.1 -0.   1.7  3.8  0.9  0.4 -0.1 -0.2  0.4 -0.1 -0.   0.8 -0.4  0.2 -0.3 -3.3 -0.  -0.6  2.9  3.7 -0.  -0.4  0.1 -0.3 -3.2  2.   1.3  4.8 -0.1 -0.  -0.1 -0.2 -1.   6.1 -0.9 -1.2 -0.2 -0.4  0.  -2.1 -0.1  0.1 -0.  14.9  0.7 -3.5 -1.3  9.6  0.8 -0.3 -0.1 -0.3  8.8 14.1  1.   0.5 -0.5 -0.3 -0.  -0.6 -0.1 -0.  -0.1 -0.1  0.7 -0.1  0.8 -0.3  4.6 -0.2 -1.2 -0.3 -0.3 -0.1 -1.  -0.3 -1.7 -0.  -0.   2.9 -0.1 -0.1 -0.  -0.2 -0.2  0.8  0.1  0.1 -0.1 -0.1 -0.  -0.2 -0.1  0.8 -0.3 -0.2  7.  -0.3 -0.6 -0.9 -0.3 -2.3 -0.2  0.2 -1.  -0.6 -0.4 -1.3 -0.3 -0.3 -0.  -1.4 -4.2  4.4 -0.9  2.7 -0.2  0.1 -0.2 -0.2 -0.2 -0.7 -0.4 -4.5 -0.2 -0.4 -1.5 -0.1 -0.8  0.2 -0.7  8.5 -0.3 -0.2  1.5 -1.  -0.5 -0.  -0.2 -0.1 -0.4 -1.2  5.7  0.1  1.   0.5  0.5 -0.3  0.6  1.  -0.7 -0.5 -0.2  3.  -0.2 -1.   1.5 -5.   0.  -1.5 -0.1 -0.2 10.6  6.  -0.  -0.  -0.9 -0.7  8.6  0.1 -3.8  0.1 -1.1 -2.1]
ty_50sample [[6 1 4 2 7 5 3 0 8 9]
 [1 3 2 7 9 5 0 6 4 8]
 [7 2 4 1 5 9 0 3 6 8]
 [8 6 5 9 1 3 7 2 0 4]
 [3 7 9 5 6 2 1 0 4 8]
 [3 6 9 4 1 5 8 7 0 2]
 [4 0 6 7 5 2 9 3 1 8]
 [2 8 5 9 6 7 4 0 1 3]
 [1 9 6 6 3 7 2 8 0 4]
 [0 3 5 4 8 9 1 6 7 2]]
tt_50sample [[6 1 4 2 7 5 3 0 8 9]
 [1 3 2 7 9 5 0 6 4 8]
 [7 2 4 1 0 5 9 3 6 8]
 [8 6 5 9 1 3 7 2 0 4]
 [3 7 9 5 6 2 1 0 4 8]
 [3 6 9 4 5 1 8 7 0 2]
 [4 0 6 7 5 2 9 3 1 8]
 [2 8 5 9 6 7 4 0 1 3]
 [1 9 5 6 3 7 2 8 0 4]
 [0 3 5 4 8 9 1 6 7 2]]
vm  [-1.6 -0.1 -2.8 -0.8 -1.2  0.7 -0.1 -0.1  0.2 -0.4  4.5 -0.2 -0.2 -0.2 -1.   3.9  0.2 -0.2 -0.6  0.1 -1.3 -0.   0.3 -0.2 -1.   3.1 -0.1 -0.4 -0.2 -1.4  2.9 -0.4 -0.3 -1.2 -0.  -0.1  0.7  3.5  4.5 -0.3  1.5  3.8 -0.8  2.  -0.3  0.4 -0.  -0.2 -1.  10.3 -0.3 -0.1  0.8  1.9 -0.9  0.6 -0.5 -1.2  5.  -1.1  5.1 -0.1  1.9  1.1 -0.3 -0.2 -0.1 -0.5 -0.6 -0.1 -0.  -0.9 -0.2  1.6 -2.3 -0.1 -0.1 -0.  -0.2 -0.3  3.9 -0.1  0.5 -0.7  1.3  7.  -0.2  0.3 -0.  -0.3 -0.  -0.   0.3 -1.4 -0.5 -0.1 -0.3 -2.5  0.7 -0.2  0.3  3.7 -0.1  0.1 -0.   0.9 -0.6  1.6  1.2 -1.4 -0.5 -0.1 -0.1 -0.9  2.2  8.3 -0.6 -0.3 -0.1 -0.5 -0.2  4.1 -0.2 -0.2 -0.2 -1.3  0.3  0.9  4.1 -2.4 -0.4 -0.3 -0.1 -0.1  4.9  0.2 -0.1 -0.1  0.6  0.1  0.6 -0.4 -0.4 -0.1 -0.1 -0.2 -0.  -0.1  3.8  0.   0.3  0.1 -0.9 -0.3 -0.2  0.1 -0.8  1.1  1.9 -0.3  0.1 -0.7 -0.1 -0.   0.1 -0.1 -0.   1.3  0.5 -0.1  0.3  0.2 -0.2 -0.  -0.2 -0.3 -0.1 -0.2 -0.3 -0.2 -0.5 -0.  -0.6 -1.9 -0.1 -0.5 -0.3 -0.4 -0.2  5.1  0.3  0.2 -0.2 -0.7 -1.4 -1.5  0.1 -0.7 -0.2 -0.  -0.2 -0.1 -0.1 -0.6 -0.1 -0.4 -0.2 -0.1  2.  -0.1  1.9  4.  -0.5  9.1 -0.4 -0.3 -1.2 -1.3 -0.4 -0.  -0.1  0.2 -0.4 -1.1  4.5  3.1 -0.6  0.9 -0.3 -0.2 -0.1 -0.7 -0.2  1.7 -0.   5.4 -0.2 -0.1  3.8  4.5  0.1  1.2 -0.  -0.1 -0.3 -1.1 -0.7  0.6 -1.4 -0.5 -1.2 -0.1  3.3  0.8 -1.5 11.8]
vy_50sample [[1 4 9 2 8 5 6 0 7 3]
 [2 3 9 4 5 8 1 7 7 6]
 [3 2 4 1 1 8 0 9 5 6]
 [9 8 1 0 2 3 4 7 6 5]
 [0 6 5 9 1 8 2 4 3 7]
 [0 6 8 4 5 3 1 7 2 9]
 [9 7 6 0 2 5 4 1 8 3]
 [3 8 2 4 5 7 6 9 0 1]
 [5 7 9 1 0 8 4 3 6 2]
 [1 9 8 0 5 3 6 4 7 2]]
vt_50sample [[1 4 9 2 8 5 6 0 7 3]
 [2 3 9 4 5 8 1 7 0 6]
 [3 2 4 1 7 8 0 9 5 6]
 [9 8 1 0 2 3 4 7 6 5]
 [0 6 5 9 1 8 2 4 3 7]
 [0 6 8 4 5 3 1 7 2 9]
 [9 7 6 0 2 5 4 1 8 3]
 [3 8 2 4 5 7 6 9 0 1]
 [5 7 9 1 0 8 4 3 6 2]
 [1 9 8 0 5 3 6 4 7 2]]
Epoch 44010: Training cost= 0.2226, Training acc= 0.8569, Validation cost= 0.2767, Validation acc= 0.8570
Epoch 44020: Training cost= 0.2206, Training acc= 0.8569, Validation cost= 0.2120, Validation acc= 0.8570
Epoch 44030: Training cost= 0.2529, Training acc= 0.8570, Validation cost= 0.2097, Validation acc= 0.8570
Epoch 44040: Training cost= 0.3062, Training acc= 0.8570, Validation cost= 0.2410, Validation acc= 0.8570
Epoch 44050: Training cost= 0.2402, Training acc= 0.8570, Validation cost= 0.2794, Validation acc= 0.8570
Epoch 44060: Training cost= 0.2726, Training acc= 0.8570, Validation cost= 0.2224, Validation acc= 0.8571
Epoch 44070: Training cost= 0.2869, Training acc= 0.8570, Validation cost= 0.3041, Validation acc= 0.8571
Epoch 44080: Training cost= 0.2442, Training acc= 0.8570, Validation cost= 0.2781, Validation acc= 0.8571
Epoch 44090: Training cost= 0.3065, Training acc= 0.8570, Validation cost= 0.2387, Validation acc= 0.8571
Epoch 44100: Training cost= 0.3147, Training acc= 0.8570, Validation cost= 0.2966, Validation acc= 0.8571
tm  [-1.4 -0.1 -0.4  7.2 -0.8 -0.4 -0.2 -0.2 -0.5 -0.4  4.9 -0.2 -0.1 -0.5 -1.5  4.3  0.3  0.4 -0.1  2.1 -1.5 -0.4  0.9 -0.1 -0.5  1.1 -0.6 -0.3 -0.8 -1.9 -2.3 -0.3 -0.4 -7.5 -0.2 -0.2  1.2  3.2 -3.4 -0.7  1.4 -1.3 -0.1 -1.4 -0.5 -0.4 -1.8 -0.2  1.8  7.  -0.5 -0.2 -0.1 14.1 -1.1  1.2 -0.6  3.4  1.   8.6  4.3 -0.  -0.2 -0.3 -1.1 -0.5 -0.3 -0.4  0.2  0.  -0.3  0.3  0.7  2.1 -4.6 -1.   0.2 -0.6 -0.2 -0.4 -5.2 -0.2 -0.1 -0.2 -0.9 -1.5 -1.  -0.6 -0.3 -0.4 -0.3  0.  -0.4  0.6 -0.2  0.  -0.3 -2.8 -0.5  0.   0.4 -2.  -0.2 -0.4  0.2 -0.2 -2.1 -0.8  2.5 -1.7 -0.6 -0.2 -0.2 -0.5 -0.3  2.6  0.2 -0.3  0.7 -0.2  1.4  2.2 -0.7 -0.  -0.5 -1.6 -0.2 -3.1  0.9  5.9 -0.2 -0.2 -0.1  1.  16.  -0.3  0.  -0.1 -0.4 -0.5 -0.6 -0.4 -0.5 -0.2 -0.1 -0.2 -0.3 -0.1  3.4 -0.2 -1.  -0.   2.2  0.2 -0.1 -0.2 -0.  -1.2 -0.4 -0.8 -0.6  0.6 -0.2 -0.3 -0.6  0.9  0.3 -0.1 -0.3 -0.1 -0.2 -0.3 -0.6 -0.4 -0.1 -0.5 -0.8 -0.3  4.7  0.1 -0.3 -0.2  1.2 -1.1 -0.2  1.3 -0.1  1.9 -0.2  5.4 -0.4 -0.5 -0.1 -0.7 -0.6 -0.4 -0.4  1.  -0.3 -0.3 -0.3 -0.3 -0.2 -0.3 -0.1 -2.1 -0.2 -0.   8.7 -0.5 -0.2 -0.1 -0.9  1.6 -0.4 -0.5  7.7 -1.1 -0.7  0.6 -0.1 -0.2 -0.8 -1.3  1.6  0.4  0.9 -0.2 -0.4  1.  -0.1  0.7 -0.5  2.1 -0.2 -0.  -0.6 -0.9  1.5 -0.6 -0.1 -0.2 -0.2 -0.1 16.1  2.4  0.1  2.7 -0.8  1.1 13.8 -0.1 -1.9  0.  -0.3 -0.9]
ty_50sample [[2 8 6 3 0 1 5 9 4 7]
 [8 7 9 5 3 1 0 6 2 4]
 [3 8 6 1 9 7 5 2 0 0]
 [5 2 8 7 6 1 3 0 9 4]
 [4 5 0 8 6 9 9 7 3 2]
 [2 1 4 6 7 8 5 0 9 3]
 [2 0 3 1 4 6 8 9 5 7]
 [7 3 9 6 0 5 4 8 2 1]
 [2 6 1 4 7 8 8 3 9 0]
 [7 3 6 0 1 1 4 9 2 5]]
tt_50sample [[2 8 6 3 1 0 5 9 4 7]
 [8 7 9 5 3 1 0 6 2 4]
 [3 8 6 1 9 7 5 2 4 0]
 [5 2 8 7 6 1 3 0 9 4]
 [4 5 0 8 6 1 9 7 3 2]
 [2 1 4 6 7 8 5 0 9 3]
 [2 0 3 1 4 6 8 9 5 7]
 [7 3 9 6 0 5 4 8 2 1]
 [2 6 1 4 7 5 8 3 9 0]
 [7 3 6 0 8 1 4 9 2 5]]
vm  [-0.9 -0.4  7.5  2.1 -1.8 -0.2 -0.7 -0.1  2.2 -0.3  1.9  0.5 -0.4 -0.1  7.3 -1.  -0.2 -0.1  1.   0.3 -1.5 -0.1 -0.9 -0.3 -0.8  3.2 -0.4 -0.3 -1.  -4.6  0.2 -0.3 -0.2  8.3 -0.1 -0.2 -0.6  2.5  3.1 -0.3  2.7 -2.3 -1.6 -0.  -0.2  0.1 -1.7  0.4  1.5 -3.8 -0.4  0.5  0.   1.8 -0.7 -0.8 -1.1  4.6 10.9  3.   4.8 -0.2  0.9 -0.1 -0.3 -0.3 -0.1 -0.3  2.2 -0.2 -0.1  0.1 -0.3  0.7 -5.1  1.1 -0.4  0.2  0.4 -0.  -0.1 -0.4  0.2 -0.  -0.7 -1.9 -1.2 -0.2 -0.3 -0.4 -0.9  0.5  0.8 -1.  -0.4  0.1  1.3 -3.7 -1.  -0.2  0.9 -0.8 -0.2  0.3 -0.4 -0.1 -1.8 -0.2  0.9 -0.2 -0.2  0.  -0.1 -1.   6.6 -0.2  1.6  3.1 -0.1 -0.1 -0.4 -0.4  0.5 -0.2 -0.2  9.1 -0.2  1.4 13.  13.8 -0.6 -0.2 -0.2 -0.5 -4.3 -0.8 -0.2 -0.1 -0.2 -0.2  0.8 -0.5 -0.  -0.4 -0.2 -0.2 -0.1 -0.3 -0.8 -0.  -0.5 -0.1 -0.4 -0.2  0.3 -0.1  1.1 -0.3  5.1 -0.4 -0.1 -2.  -0.2 -0.  -0.2 -0.5 -0.2  0.1  0.1 -0.  -0.2 -0.3 -0.3 -0.4 -0.3  2.1 -0.1 -0.4  0.2  0.2 -0.7 -0.3 -0.1 -1.7 -0.4 -0.2 -0.1 -0.4 -0.1 12.9  0.1  0.8 -0.2 -0.7 -1.4 -4.3 -0.4 -1.9  0.1 -0.2  0.2 -0.2 -0.1  0.3 -0.1 -2.2 -0.2 -0.4 -0.6 -0.3 -0.4 -0.4 -0.6  1.3 -0.8  0.7 -0.1 -1.3 -0.1 -0.4 -0.1 -0.1  0.7 -0.8 -2.3 -0.4 -2.3 -0.3  0.5  0.8  0.6 -0.2  0.5 -0.4 -0.4 -1.8  0.1 -0.5  2.4 -1.   0.1 -0.3 -0.1  0.1  2.7  0.8 -0.4 -0.3 -1.3 -0.2  0.1  0.1  2.  -0.2  7.6 -3.4]
vy_50sample [[3 0 7 1 5 8 2 9 6 6]
 [9 8 3 4 6 1 2 7 0 0]
 [3 9 2 6 7 5 0 1 8 4]
 [9 1 2 6 3 7 0 5 8 4]
 [7 7 5 5 0 6 8 4 1 3]
 [6 2 9 7 1 0 4 3 5 8]
 [2 1 4 5 6 7 0 9 3 8]
 [8 7 5 1 9 0 4 3 6 2]
 [1 9 2 6 8 4 3 7 0 5]
 [9 6 8 5 2 0 0 3 4 1]]
vt_50sample [[3 0 7 1 5 8 9 2 4 6]
 [9 8 3 4 6 1 2 7 0 5]
 [3 9 2 6 7 5 0 1 8 4]
 [1 9 2 6 3 7 0 5 8 4]
 [9 7 5 2 0 6 8 4 1 3]
 [6 2 7 9 1 0 4 3 5 8]
 [2 1 4 5 6 7 0 9 3 8]
 [8 7 5 9 1 4 0 3 6 2]
 [1 9 2 6 8 4 3 7 0 5]
 [9 6 8 5 2 7 0 3 4 1]]
Epoch 44110: Training cost= 0.2614, Training acc= 0.8570, Validation cost= 0.2475, Validation acc= 0.8571
Epoch 44120: Training cost= 0.1989, Training acc= 0.8570, Validation cost= 0.2851, Validation acc= 0.8571
Epoch 44130: Training cost= 0.2319, Training acc= 0.8571, Validation cost= 0.2482, Validation acc= 0.8571
Epoch 44140: Training cost= 0.2270, Training acc= 0.8571, Validation cost= 0.2163, Validation acc= 0.8571
Epoch 44150: Training cost= 0.2183, Training acc= 0.8571, Validation cost= 0.2154, Validation acc= 0.8571
Epoch 44160: Training cost= 0.2277, Training acc= 0.8571, Validation cost= 0.2912, Validation acc= 0.8572
Epoch 44170: Training cost= 0.2845, Training acc= 0.8571, Validation cost= 0.2385, Validation acc= 0.8572
Epoch 44180: Training cost= 0.2974, Training acc= 0.8571, Validation cost= 0.3567, Validation acc= 0.8572
Epoch 44190: Training cost= 0.2241, Training acc= 0.8571, Validation cost= 0.2482, Validation acc= 0.8572
Epoch 44200: Training cost= 0.2296, Training acc= 0.8571, Validation cost= 0.3057, Validation acc= 0.8572
tm  [-0.7 -0.3 -3.8 -0.3 -1.6 -0.1 -0.1 -0.1 -0.3 -0.2  6.5 -0.4  0.2 -0.2 -2.5 -0.8 -0.1 -0.6 -0.5 -1.1 -1.1 -0.3  1.4  0.3 -1.   3.9 -0.3 -0.3 -1.3 -1.8  4.5 -0.3 -0.1  3.  -0.2 -0.   2.4  2.6 13.5 -0.3  1.4  4.7 -0.5  4.  -0.1 -0.2  7.1 -0.2 -0.3  4.5 -0.2 -0.1  0.1 -1.6 -0.1  2.7 -0.6 -1.5  2.6 -3.3 -0.6 -0.2  0.1 -0.2  0.8  0.2  0.5 -0.4  0.4 -0.2 -0.   2.5 -0.2 -0.1 -0.   1.1 -0.1  1.  -0.2 -0.2 18.4 -0.1 -0.3 -0.3 -0.2  5.7  3.9 -0.1  0.1 -0.1 -0.3 -0.1  0.  -0.6 -0.4 -0.2  0.4 -1.2 -0.1 -0.4 -0.   3.7 -0.2 -0.  -0.2  0.3 -0.1  3.2  1.5 -1.5 -0.4  0.1 -0.1 -0.1  5.2 -1.8  0.9 -0.5 -0.2  0.  -0.1  6.4 -0.   0.7 -0.  -3.   0.6  7.3  2.  -3.4 -0.6  0.3 -0.3 -0.5  0.1  3.4 -0.2 -0.1  0.8 -0.6  0.5 -1.1 -0.2 -0.2 -0.   0.1  0.5 -0.   4.3 -0.4 -0.2  0.2 -0.8 -0.1 -0.1 -0.1 -0.4 -0.1  2.4 -0.2  1.  -1.2  0.4 -0.1  0.  -0.4 -0.2 -0.2  0.  -0.1 -0.1 -0.  -0.2 -0.3  0.3 -0.6 -0.5  0.4 -1.1 -0.1 -0.6 -0.2 -0.3 -1.5 -0.1 -0.5 -0.2 -0.2 -0.1  5.  -0.1 -0.2 -0.2 -0.9  6.  -0.5  0.4 -1.4 -0.1 -0.1  0.  -0.1  0.4 -0.3 -0.   2.8  0.7 -0.  -2.  -0.  -0.1 -1.2 -0.4  3.6 -0.1 -0.3 -2.  -1.1 -0.4 -0.5 -0.2 -0.3 -0.8 -0.9  2.3 -1.3 -1.4 -0.3  2.2 -0.3 -0.8 -0.9 -0.4 -0.8  1.2  5.5  0.5  0.2  1.3 10.6  0.1  2.7 -0.1 -0.1 -3.8 -2.4 -0.4 -0.2 -1.1 -0.1 -4.6 -0.1  8.1 -0.2 -0.7 14.2]
ty_50sample [[4 9 0 1 5 2 7 6 8 3]
 [6 4 2 3 3 9 7 5 8 1]
 [7 4 5 9 9 8 6 0 2 3]
 [4 8 2 9 1 1 5 0 0 3]
 [5 7 9 0 4 1 2 8 6 3]
 [7 9 0 8 1 4 3 2 6 5]
 [0 7 5 2 3 8 9 1 4 6]
 [5 7 9 3 0 1 8 2 6 4]
 [1 3 7 8 4 4 0 2 6 5]
 [7 8 1 0 0 5 9 6 4 2]]
tt_50sample [[4 9 0 1 5 2 7 6 8 3]
 [6 4 2 3 0 9 7 5 1 8]
 [7 4 5 9 1 8 6 0 2 3]
 [4 8 9 2 7 1 6 5 0 3]
 [5 7 9 0 4 1 2 8 6 3]
 [7 9 8 0 1 4 3 2 6 5]
 [0 7 5 2 3 8 9 1 4 6]
 [5 7 9 0 3 1 8 2 6 4]
 [1 3 7 8 9 4 0 2 6 5]
 [7 8 1 0 3 5 9 6 4 2]]
vm  [-0.9 -0.4  1.4  5.8 -1.5  0.  -0.1 -0.1 -0.2  0.8  6.7 -0.3  0.1 -0.4 -0.4 -0.8  1.  -0.4  0.8 -0.6 -1.1 -0.2  0.4 -0.  -1.1  3.6 -0.1 -0.3 -1.3 -2.8 -0.3 -0.3 -0.5 -1.2  0.1 -0.1  2.7  7.2  9.2 -0.4  0.9  4.1 -0.6  0.4 -0.1 -0.1  2.3 -0.6 -0.8  9.9 -0.1 -0.1 -0.3  7.7  2.3  1.2 -0.6  2.7  4.3  3.4  3.  -0.  -0.2 -0.1 -0.4 -0.1 -0.1 -0.3 -0.2 -0.  -0.1  6.2 -0.1 -0.1 -2.1 -0.1 -0.2  0.5 -0.1 -0.1  0.5  0.  -0.3 -0.5  0.1  5.7 -1.  -0.1  0.6  0.3 -0.3 -0.2 -0.  -0.8 -0.2 -0.2  0.2 -2.3 -0.3 -0.2 -0.5  4.6 -0.5 -0.3 -0.2 -0.1 -1.5 -0.2  0.6 -1.1 -0.3 -0.1 -0.1 -0.3  5.5 -3.3  0.8 -0.5 -0.2  0.8 -0.2  4.  -0.1 -0.  -0.1 -0.6 -0.2 -1.5  2.3 -1.9 -0.5 -0.2 -0.3 -0.1 -1.5 -2.7 -0.  -0.  -0.2  0.1 -0.4 -1.2 -0.4 -0.1  0.3 -0.2  0.2 -0.1  2.8 -0.1 -0.4 -0.2 -0.2 -0.1 -0.  -0.3 -0.2  1.5  1.7 -0.3 -0.  -1.6  0.2 -0.  -0.  -0.5 -0.2 -0.6 -0.2 -0.   0.1 -0.  -0.2 -0.1 -0.1 -0.3  0.3 -0.4 -0.8 -0.1 -0.8 -0.1 -0.5 -1.4 -0.2 -0.3 -0.4 -0.4 -0.2  8.4 -0.2 -0.1 -0.3 -0.5 -0.8 -0.8 -0.7 -1.5 -0.2 -0.  -0.1 -0.  -0.2 -0.  -0.1 -1.1 -0.  -0.1  2.  -0.1  0.4 -1.9 -0.1  2.8 -0.7  0.  -0.3 -1.2 -0.5 -0.4 -0.2 -0.2  0.3 -1.1  2.8 -1.3  1.4 -0.  -0.3 -0.2 -0.6  0.3 -0.1  1.2  3.  -0.1  1.3 -0.8  1.2  2.7 -0.1  0.5 -0.  -0.1  1.7 -0.7  0.1 -0.3 -1.  -0.5 -0.4 -0.2  5.9 -0.1 -2.1  9.3]
vy_50sample [[0 2 1 8 8 5 7 4 6 3]
 [1 2 3 9 5 4 0 7 6 8]
 [4 8 3 1 5 9 6 7 2 0]
 [9 6 2 3 0 8 5 4 1 7]
 [8 3 0 9 6 5 4 7 1 2]
 [6 9 2 5 1 0 4 3 3 7]
 [8 7 4 0 6 5 2 2 1 9]
 [5 7 8 0 2 1 3 9 6 4]
 [7 9 5 3 1 2 6 4 0 8]
 [4 9 6 3 0 5 1 7 8 2]]
vt_50sample [[0 2 1 8 9 5 7 4 6 3]
 [1 2 3 9 5 4 0 7 6 8]
 [4 8 3 1 5 9 6 7 0 2]
 [9 6 2 3 0 8 5 4 1 7]
 [8 3 0 9 6 5 4 7 1 2]
 [6 9 2 5 1 0 4 8 3 7]
 [8 7 4 0 6 5 3 2 9 1]
 [5 7 8 0 2 1 3 9 6 4]
 [7 9 5 3 1 2 6 4 0 8]
 [4 9 6 3 0 5 1 7 8 2]]
Epoch 44210: Training cost= 0.2629, Training acc= 0.8571, Validation cost= 0.2198, Validation acc= 0.8572
Epoch 44220: Training cost= 0.2626, Training acc= 0.8571, Validation cost= 0.3100, Validation acc= 0.8572
Epoch 44230: Training cost= 0.2388, Training acc= 0.8572, Validation cost= 0.2251, Validation acc= 0.8572
Epoch 44240: Training cost= 0.2509, Training acc= 0.8572, Validation cost= 0.2607, Validation acc= 0.8572
Epoch 44250: Training cost= 0.2363, Training acc= 0.8572, Validation cost= 0.2790, Validation acc= 0.8572
Epoch 44260: Training cost= 0.2696, Training acc= 0.8572, Validation cost= 0.2235, Validation acc= 0.8572
Epoch 44270: Training cost= 0.2448, Training acc= 0.8572, Validation cost= 0.2184, Validation acc= 0.8573
Epoch 44280: Training cost= 0.2367, Training acc= 0.8572, Validation cost= 0.2255, Validation acc= 0.8573
Epoch 44290: Training cost= 0.2974, Training acc= 0.8572, Validation cost= 0.2637, Validation acc= 0.8573
Epoch 44300: Training cost= 0.2758, Training acc= 0.8572, Validation cost= 0.2327, Validation acc= 0.8573
tm  [-0.4 -0.7 -3.3 -6.5 -1.2 -0.3 -0.2 -0.1 -0.6 -0.3 -4.2  0.3 -0.4 -0.3  5.3  2.4 -0.1 -0.   0.1 -0.2 -1.2 -0.3 -0.4 -0.2 -1.3 -0.3 -0.1 -0.4  2.2  1.2  3.1 -0.1  0.1 -3.1  0.4 -0.4 -0.2 -0.7 -2.8 -0.1 -0.6 -3.1 -0.8  2.4 -0.4 -0.5 -1.6 -0.6  0.6 -0.4 -0.4 -0.2 -0.8  3.6 -2.3 -0.6 -0.6 -3.6  1.6 -1.   3.4 -0.4 -0.7 -0.1 -0.4 -0.3 -0.2  1.9  2.7 -0.6 -0.4 -2.5 -0.2 -0.5 -5.8  2.  -0.3 -0.  -0.2 -0.2 -6.  -0.3 -0.5 -0.  -1.1 -2.9  6.7 -0.2  0.4 -0.4 -0.1 -0.  -0.4 -0.  -0.9 -0.2 -0.7 -3.2 -0.4 -0.7  0.5 -1.1 -0.4 -0.1 -0.1  0.4 -3.1  1.6 -1.1  1.   1.4 -0.3 -0.1 -0.7 -0.4 13.3  0.6  0.6  0.2  0.2 -0.2 -1.3 -0.2 -0.3 -0.1  6.6  0.3 -0.2  0.2 15.7  1.7 -0.1 -0.  -0.5  4.2 -1.4 -0.4 -0.2 -0.7 -0.4 -0.  -0.4  0.6 -0.3 -0.2 -0.1 -0.5 -0.1 -1.  -0.4  5.5 -0.   1.4 -0.3 -0.1 -0.1 -0.3 -0.7 -0.8 -0.2  0.6 -0.6 -0.2 -0.1 -0.4 -0.6 -0.6  1.  -0.2 -0.3 -0.3 -0.3  0.1 -0.4 -0.3  2.6 -1.4 -0.3  3.2 -0.2  1.4 -0.1  0.8 -2.5 -0.4  1.9  0.7 -0.5  0.6 -0.4 -0.1 -0.2 -0.2 -1.7 -0.6 -0.3 -1.   1.5 -0.2 -0.3 -0.1 -0.3 -0.2 -0.7 -0.2 -3.1 -0.  -0.5  9.9 -0.4 -0.4  3.6 -1.2  0.5  1.2 -0.1 -1.3 -0.5  0.4  1.  -0.4 -0.3 -0.4 -1.6 -0.3  5.  -1.9 -0.3 -0.1  0.1 -0.8  3.3 -0.5  0.8 -2.4  4.2  0.4 -1.5 -0.  -0.1 -0.2 -0.1 -0.5 -0.1 18.   2.4  0.9 -0.6 -1.  -0.5 16.2  0.2 -1.6 -0.3  5.2 -3.7]
ty_50sample [[4 3 8 6 7 1 2 5 9 0]
 [3 1 7 7 5 0 2 4 9 6]
 [9 7 1 3 2 8 5 4 0 6]
 [1 8 7 5 3 9 4 0 6 2]
 [1 5 6 4 2 3 9 0 7 8]
 [5 0 3 8 1 4 2 9 6 7]
 [3 2 1 9 7 6 4 8 0 5]
 [0 3 4 5 6 8 9 7 2 1]
 [4 7 0 9 3 2 6 1 5 8]
 [7 6 9 3 0 4 1 2 5 8]]
tt_50sample [[4 3 8 6 7 1 2 5 9 0]
 [3 1 7 8 5 0 2 4 9 6]
 [9 7 1 3 2 8 5 4 0 6]
 [8 1 7 5 3 9 4 0 6 2]
 [1 5 6 4 2 3 9 0 7 8]
 [5 0 3 8 1 4 2 9 6 7]
 [3 2 1 9 7 6 4 8 0 5]
 [0 3 4 5 6 8 9 7 2 1]
 [4 7 0 9 3 2 6 1 5 8]
 [7 6 9 3 0 4 1 2 5 8]]
vm  [-0.7 -0.2 -2.  -3.5 -2.   0.4 -0.2  0.1 -1.3 -0.5  0.7 -0.4 -0.1 -0.2  4.1 -1.5 -0.3 -0.7 -0.1 -0.1 -1.2 -0.4 -0.  -0.2 -1.3  2.6 -0.2 -0.4 -1.5  3.4  3.8 -0.1 -0.6  6.7 -0.1 -0.1  3.9 -1.  -1.4 -0.3 -0.3  3.2  0.6  1.6 -0.6 -0.1 -0.5 -0.3  1.3  7.1 -0.4 -0.1 -0.  -0.1  0.2 -0.5 -0.6 -2.1 -0.8 -2.9  2.9 -0.7 -0.1 -0.3 -0.6  0.3 -0.  -0.6  1.8 -0.3  0.3  5.4  0.2  0.4 -2.7 -0.5 -0.4 -0.6  0.5 -0.3  2.7 -0.1 -0.  -0.7 -0.6  4.5  6.9 -0.2  0.  -0.4 -0.4 -0.1 -0.2 -0.2 -0.4  0.2 -0.7 -2.2 -0.2 -0.3  0.3  5.8 -0.4 -0.3 -0.  -0.  -1.4  3.2  0.8 -1.2 -0.7 -0.3 -0.2  0.2  2.1 -2.3 -0.6 -0.7  0.1 -0.2 -0.1  3.8 -0.   1.1 -0.4  5.  -0.1  2.8 -1.2 -1.9  1.1 -0.1 -0.3 -0.2  3.   8.4 -0.3 -0.   0.6 -0.4  1.9 -1.1  0.7 -0.1 -0.2 -0.1 -0.2 -0.1 -0.7 -0.   2.6  0.1 -0.3  1.6 -0.2 -0.2 -0.4 -0.2 -0.6 -0.1 -0.9 -0.1  0.6 -0.1 -0.4 -0.2 -0.  -0.4 -0.1 -0.2  0.1 -0.2 -0.2 -0.2 -0.5  2.1 -0.2 -0.2  2.6 -0.1 -0.8  0.5 -0.2 -1.8  0.   0.5 -0.2 -0.5 -0.3 -0.8 -0.2 -0.1 -0.1 -1.3 -0.4  4.3 -0.4 -0.3 -0.2 -0.1 -0.3 -0.1 -0.6 -0.3 -0.1 -1.3 -0.1 -0.  -0.5 -0.3  2.2 -1.6 -0.7  2.2  0.2 -0.5 -1.  -1.  -0.3  0.2 -0.3 -0.1 -0.9 -1.3  4.7 -1.3 -2.1 -0.5  1.3  0.5 -0.2 -0.2 -0.4 -0.2  2.2  2.7 -0.3 -0.5  1.9 -0.  -0.1 -0.1 -0.2 -0.  -0.  -0.4 -0.5  0.4 -0.9 -0.2 -0.8  0.  -0.7 -0.1 -0.1  9.2]
vy_50sample [[4 0 6 7 1 5 9 8 2 3]
 [0 1 9 9 4 6 2 8 7 5]
 [8 1 9 7 2 6 3 4 5 0]
 [9 8 4 2 3 6 0 1 7 5]
 [7 7 6 9 4 3 5 1 0 8]
 [2 7 8 1 9 5 4 3 6 0]
 [8 5 9 1 3 4 4 6 7 0]
 [1 7 5 9 3 6 0 4 8 2]
 [9 5 8 7 4 2 0 1 6 3]
 [9 4 7 6 1 3 5 0 8 2]]
vt_50sample [[4 0 6 7 1 5 9 8 2 3]
 [0 1 9 3 4 6 2 8 7 5]
 [8 1 9 7 2 6 3 4 5 0]
 [9 8 4 2 3 6 0 1 7 5]
 [7 6 2 9 4 3 5 1 0 8]
 [2 8 7 1 9 5 4 3 6 0]
 [8 5 9 1 2 3 4 6 7 0]
 [1 7 5 9 3 6 0 4 8 2]
 [9 5 8 7 4 2 0 1 6 3]
 [9 7 4 6 1 3 5 0 8 2]]
Epoch 44310: Training cost= 0.2488, Training acc= 0.8572, Validation cost= 0.2720, Validation acc= 0.8573
Epoch 44320: Training cost= 0.2748, Training acc= 0.8572, Validation cost= 0.2385, Validation acc= 0.8573
Epoch 44330: Training cost= 0.1927, Training acc= 0.8573, Validation cost= 0.2283, Validation acc= 0.8573
Epoch 44340: Training cost= 0.2327, Training acc= 0.8573, Validation cost= 0.2494, Validation acc= 0.8573
Epoch 44350: Training cost= 0.2101, Training acc= 0.8573, Validation cost= 0.2705, Validation acc= 0.8573
Epoch 44360: Training cost= 0.2192, Training acc= 0.8573, Validation cost= 0.1953, Validation acc= 0.8574
Epoch 44370: Training cost= 0.3535, Training acc= 0.8573, Validation cost= 0.2493, Validation acc= 0.8574
Epoch 44380: Training cost= 0.2266, Training acc= 0.8573, Validation cost= 0.2448, Validation acc= 0.8574
Epoch 44390: Training cost= 0.2333, Training acc= 0.8573, Validation cost= 0.2726, Validation acc= 0.8574
Epoch 44400: Training cost= 0.2721, Training acc= 0.8573, Validation cost= 0.2794, Validation acc= 0.8574
tm  [-1.2 -0.2  8.8 15.7 -1.4  0.  -0.1  0.2 -0.6 -0.5 -1.5  0.5 -0.1 -0.4  1.2  5.2 -0.1  0.2 -0.1 -1.8 -0.9 -0.2 -0.6 -0.2 -0.8 -0.3 -0.4  0.7  2.1 -0.2 -1.1 -0.4 -0.5  3.5  0.2  0.   1.9  2.6 13.1 -0.3 -0.6 -3.8 -0.3 -0.5 -0.2 -0.2  8.1 -0.2 -1.7 -1.7 -0.1 -0.2 -0.3 -1.4 -2.1 -0.2 -0.2  0.8 -0.9  5.2  2.5 -0.4 -0.7 -0.4 -0.2 -0.2 -0.4  0.6  0.1 -0.5 -0.1 -2.6 -0.8 -0.4 -0.3  0.8 -0.3 -0.1 -0.2  0.5  4.   1.  -0.5 -0.2  1.8 -3.3 -2.2 -0.2 -0.1 -0.2 -0.3 -0.  -0.3  0.8 -0.6 -0.2 -0.4 -0.9 -0.1 -0.3  1.6 -0.9 -0.2 -0.1 -0.2 -0.2 -0.6 -0.4 -0.3 -1.7  1.8 -0.3 -0.1 -0.3 -1.3 13.6 -0.9 -0.9 -0.6 -0.7  0.6  5.5 -0.2  0.  -0.1  1.2  0.2  6.5 -1.4  5.6  0.3 -0.  -0.2 -0.  -3.3 -2.7 -0.3 -0.2 -0.2 -0.4 -0.5 -0.2 -0.6 -0.2 -0.  -0.4 -0.3 -0.1 -2.  -0.2 -1.7 -0.3 -0.5 -0.2 -0.1 -0.  -0.1 -0.4 -0.2  0.1 -0.2 -1.2 -0.3 -0.   0.5 -0.1 -0.5  1.3  0.1 -0.2 -0.1 -0.2  0.3  0.2 -0.2  2.6 -0.1 -0.3 -1.4 -0.2  0.3  0.8  0.4 -1.8 -0.1 -0.4 -0.5 -1.  -0.1  0.6 -0.2  0.5 -0.2 -1.2 -0.2  4.3  0.   4.3 -0.3 -0.1 -0.1 -0.1 -0.4 -0.3 -0.1  1.  -0.2 -0.1  7.4  0.2 -0.3  4.3 -0.7  5.7 -0.1 -0.2  2.1 -0.4 -0.6 -0.1 -0.3 -0.3 -0.4 -0.7 -1.5  5.5 -1.2 -0.1  1.4 -0.6 -0.9 -0.1 -0.4  1.1 -1.8 -2.1 -0.3 -0.3 -0.3 17.2 -0.3  5.  -0.3 -0.1 -0.3 -1.7 -0.5 -0.4 -0.9 -0.4 -1.1  0.4  8.1 -0.1  5.  -0.8]
ty_50sample [[3 1 7 9 8 2 6 5 5 0]
 [4 1 6 9 3 0 5 8 2 7]
 [3 1 6 8 0 5 2 4 7 9]
 [5 2 4 3 8 9 1 0 7 6]
 [2 6 6 1 4 0 5 8 7 3]
 [8 3 0 7 9 2 6 5 4 1]
 [5 8 3 2 6 4 0 1 9 7]
 [6 5 8 9 7 1 3 0 2 4]
 [1 8 0 4 6 2 9 3 5 7]
 [2 0 7 5 1 9 8 6 4 3]]
tt_50sample [[3 1 7 9 8 2 6 4 5 0]
 [4 1 6 9 3 0 5 8 2 7]
 [3 1 6 8 0 2 5 4 7 9]
 [5 2 4 3 8 9 1 0 6 7]
 [2 6 9 1 4 0 5 8 7 3]
 [8 3 0 7 9 2 6 5 4 1]
 [5 8 3 2 6 4 0 1 9 7]
 [6 5 8 9 7 1 3 0 2 4]
 [1 0 8 4 6 2 9 3 5 7]
 [2 0 5 7 1 9 8 6 4 3]]
vm  [-0.9  0.3 -3.5 -0.5 -1.3 -0.2  0.3 -0.  -0.8 -1.5  6.9 -0.5 -0.2 -0.2 -1.8  0.2 -0.2 -0.4 -0.9  0.2 -1.6 -0.3 -1.3  0.5 -1.2  1.7 -0.6 -0.6 -1.1 -2.4  3.7 -0.1 -0.2  3.7 -0.2 -0.   2.6  1.2  3.1 -0.2  4.7 -1.6  0.8  3.9 -0.1 -0.2  0.3 -0.1 -0.3 -4.6 -0.4 -0.1 -0.3  0.1 -0.6  1.5 -0.7 -0.7  2.7 -3.4  2.6 -0.5 -0.2 -0.3 -1.1 -0.2  0.1 -0.4 -0.1 -0.  -0.  -0.2  0.7  1.3 -1.5 -0.3 -0.2 -0.  -0.2 -0.7 16.9 -0.2 -0.  -0.8 -0.1 -1.2  1.2 -0.3 -0.1 -0.5 -0.3 -0.2 -0.1  0.8 -0.8 -0.1  0.4 -2.1  0.5 -0.7  5.4 -2.6  1.5 -0.1 -0.4 -0.5 -0.8  1.4  0.7 -1.4 -1.   0.3 -0.1 -0.1  0.5  5.   1.1 -0.7  0.  -0.8 -0.2  4.7  0.3 -0.  -0.5 -2.4  0.3  2.8  5.7  4.5 -0.4 -0.4 -0.4 -0.5  6.9 10.2 -0.2 -0.2  0.7 -0.4  2.1 -0.5 -0.1 -0.2 -0.1  0.1 -0.1 -0.1  5.7 -0.2 -0.1  0.2 -1.6  0.  -0.2 -0.3 -0.  -0.   2.9  1.6 -0.5 -0.6 -0.  -0.2 -0.2  0.3  1.3 -0.1 -0.1 -0.3 -0.  -0.  -0.2 -0.  -0.2 -0.9 -0.5 -0.5  0.3 -0.2 -1.  -0.3 -0.6 -1.8 -0.1 -0.4 -0.3  0.4 -0.5  6.5 -0.   0.4 -0.2 -1.1 -0.4 -1.8  0.1 -0.1 -0.3 -0.  -0.5  0.  -0.1 -0.4 -0.2 -0.9 -0.2 -0.  -3.7 -0.1 -0.3  0.6 -0.7  5.6 -0.7 -0.8 -1.4 -1.1 -0.7 -0.1 -0.2  0.2 -0.3 -1.  -1.8 -1.  -1.5 -0.5  1.1  0.4 -0.4 -0.7 -0.5 -1.4  1.7  4.9 -0.5 -0.3  2.3  2.4 -0.1  0.6 -0.1 -0.2 -3.5 -0.8 -0.5 -0.3 -1.4 -0.  -4.5 -0.1  1.6 -0.1  7.9 -0.4]
vy_50sample [[3 4 4 9 5 0 2 6 7 8]
 [6 1 2 4 3 7 5 0 9 8]
 [2 3 7 5 4 0 9 6 1 1]
 [6 3 8 4 1 2 7 5 9 0]
 [7 2 5 0 1 8 9 3 4 6]
 [4 0 8 8 2 6 9 3 7 5]
 [9 8 3 5 0 7 4 1 6 2]
 [7 1 8 5 6 6 2 3 9 0]
 [2 3 5 5 4 6 1 7 0 9]
 [8 6 0 1 9 2 4 5 3 7]]
vt_50sample [[3 4 1 9 5 0 2 6 7 8]
 [6 1 2 4 3 7 0 5 9 8]
 [2 3 7 5 4 0 9 6 8 1]
 [6 3 8 4 1 2 7 5 9 0]
 [7 2 5 0 1 8 9 3 4 6]
 [4 0 1 8 2 9 6 3 7 5]
 [9 3 8 5 0 7 4 6 1 2]
 [7 1 8 5 4 6 2 3 9 0]
 [2 3 5 4 8 6 1 7 0 9]
 [8 0 6 1 9 2 4 5 3 7]]
Epoch 44410: Training cost= 0.2715, Training acc= 0.8573, Validation cost= 0.2796, Validation acc= 0.8574
Epoch 44420: Training cost= 0.2289, Training acc= 0.8573, Validation cost= 0.2802, Validation acc= 0.8574
Epoch 44430: Training cost= 0.2585, Training acc= 0.8574, Validation cost= 0.2035, Validation acc= 0.8574
Epoch 44440: Training cost= 0.1966, Training acc= 0.8574, Validation cost= 0.2036, Validation acc= 0.8574
Epoch 44450: Training cost= 0.2489, Training acc= 0.8574, Validation cost= 0.2380, Validation acc= 0.8574
Epoch 44460: Training cost= 0.3044, Training acc= 0.8574, Validation cost= 0.2845, Validation acc= 0.8575
Epoch 44470: Training cost= 0.2714, Training acc= 0.8574, Validation cost= 0.3317, Validation acc= 0.8575
Epoch 44480: Training cost= 0.2305, Training acc= 0.8574, Validation cost= 0.2273, Validation acc= 0.8575
Epoch 44490: Training cost= 0.2953, Training acc= 0.8574, Validation cost= 0.2307, Validation acc= 0.8575
Epoch 44500: Training cost= 0.2377, Training acc= 0.8574, Validation cost= 0.2462, Validation acc= 0.8575
tm  [-0.5 -0.5  2.6  2.9 -0.7 -0.3 -0.4 -0.3 -0.1  0.8  5.1 -0.  -0.3 -0.2  1.2  1.2 -0.5 -0.3  0.5 -0.1 -1.  -0.4 -0.6 -0.2 -0.8 -0.5 -0.6 -0.3 -0.3 -4.1 -1.6 -0.2 -0.7 -4.6 -0.2 -0.3 -0.2  5.4  0.8 -0.4 -0.1 -0.3 -1.1 -0.2 -0.3 -0.4 -1.2 -0.1 -1.1 -2.2 -0.5 -0.2 -0.6 15.6 -1.7 -0.2 -0.6 10.4  6.4  6.2  5.2 -0.7 -0.9 -0.5 -0.  -1.2 -0.3  1.7  1.9 -0.6 -0.3 -1.5 -0.5 -1.1 -6.5 -0.7 -0.1 -0.3 -0.1 -0.1 -5.   1.2 -0.6  1.4 -0.4 -0.6 -1.8 -0.3  0.2 -0.4 -0.1 -0.2 -0.1  0.7 -0.9 -0.1 -0.9 -3.1 -0.4 -0.5 -0.2 -3.   0.1 -0.1 -0.4 -0.4 -4.3 -0.3  1.4  0.3  1.2 -0.2 -0.2 -0.6 -0.2  4.5  1.2  2.3 -0.5  0.2 -0.4 -1.2 -0.5  0.  -0.5  1.4  0.3 -3.5 11.  18.4  0.2 -0.3 -0.2 -0.  -0.1 -4.2 -0.1 -0.4 -0.7 -0.9 -0.4 -0.1 -0.1 -0.1 -0.1 -0.4 -0.3 -0.2  7.6 -0.2 -0.7 -0.3  0.4  1.  -0.3 -0.1  0.7 -1.   0.1 -0.7 -0.9 -1.5 -0.2 -0.3 -0.5  0.2 -0.5 -0.1 -0.3 -0.1 -0.3 -0.2 -0.1  0.4 -0.2 -2.  -0.1 -0.6 -0.  -0.2 -2.2 -0.8 -0.3 -2.  -0.4  0.6 -0.5 -0.3 -0.4 11.  -0.4 -0.4 -0.5 -1.5 -2.1 -3.6 -1.5  1.5 -0.3 -0.3 -0.3 -0.2 -1.  -0.3 -0.1 -4.  -0.3 -0.2 -2.3 -0.1 -1.  -0.  -0.9 -0.2 -0.2 -0.   1.2 -1.1 -0.5 -0.1 -0.1 -0.2 -0.2 -1.2 -2.4  2.6 -0.4 -0.7  0.3  0.3 -1.2  5.3 -0.4 -0.9 -1.4 -0.5  1.3 -1.9 -0.2 -7.7 -0.3 -2.4 -0.1 -0.1 15.6  4.5  3.1 -0.5 -0.8 -0.  13.4 -0.2  0.3 -0.4  3.6 -4.8]
ty_50sample [[3 5 2 8 1 0 7 6 4 4]
 [9 8 7 6 2 3 1 5 4 0]
 [7 3 9 1 0 8 6 4 5 2]
 [0 4 3 5 8 9 6 7 2 1]
 [3 8 7 0 9 4 5 6 1 2]
 [7 8 5 6 1 4 9 2 2 0]
 [5 3 7 4 2 1 6 0 9 8]
 [6 7 5 3 2 0 8 1 9 4]
 [1 0 3 9 8 4 5 7 6 2]
 [3 3 8 5 4 9 6 1 2 7]]
tt_50sample [[3 5 2 8 1 0 7 6 4 9]
 [9 8 7 6 2 1 3 5 4 0]
 [7 3 9 1 0 8 6 4 5 2]
 [0 4 3 5 8 9 6 7 2 1]
 [3 8 7 0 4 9 5 6 1 2]
 [7 5 8 6 1 4 9 2 3 0]
 [5 3 7 4 2 1 6 0 9 8]
 [6 7 5 3 2 0 8 1 9 4]
 [1 0 3 9 8 4 5 7 6 2]
 [0 3 8 5 4 9 6 1 2 7]]
vm  [-1.4 -0.   4.5  9.1 -1.4 -0.3  0.4  0.1 -0.8 -0.7 -0.8  0.  -0.3  0.8  0.4  6.2 -0.1  0.2  0.2 -1.2 -0.8 -0.2  0.5 -0.  -1.  -0.2 -0.1 -0.1  0.7  5.  -1.1 -0.   0.1 -1.2 -0.  -0.1  2.7  3.4  7.9 -0.1  1.5 -0.7  2.6  0.1 -0.1 -0.3  6.4 -0.5 -2.2 11.4 -0.1 -0.1 -0.1  1.5 -1.8 -0.1 -0.4 -1.1 -2.1  5.   2.4 -0.3 -0.6 -0.4 -0.5 -0.3 -0.5 -0.1  0.  -0.3  0.  -2.  -0.2 -0.4  0.6 -0.3  0.7 -0.1 -0.1 -0.1 -0.7  0.1 -0.3 -0.3  2.4 -0.3 -1.5 -0.2 -0.1 -0.2 -0.2 -0.2 -0.3  0.7 -0.4 -0.4 -0.3 -0.8 -0.1 -0.   2.4  4.7  0.7  0.2 -0.1 -0.4 -0.6 -0.5 -0.1 -1.4 -0.1 -0.4 -0.2 -0.1 -1.7 12.3 -0.4 -1.6 -0.3 -0.2  0.5  5.1 -0.2 -0.   0.4  0.2  0.3  0.6 -2.7 -2.1 -0.5 -0.2 -0.4 -0.1 -1.7 -3.2 -0.2 -0.1 -0.4 -0.2 -0.5 -0.2 -0.5 -0.1 -0.  -0.2 -0.2  0.3 -1.6 -0.1 -1.  -0.2  0.3 -0.2  0.  -0.2 -0.3  1.5 -0.2 -0.  -0.2 -0.7 -0.3 -0.  -0.  -0.4 -0.3  1.   0.   0.1 -0.2 -0.2  0.7 -0.3 -0.2  2.3 -0.6 -0.2 -0.9  0.1 -0.   1.3  0.5 -1.5 -0.2 -0.1 -0.8 -0.8 -0.  -1.3 -0.3 -0.2  0.1 -0.9 -0.2  9.4  0.2  4.5 -0.2  0.  -0.3 -0.1 -0.2 -0.4  0.   0.5 -0.1 -0.1 10.5 -0.1 -0.2  3.9 -0.2  8.5 -0.2 -0.4 -0.  -0.3 -0.4  0.5 -0.2 -0.1 -0.1 -0.8  2.1  5.1  0.5 -0.1 -0.5 -0.8 -0.6 -0.4 -0.1  2.3 -1.1 -0.6 -0.4  0.1 -0.1 16.5 -0.   4.6 -0.3 -0.1  3.6 -1.5 -0.6 -0.2 -0.9 -0.4  0.6  0.3  5.  -0.3 -1.   8.9]
vy_50sample [[8 1 2 7 7 6 4 3 5 0]
 [1 2 9 6 3 7 7 8 0 5]
 [3 0 0 8 7 6 2 4 9 5]
 [7 2 1 3 8 5 4 0 0 6]
 [9 1 0 7 4 4 2 8 5 6]
 [8 3 7 2 1 0 4 5 9 6]
 [4 5 8 9 1 3 0 2 7 6]
 [7 9 5 8 2 4 3 1 6 0]
 [0 7 2 4 6 5 3 1 9 8]
 [3 7 8 0 4 6 5 9 2 1]]
vt_50sample [[8 1 2 9 7 6 4 3 5 0]
 [1 2 9 6 3 4 7 8 0 5]
 [3 0 1 8 7 6 2 4 9 5]
 [7 2 1 3 8 5 4 9 0 6]
 [9 1 0 7 4 3 2 8 5 6]
 [8 3 7 2 1 0 4 5 9 6]
 [4 5 8 9 1 3 0 2 7 6]
 [7 9 5 8 2 4 3 1 6 0]
 [0 7 2 4 6 5 3 1 9 8]
 [3 7 8 0 4 6 5 9 2 1]]
Epoch 44510: Training cost= 0.2610, Training acc= 0.8574, Validation cost= 0.2569, Validation acc= 0.8575
Epoch 44520: Training cost= 0.2561, Training acc= 0.8574, Validation cost= 0.2800, Validation acc= 0.8575
Epoch 44530: Training cost= 0.2502, Training acc= 0.8575, Validation cost= 0.3304, Validation acc= 0.8575
Epoch 44540: Training cost= 0.2440, Training acc= 0.8575, Validation cost= 0.2752, Validation acc= 0.8575
Epoch 44550: Training cost= 0.2672, Training acc= 0.8575, Validation cost= 0.2553, Validation acc= 0.8575
Epoch 44560: Training cost= 0.2267, Training acc= 0.8575, Validation cost= 0.2550, Validation acc= 0.8575
Epoch 44570: Training cost= 0.2433, Training acc= 0.8575, Validation cost= 0.2368, Validation acc= 0.8576
Epoch 44580: Training cost= 0.2582, Training acc= 0.8575, Validation cost= 0.2528, Validation acc= 0.8576
Epoch 44590: Training cost= 0.2693, Training acc= 0.8575, Validation cost= 0.2114, Validation acc= 0.8576
Epoch 44600: Training cost= 0.2445, Training acc= 0.8575, Validation cost= 0.2431, Validation acc= 0.8576
tm  [-0.4 -0.7  5.8  4.1 -1.9 -0.1  0.3 -0.3 -1.1  2.1 -0.4 -0.4 -0.2  0.1  6.  -2.8 -0.  -0.6 -0.  -0.8 -0.7  0.5 -0.4 -0.2 -1.   2.5 -0.1  0.6 -1.8 -0.1  2.4 -0.5 -1.1 16.1  0.5 -0.3  2.2 -1.5  2.5 -0.4 -0.8  5.   0.  -0.2 -0.5 -0.   1.4 -0.6  1.7 -1.   0.5 -0.3 -0.2 -2.6  2.2 -0.6 -0.5  4.7 -0.4 -1.5 -0.3 -0.4 -0.4  0.2  0.5 -0.7 -0.3 -0.4  0.7 -0.1  0.3  8.2 -0.4 -0.3 -2.7 -1.2 -0.4 -0.7 -0.3  1.  15.2  0.1 -0.2 -0.7 -1.2  5.4  1.3 -0.1 -0.3 -0.1  0.  -0.2  0.1  0.2 -0.4 -0.1 -0.9 -1.9 -0.  -0.3 -1.3  6.  -0.5 -0.1 -0.1  1.  -1.2  0.8 -0.1 -1.5  1.   0.2 -0.3 -0.1  4.7 -4.5 -0.9  0.   0.5 -0.1 -0.2  5.3 -0.5  0.5 -0.   7.7 -0.1 10.3 -0.2 -0.6  1.7  1.  -0.1  1.9 -2.4 11.3 -0.1  0.1 -0.4 -0.2  2.2 -1.1  0.1 -0.3  0.1 -0.3 -0.5 -0.  -0.  -0.3 -0.5 -0.3 -0.8  0.4 -0.1 -0.2 -0.3 -0.6 -0.8 -0.5  0.4 -1.1 -0.   0.1  0.7 -0.1 -0.8 -0.7 -0.2 -0.1 -0.1 -0.2 -0.1  0.2 -0.   0.6 -0.1 -0.1  0.   0.1 -2.  -0.1 -0.2 -1.8  0.3  0.1 -0.2 -0.6  0.6 -0.  -0.  -0.2 -0.1 -0.9  4.1  2.1 -0.5 -1.3 -0.1 -0.  -0.1 -0.1 -0.  -0.4 -0.1 -0.4 -0.1  0.1 -4.8  0.1 -0.5 -2.7 -0.6  0.4 -0.7 -0.2  1.1 -1.  -0.6 -0.3 -0.2 -0.   0.1 -1.2  3.6 -2.5 -2.7 -0.1 -1.1 -0.1 -0.7  0.3 -0.2 -1.8  1.6 -1.2  1.  -0.6 -0.1 -1.9 -0.2 -0.7 -0.2 -0.1 -3.  -0.8 -0.5 -0.1 -0.8 -0.7 -4.1 -0.   1.3 -0.4  2.7  3.9]
ty_50sample [[0 7 5 6 6 4 1 3 8 2]
 [1 6 4 0 8 2 3 7 5 9]
 [8 2 1 4 3 7 0 5 6 9]
 [3 0 9 1 5 2 8 7 6 4]
 [2 0 5 6 4 1 3 8 7 9]
 [6 5 0 3 1 7 4 8 2 9]
 [7 2 6 8 5 0 3 1 4 9]
 [9 8 4 0 2 7 3 6 1 5]
 [1 6 4 8 7 3 0 5 2 9]
 [2 4 8 5 1 3 9 7 6 0]]
tt_50sample [[0 7 5 6 9 4 1 3 8 2]
 [1 6 4 0 8 2 3 7 5 9]
 [8 2 4 1 3 7 5 0 6 9]
 [3 0 9 1 5 2 8 7 6 4]
 [2 0 5 6 4 1 3 8 7 9]
 [6 5 0 3 1 7 4 8 2 9]
 [7 2 6 8 5 0 3 1 4 9]
 [9 8 4 0 2 7 3 6 1 5]
 [1 6 4 8 7 3 0 5 2 9]
 [2 4 8 5 1 3 9 7 6 0]]
vm  [ 1.3 -0.2  6.   7.1 -1.6 -0.3 -0.3 -0.1 -0.1  0.7 -1.  -0.2 -0.2 -0.2  3.5 -1.  -0.1 -0.6 -0.  -0.1 -1.  -0.3 -0.5 -0.2 -0.7  3.1 -0.2 -0.  -0.8 -1.4 -0.7 -0.4 -0.6  3.1 -0.1 -0.3 -0.4 -1.8 -3.3 -0.1 -0.3 -0.3 -0.4 -1.6 -0.1  1.  -1.   0.1 10.  -0.9 -0.2 -0.  -0.1 -0.   0.8 -0.5 -0.5  6.8  4.1  4.5 -0.7 -0.4 -0.3  0.8 -0.4  0.4  0.5 -0.3  1.  -0.2  0.7  3.1 -0.4  2.8 -4.   0.  -0.5  0.6 -0.  -0.3 -0.4 -0.4  0.2  0.  -2.1  0.8  2.9 -0.1 -0.  -0.5 -0.5 -0.  -0.2 -1.2 -0.7  0.3  0.7 -3.4 -0.2 -0.2 -0.5 -0.5 -1.1 -0.1 -0.2  0.2 -1.  -0.4 -0.4 -0.7 -0.3 -0.  -0.  -0.7  4.4 -1.  -0.4  1.8 -0.2 -0.2 -0.4  2.6  0.4 -0.5 -0.3  4.1 -0.2  3.2  4.5  6.1  0.9 -0.4 -0.5 -0.4  9.2 12.  -0.  -0.   0.  -0.4  0.5 -0.9  0.8 -0.2 -0.1 -0.1 -0.3 -0.2  2.8 -0.  -0.8 -0.1  3.2 -0.  -0.1  0.2 -0.3 -0.4 -0.9 -0.3 -0.2  1.2 -0.1 -0.  -0.  -0.  -0.1 -0.7 -0.1 -0.2 -0.2 -0.  -0.3 -0.3 -0.  -0.1 -0.8 -0.1  4.9 -0.  -1.5  0.  -0.5 -1.8 -0.  -0.2  1.3 -0.6 -0.3  3.8 -0.3 -0.1 -0.1 -0.5  8.6 -1.5 -0.2 -1.4 -0.2 -0.2 -0.  -0.1 -0.   0.  -0.2 -1.8 -0.  -0.3 -0.7 -0.2 -0.8 -1.  -0.7 -2.2 -1.  -0.2  8.  -1.  -0.3 -0.7 -0.2 -0.   0.1 -1.2  2.8 -0.6 -2.1  0.1  2.6  5.2  1.9 -0.5 -0.2 -0.4  1.  -1.4 -0.1 -0.1  4.3 -1.3 -0.1 -0.3  0.1  0.5  3.5  0.8 -0.1 -0.1 -1.2 -0.2  0.5  0.2 -2.  -0.4  5.2 -1.1]
vy_50sample [[6 0 3 5 7 8 9 2 4 1]
 [2 9 0 5 4 7 8 6 3 1]
 [7 8 8 4 9 6 5 3 2 1]
 [1 7 2 6 9 5 8 4 0 3]
 [3 7 9 8 0 5 6 2 4 1]
 [2 7 5 3 1 0 0 9 4 6]
 [0 8 6 4 3 7 9 9 2 1]
 [5 0 2 9 6 4 7 3 1 8]
 [0 0 4 2 6 3 1 7 8 5]
 [2 7 5 0 3 8 9 1 6 6]]
vt_50sample [[6 0 3 5 7 8 9 2 4 1]
 [2 9 0 5 4 7 8 6 3 1]
 [7 0 8 4 9 6 5 3 2 1]
 [1 7 2 6 9 5 8 4 3 0]
 [3 7 9 8 0 5 6 2 4 1]
 [2 5 7 3 1 0 8 9 4 6]
 [0 8 6 4 3 7 9 5 2 1]
 [5 0 2 9 6 4 7 3 1 8]
 [0 9 4 2 6 3 1 7 8 5]
 [2 7 5 0 8 3 9 1 4 6]]
Epoch 44610: Training cost= 0.2193, Training acc= 0.8575, Validation cost= 0.2332, Validation acc= 0.8576
Epoch 44620: Training cost= 0.2328, Training acc= 0.8575, Validation cost= 0.3252, Validation acc= 0.8576
Epoch 44630: Training cost= 0.2702, Training acc= 0.8575, Validation cost= 0.2372, Validation acc= 0.8576
Epoch 44640: Training cost= 0.2406, Training acc= 0.8576, Validation cost= 0.2225, Validation acc= 0.8576
Epoch 44650: Training cost= 0.2321, Training acc= 0.8576, Validation cost= 0.2520, Validation acc= 0.8576
Epoch 44660: Training cost= 0.2196, Training acc= 0.8576, Validation cost= 0.2841, Validation acc= 0.8576
Epoch 44670: Training cost= 0.2790, Training acc= 0.8576, Validation cost= 0.2518, Validation acc= 0.8577
Epoch 44680: Training cost= 0.2485, Training acc= 0.8576, Validation cost= 0.2213, Validation acc= 0.8577
Epoch 44690: Training cost= 0.2058, Training acc= 0.8576, Validation cost= 0.2522, Validation acc= 0.8577
Epoch 44700: Training cost= 0.2049, Training acc= 0.8576, Validation cost= 0.2419, Validation acc= 0.8577
tm  [-1.1 -0.1 -1.5 -3.3 -1.2 -0.2 -0.2 -0.  -0.9 -0.9  6.9 -0.2 -0.1 -0.1  5.1  6.5 -0.1 -0.2 -0.6 -0.4 -1.5 -0.1  0.5 -0.1 -1.5  0.1 -0.1 -0.5 -0.2  0.5  2.3 -0.3 -0.4  0.7 -0.  -0.2  3.3  6.9  1.4 -0.4  1.5 -2.4  1.2  3.9 -0.2  0.4 -0.5 -0.3 -0.9  1.8 -0.2 -0.1 -0.5 10.9 -1.6 -0.6 -0.8 -3.4 -0.3 -0.9  6.   0.8 -0.3  0.5 -0.2  0.7 -0.3  0.1 -0.3 -0.  -0.1 -1.2 -0.3  0.3 -2.8 -0.2 -0.2 -0.1 -0.1  0.3 -1.9  0.3 -0.3  0.7  1.1 -2.1  3.  -0.2 -0.1 -0.4 -0.5 -0.  -0.4  0.4 -0.4 -0.2 -0.2 -2.4  0.1 -0.3  3.4  0.6 -0.2  0.2 -0.1  0.2 -2.1  1.3  1.1 -0.8 -0.4  0.1 -0.4 -0.3 -0.6  8.3 -0.4 -1.2 -0.2 -0.5 -0.   1.7  0.4  0.1 -0.   6.3 -0.2 -2.3 -0.7  5.8 -0.1 -0.3 -0.2 -0.2 -1.3 -1.7 -0.4 -0.2 -0.2 -0.3 -0.9 -0.4 -0.8 -0.2 -0.2 -0.4 -0.2 -0.1 -1.4  0.1  1.6 -0.1 -0.4 -0.8 -0.2 -0.2 -0.7  0.4  0.7 -0.3  1.6 -0.6 -0.2 -0.2 -0.5  0.2 -0.3 -0.   0.   0.5 -0.1 -0.2 -0.2 -0.1 -0.1  2.2 -0.2 -0.3  0.   0.1  1.7 -0.1 -0.4 -1.7 -0.4 -0.6 -0.4 -0.5 -0.3 -0.  -0.2 -0.4 -0.4 -1.2 -1.8  1.8 -0.4  1.4 -0.1 -0.1 -0.1 -0.2 -0.3 -0.6 -0.  -2.9 -0.1 -0.3  8.   0.5 -0.5  1.5 -0.5  5.4 -0.3 -0.3 -1.8 -0.9 -0.6 -0.2 -0.1 -0.2 -0.2 -1.2 -0.5  4.3  3.5  0.2  1.1 -0.1 -0.8  0.8 -0.4  2.1 -0.3  3.5 -0.3 -0.6  0.9  9.4 -0.1  3.5 -0.3 -0.2  7.2  2.2 -0.5 -0.  -0.9 -0.6  4.6 -0.1  0.8 -0.1 -1.  -0.9]
ty_50sample [[2 4 1 8 8 7 6 9 0 5]
 [0 4 8 7 3 1 6 9 2 5]
 [2 6 4 3 7 5 9 0 1 8]
 [1 0 4 7 8 3 9 5 2 6]
 [7 3 5 0 1 9 2 8 4 6]
 [6 8 7 5 3 4 2 0 0 9]
 [3 5 0 1 1 4 7 6 2 8]
 [3 6 4 5 9 9 8 0 7 2]
 [8 3 1 4 0 5 6 9 7 2]
 [9 6 2 7 3 5 1 8 4 0]]
tt_50sample [[2 4 1 3 8 7 6 9 0 5]
 [0 4 8 7 3 1 6 9 2 5]
 [2 6 4 3 7 5 9 0 1 8]
 [1 0 4 7 8 3 9 5 2 6]
 [7 3 5 0 1 9 2 8 4 6]
 [6 8 7 5 3 4 2 1 0 9]
 [3 5 0 1 9 4 7 6 2 8]
 [3 6 4 5 1 9 8 0 7 2]
 [8 3 1 4 0 5 6 9 7 2]
 [9 6 2 7 3 5 1 8 4 0]]
vm  [-1.  -0.3  5.8 14.5 -2.  -0.1  1.1 -0.1 -1.3  0.9 -2.9  0.8 -0.1 -0.5 -0.4 -1.8 -0.3 -0.3 -0.5 -1.6 -1.  -0.  -0.3 -0.1 -1.2  2.3 -0.  -0.2 -1.6 -0.8 -0.2 -0.4 -0.2  5.3 -0.2 -0.1  5.2  0.4 16.9 -0.3  1.3 -2.9 -0.1  1.5 -0.2 -0.4 10.1 -0.2 -2.3 -0.7 -0.3 -0.1 -0.  -3.4  0.5 -0.1 -0.3 -1.9 -1.1  3.1  2.2 -0.2 -0.3 -0.3 -0.  -0.3 -0.  -0.   0.6 -0.3 -0.3  4.3 -0.8 -1.3  4.2 -0.2 -0.1 -0.5 -0.1  1.1  9.9  2.  -0.4  0.8  2.8 -2.6 -1.5 -0.2  0.2 -0.2  0.1 -0.1 -0.2  1.1 -0.3 -0.2 -0.7  1.2 -0.1 -0.1 -0.8  1.  -0.4 -0.2 -0.1 -0.4 -0.2 -0.  -1.  -1.6  1.1 -0.1 -0.2  2.1  1.8 -4.  -0.6 -1.4 -0.4 -0.2  0.6  6.  -0.3 -0.1 -0.1 -0.6  0.2 11.8 -2.4 -0.3 -0.4  0.1 -0.3  0.  -3.6 -2.5 -0.1 -0.1  0.  -0.8  0.5 -0.9 -0.  -0.3  0.5 -0.3 -0.1 -0.2 -2.3 -0.4 -1.5 -0.2 -1.1 -0.1 -0.2 -0.1 -0.4 -0.2 -0.  -0.5  0.5 -1.5 -0.1 -0.2  0.8  0.3 -0.5 -0.3 -0.4  0.4  0.2 -0.2 -0.4 -0.1 -0.1  3.4 -0.1 -0.1 -1.6 -0.1  2.7 -0.6  0.8 -1.6 -0.3 -0.5 -1.3 -0.6 -0.   1.9 -0.3 -0.4 -0.3 -1.3 -0.2  9.  -0.3 -0.3 -0.  -0.1 -0.2 -0.1  0.  -0.1 -0.   3.3  0.4  0.2  7.7 -0.1 -0.9 -2.7 -0.6  8.2 -0.5  0.7 -0.6 -0.5 -0.5 -0.  -0.3 -0.2  0.5 -0.2 -0.9 -1.5 -1.7 -0.   1.6 -1.3 -0.5 -0.4 -0.4  1.6 -0.  -1.   1.   0.4 -0.2 24.8  0.2  7.4 -0.1 -0.1 -1.8 -2.4 -0.  -0.4 -0.4 -0.5 -2.7 -0.2 10.2 -0.   5.1  2.6]
vy_50sample [[1 0 9 3 7 8 4 6 2 5]
 [7 2 0 5 9 4 3 6 6 1]
 [6 5 1 7 3 2 4 8 9 0]
 [4 2 7 9 1 0 5 8 6 3]
 [8 1 3 5 4 7 6 2 9 0]
 [3 2 8 1 5 5 7 0 0 4]
 [6 5 5 8 0 4 7 1 9 3]
 [8 4 2 3 7 5 6 1 9 0]
 [6 9 5 4 1 3 2 0 8 7]
 [5 6 3 0 7 4 9 2 1 8]]
vt_50sample [[1 9 0 3 7 8 4 6 2 5]
 [7 2 0 5 9 4 3 6 8 1]
 [6 5 1 7 3 2 4 8 9 0]
 [4 2 7 9 0 1 5 8 6 3]
 [8 1 3 5 4 7 6 2 9 0]
 [3 2 8 1 5 6 7 9 0 4]
 [2 6 5 8 0 4 7 1 9 3]
 [8 4 2 3 7 5 6 9 1 0]
 [6 9 5 4 1 3 2 0 8 7]
 [5 6 3 0 7 4 9 2 1 8]]
Epoch 44710: Training cost= 0.2511, Training acc= 0.8576, Validation cost= 0.2075, Validation acc= 0.8577
Epoch 44720: Training cost= 0.2118, Training acc= 0.8576, Validation cost= 0.2060, Validation acc= 0.8577
Epoch 44730: Training cost= 0.2620, Training acc= 0.8577, Validation cost= 0.2154, Validation acc= 0.8577
Epoch 44740: Training cost= 0.2264, Training acc= 0.8577, Validation cost= 0.2412, Validation acc= 0.8577
Epoch 44750: Training cost= 0.2633, Training acc= 0.8577, Validation cost= 0.2682, Validation acc= 0.8577
Epoch 44760: Training cost= 0.2356, Training acc= 0.8577, Validation cost= 0.2422, Validation acc= 0.8578
Epoch 44770: Training cost= 0.2634, Training acc= 0.8577, Validation cost= 0.2516, Validation acc= 0.8578
Epoch 44780: Training cost= 0.2112, Training acc= 0.8577, Validation cost= 0.2308, Validation acc= 0.8578
Epoch 44790: Training cost= 0.2435, Training acc= 0.8577, Validation cost= 0.2583, Validation acc= 0.8578
Epoch 44800: Training cost= 0.2299, Training acc= 0.8577, Validation cost= 0.2102, Validation acc= 0.8578
tm  [ 0.4 -0.6  4.2 -1.3 -1.7 -0.2 -0.3 -0.1 -0.7 -0.6  4.4 -0.4 -0.2 -0.3  7.9 -0.4 -0.1 -0.4 -0.1 -0.4 -1.2 -0.1 -0.2 -0.2 -1.3  3.  -0.5 -0.2 -0.5  4.2  2.9  0.3 -0.2 13.2 -0.1 -0.2  1.9 -0.9 -1.2 -0.3  1.1  4.8  2.   0.5 -0.  -0.1 -0.3 -0.   6.  -0.6 -0.4 -0.  -0.   0.4 -0.5 -0.8 -0.8  2.5 -0.8 -2.  -1.  -0.4 -0.4 -0.  -0.2 -0.  -0.1 -0.5  1.7  0.5 -0.1 -0.1 -0.   0.7 -2.5 -0.4 -0.   1.1 -0.1 -0.5  6.5 -0.3  0.2  0.4 -1.4  4.6  7.7 -0.  -0.  -0.3 -0.4 -0.1 -0.4 -0.  -0.5  0.3  0.7 -2.4 -0.5 -0.3  1.6  6.  -0.4  0.  -0.2 -0.  -1.6  0.7  1.7 -1.1 -0.3 -0.1 -0.2 -0.6 -0.2  3.2  0.2 -0.5  0.  -0.2 -0.2  3.4 -0.  -0.3  0.2 10.1  0.3  2.3  0.2  1.2 -0.2 -0.3 -0.5 -0.5 -2.1 10.3  0.3 -0.1 -0.6 -0.2  0.6 -0.5  1.6 -0.1 -0.2 -0.2 -0.  -0.1 -0.2 -0.1  0.9 -0.3  1.8  0.8 -0.1 -0.1 -0.5 -0.4 -0.5 -0.5 -0.1 -0.2 -0.  -0.1 -0.2 -0.4 -0.2 -0.8 -0.1 -0.1 -0.1 -0.1 -0.1 -0.3  0.2  1.4 -0.9 -0.4  2.1 -0.1 -2.1  0.6 -0.4 -1.7  0.   0.2 -0.  -0.5 -0.2 -1.  -0.1 -0.2 -0.2 -0.7 10.2  0.6 -0.3 -0.1 -0.1  0.2 -0.  -0.2 -0.2 -0.3 -0.3 -1.7 -0.1 -0.2 -3.1 -0.1 -0.4 -0.1 -0.1 -1.3 -0.7 -0.1 -0.1 -1.1 -0.  -0.7  0.  -0.1 -0.4 -0.9  2.1 -0.4 -1.4 -0.6 -0.5  4.5 -0.4 -0.  -0.3 -1.2 -0.1 -0.7 -0.5 -0.3  2.5 -2.  -0.1 -0.6 -0.2 -0.2 -0.8 -0.2  0.3 -0.3 -1.1 -0.2 -1.8 -0.  -0.7 -0.3  2.9  1.4]
ty_50sample [[7 5 4 6 0 9 3 2 8 1]
 [2 9 3 0 1 4 8 5 6 7]
 [4 6 9 8 2 7 0 3 1 5]
 [6 2 1 0 9 8 7 5 4 3]
 [2 3 0 5 7 1 9 9 8 6]
 [7 4 6 9 3 8 2 2 0 5]
 [7 8 2 6 3 9 5 1 4 0]
 [3 0 7 5 1 6 4 9 2 8]
 [1 0 2 3 5 9 8 7 6 4]
 [2 4 3 1 0 8 7 9 5 6]]
tt_50sample [[7 5 4 6 0 9 3 2 8 1]
 [2 9 3 0 1 4 8 5 6 7]
 [4 6 9 8 2 7 0 3 5 1]
 [6 2 1 0 9 8 7 5 4 3]
 [2 3 0 5 7 1 9 4 8 6]
 [7 4 6 9 3 8 2 1 0 5]
 [7 8 2 6 3 9 5 1 4 0]
 [3 0 7 5 1 6 4 9 2 8]
 [1 0 2 3 5 9 8 7 6 4]
 [2 4 3 1 0 8 7 9 5 6]]
vm  [-0.2 -0.2  8.5 18.6 -1.9 -0.2 -0.3 -0.2 -1.2 -0.  -5.1 -0.5 -0.3 -0.1 -0.2 -2.4 -0.5 -0.8  0.5 -1.5 -0.9 -0.   0.2 -0.5 -0.8  1.5 -0.4 -0.2 -1.7  1.2 -1.1 -0.3 -0.4  4.4 -0.1 -0.1  4.7 -2.   2.3 -0.5 -0.1 -0.6  0.1 -1.  -0.3 -0.   8.4 -0.1  2.4 -0.  -0.1 -0.2 -0.5 -4.2  1.6 -0.1 -0.6  5.1 -1.3  5.3 -1.3 -0.4 -1.   0.2 -0.4  0.9  1.  -0.5  1.6  0.1  0.1  6.3 -0.3 -0.7  3.4 -0.3 -0.6 -0.7 -0.1  1.5  7.2 -0.1 -0.2  0.8 -0.6 -0.2 -0.3 -0.  -0.2 -0.2  0.4 -0.1 -0.3 -0.3 -0.4  0.5 -0.5 -1.1 -0.1  0.1 -0.1  3.  -0.4 -0.1  0.2  0.9 -0.  -0.2 -1.6 -1.8 -0.2 -0.2 -0.1  0.6  1.8 -3.1 -0.7 -0.8 -0.2 -0.3  0.1  9.2  0.3 -0.1  0.5 -0.3  0.7 14.8 -1.6 -0.5  0.8 -0.2  0.  -0.6  3.1  5.7 -0.2 -0.  -0.  -0.4  0.6 -0.9  0.  -0.5 -0.  -0.  -0.5 -0.1 -0.8 -0.3 -1.8  0.1  1.9 -0.4 -0.2  0.2 -0.  -0.2 -1.1 -0.6  0.6  1.1 -0.  -0.1  0.1  0.2 -0.3 -0.4 -0.3 -0.1 -0.1 -0.1  0.   0.8 -0.2  1.7 -0.5 -0.3 -0.  -0.2 -1.2 -0.3 -0.2 -1.5  0.7  0.3 -0.2  0.   0.7  0.2  0.6 -0.2 -0.2 -0.8 10.5  7.1 -0.2 -0.4  0.1 -0.  -0.1 -0.2 -0.3 -0.4 -0.3 -0.  -0.3 -0.2  3.1 -0.3 -0.6 -2.6 -0.7 -0.4 -0.4 -0.2  6.9 -1.  -0.4  0.1 -0.3 -0.2 -0.2 -1.1  2.8 -1.1 -1.3  1.   2.6  2.8 -0.6 -1.  -0.1  1.3  2.8 -1.9  1.   1.1  2.3  9.4 -0.2  2.5 -0.2 -0.1 -1.  -1.2  0.2  1.6 -1.1 -0.6 -1.9 -0.1  1.4 -0.3  6.3  4.3]
vy_50sample [[0 9 6 7 3 8 5 1 4 2]
 [5 0 6 4 2 3 1 8 9 7]
 [5 2 9 1 7 8 0 6 3 4]
 [0 3 8 2 7 9 9 1 6 4]
 [7 1 1 5 5 0 0 9 6 8]
 [9 3 2 7 8 4 6 1 5 0]
 [7 8 4 6 1 9 2 3 5 0]
 [0 3 6 1 4 2 8 7 9 5]
 [5 9 1 4 8 0 6 7 3 2]
 [6 8 7 4 3 9 0 1 5 2]]
vt_50sample [[0 9 6 7 3 8 5 1 4 2]
 [5 0 6 4 2 3 1 8 9 7]
 [5 2 9 1 7 8 0 6 3 4]
 [0 3 8 2 7 9 5 1 6 4]
 [7 2 1 5 3 4 0 9 6 8]
 [9 3 2 7 8 4 6 1 5 0]
 [7 8 4 6 1 9 2 3 5 0]
 [0 3 6 1 4 2 7 8 9 5]
 [5 9 1 4 8 0 6 7 3 2]
 [6 8 7 4 3 9 0 1 5 2]]
Epoch 44810: Training cost= 0.2480, Training acc= 0.8577, Validation cost= 0.2163, Validation acc= 0.8578
Epoch 44820: Training cost= 0.2592, Training acc= 0.8578, Validation cost= 0.2394, Validation acc= 0.8578
Epoch 44830: Training cost= 0.2584, Training acc= 0.8578, Validation cost= 0.2633, Validation acc= 0.8578
Epoch 44840: Training cost= 0.2131, Training acc= 0.8578, Validation cost= 0.2167, Validation acc= 0.8578
Epoch 44850: Training cost= 0.2001, Training acc= 0.8578, Validation cost= 0.2821, Validation acc= 0.8579
Epoch 44860: Training cost= 0.2476, Training acc= 0.8578, Validation cost= 0.2311, Validation acc= 0.8579
Epoch 44870: Training cost= 0.2517, Training acc= 0.8578, Validation cost= 0.2516, Validation acc= 0.8579
Epoch 44880: Training cost= 0.2220, Training acc= 0.8578, Validation cost= 0.2595, Validation acc= 0.8579
Epoch 44890: Training cost= 0.2685, Training acc= 0.8578, Validation cost= 0.2546, Validation acc= 0.8579
Epoch 44900: Training cost= 0.2422, Training acc= 0.8578, Validation cost= 0.2739, Validation acc= 0.8579
tm  [ 0.   0.1  4.2  8.1 -1.8 -0.3 -0.3 -0.2 -1.  -0.6 -1.8 -0.4 -0.2  0.  -0.  -2.2 -0.3 -0.7  1.4 -1.3 -1.1 -0.3 -0.7 -0.4 -1.   1.7 -0.3 -0.1 -1.2 -1.   1.7 -0.2  0.2  9.1  0.  -0.2  3.7 -1.6  1.6 -0.2 -0.4 -1.6 -0.2 -0.8 -0.  -0.2  6.4 -0.2  4.  -3.  -0.2  0.1 -0.6 -3.5  1.7 -0.2 -0.5  3.  -0.4 -0.7 -1.2 -0.5 -0.5  0.3  0.2  0.6  0.1 -0.5  1.1 -0.1 -0.1  6.2 -0.3 -0.4  0.  -0.2 -0.4 -0.8 -0.  -0.1 14.8 -0.3 -0.2 -0.3 -0.9 -1.1  2.3 -0.1 -0.2  0.7 -0.1 -0.1 -0.3 -0.3 -0.6  0.3 -0.2 -1.7 -0.1  0.4  2.  -0.8 -0.6  0.1 -0.  -0.1 -0.8 -0.1 -0.6 -1.5 -0.  -0.2 -0.1 -0.2  3.1 -2.8 -0.5 -0.5 -0.2 -0.4 -0.5  7.3 -0.1  1.  -0.1 -0.   0.3 12.6 -0.2  2.2  0.8 -0.4 -0.1 -0.7  3.3 11.3 -0.1 -0.1  1.1 -0.1  0.7 -0.7  0.1 -0.3 -0.1 -0.2 -0.5 -0.1 -0.1 -0.4 -0.7 -0.1  0.9 -0.4 -0.1  0.2 -0.1 -0.5 -0.9 -0.4 -0.5 -0.1 -0.1 -0.1 -0.2  0.2  0.  -0.4 -0.3 -0.2 -0.1 -0.2 -0.1  0.2 -0.3  0.8 -0.7 -0.6  0.4 -0.1 -1.5  0.  -0.2 -1.7  0.2 -0.2 -0.  -0.5  0.4  3.5 -0.1 -0.2 -0.3 -1.1  9.9  1.6 -0.6 -0.9 -0.2 -0.1 -0.4 -0.3 -0.2 -0.4 -0.3 -0.8 -0.1 -0.  -1.7 -0.   0.6 -2.3 -0.6 -0.9 -0.3 -0.1  3.7 -1.2 -0.5 -0.  -0.1 -0.2 -0.2 -1.  -0.2 -1.5 -1.7  1.4  0.1  3.7 -0.8 -0.7 -0.1 -0.6  3.5 -0.9  0.2  0.8  2.   5.6 -0.1  1.3 -0.1 -0.2 -2.8 -1.  -0.2 -0.2 -1.2 -0.  -3.9 -0.2  1.  -0.2  8.6  0.3]
ty_50sample [[0 3 9 6 7 5 4 8 1 2]
 [1 1 8 7 2 5 3 4 0 9]
 [3 9 4 7 5 1 0 0 2 8]
 [9 4 8 3 7 6 2 5 0 1]
 [1 2 6 7 3 8 0 5 4 4]
 [3 9 0 8 1 6 7 4 2 5]
 [3 8 9 5 4 2 7 0 1 6]
 [2 5 3 3 9 6 0 7 8 1]
 [6 1 4 5 7 0 2 8 9 3]
 [3 0 4 5 7 9 1 6 8 8]]
tt_50sample [[0 3 9 6 7 5 4 8 1 2]
 [6 1 8 7 2 5 3 4 0 9]
 [3 9 4 7 5 1 0 6 2 8]
 [9 4 8 3 7 6 2 5 0 1]
 [1 2 6 7 3 8 0 5 9 4]
 [3 9 0 8 1 6 7 4 2 5]
 [3 8 9 5 4 2 7 0 1 6]
 [2 5 4 3 9 6 0 7 8 1]
 [6 1 4 5 7 0 2 8 9 3]
 [3 0 4 5 7 9 1 6 8 2]]
vm  [-0.2 -0.1 -2.4  0.4 -1.1 -0.2 -0.2 -0.  -0.9 -0.8  6.5  0.3 -0.4 -0.2 -1.7  1.7 -0.1  0.2 -0.5  0.3 -1.4 -0.3 -0.5 -0.1 -1.4  2.7  0.8 -0.6 -0.8 -2.4  1.1 -0.2 -0.  -3.2 -0.1 -0.1  3.7  4.9  1.2 -0.4  2.9  2.9  2.2  0.6 -0.2 -0.  -0.9 -0.1  6.3 -1.8 -0.5  0.   0.4  5.8 -0.9  1.4 -0.6  7.7 -0.2  1.3  1.4 -0.5  1.1 -0.  -0.5 -0.2 -0.2 -0.5 -0.4  0.6  0.5  2.   0.2  0.9 -3.8 -0.5 -0.2 -0.6 -0.1 -0.2  0.  -0.2  0.3 -0.5 -1.5  2.   3.8 -0.2 -0.1 -0.3 -0.6 -0.1 -0.   2.  -0.5 -0.5  0.1 -2.6 -0.4 -0.2  2.1 -2.7 -0.7 -0.3 -0.2  1.1 -1.8  0.4  1.  -0.7 -0.6 -0.4 -0.2 -0.5 -0.4 -0.2  0.2 -0.7  0.3 -0.5 -0.3  0.9 -0.2  0.  -0.4 -1.9 -0.2 -1.   3.8  8.3 -0.  -0.3 -0.1  0.   7.2 -0.1 -0.4  0.   0.1 -0.4 -0.7 -0.5 -0.7  0.1 -0.2 -0.3 -0.4 -0.1 10.  -0.  -0.2 -0.1  1.8 -0.9 -0.1 -0.1 -0.3 -0.2  2.6 -0.8 -0.  -1.4 -0.2 -0.   0.1 -0.4 -0.2 -0.8  0.1 -0.1  0.1 -0.3 -0.5 -0.4 -0.4 -2.3 -0.5 -0.5  1.   0.3 -2.5 -0.  -0.2 -1.9 -0.1 -0.3  1.3  1.2 -0.3  7.5  0.3 -0.  -0.3 -1.5  1.8 -0.9 -0.3  0.6 -0.3 -0.2  0.4 -0.2 -0.1 -0.2 -0.3 -1.7 -0.3 -0.2 -3.8 -0.2 -0.1 -0.7 -0.7 -0.8 -0.2 -0.2 -0.5 -1.3 -0.7  0.3 -0.   0.2  0.9 -0.5 -1.6 -0.3 -0.4 -0.2 -0.3  1.9 -0.3 -0.2 -0.2 -1.3 -0.1  1.7 -0.2 -0.2  0.9 -4.4 -0.1 -1.5  0.  -0.2  2.8 -0.4 -0.7  0.2 -1.2 -0.3 -0.3 -0.   1.1  0.8  2.3 -1.7]
vy_50sample [[5 3 2 0 4 4 9 1 1 7]
 [3 7 1 5 9 0 2 6 6 4]
 [0 5 6 9 7 1 2 3 8 4]
 [2 3 9 0 7 5 8 4 6 1]
 [5 6 2 9 0 7 3 1 4 8]
 [3 1 2 4 6 9 8 7 5 0]
 [5 4 6 0 2 8 7 3 9 9]
 [8 4 1 7 6 3 0 2 5 9]
 [5 0 6 9 3 2 1 8 4 7]
 [9 7 1 1 4 5 2 0 3 6]]
vt_50sample [[5 3 2 0 8 4 9 6 1 7]
 [3 7 1 5 9 0 2 8 6 4]
 [0 5 6 9 7 1 2 3 8 4]
 [2 3 9 0 7 5 8 4 6 1]
 [5 2 6 9 0 7 3 1 4 8]
 [3 1 2 4 6 9 8 7 5 0]
 [5 4 6 0 2 8 7 3 1 9]
 [8 4 1 7 6 3 0 2 9 5]
 [5 0 6 9 3 2 1 8 4 7]
 [9 7 1 8 4 5 2 0 3 6]]
Epoch 44910: Training cost= 0.2325, Training acc= 0.8579, Validation cost= 0.2070, Validation acc= 0.8579
Epoch 44920: Training cost= 0.2249, Training acc= 0.8579, Validation cost= 0.2769, Validation acc= 0.8579
Epoch 44930: Training cost= 0.2302, Training acc= 0.8579, Validation cost= 0.3185, Validation acc= 0.8579
Epoch 44940: Training cost= 0.2642, Training acc= 0.8579, Validation cost= 0.2377, Validation acc= 0.8579
Epoch 44950: Training cost= 0.3406, Training acc= 0.8579, Validation cost= 0.2090, Validation acc= 0.8580
Epoch 44960: Training cost= 0.2597, Training acc= 0.8579, Validation cost= 0.1986, Validation acc= 0.8580
Epoch 44970: Training cost= 0.2756, Training acc= 0.8579, Validation cost= 0.2223, Validation acc= 0.8580
Epoch 44980: Training cost= 0.2601, Training acc= 0.8579, Validation cost= 0.2448, Validation acc= 0.8580
Epoch 44990: Training cost= 0.2020, Training acc= 0.8579, Validation cost= 0.2364, Validation acc= 0.8580
Epoch 45000: Training cost= 0.2330, Training acc= 0.8579, Validation cost= 0.2591, Validation acc= 0.8580
tm  [ 1.5 -0.2 -2.1 13.4 -0.5  0.6 -0.4 -0.1  3.1 -0.2  1.9 -0.1 -0.1 -0.1 -3.4  4.8 -0.3  0.3 -0.6 -1.5 -0.9  0.1 -0.3 -0.3 -0.6  0.2 -0.  -0.   1.4 -3.9 -0.1 -0.6 -0.6 -3.2  0.5  0.3 -1.2  4.9 16.5 -0.7 -0.8 -3.5 -1.9 -0.6 -0.2  0.3  8.4 -0.7  8.7 -1.5 -0.2 -0.2  0.8 -1.7 -1.3  4.   1.8 -1.4 11.4  3.4 -2.3 -0.6  1.7  1.2  0.4 -0.3  0.1 -0.2 -0.9 -0.4 -0.2 -1.9 -0.4  0.4  0.6 -0.2 -0.6 -0.4 -0.4  0.1 11.7 -0.1 -0.2 -0.4 -2.1 -2.7  5.3  0.2 -0.4 -0.3  0.7 -0.1 -0.2 -2.4 -0.4 -0.4 -0.4 -2.1  0.  -0.2 -0.4 -2.9 -1.5 -0.2  0.3 -0.4  2.2 -0.5  0.3 -1.9 -0.1 -0.2  0.2 -0.7  3.3 10.1 -1.4  1.8  0.1 -0.7 -0.4  6.4 -0.1 -0.5 -0.4 -4.4 -0.5  7.4 10.6 -0.   2.9 -0.5  0.2 -0.4  6.2 -2.   0.  -0.   0.  -0.1 -1.2 -0.3 -1.1 -0.1 -0.1 -0.4 -0.2 -0.4  2.2  0.4 -1.4 -0.2  2.8 -1.  -0.1 -0.2 -0.5 -0.  -0.2  0.1 -0.2 -0.7 -0.4 -0.3  0.7 -0.3 -0.6  0.4 -0.3 -0.1 -0.2 -0.1 -0.4 -0.  -0.2 -0.3 -0.5 -0.2 -1.6 -0.1 -0.1 -0.6 -0.8 -2.2 -0.2 -0.9  2.9 -0.4 -0.4  9.7 -0.   0.1 -0.5 -0.9 15.4 -3.9  1.7 -1.4 -0.4  0.1 -0.2 -0.1 -0.  -0.9 -0.3  5.1 -0.2 -0.2  6.7  0.2 -0.6  5.7 -1.2 -2.8 -1.  -0.2 -0.3 -0.7 -0.7  0.4 -0.1 -0.1  0.5 -1.6 -1.2  4.1 -0.9  1.8 -0.9  5.6 -1.  -1.4  1.2  3.  -1.   2.7 -0.4  1.3  3.3 20.5 -0.1  5.5 -0.1  0.2 -2.  -3.2 -0.5 -0.3 -1.3 -0.7 -3.3 -0.2  9.5  0.9  1.4  1.9]
ty_50sample [[9 3 8 8 4 6 6 5 7 1]
 [8 2 6 3 9 1 5 7 0 4]
 [3 8 0 7 5 6 2 9 1 4]
 [4 2 6 3 1 1 7 7 5 0]
 [0 5 9 6 7 8 1 1 3 2]
 [8 0 9 7 4 6 1 5 2 3]
 [1 7 8 2 4 6 5 0 3 9]
 [3 3 4 6 2 1 7 8 9 5]
 [1 5 3 8 4 6 0 2 7 9]
 [4 8 6 1 7 3 5 0 2 9]]
tt_50sample [[9 3 8 2 4 6 5 0 1 7]
 [8 2 6 3 9 1 5 7 0 4]
 [3 8 0 7 5 6 2 9 1 4]
 [4 2 6 3 9 1 7 8 5 0]
 [0 5 9 6 7 8 1 4 3 2]
 [8 0 9 7 4 6 1 5 2 3]
 [1 7 8 2 4 5 6 0 9 3]
 [3 0 4 6 2 1 7 8 9 5]
 [1 5 3 8 4 6 0 2 7 9]
 [4 8 6 1 7 3 5 0 2 9]]
vm  [-0.5 -0.2  6.2 11.4 -2.1 -0.2  0.4 -0.2 -0.  -0.6 -4.7 -0.1 -0.2 -0.2  0.9 -0.9 -0.1 -0.  -0.6 -0.8 -1.4 -0.1 -0.4 -0.3 -0.7  2.  -0.3 -0.3 -0.1 -0.8 -0.3 -0.3 -0.4  6.2 -0.1 -0.1 -0.  -0.3 15.  -0.6  2.9 -1.2  0.1  2.2  0.2 -0.   5.   0.4  5.  -1.7 -0.5 -0.2  1.4 -3.6 -1.1  0.  -0.4  2.5  0.6  3.2 -1.3 -0.3  0.2 -0.3 -1.  -0.5  0.3 -0.4 -0.1  0.9 -0.2 -0.8 -0.1 -0.  -0.4  0.6 -0.3  0.9 -0.3  0.6  7.7 -0.1 -0.1 -0.1 -1.6 -0.7  3.2 -0.2 -0.1 -0.4 -0.3 -0.1 -0.  -0.4 -0.8 -0.2  1.2 -1.6 -0.5 -0.   0.7 -0.1 -0.5 -0.1 -0.1  0.1 -0.1 -0.3 -1.6 -1.9 -0.3 -0.2 -0.2 -0.7 -0.1  5.5  1.2 -0.2  0.9 -0.3 -0.1  6.7 -0.2 -0.5 -0.4  1.5 -0.1 13.5  2.9  4.  -0.3 -0.4 -0.4  0.1 -4.9 -2.8  0.1 -0.1 -0.4 -0.2  2.8 -0.3  1.3 -0.   0.1 -0.2 -0.3 -0.2 -0.5 -0.2 -1.1 -0.1  3.2 -0.  -0.  -0.1 -0.3 -0.1  3.9 -0.8 -0.1 -1.6 -0.3 -0.3  0.3 -0.  -0.3 -0.4 -0.1 -0.  -0.  -0.1 -0.3 -0.  -0.2  1.1  0.1 -0.  -1.3  0.  -1.2  0.7 -0.3 -1.7 -0.1 -0.2  0.8 -0.2 -0.1  2.2 -0.3 -0.  -0.2 -0.6 10.3 -1.   0.9 -0.2  0.2  0.2  0.8 -0.  -0.1 -0.2 -0.3  2.3 -0.3 -0.1  2.7 -0.4 -0.5  2.7 -0.1 -0.7 -0.7  0.8 -1.  -0.9 -0.1  0.2  0.  -0.1 -0.3 -1.  -2.1  2.8 -2.1 -0.8  0.5  3.4 -0.2 -0.8 -0.2  1.6 -0.6 -1.2 -0.4  0.6  2.5  9.6 -0.1  2.5  0.1 -0.2 -1.1 -2.2 -0.6 -0.3 -1.  -0.6 -2.2 -0.3  9.2 -0.1  9.6 -0.4]
vy_50sample [[3 7 7 8 5 4 0 1 6 2]
 [9 2 8 5 6 1 0 7 4 3]
 [3 3 2 7 6 1 5 9 0 8]
 [0 8 4 9 2 6 5 1 3 7]
 [6 2 9 8 7 4 0 1 3 5]
 [7 8 9 4 5 1 2 0 6 3]
 [2 1 3 5 7 6 4 8 9 0]
 [0 8 7 4 5 9 3 2 1 1]
 [4 0 2 9 5 3 1 7 8 6]
 [4 6 3 1 7 8 9 0 2 5]]
vt_50sample [[3 7 9 8 5 4 0 1 6 2]
 [9 2 8 5 6 1 0 7 4 3]
 [3 4 2 7 6 1 5 9 0 8]
 [0 8 4 9 2 6 5 1 3 7]
 [6 2 9 8 7 4 0 1 3 5]
 [7 8 9 4 5 1 2 0 6 3]
 [2 1 3 5 7 6 4 8 9 0]
 [0 8 7 4 5 9 3 2 1 6]
 [4 0 2 9 5 3 1 7 8 6]
 [4 6 3 1 8 7 9 0 2 5]]
Epoch 45010: Training cost= 0.2319, Training acc= 0.8579, Validation cost= 0.2342, Validation acc= 0.8580
Epoch 45020: Training cost= 0.2398, Training acc= 0.8580, Validation cost= 0.2250, Validation acc= 0.8580
Epoch 45030: Training cost= 0.2416, Training acc= 0.8580, Validation cost= 0.1933, Validation acc= 0.8580
Epoch 45040: Training cost= 0.2129, Training acc= 0.8580, Validation cost= 0.2914, Validation acc= 0.8580
Epoch 45050: Training cost= 0.2685, Training acc= 0.8580, Validation cost= 0.2526, Validation acc= 0.8581
Epoch 45060: Training cost= 0.2220, Training acc= 0.8580, Validation cost= 0.2246, Validation acc= 0.8581
Epoch 45070: Training cost= 0.2049, Training acc= 0.8580, Validation cost= 0.2267, Validation acc= 0.8581
Epoch 45080: Training cost= 0.2117, Training acc= 0.8580, Validation cost= 0.2967, Validation acc= 0.8581
Epoch 45090: Training cost= 0.2413, Training acc= 0.8580, Validation cost= 0.2472, Validation acc= 0.8581
Epoch 45100: Training cost= 0.2740, Training acc= 0.8580, Validation cost= 0.2060, Validation acc= 0.8581
tm  [ 1.7 -0.4 -1.4  1.3 -0.9 -0.1 -0.2 -0.1 -0.9 -0.6 -3.9 -0.1 -0.2 -0.3 -1.3  1.7  0.2 -0.2 -0.1 -1.3 -1.1 -0.2 -0.4 -0.3 -1.  -0.3 -0.2 -0.6  1.5  4.  -0.3 -0.2  1.2 -3.   0.  -0.2  1.7 -1.6 -1.8 -0.5  0.1 -1.6  0.9 -0.5 -0.2 -0.4  4.6 -0.4  4.9 -0.9 -0.4 -0.2 -0.5 -1.7 -1.7  1.3 -0.6 -0.2 -1.3  3.  -1.4 -0.5 -0.6 -0.  -0.3 -0.  -0.1  0.3  2.6 -0.3 -0.3 -1.7 -0.5 -0.3 -1.7  0.4 -0.5  0.1 -0.4  0.3 -0.9 -0.4 -0.4  0.6 -1.8 -1.5  6.5 -0.1 -0.1 -0.4 -0.5 -0.1 -0.4  1.  -0.5 -0.2 -0.1 -1.8 -0.6 -0.3  2.1 -1.5 -0.8 -0.  -0.2 -0.  -1.1 -0.3 -1.1 -1.3 -0.2 -0.3 -0.1 -0.4 -1.2 11.3  0.4 -0.5  0.8 -0.1 -0.3  4.2 -0.2 -0.7 -0.1 -1.5 -0.3  7.8 -1.1  7.4 -0.1 -0.4 -0.  -0.5 11.   6.  -0.2 -0.1 -0.2 -0.5 -0.6 -0.1  0.5 -0.3 -0.1  0.  -0.6 -0.4  3.1 -0.2 -0.3 -0.   4.1 -0.5 -0.3 -0.2  1.  -0.4 -1.3 -0.3 -0.2  1.2 -0.2 -0.1 -0.2 -0.1 -0.4 -0.5 -0.5 -0.3 -0.1 -0.  -0.1 -0.3 -0.2 -0.4 -1.9 -0.4  1.6 -0.3 -1.3 -0.1 -0.2 -1.7 -0.1 -0.   1.3 -0.3 -0.1 -1.1 -0.1  0.2 -0.5 -1.3 12.3  3.3 -0.2  2.8 -0.2 -0.2 -0.1 -0.  -0.  -0.5 -0.3 -1.  -0.2 -0.2  4.6 -0.2 -0.6  1.9 -0.7 -2.2 -0.  -0.2  2.  -0.3  0.2  0.3 -0.  -0.4 -0.2 -1.1 -0.2  4.9 -1.5 -0.1 -0.3  3.7 -0.1  1.4 -0.1  1.1 -1.5  0.7  0.2 -0.3  0.1  4.  -0.1  1.4 -0.3 -0.2  4.6 -1.   0.6 -0.3 -0.9 -0.5  1.7 -0.2 -1.1 -0.   6.1 -1.3]
ty_50sample [[3 6 8 4 9 5 7 2 0 1]
 [0 0 2 8 7 5 1 3 6 4]
 [7 8 4 0 0 3 2 5 1 9]
 [1 6 4 3 9 0 8 7 2 5]
 [0 1 8 5 7 7 3 4 2 6]
 [5 9 3 4 2 0 7 8 1 6]
 [5 3 6 9 2 0 4 8 7 1]
 [0 1 6 3 2 2 7 4 5 8]
 [3 0 0 8 9 2 1 5 4 7]
 [9 7 8 6 0 2 3 5 4 1]]
tt_50sample [[3 6 8 4 9 5 7 2 0 1]
 [0 9 2 8 7 5 1 3 6 4]
 [7 8 4 6 0 3 2 5 1 9]
 [1 6 4 3 9 0 8 7 2 5]
 [0 1 8 5 9 7 3 4 2 6]
 [5 9 3 4 2 0 7 8 1 6]
 [5 3 6 9 2 0 4 8 7 1]
 [0 1 6 3 2 7 9 4 5 8]
 [3 0 6 8 9 2 1 5 4 7]
 [7 9 8 6 0 2 3 5 4 1]]
vm  [-1.6 -0.1 -2.  10.4 -0.6  0.2 -0.2  0.1 -0.4 -0.9 -3.1 -0.3 -0.  -0.2 -3.4  3.4  1.2 -0.2 -0.1 -0.8 -1.1 -0.2  1.7 -0.3 -0.7  0.9 -0.2  0.8  0.2 -1.6 -1.3 -0.7 -0.8 -7.4 -0.1  0.2  1.1 -0.3  5.4 -0.5 -0.8 -1.9 -0.3 -1.  -0.2  0.2  2.8 -0.  -1.4  3.8 -0.5 -0.1 -0.1 -0.9 -1.5  3.3 -0.3  3.3  0.1  5.6  3.9 -0.2 -0.4  0.4 -1.  -0.3 -0.1 -0.8 -0.1  0.3 -0.1 -1.7  0.2  1.1 -1.2 -0.  -0.1  0.1 -0.3  0.7 -1.3 -0.1 -0.2 -0.2  2.1 -1.2 -2.4 -0.2 -0.4 -0.2 -0.5 -0.1 -0.1  0.3 -0.6 -0.5  0.4 -1.6 -0.6  0.6  2.9 -2.6 -0.2 -0.2 -0.3 -0.1 -0.3 -0.4 -0.8 -2.   0.5 -0.3 -0.2 -0.4 -0.6 12.8 -0.7 -0.6 -0.  -0.5 -0.1  6.4  0.3  1.7 -0.  -4.1 -0.3  5.5 -0.2  2.6 -0.1  0.3 -0.1 -0.6 12.6 -2.6 -0.3 -0.1 -0.2 -0.1 -0.2 -0.5 -0.5 -0.1 -0.  -0.4  0.1 -0.2  5.3 -0.2 -1.  -0.3  0.4 -0.2 -0.2 -0.1 -0.1 -1.4 -0.3 -0.1 -0.4 -0.3 -0.1 -0.1 -0.2 -0.3 -0.3  0.4 -0.1 -0.2 -0.1 -0.3 -0.  -0.3  0.  -0.9 -0.2 -0.  -0.6 -0.  -0.9  1.  -0.4 -1.6 -0.   1.2 -0.6  1.1  0.2  4.9 -0.2 -0.2 -0.4 -1.1 -0.9  0.2  0.7  2.2 -0.2 -0.   0.3 -0.  -0.3 -0.2 -0.1  0.2 -0.3 -0.   7.7  0.  -0.5  3.3 -0.5  8.   0.6 -0.4  3.5 -0.6 -0.4  0.3 -0.1 -0.3 -0.3 -0.6 -0.2  4.8 -1.   0.3 -0.8 -0.6 -0.5 -0.7 -0.1  1.7 -0.6  1.9 -0.9  0.5  0.5  8.7 -0.2  2.6 -0.1 -0.3  6.  -1.3 -0.3  0.5 -1.  -0.4  2.9 -0.3  3.2  0.2  3.7  0.3]
vy_50sample [[1 1 3 9 6 5 2 4 0 7]
 [5 9 4 6 7 1 0 2 3 8]
 [8 0 2 1 3 7 9 5 6 4]
 [7 8 6 3 2 0 4 5 9 1]
 [5 8 1 6 4 9 7 0 2 3]
 [1 7 6 8 2 4 9 3 5 0]
 [9 4 8 0 2 3 6 7 1 5]
 [1 7 6 6 8 2 9 0 3 4]
 [2 4 0 8 7 9 1 3 6 5]
 [2 7 9 1 1 8 6 0 5 4]]
vt_50sample [[1 8 3 9 6 5 2 4 0 7]
 [5 9 4 6 7 1 0 2 3 8]
 [8 0 2 1 3 7 9 5 6 4]
 [7 8 6 3 2 0 4 5 9 1]
 [5 8 1 6 4 9 7 0 2 3]
 [1 7 6 8 2 4 9 3 5 0]
 [9 4 8 0 2 3 6 7 1 5]
 [1 7 6 5 8 2 9 0 3 4]
 [2 4 0 8 7 9 1 6 3 5]
 [2 7 9 1 8 3 6 0 5 4]]
Epoch 45110: Training cost= 0.2596, Training acc= 0.8581, Validation cost= 0.2536, Validation acc= 0.8581
Epoch 45120: Training cost= 0.3323, Training acc= 0.8581, Validation cost= 0.3143, Validation acc= 0.8581
Epoch 45130: Training cost= 0.2581, Training acc= 0.8581, Validation cost= 0.2602, Validation acc= 0.8581
Epoch 45140: Training cost= 0.2619, Training acc= 0.8581, Validation cost= 0.2228, Validation acc= 0.8581
Epoch 45150: Training cost= 0.2478, Training acc= 0.8581, Validation cost= 0.2427, Validation acc= 0.8582
Epoch 45160: Training cost= 0.2315, Training acc= 0.8581, Validation cost= 0.2779, Validation acc= 0.8582
Epoch 45170: Training cost= 0.2926, Training acc= 0.8581, Validation cost= 0.2470, Validation acc= 0.8582
Epoch 45180: Training cost= 0.2160, Training acc= 0.8581, Validation cost= 0.2384, Validation acc= 0.8582
Epoch 45190: Training cost= 0.1947, Training acc= 0.8581, Validation cost= 0.2368, Validation acc= 0.8582
Epoch 45200: Training cost= 0.2626, Training acc= 0.8581, Validation cost= 0.1993, Validation acc= 0.8582
tm  [-0.4 -0.1  8.5 18.1 -1.3 -0.4 -0.  -0.3 -1.1  0.1 -8.2 -0.4 -0.3 -0.3 -0.5 -1.3 -0.3 -0.6 -0.7 -1.9 -0.8 -0.2  1.8 -0.3 -0.4 -0.2  0.5 -0.4 -0.6  9.5 -1.4 -0.2 -0.2 -0.4 -0.1 -0.   2.9 -2.7 -0.1 -0.5 -0.1 -2.3  2.  -1.1 -0.3 -0.2 12.1  0.6  0.1  7.  -0.2 -0.3 -0.7 -4.9 -1.1  0.1 -0.4 -0.6 -2.5  7.  -0.9  0.2 -0.7 -0.6 -0.7 -0.2 -0.3  0.5 -0.3 -0.2 -0.2  0.4 -0.7 -1.2  5.6  1.2 -0.1  0.7 -0.6  2.   2.2  1.4 -0.4  2.2 -0.7 -2.2 -0.2 -0.  -0.2 -0.2 -0.1 -0.  -0.3  2.3 -0.3 -0.4  0.4  0.8 -0.2 -0.9 -0.   3.4  0.4 -0.5 -0.1  0.8  0.6 -0.8 -2.4 -2.3 -0.2 -0.1 -0.3  0.6 -0.5 -0.9 -1.1 -1.  -0.2 -1.1 -0.1  9.5 -0.2  0.4 -0.1 -0.5 -0.2 16.5 -3.6 -1.   1.6 -0.  -0.2  0.6  6.6  4.7 -0.4  0.3  0.1 -0.1 -0.3 -0.3 -0.2 -0.2 -0.1 -0.4 -0.5  0.1 -2.4 -0.3 -2.  -0.2  2.  -0.5 -0.4 -0.2 -0.7  1.8 -2.3 -0.8  0.2  3.5 -0.3 -0.1  0.4  2.7 -0.8 -0.2 -0.4 -0.2 -0.  -0.1  0.1  0.8 -0.3  2.6 -0.6 -0.3  0.2 -0.2  2.7 -0.2 -0.  -0.4  0.2 -0.4 -0.4 -0.6 -0.3 -2.   0.1 -0.3 -0.3 -0.7  7.9 12.8  0.6 -0.1 -0.  -0.3  0.5 -0.2  0.5 -0.2 -0.5  1.6 -0.3 -0.4 13.5  0.4 -1.2 -1.2 -0.7 -0.1  0.  -0.2  7.5 -0.5 -0.6 -0.6 -0.2 -0.2 -0.5 -0.7  3.7  1.1 -1.4 -0.6  0.9  0.9 -0.1 -0.7 -0.7  2.2 -0.3 -1.6 -0.2  0.8  0.3 27.7 -0.3  8.2 -0.4  0.2  0.3 -2.  -0.7 -0.5 -0.7 -0.4 -0.7 -0.1 -0.   0.5  6.6  5.2]
ty_50sample [[6 9 8 7 0 3 1 4 5 2]
 [0 9 2 8 5 7 1 6 3 4]
 [7 6 8 4 4 2 3 1 9 5]
 [1 0 4 3 8 7 5 6 2 9]
 [4 0 7 1 5 9 2 3 8 6]
 [6 0 5 8 4 7 9 3 2 1]
 [5 0 3 4 1 1 8 7 2 6]
 [8 7 9 5 4 3 2 0 6 1]
 [7 8 0 6 4 5 3 2 1 1]
 [3 0 9 5 4 7 8 6 2 1]]
tt_50sample [[6 9 8 7 0 3 1 4 5 2]
 [0 9 2 8 5 1 7 6 3 4]
 [7 6 8 4 0 2 3 1 9 5]
 [1 0 4 8 3 7 5 6 2 9]
 [4 0 7 1 5 9 2 3 8 6]
 [6 0 5 8 4 7 9 3 2 1]
 [5 0 3 4 9 1 8 7 2 6]
 [8 7 9 5 4 3 2 0 6 1]
 [7 8 0 6 4 5 3 2 9 1]
 [3 0 9 4 5 7 8 6 2 1]]
vm  [-0.1  0.7  3.3  8.1 -1.2 -0.1 -0.3 -0.3 -0.6 -0.8 -0.1 -0.2 -0.  -0.2 -0.4  3.1 -0.1 -0.   1.2 -0.1 -1.1 -0.1  2.  -0.1 -1.1  1.8 -0.  -0.3 -0.7 -1.5 -1.3 -0.3  0.4 -3.3 -0.1 -0.1  2.   4.4  0.5 -0.3  0.4  4.2  2.8 -0.9 -0.2  0.8 -0.3 -0.3  7.1  4.6 -0.4 -0.2 -0.4  4.4 -0.8  0.  -0.6 11.7 -0.6  6.7 -0.5 -0.5  0.3 -0.  -0.6 -0.6  0.1 -0.3 -0.4 -0.   0.9  1.3  0.6  2.  -2.8  0.1 -0.3 -0.7 -0.1 -0.3 -2.  -0.6 -0.1 -0.4 -1.8  4.2  0.4 -0.  -0.1 -0.1 -0.5  0.1  0.1  0.  -0.5 -0.2  0.5 -2.6 -0.2 -0.1  3.6 -1.1 -0.8 -0.  -0.2 -0.1 -1.1 -0.7 -0.1 -0.6 -0.6 -0.  -0.3 -0.5 -0.6  2.4  0.  -0.8 -0.1 -0.2 -0.3  2.8 -0.1 -0.7 -0.3 -0.5 -0.  -0.6  1.   3.4 -0.2 -0.3 -0.  -0.4  4.  -1.9 -0.1 -0.2  0.1 -0.2 -0.9 -0.6 -0.8 -0.1 -0.1 -0.1 -0.2 -0.3  8.  -0.  -0.9 -0.1  4.  -0.8 -0.1 -0.  -0.3 -0.3  2.1 -0.3  0.1 -0.5 -0.3 -0.1 -0.2 -0.2 -0.1 -0.8  0.7 -0.2 -0.  -0.  -0.4 -0.5 -0.4 -1.6 -0.8 -0.   0.7  0.  -2.5 -0.2 -0.6 -1.9  0.2 -0.5  1.2 -0.3 -0.3  4.7 -0.1 -0.3 -0.1 -0.7  6.3 -0.2 -0.1  0.5 -0.3 -0.1 -0.  -0.1 -0.2 -0.1 -0.4 -1.5 -0.1 -0.1 -1.8 -0.1 -0.5 -0.5 -0.4 -1.  -0.  -0.7  3.8 -1.1 -0.4 -0.5  0.1  0.  -0.2 -1.  -0.7  2.3 -0.   0.8 -0.5  3.2 -0.4 -0.3 -0.3 -0.6  0.5 -0.6 -0.4  0.5  0.2 -4.  -0.  -1.3 -0.1 -0.1  7.6 -0.2 -0.1  1.2 -1.2 -0.2  4.1 -0.2  0.1 -0.1 -0.  -0.3]
vy_50sample [[5 8 2 3 0 6 9 7 1 4]
 [8 3 4 0 2 6 1 5 5 9]
 [0 7 5 3 1 6 8 8 4 9]
 [4 9 3 8 7 5 2 0 6 1]
 [0 2 9 6 5 8 4 3 7 1]
 [9 3 6 7 4 2 0 1 8 5]
 [6 9 8 1 2 7 5 3 4 0]
 [6 8 3 9 7 5 4 1 0 2]
 [5 0 1 9 4 3 6 8 7 2]
 [6 1 9 3 8 2 4 5 7 0]]
vt_50sample [[5 8 2 3 0 6 9 7 1 4]
 [8 3 0 4 2 6 7 1 5 9]
 [0 7 5 3 1 6 8 2 4 9]
 [9 4 3 8 7 5 2 0 6 1]
 [0 2 9 6 5 8 4 3 7 1]
 [9 3 6 7 4 2 0 1 8 5]
 [6 9 8 1 2 7 5 3 4 0]
 [6 8 3 9 7 5 4 1 0 2]
 [5 0 1 9 4 3 6 8 7 2]
 [6 1 9 3 8 2 4 5 7 0]]
Epoch 45210: Training cost= 0.2131, Training acc= 0.8582, Validation cost= 0.2219, Validation acc= 0.8582
Epoch 45220: Training cost= 0.2653, Training acc= 0.8582, Validation cost= 0.2651, Validation acc= 0.8582
Epoch 45230: Training cost= 0.2278, Training acc= 0.8582, Validation cost= 0.2416, Validation acc= 0.8582
Epoch 45240: Training cost= 0.2682, Training acc= 0.8582, Validation cost= 0.2283, Validation acc= 0.8582
Epoch 45250: Training cost= 0.2874, Training acc= 0.8582, Validation cost= 0.2547, Validation acc= 0.8583
Epoch 45260: Training cost= 0.2464, Training acc= 0.8582, Validation cost= 0.2513, Validation acc= 0.8583
Epoch 45270: Training cost= 0.2630, Training acc= 0.8582, Validation cost= 0.2465, Validation acc= 0.8583
Epoch 45280: Training cost= 0.2095, Training acc= 0.8582, Validation cost= 0.2509, Validation acc= 0.8583
Epoch 45290: Training cost= 0.2587, Training acc= 0.8582, Validation cost= 0.2365, Validation acc= 0.8583
Epoch 45300: Training cost= 0.2492, Training acc= 0.8582, Validation cost= 0.2322, Validation acc= 0.8583
tm  [ 0.9 -0.4  3.8 -2.8 -1.7 -0.2 -0.1 -0.1 -1.1 -0.9  4.7 -0.  -0.1 -0.   9.9  2.1 -0.1 -0.3  1.   0.1 -1.3 -0.1 -0.5  0.2 -1.5  0.8 -0.1 -0.  -0.5  0.8  2.3 -0.3 -0.1 10.  -0.2 -0.2  1.8  3.4  2.4 -0.4 -0.3  2.8  3.1  1.8 -0.  -0.2 -1.  -0.3  4.6 -2.3 -0.4  0.  -0.3  5.2 -1.  -1.2 -0.9  5.7 -1.2 -1.2 -0.5 -0.5  0.3 -0.1 -0.3 -0.4 -0.2 -0.4  1.2 -0.1 -0.2 -0.5 -0.2 -0.7 -4.1 -0.1 -0.  -0.  -0.3 -0.2 -0.4 -0.6 -0.  -0.1 -1.6  1.9  6.4 -0.  -0.2 -0.2 -0.6 -0.  -0.3  1.7 -0.7 -0.3  0.9 -2.5 -0.4 -0.1  3.3  0.1 -0.6 -0.2 -0.1 -0.2 -2.9 -0.1  1.3 -0.4 -0.2  0.  -0.1 -0.5 -1.   3.8  0.8 -0.7 -0.1 -0.1 -0.2  0.  -0.3 -0.4 -0.3 12.6 -0.2 -0.8  0.5 11.1 -0.1 -0.6 -0.2 -0.2 -4.6 -1.   0.5 -0.2 -0.6 -0.4 -0.4 -0.3 -0.  -0.2 -0.  -0.1 -0.1 -0.1  4.1 -0.1  2.8 -0.1  3.  -0.4 -0.  -0.2 -0.4 -0.3  1.1 -0.3 -0.3 -1.3 -0.1 -0.2 -0.2 -0.  -0.2 -0.7 -0.3 -0.1 -0.1 -0.1 -0.3 -0.4  0.5 -0.5 -0.2 -0.4 -0.1 -0.  -2.4 -0.2 -0.1 -1.7 -0.2 -0.4 -0.1 -0.6 -0.2 -0.5 -0.3 -0.3 -0.4 -0.9  5.9  0.4 -0.8  2.5 -0.3 -0.  -0.3 -0.1  0.1 -0.5 -0.4 -2.8 -0.1 -0.  -3.7 -0.2 -0.4 -0.1  0.1 -1.3  0.6  0.2 -1.3 -1.  -0.3 -0.5  0.3 -0.3 -0.3 -1.1 -1.8  0.7 -0.8 -0.6 -0.4  3.1 -0.7  2.1 -0.3 -1.2 -0.8 -0.5 -0.4 -0.7 -0.  -5.1 -0.  -1.7 -0.1 -0.3  3.4  2.  -0.1 -0.4 -0.6 -0.3  0.2 -0.2  1.4  0.2  3.8 -2.6]
ty_50sample [[5 3 7 4 2 0 0 9 6 1]
 [0 4 1 6 2 3 3 8 8 5]
 [5 8 7 4 0 2 6 1 1 9]
 [9 1 8 0 3 6 4 2 7 5]
 [1 0 0 6 7 3 5 9 4 2]
 [4 7 0 0 1 1 3 5 2 6]
 [2 4 0 1 9 9 3 6 5 7]
 [7 3 9 1 5 6 8 0 2 4]
 [2 1 4 9 6 8 7 3 5 0]
 [7 9 2 4 3 8 0 6 5 1]]
tt_50sample [[5 3 7 4 2 0 8 9 6 1]
 [0 4 1 6 2 9 3 7 8 5]
 [5 8 7 4 0 2 6 3 1 9]
 [9 1 8 0 3 6 4 2 7 5]
 [1 8 0 6 7 3 5 9 4 2]
 [7 4 8 0 1 9 3 5 2 6]
 [2 4 0 1 9 8 3 6 5 7]
 [7 3 9 1 5 6 8 0 2 4]
 [2 1 4 9 6 8 7 3 5 0]
 [7 9 2 4 3 8 0 6 5 1]]
vm  [ 1.2 -0.1  9.  -3.3 -1.4 -0.2 -0.6  0.4 -1.1 -0.3  2.4 -0.4 -0.2 -0.4 18.  -0.5 -0.2 -0.4  0.5  2.6 -1.  -0.2  0.4 -0.1 -1.2  1.2 -0.6 -0.3 -1.2  2.3 -0.2  0.5  0.9  9.6 -0.2 -0.2  0.5 -1.1 -6.8 -0.7 -0.3 -1.9 -0.1 -1.4 -0.   0.2 -3.3 -0.2  7.  -0.  -0.3  0.2 -0.1 11.5 -0.2 -2.  -0.7 -0.4 -0.1  3.2  1.  -0.2  0.4  0.4 -0.7  0.5 -0.2 -0.6  1.4 -0.1 -0.2  3.  -0.4  0.2 -6.5 -0.5 -0.4 -0.3 -0.3 -0.3 -4.8 -0.3  0.7 -0.3 -1.8 -2.   4.  -0.1 -0.3 -0.  -0.3  0.6 -0.2  0.4 -0.2  0.5  0.2 -3.7 -0.4  0.4  0.7  4.3 -0.5  0.4 -0.3  0.9 -2.6 -0.2  0.9  2.2 -0.4 -0.2 -0.  -0.6  2.1 -1.3 -0.4  0.4  0.3 -0.4 -0.3 -1.4 -0.3 -0.5 -0.2 22.3 -0.2 -2.5 -0.6 11.   0.2 -0.5  0.3 -0.2  0.7 11.5 -0.2 -0.2 -0.1 -0.4 -0.4 -0.9 -0.5 -0.4 -0.  -0.2 -0.2 -0.1 -2.7 -0.3  2.7 -0.2  3.3 -0.1 -0.3 -0.2 -0.1 -0.3 -1.  -0.1 -0.5  1.  -0.  -0.1 -0.5  0.4  0.2 -0.3 -0.3 -0.3 -0.1 -0.  -0.2 -0.1  0.1  4.1 -0.9 -0.4  8.3 -0.2  0.3  1.4 -0.2 -1.3 -0.2 -0.6 -0.1 -0.5 -0.1 -0.6 -0.2 -0.2 -0.2 -1.   1.6  2.2 -0.8 -0.8 -0.1  0.   0.3 -0.4 -0.1 -0.3 -0.6 -3.5 -0.2 -0.2  5.9 -0.4 -0.1 -1.4 -0.4 -1.8 -0.1 -0.5  6.3 -0.8 -0.5 -0.2 -0.1 -0.1 -0.1 -1.2  2.  -0.6 -0.9  0.1  0.3  3.3  1.8  0.6 -0.5  1.7  0.3 -2.  -0.1 -0.8  1.4 -2.  -0.1 -0.6 -0.1 -0.2 15.2  6.3 -0.5 -0.  -1.1  0.7 12.6 -0.  -4.1 -0.2  2.3 -2.7]
vy_50sample [[7 6 0 3 2 8 4 5 1 9]
 [9 1 6 6 7 4 3 8 5 2]
 [8 3 0 5 9 6 4 1 2 7]
 [1 9 2 6 7 0 4 3 5 8]
 [5 5 4 1 1 7 0 9 2 6]
 [7 2 0 9 3 8 5 4 6 6]
 [2 0 1 3 7 8 6 4 5 9]
 [0 3 2 6 4 5 5 7 8 1]
 [8 1 3 9 4 6 0 5 2 7]
 [6 2 1 5 7 4 9 3 8 0]]
vt_50sample [[7 6 0 3 8 2 4 5 1 9]
 [9 1 6 0 7 4 3 8 5 2]
 [8 3 0 5 9 6 4 1 2 7]
 [1 9 2 6 7 0 4 3 5 8]
 [5 3 4 8 1 7 0 9 2 6]
 [7 2 0 9 3 8 5 4 1 6]
 [2 0 1 3 7 8 6 4 5 9]
 [0 3 2 6 4 9 5 7 8 1]
 [8 3 1 9 4 6 0 5 2 7]
 [6 2 1 5 7 4 9 3 8 0]]
Epoch 45310: Training cost= 0.2230, Training acc= 0.8582, Validation cost= 0.2571, Validation acc= 0.8583
Epoch 45320: Training cost= 0.2633, Training acc= 0.8583, Validation cost= 0.2958, Validation acc= 0.8583
Epoch 45330: Training cost= 0.2487, Training acc= 0.8583, Validation cost= 0.2631, Validation acc= 0.8583
Epoch 45340: Training cost= 0.2307, Training acc= 0.8583, Validation cost= 0.2877, Validation acc= 0.8583
Epoch 45350: Training cost= 0.2809, Training acc= 0.8583, Validation cost= 0.2768, Validation acc= 0.8583
Epoch 45360: Training cost= 0.2635, Training acc= 0.8583, Validation cost= 0.2350, Validation acc= 0.8584
Epoch 45370: Training cost= 0.2528, Training acc= 0.8583, Validation cost= 0.2879, Validation acc= 0.8584
Epoch 45380: Training cost= 0.2621, Training acc= 0.8583, Validation cost= 0.2835, Validation acc= 0.8584
Epoch 45390: Training cost= 0.3028, Training acc= 0.8583, Validation cost= 0.2937, Validation acc= 0.8584
Epoch 45400: Training cost= 0.2799, Training acc= 0.8583, Validation cost= 0.2519, Validation acc= 0.8584
tm  [-0.2 -0.3 -1.1 -0.5 -2.1 -0.1  0.6  0.2 -0.6 -0.4  4.8 -0.3 -0.1 -0.3  1.  -0.6 -0.2 -0.4 -0.7 -0.1 -1.5 -0.3 -0.4 -0.1 -1.2  4.1  0.3 -0.4 -1.1 -2.   2.7 -0.2 -1.   3.7 -0.2 -0.2  2.7  4.3 13.7 -0.2  1.1  3.8  1.3  4.2  0.4  0.9 -0.1 -0.3  6.  -1.  -0.2 -0.2  0.7  1.6  0.8 -0.2 -0.5  3.   2.8 -1.1 -0.2 -0.4  0.6  0.2 -0.5  0.1 -0.1 -0.5  0.5  0.4 -0.1  2.9 -0.4  1.  -2.1 -0.6 -0.1  1.1 -0.  -0.   4.2  0.7 -0.   0.6 -0.7  4.3  6.1 -0.2  0.2 -0.5  0.5 -0.2 -0.3 -0.5 -0.8  0.7  1.4 -2.7 -0.1 -0.2  0.2 -0.3 -0.8 -0.2 -0.1 -0.3 -1.3  1.6  2.2 -0.9 -0.7 -0.3  0.1 -0.4  2.6 -1.3 -0.6 -0.5 -0.1 -0.4 -0.   3.7 -0.1 -0.  -0.5  1.1 -0.   1.6  5.2  2.6 -0.2 -0.5 -0.4 -0.2 -3.4 -3.1 -0.3 -0.1 -0.  -0.3  0.9 -0.9  0.3 -0.1 -0.  -0.5 -0.5 -0.2  6.6 -0.1 -0.1 -0.   1.3  0.2 -0.1  0.6 -0.7 -0.3  3.3 -0.1 -0.1 -1.6 -0.3 -0.  -0.2 -0.1 -0.3 -0.8 -0.1 -0.1 -0.  -0.1 -0.   0.  -0.  -0.9  3.2 -0.4 -1.2 -0.  -1.9 -0.1 -0.6 -1.6 -0.  -0.6  0.4 -0.6 -0.4  5.9 -0.3 -0.1 -0.3 -1.1  5.2 -1.6 -0.2 -0.6  0.2 -0.2  0.1  0.  -0.2 -0.1 -0.3 -1.2 -0.3 -0.2 -3.   0.5 -0.4 -0.9 -0.6 -0.5 -1.4 -0.2 -2.3 -1.4 -0.1 -0.7  0.2 -0.1 -0.3 -0.8 -1.5 -0.8 -1.3 -0.5  2.6  3.4 -0.4 -0.9 -0.2 -1.1  1.8  1.9 -0.1  0.2  5.  -1.9  0.3 -0.7 -0.2 -0.3 -0.2 -0.7 -0.4 -0.4 -1.1 -0.3 -1.3  0.1  8.6 -0.1  3.6  0.2]
ty_50sample [[5 0 4 3 9 2 7 8 1 6]
 [3 4 9 1 2 8 6 5 0 7]
 [4 7 0 0 5 6 2 2 3 8]
 [9 0 3 3 6 4 4 5 2 1]
 [5 3 6 7 0 9 8 4 1 2]
 [0 2 1 6 4 9 7 7 8 5]
 [4 5 1 2 7 0 6 9 8 3]
 [7 3 1 6 8 0 2 9 5 4]
 [6 9 1 5 2 0 4 7 3 8]
 [8 6 3 7 0 2 1 9 5 4]]
tt_50sample [[5 0 4 3 9 2 7 8 1 6]
 [3 4 9 1 2 8 6 5 0 7]
 [4 7 0 9 5 6 1 2 3 8]
 [9 0 3 8 6 4 7 5 2 1]
 [5 3 6 7 0 9 8 4 1 2]
 [0 2 1 6 4 9 7 3 8 5]
 [4 5 1 2 7 0 6 9 8 3]
 [7 3 1 6 8 2 0 9 5 4]
 [6 9 1 5 2 0 4 7 3 8]
 [8 6 7 3 0 2 1 9 5 4]]
vm  [-0.9  1.  -2.6 -1.1 -1.6 -0.3 -0.3 -0.1  0.9 -1.1 -0.3 -0.4 -0.3 -0.2 -0.8  1.5 -0.2 -0.4 -0.8  0.6 -1.4 -0.3 -0.6 -0.  -1.4  3.3 -0.3 -0.1  0.3 -3.7  2.  -0.  -0.3 -2.  -0.1 -0.4 -0.4 -0.2 -0.5  0.3  3.1 -0.5 -0.6  0.4  0.1 -0.2 -1.2 -0.1  2.1 -1.9 -0.2 -0.   1.1  0.6 -0.8  0.4 -0.6  3.4  8.6 -0.5  3.  -0.6  1.3 -0.  -0.   0.5 -0.1 -0.5 -0.3 -0.2 -0.3 -1.6 -0.6  0.8 -3.6 -0.1 -0.4  1.6 -0.3  0.  -0.2 -0.2 -0.  -0.2 -0.2 -0.1 -0.1 -0.1 -0.1 -0.4  0.  -0.3 -0.2 -1.2 -0.6  0.3  1.3 -3.6 -0.3 -0.1  2.9 -2.7 -0.3 -0.1 -0.1  0.5 -1.3  0.9 -0.1 -0.2 -0.4  0.5 -0.1 -1.   3.  11.3 -0.5  1.3  0.1 -0.5 -0.5 -0.2 -0.   1.8 -0.1 -0.9 -0.   2.5 11.9  7.6  0.1 -0.6 -0.6 -0.6  8.3  3.7  0.4  0.3  0.7 -0.2  1.7 -0.4 -0.2 -0.3 -0.2 -0.1 -0.3  0.   8.3 -0.2  0.6 -0.  -0.2 -0.1 -0.2  0.4 -0.9 -0.1  2.  -0.2 -0.6 -0.5  0.1 -0.1  0.2 -0.2  0.1 -0.1 -0.  -0.2 -0.1 -0.  -0.2 -0.2 -0.1 -1.3 -0.7 -0.2  1.8 -0.  -1.3 -0.1 -0.2 -2.4 -0.2 -0.5 -0.2 -0.3 -0.2 10.5 -0.   0.   0.3 -1.2 -0.7 -3.9 -0.2 -0.9 -0.2 -0.1 -0.3 -0.1 -0.1 -0.5 -0.1 -1.8 -0.3 -0.1 -1.6  1.2 -0.1  5.  -0.4  2.9 -1.2 -0.5 -0.4 -1.4 -0.8 -0.5 -0.3  0.  -0.2 -1.2 -1.1  2.9 -1.7  0.3 -0.3  1.6 -0.4 -1.1 -0.3 -0.6 -0.3  3.9 -0.4 -0.2  5.6 -2.  -0.1 -0.7  0.  -0.3  2.9 -0.3 -0.7 -0.4 -1.8  1.  -0.  -0.1 -0.2 -0.2  7.6 -1.4]
vy_50sample [[3 5 1 4 6 8 9 2 0 7]
 [0 2 1 4 5 3 8 6 9 7]
 [4 3 3 8 7 1 5 9 6 0]
 [0 6 3 7 9 5 4 2 8 1]
 [8 6 0 2 3 4 1 5 7 9]
 [3 1 4 2 7 8 5 6 0 9]
 [0 9 2 7 5 1 3 6 4 8]
 [5 8 2 7 3 1 9 4 6 0]
 [2 1 3 6 0 0 8 7 4 9]
 [7 0 5 6 9 1 3 8 4 2]]
vt_50sample [[3 5 4 1 6 8 9 2 0 7]
 [0 2 1 5 4 3 8 6 9 7]
 [4 2 3 8 7 1 5 9 6 0]
 [0 6 3 7 9 5 4 2 8 1]
 [8 6 0 2 3 4 1 5 7 9]
 [3 1 4 2 7 8 5 6 0 9]
 [0 9 2 7 5 1 3 6 4 8]
 [5 8 2 7 3 9 1 4 6 0]
 [2 1 3 6 0 5 8 7 4 9]
 [7 0 5 6 9 1 3 8 4 2]]
Epoch 45410: Training cost= 0.2849, Training acc= 0.8583, Validation cost= 0.2728, Validation acc= 0.8584
Epoch 45420: Training cost= 0.2502, Training acc= 0.8583, Validation cost= 0.2551, Validation acc= 0.8584
Epoch 45430: Training cost= 0.2392, Training acc= 0.8584, Validation cost= 0.2582, Validation acc= 0.8584
Epoch 45440: Training cost= 0.2668, Training acc= 0.8584, Validation cost= 0.3005, Validation acc= 0.8584
Epoch 45450: Training cost= 0.2446, Training acc= 0.8584, Validation cost= 0.2696, Validation acc= 0.8584
Epoch 45460: Training cost= 0.2400, Training acc= 0.8584, Validation cost= 0.2665, Validation acc= 0.8584
Epoch 45470: Training cost= 0.2658, Training acc= 0.8584, Validation cost= 0.2218, Validation acc= 0.8585
Epoch 45480: Training cost= 0.2256, Training acc= 0.8584, Validation cost= 0.2047, Validation acc= 0.8585
Epoch 45490: Training cost= 0.2193, Training acc= 0.8584, Validation cost= 0.2307, Validation acc= 0.8585
Epoch 45500: Training cost= 0.2578, Training acc= 0.8584, Validation cost= 0.2255, Validation acc= 0.8585
tm  [-1.2 -0.2 -2.9 -2.2 -1.3 -0.2  0.1 -0.1 -0.5 -0.2 -4.5 -0.1 -0.3 -0.4 -0.  -0.3  1.1 -0.1 -1.   1.8 -1.7 -0.  -0.5 -0.  -1.3  1.6 -0.1 -0.7 -0.7 -2.3 -0.5 -0.5 -1.  -5.6 -0.2 -0.2 -0.  -0.6 -2.  -0.5  1.6 -2.8 -0.5  1.3 -0.3  0.  -2.6 -0.2 -0.1 -1.  -0.3 -0.1 -0.1  2.7 -1.4 -0.3 -0.6 -1.1  4.   3.7  6.  -0.3 -0.2  0.1 -1.  -0.7 -0.2 -0.3 -0.3 -0.1  0.1 -0.7  0.2  1.6 -6.  -0.7 -0.3 -0.4 -0.1 -0.4 -5.5  0.8 -0.2 -0.4 -0.5 -2.8 -0.1 -0.3 -0.2 -0.5  0.6 -0.2  0.7 -0.3 -0.6 -0.3 -0.5 -3.4 -0.1 -0.2 -0.1 -3.1 -0.  -0.  -0.5  0.3 -2.2 -0.1 -1.5 -0.1 -0.1  0.4 -0.1 -0.7  1.7  4.9 -0.7  0.6  0.5 -0.4  0.3 -0.7 -0.1 -0.   0.7  0.4 -0.2  0.5  4.7 16.7 -0.2 -0.   0.8 -0.1  9.8 -2.3 -0.1 -0.2  0.3 -0.3  2.7 -0.5 -0.   0.1  0.1 -0.3 -0.2 -0.2  4.2 -0.1  1.2 -0.3  1.6 -0.  -0.2 -0.  -1.  -1.   1.  -0.3  0.  -0.6  0.8 -0.2  0.1 -0.2 -0.4  0.7  1.3 -0.  -0.1 -0.1 -0.2 -0.1 -0.1 -0.1 -0.3 -0.1  3.2 -0.2 -0.2 -0.5 -0.4 -2.3 -0.4  0.4 -0.6  0.3 -0.4  6.6 -0.3 -0.1 -0.1 -1.3 -2.1 -1.6 -0.3 -0.3 -0.1  0.6 -0.  -0.2 -0.1 -0.8 -0.  -2.3 -0.4 -0.4  8.  -0.4 -0.5  1.4 -1.1  6.4 -0.8 -0.5 -0.4 -1.1 -0.6  1.1 -0.2 -0.2  0.3 -0.9 -1.1  2.  -2.2 -0.1 -0.6 -0.4 -0.3 -0.4 -0.5  1.5 -0.9  4.6 -0.2 -0.8  2.8 -1.3  0.3 -0.6  0.1 -0.4 16.8  2.1 -0.7  0.6 -1.1 -0.5 14.  -0.1 -1.1 -0.1  8.9 -4. ]
ty_50sample [[3 8 1 4 6 0 5 2 9 7]
 [8 3 7 7 6 5 4 0 9 1]
 [7 4 5 0 1 2 8 9 6 3]
 [3 2 9 8 5 6 1 7 4 0]
 [4 9 5 7 0 8 8 6 1 2]
 [4 6 1 2 5 7 3 3 0 8]
 [7 3 5 8 2 6 9 4 1 0]
 [7 1 2 4 5 9 9 6 8 0]
 [9 4 8 2 3 0 7 6 1 5]
 [0 6 8 4 3 5 9 7 2 1]]
tt_50sample [[3 8 1 4 6 0 5 2 9 7]
 [8 3 2 7 6 5 4 0 9 1]
 [7 4 5 0 1 2 8 9 6 3]
 [3 2 9 8 5 6 1 7 4 0]
 [4 9 5 0 7 8 3 6 1 2]
 [4 6 1 2 5 7 3 0 9 8]
 [7 3 5 8 2 6 9 4 1 0]
 [7 1 2 4 5 3 9 6 8 0]
 [9 4 8 2 3 0 7 6 1 5]
 [0 6 8 4 3 9 5 7 2 1]]
vm  [-0.5 -0.  -3.   1.7 -1.9  0.3 -0.3  0.2 -0.8 -0.7  5.9 -0.3  0.5 -0.4 -2.1  0.6 -0.2 -0.3 -0.7 -0.5 -1.2 -0.2  1.  -0.  -1.2  4.6 -0.1 -0.2 -1.5 -1.   3.2 -0.4 -0.3 -0.1  0.1  0.3  5.4  6.9 18.8 -0.2  1.8  1.9  1.9  4.6  0.1  1.1  4.3 -0.1  2.8  2.1 -0.3 -0.3  1.4 -0.9  0.5  1.8 -0.5 -1.3 -0.5 -1.9 -0.8 -0.3  2.1  1.  -0.5  0.6 -0.1 -0.5 -0.3 -0.   1.   3.1 -0.3  1.2  2.6 -0.2 -0.1  0.7  0.3  0.8 13.4  0.  -0.1 -0.  -0.4  3.7  5.6 -0.2 -0.1 -0.1  1.3 -0.2  0.6 -0.2 -0.2  0.1  0.5 -0.9  1.1 -0.   1.1  0.1 -0.7 -0.1 -0.1 -0.2  1.8  2.4  1.9 -1.  -0.8  0.1 -0.1  0.5  1.4 -1.6 -0.5 -1.3 -0.4 -0.6  0.3  5.7  0.9  1.9 -0.1 -2.6 -0.   5.2 -0.7 -1.9 -0.5 -0.   0.4 -0.5 -1.8 -2.6 -0.1 -0.3  1.  -0.3 -0.3 -1.1 -0.5 -0.1 -0.1 -0.3 -0.2 -0.2  4.2 -0.1 -0.6 -0.3  0.5 -0.4 -0.   0.3 -0.9  0.6  4.5 -0.4  2.3 -1.5 -0.1  0.1  0.2 -0.5 -0.3 -0.5  0.7 -0.2 -0.1 -0.  -0.1  0.7 -0.  -0.5  1.9  0.9 -1.6 -0.  -0.6 -0.2 -0.6 -1.6 -0.3 -0.6 -0.1 -0.4 -0.4  2.9  0.1  0.2  0.3 -1.1  7.6  2.5  1.7 -0.3  0.1  0.  -0.  -0.  -0.1 -0.6 -0.   3.5 -0.  -0.3 -0.4  0.6 -0.6 -1.1 -0.6  3.8 -0.8 -0.3 -2.4 -1.1 -0.5 -0.3 -0.1 -0.1 -0.6 -0.7 -0.5 -0.5 -0.4  0.8  0.9  0.3 -0.3 -1.8  0.2 -0.   3.2  5.8 -0.1  2.7  2.5 11.2 -0.1  3.4 -0.  -0.1 -2.4 -2.2 -0.6  1.6 -1.  -0.6 -3.5 -0.  11.2 -0.1 -0.6  8.3]
vy_50sample [[9 4 0 2 5 1 3 8 7 6]
 [0 1 8 4 2 7 6 3 9 5]
 [8 2 3 4 6 7 5 0 9 1]
 [6 1 8 7 5 4 9 0 3 2]
 [1 8 8 6 6 5 5 2 4 0]
 [9 6 5 3 8 2 7 1 0 4]
 [0 6 7 2 4 5 8 9 1 3]
 [1 4 5 3 8 0 6 9 2 7]
 [5 9 3 1 4 6 2 8 7 0]
 [2 5 6 8 7 4 3 9 1 0]]
vt_50sample [[9 4 0 2 5 1 3 8 7 6]
 [0 1 8 4 2 7 6 3 9 5]
 [8 2 3 4 6 7 5 0 9 1]
 [6 1 8 7 5 4 9 0 3 2]
 [1 7 8 6 9 5 2 0 3 4]
 [9 6 5 3 8 2 7 1 0 4]
 [0 6 7 2 4 5 8 9 1 3]
 [1 4 5 3 8 0 6 9 2 7]
 [5 9 3 1 4 6 2 8 7 0]
 [2 5 6 8 7 4 3 9 1 0]]
Epoch 45510: Training cost= 0.2187, Training acc= 0.8584, Validation cost= 0.1876, Validation acc= 0.8585
Epoch 45520: Training cost= 0.2436, Training acc= 0.8585, Validation cost= 0.2118, Validation acc= 0.8585
Epoch 45530: Training cost= 0.2323, Training acc= 0.8585, Validation cost= 0.2344, Validation acc= 0.8585
Epoch 45540: Training cost= 0.2117, Training acc= 0.8585, Validation cost= 0.2248, Validation acc= 0.8585
Epoch 45550: Training cost= 0.2477, Training acc= 0.8585, Validation cost= 0.2590, Validation acc= 0.8585
Epoch 45560: Training cost= 0.2197, Training acc= 0.8585, Validation cost= 0.2297, Validation acc= 0.8585
Epoch 45570: Training cost= 0.2618, Training acc= 0.8585, Validation cost= 0.2295, Validation acc= 0.8586
Epoch 45580: Training cost= 0.2584, Training acc= 0.8585, Validation cost= 0.2167, Validation acc= 0.8586
Epoch 45590: Training cost= 0.2250, Training acc= 0.8585, Validation cost= 0.2411, Validation acc= 0.8586
Epoch 45600: Training cost= 0.2799, Training acc= 0.8585, Validation cost= 0.2497, Validation acc= 0.8586
tm  [-1.4 -0.1 -2.6  3.1 -1.4 -0.  -0.8 -0.2 -0.1 -0.2  5.3 -0.3 -0.1 -0.2 -2.3 -0.4 -0.4 -0.2 -0.4 -0.5 -1.9 -0.2 -0.2  0.4 -1.   2.3 -0.7 -0.2 -0.9 -5.3  2.  -0.  -0.4 -1.  -0.1 -0.1  0.5  4.5 11.2 -0.4  1.3 -1.8 -1.4  2.1 -0.3 -0.   0.6 -0.1 -1.2 -2.  -0.1 -0.2  0.1 -0.1 -0.6  2.2 -0.9 -0.9 10.1 -1.   5.1 -0.6  1.3 -0.  -0.3 -0.5 -0.1 -0.5  0.  -0.4 -0.   0.9 -0.1  3.2 -2.4 -0.6 -0.4 -0.8 -0.2 -0.4 10.2  0.  -0.1 -0.7  1.9 -1.6 -1.3 -0.2 -0.1 -0.5 -0.2 -0.  -0.1 -1.2 -0.6  0.1 -0.6 -2.8 -0.1 -0.1  1.9 -2.   1.1  0.1 -0.1 -0.2 -0.8  0.4  1.  -1.3 -0.7 -0.  -0.3 -0.4  5.9  0.2 -0.   0.6 -0.4 -0.3 -0.3  4.5  0.7 -0.2 -0.3 -2.6  0.6  3.1 12.   2.  -0.5 -0.4 -0.  -0.1  2.1 -0.9 -0.2 -0.2  1.1 -0.   1.  -0.5 -0.6 -0.1 -0.2 -0.1 -0.3 -0.2  3.7 -0.2 -0.4 -0.1 -1.5 -0.1 -0.1 -0.2  0.1  1.2  4.1 -0.2 -0.5 -1.6 -0.3  0.  -0.4  0.2  0.3  0.7  0.1 -0.1 -0.1 -0.1 -0.3  0.3 -0.1 -0.5  0.1 -0.3 -0.8 -0.2 -0.8 -0.3 -0.3 -1.7 -0.1 -0.3 -0.5 -0.  -0.5 14.8 -0.  -0.  -0.  -1.  -1.3 -3.8  0.6 -1.6 -0.  -0.1 -0.3 -0.1 -0.3 -0.5 -0.  -0.9 -0.4 -0.1 -0.8 -0.  -0.3 -0.2 -1.1  7.1 -0.8 -0.6 -1.2 -1.4 -0.8  0.8 -0.1 -0.2 -0.3 -1.  -1.9 -0.3 -1.6  1.2 -0.2 -0.4 -0.1 -0.7 -0.1 -0.2  1.2  3.6 -0.5 -0.1  4.   5.8 -0.2  0.9 -0.3 -0.  -1.7 -0.8 -0.6  0.5 -1.4  1.7 -2.8  0.2  7.3  0.1  5.9  0.7]
ty_50sample [[1 3 0 9 4 2 5 8 7 7]
 [2 8 3 0 1 7 5 9 6 4]
 [3 1 8 9 9 7 4 0 2 6]
 [1 3 9 0 5 7 8 8 6 2]
 [5 2 0 6 4 9 8 3 7 1]
 [2 3 8 4 0 6 7 5 1 9]
 [5 7 1 4 9 3 6 2 8 0]
 [7 0 0 2 8 8 3 1 4 6]
 [9 7 0 3 8 4 2 1 1 5]
 [5 1 0 2 3 6 7 8 9 4]]
tt_50sample [[1 3 0 9 4 2 5 8 6 7]
 [2 8 3 0 1 7 5 9 6 4]
 [3 1 8 5 9 7 4 0 2 6]
 [1 3 9 5 0 7 8 4 6 2]
 [5 2 0 6 4 9 8 3 7 1]
 [2 3 8 4 0 6 5 7 1 9]
 [5 7 1 9 4 3 6 2 8 0]
 [7 0 9 2 5 8 3 1 4 6]
 [9 7 0 3 8 4 2 6 1 5]
 [5 1 0 2 3 6 7 8 9 4]]
vm  [ 0.5  0.1 -2.9 -3.1 -0.7 -0.3 -0.6 -0.4  1.3 -0.4  7.8 -0.3 -0.2 -0.  -0.3  3.5 -0.5 -0.3 -0.2 -0.3 -1.6 -0.1  0.1 -0.2 -1.2 -0.1 -0.6  0.1  0.1 -2.1  3.2 -0.3  2.1 -1.1 -0.1 -0.3 -0.8 -0.1 -4.  -0.3 -0.6 -2.4 -1.5 -0.9 -0.3 -0.5 -0.5 -0.3  5.  -0.1 -0.3 -0.3 -0.1 10.1 -1.6 -0.1 -0.4 -2.6  8.7 -1.6 -0.3 -0.4  0.1 -0.1  2.  -1.  -0.5  1.3 -0.1 -0.3 -0.3 -1.   0.4 -0.4 -4.3 -0.2 -0.4 -0.3 -0.2 -0.3 -0.1 -0.6  0.3 -0.3 -1.9 -2.3  6.  -0.  -0.3 -0.3 -0.2 -0.2 -0.5 -1.4 -0.5 -0.2 -0.4 -3.2 -0.7 -0.3  1.9 -0.7 -0.8 -0.1  0.3 -0.5 -2.5 -0.2  0.6 -0.3 -0.3 -0.1 -0.1 -1.1  4.7  4.8  0.7  1.9 -0.2 -0.  -0.5 -0.4 -0.2 -0.2 -0.4 -0.3 -0.3 -2.   7.   3.3  0.9 -0.6 -0.3  0.5 14.3 14.4  1.  -0.  -0.2 -0.8 -0.9 -0.4 -0.7 -0.  -0.2  0.4 -0.4 -0.2 -0.7  0.2  2.4 -0.1  3.4 -0.3 -0.1 -0.2 -0.2  0.8 -1.3 -0.2 -0.7  0.1 -0.2 -0.2 -0.3 -0.1 -0.1  0.7 -0.4 -0.1 -0.1 -0.3 -0.2 -0.3 -0.4  2.2 -1.8 -0.3  4.3 -0.2  1.4 -0.6  0.2 -1.6 -0.2  0.1  0.8 -0.1 -0.1  5.2 -0.2 -0.4 -0.3 -1.1  5.1 -2.4 -0.5 -1.4 -0.4 -0.3 -0.3 -0.2 -0.7 -0.5 -0.4 -2.4 -0.3 -0.1  6.7 -0.3 -0.5  2.8 -0.8 -1.5  0.5 -0.3  3.2 -1.3 -0.6  1.7 -0.2 -0.2 -0.2 -1.6  1.9  2.2 -0.1  0.7 -0.2  3.6  0.5  0.4 -0.4  2.3 -0.8  3.3  0.1 -0.7  1.7  8.2 -0.2  1.7 -0.1 -0.1  2.5 -0.4  0.4 -0.2 -1.3  2.8 -0.4 -0.2 -2.2 -0.4 -0.2 -0.3]
vy_50sample [[6 2 4 3 8 9 0 7 1 5]
 [3 2 0 6 7 8 1 1 9 5]
 [0 6 5 8 2 9 9 1 7 4]
 [9 6 3 7 4 5 0 8 1 2]
 [5 6 7 8 1 4 9 0 2 3]
 [5 1 9 2 4 3 8 7 0 6]
 [0 4 5 6 8 3 2 7 1 9]
 [0 4 3 5 7 2 8 1 6 9]
 [9 7 0 5 4 2 8 6 3 1]
 [3 8 1 0 0 6 9 5 7 7]]
vt_50sample [[6 2 4 3 8 9 0 7 1 5]
 [3 2 0 6 7 8 1 9 4 5]
 [0 6 5 8 2 3 9 1 7 4]
 [9 6 3 7 4 5 0 8 1 2]
 [5 6 7 8 1 4 9 0 2 3]
 [5 1 9 2 4 3 8 7 0 6]
 [0 4 5 6 8 3 7 2 1 9]
 [0 4 3 5 7 2 8 1 6 9]
 [9 7 0 5 4 2 8 6 3 1]
 [3 8 1 0 9 6 2 5 7 4]]
Epoch 45610: Training cost= 0.2300, Training acc= 0.8585, Validation cost= 0.2179, Validation acc= 0.8586
Epoch 45620: Training cost= 0.2775, Training acc= 0.8586, Validation cost= 0.2682, Validation acc= 0.8586
Epoch 45630: Training cost= 0.2148, Training acc= 0.8586, Validation cost= 0.2382, Validation acc= 0.8586
Epoch 45640: Training cost= 0.2841, Training acc= 0.8586, Validation cost= 0.2660, Validation acc= 0.8586
Epoch 45650: Training cost= 0.2591, Training acc= 0.8586, Validation cost= 0.2363, Validation acc= 0.8586
Epoch 45660: Training cost= 0.2002, Training acc= 0.8586, Validation cost= 0.2364, Validation acc= 0.8586
Epoch 45670: Training cost= 0.1964, Training acc= 0.8586, Validation cost= 0.2261, Validation acc= 0.8587
Epoch 45680: Training cost= 0.2515, Training acc= 0.8586, Validation cost= 0.1924, Validation acc= 0.8587
Epoch 45690: Training cost= 0.2481, Training acc= 0.8586, Validation cost= 0.1938, Validation acc= 0.8587
Epoch 45700: Training cost= 0.2751, Training acc= 0.8586, Validation cost= 0.3010, Validation acc= 0.8587
tm  [-1.1 -0.3  7.9 10.8 -2.2  0.4 -0.  -0.2 -0.5  0.4 -4.  -0.3 -0.2 -0.1  3.6 -2.6 -0.3 -0.4 -0.  -0.7 -0.9 -0.3 -0.  -0.2 -0.9  2.  -0.3  0.5 -1.5 -2.8 -1.3 -0.2 -0.3 -0.5 -0.  -0.3  2.1 -0.   5.4 -0.2 -0.5  5.1 -0.5 -0.7 -0.3 -0.4  0.9 -0.4 -1.   7.5 -0.1 -0.  -0.6 -1.   2.3 -0.4 -0.7 11.   1.8  6.4  4.  -0.6 -0.4 -0.3 -0.7 -0.4  0.4 -0.3  1.6 -0.3 -0.   7.1 -0.6 -0.3 -3.6 -0.5 -0.2 -0.7 -0.1 -0.1 -1.9 -0.3 -0.5 -0.8  0.1  5.1 -2.5 -0.  -0.1 -0.2  0.3 -0.1  0.2 -0.6 -0.2 -0.4 -0.5 -2.6 -0.2 -0.4 -0.3  3.3 -0.5 -0.5 -0.3 -0.1 -1.8 -0.3 -1.2 -1.   0.4  0.3 -0.2 -0.   5.6 -4.  -0.7 -0.1 -0.3 -0.1 -0.2  3.1 -0.3  0.2  0.2  4.2 -0.1  5.1  2.  -0.3 -0.4 -0.3 -0.2 -0.1 -2.3 -3.  -0.3  0.  -0.  -0.4  0.5 -1.  -0.1 -0.4 -0.   0.3 -0.3 -0.1  3.9 -0.3 -1.2 -0.1  0.3  0.2 -0.2 -0.1 -0.4  1.1  0.6 -0.3 -0.5 -1.4 -0.  -0.1 -0.3 -0.2  0.2 -0.3 -0.3 -0.2 -0.2  0.  -0.3 -0.2 -0.3 -0.6 -0.  -0.4 -0.3 -0.1 -2.3 -0.3  0.  -1.8 -0.2 -0.1 -0.3 -0.4  0.8  7.4 -0.  -0.1 -0.2 -0.8 -1.2 -0.5 -0.8 -1.2 -0.  -0.1 -0.3 -0.1 -0.3 -0.3 -0.2 -1.6 -0.4 -0.3 -1.5 -0.1 -0.4 -2.6 -0.3  4.3 -0.1 -0.5  3.4 -0.9 -0.6 -0.4 -0.2 -0.1 -0.4 -1.4  0.3 -1.5 -1.7  0.5 -0.1 -0.4 -0.8  0.9 -0.3 -0.6  2.2 -1.9 -0.  -0.7  1.1 -3.6 -0.  -1.3 -0.2  0.   7.  -0.1 -0.2 -0.1 -1.   0.7  4.4 -0.   3.2 -0.1  3.9  3.5]
ty_50sample [[0 5 1 8 7 9 3 6 2 4]
 [7 9 9 4 0 6 8 1 2 3]
 [3 4 8 0 1 5 6 2 9 7]
 [5 4 0 7 6 9 3 1 8 2]
 [0 7 4 5 2 1 3 6 6 8]
 [5 1 6 3 2 7 9 8 4 0]
 [8 7 9 2 6 0 5 3 4 1]
 [0 2 4 3 1 7 6 9 8 8]
 [0 6 9 7 4 2 1 5 8 3]
 [1 7 5 8 4 2 3 0 6 9]]
tt_50sample [[0 5 1 8 7 9 3 6 2 4]
 [7 9 4 5 0 6 8 1 2 3]
 [3 4 8 0 1 5 6 2 9 7]
 [5 4 0 7 6 3 9 1 8 2]
 [0 7 4 5 2 1 3 9 6 8]
 [5 1 6 3 2 7 9 8 4 0]
 [8 7 9 6 2 0 5 3 4 1]
 [0 2 4 1 3 7 6 9 8 5]
 [0 6 9 7 4 2 1 5 8 3]
 [1 7 5 8 4 2 3 0 6 9]]
vm  [-0.8 -0.2 -0.4 -0.5 -0.9 -0.1 -0.4  0.4 -1.3 -0.8 -0.1 -0.3 -0.1 -0.3  1.2  5.  -0.2 -0.4 -0.3 -0.2 -1.  -0.   1.5 -0.3 -1.4 -0.2 -0.4  0.1  1.1  4.5 -1.2 -0.1 -1.2 -4.5 -0.1 -0.3  1.4 -1.2 -5.2 -0.5 -0.8  2.6  2.1 -1.2 -0.1  0.2 -1.3  0.3 -0.3  4.1 -0.1  0.3 -0.4 10.2 -1.2 -0.4 -0.7  7.9 -1.3  5.7  6.1 -0.7 -0.9 -0.1 -0.1  0.9 -0.2  0.1 -0.2 -0.3 -0.1 -1.6 -0.4 -0.1 -4.1 -0.1 -0.2  0.1 -0.   1.1 -4.8 -0.  -0.2  1.3 -0.2  3.7 -0.6 -0.2 -0.2 -0.5 -0.8 -0.2 -0.4  1.6 -0.4  0.7 -0.2 -3.1 -0.4 -0.1  2.1 -1.2 -0.1 -0.  -0.2 -0.1 -2.7 -0.4  0.4 -0.4 -0.4 -0.2 -0.1 -0.5 -2.  12.9 -0.9 -0.9 -0.4 -0.4 -0.1  0.1 -0.3 -0.  -0.   1.6  0.1 -1.9 -0.9 10.   0.4 -0.5 -0.7 -0.4 16.3  8.2 -0.3 -0.1 -0.7 -0.3 -0.6 -0.3 -0.5 -0.  -0.1 -0.1 -0.  -0.3  7.3 -0.2 -0.2 -0.1  1.1 -0.1 -0.4  0.1 -0.1 -0.5 -2.2 -0.9 -0.6  3.4 -0.2 -0.2 -0.1  0.3 -0.4 -0.4 -0.3 -0.2 -0.1 -0.2 -0.2 -0.4  0.2 -1.5 -1.  -0.2  5.  -0.2 -2.6  0.6 -0.6 -1.9 -0.2  0.1 -0.4 -0.4  0.5 -1.1 -0.1 -0.1 -0.1 -0.7 -2.   2.9 -0.8  4.5 -0.3 -0.3 -0.2 -0.1 -0.5 -0.1  0.7 -4.1  0.5 -0.1 -0.7  0.5 -1.   0.5 -0.4  0.9 -0.4 -0.2  6.5 -0.4 -0.5 -0.5 -0.  -0.2 -0.2 -1.   3.6  7.  -0.3 -0.5 -0.5  1.4 -0.   2.  -0.4 -0.4 -0.7  0.6 -0.2 -0.8  1.2 -5.6  0.5 -1.6 -0.  -0.  15.5  5.7  0.6 -0.2 -0.6 -0.6 12.7  0.5 -3.1 -0.2  0.3 -2.2]
vy_50sample [[6 5 8 2 3 1 4 7 7 0]
 [0 6 3 8 2 4 9 1 7 5]
 [9 6 1 7 0 8 5 2 3 4]
 [1 2 5 3 0 8 4 9 7 6]
 [0 3 8 7 1 5 4 9 6 2]
 [8 7 0 0 4 3 6 5 1 2]
 [8 4 2 1 3 7 0 6 9 5]
 [7 6 4 1 3 0 2 5 8 9]
 [5 9 8 3 4 2 1 7 6 0]
 [9 6 5 4 4 0 8 1 7 3]]
vt_50sample [[6 5 8 3 2 1 4 7 9 0]
 [0 6 3 8 2 4 9 1 7 5]
 [9 6 1 7 0 8 5 2 3 4]
 [1 2 3 5 0 8 4 9 7 6]
 [0 3 8 1 7 5 4 9 6 2]
 [8 7 9 0 4 3 6 5 1 2]
 [8 4 2 1 3 7 0 6 5 9]
 [7 6 4 1 3 0 2 5 8 9]
 [5 9 8 3 4 2 1 7 6 0]
 [9 6 5 4 2 0 8 1 3 7]]
Epoch 45710: Training cost= 0.3016, Training acc= 0.8586, Validation cost= 0.2716, Validation acc= 0.8587
Epoch 45720: Training cost= 0.3119, Training acc= 0.8587, Validation cost= 0.2653, Validation acc= 0.8587
Epoch 45730: Training cost= 0.3647, Training acc= 0.8587, Validation cost= 0.2102, Validation acc= 0.8587
Epoch 45740: Training cost= 0.2047, Training acc= 0.8587, Validation cost= 0.2315, Validation acc= 0.8587
Epoch 45750: Training cost= 0.2624, Training acc= 0.8587, Validation cost= 0.2218, Validation acc= 0.8587
Epoch 45760: Training cost= 0.2321, Training acc= 0.8587, Validation cost= 0.2609, Validation acc= 0.8587
Epoch 45770: Training cost= 0.2653, Training acc= 0.8587, Validation cost= 0.2530, Validation acc= 0.8587
Epoch 45780: Training cost= 0.2978, Training acc= 0.8587, Validation cost= 0.2384, Validation acc= 0.8588
Epoch 45790: Training cost= 0.2773, Training acc= 0.8587, Validation cost= 0.2510, Validation acc= 0.8588
Epoch 45800: Training cost= 0.2844, Training acc= 0.8587, Validation cost= 0.2311, Validation acc= 0.8588
tm  [-0.4 -0.1 10.7 -0.9 -1.3 -0.3 -0.3 -0.1 -0.4  0.3 10.  -0.2 -0.2  0.1 17.9  3.5 -0.4  0.3 -0.5 -0.3 -1.3  0.3 -0.4 -0.3 -0.7 -0.8 -0.  -0.2 -0.5 -1.4  1.  -0.2  1.3 18.7 -0.1 -0.2 -0.   7.4 -0.  -0.4  1.8  6.6 -0.4  1.5 -0.4  0.3 -2.  -0.3 -0.7 -1.9 -0.2 -0.4 -0.5 12.5 -1.5 -2.  -1.  10.1  3.2 -0.2  6.7 -0.5  0.6  0.7  2.9 -1.  -0.4 -0.1 -0.2 -0.3  0.6 -1.  -0.6 -0.6 -6.8 -1.1 -0.2 -0.6 -0.3 -0.2 -0.1 -0.3 -0.2 -0.4 -0.4  4.  -1.1 -0.1 -0.4 -0.5 -0.1 -0.   0.1  0.5 -0.3 -0.8 -0.3 -3.7 -0.1 -0.4  0.6  5.3  0.4 -0.2 -0.3 -0.2 -3.6  0.1  0.5  2.   1.1  0.  -0.4 -1.1  0.2  4.9 -0.8  1.8 -0.3 -0.2 -0.1 -1.3 -0.1  0.8  0.7 21.9 -0.3 -2.8  8.   8.9 -0.2 -0.   0.1  0.6 -7.5  1.  -0.2 -0.1 -0.3 -0.6 -0.7 -0.  -0.5 -0.4 -0.1 -0.4 -0.6 -0.3  3.4 -0.2 -0.1 -0.2 -1.1 -0.7  0.1 -0.2 -0.3  0.1  2.7 -0.7 -0.3 -1.7 -0.1 -0.2 -0.2  1.2 -0.  -0.  -0.1 -0.2 -0.2  0.1  0.3 -0.  -0.1 -0.1 -0.4 -0.7  0.5 -0.1 -2.5 -0.8 -0.2 -1.2 -0.1 -0.6 -0.6 -0.8 -0.3  4.1  0.6 -0.4 -0.2 -0.7 -2.6 -2.4 -1.1 -0.2 -0.2 -0.2 -0.4 -0.2 -0.  -0.6 -0.2 -3.8 -0.2 -0.4 -6.4 -0.1 -0.8  0.7 -0.7  1.5  0.2 -0.4 -0.5 -1.3 -0.5 -0.3 -0.1 -0.1  0.9 -1.  -1.2  0.2  0.2  1.2 -1.7  0.2 -0.5  2.3 -0.1 -1.9 -0.7 -2.1  0.2 -1.2  0.9 -8.6 -0.3 -3.1 -0.1 -0.   2.5  5.5 -0.6 -0.1 -0.8  1.1 -0.2 -0.3  0.4 -0.4 -0.2 -2.1]
ty_50sample [[5 7 2 1 3 0 4 8 6 9]
 [0 6 2 1 9 4 5 8 7 3]
 [1 2 3 8 6 4 0 5 7 9]
 [3 8 5 7 4 2 1 6 9 0]
 [8 0 2 1 6 4 5 9 7 3]
 [9 0 2 1 8 7 3 4 5 5]
 [8 9 3 1 5 2 0 4 6 7]
 [6 1 7 4 4 2 3 8 5 0]
 [2 4 0 6 5 9 3 8 1 7]
 [7 6 3 1 4 4 0 2 5 9]]
tt_50sample [[5 7 2 1 3 0 4 8 6 9]
 [0 6 2 1 9 4 8 5 7 3]
 [1 2 8 3 4 6 0 5 7 9]
 [3 8 7 5 4 2 1 6 9 0]
 [8 2 0 1 6 4 5 9 7 3]
 [9 0 2 1 8 7 3 4 6 5]
 [8 9 3 1 5 2 0 4 6 7]
 [6 1 7 9 4 2 3 8 0 5]
 [4 2 0 6 5 9 3 8 1 7]
 [7 6 3 1 8 4 0 2 5 9]]
vm  [-0.9 -0.2 -0.1  6.3 -1.6 -0.3 -0.2  0.   1.8 -0.1  1.9 -0.5 -0.2 -0.1 -1.  -1.3 -0.1 -0.5 -0.1 -1.1 -1.4 -0.  -0.2 -0.1 -0.6  3.2 -0.2 -0.4 -0.4 -3.2  2.9 -0.2 -0.4  7.7 -0.  -0.2 -0.5 -0.7  7.4 -0.1  2.5  6.1 -0.6  2.5  0.3  0.6  4.9  0.4 -0.4 -0.3 -0.2 -0.1 -0.4 -2.5  0.1  1.3 -0.9  4.8  8.9 -1.6  1.  -0.3 -0.3  0.2  1.5  0.5 -0.  -0.4  2.1 -0.1  0.1  1.  -0.4  0.9 -1.1 -0.4 -0.1  0.2 -0.1 -0.2 17.3 -0.2  0.1  0.7  1.8  6.9 -0.6  0.1 -0.2 -0.3  0.2  0.2 -0.1 -1.9 -0.6  0.2  1.7 -2.8 -0.3 -0.3  1.1  3.6  0.6 -0.  -0.2 -0.  -0.6  0.2  0.8 -1.5 -0.7  0.  -0.  -0.6  8.2 -0.   0.8  1.7 -0.3 -0.3  0.4  6.3  0.4  0.   0.9 -1.1 -0.  10.4 11.6 -1.8 -0.6 -0.5 -0.5 -0.7 -0.2  7.7 -0.3 -0.2 -0.2 -0.1  2.4 -0.4  0.6 -0.  -0.  -0.1 -0.2 -0.   5.9 -0.  -0.5 -0.1 -1.   0.9 -0.  -0.  -0.3 -0.3  2.  -0.  -0.1 -0.6 -0.2 -0.2 -0.3 -0.5 -0.1 -0.1 -0.1  0.2 -0.1 -0.   0.5 -0.2  0.  -0.5 -0.4 -0.5 -0.4  0.3 -1.6 -0.  -0.6 -1.7 -0.1 -0.3 -0.3 -0.5  0.2  9.7  0.3 -0.2 -0.5 -0.5  2.  -3.7 -0.  -2.3  0.2 -0.1 -0.1 -0.1 -0.  -0.4 -0.  -0.8 -0.3 -0.2 -4.5  0.4 -0.3 -0.3 -0.5  4.7 -1.4 -0.4 -0.5 -1.4 -0.1 -0.8 -0.1 -0.  -0.2 -0.8  2.5 -0.5 -2.  -0.2  1.4  1.6 -0.4 -0.8  0.  -1.6  1.8  1.2  0.4  0.6  6.  -0.3  0.2 -0.2  0.4 -0.3 -3.3 -1.  -0.3 -0.2 -1.9  0.3 -4.4 -0.   4.8 -0.3  3.7  9. ]
vy_50sample [[5 1 1 0 4 7 6 3 2 8]
 [9 7 3 8 5 2 4 0 6 1]
 [8 0 5 7 1 2 6 3 3 9]
 [5 6 0 1 7 4 8 2 3 9]
 [9 7 4 4 2 1 5 0 6 3]
 [4 6 9 9 3 8 2 2 5 1]
 [2 5 6 9 4 8 0 1 3 7]
 [7 4 3 0 0 5 6 6 2 9]
 [1 5 6 9 8 2 0 7 4 3]
 [5 8 3 7 6 1 2 9 0 0]]
vt_50sample [[5 1 9 0 4 7 6 3 2 8]
 [9 7 3 8 5 2 4 0 6 1]
 [0 8 5 1 7 2 6 3 4 9]
 [5 6 0 1 7 4 8 2 3 9]
 [9 7 4 8 2 1 5 0 6 3]
 [6 4 9 7 3 8 0 2 5 1]
 [2 5 6 9 4 8 0 1 3 7]
 [7 4 3 0 1 8 5 6 2 9]
 [1 5 6 9 8 2 0 7 4 3]
 [5 8 3 7 6 1 2 9 0 4]]
Epoch 45810: Training cost= 0.2468, Training acc= 0.8587, Validation cost= 0.2036, Validation acc= 0.8588
Epoch 45820: Training cost= 0.2815, Training acc= 0.8587, Validation cost= 0.2062, Validation acc= 0.8588
Epoch 45830: Training cost= 0.2828, Training acc= 0.8587, Validation cost= 0.3146, Validation acc= 0.8588
Epoch 45840: Training cost= 0.2438, Training acc= 0.8588, Validation cost= 0.2265, Validation acc= 0.8588
Epoch 45850: Training cost= 0.2550, Training acc= 0.8588, Validation cost= 0.2228, Validation acc= 0.8588
Epoch 45860: Training cost= 0.2158, Training acc= 0.8588, Validation cost= 0.2000, Validation acc= 0.8588
Epoch 45870: Training cost= 0.2255, Training acc= 0.8588, Validation cost= 0.2295, Validation acc= 0.8588
Epoch 45880: Training cost= 0.2921, Training acc= 0.8588, Validation cost= 0.1708, Validation acc= 0.8589
Epoch 45890: Training cost= 0.2095, Training acc= 0.8588, Validation cost= 0.2494, Validation acc= 0.8589
Epoch 45900: Training cost= 0.2340, Training acc= 0.8588, Validation cost= 0.2028, Validation acc= 0.8589
tm  [-1.  -0.2 -3.2  4.1 -1.  -0.1 -0.  -0.2  0.3 -0.1 -3.8 -0.1 -0.   0.5 -2.8 -0.1 -0.3  0.1 -0.5 -1.1 -1.3 -0.1 -0.1  0.7 -0.5 -0.1 -0.3 -0.7 -0.4 -3.4 -0.3  0.6  0.7 -6.4  0.  -0.  -0.2  5.  16.3 -0.2  4.5 -0.7 -0.9  3.9 -0.1 -0.1  6.9  0.1 -0.7 12.1 -0.3 -0.2 -0.7 -1.  -0.6  3.1 -0.7 -2.5  7.3  3.9  1.9 -0.4 -0.2 -0.4 -1.2 -0.6 -0.  -0.2  0.6 -0.3  0.5 -0.   0.4  0.9 -1.1 -0.1 -0.2 -0.3 -0.3 -0.7 -1.4  0.  -0.3  0.1 -0.  -0.3 -0.2 -0.1  0.  -0.3  0.2 -0.3 -0.  -1.3 -0.3 -0.4 -0.2 -1.9 -0.1 -0.4  1.1 -0.3  1.   0.1 -0.2 -1.1 -0.6 -0.5 -1.3 -1.6 -0.8  0.3 -0.2 -0.5  5.6  0.7  1.4 -0.1 -0.3 -0.4  0.2  5.5 -0.1 -0.3 -0.  -3.4  0.3  5.4  5.7 -2.4 -0.9 -0.3 -0.3 -0.7 -0.4 -6.9 -0.1 -0.3 -0.2  1.  -0.  -0.4 -0.5  0.1 -0.1  0.6 -0.2 -0.2  3.  -0.  -0.5 -0.2  0.5 -0.1 -0.2 -0.  -0.1 -1.   4.4  1.9 -0.1 -1.7 -0.2 -0.3 -0.3 -0.4  0.1 -0.   0.8 -0.2 -0.1 -0.1 -0.2 -0.4 -0.2  0.  -0.6 -0.1 -1.5 -0.1 -0.2 -0.3 -0.4 -1.1 -0.3 -0.1 -0.3 -0.2 -0.4  9.8 -0.2 -0.2 -0.2 -0.4  0.7 -2.1 -0.  -1.4  0.1 -0.1 -0.5 -0.1 -0.7 -0.2 -0.5 -0.3 -0.3 -0.2 11.6 -0.2 -0.5 -0.2 -0.5  3.9 -0.7 -0.7 -2.  -1.1 -0.4 -0.  -0.  -0.1 -0.  -1.  -1.1  1.7 -0.9 -0.1 -0.7 -0.3 -0.4 -0.2 -0.   2.1 -0.2  4.1 -0.3 -0.1  3.8 16.2 -0.2  4.3 -0.2 -0.1  5.5 -1.9 -0.2 -0.3 -1.2  0.3  2.4 -0.1  9.7 -0.4  1.4 10.4]
ty_50sample [[8 1 9 4 0 2 3 5 7 6]
 [9 8 5 0 4 7 2 1 6 3]
 [0 5 4 7 6 1 8 9 2 3]
 [6 2 8 0 1 3 9 4 7 5]
 [1 8 3 4 4 2 5 9 6 0]
 [4 0 9 2 7 1 8 5 3 6]
 [6 3 2 4 7 8 5 0 9 1]
 [7 9 9 4 4 1 0 3 5 2]
 [6 2 1 8 0 7 9 3 5 4]
 [9 1 0 6 5 7 4 2 8 3]]
tt_50sample [[8 1 9 4 0 2 3 5 7 6]
 [9 8 5 0 4 7 2 1 6 3]
 [0 5 4 6 7 1 8 9 2 3]
 [6 2 8 0 9 1 3 4 7 5]
 [1 3 8 4 7 2 5 9 6 0]
 [4 0 9 2 7 1 8 5 3 6]
 [6 3 2 4 8 7 5 0 9 1]
 [7 9 8 6 4 1 0 3 5 2]
 [6 2 1 8 0 7 9 3 5 4]
 [9 1 0 6 5 7 4 2 8 3]]
vm  [ 0.3 -0.1 -0.1 -2.6 -1.1 -0.  -0.2 -0.1  0.2 -0.6  8.6 -0.4 -0.  -0.1  6.5  7.3 -0.2 -0.1 -0.2 -0.8 -0.8 -0.3  1.  -0.3 -1.2 -0.1 -0.3 -0.1  2.6  0.3  2.6 -0.2 -0.1  6.8  0.5 -0.2 -0.2  4.1 -0.6 -0.2 -0.4  0.9 -0.4  0.3 -0.1 -0.1  0.2 -0.2  5.2  6.3 -0.2 -0.  -0.4  9.4 -1.1 -0.8 -0.6 -1.7  4.6 -1.5 -0.5 -0.3 -0.4  0.7  0.6  0.6 -0.1 -0.2 -0.2 -0.2 -0.1 -1.9 -0.5 -0.1 -3.   0.6 -0.4  2.5 -0.1 -0.3 -0.  -0.5 -0.3  0.  -1.4  2.6  7.7 -0.1 -0.2 -0.2 -0.8 -0.1 -0.5 -1.3 -0.6 -0.2  1.6 -2.8 -0.2  0.7  1.5  5.6 -0.8  0.1  0.1  0.1 -1.8 -0.   0.7 -0.9 -0.3 -0.2  0.1 -1.1  0.6 13.2 -0.3  0.  -0.2 -0.3 -0.4  3.2 -0.2 -0.3 -0.1  8.2 -0.1 -1.8  3.3 -0.7  1.3 -0.5 -0.6 -0.3 -1.3  4.3 -0.2 -0.1 -0.4 -0.1 -1.2 -0.4 -0.6 -0.2 -0.   0.  -0.5  0.  -1.2 -0.2  2.2 -0.   2.9 -0.7  0.  -0.2 -0.2 -0.1 -0.4 -0.1 -0.  -0.3 -0.3  0.3 -0.1  0.7 -0.2 -0.5 -0.2  0.1 -0.1 -0.1 -0.3 -0.4 -0.1  1.6 -1.2 -0.3  0.7 -0.1 -0.4  0.3 -0.2 -1.6 -0.  -0.7  0.2 -0.8  0.5  0.1 -0.1 -0.2 -0.3 -0.6  7.2 -1.4 -0.3 -0.6 -0.2 -0.  -0.3 -0.3 -0.1 -0.3 -0.1 -2.  -0.2 -0.   4.2  0.2 -0.3  4.2 -0.  -1.8 -0.2 -0.1 -0.5 -0.9 -0.3 -0.6 -0.1 -0.1 -0.3 -1.5  2.7  4.7  2.5  0.1 -0.   3.9 -0.9  0.8 -0.   1.2 -0.9  0.8 -0.1 -0.5  2.6  6.2 -0.2  2.  -0.1 -0.1  2.2  0.7 -0.3 -0.4 -1.4  0.  -0.2 -0.1 -0.3 -0.2 -1.8  5. ]
vy_50sample [[2 4 7 6 8 9 5 3 1 0]
 [4 6 1 7 9 0 3 8 5 2]
 [7 3 0 8 4 9 6 1 2 5]
 [8 6 5 0 9 3 7 1 2 4]
 [1 8 4 5 0 3 2 2 7 6]
 [9 7 4 6 0 2 1 3 5 8]
 [4 1 2 9 8 0 0 3 5 7]
 [6 9 0 0 2 1 5 4 3 7]
 [2 8 5 9 3 0 1 7 4 6]
 [8 2 4 3 7 6 9 1 0 5]]
vt_50sample [[2 4 7 6 8 9 5 3 1 0]
 [4 6 1 7 9 0 3 8 5 2]
 [7 3 0 8 4 9 6 1 2 5]
 [8 6 5 0 9 3 7 1 2 4]
 [1 8 4 5 9 0 3 2 7 6]
 [9 7 4 6 0 2 1 3 5 8]
 [4 1 2 9 8 6 0 3 5 7]
 [6 9 0 8 2 1 5 4 3 7]
 [2 8 5 9 3 0 1 7 4 6]
 [8 2 4 3 7 6 9 1 0 5]]
Epoch 45910: Training cost= 0.1931, Training acc= 0.8588, Validation cost= 0.2296, Validation acc= 0.8589
Epoch 45920: Training cost= 0.2725, Training acc= 0.8588, Validation cost= 0.2393, Validation acc= 0.8589
Epoch 45930: Training cost= 0.3114, Training acc= 0.8588, Validation cost= 0.3071, Validation acc= 0.8589
Epoch 45940: Training cost= 0.3049, Training acc= 0.8589, Validation cost= 0.3020, Validation acc= 0.8589
Epoch 45950: Training cost= 0.2238, Training acc= 0.8589, Validation cost= 0.2665, Validation acc= 0.8589
Epoch 45960: Training cost= 0.2409, Training acc= 0.8589, Validation cost= 0.1973, Validation acc= 0.8589
Epoch 45970: Training cost= 0.2384, Training acc= 0.8589, Validation cost= 0.2221, Validation acc= 0.8589
Epoch 45980: Training cost= 0.2125, Training acc= 0.8589, Validation cost= 0.2034, Validation acc= 0.8590
Epoch 45990: Training cost= 0.2132, Training acc= 0.8589, Validation cost= 0.2018, Validation acc= 0.8590
Epoch 46000: Training cost= 0.3020, Training acc= 0.8589, Validation cost= 0.2555, Validation acc= 0.8590
tm  [-0.3 -0.2 -3.   0.5 -1.3 -0.3  0.6 -0.  -0.4 -0.7  5.1 -0.1 -0.1  0.5 -2.4 -0.5 -0.6 -0.5 -0.5 -1.1 -1.5 -0.2 -0.8 -0.1 -0.6  1.4 -0.4 -0.  -0.8 -2.   5.  -0.2 -0.1  7.2 -0.2 -0.1  0.6  0.5 16.3 -0.   2.6 -0.2 -0.1  5.1 -0.1 -0.3  9.   0.3  1.  -3.8 -0.2  0.1 -0.  -3.  -0.9  2.6 -0.6 -0.9  3.1 -4.  -1.2 -0.6 -0.4 -0.6  0.5 -0.6 -0.3  0.   3.5 -0.4 -0.3 -0.2 -0.  -0.6  0.7  0.  -0.2 -0.4 -0.2 -0.1 25.2 -0.  -0.1  0.3 -0.8 -0.3  5.6  0.2 -0.3 -0.2 -0.2 -0.1 -0.2 -0.4 -0.7 -0.3 -0.2 -1.2 -0.1 -0.6  3.2 -1.  -0.1 -0.1 -0.1 -0.2 -0.9  1.9  1.8 -1.8 -0.9  0.6  0.6 -0.4  2.1  1.1  1.6 -0.1 -0.2 -0.2 -0.1  6.5 -0.1  1.  -0.4 -2.9 -0.1 11.8  7.1 -0.2 -0.3 -0.4 -0.3 -0.7 -1.2  5.  -0.1 -0.2 -0.2 -0.8  1.3 -0.4  1.3 -0.1 -0.1 -0.1 -0.1 -0.1  4.8 -0.1 -0.4  0.1 -0.5  1.   0.2 -0.2 -0.  -0.4  1.9  0.2 -0.3 -1.1 -0.3 -0.1  0.3 -0.2 -0.3 -0.1 -0.1 -0.1 -0.1 -0.1 -0.1 -0.  -0.1 -0.7 -0.2 -0.4 -1.3 -0.  -1.3 -0.5 -0.3 -1.6 -0.  -0.3 -0.1 -0.2 -0.1  5.3  0.4 -0.2 -0.2 -1.2  9.6 -2.1  0.2 -0.5 -0.2  0.2 -0.4 -0.1 -0.2 -0.4  0.4  0.3  0.  -0.  -4.1  0.  -0.3 -0.2 -0.7 -0.2 -0.3 -0.2 -2.3 -1.3 -0.2  0.5 -0.2 -0.3 -0.7 -1.1 -1.9 -0.6 -2.3 -0.8  0.1  2.1 -0.8 -0.5 -0.  -1.4 -0.2  4.2  0.5 -0.   2.7  6.4 -0.   1.   0.3 -0.2 -5.2 -2.3 -0.  -0.4 -1.6 -0.2 -6.4 -0.1 10.  -0.2  8.1  3.1]
ty_50sample [[4 9 3 5 0 1 7 2 6 8]
 [9 0 4 6 8 5 1 7 2 3]
 [3 6 1 2 4 5 9 7 8 0]
 [9 6 1 3 5 5 4 8 8 0]
 [2 1 1 6 5 4 9 0 7 3]
 [4 5 1 3 8 7 6 9 2 0]
 [5 1 8 3 9 7 0 4 2 6]
 [6 2 1 0 5 4 7 8 3 9]
 [3 8 7 0 2 5 9 1 6 4]
 [4 5 8 8 7 7 9 3 2 6]]
tt_50sample [[4 9 3 5 0 7 1 2 6 8]
 [9 0 4 6 8 5 1 7 2 3]
 [3 6 1 2 4 9 5 7 8 0]
 [9 6 1 3 5 4 2 7 8 0]
 [2 1 8 5 6 4 9 0 7 3]
 [4 5 1 3 8 7 6 9 2 0]
 [5 1 8 3 9 7 0 4 2 6]
 [6 2 1 0 5 4 7 8 3 9]
 [3 8 7 0 2 5 9 1 6 4]
 [4 5 0 8 1 7 9 3 2 6]]
vm  [-0.3 -0.4 -5.6 -2.8 -0.5 -0.2 -0.2 -0.  -1.9 -0.3 -3.3 -0.1  0.  -0.1 -2.7 -1.  -0.1 -0.1 -0.4 -0.5 -1.5 -0.4  1.  -0.2 -1.2 -0.1 -0.4 -0.3 -1.7 -0.1  0.8 -0.1  0.8 -8.6 -0.2 -0.   4.6 -0.4 -1.8 -0.6  3.1 -1.8  3.   2.6 -0.1 -0.   1.5 -0.3  1.5  4.8  0.1 -0.2 -0.5  2.6 -0.2  2.7 -1.3 -2.3 -1.7  3.4 -0.2  0.5 -0.2 -0.3 -0.7  0.4 -0.  -0.7  0.3  0.  -0.1  5.9 -0.3 -0.5 -2.8 -0.1 -0.2 -0.2 -0.4 -0.1 -4.2 -0.4 -0.3  0.8 -1.  -1.9  7.1  0.1  0.4  0.  -0.9 -0.1 -0.5  5.3 -0.2 -0.1  0.4 -2.1 -0.3  0.5  1.3 -2.3 -0.4  0.7  0.2 -0.4 -2.5 -0.1 -1.  -1.5 -0.8 -0.6 -0.2 -0.4 -0.3 -3.3  2.5 -1.2 -0.1 -0.6  0.2  3.9 -0.8 -0.6 -0.4 -3.2 -0.3 -0.1 -2.3  8.4 -0.7 -0.2 -0.2  1.1 15.1 -1.7 -0.2 -0.1 -0.4 -0.1 -1.  -0.7 -0.4 -0.6 -0.2 -0.1 -0.4 -0.2  4.5 -0.4  2.6  0.   3.5 -0.8  0.2 -0.1  1.3 -1.5 -0.7 -0.6 -0.1 -0.5 -0.4 -0.3 -0.5 -0.3 -0.2 -0.9 -0.7 -0.1  0.  -0.2 -0.2 -0.4 -0.1 -1.2 -1.3 -0.4  3.1 -0.2 -0.8 -0.1  0.6 -1.2 -0.2  0.7 -0.4  2.5 -0.1  1.  -0.1 -0.3 -0.3 -1.   5.1  8.5 -0.9  0.1  0.2 -0.2  0.8 -0.   0.5 -0.1 -0.4 -2.6 -0.2 -0.2 10.3 -0.3 -0.3 -2.7 -0.5 -0.9  0.6 -0.1 -1.1 -0.8 -0.4 -0.   0.5 -0.1 -0.1 -1.2 -0.4 -0.5 -0.7 -0.8 -0.4  0.1 -0.4  3.8 -0.3  2.1  1.7  4.9  0.9 -0.8 -0.3  4.9  0.7  0.9 -0.2 -0.4 13.3  0.2  0.5  0.3 -0.7 -0.4 10.4  0.8 -1.1 -0.3  2.7 -1.4]
vy_50sample [[8 0 4 3 6 2 9 5 1 7]
 [2 2 7 5 9 0 3 4 8 1]
 [9 3 5 2 0 8 4 7 6 1]
 [2 6 0 8 4 7 1 3 9 5]
 [6 5 0 1 3 9 4 8 2 7]
 [1 3 7 7 0 6 5 2 4 8]
 [4 8 5 3 2 1 6 0 7 9]
 [0 8 9 2 4 4 3 6 1 7]
 [9 1 3 6 8 8 4 2 7 5]
 [2 2 8 3 6 4 1 9 7 0]]
vt_50sample [[8 0 4 3 6 2 9 5 1 7]
 [6 2 7 5 9 0 3 4 8 1]
 [9 3 5 2 0 8 4 7 6 1]
 [2 6 0 8 4 7 1 3 9 5]
 [6 5 0 1 3 9 4 8 2 7]
 [1 3 9 0 7 6 5 2 4 8]
 [4 8 5 3 2 1 0 6 7 9]
 [0 8 9 5 4 2 3 6 1 7]
 [9 1 3 6 0 8 4 2 7 5]
 [5 2 8 3 6 4 1 9 7 0]]
Epoch 46010: Training cost= 0.2080, Training acc= 0.8589, Validation cost= 0.2645, Validation acc= 0.8590
Epoch 46020: Training cost= 0.2297, Training acc= 0.8589, Validation cost= 0.2370, Validation acc= 0.8590
Epoch 46030: Training cost= 0.2560, Training acc= 0.8589, Validation cost= 0.2146, Validation acc= 0.8590
Epoch 46040: Training cost= 0.2543, Training acc= 0.8590, Validation cost= 0.2614, Validation acc= 0.8590
Epoch 46050: Training cost= 0.2236, Training acc= 0.8590, Validation cost= 0.2304, Validation acc= 0.8590
Epoch 46060: Training cost= 0.2442, Training acc= 0.8590, Validation cost= 0.2000, Validation acc= 0.8590
Epoch 46070: Training cost= 0.2210, Training acc= 0.8590, Validation cost= 0.3276, Validation acc= 0.8590
Epoch 46080: Training cost= 0.2741, Training acc= 0.8590, Validation cost= 0.3119, Validation acc= 0.8591
Epoch 46090: Training cost= 0.3082, Training acc= 0.8590, Validation cost= 0.2626, Validation acc= 0.8591
Epoch 46100: Training cost= 0.2542, Training acc= 0.8590, Validation cost= 0.2089, Validation acc= 0.8591
tm  [-0.1 -0.2 10.2 17.6 -1.5 -0.3 -0.2 -0.1  1.4 -1.  -1.3 -0.1 -0.2 -0.2 -0.2  0.2 -0.4  0.2  1.4 -1.  -1.2 -0.1 -0.3 -0.1 -0.8  2.8 -0.5 -0.2 -0.5 -2.8 -1.1 -0.2  0.4  4.  -0.1 -0.2 -0.1  2.8 12.9 -0.3 -0.1 -1.9 -0.6 -1.1 -0.3 -0.   6.1  0.   6.3 -0.9 -0.4 -0.1 -0.2 -1.8 -0.7  0.4 -0.6  5.7  4.5  6.1 -1.2 -0.1 -0.2 -0.3 -0.7 -0.1 -0.1 -0.2  3.6 -0.3 -0.1 -0.2  0.3  1.2 -0.   2.  -0.4 -0.1 -0.1 -0.   6.9 -0.7  0.3  0.7 -1.5 -1.6 -0.6 -0.3 -0.2 -0.3 -0.8 -0.1 -0.3 -1.5 -0.4 -0.2  2.2 -2.  -1.  -0.2  3.9  1.1 -0.8  0.1 -0.  -0.2  0.2 -0.4 -0.4 -1.6 -0.5  0.  -0.1 -0.4  3.1  1.4  0.7 -0.1 -0.2 -0.6 -0.4  5.9  0.4 -0.2 -0.1 -0.2 -0.1  7.7  5.3  0.  -0.4 -0.4 -0.2 -0.9 -3.7 -2.2  0.5 -0.1 -0.3 -0.2 -0.6 -0.7 -0.4 -0.1 -0.2  0.6 -0.1 -0.1 -1.6 -0.2 -1.7  0.   3.7 -0.4 -0.  -0.1  0.3 -0.3  2.9  0.1 -0.3 -0.8 -0.2 -0.2 -0.3 -0.6  0.3 -0.1 -0.3 -0.  -0.3 -0.2 -0.4 -0.5 -0.5  2.4 -0.3 -0.  -0.9  0.1 -0.6  0.2 -0.1 -1.4 -0.2 -0.3  2.  -0.2 -0.1  7.7  0.6 -0.2 -0.5 -0.6 11.3 -1.7  1.2 -1.  -0.2  0.1 -0.4 -0.2 -0.3 -0.3 -0.2  0.3 -0.2 -0.   5.  -0.1 -0.3 -0.  -0.3 -1.5 -0.2 -0.4  3.2 -0.9  0.  -0.4 -0.1 -0.2 -0.3 -0.9 -1.6  1.3 -1.   0.1  1.9  4.  -0.4 -0.9 -0.   1.2 -0.1 -2.6 -0.3  2.2  2.5 14.3  0.1  3.8  0.1 -0.  -0.9 -2.2 -0.1  0.  -1.5 -0.  -2.  -0.1  7.5 -0.1  5.6  2.1]
ty_50sample [[9 3 7 8 0 2 5 1 1 4]
 [3 5 8 4 9 2 0 0 6 7]
 [7 0 1 8 3 4 9 2 5 6]
 [8 9 3 3 6 0 5 2 7 4]
 [5 8 2 9 7 3 4 6 0 1]
 [6 8 5 0 9 7 1 2 4 3]
 [8 0 6 1 9 9 5 4 3 7]
 [1 2 6 5 4 0 7 3 9 8]
 [0 9 7 4 5 1 2 8 8 3]
 [0 8 2 9 1 5 6 4 3 7]]
tt_50sample [[9 3 7 8 0 5 2 1 6 4]
 [3 5 8 4 9 2 1 0 6 7]
 [7 0 1 8 3 9 4 2 5 6]
 [8 9 1 3 6 0 5 2 7 4]
 [5 8 2 9 3 7 4 6 0 1]
 [6 8 5 9 7 0 1 2 4 3]
 [8 0 6 1 2 9 5 4 3 7]
 [1 2 6 5 4 0 3 7 9 8]
 [0 9 7 4 5 1 2 6 8 3]
 [0 8 2 9 1 5 6 4 3 7]]
vm  [-0.2 -0.1 -0.4 -5.5 -1.6 -0.2 -0.1 -0.  -1.2 -1.4  5.  -0.1 -0.3 -0.2 12.8  4.6 -0.4 -0.3 -0.3  2.3 -1.4  0.1  1.4 -0.1 -1.9  1.1 -0.3 -0.7 -0.2  4.5  1.7  0.2 -0.5  4.2 -0.3 -0.1  2.   5.7 -0.8 -0.5  2.2  1.9  3.5  5.5 -0.1 -0.2 -2.1 -0.3  2.5  4.4 -0.5 -0.2 -0.4 14.  -1.2 -1.3 -0.9 -1.1 -1.2 -1.1  4.2 -0.2 -0.5 -0.2 -0.4 -0.   0.  -0.2  1.6 -0.2 -0.3 -1.1  0.9 -0.4 -4.6 -0.3 -0.2 -0.2  0.  -0.2 -4.7 -0.1 -0.1  0.4 -0.9  2.7  7.1  0.3 -0.2 -0.2 -0.3 -0.2 -0.1  0.2 -0.6 -0.2 -0.2 -3.2 -0.5 -0.1  4.3  4.9 -0.4 -0.1 -0.1 -0.4 -2.9  0.9  1.9  2.7 -0.6 -0.2 -0.1 -0.4 -1.3  8.   0.3 -0.9 -0.1 -0.2  0.3 -1.3 -0.2 -0.5 -0.  16.2 -0.2 -3.  -0.5  7.9 -0.2 -0.4 -0.2 -0.5 -4.2 -2.9 -0.1 -0.  -0.5 -0.6 -0.3 -0.7 -0.2 -0.2 -0.1 -0.1 -0.2 -0.1 -0.6 -0.   4.2 -0.1  2.7 -0.1 -0.2 -0.1 -0.2 -0.2  2.5  0.2 -0.  -0.8 -0.2 -0.1 -0.5 -0.7 -0.1 -0.2 -0.2 -0.   0.1 -0.1 -0.3  0.  -0.2  1.5 -0.2 -0.5  1.2 -0.3 -1.1 -0.5 -0.3 -2.1 -0.2 -0.1 -0.2 -0.3 -0.2 -1.1 -0.  -0.2 -0.2 -1.3 -1.   2.3 -0.7  3.3 -0.  -0.1  0.1  0.1 -0.3 -0.1 -0.3 -3.8 -0.3 -0.3  0.8 -0.2 -0.5  0.7 -0.4 -0.1 -0.4 -0.2 -2.4 -0.9 -0.   0.7  0.1 -0.2 -0.5 -1.5 -0.8  3.7  0.9 -0.4  1.6  2.  -0.6  0.9 -0.3  0.5 -0.5  1.2  0.1 -0.8  1.8 -4.4 -0.  -1.4 -0.2 -0.1 14.7  4.1 -0.1  1.1 -0.8 -0.3 12.2 -0.3 -0.5 -0.1 -0.5 -1.6]
vy_50sample [[4 7 2 5 8 3 1 0 6 9]
 [4 8 1 0 7 9 5 6 3 2]
 [3 1 2 8 4 0 7 6 9 5]
 [0 1 3 2 4 5 9 6 7 8]
 [7 5 0 1 6 4 9 8 3 2]
 [6 2 4 7 3 1 9 8 0 5]
 [3 4 9 1 8 2 0 0 5 6]
 [3 5 9 0 7 8 2 6 4 1]
 [0 2 5 4 3 1 9 9 8 6]
 [7 3 5 2 4 1 0 6 9 8]]
vt_50sample [[4 2 7 5 8 3 1 0 6 9]
 [4 8 1 0 7 9 5 6 3 2]
 [3 1 2 8 4 0 7 6 9 5]
 [0 1 2 3 4 5 9 6 7 8]
 [7 5 0 1 6 4 9 8 3 2]
 [6 2 4 7 3 1 9 8 0 5]
 [3 4 9 1 8 2 0 7 5 6]
 [3 5 9 0 7 8 2 6 4 1]
 [0 2 5 4 3 1 7 9 6 8]
 [7 3 5 2 4 1 6 0 9 8]]
Epoch 46110: Training cost= 0.3170, Training acc= 0.8590, Validation cost= 0.3528, Validation acc= 0.8591
Epoch 46120: Training cost= 0.2941, Training acc= 0.8590, Validation cost= 0.2816, Validation acc= 0.8591
Epoch 46130: Training cost= 0.3140, Training acc= 0.8590, Validation cost= 0.2639, Validation acc= 0.8591
Epoch 46140: Training cost= 0.2331, Training acc= 0.8590, Validation cost= 0.2614, Validation acc= 0.8591
Epoch 46150: Training cost= 0.2501, Training acc= 0.8591, Validation cost= 0.2518, Validation acc= 0.8591
Epoch 46160: Training cost= 0.2006, Training acc= 0.8591, Validation cost= 0.2670, Validation acc= 0.8591
Epoch 46170: Training cost= 0.2559, Training acc= 0.8591, Validation cost= 0.1843, Validation acc= 0.8591
Epoch 46180: Training cost= 0.2481, Training acc= 0.8591, Validation cost= 0.2534, Validation acc= 0.8591
Epoch 46190: Training cost= 0.2347, Training acc= 0.8591, Validation cost= 0.2452, Validation acc= 0.8592
Epoch 46200: Training cost= 0.2049, Training acc= 0.8591, Validation cost= 0.2641, Validation acc= 0.8592
tm  [ 0.5 -0.1 -1.  -1.1 -1.9 -0.  -0.5  0.  -1.1 -1.   4.5 -0.2 -0.3  0.1  1.3 -0.3 -0.6 -0.2 -0.3 -0.3 -1.7 -0.2 -0.6  0.6 -1.5  2.6 -0.6 -0.5 -1.2 -1.7  2.3  0.1 -0.3  3.4 -0.1 -0.1  3.2  3.4  5.9 -0.2  2.  -2.3  0.4  2.3 -0.2  0.3 -0.2 -0.3  6.5 -2.  -0.4  0.1 -0.1  2.5 -0.1 -0.2 -0.8 -1.4  0.7 -1.1 -1.  -0.4 -0.3  0.5 -0.6 -0.2 -0.2 -0.3  1.5 -0.3  0.5  3.2  0.5  2.  -1.8 -0.6 -0.2 -0.8  0.3 -0.4  2.8 -0.2 -0.  -0.2 -1.5 -2.1  7.9 -0.2 -0.1 -0.3 -0.1 -0.  -0.1 -0.6 -0.3  0.8 -0.4 -2.5 -0.2 -0.2  3.5 -1.  -0.8 -0.1 -0.1 -0.1 -1.1  1.3  1.7 -0.9 -1.  -0.3 -0.  -0.2  1.2 -0.9  0.3 -0.8 -0.1 -0.3 -0.1  3.1 -0.1 -0.6 -0.3  1.8  0.1  0.2  2.   5.7 -0.3 -0.4  0.2 -0.6 -1.9 -1.   0.1 -0.1  0.4 -0.2 -0.2 -0.9 -0.3 -0.  -0.1 -0.  -0.4 -0.2 -0.3 -0.1  0.3 -0.2  2.3 -0.2  0.2 -0.1 -0.  -0.2  2.7  0.2 -0.6 -1.1 -0.3 -0.  -0.4 -0.5  1.  -0.4  0.  -0.  -0.1 -0.2 -0.1 -0.1 -0.3  1.8 -0.4 -0.4 -0.2 -0.1 -0.9 -0.2 -0.4 -2.3 -0.1 -0.1  0.4 -0.5 -0.1  4.5 -0.1 -0.2 -0.1 -1.5  9.2 -0.6  0.4 -0.3 -0.1 -0.  -0.2 -0.2 -0.6 -0.5 -0.2 -1.4 -0.3 -0.2  1.1 -0.1 -0.1 -1.2 -0.9 -1.2 -1.  -0.6 -1.6 -1.3  0.1  1.  -0.1 -0.  -0.6 -1.3 -2.1 -0.5 -1.1  0.   2.4  3.8 -0.4 -0.5 -0.1  0.8  1.4  1.5 -0.1  0.2  2.8  3.4 -0.1  0.6 -0.2 -0.2  0.4 -0.7 -0.3  0.8 -1.3 -0.1 -0.9 -0.1  3.8 -0.3  5.4 -0.9]
ty_50sample [[3 4 0 2 7 9 8 8 6 1]
 [7 4 6 1 5 8 2 9 3 0]
 [7 9 9 8 5 0 1 1 2 3]
 [0 4 8 7 3 6 5 1 2 9]
 [5 9 8 2 0 6 3 4 1 7]
 [1 1 4 8 6 0 3 7 9 2]
 [1 7 6 0 3 4 8 5 9 2]
 [3 6 1 4 5 0 2 9 7 8]
 [7 4 2 8 3 0 5 9 6 1]
 [6 1 7 9 2 4 8 5 3 0]]
tt_50sample [[3 4 0 7 2 9 5 8 6 1]
 [7 4 6 1 5 8 2 9 3 0]
 [7 9 4 8 5 0 1 6 2 3]
 [0 4 8 7 3 6 5 1 2 9]
 [5 9 8 2 0 6 3 4 1 7]
 [5 1 4 8 6 0 3 7 9 2]
 [1 7 6 0 3 4 8 5 9 2]
 [3 6 1 4 5 0 2 9 7 8]
 [7 4 8 2 3 0 5 9 6 1]
 [6 1 7 9 2 4 8 5 3 0]]
vm  [-0.6 -0.3  4.  -3.8 -2.  -0.2 -0.1 -0.3 -0.3  0.9  3.5 -0.2  0.4 -0.3 13.7 -0.6 -0.1 -0.5  0.5 -0.1 -0.8 -0.2 -0.1 -0.1 -1.1  1.  -0.4  0.9 -1.4 -2.1 -0.2 -0.  -0.7  1.7 -0.1 -0.1 -0.1  6.6  0.4 -0.3  0.1  2.2 -0.7  2.4 -0.1 -0.2 -1.6 -0.1  0.3 14.2 -0.3 -0.2 -1.1 14.9  2.7 -1.6 -0.6 -1.5  7.8  3.7  4.5  0.9 -0.7  0.  -0.9  0.2 -0.1 -0.6  1.2 -0.3 -0.2  4.1 -0.7 -0.5 -5.2  0.6  0.2  2.6 -0.3 -0.4 -6.2 -0.3 -0.3  0.7 -0.6  3.8  1.5 -0.3 -0.1  0.4 -0.7  0.4 -0.  -1.2 -0.2 -0.4  0.8 -3.6 -0.6  0.3 -0.2  8.3 -0.3 -0.1 -0.  -0.6 -2.8 -0.3  1.6  0.8 -0.3 -0.2 -0.2 -0.4  7.7 -3.3 -0.   1.3 -0.3 -0.2 -0.3 -0.6  0.3 -0.5  0.3 17.2 -0.2 -3.2  4.8  0.2 -0.5 -0.5 -0.4 -0.8 -5.6 -5.4  0.2 -0.1 -0.5 -0.4 -0.8 -1.1 -0.4 -0.2 -0.  -0.2 -0.3 -0.1 -2.   0.3  3.4 -0.3  2.5  1.2  0.  -0.1  0.3  0.8  2.4 -0.3  0.2 -1.1 -0.2 -0.2 -0.1 -0.2 -0.1 -0.5 -0.1 -0.1 -0.2  0.2 -0.3 -0.5 -0.1  2.1  0.4 -0.7  0.2 -0.2 -0.2 -0.1 -0.2 -1.1 -0.2 -0.4 -0.4 -0.5 -0.1  4.9 -0.1 -0.2 -0.2 -0.3 -1.5 -1.5 -1.1 -2.1 -0.3 -0.2 -0.2  0.4 -0.4  0.4 -0.2 -3.9 -0.2 -0.1  9.1  0.1 -0.5 -2.5 -0.1 -0.5 -0.8 -0.  -1.5 -0.6 -0.  -1.2 -0.2 -0.2  0.1 -0.9  2.5 -1.2 -0.1 -0.1  1.9  1.8 -0.9  0.2 -0.1  1.5  2.5 -0.6  0.8 -1.2  1.9 -0.8 -0.  -0.3 -0.1 -0.1 18.7  5.7 -0.2 -0.5 -0.9 -0.4 16.2 -0.2  0.  -0.4 -2.   1.5]
vy_50sample [[0 2 8 8 4 1 5 6 9 3]
 [2 4 0 0 9 5 3 6 8 7]
 [4 2 1 5 8 3 3 6 0 0]
 [2 8 0 7 9 3 6 1 4 5]
 [4 6 5 9 0 2 1 1 7 3]
 [6 8 0 4 9 3 7 1 5 1]
 [6 0 4 3 8 2 9 7 1 5]
 [2 8 1 7 0 6 6 5 4 9]
 [1 5 3 7 7 8 8 6 6 4]
 [6 1 4 3 2 2 5 7 9 8]]
vt_50sample [[0 7 2 8 4 1 5 6 9 3]
 [2 4 1 0 9 5 3 6 8 7]
 [4 2 1 5 8 3 7 6 9 0]
 [2 8 0 7 9 3 6 1 4 5]
 [4 6 5 9 0 2 1 7 8 3]
 [6 8 0 4 9 3 7 5 2 1]
 [6 0 4 3 8 2 9 7 1 5]
 [2 8 1 7 0 6 3 5 4 9]
 [1 5 3 2 0 7 8 9 6 4]
 [6 1 4 3 0 2 5 7 9 8]]
Epoch 46210: Training cost= 0.2330, Training acc= 0.8591, Validation cost= 0.2453, Validation acc= 0.8592
Epoch 46220: Training cost= 0.2278, Training acc= 0.8591, Validation cost= 0.2499, Validation acc= 0.8592
Epoch 46230: Training cost= 0.2291, Training acc= 0.8591, Validation cost= 0.2173, Validation acc= 0.8592
Epoch 46240: Training cost= 0.2080, Training acc= 0.8591, Validation cost= 0.2312, Validation acc= 0.8592
Epoch 46250: Training cost= 0.2146, Training acc= 0.8592, Validation cost= 0.2240, Validation acc= 0.8592
Epoch 46260: Training cost= 0.1876, Training acc= 0.8592, Validation cost= 0.2354, Validation acc= 0.8592
Epoch 46270: Training cost= 0.2177, Training acc= 0.8592, Validation cost= 0.2151, Validation acc= 0.8592
Epoch 46280: Training cost= 0.2428, Training acc= 0.8592, Validation cost= 0.3090, Validation acc= 0.8593
Epoch 46290: Training cost= 0.2732, Training acc= 0.8592, Validation cost= 0.2040, Validation acc= 0.8593
Epoch 46300: Training cost= 0.2542, Training acc= 0.8592, Validation cost= 0.2535, Validation acc= 0.8593
tm  [-1.6 -0.2  5.6 24.6 -1.6  0.3  0.6 -0.  -0.7 -0.1  0.5 -0.1 -0.1 -0.2 -2.6 -0.1  0.2 -0.3 -0.4 -0.5 -0.8 -0.   1.2 -0.  -0.7  3.3 -0.1  0.4 -1.  -0.1 -1.2 -0.3 -0.1 -1.3 -0.2  0.4  4.3 -0.7  4.1  0.1  1.8  3.5  1.9 -1.2 -0.2  0.3  6.1 -0.2 -1.9  7.4 -0.1 -0.1  1.2 -1.9 -0.2  1.9 -0.6  7.2 -1.8  7.   2.2 -0.3  0.8 -0.2 -0.6  0.5 -0.1 -0.5 -0.5 -0.1 -0.1  2.2 -0.3 -0.2  5.2 -0.2  1.   0.9 -0.1  0.  12.8 -0.1 -0.1 -0.5  2.8  5.1 -3.2 -0.3 -0.2  0.3 -0.  -0.1 -0.1  0.5 -0.3 -0.2 -0.3  1.5  0.7  0.5 -0.1  3.1  0.1 -0.3 -0.3 -0.1  2.8 -0.4  0.5 -2.  -0.6 -0.   0.5  0.7 -0.5 -0.9 -0.4 -1.4 -0.  -0.4  0.5  8.3 -0.2 -0.   0.5 -3.2 -0.1  7.7 -2.5 -3.1 -0.5  0.7 -0.3  0.1 10.1  8.2 -0.  -0.   0.3 -0.5  0.  -0.4 -0.3 -0.4  0.3 -0.1  0.  -0.1  3.6 -0.  -2.5 -0.3 -1.   1.2 -0.2 -0.1 -0.6  1.5 -0.6 -0.3  1.2 -0.1 -0.1 -0.1  0.3  0.4 -0.2 -0.4  0.2 -0.2  0.1  0.4 -0.3 -0.1 -0.  -0.3 -0.5 -0.1 -0.2 -0.1 -1.  -0.1 -0.2 -1.4 -0.  -0.2 -1.  -0.4 -0.1  0.5 -0.1 -0.2  0.9 -0.3  0.   8.9  1.5  1.3  0.2 -0.  -0.1 -0.   0.4 -0.2 -0.1  5.8 -0.  -0.4  1.6 -0.  -0.3 -0.9  0.2 10.8 -0.7 -0.1  7.2 -0.5 -0.5 -0.1 -0.2 -0.1 -0.3 -0.8  4.6 -0.3 -1.  -0.2 -0.4 -1.1  0.7 -1.2 -0.1  1.   1.  -0.9 -0.6  1.8  0.9 13.4 -0.2  3.6 -0.1 -0.1 -2.4 -2.1 -0.5  0.7 -0.8 -0.6 -3.3 -0.2  2.1  0.5 -0.5 12.1]
ty_50sample [[9 9 6 0 0 5 2 7 3 4]
 [7 1 0 6 2 3 3 8 5 4]
 [1 8 0 7 9 2 5 6 4 3]
 [0 2 1 5 8 6 7 9 4 3]
 [9 0 4 2 7 3 8 1 6 5]
 [9 5 2 0 1 8 4 7 6 3]
 [6 9 8 0 5 3 7 1 4 2]
 [7 8 4 9 1 5 3 2 6 0]
 [3 3 4 2 0 1 8 7 6 5]
 [1 7 5 3 4 6 8 2 9 9]]
tt_50sample [[9 1 6 0 8 5 2 7 3 4]
 [7 1 0 6 2 9 3 8 5 4]
 [1 8 0 7 9 2 5 6 4 3]
 [0 2 1 5 8 6 7 9 4 3]
 [9 0 2 4 7 3 8 1 6 5]
 [9 5 2 0 1 8 4 7 6 3]
 [6 9 8 0 5 3 7 1 4 2]
 [7 8 4 9 1 3 5 2 6 0]
 [3 9 4 2 0 1 8 7 6 5]
 [1 7 5 3 4 6 8 2 0 9]]
vm  [-1.2 -0.2  5.9 14.  -2.  -0.2  0.3 -0.1 -0.6 -0.7 -6.9 -0.4 -0.2 -0.1 -0.5 -1.6 -0.  -0.5 -0.3 -1.  -1.1 -0.2 -0.2  0.1 -1.   2.2 -0.1 -0.3 -1.  -0.4 -1.8 -0.3 -0.2 -2.9 -0.2 -0.   2.  -1.1  5.4 -0.1  3.1  5.7  3.3 -0.1 -0.   0.7  5.2 -0.1 -0.5 12.3 -0.4 -0.1 -0.5 -2.4 -0.2  0.5 -0.9  8.9 -1.2  7.8 -0.  -0.4 -0.6 -0.  -1.2 -0.2 -0.  -0.6  1.4 -0.1 -0.   2.9  0.2 -0.  -0.4 -0.   0.5  0.5 -0.  -0.3 -1.6 -0.3 -0.2 -0.1 -0.4  6.1 -1.7 -0.2 -0.2 -0.2 -0.2 -0.1  0.5 -0.4 -0.6 -0.3  0.7 -1.8 -0.3  0.2  2.6  4.2 -0.4 -0.1 -0.5 -0.5 -0.7 -0.7 -1.9 -1.3 -0.7 -0.1 -0.  -0.1  1.5 -0.7  0.3 -1.  -0.5 -0.3 -0.1  6.5 -0.  -0.5 -0.2 -0.7 -0.2 10.2 -0.9 -2.1 -0.7 -0.2 -0.6 -0.6 -0.4 -3.4 -0.2 -0.2 -0.2  2.3  1.5 -0.8  0.6  0.2 -0.1 -0.1 -0.2 -0.2  4.2 -0.  -1.5 -0.2  2.2  1.2 -0.1  0.5 -0.  -0.1  0.9 -0.4 -0.1 -0.5 -0.1 -0.1 -0.1 -0.2 -0.2 -0.5  0.5 -0.1 -0.  -0.1 -0.  -0.2 -0.  -0.4 -0.6 -0.2 -0.  -0.1 -2.1 -0.2 -0.5 -1.8  0.5 -0.1 -0.2 -0.8 -0.2  0.8 -0.  -0.2 -0.3 -0.3  3.1  4.3  0.9 -0.5 -0.2 -0.  -0.2  0.  -0.4 -0.   0.  -0.5 -0.1 -0.   4.3 -0.1 -0.3 -1.1 -0.1  4.4 -0.8 -0.1  2.7 -0.8 -0.3 -0.7 -0.1 -0.1 -0.7 -1.   1.8  0.  -1.7 -0.8 -0.4  0.5 -0.6 -0.8 -0.   1.7  1.5 -1.1 -0.5  0.4  0.9  0.5 -0.2 -0.1  0.1 -0.1  6.3 -1.1 -0.4 -0.1 -1.1 -0.4  2.8 -0.3  2.9 -0.5  5.2  8.1]
vy_50sample [[8 5 0 9 1 7 6 3 4 2]
 [6 2 9 5 4 8 1 7 0 3]
 [7 1 4 9 8 3 6 5 2 0]
 [1 5 7 7 2 2 0 8 4 6]
 [6 3 8 7 9 1 1 2 5 0]
 [2 3 1 6 4 9 8 7 5 0]
 [0 2 7 8 3 5 1 4 9 6]
 [3 2 7 4 1 8 9 5 6 0]
 [4 2 6 1 5 3 3 0 9 8]
 [3 9 8 2 4 5 0 6 1 7]]
vt_50sample [[8 5 0 9 1 7 6 3 4 2]
 [6 2 9 5 4 8 1 7 0 3]
 [7 1 4 9 8 3 6 5 0 2]
 [1 5 9 7 0 2 3 4 8 6]
 [6 3 8 7 9 4 1 2 5 0]
 [2 3 1 6 4 9 8 7 5 0]
 [0 2 7 8 3 5 1 4 9 6]
 [3 2 7 4 1 8 9 5 6 0]
 [4 2 6 1 5 7 3 0 9 8]
 [3 9 8 2 4 0 5 6 1 7]]
Epoch 46310: Training cost= 0.2402, Training acc= 0.8592, Validation cost= 0.2856, Validation acc= 0.8593
Epoch 46320: Training cost= 0.2491, Training acc= 0.8592, Validation cost= 0.3277, Validation acc= 0.8593
Epoch 46330: Training cost= 0.3058, Training acc= 0.8592, Validation cost= 0.2258, Validation acc= 0.8593
Epoch 46340: Training cost= 0.2675, Training acc= 0.8592, Validation cost= 0.2766, Validation acc= 0.8593
Epoch 46350: Training cost= 0.2751, Training acc= 0.8593, Validation cost= 0.2183, Validation acc= 0.8593
Epoch 46360: Training cost= 0.2360, Training acc= 0.8593, Validation cost= 0.2404, Validation acc= 0.8593
Epoch 46370: Training cost= 0.2577, Training acc= 0.8593, Validation cost= 0.2732, Validation acc= 0.8593
Epoch 46380: Training cost= 0.2653, Training acc= 0.8593, Validation cost= 0.2636, Validation acc= 0.8594
Epoch 46390: Training cost= 0.2319, Training acc= 0.8593, Validation cost= 0.2499, Validation acc= 0.8594
Epoch 46400: Training cost= 0.2166, Training acc= 0.8593, Validation cost= 0.2249, Validation acc= 0.8594
tm  [-1.4 -0.   7.3 -1.6 -1.1  0.2 -0.2 -0.1 -0.   0.2  8.7 -0.  -0.2 -0.2 13.   2.   0.  -0.1 -0.1  0.1 -1.3 -0.1  1.3 -0.2 -1.1  0.8 -0.2 -0.3 -0.4 -1.3  2.1 -0.4  1.  14.7 -0.2 -0.   0.2  1.4 -3.1 -0.4  1.1  1.9 -1.1 -0.5 -0.3 -0.1 -1.8 -0.1 -2.3  4.3 -0.1 -0.4 -0.3 10.2 -0.9 -1.5 -0.9 -0.5  6.8 -1.1 10.3 -0.4  1.7  0.4  1.8 -0.7 -0.1 -0.2  0.2 -0.2 -0.  -0.6 -0.1 -0.2 -5.5 -0.4 -0.2 -0.2  0.4 -0.7  1.4 -0.1 -0.1 -0.3  2.3  4.  -2.2 -0.1  0.1 -0.3 -0.7  0.3  0.6 -0.5 -0.6 -0.2 -0.1 -3.3 -0.7 -0.2 -0.1  8.   0.9 -0.2 -0.3 -0.1 -2.5  0.4  0.1 -0.2 -0.2 -0.2 -0.  -0.8  4.5  1.9 -0.4  0.8 -0.3 -0.4 -0.6 -0.5 -0.1 -0.4 -0.4 15.8 -0.3 -2.1  4.  -0.3 -0.4 -0.2 -0.4 -0.  -1.6 12.9 -0.2 -0.1  0.2 -0.6 -0.4 -0.4 -0.3 -0.2 -0.1  0.  -0.3 -0.1 -2.3  0.1  1.  -0.2 -1.9  0.4 -0.2 -0.1 -0.6 -0.2 -0.3 -0.4 -0.3 -0.3  0.3 -0.2  0.  -0.1 -0.3  0.4 -0.  -0.  -0.  -0.2 -0.2 -0.4 -0.5  4.3 -0.9 -0.1  3.6 -0.2 -0.3 -0.3 -0.2 -1.4 -0.1 -0.5 -0.9 -0.4 -0.3  3.9 -0.3 -0.2 -0.4 -0.8 -4.4 -1.5 -0.7 -1.2 -0.1 -0.1  0.5 -0.1 -0.5 -0.6 -0.1 -2.6 -0.3 -0.2 -0.3 -0.4 -0.2  0.4 -0.4  9.  -0.2 -0.4  2.1 -1.  -0.2 -0.1 -0.1 -0.2 -0.  -1.1  4.6 -0.4 -0.5  0.3 -1.  -0.8 -0.3  1.  -0.3 -0.3 -0.4 -1.5 -0.3 -1.   2.4 -0.4 -0.1 -0.4 -0.2  0.3  0.9  2.1 -0.4 -0.1 -1.   0.4 -0.7 -0.  -1.7 -0.  -1.5  4.2]
ty_50sample [[1 7 2 6 0 4 5 9 8 3]
 [7 2 8 8 4 1 0 3 5 9]
 [8 0 3 4 7 2 1 6 5 9]
 [8 8 6 9 9 1 2 3 0 5]
 [1 4 0 3 8 2 6 9 5 7]
 [1 3 6 7 5 9 8 0 4 2]
 [8 4 7 3 9 2 0 6 1 5]
 [9 6 1 8 5 2 4 3 0 7]
 [9 3 2 5 6 0 7 8 1 4]
 [8 2 1 9 0 3 4 7 6 5]]
tt_50sample [[1 7 2 6 0 4 5 9 8 3]
 [7 2 8 6 4 1 0 3 5 9]
 [8 0 3 4 7 2 1 6 5 9]
 [8 7 4 6 9 1 2 3 0 5]
 [1 4 0 3 8 2 6 9 5 7]
 [1 3 6 7 5 9 8 0 4 2]
 [8 7 4 3 9 2 0 6 1 5]
 [6 9 1 8 5 2 4 3 0 7]
 [9 3 5 2 6 0 7 8 1 4]
 [8 2 1 9 0 3 4 7 6 5]]
vm  [-1.1 -0.4 -5.1 -2.9 -1.4 -0.1 -0.2 -0.2 -0.8 -0.4 -0.9 -0.3 -0.2 -0.2 -1.5 -0.5 -0.2 -0.4 -0.8 -0.1 -1.5 -0.1  2.   0.1 -1.3  2.2 -0.2 -0.3 -1.1 -2.1  2.9 -0.1 -1.  -4.3  0.  -0.   3.1  3.3  8.  -0.4  0.9  2.5 -0.1  5.6 -0.2  0.8 -0.2 -0.2 -0.8  5.9 -0.2 -0.1 -0.2  1.9 -0.5  1.1 -0.7 -1.6  3.8 -1.1  4.3 -0.1  0.2  0.1 -0.5 -0.  -0.1 -0.5  0.2 -0.1  0.1  2.  -0.2  1.1 -2.3 -0.3 -0.2  0.2 -0.1  0.2 -1.4  1.  -0.2  1.6  1.2  4.1  3.  -0.1  0.3 -0.1 -0.1 -0.1 -0.1 -0.7 -0.6  0.4 -0.3 -2.8  0.6  0.4  1.6 -0.6 -0.1  0.4 -0.3 -0.5 -1.6  2.  -0.3 -0.7 -0.5  0.  -0.2 -0.4  3.1 -0.6 -0.5 -0.4  0.1 -0.4  0.6  2.8  0.7  0.1 -0.2 -1.8  0.2  1.1  4.3  1.6 -0.3 -0.1  0.4 -0.5  3.4 -3.7  0.5  0.6 -0.2 -0.1  1.3 -0.9 -0.3 -0.1  0.1 -0.2 -0.2 -0.2  6.3 -0.1  1.5 -0.1  0.3  0.3  0.  -0.1 -0.2 -0.5  2.4 -0.2  1.2 -0.9 -0.1 -0.1 -0.1 -0.5 -0.2 -0.1  0.  -0.1 -0.  -0.1 -0.1  0.3 -0.2 -1.1  2.2 -0.1 -0.6 -0.2 -1.  -0.3 -0.5 -2.2 -0.1 -0.1 -0.6  0.4 -0.2  6.3 -0.1 -0.3 -0.3 -1.  -0.9 -1.3 -0.3 -0.8  0.3 -0.2  0.3 -0.1 -0.4 -0.5 -0.2 -2.2 -0.  -0.1  2.1  0.1 -0.7 -1.  -0.7  7.  -1.  -0.  -2.6 -1.3 -0.3 -0.4  0.  -0.2 -0.4 -1.4 -0.2  0.7 -0.8 -0.2 -0.4  0.1 -0.6 -0.4 -0.2  1.7  2.1  6.8  0.5 -0.4  4.2 -0.8 -0.2 -0.4 -0.2 -0.1  6.2 -0.1 -0.1  0.9 -1.3 -0.6  2.9  0.3  4.9 -0.1  0.5  1.3]
vy_50sample [[4 1 0 8 5 2 2 3 6 7]
 [6 8 9 0 7 3 5 4 1 2]
 [3 0 6 2 9 8 7 4 5 1]
 [3 1 6 2 7 8 0 5 9 4]
 [1 6 9 5 5 3 8 8 0 2]
 [2 4 3 0 6 8 1 5 7 9]
 [1 2 7 9 5 4 8 3 0 6]
 [5 0 7 2 1 9 6 3 4 8]
 [8 1 4 3 6 7 0 2 5 9]
 [6 2 1 0 5 8 7 3 4 9]]
vt_50sample [[4 1 8 0 5 2 3 9 6 7]
 [6 8 9 0 7 3 5 4 1 2]
 [3 0 6 2 9 7 8 4 5 1]
 [3 1 6 2 7 8 0 5 9 4]
 [1 6 9 5 4 3 8 7 0 2]
 [2 4 3 0 6 8 1 5 7 9]
 [1 2 7 9 5 4 8 3 0 6]
 [5 0 7 2 1 9 6 3 4 8]
 [8 1 4 3 6 7 0 2 5 9]
 [6 2 1 0 5 8 7 3 4 9]]
Epoch 46410: Training cost= 0.2937, Training acc= 0.8593, Validation cost= 0.2770, Validation acc= 0.8594
Epoch 46420: Training cost= 0.2658, Training acc= 0.8593, Validation cost= 0.2645, Validation acc= 0.8594
Epoch 46430: Training cost= 0.2897, Training acc= 0.8593, Validation cost= 0.2562, Validation acc= 0.8594
Epoch 46440: Training cost= 0.2322, Training acc= 0.8593, Validation cost= 0.2699, Validation acc= 0.8594
Epoch 46450: Training cost= 0.2784, Training acc= 0.8593, Validation cost= 0.2346, Validation acc= 0.8594
Epoch 46460: Training cost= 0.2565, Training acc= 0.8594, Validation cost= 0.2055, Validation acc= 0.8594
Epoch 46470: Training cost= 0.2242, Training acc= 0.8594, Validation cost= 0.2582, Validation acc= 0.8594
Epoch 46480: Training cost= 0.1987, Training acc= 0.8594, Validation cost= 0.2153, Validation acc= 0.8594
Epoch 46490: Training cost= 0.2634, Training acc= 0.8594, Validation cost= 0.2262, Validation acc= 0.8595
Epoch 46500: Training cost= 0.2344, Training acc= 0.8594, Validation cost= 0.2139, Validation acc= 0.8595
tm  [-0.7 -0.5 -2.9 -3.  -1.5 -0.1 -0.2 -0.1 -0.4 -0.3  9.3 -0.2 -0.  -0.2  1.2 -0.2 -0.3 -0.2 -0.6  0.6 -1.7 -0.  -0.5 -0.2 -1.   2.7 -0.1 -0.4 -1.7 -2.5  4.  -0.5 -0.4  7.9 -0.1 -0.2  2.2  4.2  0.9 -0.6  3.1 -1.8 -1.   4.3 -0.  -0.3 -0.9 -0.5  2.  -2.2 -0.1 -0.2 -0.5  4.7  0.7 -0.2 -0.8 -3.6  8.1 -4.2  2.1 -0.5  0.8  0.5 -1.  -0.2  0.6 -0.4 -0.1 -0.1  0.3  3.9 -0.1  1.8 -3.3  0.1 -0.4 -0.3 -0.2 -0.4 11.5 -0.3 -0.5 -0.6 -0.5 -1.1  4.8 -0.   0.  -0.5 -0.2 -0.3  0.4 -1.  -0.3 -0.1 -0.2 -3.2  0.4 -0.7  0.4  0.6 -0.5 -0.  -0.2 -0.4 -1.3  1.5  0.2 -0.7 -0.9  1.1 -0.  -0.2  7.  -1.9  0.4  0.2 -0.3 -0.3 -0.   1.7 -0.  -0.  -0.3  1.3 -0.1 -0.5  6.6  2.2 -0.4  0.1 -0.1 -0.6 -0.1  8.4 -0.4 -0.3  0.7 -0.3 -0.2 -0.9 -0.9 -0.2 -0.  -0.1 -0.4 -0.2 -0.9 -0.4  1.7 -0.1 -1.  -0.5 -0.3 -0.3 -0.6 -0.3  2.7  1.5  2.5 -1.   0.2  0.   0.  -0.4 -0.3  0.2 -0.2 -0.2 -0.2  0.  -0.3 -0.4 -0.1  1.9 -0.4  0.8  1.4 -0.1  1.7 -0.3 -0.2 -1.8 -0.  -0.2  0.5 -0.1 -0.4  7.2 -0.1 -0.  -0.1 -1.  -0.1 -2.3 -0.4 -2.1 -0.3  0.3 -0.3 -0.1 -0.3 -0.7 -0.1 -1.3 -0.1 -0.2 -0.1 -0.2 -0.7 -1.3 -1.   3.3 -0.6 -0.4 -1.9 -1.3 -0.5 -0.  -0.2 -0.2 -0.8 -1.7 -0.1 -1.6 -0.3  1.9 -0.2  0.4 -0.3 -0.6 -0.2  0.1  2.5  5.4  1.1 -0.6  2.9 10.3 -0.1  2.7 -0.1 -0.1 -2.2 -0.5 -0.6  1.7 -1.6 -0.6 -3.1 -0.1  0.5  0.1 -0.5  0.8]
ty_50sample [[4 0 2 1 3 7 6 6 5 8]
 [9 2 3 5 7 4 6 1 8 0]
 [5 1 9 9 4 8 6 2 7 3]
 [8 4 3 9 1 0 6 5 7 2]
 [5 2 3 7 1 6 4 0 8 9]
 [8 1 3 0 4 9 7 5 2 6]
 [3 1 2 8 7 5 0 6 4 9]
 [3 9 1 2 0 6 8 4 5 7]
 [4 5 9 6 0 3 7 8 2 1]
 [2 8 4 7 7 0 5 1 6 9]]
tt_50sample [[4 0 2 1 3 7 6 9 5 8]
 [9 2 3 5 7 4 6 1 8 0]
 [5 1 9 0 4 8 6 2 7 3]
 [8 4 3 9 1 0 6 5 7 2]
 [5 2 3 1 7 6 4 0 8 9]
 [8 1 3 0 4 9 7 5 2 6]
 [3 1 2 8 7 5 0 6 4 9]
 [3 9 1 2 0 6 8 4 5 7]
 [4 5 9 6 0 3 7 8 2 1]
 [2 8 4 3 7 0 5 1 6 9]]
vm  [-0.2  0.8  4.5 22.9 -1.1  0.1 -0.   0.3 -0.1 -1.1  4.5 -0.5 -0.1 -0.1 -3.   6.7 -0.3 -0.2  0.5 -0.9 -0.9 -0.2  1.9 -0.2 -0.5  1.6 -0.1  0.6  1.4  0.9 -0.9 -0.3  0.3 -1.5 -0.1 -0.2  1.1 -0.   7.  -0.4 -0.3 -1.5 -0.1 -1.4 -0.1  0.1  9.3 -0.2  3.2  2.1 -0.3 -0.   0.5 -1.4 -1.   3.3  0.3  3.2 -1.   6.4 -2.  -0.3 -0.3 -0.1 -0.2  0.7  0.1 -0.  -0.2 -0.2 -0.1 -1.7  0.8 -0.4  9.5 -0.  -0.1 -0.  -0.   0.5 13.6 -0.2 -0.   1.  -0.8 -1.  -0.5 -0.2 -0.3 -0.   1.   0.2 -0.1 -0.7 -0.4 -0.1 -0.2 -0.1  0.1  0.8  3.4 -0.6 -0.6 -0.2 -0.1 -0.1  3.8 -0.4  1.8 -1.8 -0.5  0.  -0.2 -0.5 -1.3 13.7 -0.5 -1.  -0.  -0.2 -0.1  8.2 -0.1 -0.3 -0.  -3.7  0.1  6.  -1.2 -1.9  0.8 -0.3 -0.2 -0.5  9.5  6.5 -0.1 -0.2  0.2 -0.4 -0.4 -0.3 -0.6 -0.1 -0.   0.1  0.2 -0.  -0.1 -0.1 -2.2 -0.   2.  -0.3 -0.1  0.1 -0.3  0.6 -0.9 -0.3 -0.1  2.1 -0.3  0.1 -0.  -0.2 -0.1  0.2  0.3 -0.2 -0.1 -0.1 -0.2  0.1 -0.   1.1 -0.7  0.1 -0.7 -0.1 -0.2 -0.  -0.3 -1.5  0.   0.5 -0.2 -0.4 -0.  -0.1 -0.2 -0.  -0.2 -0.5 14.   3.8  2.3  3.4  0.2 -0.2 -0.  -0.  -0.1 -0.3 -0.1  5.2 -0.1 -0.2  5.6 -0.1 -0.2  4.2 -0.5 -0.1 -0.6 -0.4  7.5 -0.7 -0.3  1.  -0.2 -0.  -0.1 -1.   2.5  4.9  0.2  1.7 -0.4  3.5  0.  -1.7  0.3  1.9 -0.5 -0.8 -0.1  3.4  2.4 20.4  0.1  6.  -0.  -0.  -2.5 -2.8 -0.1  0.3 -1.2  0.  -3.6 -0.1  4.1 -0.2 -0.   8. ]
vy_50sample [[9 6 2 8 3 7 5 1 4 0]
 [2 4 6 0 8 7 1 5 3 9]
 [4 8 2 0 6 3 7 1 9 5]
 [4 0 9 8 6 7 5 1 2 3]
 [8 5 3 6 9 1 7 0 4 2]
 [1 4 9 0 6 8 7 2 5 3]
 [5 3 7 6 2 4 9 8 1 0]
 [2 6 7 9 3 0 5 8 1 4]
 [1 8 7 5 2 3 6 4 9 0]
 [3 7 7 9 0 5 8 2 1 6]]
vt_50sample [[9 6 2 8 3 7 5 1 4 0]
 [2 4 6 0 8 7 1 5 3 9]
 [4 8 2 0 6 3 7 1 9 5]
 [4 0 9 8 6 7 5 1 2 3]
 [8 5 3 6 1 9 7 0 4 2]
 [1 4 9 6 0 8 7 2 5 3]
 [5 3 6 7 2 4 9 8 1 0]
 [2 6 7 9 3 5 0 8 1 4]
 [8 1 7 5 2 3 6 4 9 0]
 [3 7 4 9 0 5 8 2 1 6]]
Epoch 46510: Training cost= 0.2317, Training acc= 0.8594, Validation cost= 0.2730, Validation acc= 0.8595
Epoch 46520: Training cost= 0.2357, Training acc= 0.8594, Validation cost= 0.2546, Validation acc= 0.8595
Epoch 46530: Training cost= 0.2422, Training acc= 0.8594, Validation cost= 0.2028, Validation acc= 0.8595
Epoch 46540: Training cost= 0.2518, Training acc= 0.8594, Validation cost= 0.2259, Validation acc= 0.8595
Epoch 46550: Training cost= 0.2540, Training acc= 0.8595, Validation cost= 0.2745, Validation acc= 0.8595
Epoch 46560: Training cost= 0.2241, Training acc= 0.8595, Validation cost= 0.2177, Validation acc= 0.8595
Epoch 46570: Training cost= 0.2290, Training acc= 0.8595, Validation cost= 0.1989, Validation acc= 0.8595
Epoch 46580: Training cost= 0.2746, Training acc= 0.8595, Validation cost= 0.2337, Validation acc= 0.8595
Epoch 46590: Training cost= 0.2234, Training acc= 0.8595, Validation cost= 0.3015, Validation acc= 0.8596
Epoch 46600: Training cost= 0.2154, Training acc= 0.8595, Validation cost= 0.2481, Validation acc= 0.8596
tm  [-1.1  0.2  3.5 13.9 -1.9 -0.  -0.  -0.1 -1.  -1.  -3.1 -0.2 -0.  -0.1 -1.5 -1.5 -0.2 -0.3  1.2 -0.5 -1.2 -0.5  2.1  0.2 -1.2  3.5  0.2  0.4 -1.6 -2.  -1.3 -0.2 -0.  -3.4 -0.2  0.4  4.5 -0.4  2.5 -0.3  0.8 -1.   1.5 -0.8 -0.   0.3  3.4 -0.3 -1.2  3.6 -0.3 -0.1 -0.2 -1.3  1.2  1.  -0.8  6.1 -0.9  6.4  1.6  0.1 -0.1 -0.3 -0.7  1.   0.1 -0.6  0.8 -0.3 -0.1  5.   0.6 -0.3 -0.  -0.2  0.5 -0.2 -0.3 -0.1 -0.3 -0.4 -0.1  0.7  1.4 -0.8 -2.3 -0.2 -0.   0.4 -0.3 -0.1  0.4 -0.2 -0.4 -0.3  0.5 -1.6 -0.1  1.5  2.4 -1.2 -0.4 -0.2 -0.1 -0.3 -0.6 -0.3 -1.  -0.7 -0.3 -0.2 -0.   1.1  1.9 -2.7 -0.3 -1.2 -0.4 -0.4 -0.1  4.1 -0.2  0.1 -0.3 -1.8 -0.1  6.6 -1.2  0.8 -0.6 -0.3 -0.3 -0.5  7.4 -0.9 -0.1 -0.1  0.4 -0.2  0.4 -1.2 -0.2 -0.2 -0.2  0.2 -0.1 -0.   2.8 -0.2 -1.3 -0.2  1.5  0.4 -0.1 -0.1  0.  -0.2 -0.3 -0.1 -0.3 -0.2 -0.  -0.1 -0.1 -0.7 -0.1 -0.1 -0.3 -0.1 -0.1 -0.2 -0.1 -0.3 -0.3 -0.3 -0.6  0.4  0.5 -0.1 -0.8 -0.  -0.2 -2.1 -0.  -0.1 -0.6 -0.3 -0.   5.5 -0.3 -0.2 -0.2 -0.6  0.9  5.   0.  -0.5  0.1 -0.1 -0.2 -0.2 -0.4 -0.2  0.5 -0.5 -0.1  0.2  6.  -0.1 -0.2 -2.  -0.3  7.  -0.7 -0.3  4.7 -0.7 -0.5 -0.2 -0.2 -0.1 -0.7 -1.1 -0.  -0.4 -1.2  0.2 -0.3 -0.4 -0.7 -0.9 -0.3  1.6  3.4 -0.5 -0.3  0.8  0.9  7.4 -0.   1.5 -0.1 -0.   3.2 -1.2 -0.3  0.9 -1.1 -0.2 -0.1 -0.   1.5 -0.3  5.4  1.2]
ty_50sample [[0 8 1 3 6 6 5 2 2 4]
 [8 4 6 0 2 7 9 5 1 3]
 [3 2 1 6 0 5 7 4 9 8]
 [4 6 3 3 1 5 2 0 7 8]
 [6 7 4 0 1 3 9 5 2 8]
 [1 0 5 8 6 2 3 7 9 4]
 [4 6 8 0 7 2 5 9 1 3]
 [8 6 3 1 4 2 5 0 0 9]
 [3 2 2 9 1 0 4 8 6 5]
 [0 4 7 3 1 2 8 6 9 5]]
tt_50sample [[0 8 1 3 9 6 5 2 7 4]
 [8 4 6 0 2 7 5 9 1 3]
 [3 1 2 6 0 5 7 4 9 8]
 [4 6 9 3 1 5 2 0 7 8]
 [6 7 4 0 1 3 9 5 2 8]
 [1 0 5 8 6 2 3 7 9 4]
 [4 6 0 8 7 2 5 9 1 3]
 [8 6 3 1 4 2 5 7 0 9]
 [3 2 7 1 9 0 4 8 6 5]
 [0 4 7 3 1 2 8 6 9 5]]
vm  [-1.1  0.8 -1.  15.1 -0.8 -0.3 -0.6 -0.1 -0.4 -0.8 -4.3  0.  -0.1  1.2 -3.6  3.5 -0.5  0.2  0.2 -0.8 -1.8 -0.2  0.  -0.  -0.1 -0.  -0.  -0.4 -0.4 -2.4 -1.8 -0.3  1.  -7.1 -0.4 -0.2  0.1  5.9 19.3 -0.8  1.6 -4.1 -0.4 -0.1 -0.4 -0.2  7.3 -0.1  1.4  7.4 -0.5 -0.4 -0.3 -1.9 -1.4  4.  -0.3 -1.7  0.1  6.4 -1.2 -0.3 -0.  -0.3 -1.4 -1.1 -0.1 -0.4 -0.3 -0.4  0.2 -0.3  1.9  0.6  2.5 -0.6 -0.3 -1.5 -0.2 -0.4 -0.5 -0.7  0.2 -0.8 -0.9 -3.9 -0.8 -0.3 -0.4 -0.2  1.8 -0.3  0.6 -0.5 -0.2 -0.6 -0.5 -1.  -0.3 -0.3  4.  -2.1  0.8 -0.3 -0.1 -0.8  2.9 -0.9 -1.2 -2.7 -0.5 -0.2 -0.1 -0.2  0.4  6.1  0.7 -0.7 -0.2 -0.4 -0.3  9.3 -0.2 -0.3 -0.1 -4.5  0.2  7.3 -0.1 -1.5 -0.7 -0.1  1.  -0.7  0.1 -7.3  0.4 -0.2  1.4  2.5 -0.4 -0.5 -1.1 -0.1 -0.1 -0.2 -0.3 -0.1 -0.5  0.2 -1.5 -0.1  0.5 -1.  -0.3 -0.4 -0.2 -1.1  5.4 -0.  -0.7 -1.2  0.7 -0.2 -0.1  1.   1.1  1.5  0.4 -0.2 -0.3 -0.4 -0.2 -0.3 -0.4  2.1 -0.3  0.7 -1.5 -0.1  2.2 -0.2 -0.  -0.4 -0.1  0.4 -0.4 -0.2 -0.2  7.4 -0.3 -0.2  0.4 -0.7  9.7  0.6  1.9  0.3 -0.2 -0.1 -0.3 -0.2 -0.1 -0.8 -0.2  5.5 -0.2 -0.1 16.  -0.5  0.5  1.1 -0.8  4.   0.7 -0.8 -0.4 -0.7 -0.5  2.5 -0.2 -0.1 -0.6 -0.6 -2.3  1.4 -0.5  1.9 -1.  -0.1 -0.4 -1.5 -0.3  2.2 -0.4  0.9 -0.7  3.2 -0.  26.8  0.   7.2 -0.2 -0.2  3.2 -2.9 -0.7  0.8 -1.1  0.9  0.   0.  11.3 -0.1  3.3  6.4]
vy_50sample [[8 9 3 2 2 4 0 7 6 5]
 [5 4 3 2 6 1 1 8 0 7]
 [7 5 4 8 9 2 0 6 3 1]
 [2 4 0 7 5 3 6 9 8 1]
 [1 2 7 5 9 9 6 6 0 8]
 [5 7 2 0 4 3 1 6 8 9]
 [3 1 5 6 4 2 0 9 7 8]
 [5 4 3 6 7 7 1 2 2 8]
 [7 5 9 4 3 8 2 0 6 1]
 [3 9 8 8 6 4 7 5 0 2]]
vt_50sample [[8 9 3 1 2 4 0 7 6 5]
 [5 4 3 6 2 9 1 8 0 7]
 [7 5 4 8 9 2 0 6 3 1]
 [2 4 0 7 5 3 6 9 8 1]
 [1 2 7 5 9 3 4 6 0 8]
 [5 7 2 0 4 3 1 6 8 9]
 [3 1 5 6 4 0 2 9 7 8]
 [5 4 3 6 7 9 1 0 2 8]
 [7 5 9 4 3 8 2 0 6 1]
 [3 1 9 8 6 4 7 5 0 2]]
Epoch 46610: Training cost= 0.2388, Training acc= 0.8595, Validation cost= 0.2594, Validation acc= 0.8596
Epoch 46620: Training cost= 0.2373, Training acc= 0.8595, Validation cost= 0.2944, Validation acc= 0.8596
Epoch 46630: Training cost= 0.2434, Training acc= 0.8595, Validation cost= 0.2692, Validation acc= 0.8596
Epoch 46640: Training cost= 0.2367, Training acc= 0.8595, Validation cost= 0.2426, Validation acc= 0.8596
Epoch 46650: Training cost= 0.2224, Training acc= 0.8595, Validation cost= 0.2385, Validation acc= 0.8596
Epoch 46660: Training cost= 0.2232, Training acc= 0.8596, Validation cost= 0.2269, Validation acc= 0.8596
Epoch 46670: Training cost= 0.2245, Training acc= 0.8596, Validation cost= 0.2809, Validation acc= 0.8596
Epoch 46680: Training cost= 0.2580, Training acc= 0.8596, Validation cost= 0.1740, Validation acc= 0.8596
Epoch 46690: Training cost= 0.2208, Training acc= 0.8596, Validation cost= 0.2292, Validation acc= 0.8597
Epoch 46700: Training cost= 0.2251, Training acc= 0.8596, Validation cost= 0.2591, Validation acc= 0.8597
tm  [ 0.7 -0.1 -3.6 -4.8 -0.5  0.2 -0.1  0.5  1.3 -0.  12.2 -0.2 -0.1 -0.2  0.3  3.4 -0.3 -0.2 -0.2 -0.6 -1.4 -0.2 -0.4 -0.1 -1.2  0.5 -0.2  0.4  0.6 -1.4  5.4 -0.5  0.5  6.4  0.2 -0.1 -0.6  2.9 -1.7 -0.1 -0.6 -1.6 -1.2  0.9 -0.1 -0.3 -0.2  0.   6.  -2.2 -0.3 -0.2 -0.2 11.4 -1.4 -0.  -0.6 -3.   7.4 -4.5 -0.5 -0.7 -0.2 -0.3  2.9 -0.8 -0.3  1.2  0.1 -0.2  0.1 -1.   1.1 -0.4 -4.7  1.2 -0.1  1.8  0.5 -0.3  8.2 -0.7 -0.1  0.2 -2.  -1.3 10.1 -0.3  0.4 -0.5 -0.5 -0.1  0.3 -0.4 -0.8 -0.2 -0.2 -3.1 -0.5 -0.5  0.3 -0.3 -1.1 -0.3 -0.2 -0.2 -2.8  1.4 -0.1 -0.6  1.2 -0.3 -0.2 -1.1  3.3  6.3  2.2  2.4 -0.4  1.8 -0.1  0.2 -0.1  0.1 -0.4  0.8 -0.4 -2.4  6.7  4.7  1.7 -0.  -0.3  0.4  6.8 12.6  0.  -0.2 -0.1 -0.6 -1.   0.   0.1 -0.  -0.1  0.1 -0.1 -0.2 -0.5 -0.1  4.3 -0.1  2.5 -0.1  0.1 -0.  -0.2 -0.5 -0.7  0.2 -0.6 -0.6 -0.1 -0.1 -0.3 -0.1 -0.1 -0.1 -0.3 -0.1 -0.2 -0.3 -0.5 -0.6 -0.2  1.8 -1.4 -0.4  1.7 -0.1  0.4 -0.3 -0.2 -1.9 -0.1  0.7  1.4 -0.2 -0.1  4.4 -0.3 -0.  -0.6 -1.1  7.5 -2.4 -0.5 -1.   0.7 -0.1 -0.2 -0.2 -0.4 -0.1 -0.3 -2.1 -0.2 -0.1 -0.1 -0.5 -0.8  1.9 -0.4 -2.2  2.8  0.1 -1.  -1.5 -0.1 -0.3  0.  -0.3 -0.8 -1.6  1.   0.  -0.2 -0.5  1.5  2.6 -0.7  2.7 -0.  -0.  -1.1  4.8  0.  -1.2  0.1  6.1 -0.2  1.2 -0.1  0.4 -1.4 -0.3  1.8 -0.7 -1.3  1.1 -2.3 -0.1 -0.9  0.1 -0.4 -0.6]
ty_50sample [[4 2 6 3 9 7 0 5 8 1]
 [8 7 6 9 3 2 1 5 0 4]
 [3 5 9 8 6 1 0 7 4 2]
 [2 6 8 7 1 5 9 3 4 0]
 [8 3 4 6 1 7 5 9 0 2]
 [3 4 4 8 5 9 6 7 0 2]
 [7 0 3 4 9 1 5 6 2 8]
 [2 5 1 6 4 3 0 7 8 9]
 [2 0 3 4 8 9 7 5 1 6]
 [8 5 6 3 2 4 7 0 9 1]]
tt_50sample [[4 2 6 3 9 7 0 5 1 8]
 [8 7 6 9 3 2 1 5 0 4]
 [3 5 9 8 6 1 0 7 4 2]
 [2 6 8 7 1 5 9 3 4 0]
 [8 3 4 6 1 7 5 9 0 2]
 [3 1 4 8 5 9 6 7 0 2]
 [7 0 3 4 9 1 5 6 2 8]
 [2 5 1 6 4 0 3 7 8 9]
 [2 0 3 4 8 9 7 5 1 6]
 [8 5 3 6 2 4 0 7 9 1]]
vm  [-0.6 -0.2 -0.   4.5 -2.1 -0.4 -0.1 -0.1 -1.3 -0.8 -1.7 -0.3  0.1 -0.6 -0.6 -1.2 -0.1 -0.6  0.6 -1.  -0.7 -0.   1.9 -0.3 -1.2  1.  -0.1 -0.2 -1.5  1.   2.4 -0.2 -0.6  6.5 -0.1  0.1  4.1  2.4 22.1 -0.2 -0.   7.5  3.6  3.6 -0.2  0.2  7.6  0.3 -0.3  3.6 -0.5 -0.3  0.2 -3.2 -0.6 -0.1 -0.6  4.  -1.9 -1.3 -0.3 -0.3 -0.2 -0.3 -0.3 -0.2  0.5 -0.3  0.8  0.7 -0.2  2.3 -0.3 -0.4  2.5 -0.4 -0.1 -0.6  0.1  0.7 13.5  0.2 -0.3 -0.1 -0.2  6.8  2.4 -0.1 -0.3 -0.3 -0.3 -0.2 -0.3  1.1 -0.5 -0.3 -0.  -0.5 -0.5 -0.4  2.4  4.2 -0.3 -0.3 -0.2 -0.2 -0.2  1.3 -0.6 -1.6 -0.1 -0.3 -0.1  0.4 -0.5 -1.5 -0.4 -1.3 -0.5 -0.3 -0.1  7.2  1.1  1.1 -0.2 -0.7 -0.4 11.9 -1.1 -2.4 -0.4 -0.1  0.  -0.3 -5.4 -3.4 -0.2 -0.2 -0.5 -0.5  1.2 -0.8  1.   0.  -0.2 -0.4 -0.1 -0.3  5.5 -0.2 -0.7 -0.1 -0.6 -0.  -0.3 -0.2 -0.4 -0.3  3.1 -0.3 -0.1 -1.4 -0.1 -0.2  0.1 -0.  -0.2 -0.7 -0.2 -0.2 -0.1 -0.2 -0.4 -0.4 -0.1 -0.7  3.9 -0.2 -2.1  0.2 -2.2 -0.1 -0.1 -1.1 -0.3 -0.  -0.4 -0.8 -0.3 -0.4 -0.2 -0.1 -0.3 -1.   3.9  5.3 -0.   1.6 -0.1 -0.2  0.5  0.4 -0.2  0.5 -0.2  1.9 -0.  -0.2 -4.2 -0.2 -0.6 -1.6 -0.7  3.5 -0.1 -0.5 -2.3 -0.7 -0.1 -0.6 -0.  -0.2 -0.2 -0.7 -0.9 -0.7 -1.7 -0.5  0.5 -0.1 -0.7 -0.8 -0.2 -1.6  0.6 -0.1 -0.3  1.4 -0.3 -0.9 -0.1 -0.6 -0.1  0.5 -2.5 -1.9 -0.2  0.1 -0.4  0.2 -3.5 -0.2 12.8 -0.1  2.9  9.6]
vy_50sample [[5 9 9 4 1 1 8 3 2 6]
 [4 7 0 9 5 3 8 1 6 2]
 [1 3 4 7 6 8 2 5 9 0]
 [4 7 3 2 5 8 1 6 0 9]
 [2 1 6 8 9 7 0 4 5 3]
 [6 9 9 2 0 1 8 4 5 3]
 [8 3 5 7 7 4 1 9 0 6]
 [7 2 9 1 0 8 5 3 6 6]
 [8 9 2 5 7 1 6 0 4 3]
 [9 4 2 6 3 8 7 5 0 1]]
vt_50sample [[5 9 0 7 4 1 8 3 2 6]
 [4 7 0 9 5 3 8 1 6 2]
 [1 3 4 7 6 2 8 5 9 0]
 [4 7 3 2 5 8 1 6 0 9]
 [2 1 6 8 9 7 0 4 5 3]
 [6 7 9 2 0 1 8 4 5 3]
 [8 3 5 7 2 4 1 0 9 6]
 [7 2 9 1 0 8 5 3 4 6]
 [8 9 2 5 1 7 6 0 4 3]
 [9 4 2 6 3 8 7 5 0 1]]
Epoch 46710: Training cost= 0.2598, Training acc= 0.8596, Validation cost= 0.2776, Validation acc= 0.8597
Epoch 46720: Training cost= 0.2374, Training acc= 0.8596, Validation cost= 0.2451, Validation acc= 0.8597
Epoch 46730: Training cost= 0.2363, Training acc= 0.8596, Validation cost= 0.3200, Validation acc= 0.8597
Epoch 46740: Training cost= 0.2390, Training acc= 0.8596, Validation cost= 0.2477, Validation acc= 0.8597
Epoch 46750: Training cost= 0.2775, Training acc= 0.8596, Validation cost= 0.2371, Validation acc= 0.8597
Epoch 46760: Training cost= 0.2519, Training acc= 0.8596, Validation cost= 0.2577, Validation acc= 0.8597
Epoch 46770: Training cost= 0.2280, Training acc= 0.8597, Validation cost= 0.2214, Validation acc= 0.8597
Epoch 46780: Training cost= 0.2604, Training acc= 0.8597, Validation cost= 0.2315, Validation acc= 0.8597
Epoch 46790: Training cost= 0.2299, Training acc= 0.8597, Validation cost= 0.2196, Validation acc= 0.8597
Epoch 46800: Training cost= 0.2249, Training acc= 0.8597, Validation cost= 0.2645, Validation acc= 0.8598
tm  [-0.3 -0.4 -3.5 -6.3 -2.2 -0.2 -0.3 -0.1 -0.6  0.2 -1.2 -0.  -0.3 -0.5  5.9 -2.7  1.7 -0.9 -0.5  2.2 -1.  -0.  -0.4 -0.4 -1.7  5.8  0.5 -0.  -1.6 -1.5  4.5 -0.5 -1.4  4.3 -0.1 -0.   0.9 -1.3 -2.4  0.5 -0.2  2.3 -0.2  2.3  0.1 -0.2 -2.9 -0.1  3.7 -1.  -0.4 -0.2  0.3  0.4  1.  -1.1 -0.8 -0.5  4.7 -3.7  5.  -0.2  2.9 -0.2 -0.5  0.8 -0.2 -0.5 -0.  -0.2 -0.1  6.2 -0.6  0.5 -6.3  0.6 -0.1  2.6 -0.3  0.3 -1.   0.7 -0.2 -0.7 -1.2  4.1  5.6 -0.1  0.  -0.3 -0.4 -0.1 -0.3 -0.1 -0.6 -0.2  1.3 -3.6 -0.3 -0.5 -1.1 -0.2 -1.  -0.3 -0.1  1.7 -2.1  2.6 -0.5  2.3  1.5 -0.  -0.1 -0.4  6.8 -3.6 -0.7  1.5 -0.2 -0.1  0.3 -0.9 -0.3  0.5  0.3  7.3 -0.1  2.1  3.1  7.8  0.6  0.3 -0.7  0.5  5.   6.6 -0.4 -0.   0.9  0.1  3.2 -1.8  1.2 -0.1 -0.1 -0.3 -0.4 -0.2  4.8 -0.2  5.3 -0.3 -0.2  1.6 -0.2  0.1 -1.1 -0.4 -0.1 -0.1  1.  -1.1  0.6 -0.3  0.  -0.7 -0.7 -0.9  0.6 -0.3 -0.2  0.6 -0.4 -0.4 -0.1 -0.6 -0.3 -0.1  3.7 -0.1 -1.2  0.9 -0.4 -2.6 -0.3 -0.3  0.1 -0.5 -0.3  3.8 -0.3 -0.3  1.2 -1.5 -1.8 -1.  -0.4 -2.  -0.3 -0.2  0.1  0.   0.1 -0.1 -0.2 -1.8 -0.3 -0.7 -2.  -0.2 -0.4 -2.1 -0.4  1.8 -0.2 -0.4 -1.4 -1.  -0.5 -1.4 -0.3  0.2 -1.2 -1.4  2.2 -1.9 -3.  -0.5  1.3 -0.2 -0.2 -0.1 -0.6 -0.9  1.2  4.7 -0.1 -1.2  1.5 -3.4 -0.3 -1.  -0.2  0.3  5.   2.2 -0.9 -0.2 -0.9 -0.6  2.5  0.  -1.5 -0.2  4.9 -1.7]
ty_50sample [[0 0 5 6 3 1 7 8 9 2]
 [8 0 7 1 9 4 3 2 5 6]
 [7 3 1 6 0 8 9 4 5 2]
 [2 3 5 9 4 1 0 7 6 8]
 [2 3 4 5 6 1 7 9 0 8]
 [0 2 5 9 1 8 3 4 7 6]
 [3 4 6 8 7 1 9 5 0 2]
 [0 3 9 1 7 2 4 6 8 5]
 [9 7 5 3 2 6 0 4 1 8]
 [1 6 2 8 0 4 9 3 7 5]]
tt_50sample [[0 4 5 6 1 3 7 8 9 2]
 [8 0 7 1 9 4 3 2 5 6]
 [7 3 1 6 0 8 9 4 5 2]
 [2 3 5 9 4 1 0 7 6 8]
 [2 3 4 5 6 1 7 9 8 0]
 [0 2 5 9 1 8 3 4 7 6]
 [3 4 6 8 7 1 9 5 0 2]
 [0 3 1 9 7 2 4 6 8 5]
 [9 7 5 3 2 6 0 4 1 8]
 [1 6 2 8 0 4 9 3 7 5]]
vm  [-0.8 -0.6  7.9 -0.7 -1.3 -0.1 -0.1  0.4 -0.4 -0.5  6.5 -0.3 -0.3 -0.4 10.2 -0.4 -0.2 -0.3  1.9  0.9 -1.  -0.3  0.1 -0.3 -1.4  4.1 -0.2 -0.  -0.8 -0.7  1.9 -0.2 -0.3 13.3 -0.  -0.2  1.6 -0.6 -2.7 -0.5 -0.4  2.9 -0.3 -0.8 -0.3 -0.1 -1.3 -0.2 -1.1 -0.1 -0.3 -0.  -0.3  5.6 -0.7 -0.9 -0.8  3.1  3.1 -0.6  6.4 -0.  -0.1  0.3  0.6 -0.4 -0.3 -0.1  3.9 -0.4 -0.2  0.4 -0.  -0.1 -3.3  0.1 -0.1  0.   0.3 -0.2  2.8 -0.3 -0.1  0.4  0.9  4.6 -1.4 -0.2 -0.2 -0.1 -0.3 -0.1 -0.4 -0.6 -0.6 -0.1  0.9 -3.2 -0.9 -0.4  1.9  8.1  0.2 -0.1 -0.3 -0.2 -2.1  0.1  1.2 -0.  -0.3  0.2 -0.1 -0.5  3.6 -0.1 -0.4 -0.2  0.2 -0.1  0.  -0.4 -0.  -0.2 -0.3 13.1 -0.1 -0.7  2.6  2.  -0.2 -0.3 -0.3 -0.7 -1.2 12.7 -0.1 -0.2 -0.4 -0.3  0.2 -0.7  1.3 -0.1 -0.2 -0.1  0.1 -0.2 -1.8 -0.   0.7 -0.2 -1.1  1.7 -0.2 -0.1 -0.2 -0.4 -0.8 -0.3  0.9  0.6 -0.3 -0.  -0.2 -1.1 -0.5  0.7 -0.  -0.2 -0.2 -0.2 -0.2 -0.3 -0.2  2.6 -0.4  0.1  3.6 -0.1 -0.6 -0.1 -0.3 -2.   0.   0.2 -0.4 -0.3 -0.3  1.4 -0.2 -0.3 -0.4 -0.8 -2.2 -0.8 -0.4 -1.   0.2  0.2 -0.  -0.1 -0.5 -0.3 -0.1 -2.7  0.2 -0.1 -1.9 -0.2 -0.4 -0.5 -0.7  5.8 -0.9  0.7  4.2 -0.9  1.1 -0.3  0.2 -0.3 -0.2 -1.1  5.5 -0.7 -1.  -0.1 -0.6 -0.1 -0.1  0.2 -0.1 -0.7  0.2 -1.8  0.2 -0.4  1.7 -1.7 -0.1 -0.4 -0.4 -0.   0.2  1.2  0.  -0.2 -1.1 -0.4 -0.8 -0.1 -1.6 -0.1 -0.3  0.7]
vy_50sample [[7 1 6 0 5 2 4 3 9 8]
 [0 3 7 2 6 9 5 4 8 1]
 [2 5 0 6 3 7 8 4 9 1]
 [4 1 9 3 8 0 6 5 7 2]
 [5 9 6 2 3 0 8 4 7 1]
 [1 2 9 7 0 4 4 8 3 5]
 [8 0 7 5 5 6 2 1 3 4]
 [4 9 8 2 0 6 3 5 1 7]
 [7 1 2 3 0 4 0 8 9 5]
 [1 6 9 5 7 4 0 8 2 3]]
vt_50sample [[7 1 6 0 5 2 4 3 9 8]
 [0 3 7 2 6 9 5 4 8 1]
 [2 5 0 6 3 7 8 4 9 1]
 [4 1 9 3 8 0 6 5 7 2]
 [5 9 6 2 3 8 0 4 7 1]
 [1 2 9 0 7 6 4 8 3 5]
 [8 0 7 5 9 6 2 1 3 4]
 [4 9 8 2 0 6 3 5 1 7]
 [1 7 2 3 0 4 6 8 5 9]
 [1 6 9 5 7 4 0 8 2 3]]
Epoch 46810: Training cost= 0.2599, Training acc= 0.8597, Validation cost= 0.2344, Validation acc= 0.8598
Epoch 46820: Training cost= 0.2457, Training acc= 0.8597, Validation cost= 0.1918, Validation acc= 0.8598
Epoch 46830: Training cost= 0.2206, Training acc= 0.8597, Validation cost= 0.2333, Validation acc= 0.8598
Epoch 46840: Training cost= 0.1913, Training acc= 0.8597, Validation cost= 0.2460, Validation acc= 0.8598
Epoch 46850: Training cost= 0.1781, Training acc= 0.8597, Validation cost= 0.2261, Validation acc= 0.8598
Epoch 46860: Training cost= 0.2037, Training acc= 0.8597, Validation cost= 0.2154, Validation acc= 0.8598
Epoch 46870: Training cost= 0.1993, Training acc= 0.8598, Validation cost= 0.2457, Validation acc= 0.8598
Epoch 46880: Training cost= 0.2353, Training acc= 0.8598, Validation cost= 0.2998, Validation acc= 0.8598
Epoch 46890: Training cost= 0.2539, Training acc= 0.8598, Validation cost= 0.2247, Validation acc= 0.8598
Epoch 46900: Training cost= 0.2562, Training acc= 0.8598, Validation cost= 0.2075, Validation acc= 0.8599
tm  [-1.5  0.2 -1.8 -0.4 -1.3  0.  -0.1 -0.1 -1.5 -0.5  7.9 -0.1 -0.3 -0.1 -0.8  1.5 -0.2 -0.3 -0.2 -0.2 -1.2 -0.3 -0.  -0.3 -1.3  1.5 -0.1 -0.2 -1.5 -0.7  1.1 -0.4 -0.4 -2.   0.2 -0.3  5.9  5.9 -0.  -0.3  2.2  2.6  0.5  1.  -0.2 -0.1  0.2 -0.6 -1.8  9.7 -0.  -0.1 -0.1  8.   0.   0.5 -1.  -1.3 -1.  -0.1  4.6 -0.2 -0.2  0.6 -0.5  0.9 -0.  -0.7 -0.7  0.1  0.1  5.  -0.3  0.6 -1.7 -0.9  0.1 -1.   0.4  0.4  0.2 -0.3 -0.2 -0.6  1.9  4.3 -0.7 -0.  -0.1 -0.2 -0.4 -0.2 -0.1  0.2 -0.  -0.1 -0.5 -1.7 -0.1  0.5  1.4  2.8 -0.3 -0.2 -0.2  1.1 -1.3  1.   1.3 -1.6 -0.8 -0.2 -0.1  0.6 -0.1 -1.9 -0.4 -1.5 -0.2 -0.1 -0.4  5.7 -0.1 -0.  -0.2 -1.1 -0.1 -1.5 -1.5 -2.2 -0.7 -0.1  0.3  0.1  5.8  1.7 -0.1  0.1  0.3 -0.4 -0.6 -0.5 -0.9 -0.3 -0.1 -0.2 -0.4 -0.1  2.  -0.2  0.2 -0.1 -0.9 -1.  -0.  -0.2 -0.3  0.4  0.7 -0.2 -0.  -0.6 -0.1 -0.1 -0.2 -0.1 -0.2 -0.2 -0.2 -0.  -0.1 -0.1 -0.2 -0.1 -0.4 -0.2 -0.5 -0.4  1.3 -0.1 -0.8 -0.2 -0.1 -1.3  0.4 -0.3 -0.9  0.  -0.2  2.1 -0.2 -0.2  0.3 -0.9 -1.3  6.3 -0.3  0.4 -0.1  0.1 -0.2  0.   0.1 -0.6 -0.1 -1.2 -0.3 -0.3  3.5 -0.3  1.1 -1.6 -0.4  8.4 -0.3 -0.3 -0.6 -0.9 -0.8  0.7 -0.1 -0.  -0.4 -1.4  3.5 -0.9  4.4  1.4 -0.1 -0.5 -0.5 -0.2 -0.1  2.   3.2  3.  -0.2 -0.4  0.2  3.9 -0.   0.8 -0.3 -0.1  2.1 -0.1 -0.5  2.1 -1.  -0.7 -0.3 -0.1  0.2 -0.  -2.9  9.5]
ty_50sample [[2 1 0 4 6 8 9 5 7 3]
 [3 8 7 5 5 1 4 0 2 6]
 [0 3 6 8 1 4 5 7 2 9]
 [2 9 0 5 8 6 7 1 1 3]
 [4 2 0 9 1 7 3 6 8 5]
 [4 6 2 2 0 8 5 1 7 3]
 [9 3 8 6 7 5 1 0 2 4]
 [7 3 5 0 1 6 4 8 2 9]
 [2 7 1 9 5 4 6 8 3 0]
 [9 1 4 5 6 2 3 8 7 0]]
tt_50sample [[2 1 0 4 8 6 9 5 7 3]
 [3 8 7 5 9 1 4 0 2 6]
 [0 3 6 8 1 4 5 7 2 9]
 [2 9 0 5 8 6 7 1 4 3]
 [4 2 0 9 1 7 3 6 8 5]
 [4 6 2 9 0 8 5 1 7 3]
 [9 3 6 8 7 5 1 0 2 4]
 [7 5 3 0 1 6 4 8 2 9]
 [2 7 1 9 5 4 6 8 3 0]
 [9 1 4 5 6 2 3 8 7 0]]
vm  [ 1.7 -0.5 -0.9 -4.4 -1.9  0.3 -0.1 -0.1 -0.9 -0.1  5.   0.  -0.5 -0.3  8.2 -1.4 -0.5 -0.5 -0.2  2.  -1.4 -0.1  0.4 -0.3 -1.6  4.2 -0.  -0.2 -1.4 -0.4  3.  -0.3 -0.3  5.4 -0.  -0.1  2.3 -0.3 -3.4 -0.1 -0.3 -0.7 -0.   0.5 -0.3 -0.2 -2.  -0.6  6.8  1.2 -0.3 -0.  -0.1  7.6  2.2 -0.9 -0.6 -2.1  2.4 -1.8  1.8 -0.3  0.1  0.8  0.5  0.3 -0.2 -0.2  3.3 -0.2 -0.2  6.5 -0.  -0.2 -4.5 -0.3 -0.1 -0.4 -0.  -0.2 -1.7  0.1 -0.1 -0.  -1.6 -0.3  8.6 -0.1 -0.  -0.1 -0.1 -0.2 -0.4 -0.6 -0.4 -0.4 -0.4 -3.4 -0.3 -0.2 -0.3  4.  -1.2 -0.3 -0.1 -0.1 -2.2  1.3  1.7  2.5 -0.5 -0.3 -0.1 -0.2  5.2 -3.4 -0.5 -0.3 -0.1  0.5 -0.  -1.  -0.3 -0.3 -0.1 10.4 -0.2 -1.3 -0.1  5.6  1.8 -0.2 -0.1 -0.4  3.6  8.  -0.1 -0.1 -0.1 -0.3 -0.1 -1.4 -0.1 -0.3 -0.2  0.  -0.3 -0.  -1.3 -0.3  4.  -0.2  2.   0.6 -0.2  0.  -0.3 -0.3 -0.8 -0.1 -0.1 -0.3  0.7 -0.  -0.4 -1.1 -0.2 -0.5 -0.1 -0.2 -0.1 -0.3 -0.1  0.1 -0.6  2.7 -0.8 -0.3  4.6 -0.2  0.2 -0.3 -0.3 -2.5  0.2 -0.1  0.8 -0.4  0.5  1.1 -0.1 -0.2 -0.2 -1.5  1.1  0.4 -0.6 -1.4 -0.  -0.  -0.2 -0.2 -0.5 -0.  -0.2 -2.8 -0.2 -0.3  3.8 -0.4 -0.4 -2.4 -0.7 -1.3 -0.6 -0.1 -0.3 -1.1 -0.2  0.3 -0.2 -0.1 -0.7 -1.7  3.  -1.5 -1.   0.1  1.1  2.7 -0.2  0.5 -0.2  1.8  2.5  1.5  2.  -0.6  2.9 -0.5 -0.2 -0.2 -0.3 -0.   7.   1.9 -0.   0.5 -1.2 -0.3  4.2 -0.2 -1.9 -0.   0.1 -0.9]
vy_50sample [[0 4 6 7 2 3 8 5 1 9]
 [3 2 8 6 7 5 4 1 0 9]
 [0 4 2 8 5 5 7 3 6 9]
 [1 2 8 7 4 0 5 9 6 3]
 [0 4 1 9 2 5 6 8 3 7]
 [6 2 9 9 8 1 5 3 7 4]
 [6 8 8 0 4 5 7 2 1 3]
 [5 2 0 6 7 8 1 1 9 3]
 [5 4 2 1 9 6 0 8 7 3]
 [3 6 6 8 1 9 5 7 2 4]]
vt_50sample [[0 4 6 7 2 3 8 5 1 9]
 [3 2 8 6 7 5 4 1 0 9]
 [0 4 2 8 1 5 7 3 6 9]
 [1 2 8 7 4 0 5 3 6 9]
 [0 4 1 9 2 5 6 8 3 7]
 [6 2 9 0 8 1 3 5 7 4]
 [6 8 9 0 4 5 7 2 1 3]
 [5 2 0 6 7 8 4 1 9 3]
 [5 4 2 1 9 6 8 0 7 3]
 [3 0 6 8 1 9 5 7 2 4]]
Epoch 46910: Training cost= 0.2869, Training acc= 0.8598, Validation cost= 0.2396, Validation acc= 0.8599
Epoch 46920: Training cost= 0.2324, Training acc= 0.8598, Validation cost= 0.2377, Validation acc= 0.8599
Epoch 46930: Training cost= 0.2489, Training acc= 0.8598, Validation cost= 0.2583, Validation acc= 0.8599
Epoch 46940: Training cost= 0.2704, Training acc= 0.8598, Validation cost= 0.3032, Validation acc= 0.8599
Epoch 46950: Training cost= 0.2470, Training acc= 0.8598, Validation cost= 0.2590, Validation acc= 0.8599
Epoch 46960: Training cost= 0.1977, Training acc= 0.8598, Validation cost= 0.2041, Validation acc= 0.8599
Epoch 46970: Training cost= 0.1781, Training acc= 0.8598, Validation cost= 0.1999, Validation acc= 0.8599
Epoch 46980: Training cost= 0.2424, Training acc= 0.8599, Validation cost= 0.2178, Validation acc= 0.8599
Epoch 46990: Training cost= 0.2318, Training acc= 0.8599, Validation cost= 0.2514, Validation acc= 0.8599
Epoch 47000: Training cost= 0.2283, Training acc= 0.8599, Validation cost= 0.2124, Validation acc= 0.8600
tm  [-0.2 -0.6  6.6  4.9 -1.  -0.1 -0.2 -0.2  0.7  1.6  5.3 -0.6 -0.1 -0.3  7.6  4.9 -0.2 -0.3 -0.8 -0.5 -0.9  0.3 -0.3 -0.1 -0.6 -0.1 -0.1 -0.5  0.3 -0.5 -1.5 -0.  -0.3 -1.   0.2 -0.1 -0.6  4.5 -1.5 -0.6  3.5  6.5 -0.8 -0.5  0.1 -0.3 -0.7 -0.2  4.5 14.2 -0.3 -0.2 -0.6 13.  -0.9 -0.9 -0.7  5.6  4.7  7.6 -0.2 -0.4 -0.6 -0.  -0.5 -0.1 -0.1  0.5 -0.  -0.2 -0.5 -1.3 -0.5 -0.6 -4.2 -0.8 -0.3  1.2 -0.2 -0.3 -4.6  0.6 -0.2  0.4 -1.7  7.9  1.2 -0.  -0.3 -0.4 -0.3 -0.2 -0.  -1.2 -0.5  0.7 -0.2 -3.1  1.3 -0.4 -0.8  6.1 -0.3  0.2 -0.1  0.  -2.1 -0.6  1.8 -0.9 -0.3  1.1  0.1 -0.7  1.   6.2 -0.6  1.2 -0.3 -0.3 -0.   0.6 -0.3 -1.  -0.1  9.5  0.2 -2.8  4.5 -0.8  1.  -0.8 -0.1 -0.3 -0.8 -1.8 -0.2 -0.2 -0.1 -0.3 -0.7 -0.3 -0.4  0.3 -0.1 -0.  -0.3 -0.1  2.3  0.  -0.8 -0.2  3.2 -0.5 -0.2 -0.  -0.4  1.9 -0.4 -0.6  0.5 -0.6 -0.2  0.  -0.3  0.1 -0.4 -0.4 -0.1 -0.1 -0.1 -0.1 -0.2  0.5 -0.1 -0.1 -1.1 -0.7  1.5 -0.  -1.8 -0.5 -0.2 -1.4 -0.  -0.6 -0.  -0.5 -0.3  1.3 -0.  -0.2 -0.3 -0.3  4.6 -1.7 -0.4 -0.4 -0.  -0.1 -0.3 -0.2 -0.3 -0.9  0.2 -2.6 -0.3 -0.1  3.1  0.5  0.9  1.7 -0.6 -1.8 -1.4 -0.3  3.3 -0.9 -0.4 -0.3  0.2 -0.4 -0.5 -1.6  4.3  3.9  1.7 -0.2 -0.2  3.9 -0.9  0.7 -0.2  0.6 -1.  -1.2  1.  -1.1  3.9 -3.4 -0.1 -1.2 -0.1  0.  13.7  2.4 -0.2 -0.1 -1.  -0.9 11.7 -0.2 -0.9 -0.4 -2.5  5.1]
ty_50sample [[2 8 5 7 6 9 0 4 1 3]
 [1 4 5 0 2 6 9 7 3 8]
 [5 1 4 2 3 0 6 9 8 7]
 [0 7 3 2 9 1 1 4 5 8]
 [7 5 4 8 0 1 6 3 9 2]
 [1 0 3 7 6 2 4 9 8 5]
 [9 7 8 1 5 0 3 2 4 4]
 [4 8 7 6 2 3 5 0 1 9]
 [1 7 9 4 3 0 6 2 8 5]
 [3 8 9 7 2 6 5 1 4 0]]
tt_50sample [[2 8 5 7 6 9 0 1 4 3]
 [1 4 5 0 2 6 9 7 3 8]
 [5 1 4 2 3 0 6 9 8 7]
 [0 7 3 2 9 6 1 4 5 8]
 [7 5 4 8 0 1 6 3 9 2]
 [1 0 3 7 6 2 4 9 8 5]
 [9 7 8 1 5 0 3 2 4 6]
 [4 8 7 6 2 3 5 0 1 9]
 [1 7 9 4 3 0 6 2 8 5]
 [3 8 9 7 2 6 5 1 4 0]]
vm  [-0.7 -0.1 -0.7 -0.6 -1.7 -0.2 -0.3 -0.3 -1.  -1.  -5.1  0.1 -0.2 -0.1  0.1 -0.3  0.1 -0.4 -0.  -0.6 -1.4  0.1 -0.5 -0.3 -1.1 -0.1  0.6 -0.6 -0.4  0.8  2.  -0.4 -0.1 -0.   0.1 -0.4  2.  -0.7  6.1 -0.5  1.9  3.1  3.1  2.4 -0.   0.8  0.5  0.2  2.8 -1.3 -0.4 -0.3 -0.1 -2.9 -1.4 -0.1 -1.1  5.1 -1.2 -0.4 -0.1 -0.6 -0.2  0.  -0.9 -0.3 -0.2 -0.4 -0.   1.   0.9 -1.1 -0.2  1.2 -2.5 -0.5 -0.4 -0.4 -0.   0.3  1.3 -0.4 -0.3 -0.7 -1.   2.3  4.  -0.2 -0.2 -0.5 -0.4 -0.2  0.3  0.6 -0.7 -0.1 -0.1 -2.  -0.5 -0.4  2.5 -1.  -0.1 -0.2 -0.3  1.4 -1.2  0.6 -1.5 -1.5 -0.3 -0.4 -0.2 -0.8 -1.1 10.3  0.9 -0.8 -0.2 -0.1 -0.2  6.  -0.1 -0.3 -0.1  0.4 -0.  10.9  0.4  5.7 -0.3 -0.2 -0.2 -0.1 -1.2 -1.3 -0.3  0.  -0.5 -0.1  2.3 -0.2  0.8  0.1 -0.2 -0.1 -0.4 -0.1  6.7 -0.1 -0.1 -0.2  1.4 -0.5 -0.2 -0.  -0.6  2.   2.6 -0.5 -0.4 -1.1 -0.1 -0.2 -0.2  0.8 -0.2 -0.6  0.6 -0.2 -0.1 -0.3 -0.4 -0.2 -0.2 -1.2 -0.2 -0.4 -0.3 -0.1 -2.6  1.3 -0.5 -1.8 -0.1 -0.1 -0.  -0.4 -0.2 -0.2 -0.2  0.5 -0.1 -1.2  4.1  0.1  0.6  2.7  0.4 -0.1 -0.2 -0.1 -0.4 -0.3 -0.3 -0.7 -0.3 -0.3 -2.7 -0.3 -0.4  2.6 -0.5  0.5  0.8 -0.2 -1.2 -1.2 -0.3 -0.5 -0.   0.1 -0.1 -0.7 -1.5  4.2 -2.1 -0.6  0.2  1.1 -0.4 -0.3 -0.1 -0.9 -0.8  1.1 -0.5  0.   0.7 -2.9 -0.2 -1.1 -0.3 -0.   1.4 -0.6 -0.5 -0.1 -0.7 -0.4 -0.6 -0.1  3.7 -0.1  9.3 -0.8]
vy_50sample [[5 3 4 8 8 7 1 6 0 2]
 [7 0 1 9 6 3 2 5 8 4]
 [1 0 9 8 4 3 5 7 2 6]
 [4 8 9 5 1 6 3 0 2 7]
 [0 6 1 8 7 7 5 3 4 9]
 [2 4 0 3 8 6 5 7 1 9]
 [4 5 2 6 1 7 3 8 9 0]
 [2 3 9 9 6 4 0 7 1 5]
 [8 3 1 4 7 9 6 2 5 0]
 [7 5 3 9 8 2 4 0 1 6]]
vt_50sample [[5 3 4 8 9 7 1 6 0 2]
 [7 0 1 9 6 3 2 5 8 4]
 [1 0 9 8 4 3 5 7 2 6]
 [4 8 9 5 1 6 3 0 2 7]
 [0 6 1 8 7 2 3 5 9 4]
 [2 4 0 3 8 6 5 7 1 9]
 [4 5 2 1 6 7 3 8 9 0]
 [2 3 8 9 6 4 0 7 1 5]
 [8 3 1 4 7 9 6 2 5 0]
 [7 5 3 9 8 2 4 0 1 6]]
Epoch 47010: Training cost= 0.2247, Training acc= 0.8599, Validation cost= 0.2128, Validation acc= 0.8600
Epoch 47020: Training cost= 0.1915, Training acc= 0.8599, Validation cost= 0.2491, Validation acc= 0.8600
Epoch 47030: Training cost= 0.1890, Training acc= 0.8599, Validation cost= 0.2506, Validation acc= 0.8600
Epoch 47040: Training cost= 0.2803, Training acc= 0.8599, Validation cost= 0.2650, Validation acc= 0.8600
Epoch 47050: Training cost= 0.2943, Training acc= 0.8599, Validation cost= 0.2629, Validation acc= 0.8600
Epoch 47060: Training cost= 0.2632, Training acc= 0.8599, Validation cost= 0.2388, Validation acc= 0.8600
Epoch 47070: Training cost= 0.2381, Training acc= 0.8600, Validation cost= 0.2231, Validation acc= 0.8600
Epoch 47080: Training cost= 0.2152, Training acc= 0.8600, Validation cost= 0.3798, Validation acc= 0.8600
Epoch 47090: Training cost= 0.2925, Training acc= 0.8600, Validation cost= 0.2669, Validation acc= 0.8600
Epoch 47100: Training cost= 0.2429, Training acc= 0.8600, Validation cost= 0.2579, Validation acc= 0.8600
tm  [-0.7 -0.1 -5.5  1.4 -1.  -0.1 -0.2  0.1 -0.7 -0.4 -4.2 -0.4  0.3 -0.  -4.5 -1.1 -0.2 -0.2 -0.6 -1.2 -1.1 -0.5  2.  -0.  -0.7 -0.  -0.   0.7 -1.4 -0.7  2.7 -0.2 -0.4 -5.  -0.2 -0.   2.2 -1.7  5.5 -0.5 -0.  -1.1 -0.4  1.2 -0.   0.7  6.4  0.4  1.7  3.4 -0.2  0.1  0.2 -4.1 -0.6  3.8 -0.8 -2.9  1.  -1.4 -1.1  0.1 -0.6  0.2 -0.7  0.4 -0.3 -0.6  0.5  0.5  0.2  1.1 -0.1  1.1  1.8 -0.3 -0.1 -0.7 -0.1  0.7  9.6 -0.1 -0.5  1.5 -0.4 -1.1  5.3 -0.  -0.3 -0.5 -0.3  0.  -0.3 -0.7 -0.2 -0.2 -0.6 -0.9  0.1  0.3  0.9 -1.2 -0.1 -0.2  0.   0.7  1.2  1.7 -1.3 -2.5 -0.4 -0.   0.1 -0.2  2.2 -0.  -0.4 -0.3 -0.2 -0.6 -0.1 10.2 -0.1  0.5  0.2 -5.4 -0.3 14.3 -0.  -1.7  0.  -0.   0.1 -0.2 14.2  4.8 -0.  -0.2 -0.1 -0.6  2.1 -0.5 -0.4 -0.  -0.1 -0.3 -0.1 -0.1  3.3 -0.1 -0.6 -0.1  1.2 -0.4  0.3 -0.2  0.2 -0.7 -0.5 -0.3  0.5  0.9 -0.1 -0.2 -0.2  1.1 -0.   1.3  0.3 -0.1 -0.2 -0.1 -0.3 -0.1 -0.1 -0.4 -0.4 -0.2 -0.4 -0.2 -0.3 -0.1 -0.3 -1.2 -0.3  0.7 -0.4  2.  -0.1  2.1 -0.1 -0.3 -0.3 -0.8  9.3  0.4  1.4 -0.5 -0.4 -0.  -0.  -0.2 -0.3 -0.4  0.1  2.8 -0.1 -0.3  5.9  0.1 -0.5 -0.7 -1.   1.5  0.  -0.4 -0.8 -0.9 -0.5  1.2 -0.3 -0.1 -0.6 -1.2  2.2  0.1 -1.7 -0.1 -0.4  0.3 -0.2 -1.3 -0.   1.8  0.4  6.8 -0.1  1.5  2.6 17.9  0.3  4.4  1.   0.1 -1.4 -1.8 -0.2  1.5 -1.2 -0.3 -2.4 -0.1  3.  -0.3  5.7  7.7]
ty_50sample [[4 4 6 0 8 3 1 5 2 7]
 [8 6 3 7 2 4 9 9 5 0]
 [9 4 1 6 7 3 2 8 0 5]
 [3 3 6 7 8 0 5 1 4 2]
 [6 8 5 9 4 3 7 1 2 0]
 [3 4 1 1 8 6 9 5 0 2]
 [5 2 3 6 9 0 4 1 8 7]
 [8 2 7 3 6 5 1 0 4 4]
 [4 3 5 8 9 6 2 0 1 7]
 [3 6 8 4 0 9 9 5 7 1]]
tt_50sample [[9 4 6 0 8 3 1 5 2 7]
 [8 6 3 7 2 4 9 1 5 0]
 [9 4 1 6 7 3 2 8 0 5]
 [9 3 6 7 8 0 5 1 4 2]
 [6 8 9 5 4 3 7 1 2 0]
 [3 4 7 1 8 6 9 5 0 2]
 [5 2 3 6 9 0 4 1 8 7]
 [8 2 7 3 6 5 1 0 4 9]
 [4 3 5 8 9 6 2 0 1 7]
 [3 6 8 4 0 2 9 5 7 1]]
vm  [-0.3  1.1 -1.   3.5 -1.  -0.1  0.5 -0.3 -1.2 -1.   9.9 -0.5 -0.1 -0.2 -0.7  3.9 -0.3 -0.4 -0.1 -0.5 -1.1 -0.3 -1.2  0.6 -0.8 -0.3 -0.1 -0.  -1.1  2.6  3.4 -0.2 -0.8 12.8 -0.2 -0.2  3.2 -0.2  1.5 -0.3 -0.9 -3.1 -0.2 -0.4 -0.4 -0.3  4.1 -0.5  0.4 -4.9 -0.1 -0.2 -0.2 -0.2 -1.   0.   0.8 -1.9 -0.8 -4.  -0.3 -0.7 -0.3 -0.  -0.8 -0.4 -0.1 -0.2 -0.7 -0.2  0.1 -0.5  1.4  0.3  1.5 -0.6 -0.2 -1.1 -0.  -0.2 25.9 -0.1 -0.2 -0.5 -0.3 -2.5  3.6 -0.  -0.2 -0.4  2.2 -0.  -0.3  0.8 -0.4 -0.5 -0.5 -1.1  1.4 -0.5  3.7 -1.3 -0.1 -0.2 -0.2 -0.7 -0.   0.6  0.2 -1.6 -0.3  0.1 -0.  -0.1 -0.9  7.5 -1.5 -1.  -0.3 -0.7 -0.1  6.6  0.7 -0.  -0.1 -1.1 -0.2  3.  -1.1  1.1  2.  -0.2  1.5 -0.5  9.1 19.4 -0.   0.3  1.2 -0.1 -0.1 -0.6 -0.6 -0.1  0.8 -0.2 -0.3 -0.1 -0.7 -0.1 -0.6  0.3 -1.4 -0.3 -0.  -0.  -0.2 -0.4 -1.4  2.2 -0.3  3.  -0.1 -0.2 -0.2  2.  -0.   2.  -0.  -0.1 -0.3  0.2 -0.3 -0.3 -0.2  3.   0.8 -0.4 -0.   0.1  0.  -0.6 -0.3 -1.7 -0.3 -0.1 -0.3 -0.4 -0.  -0.5 -0.1  0.3 -0.3 -1.2  4.6  3.7  0.2  2.3 -0.3  0.1 -0.4 -0.  -0.4 -0.7 -0.5 -0.1 -0.2 -0.2 -2.2 -0.1 -0.6  0.1 -1.2  3.8 -0.1 -0.6  2.6 -1.  -0.5  1.8 -0.2 -0.1 -0.3 -1.3  2.4 -0.7 -0.2  3.2 -0.5  1.2 -0.6 -1.2 -0.3 -0.6  0.4  2.7 -0.2  0.7  1.8 14.6  0.1  2.9  0.3 -0.  -5.6 -1.4 -0.3  0.4 -1.3 -0.  -6.6 -0.1  0.7 -0.1  3.1  1.6]
vy_50sample [[6 9 3 4 2 1 7 0 5 8]
 [1 6 2 7 0 9 5 3 4 8]
 [6 7 1 0 4 9 2 3 5 8]
 [4 9 5 2 3 8 1 7 6 0]
 [6 9 1 5 3 4 2 0 0 8]
 [2 4 1 7 3 6 5 9 8 0]
 [0 9 1 2 5 3 6 6 4 7]
 [2 8 1 5 4 9 7 0 6 3]
 [8 7 1 1 0 6 4 5 3 9]
 [3 2 1 6 4 7 0 8 9 5]]
vt_50sample [[6 9 3 4 2 1 7 0 5 8]
 [1 6 2 7 0 9 5 3 4 8]
 [6 7 1 0 4 9 2 3 5 8]
 [4 9 5 2 3 8 1 7 6 0]
 [6 9 1 5 3 4 2 7 0 8]
 [2 4 1 7 3 6 5 9 8 0]
 [0 9 1 2 5 3 8 6 4 7]
 [2 8 1 5 4 9 7 0 6 3]
 [8 7 1 0 2 6 4 5 3 9]
 [3 2 1 6 4 7 0 8 9 5]]
Epoch 47110: Training cost= 0.2137, Training acc= 0.8600, Validation cost= 0.2464, Validation acc= 0.8601
Epoch 47120: Training cost= 0.2346, Training acc= 0.8600, Validation cost= 0.2366, Validation acc= 0.8601
Epoch 47130: Training cost= 0.2266, Training acc= 0.8600, Validation cost= 0.2396, Validation acc= 0.8601
Epoch 47140: Training cost= 0.2197, Training acc= 0.8600, Validation cost= 0.2692, Validation acc= 0.8601
Epoch 47150: Training cost= 0.2337, Training acc= 0.8600, Validation cost= 0.2477, Validation acc= 0.8601
Epoch 47160: Training cost= 0.2676, Training acc= 0.8600, Validation cost= 0.2937, Validation acc= 0.8601
Epoch 47170: Training cost= 0.2370, Training acc= 0.8600, Validation cost= 0.2642, Validation acc= 0.8601
Epoch 47180: Training cost= 0.2582, Training acc= 0.8601, Validation cost= 0.2119, Validation acc= 0.8601
Epoch 47190: Training cost= 0.2843, Training acc= 0.8601, Validation cost= 0.2274, Validation acc= 0.8601
Epoch 47200: Training cost= 0.3198, Training acc= 0.8601, Validation cost= 0.2420, Validation acc= 0.8601
tm  [-0.7 -0.4  3.3  3.9 -1.9 -0.2 -0.4 -0.2 -0.2 -0.1 -9.4  0.2 -0.4 -0.4  1.4 -1.4  1.7 -0.2  2.8  0.7 -1.1 -0.  -0.4 -0.2 -1.3  3.8 -0.4  0.8 -0.6 -0.2 -1.8 -0.5 -1.1 -5.4 -0.2 -0.2 -0.3 -1.1 -0.1 -0.1 -1.2  4.9  1.2 -0.8 -0.3 -0.1 -1.  -0.3  3.2 13.6 -0.2 -0.1 -0.3 -1.8 -0.5 -0.2 -0.4  9.2 -0.5  7.2  1.4 -0.5  0.5 -0.2 -1.1 -0.4 -0.1 -0.2  0.2 -0.1 -0.4  1.2  1.3  1.3 -3.5  0.9 -0.1 -0.4 -0.4 -0.  -5.7 -0.5 -0.2 -0.8 -1.4  7.1 -1.2 -0.1 -0.5  0.8 -0.2 -0.3 -0.3 -0.8 -0.9 -0.2  1.2 -3.3 -0.3 -0.5  0.1  3.4 -0.5 -0.  -0.3  0.5 -1.1 -0.8 -2.6 -0.4  1.3 -0.  -0.2 -0.   1.5  1.1 -0.8 -0.4 -0.2  0.1 -0.5  1.7 -0.1 -0.4  0.5  1.5  0.2  8.3 -0.6  0.2  1.2  0.4 -0.4 -0.3  4.6 -5.2 -0.3 -0.3  0.6  5.   2.5 -0.9 -0.1 -0.  -0.4 -0.2 -0.5 -0.2  5.5 -0.2 -0.4 -0.3  1.6  0.5 -0.3 -0.1 -0.8 -0.7 -0.3 -0.1  2.2 -0.7 -0.2 -0.1 -0.2 -0.4 -0.4 -0.1 -0.  -0.3 -0.2 -0.3 -0.1 -0.8 -0.3 -0.7 -0.2  0.9  1.1  0.4 -1.5  0.3 -0.3 -2.4  0.3 -0.1  0.8 -0.6 -0.2  1.  -0.  -0.3 -0.1 -0.3  1.   3.  -0.3 -0.5 -0.3 -0.1 -0.3  0.1 -0.  -0.3 -0.1 -0.4  0.2 -0.   5.8 -0.2 -0.6 -0.  -0.5  3.9 -0.2 -0.   3.9 -0.4 -0.5 -0.7 -0.1 -0.2 -0.6 -1.3  5.2 -0.2 -2.3 -0.1 -1.  -0.  -0.7 -0.7 -0.2  0.7 -0.7 -0.5 -0.3 -0.1  0.7 -2.6 -0.2 -1.1 -0.2 -0.3 16.4 -0.8 -0.5 -0.6 -1.  -0.8 14.  -0.3  0.3 -0.3  5.   2.4]
ty_50sample [[8 5 0 6 1 7 7 3 4 2]
 [2 0 8 5 5 7 4 6 3 1]
 [9 6 7 1 4 8 0 2 5 3]
 [6 3 4 5 2 1 0 0 7 9]
 [7 9 3 4 6 2 0 5 1 8]
 [5 8 1 4 0 7 3 3 2 9]
 [2 9 4 7 0 3 8 6 5 1]
 [1 0 3 6 2 4 7 5 8 9]
 [3 6 8 4 7 2 5 9 9 1]
 [8 0 6 9 4 3 2 1 7 5]]
tt_50sample [[8 5 0 6 1 9 7 3 4 2]
 [2 0 8 5 9 7 4 6 3 1]
 [9 6 7 1 4 8 0 2 5 3]
 [6 3 4 5 2 1 8 0 7 9]
 [7 9 3 4 6 2 0 5 1 8]
 [5 8 1 4 0 7 6 3 2 9]
 [9 2 4 7 0 3 8 6 5 1]
 [1 0 3 6 2 4 7 5 8 9]
 [3 6 8 4 7 2 5 9 0 1]
 [8 0 6 9 4 3 2 1 7 5]]
vm  [-0.8  1.3 -2.6 -2.4 -0.9  0.8 -0.6 -0.4 -1.7 -1.8  4.6 -0.3 -0.  -0.4 -0.6  4.5  0.7 -0.3 -0.5  2.9 -1.1  0.3 -0.7  0.3 -1.7  2.5 -0.2 -0.3 -0.9 -0.2  1.3 -0.3 -0.2 -4.4 -0.4 -0.2  5.2  2.6 -2.6 -0.6  1.9 -0.4  4.7 -0.2  0.3  0.9 -2.3  0.3  5.7 -1.4 -0.2  0.2  0.6  9.2 -0.6  0.1 -1.   5.9 -1.6  2.1  4.7 -0.2  0.9  0.7 -1.3  3.1 -0.2 -1.1 -0.3  0.4 -0.1  0.4 -0.2  1.7 -3.6  1.2 -0.5  0.4 -0.4  0.5 -2.9 -0.4  0.5 -0.  -0.9  0.1  4.3  0.2  0.1 -0.4 -1.2 -0.  -0.4  2.8 -0.2 -0.1  2.4 -2.8 -0.8  0.2  6.9 -2.6 -0.4  0.  -0.   0.9 -2.1  0.6  2.2 -0.8 -0.8 -0.3 -0.3 -0.5 -1.8  5.2 -0.1 -1.6 -0.2 -1.2 -0.4  2.3 -0.3  0.1 -0.2 -0.6 -0.3 -1.8 -0.9 12.2 -0.  -0.9 -0.4 -0.4  9.8  2.6 -0.   0.3 -0.6 -0.3 -0.5 -0.8 -1.1 -0.3 -0.1 -0.1  0.3 -0.1  8.   0.5  1.9 -0.1  2.6 -0.7 -0.4 -0.3 -0.8 -0.7  1.2 -0.9 -0.8 -0.2  0.1 -0.1 -0.3  1.   1.6 -0.9 -0.3 -0.2  0.1  0.5 -0.2 -0.7 -0.3 -1.7 -0.  -0.7  3.8 -0.1 -2.4  0.9 -0.4 -1.9  0.   0.6 -0.2  1.6 -0.1  1.3  0.8  0.3  0.8 -1.1 -1.1  3.2 -0.3  4.7 -0.5 -0.  -0.4 -0.1 -0.3 -0.1 -0.5 -3.  -0.4 -0.4 -0.7 -0.4  0.2 -0.6 -0.3 -0.3  0.1 -0.2 -0.  -1.2 -0.6 -0.7 -0.2  0.4  0.1 -0.7 -1.4  2.4  0.  -0.2  0.4  3.2 -0.6 -0.4 -0.5 -0.3  1.8  2.  -0.8 -0.2  1.7 -3.7 -0.1 -1.4  0.8 -0.1 11.   3.9 -0.2  0.6 -1.1 -0.4  7.6 -0.2 -1.5  1.2  3.8 -2.6]
vy_50sample [[3 5 2 6 4 8 0 1 9 7]
 [7 5 4 0 2 6 8 3 9 9]
 [1 5 6 4 2 7 8 3 0 9]
 [5 6 0 8 8 2 1 4 7 3]
 [0 7 6 2 5 8 1 4 9 3]
 [8 4 5 9 6 2 1 0 7 3]
 [9 7 4 2 8 5 6 1 3 0]
 [2 4 8 1 7 6 3 0 5 9]
 [5 7 3 4 8 1 2 6 0 9]
 [9 2 1 6 3 5 0 4 4 7]]
vt_50sample [[3 5 2 6 4 8 0 1 9 7]
 [7 5 4 0 2 6 8 3 9 1]
 [1 5 6 4 2 7 8 3 9 0]
 [5 6 0 8 9 2 1 4 3 7]
 [0 7 6 2 5 8 1 4 9 3]
 [8 4 5 9 6 2 0 1 7 3]
 [9 7 4 2 8 5 6 1 3 0]
 [2 4 8 1 7 6 3 0 5 9]
 [5 7 3 4 8 1 2 6 0 9]
 [9 2 1 3 6 5 8 0 4 7]]
Epoch 47210: Training cost= 0.2125, Training acc= 0.8601, Validation cost= 0.2758, Validation acc= 0.8602
Epoch 47220: Training cost= 0.2780, Training acc= 0.8601, Validation cost= 0.2602, Validation acc= 0.8602
Epoch 47230: Training cost= 0.2317, Training acc= 0.8601, Validation cost= 0.2052, Validation acc= 0.8602
Epoch 47240: Training cost= 0.2391, Training acc= 0.8601, Validation cost= 0.2845, Validation acc= 0.8602
Epoch 47250: Training cost= 0.2615, Training acc= 0.8601, Validation cost= 0.2280, Validation acc= 0.8602
Epoch 47260: Training cost= 0.2441, Training acc= 0.8601, Validation cost= 0.2471, Validation acc= 0.8602
Epoch 47270: Training cost= 0.1918, Training acc= 0.8601, Validation cost= 0.2729, Validation acc= 0.8602
Epoch 47280: Training cost= 0.2697, Training acc= 0.8602, Validation cost= 0.2844, Validation acc= 0.8602
Epoch 47290: Training cost= 0.2375, Training acc= 0.8602, Validation cost= 0.2399, Validation acc= 0.8602
Epoch 47300: Training cost= 0.2547, Training acc= 0.8602, Validation cost= 0.2904, Validation acc= 0.8602
tm  [-1.7 -0.3  9.1  8.4 -1.7  0.4  0.5 -0.1 -1.1 -0.1  0.2 -0.3 -0.1 -0.2  7.8 -0.3 -0.5 -0.3 -0.9  2.7 -1.3 -0.1  1.1 -0.3 -0.9  2.3 -0.1 -0.5 -1.2 -0.7 -1.5 -0.2 -0.3 -0.  -0.   0.6  3.  -0.9 -5.1 -0.4  2.2 -0.1 -0.1 -1.  -0.3 -0.1 -2.3 -0.3 -1.8  7.3 -0.1 -0.4 -0.   8.6 -0.3 -1.  -0.8  4.5  0.3  8.3 10.7 -0.3 -0.2 -0.4 -0.7 -0.2 -0.3 -0.3  1.1 -0.3 -0.3  3.5 -0.2  0.4 -5.  -1.1 -0.  -0.5 -0.1 -0.1 -3.7 -0.2 -0.2 -0.7  2.3  0.5 -3.3 -0.3  0.3 -0.2 -0.3  0.1 -0.3 -0.1 -0.4 -0.3 -0.6 -3.3  1.2 -0.3 -0.4  4.4 -0.1 -0.3  0.5  0.1 -2.2 -0.3  0.4 -0.6 -1.  -0.3 -0.1 -0.4  1.6 -1.4 -0.6 -0.4 -0.  -0.5  1.2  0.8 -0.2 -0.  -0.1  9.9 -0.1 -1.7 -0.8  4.3 -0.1 -0.  -0.2  0.4  7.9  8.4 -0.2  0.2 -0.1 -0.7  0.  -0.6 -0.2  0.  -0.3 -0.  -0.4  0.2 -1.  -0.  -1.3 -0.2 -0.9  0.2 -0.1 -0.3 -0.2  2.  -1.  -0.7 -0.   1.  -0.  -0.  -0.4 -0.1 -0.1 -0.3  0.  -0.2 -0.2  0.2 -0.   0.  -0.3  1.6 -0.7 -0.4  6.1 -0.1 -0.5 -0.4 -0.2 -1.6 -0.  -0.4 -1.  -0.4 -0.1  1.6 -0.1 -0.2  0.3 -1.  -4.4  2.6 -0.6 -0.3  0.1 -0.  -0.3 -0.2 -0.2 -0.2 -0.2 -2.6 -0.3 -0.4  6.3 -0.3 -0.5 -1.2 -0.8 10.  -1.  -0.4  7.8 -1.  -0.4  0.3 -0.1  0.3 -0.7 -1.1  4.  -0.5 -1.1 -0.4  0.4 -0.6  1.1  0.1 -0.2  1.9  1.2 -1.9 -0.2 -1.1  2.3 -1.3 -0.1 -0.5 -0.1  0.2 12.1  3.8 -0.5  1.5 -1.  -0.6  9.6 -0.3 -2.9  0.5 -0.2 -0.5]
ty_50sample [[1 6 0 8 7 2 3 5 9 4]
 [7 1 9 4 8 5 2 3 6 6]
 [7 3 2 0 1 6 5 8 9 4]
 [5 6 4 9 3 7 0 1 2 8]
 [2 0 5 7 6 9 8 3 1 4]
 [9 6 1 4 7 8 5 2 3 0]
 [1 4 9 3 6 8 7 5 2 2]
 [9 3 4 7 1 8 5 0 2 6]
 [8 7 0 6 3 9 5 1 2 4]
 [8 0 9 2 3 1 4 6 5 7]]
tt_50sample [[1 6 0 8 2 7 3 5 9 4]
 [7 1 9 4 8 5 2 3 0 6]
 [7 3 2 0 1 6 8 5 9 4]
 [5 6 4 9 3 7 0 1 2 8]
 [0 2 5 7 6 9 8 3 1 4]
 [9 6 1 7 4 8 5 2 3 0]
 [1 4 9 6 3 8 7 5 2 0]
 [9 3 4 7 1 8 5 0 2 6]
 [8 7 0 6 3 9 5 1 2 4]
 [8 0 9 2 3 1 4 6 5 7]]
vm  [-1.2 -0.2  1.2 -0.6 -1.8 -0.3 -0.4 -0.1 -0.8 -1.2 -4.1  0.5 -0.1 -0.1  2.8  2.2  0.2 -0.   0.5  1.4 -1.3 -0.2  1.3 -0.1 -1.6  2.4 -0.2 -0.6  1.9 -0.2 -0.7 -0.1 -0.2 -3.6 -0.1 -0.2  0.3  0.6  0.1 -0.2  3.   2.7  3.2  2.4 -0.1 -0.3 -1.5 -0.2  0.8  4.1 -0.4 -0.1 -0.3  2.3 -1.2 -0.4 -0.7  6.5 -0.9  4.2  2.9 -0.8 -0.2 -0.1 -0.9 -0.3 -0.2 -0.2  1.6 -0.2  0.2 -1.8 -0.1  0.5 -4.  -0.5 -0.3  0.1 -0.1 -0.3 -4.7 -0.3 -0.3 -0.7 -0.7  3.2 -0.3 -0.1  0.5 -0.2 -0.1 -0.2  0.7 -0.1 -0.7  0.1 -0.1 -3.  -0.6 -0.4  3.  -0.8 -0.3 -0.4 -0.4 -0.3 -1.7 -0.2 -1.1  0.1 -0.6 -0.3 -0.1 -0.5 -1.2 14.6  1.5 -0.7 -0.  -0.   0.5 -0.3 -0.6 -0.3 -0.2  4.   0.4  0.6  0.3  8.9 -0.5 -0.4 -0.6 -0.5 -1.  -4.  -0.3  0.4 -0.4 -0.2  2.3 -0.7  1.1  0.3 -0.   0.2 -0.1 -0.1  5.8 -0.4  0.2 -0.1  1.8  1.5 -0.3 -0.  -0.4 -0.4  3.2 -0.4 -0.4 -1.  -0.2 -0.1 -0.3 -0.9 -0.3 -0.5  1.2  0.2 -0.1 -0.1 -0.1 -0.6 -0.3 -0.8 -0.5  0.2  0.4 -0.2 -2.   1.  -0.4 -2.5 -0.3  0.6 -0.2 -0.5 -0.1  0.7 -0.3 -0.2  0.6 -1.1 -0.8 -0.1 -0.2  4.  -0.3 -0.1 -0.1  0.1 -0.3 -0.2  0.2 -1.8 -0.1 -0.2 -0.1 -0.  -0.6  4.1 -0.6  4.  -0.7 -0.2 -0.7 -0.4  0.2 -0.6 -0.   0.  -0.6 -1.2 -1.4  4.1 -1.9 -0.6 -0.7 -0.  -0.1 -0.  -0.5 -0.2 -1.4 -0.2 -0.2 -0.3  2.  -4.7 -0.1 -1.4 -0.3 -0.2 14.8 -0.  -0.2 -0.3 -1.1 -0.2 11.7 -0.2 -0.1  0.5  6.6 -1.7]
vy_50sample [[5 8 3 1 7 4 6 2 9 0]
 [4 2 8 1 3 7 9 0 5 6]
 [0 4 7 6 3 5 2 2 8 1]
 [7 9 4 0 5 6 2 1 3 8]
 [4 1 8 9 2 3 5 6 7 0]
 [1 4 2 0 6 7 7 3 9 9]
 [8 2 1 7 3 4 0 6 5 9]
 [9 8 0 6 4 7 2 1 5 3]
 [1 8 4 2 0 6 5 9 7 3]
 [9 9 5 2 8 0 4 7 3 1]]
vt_50sample [[5 8 3 1 7 4 2 6 9 0]
 [4 2 1 8 3 7 9 0 5 6]
 [0 4 7 6 9 3 5 2 8 1]
 [7 9 4 0 5 6 2 1 3 8]
 [4 8 1 9 2 3 5 6 7 0]
 [1 4 2 0 6 7 5 3 8 9]
 [8 2 1 7 3 4 0 6 5 9]
 [9 8 0 6 4 2 7 1 5 3]
 [1 8 2 4 0 6 5 9 7 3]
 [9 6 5 2 8 0 4 7 3 1]]
Epoch 47310: Training cost= 0.2621, Training acc= 0.8602, Validation cost= 0.2283, Validation acc= 0.8602
Epoch 47320: Training cost= 0.2686, Training acc= 0.8602, Validation cost= 0.2755, Validation acc= 0.8603
Epoch 47330: Training cost= 0.2456, Training acc= 0.8602, Validation cost= 0.2601, Validation acc= 0.8603
Epoch 47340: Training cost= 0.2052, Training acc= 0.8602, Validation cost= 0.3419, Validation acc= 0.8603
Epoch 47350: Training cost= 0.2915, Training acc= 0.8602, Validation cost= 0.2569, Validation acc= 0.8603
Epoch 47360: Training cost= 0.2465, Training acc= 0.8602, Validation cost= 0.2823, Validation acc= 0.8603
Epoch 47370: Training cost= 0.2658, Training acc= 0.8602, Validation cost= 0.2605, Validation acc= 0.8603
Epoch 47380: Training cost= 0.2636, Training acc= 0.8602, Validation cost= 0.2311, Validation acc= 0.8603
Epoch 47390: Training cost= 0.2392, Training acc= 0.8602, Validation cost= 0.2524, Validation acc= 0.8603
Epoch 47400: Training cost= 0.2586, Training acc= 0.8603, Validation cost= 0.2454, Validation acc= 0.8603
tm  [-0.5 -0.5  9.3  4.5 -1.4 -0.2 -0.5 -0.1 -0.6 -0.2  5.4 -0.3 -0.2 -0.4  9.7 -0.6 -0.  -0.1 -0.2  0.1 -1.1 -0.2 -0.3  0.4 -0.8  1.6  0.3 -0.4 -0.8 -0.4  1.   0.1  0.  14.5 -0.1 -0.2  1.1 -0.9 -2.6 -0.1  0.6  7.5  0.9 -1.2 -0.4 -0.1 -1.2 -0.1  2.1 -0.9 -0.3 -0.1 -0.2  1.9 -0.5 -1.1 -0.8 11.3  0.1  0.9  3.1 -0.4  0.6 -0.1  0.7 -0.5 -0.5 -0.1  2.  -0.3 -0.1 -0.1 -0.1 -0.  -4.6 -1.  -0.2 -0.7 -0.3 -0.4  5.1 -0.2 -0.  -0.4 -0.7  5.4 -0.8 -0.4 -0.5 -0.4 -0.1 -0.1 -0.4 -0.2 -0.4 -0.5 -0.5 -3.2 -0.3 -0.5  0.3  4.8 -0.3 -0.2 -0.1 -0.1 -2.1  1.1  1.9 -0.3  0.4 -0.  -0.1 -0.5  1.4  0.  -0.7 -0.1 -0.  -0.2 -0.1 -0.3 -0.3  1.3 -0.2 12.4 -0.3  1.1  3.2  1.4  0.8 -0.3 -0.3 -0.4 -0.9 13.5 -0.2 -0.1 -0.  -0.5  0.7 -0.5  0.3 -0.2 -0.1 -0.2 -0.3 -0.1  3.5  0.  -0.7 -0.2 -0.8 -0.  -0.3 -0.3 -0.5 -0.3 -0.5  0.1 -0.4 -0.5 -0.1 -0.1 -0.4 -0.2 -0.1 -0.3 -0.1 -0.1 -0.1 -0.2 -0.3 -0.3 -0.3 -0.3 -0.9 -0.3  3.1 -0.1 -2.3 -0.3 -0.3 -1.7 -0.2 -0.2 -0.2 -0.6 -0.4  1.  -0.  -0.2 -0.3 -0.9 -0.6 -0.8 -0.5 -0.3 -0.2 -0.1 -0.3 -0.3 -0.6 -0.6 -0.4 -2.1 -0.3 -0.4 -6.2  0.2 -0.2 -0.3 -0.8  0.6 -0.6 -0.5  5.2 -1.2 -0.2 -0.5  0.1 -0.1  0.3 -0.8  2.4 -0.7 -1.7 -0.1 -0.7  1.  -0.2  0.4 -0.4 -1.9 -0.4 -2.4 -0.4 -0.4  2.4 -6.2 -0.1 -2.2 -0.3 -0.1 -0.5 -0.1 -0.3 -0.1 -1.   1.2 -1.4 -0.1 -1.5 -0.1  3.4  0.7]
ty_50sample [[5 7 6 0 1 3 2 9 4 8]
 [4 6 8 0 3 2 1 9 5 7]
 [7 1 3 4 6 0 9 8 5 2]
 [6 0 9 2 3 5 8 1 4 7]
 [3 4 5 0 8 6 2 9 7 1]
 [2 3 7 6 4 0 8 1 9 5]
 [5 4 3 3 2 6 1 9 7 0]
 [9 1 6 0 5 8 3 7 2 4]
 [8 1 0 0 3 3 2 6 4 5]
 [2 9 6 1 8 3 7 0 5 4]]
tt_50sample [[5 7 6 0 1 3 2 9 4 8]
 [4 6 8 0 3 2 9 1 5 7]
 [1 7 3 4 6 0 9 8 5 2]
 [6 0 9 2 3 5 1 8 4 7]
 [3 4 5 0 8 6 2 9 7 1]
 [2 3 7 6 4 0 8 9 1 5]
 [5 4 3 8 6 2 1 9 7 0]
 [9 1 6 5 0 8 3 7 2 4]
 [8 1 0 9 3 2 7 6 4 5]
 [2 9 6 1 8 3 7 0 5 4]]
vm  [-0.8 -0.4 -3.  -1.3 -0.6 -0.1 -0.2 -0.3 -0.4 -0.3 13.8 -0.6 -0.1 -0.1 -1.5  6.  -0.3 -0.5 -0.1 -1.3 -0.9  0.   0.1 -0.2 -0.9 -0.5 -0.3  0.9  1.5 -0.7  4.8 -0.4 -0.1  7.3 -0.1 -0.1  1.7  6.3  7.2 -0.4 -0.5  3.2 -0.4  1.3 -0.3 -0.3  6.  -0.3 -1.7 -0.2 -0.1 -0.3 -0.6  7.4 -2.4  1.4 -0.3 -0.9  0.9 -4.   2.3 -0.4 -0.5 -0.5  2.7 -1.1 -0.2  0.8 -0.2 -0.2 -0.4 -1.6 -0.1 -0.8 -1.5 -0.2 -0.3 -0.2 -0.4 -0.2 20.7 -0.3 -0.4 -0.3 -0.   3.7  1.  -0.2 -0.1 -0.3 -0.3 -0.  -0.7 -0.  -0.8 -0.3 -0.9 -1.5  0.2 -0.4  2.4  2.  -0.   0.3 -0.3 -0.1 -2.2  0.6 -0.5 -1.5  0.  -0.1 -0.3 -0.5 -0.7 10.6  1.  -0.5 -0.2  0.8 -0.1  5.3  0.   0.2 -0.3 -2.  -0.  -1.4  2.2 -2.4 -0.1  0.3 -0.1 -0.1  4.4 10.8 -0.3 -0.2 -0.2 -0.5 -0.9  0.1 -0.4 -0.3 -0.2 -0.  -0.5 -0.   3.7 -0.3  0.9 -0.1 -1.8 -0.6 -0.1 -0.1 -0.1 -0.5 -0.6  0.4 -0.5 -0.6 -0.1  0.2 -0.2  1.  -0.5  0.7 -0.5 -0.2 -0.1 -0.2 -0.1 -0.2 -0.2 -1.  -0.9 -0.1 -0.8 -0.1 -0.9 -0.2  0.8 -1.5 -0.1 -0.3 -0.3 -0.4 -0.1  2.7 -0.3 -0.5 -0.3 -1.1 -0.4 -0.6 -0.2  1.8 -0.   0.1 -0.4 -0.3 -0.  -0.4 -0.3 -1.  -0.3 -0.1 -4.1 -0.1 -0.1  3.1 -0.8  4.4  1.9 -0.4 -1.2 -0.9 -0.4  0.3 -0.3 -0.2 -0.5 -1.5  2.   1.8  2.8 -0.2 -0.  -0.5 -1.5  2.  -0.3 -1.1 -0.9  4.4 -0.2 -0.7 -0.4  1.2 -0.2 -0.2 -0.3 -0.2 -4.4 -1.1  0.2 -0.7 -1.2  1.8 -5.3 -0.   3.4 -0.5 -2.1 10.4]
vy_50sample [[2 4 1 9 5 6 7 3 8 0]
 [9 6 2 5 8 1 3 4 7 0]
 [2 2 0 0 5 4 6 8 7 9]
 [5 0 4 2 7 9 3 6 8 1]
 [0 8 6 9 3 7 4 1 2 5]
 [2 9 0 6 5 8 3 7 4 1]
 [2 3 0 8 7 1 9 4 5 6]
 [3 4 6 8 9 1 2 5 0 7]
 [3 5 9 1 4 4 7 2 6 0]
 [7 0 5 4 1 1 2 6 8 3]]
vt_50sample [[2 4 1 5 9 6 7 3 8 0]
 [9 6 2 5 8 1 3 4 7 0]
 [2 3 1 0 5 4 6 8 7 9]
 [5 0 4 2 7 3 9 6 8 1]
 [0 8 6 9 3 7 4 1 2 5]
 [2 9 0 6 5 8 3 7 4 1]
 [2 3 0 8 7 1 9 4 5 6]
 [3 4 6 8 9 1 2 5 0 7]
 [3 5 9 1 8 4 7 2 6 0]
 [7 0 5 4 1 9 2 6 8 3]]
Epoch 47410: Training cost= 0.2134, Training acc= 0.8603, Validation cost= 0.2247, Validation acc= 0.8603
Epoch 47420: Training cost= 0.2558, Training acc= 0.8603, Validation cost= 0.2376, Validation acc= 0.8603
Epoch 47430: Training cost= 0.3137, Training acc= 0.8603, Validation cost= 0.2863, Validation acc= 0.8604
Epoch 47440: Training cost= 0.1945, Training acc= 0.8603, Validation cost= 0.2602, Validation acc= 0.8604
Epoch 47450: Training cost= 0.3303, Training acc= 0.8603, Validation cost= 0.2973, Validation acc= 0.8604
Epoch 47460: Training cost= 0.2457, Training acc= 0.8603, Validation cost= 0.2686, Validation acc= 0.8604
Epoch 47470: Training cost= 0.2906, Training acc= 0.8603, Validation cost= 0.2480, Validation acc= 0.8604
Epoch 47480: Training cost= 0.2831, Training acc= 0.8603, Validation cost= 0.2320, Validation acc= 0.8604
Epoch 47490: Training cost= 0.1858, Training acc= 0.8603, Validation cost= 0.2074, Validation acc= 0.8604
Epoch 47500: Training cost= 0.2525, Training acc= 0.8603, Validation cost= 0.2062, Validation acc= 0.8604
tm  [-0.4  1.1  7.1 13.1 -0.9 -0.2 -0.1 -0.  -0.8 -1.6 10.9 -0.4 -0.2 -0.3 -0.2  2.8 -0.4 -0.3  2.1 -0.6 -1.5  0.3 -1.2 -0.3 -0.5  0.3 -0.3 -0.5 -1.  -1.5  0.9 -0.3  1.9 15.1 -0.   0.5  3.5  3.8  6.7 -0.6  2.3 -3.7  0.3 -0.5 -0.4 -0.1  5.7 -0.   1.5 -5.3 -0.2 -0.2 -0.2 -0.1 -0.5  0.1 -0.6  0.3  0.6 -2.1 -0.5 -0.3 -0.6 -0.1 -0.9 -0.2 -0.1 -0.6  0.9 -0.3 -0.   0.9  0.9  0.6  1.9  0.6 -0.2 -0.4 -0.  -0.4 26.8 -0.6  0.2 -0.3 -0.5 -3.2 -0.7 -0.3 -0.3 -0.6 -0.3 -0.1 -0.   0.9 -0.6 -0.2 -0.1 -1.4 -0.5 -0.4  7.9 -0.5  1.2 -0.3 -0.3 -0.6 -0.1 -0.5 -0.2 -1.9 -1.1 -0.   0.1 -0.3  0.5  2.4  0.9 -0.7 -0.2 -0.6 -0.5  8.   0.3 -0.  -0.2 -0.4 -0.3  2.3  1.2  1.9 -0.6 -0.2  1.4 -1.  -1.6 14.1 -0.3 -0.1 -0.1  0.1 -0.6 -0.4 -0.3  0.5 -0.1 -0.1 -0.2 -0.2 -2.3 -0.  -1.1 -0.2 -1.1 -0.7 -0.3 -0.1  1.1 -0.5  1.8  0.9 -0.5 -0.1 -0.  -0.  -0.3  0.8  1.   0.7  0.4 -0.3  0.  -0.3 -0.1 -0.2 -0.5  3.7 -0.5 -0.6 -0.3 -0.1  0.1 -0.7 -0.3 -1.  -0.1 -0.1 -0.3 -0.3 -0.5  4.1 -0.  -0.   0.2 -0.8  5.3 -0.2  0.8 -0.1 -0.3 -0.3 -0.3 -0.1 -0.1 -0.4 -0.1 -0.  -0.2 -0.2 -1.4  0.3 -0.3 -0.6 -0.6  1.7  0.8 -0.5  3.1 -1.1 -0.  -0.1 -0.3 -0.  -0.5 -0.7 -1.5 -1.   1.1  0.9 -1.1  1.7 -0.5 -1.1 -0.  -0.4  2.4 -1.6 -0.6  2.   0.3 19.7 -0.2  5.1 -0.3  0.  -5.7 -1.5 -0.4  0.4 -1.1  0.7 -6.9  0.2  3.7 -0.1  3.1  0.4]
ty_50sample [[3 9 7 2 0 1 6 4 5 8]
 [3 2 5 0 1 9 6 7 8 4]
 [9 8 6 6 5 4 0 7 1 2]
 [1 0 0 6 3 4 8 7 2 5]
 [5 9 0 2 3 1 8 7 6 4]
 [5 4 0 3 8 7 6 9 2 1]
 [2 4 0 3 5 1 7 9 8 6]
 [6 5 1 3 2 2 8 9 9 7]
 [8 4 0 5 3 2 6 7 1 9]
 [9 0 7 1 8 6 5 3 2 4]]
tt_50sample [[3 9 2 7 0 1 6 4 5 8]
 [3 2 5 0 1 9 6 7 8 4]
 [9 8 6 3 5 4 0 7 1 2]
 [1 9 0 6 3 4 8 7 2 5]
 [5 9 0 2 3 1 8 7 6 4]
 [5 4 0 3 8 7 6 2 9 1]
 [2 4 0 3 5 1 7 9 8 6]
 [6 5 1 3 2 0 4 8 9 7]
 [8 4 0 5 3 2 6 7 1 9]
 [9 0 1 7 8 6 5 3 2 4]]
vm  [-1.6 -0.3 -1.9  6.4 -0.8 -0.1 -0.4 -0.1 -0.6  0.6 -2.9  0.3 -0.2 -0.2 -2.2 -1.  -0.3 -0.2 -0.3 -1.  -1.4 -0.2  1.1 -0.3 -0.9  0.8 -0.  -0.4 -1.1 -4.6 -0.9 -0.3 -0.6 -5.8 -0.   0.1  3.1  3.2 11.2 -0.3  1.3 -0.6 -0.7  1.8 -0.4 -0.1  2.7 -0.1 -2.5  0.6 -0.2 -0.1 -0.8 -0.6 -0.6  1.8 -0.9  3.7  5.9  4.9  7.5 -0.4 -0.2  0.3 -0.4 -0.5 -0.  -0.3  0.1 -0.1 -0.1  2.8 -0.5  0.7 -2.7 -0.5 -0.4 -0.1  0.2  0.  -2.   0.6 -0.1  0.2  3.3 -0.5 -2.3 -0.  -0.  -0.5 -0.3 -0.1 -0.1 -0.6 -0.3 -0.  -0.3 -2.6 -0.1  0.5  0.3 -2.5  0.1 -0.2 -0.1 -0.4 -1.8  0.  -0.8 -1.2 -0.1 -0.3 -0.2 -0.2  4.  -1.3 -0.3 -0.3 -0.1 -0.6 -0.1  4.5  0.3 -0.1 -0.3 -2.7 -0.2  4.4  7.2  6.3 -0.3  0.2  0.6 -0.   3.6 -5.2 -0.2  0.7 -0.1 -0.2  0.4 -0.6 -0.6 -0.3 -0.1 -0.4 -0.4 -0.   6.4 -0.  -0.8  0.4 -0.6 -0.3 -0.  -0.4  0.6 -0.9  1.5 -0.1 -0.2 -1.2 -0.3 -0.1 -0.2  0.1  0.2 -0.2 -0.2 -0.2 -0.1  0.2 -0.1  0.  -0.2 -1.4  0.9 -0.4 -1.  -0.2 -1.4 -0.2 -0.3 -1.5 -0.1 -0.1 -0.7  1.  -0.4 12.9 -0.3  0.  -0.4 -0.9 -2.6 -2.1 -0.5 -1.  -0.2 -0.2 -0.2 -0.1 -0.4 -0.3 -0.2 -2.1 -0.3 -0.2  2.9 -0.1 -0.8 -1.4 -0.6  8.  -0.9 -0.2 -0.9 -1.1 -0.4 -0.3 -0.   0.1 -0.2 -1.3 -2.  -0.4 -1.3  0.4 -0.1 -0.5 -0.6  0.9 -0.4  0.8  0.7  2.1 -0.  -0.8  3.  -0.8 -0.2 -0.4 -0.2 -0.2  7.8 -0.1  0.3 -0.2 -1.  -0.4  4.5 -0.1  6.8 -0.   5.4 -1. ]
vy_50sample [[1 0 3 8 5 9 4 2 6 7]
 [9 0 4 3 7 5 6 1 8 2]
 [7 5 4 9 8 1 1 3 6 0]
 [2 5 0 7 8 6 6 9 4 1]
 [9 0 4 7 8 1 3 2 5 6]
 [0 5 4 7 1 9 2 3 6 8]
 [8 7 9 5 3 1 6 0 4 2]
 [9 8 5 3 7 1 2 6 0 4]
 [6 1 8 2 7 3 5 4 9 0]
 [7 4 6 1 5 8 2 0 9 3]]
vt_50sample [[1 0 3 8 5 9 4 2 6 7]
 [9 0 4 3 7 5 6 1 8 2]
 [7 5 4 9 8 1 2 3 6 0]
 [2 5 0 8 7 6 3 9 4 1]
 [0 9 4 7 8 1 3 2 5 6]
 [0 5 4 7 1 9 2 3 6 8]
 [8 7 9 5 3 1 6 0 4 2]
 [9 8 5 3 7 1 2 6 0 4]
 [6 1 8 2 7 3 5 4 9 0]
 [7 4 6 1 5 8 2 0 9 3]]
Epoch 47510: Training cost= 0.2523, Training acc= 0.8604, Validation cost= 0.2576, Validation acc= 0.8604
Epoch 47520: Training cost= 0.2144, Training acc= 0.8604, Validation cost= 0.2060, Validation acc= 0.8604
Epoch 47530: Training cost= 0.2347, Training acc= 0.8604, Validation cost= 0.2404, Validation acc= 0.8604
Epoch 47540: Training cost= 0.2744, Training acc= 0.8604, Validation cost= 0.2261, Validation acc= 0.8605
Epoch 47550: Training cost= 0.2459, Training acc= 0.8604, Validation cost= 0.2259, Validation acc= 0.8605
Epoch 47560: Training cost= 0.2800, Training acc= 0.8604, Validation cost= 0.1995, Validation acc= 0.8605
Epoch 47570: Training cost= 0.2492, Training acc= 0.8604, Validation cost= 0.2494, Validation acc= 0.8605
Epoch 47580: Training cost= 0.2643, Training acc= 0.8604, Validation cost= 0.2267, Validation acc= 0.8605
Epoch 47590: Training cost= 0.2817, Training acc= 0.8604, Validation cost= 0.2530, Validation acc= 0.8605
Epoch 47600: Training cost= 0.2581, Training acc= 0.8604, Validation cost= 0.3024, Validation acc= 0.8605
tm  [-0.9 -0.3 -1.1 -1.4 -1.3  0.4 -0.4 -0.1  1.  -0.   8.1  0.3 -0.1 -0.3  1.1 -0.4 -0.  -0.2 -0.3 -0.4 -2.  -0.1 -0.8  0.3 -1.1  1.1  0.  -0.5 -0.5 -6.2  2.5 -0.2  0.5  0.7 -0.1  0.4 -0.4  4.9 -0.1 -0.2  5.2 -2.5 -2.1  1.7 -0.2 -0.2 -1.1 -0.1 -1.8 -3.5 -0.5 -0.1 -0.4  9.8 -0.4 -0.3 -1.1 -0.4 15.4 -0.7  9.9 -0.5  0.9 -0.1  2.6 -0.4  0.5  0.3 -0.3 -0.2 -0.2  0.6 -0.5 -0.7 -5.6  2.  -0.1  1.8 -0.1 -0.7 -0.   0.8 -0.   0.1  2.2 -1.8 -1.9 -0.1 -0.2 -0.7 -0.4 -0.2  0.7 -0.9 -0.6  1.1 -0.2 -4.  -0.3 -0.1  0.2 -2.1 -0.1 -0.4 -0.2 -0.3 -2.8  0.5  0.5  1.9 -0.1  0.1 -0.3 -1.1  7.4 -0.8  2.1  2.8 -0.5 -0.1 -0.3 -1.  -0.1 -0.5 -0.2  1.5  0.3 -1.8 15.5 13.4 -0.8 -0.3 -0.3 -0.3  0.3  1.  -0.4 -0.1 -0.  -0.5 -0.3 -0.3 -0.3 -0.2 -0.  -0.3  0.4 -0.3  2.9 -0.2  0.5 -0.3 -2.  -0.3  0.3  0.1 -0.2  1.1  2.9 -0.4 -0.3 -1.7 -0.3 -0.2  0.4 -0.2 -0.2 -0.3 -0.1 -0.3 -0.2 -0.1 -0.5 -0.3 -0.1 -0.2 -0.7 -0.7  1.  -0.2 -0.7 -0.7 -0.5 -2.2 -0.2 -0.4 -0.6 -0.4 -0.2 17.5 -0.2 -0.2 -0.2 -0.9 -4.3 -5.3 -0.7 -2.1  0.1  0.1 -0.  -0.1  0.  -0.2 -0.2 -3.3 -0.  -0.4 -0.2  0.  -0.6 -0.8 -0.6  5.9 -1.1  0.4 -1.1 -1.6 -0.4 -0.2 -0.2 -0.1 -0.2 -0.9 -2.2 -0.5 -1.  -0.3  1.8 -0.5 -0.6  0.5 -0.2 -0.  -0.3  1.7  0.  -1.1  3.2 -0.6 -0.1 -0.5 -0.3 -0.   2.1  2.1 -0.2 -0.6 -1.4 -0.5 -0.1 -0.   0.2 -0.1  3.6 -3.3]
ty_50sample [[1 3 0 2 4 5 5 8 6 9]
 [3 0 5 9 7 8 1 6 2 4]
 [4 0 9 8 5 1 2 3 7 6]
 [4 7 9 3 2 1 6 0 5 8]
 [7 7 5 8 6 9 0 2 4 4]
 [5 0 4 7 9 1 3 6 8 2]
 [7 6 1 3 8 8 2 4 9 0]
 [8 4 6 9 2 0 1 3 5 7]
 [7 4 1 1 6 0 3 5 9 2]
 [1 7 6 4 9 2 0 3 8 5]]
tt_50sample [[1 3 0 2 4 5 7 8 6 9]
 [3 0 5 9 7 1 8 6 2 4]
 [4 0 9 8 5 1 2 3 7 6]
 [4 7 9 3 2 1 6 0 5 8]
 [7 3 5 8 6 9 0 1 2 4]
 [5 0 4 7 9 1 3 6 8 2]
 [7 6 1 3 5 8 2 4 9 0]
 [8 4 6 9 0 2 1 3 5 7]
 [7 4 8 1 6 0 3 5 9 2]
 [1 7 6 4 9 2 0 3 8 5]]
vm  [-0.2 -0.3  8.  -0.  -1.7 -0.1 -0.   0.  -1.  -0.1  4.5 -0.3 -0.2 -0.2 10.7 -0.3 -0.6 -0.1 -0.  -0.3 -1.  -0.3  0.4 -0.1 -1.3  3.3 -0.1 -0.  -1.3  1.8 -0.3 -0.  -0.8  8.4 -0.1 -0.2  2.1  2.7 -0.5 -0.6 -0.2  1.4  1.1 -0.3  0.  -0.  -0.5 -0.3  3.7 10.9 -0.3 -0.2  0.2  7.3 -0.1 -1.2 -0.4 -1.1 -0.5  3.6  0.6 -0.1 -0.3 -0.4 -0.3  0.  -0.2 -0.1  1.5 -0.1  0.   4.5  0.4  0.6 -2.6 -0.6 -0.1 -0.5 -0.1 -0.2 -1.8 -0.1 -0.1 -0.2 -1.3  2.6  2.7 -0.2 -0.2 -0.4 -0.5 -0.2 -0.  -0.5 -0.3 -0.1 -0.1 -2.6 -0.2 -0.1 -0.2  8.8 -0.6 -0.1 -0.   0.6 -1.4 -0.3  1.5 -0.4 -0.4 -0.2  0.5 -0.1  2.2 -2.3 -1.  -0.5  0.  -0.2  0.   1.  -0.  -0.3 -0.3 13.5 -0.3 -1.2 -1.4 -0.8  0.6  0.2 -0.1  0.5 -3.4 -0.6 -0.2 -0.1 -0.4 -0.2 -0.3 -1.1 -0.4 -0.2 -0.1 -0.  -0.1 -0.  -2.9  0.4 -0.2 -0.2  2.5 -0.  -0.2  0.1 -0.3 -0.3 -0.3 -0.2  0.8 -0.3 -0.1 -0.2 -0.2 -0.8 -0.3 -0.4 -0.2 -0.1 -0.2 -0.  -0.  -0.1 -0.3  3.4 -0.3 -0.1  1.2 -0.1  0.4 -0.4 -0.5 -1.9 -0.1 -0.6  0.5 -0.3  0.1 -0.5 -0.1 -0.1 -0.4 -0.8  2.5  5.  -0.1 -0.8 -0.  -0.1 -0.3 -0.2 -0.5  0.5 -0.1 -1.9 -0.1 -0.1  7.1 -0.1 -0.1 -1.5 -0.7 -0.3 -0.9 -0.2  1.3 -0.9 -0.2  0.2 -0.  -0.  -0.  -0.9  4.9 -0.4 -0.1  0.3 -0.   1.3 -0.4 -0.1  0.   1.7  1.9 -1.4  1.5 -0.2  2.2  5.3 -0.1  1.5  0.2 -0.2  6.9 -0.2 -0.6  0.2 -1.  -0.7  4.4 -0.2 -0.2 -0.2 -1.5  5.2]
vy_50sample [[7 0 2 8 6 4 9 1 5 3]
 [8 3 1 9 0 4 5 2 7 6]
 [1 2 9 6 7 5 4 8 0 3]
 [8 3 0 6 9 1 2 5 4 7]
 [1 4 5 3 2 6 7 9 8 8]
 [0 2 9 6 4 8 7 5 3 3]
 [3 1 9 4 5 2 7 8 6 0]
 [5 1 6 3 9 2 4 8 7 0]
 [4 8 3 0 5 6 9 9 2 7]
 [2 8 9 4 3 7 6 1 5 5]]
vt_50sample [[7 0 2 8 6 4 9 1 5 3]
 [8 3 9 1 0 4 5 2 6 7]
 [1 2 9 6 7 5 4 0 8 3]
 [8 3 0 6 9 1 2 5 4 7]
 [1 4 5 3 2 6 7 9 0 8]
 [0 2 9 6 4 8 7 5 1 3]
 [3 1 9 4 5 2 7 8 6 0]
 [5 1 6 3 9 2 4 8 7 0]
 [4 8 3 0 5 6 1 9 2 7]
 [2 8 9 4 3 7 6 1 5 0]]
Epoch 47610: Training cost= 0.2227, Training acc= 0.8605, Validation cost= 0.2368, Validation acc= 0.8605
Epoch 47620: Training cost= 0.2368, Training acc= 0.8605, Validation cost= 0.2463, Validation acc= 0.8605
Epoch 47630: Training cost= 0.2924, Training acc= 0.8605, Validation cost= 0.2288, Validation acc= 0.8605
Epoch 47640: Training cost= 0.2360, Training acc= 0.8605, Validation cost= 0.2160, Validation acc= 0.8605
Epoch 47650: Training cost= 0.2488, Training acc= 0.8605, Validation cost= 0.2437, Validation acc= 0.8606
Epoch 47660: Training cost= 0.2117, Training acc= 0.8605, Validation cost= 0.2398, Validation acc= 0.8606
Epoch 47670: Training cost= 0.2188, Training acc= 0.8605, Validation cost= 0.2532, Validation acc= 0.8606
Epoch 47680: Training cost= 0.2300, Training acc= 0.8605, Validation cost= 0.2128, Validation acc= 0.8606
Epoch 47690: Training cost= 0.2114, Training acc= 0.8605, Validation cost= 0.2194, Validation acc= 0.8606
Epoch 47700: Training cost= 0.2457, Training acc= 0.8605, Validation cost= 0.2448, Validation acc= 0.8606
tm  [ 1.2  0.4 -0.8  6.8 -1.4  0.1 -0.  -0.  -1.3 -0.5  6.7  0.2 -0.1 -0.5 -1.8 -1.  -0.1 -0.5 -0.1 -0.9 -1.  -0.1 -0.7 -0.3 -0.8  1.   0.7 -0.6 -1.6  1.3  3.1 -0.4 -0.4 13.2 -0.1  0.4  2.8 -0.1 13.1  0.1  2.4  6.7  4.2  3.3 -0.3 -0.1  6.8  0.9  6.  -3.1 -0.2 -0.2 -0.2 -2.8 -0.1  1.9 -0.6  4.6 -1.6 -4.  -1.7 -0.5 -0.5 -0.1 -0.6 -0.5 -0.2 -0.1  2.8 -0.1  0.2  3.9  0.2  0.4  2.2 -0.8 -0.1 -0.5 -0.1 -0.2 31.  -0.1 -0.5 -0.4 -1.4  5.   8.6 -0.3  0.2 -0.3 -0.4 -0.  -0.1  2.1 -0.5 -0.4  0.8 -0.4 -0.3 -0.1  1.5  3.1 -0.4 -0.2 -0.2 -0.3  1.1  1.4  0.6 -1.7 -0.7 -0.1 -0.2 -0.  -0.1 -1.5  1.4 -0.9 -0.2 -0.2  0.9  7.9 -0.1  0.5 -0.3 -2.2 -0.3 10.6 -0.3 -2.1 -0.   0.2  0.  -0.2 -1.3 11.2 -0.2 -0.2 -0.3 -0.7  0.3 -0.7  0.5 -0.3 -0.2 -0.2 -0.2 -0.   6.2 -0.1 -0.9 -0.3 -0.2  0.2 -0.2 -0.1 -0.4 -0.4  1.1  1.1 -0.  -0.9 -0.1 -0.2 -0.3  0.4 -0.  -0.7 -0.1 -0.3 -0.1 -0.1 -0.2 -0.1 -0.3 -0.9 -0.2 -0.5 -0.9 -0.3 -2.2 -0.2 -0.1 -1.1 -0.1  0.1 -0.2 -0.3 -0.3 -0.3  0.1  0.2 -0.2 -0.7 14.3  2.2  0.6  0.5 -0.1 -0.  -0.2 -0.2 -0.3  0.2 -0.2  4.5 -0.2 -0.2 -7.6 -0.3 -0.6 -1.8 -0.5 -1.   1.  -0.5 -1.1 -0.7 -0.3 -0.5 -0.2 -0.  -0.5 -0.3 -0.4 -1.9 -1.7 -0.9 -0.4  1.7 -0.5 -1.1 -0.1 -2.3  1.7  1.4 -0.4  2.3  0.2 -0.2 -0.2 -0.5 -0.3 -0.  -6.7 -1.9 -0.1 -0.2 -1.   0.3 -7.6 -0.1  7.9 -0.2  4.7  8.3]
ty_50sample [[5 9 0 4 7 3 6 2 1 8]
 [2 9 3 1 8 7 6 0 4 5]
 [9 8 2 7 0 3 6 4 1 5]
 [8 5 9 2 3 7 4 1 6 0]
 [6 2 5 9 1 7 8 4 0 3]
 [5 8 6 7 4 1 2 0 9 3]
 [8 2 1 3 4 6 9 9 5 7]
 [0 5 9 6 1 7 8 4 3 2]
 [8 6 1 2 7 4 5 0 3 9]
 [7 6 6 5 2 8 9 1 3 4]]
tt_50sample [[5 9 4 0 7 3 6 2 1 8]
 [2 9 3 1 8 7 6 0 4 5]
 [9 8 2 7 0 3 6 4 1 5]
 [8 5 9 2 7 3 4 1 6 0]
 [6 2 9 5 1 7 8 4 0 3]
 [5 8 6 7 4 1 2 0 9 3]
 [8 1 2 3 4 6 0 9 5 7]
 [0 5 9 6 1 7 8 4 3 2]
 [8 6 1 2 7 4 5 0 9 3]
 [7 6 0 5 2 8 9 3 1 4]]
vm  [-1.1 -0.1  0.2 21.8 -1.   0.3 -0.1 -0.1 -1.1  0.2  7.3 -0.2 -0.2 -0.1 -3.8 -0.8 -0.4 -0.2  0.1 -1.3 -1.3 -0.1 -0.5 -0.2 -0.6  1.3 -0.4 -0.3 -1.3 -4.2 -0.4 -0.2 -0.  -1.2 -0.2  0.4  4.8  3.  10.1 -0.1  3.7 -1.  -0.4 -0.2 -0.4 -0.3  8.9  0.3 -3.  -2.6 -0.3 -0.  -0.3 -0.4 -0.   4.1 -0.7  5.7  0.4  3.5  2.8 -0.5 -0.7 -0.4  1.  -0.7  0.1 -0.2 -0.1 -0.3  0.2  4.8 -0.2 -0.4 -0.2 -0.5 -0.  -0.3 -0.1 -0.6 19.5  0.  -0.3 -0.7  3.  -1.  -3.1 -0.1 -0.2 -0.2 -0.1 -0.2  0.2  1.7 -0.5 -0.  -0.6 -0.8  0.1  0.9  0.  -2.   1.  -0.2 -0.4 -0.1 -0.8 -0.1  0.1 -1.9 -0.2 -0.4 -0.2 -0.2  1.5 -2.5  2.5 -0.8 -0.3  0.3 -0.2  7.7 -0.2 -0.4  0.1 -4.8  0.3  3.3  1.5  0.2 -0.8  0.4 -0.2  1.1  8.1  6.2 -0.3 -0.3 -0.1 -0.5 -0.4 -0.1 -0.3 -0.3 -0.2  0.2  0.  -0.   4.9 -0.4 -2.1 -0.1 -1.9  0.2  0.2 -0.2  1.3  1.4  0.  -0.7 -0.7 -1.  -0.1 -0.1  0.1  0.9 -0.2 -0.4 -0.4 -0.3 -0.1 -0.2 -0.   0.3 -0.1 -1.3 -0.9 -0.5 -0.6 -0.4 -1.5 -0.5  0.  -1.5  0.1 -0.1 -1.3  0.5  0.6 11.9 -0.2 -0.3 -0.2 -0.6 -0.3 -0.2 -0.2 -0.5 -0.4 -0.1 -0.3 -0.1 -0.4  0.2  0.2  0.4  0.3 -0.  -2.1 -0.1 -0.4 -2.3 -0.3  8.8 -0.4  0.3  2.7 -1.3 -0.4  1.1 -0.1 -0.1  0.5 -0.6 -1.4 -1.5 -0.3 -0.2  0.1 -1.1 -0.7 -0.1 -0.2 -0.5  1.9 -0.1 -0.3 -0.2 -0.2  8.5 -0.2  1.6 -0.2 -0.2 -4.  -1.4 -0.2 -0.4 -1.  -0.3 -5.1 -0.2  6.4 -0.1  2.7  1.9]
vy_50sample [[1 0 9 3 2 5 6 8 4 7]
 [4 8 0 6 1 5 7 2 3 9]
 [8 2 3 0 6 1 9 4 7 5]
 [4 5 9 8 0 2 3 1 1 7]
 [5 3 2 8 1 7 0 9 9 4]
 [9 4 5 0 8 2 6 7 3 3]
 [7 3 2 1 6 0 4 8 5 9]
 [9 5 2 0 8 4 3 6 7 1]
 [9 5 4 0 3 2 8 6 1 7]
 [5 6 8 8 4 4 2 3 1 7]]
vt_50sample [[1 0 9 3 2 5 6 8 4 7]
 [4 8 0 6 1 5 7 2 3 9]
 [8 2 3 0 6 1 9 4 7 5]
 [4 5 9 8 0 2 3 1 6 7]
 [5 3 2 8 1 7 0 9 6 4]
 [9 4 5 0 2 8 6 7 1 3]
 [7 3 2 1 6 0 4 8 5 9]
 [9 5 2 0 8 4 6 3 7 1]
 [9 5 4 0 3 2 8 6 1 7]
 [5 6 8 0 9 4 2 3 1 7]]
Epoch 47710: Training cost= 0.2805, Training acc= 0.8606, Validation cost= 0.2322, Validation acc= 0.8606
Epoch 47720: Training cost= 0.2280, Training acc= 0.8606, Validation cost= 0.2343, Validation acc= 0.8606
Epoch 47730: Training cost= 0.2535, Training acc= 0.8606, Validation cost= 0.2334, Validation acc= 0.8606
Epoch 47740: Training cost= 0.2277, Training acc= 0.8606, Validation cost= 0.2073, Validation acc= 0.8606
Epoch 47750: Training cost= 0.2218, Training acc= 0.8606, Validation cost= 0.2439, Validation acc= 0.8607
Epoch 47760: Training cost= 0.2426, Training acc= 0.8606, Validation cost= 0.2635, Validation acc= 0.8607
Epoch 47770: Training cost= 0.2600, Training acc= 0.8606, Validation cost= 0.2702, Validation acc= 0.8607
Epoch 47780: Training cost= 0.2958, Training acc= 0.8606, Validation cost= 0.2703, Validation acc= 0.8607
Epoch 47790: Training cost= 0.2789, Training acc= 0.8606, Validation cost= 0.2380, Validation acc= 0.8607
Epoch 47800: Training cost= 0.2579, Training acc= 0.8606, Validation cost= 0.2456, Validation acc= 0.8607
tm  [-1.2  1.3 -0.6 -2.6 -1.8  0.  -0.4 -0.3 -0.8 -1.3  8.3 -0.4 -0.2 -0.2  5.9  5.3 -0.3 -0.4 -0.   3.6 -1.4 -0.3 -0.4  0.9 -1.7  2.2 -0.4  0.9 -0.8 -3.2  0.2 -0.1 -0.8 -1.4 -0.2 -0.3  3.   9.7  6.6 -0.1 -0.9 -1.2 -0.2 -0.2 -0.2 -0.1 -2.8 -0.5 -0.4 -0.7 -0.1 -0.1  0.1 15.3 -0.8 -0.9 -0.5  4.   3.4  2.5  6.4 -0.6  1.4  0.2 -0.8 -0.1 -0.3 -0.4 -0.8 -0.2 -0.2 -0.1 -0.3  1.1 -4.4 -0.2 -0.  -0.2 -0.1  0.2 -3.6 -0.3  0.8  0.1  0.4 -0.4 -0.8 -0.1 -0.   0.5  0.1 -0.3 -0.2 -0.5 -0.3 -0.2  0.  -3.5 -0.1 -0.1  4.9 -1.7 -0.4 -0.3 -0.  -0.4 -2.5  0.1  1.6 -0.  -0.2 -0.2 -0.3 -0.7 -0.3  5.  -1.  -0.9 -0.2 -0.5 -0.6 -0.2 -0.1  1.7 -0.2  7.2 -0.1 -3.3  5.8 10.9  0.2 -0.7 -0.3 -0.4 -2.7 -4.8  1.   0.5  1.8 -0.1 -0.3 -0.6 -1.1 -0.  -0.   0.6 -0.1 -0.   5.  -0.2  2.3 -0.2 -0.1 -0.6  0.2 -0.2 -1.2  0.4  3.3 -0.2 -0.3 -1.1  0.8 -0.2  0.6  1.9  0.9  0.1 -0.1 -0.2 -0.2  0.7 -0.1 -0.3 -0.4 -0.5  4.6 -0.3 -0.6 -0.2 -1.3 -0.4 -0.5 -1.7 -0.3 -0.4 -0.7 -0.6 -0.4  9.  -0.3 -0.1  0.3 -1.2 -2.6 -1.6 -0.4  1.5 -0.4 -0.1 -0.5 -0.2 -0.4 -1.  -0.2 -3.3 -0.2 -0.1 -0.1  0.2 -0.6  0.9 -0.6  7.5 -0.3 -0.9 -1.  -1.3 -0.7 -0.2 -0.4  0.1  0.2 -1.3 -2.1  2.   2.   3.4 -0.1  1.3 -0.7 -0.5 -0.5  0.1  1.4  1.9 -0.4 -0.3  3.3 -3.7 -0.3 -1.2 -0.  -0.1 12.2  3.6 -0.3  0.3 -1.1  1.   9.  -0.1  4.3 -0.3 -0.1 -2.4]
ty_50sample [[2 3 1 5 8 4 0 7 9 6]
 [7 6 4 5 8 2 1 9 3 0]
 [6 0 9 1 5 4 3 8 2 7]
 [9 7 1 6 0 4 8 2 3 5]
 [0 4 3 7 9 8 6 5 2 1]
 [7 5 8 1 3 6 2 4 9 0]
 [1 8 2 0 4 3 7 6 9 5]
 [7 0 0 4 4 1 8 5 3 6]
 [5 1 8 6 0 9 7 3 4 2]
 [3 8 5 7 2 6 4 0 1 9]]
tt_50sample [[2 3 1 5 8 4 0 7 9 6]
 [7 6 4 5 8 2 1 3 9 0]
 [6 0 9 1 5 4 3 8 2 7]
 [9 7 1 6 0 4 8 2 3 5]
 [0 4 3 7 9 8 6 5 2 1]
 [7 5 8 1 3 6 2 4 9 0]
 [1 2 8 0 4 3 7 6 9 5]
 [7 0 9 2 4 1 8 5 3 6]
 [5 1 8 6 0 9 7 3 4 2]
 [3 8 5 7 2 6 4 0 1 9]]
vm  [-0.7 -0.4 10.5 23.6 -1.8 -0.1 -0.1  0.  -1.  -0.2  3.4 -0.2 -0.3 -0.  -0.4 -1.  -0.7 -0.4 -0.2 -0.9 -0.8 -0.1  0.8 -0.1 -0.6  1.9 -0.3  0.2 -2.  -1.  -1.5 -0.  -0.6  4.1 -0.1 -0.   5.   4.5 17.6 -0.   2.4  1.2  0.8 -0.2 -0.2 -0.4  9.2 -0.2 -1.   7.8 -0.2 -0.2  0.1 -1.   3.3  0.1 -0.4  5.8 -1.3  6.7 -0.7 -0.3 -0.5 -0.2 -0.3  0.8 -0.1 -0.5  2.6 -0.4 -0.1  6.7 -0.4 -0.7  6.5 -0.4  0.   0.4 -0.3 -0.   8.6  0.4 -0.2  0.6  0.4  2.8 -2.1 -0.2 -0.2  0.2 -0.1 -0.2 -0.2 -0.3 -0.1 -0.3  0.4 -0.3 -0.1  0.5  0.9  6.2 -0.5 -0.3 -0.1 -0.5  1.2 -0.1  1.9 -1.6 -0.4 -0.3  0.1  1.5  2.1 -4.2 -0.4 -1.3 -0.1 -0.3  0.2  7.4 -0.1  0.3  0.  -0.5 -0.2  4.6 -2.1 -3.  -0.3 -0.2 -0.  -0.4 -4.5 -3.2  0.3  0.2 -0.2 -0.6 -0.4 -1.1 -0.3 -0.5 -0.   0.2 -0.3  0.4 -1.5 -0.2 -2.4  0.1  0.9  0.9  0.5 -0.2  0.6 -0.3  1.2 -0.1  0.4 -1.2  0.1 -0.2 -0.1 -0.5 -0.  -0.4 -0.5 -0.2 -0.1 -0.1  0.3  0.7 -0.2  1.9  0.9 -0.4 -1.5 -0.2 -0.8 -0.5  0.3 -1.1  0.4  0.  -0.6 -0.2  1.   2.8  0.3 -0.1 -0.2 -0.6  6.2  8.5  0.1 -0.4  0.1 -0.  -0.1 -0.2 -0.3 -0.2 -0.1  2.6 -0.1 -0.1  4.2  0.3 -0.6 -3.  -0.3  3.2 -0.6 -0.4  1.7 -0.7 -0.1 -0.3 -0.1 -0.1 -0.3 -0.6 -0.2 -1.6 -0.1  0.3  1.6 -0.2 -0.6 -0.8 -0.1  1.1  4.2 -2.3  0.8  1.6  1.  14.9 -0.1  4.1 -0.1 -0.  -1.3 -2.1 -0.5  0.5 -0.6 -0.  -2.3 -0.1 10.5 -0.1 -0.7 11. ]
vy_50sample [[0 9 7 2 1 8 5 3 6 4]
 [9 0 5 8 2 3 1 6 7 4]
 [1 5 6 2 3 0 4 4 8 7]
 [7 2 9 3 5 6 4 8 0 1]
 [0 2 5 8 4 6 3 7 9 1]
 [7 6 6 2 8 3 5 4 4 9]
 [7 2 3 8 1 6 9 4 0 5]
 [1 5 2 4 8 7 3 0 9 6]
 [1 2 4 6 8 9 0 5 3 7]
 [9 2 4 7 1 3 0 5 6 8]]
vt_50sample [[0 9 7 2 1 8 5 3 6 4]
 [9 0 5 8 2 3 1 6 7 4]
 [1 5 6 2 3 0 4 9 8 7]
 [2 7 9 3 5 6 4 8 0 1]
 [0 2 5 8 4 6 3 7 9 1]
 [7 1 6 2 8 3 5 4 0 9]
 [7 2 3 8 1 6 9 4 0 5]
 [1 5 2 4 8 7 3 0 9 6]
 [1 2 4 6 8 9 0 5 3 7]
 [9 2 4 7 1 3 0 5 6 8]]
Epoch 47810: Training cost= 0.2677, Training acc= 0.8606, Validation cost= 0.2020, Validation acc= 0.8607
Epoch 47820: Training cost= 0.1882, Training acc= 0.8607, Validation cost= 0.1786, Validation acc= 0.8607
Epoch 47830: Training cost= 0.2855, Training acc= 0.8607, Validation cost= 0.2819, Validation acc= 0.8607
Epoch 47840: Training cost= 0.2624, Training acc= 0.8607, Validation cost= 0.2477, Validation acc= 0.8607
Epoch 47850: Training cost= 0.3239, Training acc= 0.8607, Validation cost= 0.2475, Validation acc= 0.8607
Epoch 47860: Training cost= 0.2032, Training acc= 0.8607, Validation cost= 0.2236, Validation acc= 0.8608
Epoch 47870: Training cost= 0.2694, Training acc= 0.8607, Validation cost= 0.2632, Validation acc= 0.8608
Epoch 47880: Training cost= 0.2965, Training acc= 0.8607, Validation cost= 0.2061, Validation acc= 0.8608
Epoch 47890: Training cost= 0.2610, Training acc= 0.8607, Validation cost= 0.2623, Validation acc= 0.8608
Epoch 47900: Training cost= 0.2364, Training acc= 0.8607, Validation cost= 0.2271, Validation acc= 0.8608
tm  [-1.  -0.2  5.3 20.9 -1.2 -0.  -0.3  0.1  2.4 -0.4  6.8  0.4 -0.2  0.6 -2.2  3.9 -0.4 -0.   1.5 -0.9 -1.  -0.3 -1.  -0.2 -0.5  1.7 -0.3 -0.1  1.6 -3.4  0.4 -0.3  0.6  5.3 -0.1 -0.1 -0.7 -0.8  2.4 -0.2  0.2 -2.5 -1.7 -1.9 -0.  -0.1  6.7 -0.6  0.3 -3.3 -0.  -0.   0.7 -2.  -1.3  2.4 -0.1  3.7  8.3  3.  -0.9 -0.5  0.5 -0.1  0.8 -0.2 -0.   0.5  0.3 -0.2 -0.1 -2.3 -0.1  0.5 -0.9  0.5 -0.3 -0.3 -0.2 -0.1 20.7 -0.7 -0.1 -0.2 -0.5 -1.9 -1.8  0.7 -0.1 -0.1 -0.  -0.1  0.2 -1.8 -0.4  0.7 -0.5 -2.3 -0.2 -0.1  1.3 -1.2 -0.7 -0.1 -0.3 -0.1  0.8  0.3  2.  -1.7  0.4 -0.1 -0.1 -1.   2.2 14.7  0.9  1.  -0.1  0.1 -0.5  5.5 -0.2  1.  -0.2 -2.7 -0.   8.5  8.2 -0.1 -0.4 -0.  -0.2 -0.7  9.3 15.2  0.3 -0.  -0.  -0.5 -0.  -0.1 -0.3 -0.  -0.  -0.1 -0.5 -0.1 -0.  -0.3 -2.   0.2 -0.3 -0.2  0.  -0.1 -0.1 -0.3 -0.2  0.9 -0.5 -0.6 -0.1 -0.1 -0.1 -0.4 -0.3  1.4 -0.2 -0.1 -0.2 -0.  -0.  -0.6 -0.2  1.1 -1.1  0.  -0.2 -0.1 -0.2  0.6 -0.4 -1.9 -0.2 -0.1 -0.1 -0.5 -0.2  9.1 -0.2  0.4 -0.3 -0.9  8.6 -3.   0.1 -0.9 -0.2 -0.  -0.3 -0.  -0.4 -0.2 -0.3  3.2 -0.1 -0.  -0.7 -0.2 -0.2  6.9 -0.5  1.5 -0.8  0.8  7.3 -1.  -0.2  0.7 -0.1 -0.2  0.5 -1.1 -0.   2.6 -1.4  0.6  1.6  0.4  0.9 -0.6  0.8 -0.2 -1.3 -1.2 -0.4  0.9  2.2 15.7  0.6  4.3 -0.1 -0.3 -4.2 -2.7 -0.1  0.1 -1.6 -0.4 -5.3 -0.   1.3 -0.2  4.3  2.7]
ty_50sample [[9 3 3 1 2 7 5 8 4 0]
 [9 8 0 6 1 7 3 4 2 5]
 [8 1 1 4 6 5 9 9 7 2]
 [6 4 5 9 1 2 0 8 7 3]
 [4 3 5 0 7 9 2 8 8 6]
 [9 6 0 2 4 5 7 8 3 1]
 [8 1 9 7 4 3 5 2 0 6]
 [6 2 7 0 5 3 9 9 4 8]
 [6 3 5 2 8 0 7 4 1 9]
 [4 5 8 9 0 2 3 7 1 6]]
tt_50sample [[9 6 3 1 2 7 5 8 4 0]
 [8 9 0 6 1 7 3 4 2 5]
 [8 1 3 4 6 5 9 0 7 2]
 [4 6 5 9 1 2 0 8 7 3]
 [4 3 5 0 7 9 2 8 1 6]
 [9 6 0 2 4 5 7 8 3 1]
 [8 9 1 7 4 3 5 2 0 6]
 [6 2 7 0 5 3 1 9 4 8]
 [6 3 5 2 8 0 7 4 1 9]
 [4 5 8 9 0 2 3 7 1 6]]
vm  [ 1.2 -0.3  4.   4.9 -1.4 -0.  -0.4  0.2 -0.8 -0.  -1.3 -0.  -0.2 -0.3  1.9  3.  -0.1 -0.4  0.8 -1.7 -0.7 -0.2 -0.  -0.4 -0.8 -0.4 -0.  -0.1 -0.   6.8 -0.8 -0.3 -0.7 -1.1 -0.1 -0.3  0.4  5.5 16.9 -0.6 -0.6  5.8  3.   1.5 -0.3  0.5  6.2  0.7  4.7  9.6 -0.  -0.2 -0.3  1.1 -1.  -0.2 -0.2  5.4 -2.7  4.8 -1.9 -1.1 -0.7 -0.1 -0.8 -0.3  0.  -0.3  0.9 -0.2  0.4 -1.2 -0.2 -0.1 -1.1 -0.7 -0.1 -0.1 -0.  -0.4 -1.6 -0.4 -0.1 -0.3 -1.7  5.1  6.3 -0.2 -0.3 -0.2 -0.8 -0.2  0.   1.1 -0.9  0.3 -0.1 -1.1 -0.3 -0.2 -0.   3.4 -0.1 -0.3 -0.3 -0.1 -1.1 -0.3 -0.2 -2.  -0.  -0.1 -0.1 -0.1 -1.8  8.1 -0.2 -0.9 -0.2 -0.3 -0.   7.3 -0.2 -1.1 -0.3  2.4 -0.2  1.2 -2.1 -1.5  0.6 -0.5 -0.  -0.2 -5.3 -6.5 -0.4 -0.2  0.2 -0.4 -0.7 -0.2 -0.1 -0.1 -0.1 -0.3 -0.4 -0.2  3.9 -0.1 -0.4 -0.3  3.6  0.3 -0.   0.  -0.2  1.9  0.9 -0.3 -0.2 -1.3 -0.1 -0.1 -0.4  1.7  0.  -0.7 -0.2 -0.2 -0.  -0.2 -0.2 -0.4 -0.1 -0.4  1.5 -0.6 -1.9 -0.2 -3.  -0.2 -0.3 -0.5 -0.1 -0.2 -0.2 -0.5 -0.1 -1.7 -0.2 -0.2 -0.3 -0.6 15.3  8.3 -0.1  5.8 -0.2 -0.1 -0.1  0.1 -0.6 -0.3  0.2 -0.3 -0.2 -0.2 -0.3 -0.2 -0.7 -0.  -0.2 -2.2  0.7 -0.1 -1.2 -0.2 -0.1 -0.5 -0.2 -0.3 -0.  -1.1 -0.9  4.  -0.8 -0.5 -0.4  2.7 -1.   0.5 -0.3 -0.3 -1.3 -0.6 -0.6 -0.2 -0.2 -1.7 -0.3 -0.8 -0.4 -0.3  5.9 -0.9  0.2 -0.4 -0.6 -0.3  2.7 -0.1  9.7 -0.2 -0.4  7. ]
vy_50sample [[5 8 7 2 9 4 3 0 6 1]
 [6 8 7 1 2 3 4 5 9 0]
 [2 0 5 9 8 3 7 6 4 1]
 [8 9 0 7 6 5 4 3 2 1]
 [8 3 9 7 1 5 6 0 4 2]
 [9 2 4 0 7 6 1 8 8 5]
 [8 1 7 5 3 2 6 0 4 9]
 [6 3 9 1 8 7 4 0 5 2]
 [9 7 3 6 8 1 2 0 4 5]
 [2 1 0 4 8 6 9 5 7 3]]
vt_50sample [[5 8 7 9 2 4 3 0 6 1]
 [6 8 7 1 2 3 4 5 9 0]
 [2 0 5 9 8 3 7 6 4 1]
 [8 9 0 7 6 5 4 3 2 1]
 [8 3 9 7 1 5 6 0 4 2]
 [9 2 4 0 7 6 1 8 3 5]
 [8 1 7 5 3 2 6 0 4 9]
 [6 3 9 1 8 7 4 0 5 2]
 [9 7 3 6 8 1 2 0 4 5]
 [2 1 0 4 8 6 9 5 7 3]]
Epoch 47910: Training cost= 0.2473, Training acc= 0.8607, Validation cost= 0.1981, Validation acc= 0.8608
Epoch 47920: Training cost= 0.2838, Training acc= 0.8607, Validation cost= 0.2903, Validation acc= 0.8608
Epoch 47930: Training cost= 0.2210, Training acc= 0.8608, Validation cost= 0.2699, Validation acc= 0.8608
Epoch 47940: Training cost= 0.2408, Training acc= 0.8608, Validation cost= 0.1926, Validation acc= 0.8608
Epoch 47950: Training cost= 0.2895, Training acc= 0.8608, Validation cost= 0.2465, Validation acc= 0.8608
Epoch 47960: Training cost= 0.2765, Training acc= 0.8608, Validation cost= 0.2341, Validation acc= 0.8609
Epoch 47970: Training cost= 0.2349, Training acc= 0.8608, Validation cost= 0.2581, Validation acc= 0.8609
Epoch 47980: Training cost= 0.2540, Training acc= 0.8608, Validation cost= 0.2526, Validation acc= 0.8609
Epoch 47990: Training cost= 0.2105, Training acc= 0.8608, Validation cost= 0.2192, Validation acc= 0.8609
Epoch 48000: Training cost= 0.2510, Training acc= 0.8608, Validation cost= 0.2455, Validation acc= 0.8609
tm  [-0.3  0.1 -2.7 -0.4 -1.3 -0.3 -0.3 -0.  -0.1 -0.5 -2.6 -0.4 -0.  -0.1 -1.1  4.  -0.3 -0.3 -0.7 -0.  -1.3 -0.3 -0.  -0.2 -1.2  2.5 -0.1 -0.2  1.2 -0.9 -0.3 -0.2 -0.9 -5.2 -0.3 -0.1 -0.5 -0.4 -0.6 -0.2 -0.5 -1.5 -0.4 -0.3  0.   0.3 -0.6 -0.3  6.6  6.3 -0.   0.2 -0.2  2.2 -1.   0.2  0.6 -1.3  3.4  3.8 -0.3 -0.6 -0.1 -0.  -0.7 -0.1 -0.  -0.3 -0.6 -0.  -0.1 -1.2  0.   2.  -2.5 -0.7 -0.2 -0.2 -0.1 -0.4 -3.  -0.2 -0.  -0.3 -1.3 -1.1  5.   0.2 -0.1 -0.   1.8 -0.1 -0.2 -1.4 -0.7 -0.1 -0.5 -3.1  0.8  0.1  1.1 -1.7 -0.6 -0.1 -0.1 -0.2 -0.8 -0.4 -0.7 -0.9 -0.5 -0.1 -0.  -0.7 -0.1 14.2 -1.5 -0.2 -0.2 -0.5 -0.1  2.4  0.1 -0.5 -0.1 -1.3  0.   0.7  3.7  2.3  1.7 -0.4 -0.3 -0.4 11.7 -1.6  0.1 -0.1  0.8  1.3  1.  -0.5 -0.5 -0.  -0.1 -0.  -0.4 -0.2  4.3 -0.2 -0.1  0.1  3.3 -0.2  0.2 -0.  -0.6 -0.6 -0.4 -0.  -0.3  0.5 -0.1 -0.2 -0.1 -0.3 -0.1 -0.1  0.6 -0.   0.1 -0.2 -0.3 -0.2 -0.1 -0.3 -0.5 -0.3  0.7 -0.1 -0.5 -0.4 -0.4 -2.5 -0.2 -0.2 -0.1 -0.2 -0.3  2.9 -0.1 -0.4 -0.1 -0.7  5.9 -1.4 -0.1  0.  -0.3 -0.1 -0.4 -0.  -0.4 -0.3 -0.  -1.4 -0.2 -0.1  8.1  0.5 -0.4  4.9 -0.8 -0.3 -1.3 -0.6  0.6 -1.1 -0.8  0.8 -0.1 -0.  -0.1 -1.6  1.9  4.7 -0.9  1.4 -0.8  3.7 -0.4 -1.1 -0.   1.8 -0.7  4.  -0.3  0.2  6.2  3.5  0.3  0.5  0.1 -0.1 10.1 -0.5 -0.6 -0.1 -1.5 -0.2  6.8 -0.2 -0.2 -0.5  3.7  0.4]
ty_50sample [[8 6 4 3 2 9 5 1 7 0]
 [0 3 2 4 5 9 8 1 6 7]
 [2 8 5 3 6 1 4 9 7 0]
 [3 2 1 0 4 5 6 9 8 7]
 [7 4 1 8 2 3 5 9 6 0]
 [2 8 4 6 1 5 3 7 7 9]
 [9 6 8 4 0 2 2 3 7 5]
 [1 4 6 2 8 9 5 3 7 0]
 [7 8 9 3 2 0 1 5 6 4]
 [4 0 5 1 3 9 7 8 6 2]]
tt_50sample [[8 6 4 3 2 9 5 1 0 7]
 [0 3 2 4 5 9 8 1 6 7]
 [2 8 5 3 6 1 4 9 7 0]
 [3 2 1 0 4 5 6 9 8 7]
 [7 4 1 8 2 3 5 6 9 0]
 [2 8 4 6 1 5 3 7 0 9]
 [9 8 6 4 0 1 2 3 7 5]
 [1 4 6 2 8 9 5 3 7 0]
 [7 8 9 3 2 0 1 5 6 4]
 [0 4 5 1 3 9 7 8 6 2]]
vm  [-1.2 -0.3 -2.4 -3.5 -1.8 -0.3 -0.1 -0.  -0.5 -0.7 -3.6 -0.2 -0.1 -0.3  2.4  2.8  0.6 -0.4 -0.  -1.1 -1.1 -0.5 -0.4 -0.5 -1.1 -0.1 -0.  -0.   1.   5.5  2.  -0.2 -1.1 -2.1 -0.1 -0.  -0.2  2.1 10.1  0.2 -0.4  5.3  0.6  5.  -0.2  0.6  1.1 -0.1 -0.2 13.2 -0.1 -0.1 -0.8 -0.1 -1.1 -0.3 -0.3 -1.4 -0.9 -0.5  0.8 -0.4 -0.8 -0.3 -1.3  0.2  0.2 -0.6  1.4  0.1 -0.1 -1.8 -0.3  1.3 -2.7  0.3 -0.2 -0.  -0.3 -0.4 -2.9 -0.6 -0.5 -0.6 -0.2  6.7  5.1 -0.1 -0.2 -0.  -0.5 -0.1 -0.1 -0.4 -0.8 -0.3 -0.  -2.5 -0.5  0.4  1.5  5.6 -0.2 -0.4 -0.3 -0.1 -1.4  1.  -0.7 -1.5 -0.2 -0.4 -0.2 -0.7 -0.9 14.5 -0.  -0.4  0.3 -0.2  0.2  5.8 -0.  -0.3 -0.2  3.1  0.2  2.7 -0.5 -1.7 -0.4 -0.5 -0.4 -0.6 -3.6 -5.5 -0.4  0.9 -0.4 -0.   0.8 -0.2  1.3 -0.2 -0.2 -0.2 -0.6 -0.3  2.6 -0.4  3.  -0.   1.3  0.8  0.  -0.2 -0.1  0.2  2.2 -0.3 -0.1 -1.1 -0.4 -0.1 -0.4 -0.2 -0.2 -0.1 -0.2 -0.3 -0.1 -0.1 -0.1 -0.3 -0.1 -0.1  1.3 -0.4 -1.  -0.3 -1.8  1.6 -0.1 -1.4 -0.1 -0.  -0.4 -0.5 -0.  -1.2 -0.2 -0.1 -0.1 -0.7  2.6  1.9 -0.2  2.6 -0.3 -0.2  0.  -0.1 -0.  -0.1  0.1 -1.2 -0.2 -0.4  4.3  0.3 -0.1  4.  -0.3  3.   0.9 -0.  -2.8 -0.5  0.2 -0.6  0.3 -0.2 -0.6 -1.   2.3  5.  -1.4 -0.6 -0.5  0.9 -0.9 -0.2 -0.2  1.3 -0.9  3.1 -0.6 -0.3  1.5 -0.8 -0.2 -0.4 -0.4 -0.1  9.7 -0.1 -0.5 -0.1 -0.9 -0.7  7.4 -0.1  6.2 -0.5 -0.5  8.2]
vy_50sample [[4 8 5 7 1 9 2 6 3 0]
 [8 2 3 7 5 4 6 1 0 9]
 [5 6 7 2 9 1 4 0 8 3]
 [0 8 4 2 6 7 3 9 1 5]
 [9 0 6 3 5 8 7 2 1 4]
 [4 6 6 2 0 5 7 7 8 1]
 [8 0 7 3 4 6 2 9 1 5]
 [1 3 7 6 4 0 5 2 9 8]
 [4 8 5 6 6 1 0 3 2 7]
 [4 6 8 9 3 5 2 7 1 0]]
vt_50sample [[4 8 5 7 9 1 2 6 3 0]
 [8 2 3 7 5 4 6 1 0 9]
 [5 6 7 2 9 1 0 4 8 3]
 [0 4 8 2 6 3 7 9 1 5]
 [9 0 6 3 5 8 7 2 1 4]
 [4 6 3 2 0 5 7 9 8 1]
 [8 0 7 3 4 6 2 9 1 5]
 [1 3 7 6 4 5 0 2 9 8]
 [4 8 5 9 6 1 0 3 2 7]
 [4 6 8 9 3 5 2 7 1 0]]
Epoch 48010: Training cost= 0.2515, Training acc= 0.8608, Validation cost= 0.2283, Validation acc= 0.8609
Epoch 48020: Training cost= 0.2256, Training acc= 0.8608, Validation cost= 0.2411, Validation acc= 0.8609
Epoch 48030: Training cost= 0.2128, Training acc= 0.8609, Validation cost= 0.2429, Validation acc= 0.8609
Epoch 48040: Training cost= 0.2540, Training acc= 0.8609, Validation cost= 0.2453, Validation acc= 0.8609
Epoch 48050: Training cost= 0.2932, Training acc= 0.8609, Validation cost= 0.2617, Validation acc= 0.8609
Epoch 48060: Training cost= 0.2697, Training acc= 0.8609, Validation cost= 0.2045, Validation acc= 0.8609
Epoch 48070: Training cost= 0.2119, Training acc= 0.8609, Validation cost= 0.2242, Validation acc= 0.8610
Epoch 48080: Training cost= 0.2575, Training acc= 0.8609, Validation cost= 0.1892, Validation acc= 0.8610
Epoch 48090: Training cost= 0.2448, Training acc= 0.8609, Validation cost= 0.2332, Validation acc= 0.8610
Epoch 48100: Training cost= 0.2911, Training acc= 0.8609, Validation cost= 0.2506, Validation acc= 0.8610
tm  [-0.4 -0.4  9.  12.7 -1.9 -0.4 -0.1  0.2 -1.2 -0.2 -5.4 -0.  -0.  -0.4  2.2 -1.1 -0.  -0.1 -0.5 -0.9 -0.9 -0.1  0.7  0.8 -1.4  3.2 -0.2 -0.6 -0.7 11.2 -1.  -0.  -0.7  2.1  0.   0.6  2.2 -1.7  2.4 -0.4  2.   3.5  5.6 -0.4 -0.1 -0.4  6.  -0.3  0.5 12.  -0.5 -0.2 -0.2 -2.4 -0.9 -0.2 -0.2  2.  -3.5  6.3 -1.2 -0.3 -0.4 -0.6 -1.  -0.3 -0.  -0.1  0.9 -0.3 -0.4  0.2  0.4 -0.6  0.8  1.4  0.1  1.8 -0.2 -0.3 -0.4  1.3 -0.4  0.2 -1.1  5.8 -0.1 -0.2  0.1 -0.3 -0.3 -0.1 -0.3  1.2 -0.9 -0.5  1.5 -0.8 -0.6 -0.4 -0.2  8.2 -0.2  0.4 -0.4 -0.2 -0.2 -0.4 -1.5 -0.9 -0.5 -0.2 -0.2  1.7 -0.9 -0.7 -0.1 -1.4 -0.1 -0.4  0.9  3.5 -0.4 -0.6 -0.2  3.2 -0.2  9.6 -4.3 -2.5  0.  -0.2 -0.6  0.8 -1.1 -0.6 -0.3 -0.3 -0.6 -0.1  1.2 -0.9  1.5 -0.1  0.1 -0.1  0.1 -0.2 -1.5 -0.2 -1.5 -0.3  1.7  2.9 -0.3 -0.  -0.4 -0.4 -1.  -0.   2.1 -0.  -0.4 -0.1 -0.4 -1.2 -0.8 -0.7 -0.3 -0.  -0.1 -0.1 -0.2 -0.1 -0.2  1.4 -0.9  1.  -0.1 -0.1 -0.4 -0.5 -0.3 -2.  -0.2 -0.3 -0.1 -0.3 -0.3 -3.1  0.3 -0.2 -0.5 -0.6  8.7 16.1  0.5  1.7  0.6 -0.2 -0.  -0.  -0.   0.3 -0.3  3.8 -0.2 -0.1  7.9 -0.3 -0.4 -0.6 -0.5  1.9 -0.8  0.9  3.1  0.5  0.4 -0.5 -0.  -0.3 -0.4 -0.7  5.4  0.2 -2.1 -1.3  1.9 -0.3 -0.1 -0.8 -0.2  1.2 -0.8 -1.6 -0.4 -0.  -0.5 13.8 -0.2  3.6 -0.2 -0.1  2.9 -2.8 -0.6 -0.7 -0.6 -1.   0.2 -0.1  1.2 -0.2  2.1  9.3]
ty_50sample [[7 8 9 6 0 5 1 4 2 3]
 [1 3 4 2 8 0 9 5 6 7]
 [0 8 9 2 7 3 6 5 1 4]
 [4 2 9 0 8 7 3 6 5 1]
 [1 9 7 8 5 0 2 6 3 4]
 [9 4 2 3 8 7 6 1 0 5]
 [5 4 1 7 2 9 0 3 8 6]
 [9 7 0 0 5 5 3 1 8 2]
 [0 3 2 9 1 6 4 8 8 7]
 [3 5 9 4 8 0 6 7 2 1]]
tt_50sample [[7 8 6 9 0 5 1 4 2 3]
 [1 3 4 2 0 8 9 5 6 7]
 [0 8 9 2 7 3 6 5 1 4]
 [4 2 9 0 8 7 3 6 5 1]
 [1 9 7 8 5 0 2 6 3 4]
 [9 4 2 3 8 7 6 1 0 5]
 [5 4 1 7 2 0 9 3 8 6]
 [7 9 0 4 6 5 3 1 8 2]
 [0 3 2 9 1 6 4 8 5 7]
 [3 5 9 4 0 8 6 7 2 1]]
vm  [-1.  -0.3 -3.1  1.  -1.5  0.6  0.4 -0.1 -0.6 -0.   7.2 -0.3 -0.4 -0.4 -2.3 -1.2 -0.3 -0.5 -0.1 -0.9 -1.2 -0.4 -0.7 -0.2 -0.7  1.3 -0.2  1.1 -1.4 -2.   4.5 -0.3 -1.1  8.6 -0.1 -0.2  1.5 -0.4 12.2 -0.1 -0.8 -2.  -1.3  1.3 -0.4 -0.8  7.4 -0.3 -1.6 -2.4 -0.4  0.2  0.8 -2.5 -0.8  2.  -0.2 -3.   4.4 -4.3  1.5 -0.4  0.1 -0.7  0.4 -0.6 -0.3 -0.   0.9 -0.5 -0.2  1.3  0.8 -0.3 -0.3 -0.  -0.4 -0.1 -0.2 -0.4 26.6 -0.2 -0.1 -0.5  0.2 -1.3  0.  -0.4 -0.1 -0.3 -0.2 -0.2 -0.2 -0.5 -0.8 -0.  -0.6 -1.3  0.3 -0.5 -0.2 -0.4  0.1 -0.3 -0.2  0.3 -0.2  2.2  1.6 -1.6  1.   0.  -0.  -0.1  5.1 -1.2 -0.5 -0.  -0.  -0.1 -0.1  5.7 -0.3 -0.3 -0.3 -2.8  0.5  9.4  0.7 -2.3  1.5 -0.1 -0.4 -0.1  4.4 11.2 -0.2 -0.3  2.5 -0.6  1.1 -0.7 -0.2 -0.1 -0.1  0.6 -0.3 -0.2 -0.8 -0.3 -0.4 -0.3 -2.2  1.9 -0.3 -0.  -0.6 -0.5 -0.5  1.6 -0.4 -0.7 -0.1 -0.1 -0.3  1.3  0.1  1.1 -0.2 -0.2 -0.2 -0.2 -0.2 -0.4 -0.2  2.6 -0.1  0.1 -1.  -0.1  1.1 -0.1  0.5 -1.9 -0.1 -0.1 -0.2 -0.4  0.2  5.6 -0.3 -0.2 -0.3 -1.3  0.  -0.3 -0.1 -1.4 -0.4 -0.  -0.5 -0.1 -0.8 -0.2 -0.5  4.7 -0.  -0.2 -0.7 -0.2 -0.6 -1.2 -0.9  7.1  0.6 -0.1 -1.2 -1.1 -0.5  0.8 -0.3 -0.2 -0.9 -1.   1.7 -1.3 -2.1 -0.1  0.3 -0.9 -0.7 -0.7 -0.7 -0.5 -0.1  4.2 -0.1 -0.3  0.  22.1 -0.2  5.4 -0.1 -0.  -5.7 -2.7 -0.4 -0.4 -1.1  1.8 -6.8 -0.2  6.7 -0.   4.1  9. ]
vy_50sample [[1 4 9 0 6 3 7 2 5 8]
 [9 5 7 8 4 0 2 3 6 1]
 [7 2 4 6 1 5 0 0 3 8]
 [8 7 1 9 3 5 2 4 0 6]
 [5 9 0 7 6 3 1 8 8 2]
 [4 1 6 7 2 0 9 9 3 8]
 [3 5 8 1 2 0 6 7 9 4]
 [2 6 1 9 0 3 5 4 8 7]
 [3 6 9 0 8 1 4 5 2 7]
 [6 3 0 9 1 4 7 5 8 2]]
vt_50sample [[1 4 9 0 6 3 2 7 5 8]
 [9 5 4 7 8 0 2 3 6 1]
 [7 2 4 6 1 5 9 0 3 8]
 [8 7 1 9 3 5 2 4 0 6]
 [5 9 0 7 6 3 1 8 4 2]
 [4 1 6 7 2 0 9 5 3 8]
 [3 5 8 1 2 0 6 7 9 4]
 [2 1 6 9 0 3 5 8 4 7]
 [3 6 9 0 8 1 4 5 2 7]
 [6 3 9 0 1 4 7 5 8 2]]
Epoch 48110: Training cost= 0.2142, Training acc= 0.8609, Validation cost= 0.2206, Validation acc= 0.8610
Epoch 48120: Training cost= 0.2415, Training acc= 0.8609, Validation cost= 0.1932, Validation acc= 0.8610
Epoch 48130: Training cost= 0.2930, Training acc= 0.8609, Validation cost= 0.3020, Validation acc= 0.8610
Epoch 48140: Training cost= 0.2787, Training acc= 0.8610, Validation cost= 0.2271, Validation acc= 0.8610
Epoch 48150: Training cost= 0.2412, Training acc= 0.8610, Validation cost= 0.3401, Validation acc= 0.8610
Epoch 48160: Training cost= 0.1934, Training acc= 0.8610, Validation cost= 0.2734, Validation acc= 0.8610
Epoch 48170: Training cost= 0.2298, Training acc= 0.8610, Validation cost= 0.2703, Validation acc= 0.8610
Epoch 48180: Training cost= 0.2364, Training acc= 0.8610, Validation cost= 0.2959, Validation acc= 0.8611
Epoch 48190: Training cost= 0.2789, Training acc= 0.8610, Validation cost= 0.2723, Validation acc= 0.8611
Epoch 48200: Training cost= 0.2771, Training acc= 0.8610, Validation cost= 0.2087, Validation acc= 0.8611
tm  [-0.1 -0.5  8.6  7.6 -1.7 -0.1 -0.1 -0.1 -0.7 -0.2 -2.6 -0.2 -0.1 -0.2  6.1 -0.1 -0.4  0.9 -0.4 -1.  -1.6 -0.1 -0.3 -0.1 -0.8 -0.1 -0.1 -0.5 -0.7 -0.8 -0.7 -0.3  0.2  4.1 -0.1 -0.3  3.   5.7 15.3 -0.8  2.9 -3.2 -0.   2.4 -0.2 -0.1  4.2 -0.4  3.2 -0.4 -0.3 -0.2 -0.6 -0.7 -0.8 -0.7 -0.5 -1.3 -0.1  4.8 -0.6 -0.1 -0.3 -0.2 -1.  -0.5 -0.3 -0.3  1.1 -0.2 -0.1  0.5 -0.2 -0.3 -1.3  0.8 -0.4 -0.3 -0.3  1.6 -1.4  0.  -0.1  1.6 -1.2 -2.9  2.1  0.5 -0.3 -0.5 -0.  -0.  -0.4 -0.3 -0.1 -0.2 -0.2 -1.6 -0.2 -0.5  1.2  2.7 -0.6 -0.1 -0.  -0.5 -1.1 -0.2 -0.8 -1.5 -0.6 -0.2 -0.3  0.2  0.8 -1.2 -0.2 -0.6  0.6 -0.9  0.5  4.2 -0.3 -0.4 -0.3  7.5 -0.3  4.2 -0.4  6.2 -0.3 -0.2 -0.1 -0.3 -7.  -5.9 -0.1 -0.1 -0.1 -0.  -0.7 -0.6 -0.8 -0.4 -0.1  0.1 -0.2 -0.1 -2.8 -0.3 -1.  -0.1  2.9 -1.  -0.3  0.  -0.2 -0.5  3.8 -0.1  1.4 -1.7 -0.   0.5 -0.1 -0.2 -0.1 -0.3 -0.4  0.1 -0.1 -0.2 -0.1 -0.1 -0.2  4.2  1.1 -0.2 -1.4 -0.1  0.5 -0.6 -0.2 -0.8 -0.1 -0.7  1.2 -0.3 -0.1  2.6 -0.  -0.4 -0.3 -0.7  6.8  1.6 -0.5 -0.3  0.2 -0.1 -0.1 -0.3 -0.1 -0.4 -0.5 -1.1 -0.1 -0.2  9.3 -0.  -0.6 -0.7 -0.8 -0.9 -0.5 -0.3 -1.5 -0.7 -0.3  0.7 -0.  -0.3 -0.5 -1.  -2.8  0.7 -0.3  0.2  2.4  2.3 -0.3  0.5 -0.3  1.6 -0.4 -1.8  1.3 -0.3  1.4 14.6 -0.   4.1 -0.2 -0.2  5.3 -1.4 -0.4 -0.1 -0.8 -0.5  2.7  0.1  9.   0.6  3.1 -1.1]
ty_50sample [[7 3 8 0 9 2 4 1 5 6]
 [5 2 7 7 6 6 9 3 0 1]
 [5 2 9 7 0 8 4 3 1 6]
 [6 0 8 5 4 9 2 1 7 3]
 [1 6 7 3 4 5 8 2 0 9]
 [2 7 1 9 4 6 3 0 5 8]
 [1 9 9 6 4 4 8 3 7 5]
 [8 7 2 6 0 1 3 5 9 4]
 [9 7 2 5 3 6 8 8 4 1]
 [5 6 0 8 2 9 4 7 1 3]]
tt_50sample [[7 3 8 0 9 2 4 1 5 6]
 [5 2 7 8 4 6 9 3 0 1]
 [5 2 9 7 0 8 4 3 1 6]
 [6 0 8 5 4 9 2 1 7 3]
 [1 6 7 3 4 5 8 2 0 9]
 [2 7 1 9 6 4 3 0 5 8]
 [1 9 2 6 0 4 8 3 7 5]
 [8 7 6 2 0 1 3 5 9 4]
 [9 7 5 2 3 6 8 0 4 1]
 [5 6 8 2 0 9 4 7 1 3]]
vm  [-1.2 -0.3  5.1  0.  -1.7 -0.3 -0.3 -0.1  0.4 -0.8 -1.9 -0.5 -0.  -0.2  5.9 -1.  -0.2 -0.4  1.3 -0.3 -1.3 -0.2  1.8 -0.1 -1.3  3.4 -0.5 -0.1 -0.5 -2.   2.3 -0.1 -0.4  9.2 -0.2 -0.2 -0.1 -1.2 -0.6 -0.3  0.5  5.1 -0.6 -0.3 -0.1 -0.1 -0.3  0.2 -0.9  3.9 -0.6 -0.  -0.4 -1.5 -0.2 -0.8 -1.   5.3  7.5 -0.5  4.5 -0.  -0.3  0.3  0.  -0.1 -0.1 -0.2  1.5  0.6 -0.2  0.4 -0.2 -0.1 -2.4  0.8 -0.2 -0.1 -0.   0.4  3.9 -0.2 -0.1  1.2  1.6  7.1 -1.5  0.1 -0.3 -0.  -0.3 -0.1 -0.3 -1.6 -0.7 -0.1  2.1 -3.3 -0.9 -0.3  3.5  6.4 -0.2 -0.1 -0.3  0.2 -1.5 -0.  -0.6 -0.8 -0.7  0.3 -0.2 -0.7  6.1  1.8  0.   0.3 -0.1 -0.3 -0.5  3.   0.9  0.2 -0.1  7.3 -0.2  7.3  8.7 -0.7 -0.4 -0.3 -0.3 -1.  -1.5  7.  -0.1 -0.2 -0.4 -0.1  2.  -0.5  0.2 -0.1 -0.2 -0.1  0.  -0.1  0.8 -0.2 -0.  -0.2 -0.7 -0.3 -0.1 -0.1 -0.3 -0.3  0.6 -0.4  0.  -0.2 -0.  -0.1 -0.2 -0.6 -0.2 -0.1 -0.3 -0.1 -0.  -0.1 -0.2 -0.3 -0.2  0.  -0.7 -0.1  1.8  0.1 -1.6 -0.4 -0.4 -2.1 -0.2 -0.2 -0.4 -0.5 -0.1  5.8 -0.1 -0.2 -0.3 -0.7 -1.4 -2.7 -0.3 -1.6  0.3 -0.1  0.3 -0.1 -0.2 -0.2 -0.2 -2.3  0.1 -0.1 -2.7  0.2 -0.4 -0.2 -0.3  6.1 -1.  -0.4  0.9 -1.   0.3 -0.7 -0.2 -0.1 -0.2 -1.2  3.1 -0.3 -1.6 -0.1  0.3  0.9 -0.5 -0.5 -0.2 -1.   0.7 -1.2 -0.3 -0.   3.9 -2.2  0.2 -0.7 -0.  -0.2 -0.1 -0.1 -0.1 -0.2 -1.2 -0.2 -1.  -0.1 -0.4 -0.2  3.4  4.8]
vy_50sample [[1 1 5 0 6 4 9 8 3 2]
 [6 9 3 1 5 4 7 8 2 0]
 [4 8 5 0 2 9 1 7 6 3]
 [0 4 6 8 2 5 9 3 1 7]
 [2 9 7 3 1 0 6 5 8 4]
 [5 7 9 8 2 6 1 4 0 3]
 [4 8 5 0 2 3 7 6 9 1]
 [2 2 7 4 8 9 0 5 1 6]
 [0 5 3 6 8 7 7 4 1 9]
 [1 7 8 3 4 2 0 9 6 5]]
vt_50sample [[5 1 7 0 6 4 9 8 3 2]
 [6 9 3 1 5 7 4 8 2 0]
 [4 8 5 0 2 9 1 7 6 3]
 [0 4 8 6 2 5 9 3 1 7]
 [2 9 7 3 1 0 5 6 8 4]
 [5 7 9 8 2 6 1 4 0 3]
 [4 8 5 0 2 3 7 6 1 9]
 [2 3 7 4 8 9 0 5 1 6]
 [0 5 3 6 8 2 7 4 1 9]
 [1 7 8 3 4 2 0 9 6 5]]
Epoch 48210: Training cost= 0.2593, Training acc= 0.8610, Validation cost= 0.2375, Validation acc= 0.8611
Epoch 48220: Training cost= 0.2455, Training acc= 0.8610, Validation cost= 0.2180, Validation acc= 0.8611
Epoch 48230: Training cost= 0.2908, Training acc= 0.8610, Validation cost= 0.2526, Validation acc= 0.8611
Epoch 48240: Training cost= 0.2509, Training acc= 0.8610, Validation cost= 0.2067, Validation acc= 0.8611
Epoch 48250: Training cost= 0.2657, Training acc= 0.8610, Validation cost= 0.2510, Validation acc= 0.8611
Epoch 48260: Training cost= 0.3209, Training acc= 0.8611, Validation cost= 0.2782, Validation acc= 0.8611
Epoch 48270: Training cost= 0.2320, Training acc= 0.8611, Validation cost= 0.2928, Validation acc= 0.8611
Epoch 48280: Training cost= 0.2243, Training acc= 0.8611, Validation cost= 0.2326, Validation acc= 0.8611
Epoch 48290: Training cost= 0.2024, Training acc= 0.8611, Validation cost= 0.2420, Validation acc= 0.8611
Epoch 48300: Training cost= 0.2462, Training acc= 0.8611, Validation cost= 0.2304, Validation acc= 0.8612
tm  [ 0.9  0.3 -2.5  1.1 -0.7 -0.1 -0.1 -0.1 -0.4 -0.3 10.6 -0.1 -0.1 -0.2 -2.1  1.5 -0.1 -0.3 -0.8 -1.8 -1.4 -0.4 -0.7 -0.3 -0.6 -0.  -0.2 -0.  -0.6 -0.7  4.4 -0.5 -0.1 11.5 -0.2  0.4  0.9  4.1 15.2 -0.1  1.  -3.6 -0.5  3.1 -0.1  0.  10.2  0.2  4.9 -4.9 -0.3 -0.1 -0.1 -0.6 -0.9  1.9 -0.4 -3.5  1.9 -4.7 -2.9 -0.3 -0.1 -0.3 -0.1 -0.5  0.7 -0.1 -0.6 -0.1 -0.1 -0.1 -0.5 -0.   1.5  0.9 -0.   1.5  0.1 -0.3 30.3 -0.1 -0.2 -0.4 -1.7 -3.1 10.9 -0.2 -0.  -0.2 -0.7 -0.1  0.6  1.7 -0.6  0.2  0.3 -0.5 -0.   0.2  1.5 -1.2 -0.  -0.  -0.4 -0.2 -0.5 -0.2 -0.4 -2.9 -0.3 -0.3 -0.1 -0.7  1.8  0.9  2.1 -0.  -0.4 -0.3  0.5 10.3 -0.2 -0.2 -0.4 -2.7 -0.1  3.8  0.7  1.2 -0.2 -0.1 -0.2 -0.1 -1.1  9.  -0.2 -0.2 -0.4 -0.5 -1.   1.1 -0.1  0.1 -0.  -0.2 -0.4 -0.2 -1.1 -0.1 -0.5 -0.3  1.4 -0.4  0.1  0.4 -0.1 -0.4 -0.  -0.8 -0.  -0.7 -0.3 -0.4  0.1  2.2 -0.5 -0.5 -0.  -0.3  0.3  0.2 -0.4 -0.6 -0.1  3.3 -0.5 -0.6 -1.4 -0.  -0.1 -0.3 -0.2 -0.9  0.1 -0.2 -0.2 -0.8 -0.2  2.5 -0.3 -0.1 -0.3 -0.8 19.7 -0.6  0.2 -0.5 -0.1 -0.2  0.2  0.1 -0.1 -0.5  0.3  2.8 -0.1  0.3  0.   0.3 -0.7 -0.5 -0.2 -1.8  2.9  2.7 -1.9 -1.2 -0.1 -0.4  0.2 -0.2 -0.7 -0.9 -1.4 -0.7 -0.4 -0.7 -0.1  1.6 -0.9 -0.5 -0.1  0.6 -0.5  4.5 -0.3 -0.  -0.1 27.8 -0.2  7.1 -0.1 -0.2 -6.6 -2.1 -0.4 -0.5 -1.2 -0.6 -7.8 -0.1  9.4 -0.4  2.2  0.8]
ty_50sample [[4 9 3 2 0 7 6 5 8 1]
 [1 4 2 0 5 3 7 8 6 9]
 [2 9 7 4 8 3 0 5 6 1]
 [0 2 4 8 5 1 3 6 7 9]
 [4 1 0 5 2 8 3 9 6 7]
 [6 9 1 2 3 0 7 5 8 4]
 [5 8 4 6 7 1 9 2 3 0]
 [1 2 4 7 9 0 5 8 3 6]
 [8 4 3 5 7 1 6 9 2 0]
 [8 1 9 2 5 6 0 7 3 4]]
tt_50sample [[4 9 3 2 0 7 6 5 1 8]
 [1 4 2 0 5 3 7 8 6 9]
 [2 9 7 4 8 3 0 5 6 1]
 [0 2 4 8 5 1 3 6 7 9]
 [4 1 0 5 2 8 3 9 6 7]
 [6 9 1 2 3 0 5 7 8 4]
 [5 8 4 6 7 9 1 2 3 0]
 [1 2 4 7 9 0 5 8 3 6]
 [8 4 3 5 7 1 6 9 2 0]
 [8 1 9 2 5 6 0 7 3 4]]
vm  [-0.5 -0.   6.9 21.3 -1.8 -0.3 -0.  -0.  -0.8 -1.  -1.2 -0.  -0.2 -0.4 -1.8 -0.5 -0.1 -0.2  1.  -0.4 -1.  -0.3 -0.2 -0.1 -0.8  2.6 -0.2 -0.2 -0.5  1.9 -0.6 -0.4 -0.6  2.2 -0.1 -0.1  1.4 -1.5  4.6  0.3 -0.2  4.5  4.  -1.4 -0.1 -0.2  5.3  0.1  4.5 -1.  -0.3 -0.1  1.8 -2.7 -0.8  1.9 -0.4 12.3 -2.3  5.  -1.5 -0.4 -0.4 -0.4 -0.3 -0.3  0.1 -0.   2.4 -0.1 -0.1 -0.5  0.8 -0.1  0.7 -0.3 -0.1 -0.3 -0.1 -0.4 14.  -0.3 -0.1 -0.2 -1.3  3.5 -0.5 -0.3 -0.2 -0.  -0.2 -0.2  0.5  0.4 -0.8 -0.3 -0.  -0.8 -0.7 -0.1  2.3 -0.3 -0.4  0.1 -0.5  1.   0.7 -0.  -0.3 -1.3 -0.3 -0.3 -0.2 -0.1 -1.3  5.   0.8 -0.9 -0.   0.   0.1  5.4 -0.  -0.  -0.  -2.2 -0.2 10.6 -1.4 -0.8  0.4  0.  -0.4 -0.3  5.9  8.1 -0.2 -0.2 -0.3 -0.7  1.2 -0.3  2.5 -0.1 -0.2  0.6 -0.1 -0.   5.3 -0.1 -2.1 -0.1  1.7  3.2 -0.2 -0.  -0.3 -0.2 -0.5 -0.2 -0.5  0.3  0.6 -0.2 -0.3 -0.5 -0.3 -0.5 -0.3 -0.1 -0.  -0.2 -0.5 -0.3 -0.2 -1.1 -0.8 -0.2 -0.3  0.  -2.2 -0.2 -0.2 -2.2 -0.4  0.3 -0.2 -0.6 -0.1 -0.5 -0.1  0.  -0.4 -1.  12.2  6.   1.3  3.9  0.1 -0.1 -0.  -0.3 -0.3 -0.1  0.4  4.4 -0.2 -0.2 -3.8 -0.4 -0.5 -0.1 -0.6 -0.1 -0.3 -0.   6.6 -0.5 -0.  -0.5 -0.  -0.2 -0.1 -0.4  0.9  1.7 -2.5 -0.8  2.   0.8 -0.3 -1.2 -0.1 -1.  -0.5 -1.7 -0.6  2.8  0.1 -0.5 -0.  -0.4 -0.2 -0.2 -2.5 -2.6 -0.2 -0.5 -0.8 -0.1 -3.7 -0.1  2.4 -0.2  8.2  4.2]
vy_50sample [[5 9 6 3 7 8 0 1 2 4]
 [9 4 8 2 7 6 0 5 1 3]
 [9 7 2 3 6 4 5 0 8 1]
 [0 4 6 9 2 3 8 1 7 5]
 [4 0 7 5 9 1 2 3 8 6]
 [6 1 0 3 5 9 4 7 8 2]
 [4 3 7 1 6 5 9 0 8 2]
 [6 4 5 7 3 1 8 9 0 2]
 [9 0 6 7 2 8 1 5 3 4]
 [8 0 1 3 6 2 7 5 9 4]]
vt_50sample [[5 9 6 3 7 8 0 1 2 4]
 [9 4 8 7 2 6 0 5 1 3]
 [9 7 2 3 6 4 5 0 8 1]
 [0 4 6 9 2 3 1 8 7 5]
 [4 7 0 5 9 1 2 3 8 6]
 [6 1 0 3 5 9 4 7 8 2]
 [4 3 7 1 6 5 9 0 8 2]
 [6 4 5 7 3 1 8 9 0 2]
 [9 0 6 7 2 8 1 5 3 4]
 [8 0 1 3 6 2 7 5 9 4]]
Epoch 48310: Training cost= 0.2263, Training acc= 0.8611, Validation cost= 0.2760, Validation acc= 0.8612
Epoch 48320: Training cost= 0.2527, Training acc= 0.8611, Validation cost= 0.2375, Validation acc= 0.8612
Epoch 48330: Training cost= 0.2772, Training acc= 0.8611, Validation cost= 0.2440, Validation acc= 0.8612
Epoch 48340: Training cost= 0.2727, Training acc= 0.8611, Validation cost= 0.2752, Validation acc= 0.8612
Epoch 48350: Training cost= 0.2861, Training acc= 0.8611, Validation cost= 0.2415, Validation acc= 0.8612
Epoch 48360: Training cost= 0.2648, Training acc= 0.8611, Validation cost= 0.2506, Validation acc= 0.8612
Epoch 48370: Training cost= 0.2171, Training acc= 0.8612, Validation cost= 0.3324, Validation acc= 0.8612
Epoch 48380: Training cost= 0.2374, Training acc= 0.8612, Validation cost= 0.2366, Validation acc= 0.8612
Epoch 48390: Training cost= 0.2311, Training acc= 0.8612, Validation cost= 0.2467, Validation acc= 0.8612
Epoch 48400: Training cost= 0.2686, Training acc= 0.8612, Validation cost= 0.2574, Validation acc= 0.8612
tm  [-0.9 -0.3  2.6 13.  -1.  -0.2 -0.3 -0.2 -0.1 -0.5 -6.  -0.1 -0.1 -0.2 -1.6  3.6 -0.7  0.9  0.6 -1.4 -1.1 -0.3  0.7 -0.2 -0.5 -0.6 -0.1 -0.5  2.  -2.3 -2.4  0.1  1.1 -7.9 -0.  -0.1  0.1  4.3 12.6 -0.5  1.6 -1.3 -0.3  0.  -0.4 -0.3  5.7 -0.3 -1.5  6.9 -0.3 -0.1 -1.1 -0.3 -2.   1.8 -0.6  6.4  2.2  9.1  3.1 -0.6 -0.6 -0.1 -0.5 -1.  -0.2  0.7  1.  -0.3 -0.1 -2.  -0.6 -0.4 -2.  -0.2 -0.  -0.2 -0.1 -0.3 -4.7 -0.3 -0.2  0.2 -0.1 -1.  -2.3 -0.1 -0.1 -0.6 -0.1 -0.2 -0.3 -0.2 -0.7 -0.2  0.  -2.6 -0.2 -0.4  2.9 -2.2 -0.1 -0.1 -0.3 -1.1 -1.6 -0.7 -1.4 -1.2 -0.1 -0.3 -0.2 -0.2 -0.7 13.3  1.6 -0.3 -0.2 -0.2 -0.3  3.7 -0.2 -0.3 -0.3 -1.9  0.   3.1  3.6  5.1 -0.7  0.9 -0.1 -0.5 -0.9 -8.7 -0.1 -0.3 -0.6  2.4 -0.6 -0.4 -0.5 -0.1 -0.2 -0.4 -0.4 -0.2  5.  -0.3 -1.5 -0.1  0.1 -0.6 -0.2 -0.   1.3 -1.3  2.3 -0.  -0.7 -1.5 -0.7 -0.2 -0.3 -0.5 -0.2  0.  -0.2  0.2 -0.1 -0.1 -0.1  0.4 -0.2 -1.3 -0.7 -0.2 -1.4 -0.2 -1.3 -0.  -0.4 -1.5 -0.3 -0.  -0.2 -0.4 -0.3  6.5 -0.3 -0.3 -0.4 -0.8 -0.7 -1.5 -0.6  2.1 -0.2 -0.2 -0.3 -0.2 -0.4 -0.3 -0.5 -1.5 -0.1 -0.2  8.2 -0.  -0.7  3.1 -1.1  2.6 -0.8 -0.5 -0.1 -0.4 -0.2 -0.1 -0.1 -0.3 -0.9 -1.3 -2.5  4.3 -0.8 -0.3 -0.8 -0.2 -0.6  3.1 -0.2  0.5 -1.2 -0.3 -0.2 -0.5 -0.1 -0.4 -0.1 -0.2 -0.5 -0.1 14.1 -1.   1.7 -0.4 -0.9  0.2 11.4  0.1  6.6 -0.1  4.9 -0.7]
ty_50sample [[8 3 1 5 9 2 7 4 6 0]
 [9 8 3 6 2 0 5 4 1 7]
 [1 0 9 8 4 6 7 2 3 5]
 [2 9 6 0 5 8 3 7 4 1]
 [6 2 5 0 1 8 4 9 7 3]
 [8 2 1 0 9 4 7 6 5 3]
 [3 5 9 8 0 0 2 6 4 7]
 [8 6 0 5 1 2 9 7 3 4]
 [4 3 2 7 0 9 5 1 6 8]
 [1 0 3 4 6 7 2 8 5 9]]
tt_50sample [[8 1 3 5 9 2 7 4 6 0]
 [9 8 3 2 6 0 5 4 1 7]
 [1 0 9 8 4 6 2 7 3 5]
 [2 9 6 0 5 8 3 7 4 1]
 [6 2 5 0 1 8 4 9 7 3]
 [8 2 1 0 9 4 7 6 5 3]
 [3 5 1 9 8 0 2 6 4 7]
 [8 6 0 5 1 2 9 7 3 4]
 [4 3 2 7 0 9 5 1 6 8]
 [0 1 3 4 6 7 2 8 5 9]]
vm  [-0.1 -0.  -0.2  1.4 -1.9 -0.2 -0.1 -0.1 -2.1 -0.4 -2.6 -0.4 -0.2  0.3  0.3 -1.  -0.3 -0.8 -0.1 -0.6 -1.  -0.2  1.4 -0.2 -1.4  1.2 -0.1  1.1 -1.1 11.6 -0.2  0.3 -1.7 -1.2  0.3  0.1  3.2 -1.5 -0.4 -0.4 -1.1  2.6  5.2 -0.4 -0.1 -0.1  3.6 -0.1  3.1 10.4 -0.2 -0.1  0.1 -0.5 -0.2 -0.1 -0.1 -0.4 -3.9  3.9 -0.9 -0.1 -1.  -0.7 -0.   0.9 -0.4 -0.   2.1 -0.3 -0.1  4.   0.9 -0.4  1.7 -0.4  0.7 -0.5 -0.2 -0.1 -0.8  0.4 -0.3  1.  -1.1  3.8  7.2  0.3 -0.2  0.7 -0.6  0.1 -0.3  1.  -0.9 -0.1 -0.6 -1.3 -0.1  0.9  0.8  4.7 -0.2 -0.1 -0.   1.  -0.7 -0.3 -0.6 -0.7 -0.5 -0.5 -0.2  1.4 -1.5 -1.5 -1.  -1.6 -0.6 -0.1 -0.1  4.3 -0.2 -0.7 -0.3  0.9 -0.3  4.  -4.3 -1.1  2.5 -0.5  0.2 -0.2  6.3  1.4 -0.1 -0.1 -0.4  0.6 -0.1 -0.9  0.1 -0.1 -0.1 -0.1 -0.1  0.5 -0.3 -0.1 -0.4 -0.3  3.9  3.  -0.1 -0.   0.7  1.6 -2.1 -0.8 -0.1  4.  -0.3 -0.1 -0.1 -0.4 -0.2 -0.5 -0.2 -0.3 -0.2 -0.2  0.2  0.8 -0.3  0.9  0.1 -0.6  0.3 -0.2 -1.4 -0.4 -0.3 -2.8  0.1  1.4 -0.3 -0.8  0.6 -2.9  0.2 -0.2 -0.1 -0.8  9.8 16.   0.4  3.9 -0.2 -0.  -0.3 -0.  -0.8 -0.3  0.6 -0.9 -0.  -0.1  6.3 -0.  -0.5 -2.2 -0.8 -0.5 -0.6  0.7  1.5 -0.1 -0.1  0.8 -0.  -0.1  0.5 -1.   6.2  1.7 -1.3 -0.6 -0.6  2.3 -0.8 -1.3  0.   1.9  2.1  0.7 -0.2  0.8  1.9  4.4 -0.2 -0.  -0.1 -0.1  4.6 -0.6 -0.2 -0.2 -1.  -1.4  0.6 -0.1 -0.1 -0.7  1.8  5.7]
vy_50sample [[8 8 0 4 7 7 5 2 3 1]
 [4 2 6 9 8 0 5 3 1 7]
 [9 3 0 5 4 2 1 6 7 8]
 [8 0 1 3 7 2 9 6 5 4]
 [7 1 6 4 5 3 8 2 9 0]
 [0 9 3 5 8 7 4 2 1 6]
 [9 3 0 4 8 2 7 6 1 5]
 [4 5 0 9 8 2 6 7 1 3]
 [9 7 4 5 1 6 0 2 2 3]
 [9 7 1 6 8 2 0 3 5 4]]
vt_50sample [[8 6 4 9 0 7 5 2 3 1]
 [4 2 6 9 8 0 5 3 1 7]
 [9 3 0 5 4 2 1 6 7 8]
 [8 0 1 3 7 2 6 9 5 4]
 [7 1 6 4 5 3 8 2 9 0]
 [0 9 3 5 8 7 4 2 1 6]
 [9 3 0 4 8 2 7 6 1 5]
 [4 5 0 9 8 2 6 1 7 3]
 [9 7 4 5 1 6 0 8 2 3]
 [9 7 1 6 8 2 0 3 5 4]]
Epoch 48410: Training cost= 0.2593, Training acc= 0.8612, Validation cost= 0.3255, Validation acc= 0.8612
Epoch 48420: Training cost= 0.2547, Training acc= 0.8612, Validation cost= 0.2223, Validation acc= 0.8613
Epoch 48430: Training cost= 0.2614, Training acc= 0.8612, Validation cost= 0.2595, Validation acc= 0.8613
Epoch 48440: Training cost= 0.1913, Training acc= 0.8612, Validation cost= 0.2913, Validation acc= 0.8613
Epoch 48450: Training cost= 0.1837, Training acc= 0.8612, Validation cost= 0.2162, Validation acc= 0.8613
Epoch 48460: Training cost= 0.2504, Training acc= 0.8612, Validation cost= 0.2674, Validation acc= 0.8613
Epoch 48470: Training cost= 0.2616, Training acc= 0.8612, Validation cost= 0.2014, Validation acc= 0.8613
Epoch 48480: Training cost= 0.2347, Training acc= 0.8612, Validation cost= 0.3313, Validation acc= 0.8613
Epoch 48490: Training cost= 0.1995, Training acc= 0.8613, Validation cost= 0.2286, Validation acc= 0.8613
Epoch 48500: Training cost= 0.2653, Training acc= 0.8613, Validation cost= 0.2354, Validation acc= 0.8613
tm  [-0.2  0.1 -2.6 12.2 -1.1 -0.1 -0.3 -0.  -1.1 -0.7  4.5 -0.3 -0.1 -0.  -4.3  0.7 -0.2 -0.2 -0.5 -0.9 -1.  -0.4 -0.4  0.1 -1.1  2.  -0.3 -0.4 -0.5 -0.4  1.9 -0.2 -0.3 -2.1 -0.2 -0.3  2.2 -0.8  6.5 -0.1  0.5  3.8  2.1 -0.6 -0.1 -0.2  7.4  0.5  5.2 -1.6 -0.1 -0.1  0.8 -2.2 -0.6  4.4 -0.1  6.4 -1.5 -0.7 -2.4 -0.5 -0.4 -0.2 -0.2 -0.2 -0.2 -0.2 -0.3 -0.3 -0.1 -0.4  0.2 -0.1  3.7 -0.5 -0.2  0.1 -0.1 -0.4 19.4 -0.1 -0.1 -0.3 -1.3  2.9  4.6 -0.2 -0.2 -0.2  0.3  0.1  0.3  0.7 -0.5 -0.4  0.8 -0.3 -0.2 -0.2  3.  -1.9 -0.4 -0.2 -0.2  0.6  0.7  0.1  1.3 -1.8 -0.1 -0.1 -0.1 -0.2 -0.8  4.4 -0.2 -1.1 -0.1 -0.4 -0.3  7.8 -0.1 -0.1  0.2 -5.3 -0.2  8.9 -0.3 -1.3 -0.2 -0.1 -0.4 -0.2 13.8 10.8  0.8 -0.1 -0.5 -0.5  0.3 -0.4 -0.5 -0.1  0.6 -0.4 -0.1 -0.1  9.5 -0.1 -1.4 -0.2  1.8  0.4 -0.1 -0.1 -0.5  0.3 -0.4 -0.6 -0.6  0.2 -0.1 -0.1 -0.1  0.2  0.6 -0.6 -0.   0.5 -0.1  0.1 -0.1 -0.3 -0.2 -2.1 -0.9 -0.4 -0.5 -0.1 -2.3 -0.  -0.2 -1.6 -0.3 -0.  -0.3 -0.  -0.1  1.3  0.5 -0.3 -0.2 -1.1 16.9  2.   2.1  2.7 -0.2 -0.  -0.1 -0.1 -0.3 -0.1 -0.2  3.8 -0.5 -0.2 -4.3  0.5 -0.6 -0.3 -0.4 -0.8 -0.3 -0.5  1.9 -1.  -0.4 -0.5 -0.2 -0.1 -0.2 -0.2  0.3 -0.2 -1.4 -0.2 -0.2  2.4 -0.4 -1.4 -0.2 -1.3 -0.3  3.1 -0.4  2.4  1.8  2.5 -0.1 -0.2  0.4 -0.2 -3.8 -2.4 -0.1 -0.3 -1.1 -0.1 -5.1 -0.1  3.7 -0.2  5.5  5.8]
ty_50sample [[9 5 6 3 4 0 2 8 1 7]
 [4 2 5 6 0 7 3 9 1 8]
 [1 1 4 0 5 2 6 9 7 3]
 [2 6 1 5 9 3 8 0 4 7]
 [5 8 4 9 3 1 0 0 6 6]
 [8 3 0 7 4 6 1 2 2 9]
 [5 1 0 3 9 2 4 6 7 8]
 [2 9 3 8 6 1 7 4 5 0]
 [3 2 0 7 9 1 8 4 5 6]
 [1 7 5 2 4 9 6 0 3 3]]
tt_50sample [[9 5 6 3 4 2 0 8 1 7]
 [4 2 5 6 0 7 3 9 1 8]
 [1 8 4 0 5 2 6 9 7 3]
 [2 6 1 5 9 3 8 0 4 7]
 [5 8 4 3 9 1 7 2 0 6]
 [8 3 0 7 4 6 1 5 2 9]
 [5 1 0 3 9 2 4 6 8 7]
 [2 9 3 8 6 1 7 4 5 0]
 [3 2 0 7 9 1 8 4 5 6]
 [1 7 5 2 4 9 6 0 8 3]]
vm  [ 0.8 -0.2 -1.6 -4.  -1.3 -0.1 -0.1  0.3 -0.9 -0.9 13.1 -0.2 -0.1 -0.4  6.4  3.8 -0.  -0.1 -0.3  1.6 -1.6 -0.3 -0.7  0.  -1.6  1.4 -0.1 -0.2 -1.1 -1.2  2.8 -0.2 -0.6  8.1  0.2 -0.3  2.7  6.2 -2.3 -0.2 -0.1 -1.7 -0.1  0.6 -0.4 -0.4 -2.4 -0.4  5.2 -3.8 -0.1 -0.  -0.4 15.4 -0.9 -0.9 -0.5 -1.   2.4 -3.3  2.9 -0.5  0.  -0.1 -0.6  0.1  0.4 -0.  -0.5 -0.3 -0.3  0.8  0.4  0.3 -4.2 -0.5 -0.4 -0.4 -0.   0.2  3.5 -0.3 -0.3 -0.5 -1.1 -1.1  7.6 -0.2 -0.  -0.5  0.2  0.  -0.2 -0.3 -0.3 -0.7 -0.4 -3.4  1.4 -0.3  3.7 -1.2 -0.9 -0.2 -0.3 -0.1 -2.5  0.6 -0.2  2.  -0.1  0.1 -0.1 -0.3  0.1  1.5 -1.1 -0.8 -0.1 -0.6 -0.2 -0.8 -0.1  1.7 -0.2  7.4 -0.2 -3.2  3.5 11.8  2.4 -0.4 -0.1 -0.1  5.  10.5 -0.1 -0.   1.2 -0.2 -0.7 -1.  -0.8 -0.2 -0.1 -0.1 -0.5 -0.2  2.4 -0.   3.  -0.  -0.4 -0.5 -0.2 -0.1 -0.5 -0.5 -0.4  2.8 -0.  -0.1  0.2 -0.1 -0.2  1.  -0.1  0.  -0.2 -0.1 -0.3 -0.1 -0.3 -0.3 -0.2  0.2 -0.2 -0.4  2.9 -0.2 -0.6 -0.5 -0.2 -2.3 -0.1 -0.3  0.2 -0.3 -0.6  3.3  0.4 -0.2 -0.1 -1.2 -0.4 -1.1 -0.3  0.9 -0.4  0.2 -0.4 -0.  -0.2 -0.8 -0.  -3.1 -0.3 -0.2 -2.6 -0.1 -0.4 -0.5 -1.1 -0.6 -0.4 -0.6 -0.3 -1.2 -0.8  0.6 -0.2 -0.  -0.4 -1.9 -0.3 -0.7  2.6  2.6 -0.2  2.7 -0.8 -0.1 -0.3 -0.6  0.4  2.9  0.3 -0.7  3.  -2.4 -0.2 -0.8 -0.2  0.4 -0.2  2.5 -0.3  0.1 -1.2  0.5 -1.  -0.1 -1.2  0.4 -0.2 -2.5]
vy_50sample [[2 3 4 6 0 5 7 1 9 8]
 [0 1 8 6 7 3 4 5 2 2]
 [7 2 8 9 6 3 5 1 4 0]
 [3 2 6 8 1 7 0 4 9 5]
 [3 1 9 4 0 5 7 2 8 6]
 [0 1 2 4 9 6 3 7 5 8]
 [2 4 9 6 5 7 8 3 0 1]
 [7 6 5 4 8 9 9 3 1 0]
 [9 4 5 2 0 6 8 3 7 1]
 [2 8 3 0 7 6 5 5 4 1]]
vt_50sample [[2 3 4 6 0 5 7 1 9 8]
 [0 1 8 6 7 3 4 9 5 2]
 [7 2 8 9 6 3 5 1 4 0]
 [3 2 6 8 1 7 0 9 4 5]
 [3 1 9 4 0 5 7 2 8 6]
 [1 0 2 4 9 6 3 7 5 8]
 [2 4 9 6 5 7 8 3 0 1]
 [7 6 5 4 8 2 9 3 1 0]
 [9 4 5 2 0 6 8 3 7 1]
 [2 8 3 0 7 6 9 5 4 1]]
Epoch 48510: Training cost= 0.2418, Training acc= 0.8613, Validation cost= 0.2361, Validation acc= 0.8613
Epoch 48520: Training cost= 0.2579, Training acc= 0.8613, Validation cost= 0.2014, Validation acc= 0.8613
Epoch 48530: Training cost= 0.2409, Training acc= 0.8613, Validation cost= 0.2402, Validation acc= 0.8614
Epoch 48540: Training cost= 0.2402, Training acc= 0.8613, Validation cost= 0.2098, Validation acc= 0.8614
Epoch 48550: Training cost= 0.2446, Training acc= 0.8613, Validation cost= 0.2187, Validation acc= 0.8614
Epoch 48560: Training cost= 0.2831, Training acc= 0.8613, Validation cost= 0.2627, Validation acc= 0.8614
Epoch 48570: Training cost= 0.2552, Training acc= 0.8613, Validation cost= 0.2747, Validation acc= 0.8614
Epoch 48580: Training cost= 0.2108, Training acc= 0.8613, Validation cost= 0.2510, Validation acc= 0.8614
Epoch 48590: Training cost= 0.2353, Training acc= 0.8613, Validation cost= 0.2217, Validation acc= 0.8614
Epoch 48600: Training cost= 0.2794, Training acc= 0.8614, Validation cost= 0.2596, Validation acc= 0.8614
tm  [-1.5 -0.2  6.7 -0.3 -2.  -0.3 -0.1 -0.1 -0.5  0.4 -8.9 -0.2 -0.1 -0.5 11.3 -1.1  0.5 -0.1 -0.9 -0.1 -1.2  0.2 -0.4 -0.3 -1.1  0.8 -0.3 -0.6 -0.1  1.5 -1.3 -0.3 -0.4 -0.9 -0.1 -0.2 -0.  -0.1  4.2 -0.2  2.3  4.1  1.5  3.1 -0.3 -0.3 -0.9 -0.1 -1.4 13.1 -0.5 -0.3 -0.6 -1.  -1.3 -1.3 -0.9  2.9 -0.5  5.9  6.  -0.3 -0.2 -0.1 -1.3 -1.4 -0.1 -0.4 -0.3 -0.  -0.5 -0.6 -0.2  0.1 -4.7 -0.2 -0.3  0.6 -0.2  0.2 -6.4  0.  -0.1 -0.7 -0.2  4.7 -1.5  0.1 -0.1 -0.4 -0.1 -0.2 -0.1 -0.3 -0.7 -0.6  1.1 -3.2 -0.6 -0.8 -0.4  6.2 -0.1  0.2 -0.2 -0.4 -2.2 -0.4 -2.4 -0.7 -0.2  0.1 -0.3 -0.3  1.3  2.3 -0.2 -0.3  0.7 -0.4 -0.1  0.9 -0.1 -0.2 -0.1 14.5 -0.2  5.4 -0.4  1.  -0.6 -0.1 -0.3  2.1 -5.8 -7.2 -0.1 -0.1 -0.5  0.4  1.6 -0.5  0.5 -0.3 -0.3 -0.1 -0.2  0.1 -0.7 -0.3 -0.  -0.3  0.6  0.8 -0.2 -0.1 -0.9  0.9  2.8 -0.5  0.3 -1.6 -0.1 -0.  -0.4 -0.2 -0.4 -0.2 -0.4 -0.1 -0.1  0.2 -0.3 -0.2 -0.2  0.3 -0.4 -0.1 -0.2 -0.  -1.  -0.2 -0.1 -1.1 -0.1 -0.6 -0.3 -0.5 -0.3 -0.4  0.2 -0.3 -0.1 -0.7 -2.4  2.1 -0.3 -0.4 -0.   0.3 -0.3 -0.1  0.  -0.2 -0.4 -1.8 -0.1  0.1  7.3 -0.1 -0.8  1.2 -0.4  7.6 -0.3 -0.1 -1.  -0.5 -0.3 -0.9 -0.  -0.2 -0.4 -0.7 -0.4  0.2 -2.1 -0.7 -0.3 -0.5 -0.2  1.9 -0.5  0.4 -1.4 -1.2 -0.7 -1.1 -0.  -1.7 -0.3 -0.6 -0.1 -0.4 18.  -0.3 -0.9 -0.8 -0.9 -0.3 15.9 -0.2  2.7  0.2  4.2  0.6]
ty_50sample [[8 7 1 5 0 4 9 3 6 2]
 [6 1 4 4 3 7 5 2 8 9]
 [3 1 8 5 2 9 4 0 6 7]
 [3 7 2 0 0 1 5 4 6 8]
 [9 4 3 2 8 0 6 1 7 5]
 [8 7 5 6 4 1 1 3 2 0]
 [0 6 2 5 9 1 7 8 4 3]
 [6 4 3 8 5 9 2 1 1 0]
 [6 3 4 1 0 7 5 2 9 8]
 [7 6 3 0 9 2 4 5 8 1]]
tt_50sample [[8 7 1 5 0 4 9 3 6 2]
 [1 6 4 0 3 7 5 2 8 9]
 [3 1 8 5 2 9 4 0 6 7]
 [3 7 2 9 0 1 5 4 6 8]
 [9 4 3 2 8 0 6 1 7 5]
 [8 7 5 6 4 1 9 3 2 0]
 [0 6 2 5 9 1 7 8 4 3]
 [6 4 3 8 5 9 2 7 1 0]
 [6 3 4 1 0 7 5 2 9 8]
 [7 6 3 0 9 2 4 5 8 1]]
vm  [-0.8 -0.3  1.5 -4.3 -1.4  0.3 -0.5 -0.2 -1.3 -0.6  2.5  0.6  0.  -0.2 11.6  4.2  0.7 -0.6  1.2  0.5 -1.  -0.1  1.5 -0.2 -1.5 -0.2 -0.4 -0.2  0.3 11.9  1.5 -0.  -0.2  6.7 -0.1 -0.3 -0.2 -1.3 -5.9 -0.7 -0.8  6.6  2.8 -0.6 -0.1 -0.4 -2.3 -0.3  1.   6.1  0.  -0.1 -0.3  8.2 -1.4 -1.3 -1.1  3.5 -2.  -0.9  3.1 -0.4 -0.4  0.1 -0.6 -0.1  0.5 -0.3  1.1 -0.1 -0.2 -2.  -0.4  0.9 -5.9 -0.5 -0.2 -0.6  0.1 -0.1 -2.7 -0.4 -0.5 -1.  -0.9  6.8  2.9 -0.1 -0.3 -0.  -0.6 -0.2 -0.3  2.  -0.5 -0.3 -0.4 -3.  -0.5  0.2  1.   4.7 -0.2 -0.2 -0.6 -0.1 -2.8 -0.2  1.4 -0.6 -0.2 -0.2 -0.1 -0.7 -2.  14.2  0.1 -0.6 -0.3 -0.2 -0.1 -0.  -0.2 -0.3 -0.4 14.9  0.2 -1.4 -1.6  3.6 -0.2 -0.1 -0.3  0.6  6.4 13.6 -0.3 -0.  -0.9 -0.9 -0.2 -0.3 -0.  -0.3 -0.  -0.5 -0.4 -0.2  3.4 -0.5  4.5 -0.4  1.4  0.  -0.3  0.1 -0.5 -0.4 -1.5 -0.3 -0.3  0.9 -0.3 -0.3 -0.4  0.5 -0.5 -0.6 -0.1 -0.4  0.1 -0.2 -0.2 -0.3  0.  -0.4 -1.1 -0.5  5.6 -0.3 -2.5  2.6 -0.4 -1.5 -0.1 -0.3 -0.5 -0.9 -0.2 -3.  -0.1 -0.2 -0.1 -1.2 -0.7  5.4 -0.6  5.1 -0.1 -0.1  0.  -0.3 -0.2 -0.4 -0.3 -3.1 -0.4 -0.3 -3.1 -0.2  0.2  2.5 -0.4 -0.2  0.7 -0.3  2.1 -0.5 -0.5 -0.2  0.5 -0.3 -0.3 -1.4  4.5  5.1 -1.1 -0.5 -0.   0.5  0.6  2.5 -0.1 -0.9 -1.1 -0.3 -0.6 -0.6  0.6 -6.7 -0.  -2.1 -0.3 -0.2  9.7  5.1 -0.2 -0.4 -0.5 -0.4  6.9  0.2 -3.5  0.1 -0.5 -0.2]
vy_50sample [[6 5 7 4 2 8 1 3 9 0]
 [2 6 5 0 3 7 9 8 1 4]
 [1 7 0 3 5 2 8 9 6 4]
 [1 8 3 3 4 9 5 0 7 6]
 [0 0 8 1 4 7 6 5 9 3]
 [4 1 8 5 5 2 3 7 6 9]
 [9 1 0 5 6 7 3 4 8 2]
 [2 6 1 7 3 0 5 8 8 4]
 [0 4 1 5 9 7 2 6 3 8]
 [0 5 6 9 7 1 2 8 4 3]]
vt_50sample [[6 5 7 4 2 8 1 3 9 0]
 [2 6 5 0 3 7 9 8 1 4]
 [1 0 7 3 5 2 8 9 6 4]
 [1 8 3 4 2 9 5 0 7 6]
 [2 0 8 1 4 7 6 5 9 3]
 [4 1 8 0 5 2 3 7 6 9]
 [9 1 0 5 6 3 7 4 8 2]
 [2 6 1 7 3 0 5 9 8 4]
 [0 4 1 5 9 7 2 6 3 8]
 [0 5 6 9 7 1 2 8 4 3]]
Epoch 48610: Training cost= 0.2890, Training acc= 0.8614, Validation cost= 0.2382, Validation acc= 0.8614
Epoch 48620: Training cost= 0.2674, Training acc= 0.8614, Validation cost= 0.2099, Validation acc= 0.8614
Epoch 48630: Training cost= 0.2094, Training acc= 0.8614, Validation cost= 0.2108, Validation acc= 0.8614
Epoch 48640: Training cost= 0.1911, Training acc= 0.8614, Validation cost= 0.2233, Validation acc= 0.8615
Epoch 48650: Training cost= 0.2408, Training acc= 0.8614, Validation cost= 0.2616, Validation acc= 0.8615
Epoch 48660: Training cost= 0.2173, Training acc= 0.8614, Validation cost= 0.2470, Validation acc= 0.8615
Epoch 48670: Training cost= 0.2099, Training acc= 0.8614, Validation cost= 0.2628, Validation acc= 0.8615
Epoch 48680: Training cost= 0.2912, Training acc= 0.8614, Validation cost= 0.2324, Validation acc= 0.8615
Epoch 48690: Training cost= 0.2504, Training acc= 0.8614, Validation cost= 0.2232, Validation acc= 0.8615
Epoch 48700: Training cost= 0.2563, Training acc= 0.8614, Validation cost= 0.2449, Validation acc= 0.8615
tm  [-0.  -0.1 -1.3 -1.8 -1.3 -0.2 -0.2 -0.2 -1.3 -0.2  1.8 -0.4 -0.   0.   0.5  0.8 -0.5 -0.5 -0.1 -0.1 -1.5 -0.1 -0.1 -0.5 -1.   0.1 -0.1 -0.2 -0.4 -2.5 -0.4 -0.4 -0.7 -4.8 -0.2 -0.2  1.3  6.9  6.2 -0.6 -0.   3.4  1.7  1.4 -0.   0.4 -1.1  1.5  4.8 -0.2 -0.4 -0.3 -0.5 11.7 -0.6 -0.2 -0.7  8.7  0.7  4.9  1.  -0.9 -0.8 -0.1 -0.5 -0.3 -0.  -0.3  1.2 -0.1 -0.1  1.3 -0.3 -0.2 -4.8 -0.3 -0.4 -0.2 -0.2 -0.2 -5.  -0.2 -0.1  0.9 -1.4  2.6  4.7 -0.4  0.1 -0.2 -0.7 -0.1  0.1  1.4 -0.6 -0.1  0.6 -3.2 -0.3  0.   2.6 -1.7 -0.2 -0.3 -0.1 -0.3 -2.9 -0.3  0.7 -0.4 -0.3 -0.3 -0.3 -0.6 -0.4 -0.3  2.  -0.4 -0.2 -0.2 -0.1  0.5 -0.1 -0.7 -0.3  1.  -0.1 -2.3  5.2 12.6 -0.4 -0.5 -0.3 -0.5 -1.6 -6.  -0.2 -0.1 -0.3 -0.5 -0.5 -0.5 -0.4 -0.3 -0.2 -0.1 -0.3 -0.1  9.3 -0.1  1.7 -0.2  3.4  0.7 -0.1 -0.1 -0.3 -0.7  2.9 -0.7 -0.4 -1.4  0.1 -0.  -0.1  0.8 -0.1 -0.8 -0.2 -0.1 -0.1  0.  -0.3 -0.4 -0.3 -2.   2.3 -0.6 -0.7 -0.1 -2.9 -0.3 -0.3 -1.5 -0.1  0.9 -0.2 -0.2 -0.3  7.6 -0.2 -0.2 -0.1 -0.8  2.6 -1.5 -0.7  1.2 -0.1 -0.1 -0.3 -0.1 -0.5  0.2 -0.3 -3.6 -0.4 -0.3 -2.  -0.5 -0.9 -1.4 -0.5 -1.5  0.  -0.4 -1.3 -1.  -0.4 -0.5 -0.1 -0.3 -0.3 -1.  -2.6  0.8 -0.4 -0.4 -0.4  2.9 -0.8  1.  -0.5 -0.8 -0.2  1.2 -0.1 -0.7  1.5 -6.9  0.4 -2.3 -0.   0.2 15.5  4.3  1.9 -0.3 -1.2 -0.  12.5 -0.1  4.2 -0.4  3.4 -2.8]
ty_50sample [[5 3 8 2 0 4 9 7 1 6]
 [7 2 8 0 3 4 6 5 1 9]
 [1 3 5 6 4 9 0 2 7 8]
 [2 8 8 5 6 1 4 3 0 9]
 [3 5 9 2 6 1 4 7 8 0]
 [4 0 2 7 3 9 8 6 1 5]
 [1 8 0 5 2 4 6 6 3 7]
 [4 7 8 6 2 3 1 5 5 9]
 [1 3 6 9 7 2 4 5 0 8]
 [7 5 0 2 3 8 8 9 9 4]]
tt_50sample [[5 3 8 2 0 4 9 7 1 6]
 [7 2 8 0 3 4 6 5 9 1]
 [1 3 5 6 4 9 0 2 7 8]
 [2 7 8 5 6 1 4 3 0 9]
 [3 5 9 2 1 6 4 7 8 0]
 [4 0 2 7 3 9 8 6 1 5]
 [1 8 0 5 2 4 6 9 3 7]
 [4 7 8 6 2 3 1 0 5 9]
 [1 3 9 6 7 2 4 5 0 8]
 [7 5 0 2 3 8 1 6 9 4]]
vm  [ 1.1 -0.3 -1.  -7.2 -1.7 -0.1 -0.3  0.2 -0.5 -0.9 -2.2 -0.2 -0.2 -0.3 14.   1.1 -0.3 -0.4 -0.1  1.9 -1.2 -0.3  0.8 -0.1 -1.4 -0.  -0.5 -0.3  0.7  5.7  2.4 -0.   0.8  3.5 -0.1 -0.2 -0.7 -1.4 -6.4 -0.2 -0.1 -0.6  0.4 -0.1  0.2 -0.2 -2.9 -0.1  6.7  4.9 -0.3 -0.  -0.   8.6 -1.5 -1.5 -0.9 -1.9  0.9 -1.4  2.8 -0.5 -0.2 -0.1 -0.3  0.2  0.1 -0.   2.3 -0.4 -0.1 -1.5 -0.2 -0.3 -6.2  0.1 -0.3 -0.  -0.1 -0.5 -5.8 -0.2 -0.1 -0.1 -1.8 -0.3 10.  -0.2 -0.  -0.2 -0.2 -0.2 -0.4 -0.3 -0.8 -0.4 -0.  -3.8 -0.4 -0.2  2.4  3.7 -0.4 -0.1 -0.1 -0.1 -2.7  0.6 -0.5  4.  -0.4 -0.3 -0.1 -0.9 -0.3 11.   0.5  0.4 -0.  -0.4 -0.3 -1.7 -0.3 -0.6  0.  17.1 -0.3 -1.4  0.5  8.9  0.2 -0.4 -0.3 -0.2  4.5  7.5 -0.1 -0.1 -0.5 -0.6 -0.1 -0.5 -0.1 -0.3 -0.1 -0.2 -0.2  0.2 -1.1 -0.3  6.4 -0.2  3.2  0.1 -0.2  0.2 -0.1 -0.3 -0.9 -0.1 -0.6  0.4 -0.  -0.1 -0.4 -0.1  0.  -0.5 -0.3 -0.2 -0.2 -0.2 -0.4 -0.1 -0.1  1.9 -1.5 -0.6  6.9 -0.2 -0.5 -0.1 -0.1 -2.2 -0.2 -0.3 -0.2 -0.7 -0.1 -1.4  0.  -0.3 -0.1 -1.6 -0.2 -0.5 -0.4  0.8 -0.3 -0.  -0.1 -0.4 -0.2 -0.2 -0.3 -3.7 -0.2 -0.4  4.6 -0.3 -0.2  1.1 -0.4 -2.   0.8 -0.5 -0.2 -0.6 -0.3 -0.3 -0.1 -0.1 -0.5 -1.4  1.6  4.6 -1.6 -0.4  1.7  3.  -0.2  0.5 -0.3  1.1 -1.2  1.2 -0.4 -0.8  2.4 -3.2 -0.1 -1.2 -0.2 -0.1 17.5  4.8 -0.1 -0.4 -1.3  0.8 15.3 -0.  -3.7 -0.   4.2 -1.9]
vy_50sample [[4 6 7 8 3 5 2 0 1 9]
 [8 2 6 1 4 3 7 5 9 0]
 [8 7 0 9 6 5 1 4 3 2]
 [2 0 1 4 9 3 6 5 8 7]
 [4 9 6 5 8 0 2 7 7 1]
 [3 8 5 4 9 1 0 2 6 7]
 [7 4 0 9 1 6 8 5 3 2]
 [7 5 3 1 8 9 2 6 0 4]
 [4 2 7 0 8 3 1 6 9 5]
 [8 0 2 7 5 3 4 9 6 1]]
vt_50sample [[4 6 7 8 3 5 2 0 1 9]
 [8 2 6 1 4 3 7 5 9 0]
 [8 7 0 9 6 5 1 4 3 2]
 [2 0 1 9 4 3 6 8 5 7]
 [4 9 5 6 8 0 2 3 7 1]
 [3 8 5 4 9 1 0 2 6 7]
 [7 4 9 0 1 6 8 5 3 2]
 [7 5 3 1 8 9 2 6 0 4]
 [4 2 7 0 8 3 1 6 9 5]
 [8 0 2 7 5 3 4 9 6 1]]
Epoch 48710: Training cost= 0.2207, Training acc= 0.8615, Validation cost= 0.2177, Validation acc= 0.8615
Epoch 48720: Training cost= 0.1947, Training acc= 0.8615, Validation cost= 0.2132, Validation acc= 0.8615
Epoch 48730: Training cost= 0.1667, Training acc= 0.8615, Validation cost= 0.1979, Validation acc= 0.8615
Epoch 48740: Training cost= 0.2573, Training acc= 0.8615, Validation cost= 0.2341, Validation acc= 0.8616
Epoch 48750: Training cost= 0.2340, Training acc= 0.8615, Validation cost= 0.2631, Validation acc= 0.8616
Epoch 48760: Training cost= 0.2436, Training acc= 0.8615, Validation cost= 0.2303, Validation acc= 0.8616
Epoch 48770: Training cost= 0.2143, Training acc= 0.8615, Validation cost= 0.2119, Validation acc= 0.8616
Epoch 48780: Training cost= 0.1931, Training acc= 0.8615, Validation cost= 0.2214, Validation acc= 0.8616
Epoch 48790: Training cost= 0.2279, Training acc= 0.8615, Validation cost= 0.2045, Validation acc= 0.8616
Epoch 48800: Training cost= 0.1794, Training acc= 0.8616, Validation cost= 0.2428, Validation acc= 0.8616
tm  [-0.5 -0.6  3.5 -3.  -2.4 -0.1 -0.4  0.3 -0.7 -0.2 -1.4 -0.3 -0.1 -0.4 11.4 -2.4 -0.5 -0.4 -0.2  1.1 -1.8 -0.1 -0.2 -0.2 -1.4  4.2 -0.3 -0.5 -1.5 -1.8  2.3 -0.1 -0.5  9.5 -0.  -0.1  1.8 -0.1 -0.3 -0.6  3.3 -0.5 -0.2  3.9 -0.2 -0.1 -1.5 -0.3 -0.1 -0.5 -0.3 -0.2 -0.1  1.6  1.  -1.4 -1.1 -1.5  5.5 -1.   4.9 -0.  -0.3  0.  -0.1 -0.2 -0.2 -0.1  3.4 -0.1 -0.2  5.9 -0.1 -0.1 -4.  -0.2 -0.3 -0.2  0.3 -0.2 -1.7  0.5 -0.2  1.5 -0.5 -0.1  2.5 -0.3 -0.3 -0.4 -0.  -0.1 -0.  -0.9 -0.6  0.5 -0.4 -3.7 -0.6 -0.2 -0.1  5.7 -0.5  0.1 -0.3 -0.1 -2.   0.7 -0.3  1.8 -0.6 -0.3 -0.2 -0.3  6.5 -3.4  0.9 -0.2 -0.1 -0.  -0.1 -0.8  0.7  0.4 -0.2 14.2  0.5  1.4  5.   7.  -0.6 -0.2 -0.1 -0.5 -4.5 -0.9 -0.2 -0.3 -0.6 -0.2  2.7 -1.1 -0.   0.  -0.  -0.3 -0.2 -0.1 -1.9 -0.3  2.2 -0.2 -0.4  0.9 -0.1  0.3  0.4 -0.4  2.4 -0.5  0.5 -1.5 -0.2 -0.1 -0.3 -1.1 -0.4 -0.6 -0.2  0.  -0.2 -0.2  0.4  0.3 -0.2  2.7 -0.4 -0.2  1.6  0.2 -0.3 -0.8 -0.3 -2.6 -0.2  0.3 -0.1 -0.2 -0.2  4.5 -0.1 -0.3 -0.3 -1.1 -1.6 -1.6 -0.6 -1.8  0.6  0.2 -0.2 -0.3 -0.4 -0.2 -0.1 -2.9  0.  -0.3  1.5 -0.4 -0.7 -2.1 -0.9  3.  -1.4  0.5 -1.8 -1.3 -0.2 -0.2 -0.1 -0.2 -0.4 -0.9 -0.4 -1.3 -1.7 -0.3 -0.  -0.  -0.2 -0.2 -0.1  1.   2.3 -0.3  0.9 -0.4  3.6 -1.2 -0.1 -0.5 -0.2 -0.2  6.8  1.4  0.1 -0.  -1.1 -0.5  3.7 -0.2 -0.1 -0.4  4.5 -1.5]
ty_50sample [[0 7 4 1 3 8 5 6 2 9]
 [7 1 2 6 3 0 4 8 9 5]
 [5 0 2 9 7 8 6 3 4 1]
 [0 5 4 8 7 2 9 1 6 3]
 [6 2 5 3 7 0 9 1 8 4]
 [8 0 4 3 7 1 2 9 6 5]
 [3 7 6 4 0 9 2 1 8 5]
 [9 1 2 5 6 3 4 7 8 0]
 [3 4 7 5 8 1 6 2 0 9]
 [1 3 5 6 4 0 2 8 9 7]]
tt_50sample [[0 7 4 1 3 8 5 6 2 9]
 [7 1 2 6 3 0 4 8 9 5]
 [5 0 2 9 7 8 6 3 4 1]
 [0 5 4 8 7 2 9 1 6 3]
 [6 2 5 3 7 0 9 1 8 4]
 [8 0 4 3 7 1 2 9 6 5]
 [3 7 6 4 0 9 2 1 8 5]
 [9 1 2 5 6 3 4 7 8 0]
 [3 4 7 5 8 6 1 2 0 9]
 [1 3 5 6 4 0 2 8 9 7]]
vm  [-0.7 -0.5  2.9 -3.4 -2.2 -0.  -0.2 -0.1 -0.3 -0.3  4.4 -0.4 -0.  -0.3 10.6 -1.4 -0.1 -0.6  0.2  2.  -1.5 -0.1 -0.2 -0.2 -1.2  4.1 -0.  -0.4 -1.3 -3.1  2.  -0.  -0.4  7.6 -0.1 -0.3  0.1  3.1 -0.5 -0.5  2.2  6.3 -0.2  2.8  0.1  0.2 -2.4 -0.1 -0.4 -0.1 -0.4 -0.2 -0.1  7.7  0.7 -1.1 -1.1  5.5  8.7 -0.9  6.5 -0.1 -0.   0.6 -0.  -0.  -0.2 -0.5  3.5 -0.1 -0.1  3.9 -0.2 -0.2 -5.1  0.2 -0.3  1.3  0.  -0.3 -2.  -0.4 -0.2  1.6 -0.   7.  -0.4 -0.1 -0.4 -0.2 -0.2 -0.1 -0.  -0.8 -0.7 -0.3  1.3 -4.2 -0.6 -0.4  1.3  5.  -0.3 -0.1 -0.3 -0.3 -2.5 -0.1  1.5  3.4 -0.4 -0.1 -0.2 -0.7  7.1 -2.2  1.8  0.3 -0.2 -0.1 -0.1 -1.3  0.8  0.1 -0.2 13.2 -0.  -1.1 10.8  5.8 -0.8 -0.4 -0.4 -1.  -4.1 -1.  -0.3 -0.3 -0.5 -0.2  1.5 -1.   0.6  0.  -0.1 -0.2 -0.1 -0.2  4.3 -0.3  2.8 -0.1 -0.8  0.4 -0.3  0.1 -0.1 -0.3  3.  -0.4  1.  -1.4 -0.1  0.  -0.3 -1.  -0.3 -0.6 -0.1  0.  -0.2 -0.3  0.  -0.2  0.  -0.4 -0.  -0.4  1.6  0.1 -1.6 -0.5 -0.2 -2.1 -0.2 -0.1 -0.4 -0.5 -0.2  8.3  0.1 -0.3 -0.3 -0.8 -2.6 -3.5 -0.6 -1.8  0.3 -0.1 -0.1 -0.   0.3 -0.2 -0.2 -3.7 -0.  -0.4 -3.9 -0.  -0.6 -1.7 -0.5  3.4 -1.1 -0.1 -1.3 -1.2 -0.1 -0.8  0.1 -0.4 -0.3 -0.8 -0.1 -1.3 -1.3 -0.1 -0.1  0.9 -0.4 -0.3 -0.2 -1.3  2.9 -0.2  0.  -0.5  3.3 -6.3 -0.1 -2.2 -0.3 -0.1  7.6  4.1  0.4 -0.4 -1.3 -0.2  4.9 -0.1 -0.2 -0.3  0.8 -1.2]
vy_50sample [[5 0 1 7 4 2 3 8 6 9]
 [2 0 5 3 1 7 6 9 9 4]
 [7 4 0 5 8 9 9 3 6 2]
 [9 5 0 4 7 1 3 2 8 6]
 [7 8 3 9 4 0 6 1 2 5]
 [1 8 2 6 9 4 0 7 3 5]
 [8 7 5 1 0 2 4 3 9 6]
 [6 2 5 0 4 8 3 9 7 1]
 [0 3 9 4 5 8 7 1 6 2]
 [1 4 9 2 3 3 8 0 5 6]]
vt_50sample [[5 0 1 7 4 2 3 8 6 9]
 [2 0 5 3 1 7 6 9 8 4]
 [7 4 0 5 1 8 9 6 3 2]
 [9 5 0 4 1 7 3 6 2 8]
 [7 8 3 9 4 0 6 1 2 5]
 [1 8 2 6 9 4 0 7 3 5]
 [8 7 5 1 0 2 4 3 9 6]
 [6 2 5 0 4 8 3 9 7 1]
 [0 3 9 4 5 8 7 1 6 2]
 [1 4 9 2 7 3 0 8 5 6]]
Epoch 48810: Training cost= 0.1935, Training acc= 0.8616, Validation cost= 0.2345, Validation acc= 0.8616
Epoch 48820: Training cost= 0.2453, Training acc= 0.8616, Validation cost= 0.2538, Validation acc= 0.8616
Epoch 48830: Training cost= 0.2468, Training acc= 0.8616, Validation cost= 0.2354, Validation acc= 0.8616
Epoch 48840: Training cost= 0.2596, Training acc= 0.8616, Validation cost= 0.2252, Validation acc= 0.8617
Epoch 48850: Training cost= 0.2866, Training acc= 0.8616, Validation cost= 0.2450, Validation acc= 0.8617
Epoch 48860: Training cost= 0.1976, Training acc= 0.8616, Validation cost= 0.1825, Validation acc= 0.8617
Epoch 48870: Training cost= 0.2929, Training acc= 0.8616, Validation cost= 0.2515, Validation acc= 0.8617
Epoch 48880: Training cost= 0.2408, Training acc= 0.8616, Validation cost= 0.2300, Validation acc= 0.8617
Epoch 48890: Training cost= 0.2033, Training acc= 0.8616, Validation cost= 0.2632, Validation acc= 0.8617
Epoch 48900: Training cost= 0.2194, Training acc= 0.8616, Validation cost= 0.2715, Validation acc= 0.8617
tm  [-0.1 -0.3 -3.5 -6.8 -1.2  0.2  0.4 -0.4 -1.2  0.3  8.4 -0.2 -0.4 -0.   6.5 -0.5 -0.4 -0.2 -0.2  1.2 -1.3 -0.2 -0.1 -0.3 -1.2 -0.5 -0.3 -0.1 -1.2 -0.2  4.  -0.2  0.9  7.4 -0.2 -0.   0.7 -1.1 -6.9 -0.7 -0.9  6.8 -0.5 -0.2 -0.3 -0.3 -2.2  0.2  0.  -0.5 -0.1 -0.1 -0.7 11.1 -0.7 -0.6 -0.6 -0.8  4.8 -4.6  5.6 -0.6 -0.4 -0.4  1.  -1.5 -0.2 -0.2  1.9 -0.3 -0.4  2.2 -0.1 -0.8 -6.3 -1.1 -0.3 -1.2 -0.2 -0.3  0.8 -0.  -0.1 -0.5 -0.8  5.2  5.8 -0.1 -0.2 -0.2 -0.4 -0.1 -0.5  0.2 -0.3 -0.5 -0.9 -3.7 -0.3 -0.4  0.7  3.2 -0.2 -0.5  0.4 -1.5 -3.7  0.8 -0.1  2.  -0.5  0.5 -0.3 -0.7  3.7 -1.2 -0.   0.9  0.1 -0.1 -0.1 -1.1 -0.2  0.3 -0.4  8.  -0.2 -2.   6.3  4.2 -0.4  0.1  0.7 -0.3 14.5 22.8 -0.3 -0.2 -0.6 -1.1 -0.4 -0.7 -0.6 -0.4 -0.  -0.3 -0.5 -0.2  5.1 -0.3  6.1 -0.3 -0.8 -0.5 -0.2 -0.4  0.7 -0.2 -1.8 -0.4 -0.2  1.6 -0.2  0.1 -0.2  0.4 -0.3 -0.1 -0.2 -0.3 -0.1  0.  -0.2 -0.1 -0.5 -0.9 -1.2 -0.5  6.6 -0.2 -1.8 -0.3  0.5 -1.2 -0.  -0.3 -0.4 -0.5 -0.3  0.9 -0.  -0.2 -0.  -1.1 -2.1 -1.9 -1.1 -0.8 -0.1  0.2 -0.2 -0.1 -0.3 -0.6 -0.5 -4.6 -0.2 -0.1 -5.7 -0.2 -0.7 -1.5 -1.1 -0.3  2.3 -0.5  1.2 -1.1 -0.4  0.7 -0.2 -0.3 -0.8 -1.3  5.4 -1.8 -0.8 -0.   0.2  1.5 -0.1  2.5 -0.5 -1.3  0.5  4.7  2.3 -1.3  0.7 -7.1 -0.2 -2.7 -0.2  0.8  1.5  5.5  0.5 -0.2 -1.5  0.7 -0.5 -0.3 -3.8  0.  -0.7 -0.4]
ty_50sample [[6 4 5 0 2 1 7 3 8 9]
 [8 5 9 1 6 2 7 4 3 0]
 [4 5 3 9 7 2 8 0 6 1]
 [8 4 1 9 5 7 3 2 6 0]
 [5 0 1 2 8 6 7 9 3 4]
 [2 9 5 3 6 4 8 7 1 0]
 [5 6 2 4 0 3 9 7 1 8]
 [0 1 9 7 4 2 5 6 8 3]
 [9 1 4 8 7 0 2 6 3 5]
 [1 7 3 9 4 2 5 8 0 0]]
tt_50sample [[6 4 5 0 2 1 7 3 8 9]
 [8 5 9 1 6 2 7 4 3 0]
 [4 5 3 9 7 2 8 0 6 1]
 [8 4 1 9 5 7 3 2 6 0]
 [5 0 1 2 8 6 7 9 3 4]
 [2 9 5 3 6 4 8 7 1 0]
 [5 6 2 4 0 3 9 7 1 8]
 [0 1 9 7 4 2 5 6 3 8]
 [9 1 4 8 7 0 2 6 3 5]
 [1 7 3 9 4 2 5 8 6 0]]
vm  [ 0.1 -0.6 -1.5  2.3 -1.2 -0.3 -0.  -0.1  0.9  0.7  2.7 -0.1 -0.  -0.3 -1.3  2.7  0.7 -0.  -0.4 -0.7 -1.3  1.  -0.2 -0.1 -1.   3.1  0.6 -0.6 -0.3 -2.  -0.5 -0.2 -0.3 -4.9 -0.2 -0.  -0.1  8.4  8.6 -0.8  3.2  3.  -0.6  1.4 -0.1 -0.1  3.3 -0.5  4.3 14.1 -0.3 -0.1 -0.5  6.7 -0.4  1.4 -0.3 -0.6  4.8  4.2 -0.6 -0.2 -0.2 -0.1 -1.1 -0.3 -0.  -0.1 -0.2 -0.1 -0.3  1.1 -0.2  0.4 -2.   1.8 -0.3  2.7 -0.5 -0.4 -2.2  0.4 -0.3  1.2 -1.4  6.6  4.4  0.  -0.1  0.2 -0.3 -0.2 -0.1 -1.2 -0.5 -0.2  0.8 -2.7 -0.2 -0.7 -0.2  4.4 -0.5  0.3 -0.3 -0.6 -1.4 -0.5 -0.  -0.7 -0.4  0.2  0.1 -0.4  3.7 -0.4  1.4 -0.4 -0.2 -0.3 -0.1  2.2 -0.3 -1.   0.3 -1.6  0.4 -1.   3.1 -1.6 -0.4 -0.2 -0.4 -0.6 -0.2 -4.8 -0.2 -0.1 -0.1  1.2 -0.9 -0.8 -0.5 -0.1 -0.   0.3 -0.2 -0.3  3.2 -0.2 -0.4 -0.2  3.2 -0.6 -0.2 -0.2 -0.5 -0.6  1.2  0.3  3.9 -1.2 -0.2  0.1  0.6 -0.9 -0.9 -0.6 -0.3 -0.2 -0.2 -0.1 -0.2 -0.4  0.2 -0.4 -0.8 -0.4 -0.7  0.1 -0.6 -0.5 -0.5 -1.8 -0.1  0.1  1.   0.1 -0.2  5.9 -0.1 -0.2 -0.2 -0.3  7.7 -1.2  0.6 -1.4 -0.2 -0.3 -0.1 -0.3 -0.1 -0.1 -0.5 -0.9 -0.2 -0.3  8.1 -0.2 -0.1 -0.3 -0.4 -1.3 -1.1  0.7 -0.9 -0.8 -0.1 -0.3 -0.1 -0.1 -0.3 -1.3  3.7  0.7  1.  -0.3 -0.8  3.  -0.6 -0.   0.7  1.3 -0.7  1.6  0.1 -0.5  2.7  7.9 -0.1  1.8  0.1 -0.2  7.7 -1.6  0.5 -0.4 -1.3 -1.1  4.8  0.3  5.1 -0.2 -2.4  8.4]
vy_50sample [[2 8 0 9 4 5 7 1 6 3]
 [5 8 1 3 7 6 9 0 2 4]
 [5 1 6 2 0 8 7 3 4 9]
 [7 5 4 4 0 2 2 8 1 3]
 [9 0 6 2 5 8 4 7 3 1]
 [3 1 8 2 9 0 6 4 5 7]
 [7 9 5 6 1 4 2 0 3 8]
 [5 3 7 2 9 4 0 0 8 1]
 [2 4 1 1 5 8 0 9 7 6]
 [5 0 3 7 8 9 1 4 6 2]]
vt_50sample [[2 8 0 9 4 5 7 6 1 3]
 [5 8 1 3 7 6 9 0 2 4]
 [5 1 6 2 0 8 7 3 4 9]
 [5 9 7 4 0 2 8 6 1 3]
 [9 0 6 2 8 5 4 7 3 1]
 [3 1 8 2 9 0 6 4 5 7]
 [7 9 5 1 6 4 2 0 3 8]
 [5 3 7 2 9 4 0 8 6 1]
 [2 4 1 3 5 8 0 9 7 6]
 [0 5 3 7 8 1 9 4 6 2]]
Epoch 48910: Training cost= 0.2261, Training acc= 0.8617, Validation cost= 0.2514, Validation acc= 0.8617
Epoch 48920: Training cost= 0.2052, Training acc= 0.8617, Validation cost= 0.2555, Validation acc= 0.8617
Epoch 48930: Training cost= 0.2098, Training acc= 0.8617, Validation cost= 0.2558, Validation acc= 0.8617
Epoch 48940: Training cost= 0.2778, Training acc= 0.8617, Validation cost= 0.2936, Validation acc= 0.8617
Epoch 48950: Training cost= 0.2701, Training acc= 0.8617, Validation cost= 0.3070, Validation acc= 0.8618
Epoch 48960: Training cost= 0.2814, Training acc= 0.8617, Validation cost= 0.2742, Validation acc= 0.8618
Epoch 48970: Training cost= 0.2418, Training acc= 0.8617, Validation cost= 0.2903, Validation acc= 0.8618
Epoch 48980: Training cost= 0.2501, Training acc= 0.8617, Validation cost= 0.2096, Validation acc= 0.8618
Epoch 48990: Training cost= 0.2504, Training acc= 0.8617, Validation cost= 0.2260, Validation acc= 0.8618
Epoch 49000: Training cost= 0.2813, Training acc= 0.8617, Validation cost= 0.3188, Validation acc= 0.8618
tm  [-1.3 -0.5 -4.1 -0.4 -1.2 -0.2 -0.1 -0.2 -0.5  0.3 -4.6  1.1 -0.1 -0.4 -3.5 -1.5 -0.5 -0.2  1.7 -1.7 -0.5 -0.5 -0.1 -0.2 -0.8 -0.1 -0.4  0.3 -1.  -2.4  3.7 -0.1 -0.5 -3.5  0.1 -0.3  2.5  0.4 20.7 -0.5 -1.2  4.4 -1.2  1.2 -0.3 -0.5 11.6 -0.1 -2.6 11.1 -0.2  0.4 -0.8 -4.3 -0.8  5.  -0.5 -1.6  3.8 -1.7  2.8 -0.4 -0.9 -0.3 -0.1 -1.  -0.1 -0.   3.5 -0.2  0.   2.1 -0.7 -0.9  0.3 -0.  -0.3 -1.1 -0.  -0.1  9.  -0.5  0.3 -0.4  2.4  5.7 -0.5 -0.2 -0.1 -0.3 -0.7 -0.  -0.5 -0.9 -0.3 -0.  -0.6 -1.  -0.9 -0.7  1.2  4.5 -0.1 -0.4 -0.2 -0.6 -0.7  0.5 -1.1 -2.1  0.1 -0.2 -0.2  0.2  4.5 -1.4  1.9 -0.1 -0.4  0.3 -0.4  8.2  0.1  0.1 -0.1 -4.5 -0.3 14.4  2.9 -4.4 -0.3  0.3  0.5 -0.8 -0.8 -3.7 -0.   0.2 -0.3 -0.6 -0.  -0.2 -0.1 -0.1  0.3  0.2 -0.4 -0.3  2.6  0.3  0.6 -0.3 -1.3 -0.5 -0.1 -0.2  1.7 -0.5 -0.  -0.2 -0.6 -1.3 -0.1 -0.1 -0.5 -0.2  0.6  1.1 -0.3 -0.1 -0.3 -0.2 -0.8 -0.5 -0.1 -0.4  1.  -0.4 -1.9 -0.1 -1.3 -0.4  0.8 -1.5 -0.3  1.7 -0.6 -0.1 -0.1  5.9 -0.1 -0.1 -0.4 -1.4 -0.4 -0.4 -0.2 -1.4 -0.3 -0.1 -0.2 -0.1 -0.2 -0.  -0.3  0.7 -0.3 -0.7 -0.1 -0.2 -0.5 -1.7 -0.7  6.7  3.3 -0.2 -1.9 -0.4  0.7  0.4 -0.1 -0.2 -0.8 -1.3  3.4 -0.8 -1.7  0.1 -0.1 -0.8 -1.5 -0.1 -0.4 -0.1 -0.1  4.1  0.9 -0.3 -0.5  7.1  0.   0.8 -0.1  0.3 -1.6 -2.1  2.2 -0.  -0.8 -0.4 -2.5 -0.  11.3  0.1 -0.2 16.1]
ty_50sample [[1 4 9 0 5 8 7 6 2 3]
 [1 7 8 9 3 5 6 0 4 2]
 [9 3 1 5 0 7 6 4 8 2]
 [5 6 0 7 2 9 3 4 1 8]
 [5 3 7 2 8 1 6 4 9 0]
 [8 4 0 5 6 3 7 7 1 2]
 [8 3 4 2 5 6 7 7 1 0]
 [2 7 9 0 1 5 6 8 4 3]
 [4 9 9 6 0 5 1 2 3 7]
 [7 3 9 5 6 8 0 4 2 1]]
tt_50sample [[1 4 0 9 5 8 7 6 2 3]
 [1 7 8 9 3 5 6 0 4 2]
 [9 3 1 5 0 7 6 4 8 2]
 [5 0 6 2 7 9 3 4 1 8]
 [5 3 7 2 1 8 6 4 9 0]
 [8 4 0 5 6 3 7 9 1 2]
 [8 3 4 2 5 6 9 7 1 0]
 [2 7 9 0 1 5 6 4 8 3]
 [4 8 9 6 0 5 1 3 2 7]
 [7 3 9 5 6 8 0 4 2 1]]
vm  [-0.7 -0.1  3.5  5.5 -1.1  0.2 -0.2  0.1 -1.1 -1.2  5.9 -0.4 -0.2 -0.2  0.2  2.4 -0.1 -0.4  1.4 -1.  -1.1 -0.3 -0.8 -0.2 -1.2  0.2 -0.1 -0.  -0.   4.9  1.9 -0.2 -0.5 11.6 -0.2  0.4  2.3 -1.4 -0.8 -0.3 -0.9 -2.5  1.5 -0.8  0.1 -0.2  4.5 -0.2 -1.1 -3.6 -0.1  0.   0.2 -0.8 -1.2 -0.1 -0.2 -0.4 -1.7 -2.   1.4 -0.3 -0.6 -0.3  0.9 -0.4 -0.2 -0.1  0.8 -0.2 -0.1 -1.5  0.3 -0.2 -0.1 -0.5 -0.  -0.6 -0.1 -0.5 18.7 -0.2 -0.2 -0.4  0.8 -1.9 -0.4 -0.2 -0.3 -0.4 -0.   0.2 -0.3  0.1 -0.7 -0.2 -0.4 -1.3 -0.1 -0.2  4.3 -0.4 -0.1 -0.3 -0.4 -0.5 -0.9 -0.2  0.4 -1.4 -0.3 -0.1 -0.2 -0.4 -1.3 11.9 -0.8 -1.2 -0.3 -0.3 -0.1  4.8  0.6 -0.2 -0.2  0.3 -0.3  4.4 -1.9  3.1  0.8 -0.2  0.4 -0.5  7.3 18.5 -0.1 -0.2 -0.1 -0.2 -0.  -0.2 -0.2  0.4 -0.2 -0.2 -0.1 -0.1 -1.2 -0.1 -0.6 -0.3 -1.4  1.1 -0.2  0.4 -0.2 -0.2 -1.7  0.4 -0.7  2.5 -0.4 -0.1 -0.1 -0.2 -0.1  0.6  0.4 -0.  -0.1 -0.3 -0.2  0.4 -0.2  2.8 -0.5 -0.2  0.4 -0.2 -0.4  0.  -0.4 -2.  -0.2 -0.1 -0.1 -0.7 -0.2 -1.4 -0.3 -0.  -0.2 -1.3  0.5  6.9 -0.2  4.1 -0.1  0.3 -0.5 -0.  -0.5 -0.3 -0.4 -0.7 -0.1 -0.  -1.3 -0.2 -0.4  2.1 -0.9  5.4  0.1 -0.4  4.4 -0.9 -0.2  0.2 -0.2 -0.1 -0.1 -0.9  2.1  2.3 -1.1 -0.1 -0.5 -0.3 -0.1 -0.6 -0.2 -0.3 -0.2 -0.4 -0.4 -0.   0.6 11.5 -0.   2.6 -0.2 -0.  -3.9 -1.1 -0.1 -0.4 -0.8 -0.5 -4.9 -0.1 -0.6 -0.3  4.9 -0.2]
vy_50sample [[6 3 1 9 7 4 2 5 8 0]
 [4 5 8 3 9 2 6 0 1 7]
 [6 0 2 9 3 1 4 8 7 5]
 [9 0 7 6 4 5 3 8 2 1]
 [4 5 7 6 8 1 9 2 3 0]
 [8 4 5 7 3 2 1 1 9 6]
 [5 0 7 8 6 2 9 9 4 3]
 [4 9 8 2 6 5 5 3 0 1]
 [6 4 1 8 0 2 3 7 9 5]
 [0 1 2 7 4 8 9 3 6 5]]
vt_50sample [[6 3 1 9 7 4 2 5 8 0]
 [4 5 8 3 9 2 6 0 1 7]
 [6 2 0 3 9 1 4 8 7 5]
 [9 0 7 6 4 5 3 8 2 1]
 [4 5 7 6 8 1 9 2 3 0]
 [8 4 5 7 3 2 0 1 9 6]
 [5 0 7 8 2 6 1 9 4 3]
 [4 8 9 2 6 5 0 3 7 1]
 [6 4 1 8 0 2 3 7 9 5]
 [0 1 2 7 4 8 3 9 6 5]]
Epoch 49010: Training cost= 0.2733, Training acc= 0.8617, Validation cost= 0.2020, Validation acc= 0.8618
Epoch 49020: Training cost= 0.2346, Training acc= 0.8618, Validation cost= 0.2617, Validation acc= 0.8618
Epoch 49030: Training cost= 0.2237, Training acc= 0.8618, Validation cost= 0.2328, Validation acc= 0.8618
Epoch 49040: Training cost= 0.2630, Training acc= 0.8618, Validation cost= 0.2533, Validation acc= 0.8618
Epoch 49050: Training cost= 0.2926, Training acc= 0.8618, Validation cost= 0.2334, Validation acc= 0.8618
Epoch 49060: Training cost= 0.2338, Training acc= 0.8618, Validation cost= 0.2656, Validation acc= 0.8619
Epoch 49070: Training cost= 0.1985, Training acc= 0.8618, Validation cost= 0.2276, Validation acc= 0.8619
Epoch 49080: Training cost= 0.2632, Training acc= 0.8618, Validation cost= 0.2518, Validation acc= 0.8619
Epoch 49090: Training cost= 0.2298, Training acc= 0.8618, Validation cost= 0.2171, Validation acc= 0.8619
Epoch 49100: Training cost= 0.2260, Training acc= 0.8618, Validation cost= 0.2872, Validation acc= 0.8619
tm  [-0.2 -0.5 -5.6 -6.5 -0.9 -0.5 -0.4 -0.3 -1.2  0.9 -5.6 -0.1 -0.2 -0.2  0.  -1.5 -0.5 -0.4 -0.5 -0.3 -1.2 -0.4  2.3 -0.4 -1.4 -0.7 -0.5 -0.  -1.4  0.5  2.6 -0.3 -0.2 -5.9 -0.2 -0.2  2.3 -1.9 -5.1 -1.2  1.1  1.7 -0.5  3.  -0.2 -0.1 -1.4  0.1  0.2  3.7 -0.3 -0.3 -1.1 -0.1 -0.7 -0.3 -1.3 -1.8  0.7 -1.3  2.3 -0.4 -1.1  0.6 -0.2  0.4 -0.4 -0.1  3.8 -0.1 -0.2  2.2 -0.9 -0.9 -5.  -0.4 -0.3 -0.6 -0.4  1.7 -6.  -0.3 -0.3  3.6 -0.5  1.6  7.4 -0.2 -0.5 -0.5 -0.2  0.  -0.3 -0.2 -0.5  1.3 -0.7 -3.3 -0.3 -0.4 -0.3 -0.9 -0.2 -0.1 -0.   0.1 -3.2  1.7 -1.4  0.2 -0.  -0.1  0.1 -0.2  1.2 -1.3  0.2  0.9 -0.2 -0.7 -0.4 -0.  -0.6 -0.6 -0.  -0.   0.3  3.1  1.3 12.9 -0.3 -0.4  0.8 -0.8 14.3  4.9 -0.4 -0.2 -0.9 -0.6 -0.1 -0.3 -0.3 -0.5 -0.1 -0.4 -0.9 -0.1  5.1 -0.3  5.6  0.3  2.4 -0.9 -0.1 -0.2  1.6 -1.1 -1.2 -0.7  2.   1.2 -0.  -0.2 -0.1 -0.1 -0.6 -0.2 -0.7 -0.3 -0.2 -0.  -0.1 -0.1 -0.2 -1.1 -1.2 -0.3  5.8 -0.1 -1.9 -0.4  0.5 -2.  -0.2  2.4 -0.3  2.2 -0.  -0.2 -0.1 -0.2 -0.5 -1.1 -0.1 -0.5 -1.  -0.4 -0.4 -0.2  0.2 -0.2  0.6 -0.5  0.5 -4.6 -0.1 -0.4  2.4  0.2 -0.8 -2.1 -1.2 -0.2 -0.1  0.8 -1.  -0.6  0.3  0.8 -0.  -0.4 -0.8 -2.1  3.8 -0.  -1.2  0.9 -0.3  1.6 -0.9  3.1 -0.4  0.9 -0.2  6.1  1.3 -1.1  2.  -5.5  0.1 -2.1 -0.  -0.2 18.2  7.4  1.1  1.8 -0.8 -1.1 16.8 -0.1 -2.9 -0.2  4.1 -2.8]
ty_50sample [[4 6 0 8 3 3 1 9 7 2]
 [8 0 6 9 9 1 3 5 7 4]
 [0 4 8 5 9 1 6 2 7 3]
 [9 4 6 5 7 3 1 8 0 2]
 [5 0 4 9 8 2 6 7 1 3]
 [2 8 0 4 5 7 9 1 6 3]
 [6 4 3 1 5 9 8 7 0 2]
 [6 8 1 9 3 7 5 4 0 2]
 [3 4 0 1 6 2 9 8 7 5]
 [8 4 4 9 9 6 6 2 5 0]]
tt_50sample [[4 6 8 0 5 3 1 9 7 2]
 [8 0 6 9 2 1 3 5 7 4]
 [0 4 8 5 9 1 6 2 7 3]
 [9 4 6 5 7 3 1 0 8 2]
 [5 4 0 9 8 2 6 7 1 3]
 [8 2 0 4 5 7 9 1 6 3]
 [6 4 3 1 5 9 8 7 0 2]
 [6 8 1 9 3 7 5 4 0 2]
 [3 4 0 1 6 2 9 8 7 5]
 [8 4 7 3 9 6 2 1 5 0]]
vm  [ 1.2  0.   4.5 20.2 -0.8 -0.1 -0.3 -0.1 -0.  -0.8  8.7 -0.4 -0.  -0.3 -2.2  6.5  0.5 -0.5 -0.  -1.2 -0.6 -0.   1.4 -0.1 -0.8  1.1 -0.2 -0.3  1.5  2.1 -0.  -0.4  0.2  4.8 -0.2 -0.1  1.2  3.4 11.3 -0.1  0.7  3.4  1.4 -1.  -0.2 -0.1  9.8  0.3  7.   2.  -0.2 -0.2  0.6 -0.6 -0.8  2.  -0.2  6.7 -1.2  2.9 -3.  -0.3 -0.3  0.8  0.3  1.  -0.  -0.1 -0.6 -0.   0.1 -1.6 -0.3 -0.2  7.9  0.3 -0.   0.7  0.  -0.1 20.9  0.  -0.3  0.3 -1.6  5.   3.6 -0.1  0.8 -0.  -0.2 -0.2  0.2 -0.5 -0.5 -0.2  1.1  0.1 -0.1  0.6  2.3  2.7 -0.4 -0.1 -0.4  1.   2.7 -0.3  0.2 -1.8 -0.2 -0.2 -0.1 -0.3 -1.2 11.8 -0.2 -1.  -0.2  0.1 -0.3  8.8  0.4 -0.3 -0.1 -2.8 -0.   3.1 -0.9 -3.4  0.5 -0.2 -0.2 -0.4  2.7  6.9 -0.2 -0.2 -0.1 -0.4 -0.8 -0.2 -0.4 -0.1 -0.   0.2 -0.1 -0.   3.1 -0.2 -2.  -0.2  2.5 -0.6 -0.3  0.4 -0.3 -0.3 -0.3 -0.6 -0.2 -0.  -0.1 -0.1  0.  -0.1 -0.3 -0.4 -0.1 -0.1 -0.1  0.1 -0.2 -0.1 -0.2 -0.5 -0.7 -0.1 -1.  -0.1 -1.4  0.1 -0.5 -1.4 -0.  -0.4 -0.1 -0.5 -0.  -0.5 -0.  -0.2 -0.2 -0.5 20.2  3.   1.6  3.4  0.3 -0.1 -0.1  0.  -0.1 -0.5  0.   6.  -0.1 -0.1 -2.3 -0.1 -0.3  2.7 -0.1 -2.1 -0.4 -0.5  3.9 -0.5 -0.6 -0.5 -0.1 -0.1  1.  -0.9  1.8  2.9  2.9  0.2  0.6  3.8 -0.7 -1.2 -0.1 -0.6 -0.4 -1.  -0.3  2.6  1.7 10.6 -0.3  3.3 -0.1 -0.2 -4.3 -2.5  0.  -0.1 -0.9 -0.2 -5.3 -0.2  6.4 -0.3 -1.2 12.4]
vy_50sample [[9 2 5 6 7 8 3 4 0 1]
 [3 1 7 5 8 2 9 6 4 0]
 [5 8 8 7 0 9 3 4 6 2]
 [3 2 5 8 1 7 6 9 4 0]
 [5 7 0 2 8 9 6 1 3 4]
 [1 3 0 7 2 9 4 6 5 8]
 [2 4 8 7 1 9 3 0 5 6]
 [1 9 2 4 0 0 3 5 8 7]
 [4 0 2 7 3 1 9 5 8 6]
 [9 3 2 0 8 6 4 7 1 5]]
vt_50sample [[9 2 5 6 7 3 8 4 0 1]
 [3 1 7 5 8 2 9 6 4 0]
 [5 1 8 7 0 9 3 4 6 2]
 [3 2 5 8 1 7 6 9 0 4]
 [5 7 0 2 8 9 6 1 3 4]
 [1 3 0 7 2 9 4 6 5 8]
 [2 4 8 7 1 9 0 3 5 6]
 [1 9 2 4 6 0 3 5 8 7]
 [4 0 2 7 3 1 5 9 8 6]
 [9 3 2 0 8 6 4 7 1 5]]
Epoch 49110: Training cost= 0.2549, Training acc= 0.8618, Validation cost= 0.2509, Validation acc= 0.8619
Epoch 49120: Training cost= 0.2168, Training acc= 0.8618, Validation cost= 0.2449, Validation acc= 0.8619
Epoch 49130: Training cost= 0.2497, Training acc= 0.8618, Validation cost= 0.2584, Validation acc= 0.8619
Epoch 49140: Training cost= 0.2912, Training acc= 0.8619, Validation cost= 0.2465, Validation acc= 0.8619
Epoch 49150: Training cost= 0.3593, Training acc= 0.8619, Validation cost= 0.2254, Validation acc= 0.8619
Epoch 49160: Training cost= 0.2429, Training acc= 0.8619, Validation cost= 0.3430, Validation acc= 0.8619
Epoch 49170: Training cost= 0.2416, Training acc= 0.8619, Validation cost= 0.2399, Validation acc= 0.8619
Epoch 49180: Training cost= 0.2094, Training acc= 0.8619, Validation cost= 0.2244, Validation acc= 0.8620
Epoch 49190: Training cost= 0.2906, Training acc= 0.8619, Validation cost= 0.1820, Validation acc= 0.8620
Epoch 49200: Training cost= 0.2537, Training acc= 0.8619, Validation cost= 0.2294, Validation acc= 0.8620
tm  [ 1.2 -0.5 -4.  -0.3 -0.8 -0.1 -0.2  0.7 -0.4 -0.1 -4.1 -0.4 -0.1 -0.3 -2.6  0.7 -0.   0.1 -0.6 -1.2 -1.5 -0.3  1.3 -0.2 -1.4  0.  -0.3 -0.4 -0.3 -0.4 -0.2 -0.3  1.2 -6.4 -0.2 -0.2  1.1 -1.  -1.4 -0.8  0.7 -1.8 -0.6 -0.3 -0.3 -0.2  4.5 -0.4  4.5  4.9 -0.4  0.3 -0.5 -1.1 -1.   2.3 -0.6 -2.   0.5  2.9 -1.3 -0.2 -0.3 -0.  -0.6 -0.2 -0.2 -0.2 -0.1 -0.1  0.1 -0.6 -0.2 -0.5 -1.5 -0.1 -0.1  0.6 -0.3 -0.1 -2.1 -0.1 -0.3  1.1 -1.3 -1.8  7.3  0.2 -0.2 -0.4 -0.3 -0.1 -0.3 -0.4 -0.5  0.1 -0.  -2.  -0.4 -0.6  0.  -1.7 -0.5 -0.2  0.  -0.2 -1.4 -0.1 -1.2 -1.5 -0.   1.1  0.3 -0.5 -0.   3.7 -0.5 -0.4 -0.2 -0.6 -0.3  3.8 -0.5 -0.6 -0.3 -3.1 -0.3  5.3 -0.4  3.  -0.1 -0.4 -0.2 -0.3 15.7  1.3  0.2 -0.2  0.1 -0.4 -0.6 -0.2 -0.5 -0.1  0.1  0.2 -0.3 -0.3  3.5 -0.3 -0.1 -0.1  3.9 -0.4 -0.2 -0.1 -0.2 -1.  -1.4 -0.1  0.7  1.1 -0.1 -0.   0.8 -0.4 -0.3 -0.3 -0.5 -0.   0.2 -0.1 -0.2 -0.2 -0.1 -0.1 -1.7 -0.1  1.3 -0.2 -0.  -0.4 -0.1 -1.4 -0.2  0.   0.2  0.5 -0.   1.4 -0.1 -0.2 -0.5 -0.8 11.9  0.5 -0.2 -0.2 -0.3 -0.1  0.1 -0.1  0.5 -0.2 -0.2 -1.1  0.5 -0.  10.1  0.3 -0.8  0.4 -0.7 -1.6 -0.3 -0.2  1.6 -0.7 -0.3  0.2 -0.1 -0.4 -0.1 -1.4  2.3  2.8 -0.9  0.6 -0.6  3.5 -0.4  0.8 -0.1  0.6 -1.   4.2  0.4 -0.4  2.9 11.9  0.5  2.9 -0.1 -0.1  7.7 -1.4  0.1 -0.5 -1.4 -0.4  4.6 -0.  -0.7 -0.   3.4 -0.1]
ty_50sample [[8 6 4 3 9 0 2 5 1 7]
 [3 2 0 1 7 9 8 4 5 6]
 [1 9 0 8 5 2 4 3 7 6]
 [6 4 7 2 3 0 1 5 5 8]
 [2 8 1 7 9 6 0 4 3 5]
 [6 3 4 5 0 9 8 1 2 7]
 [2 9 1 0 4 5 7 6 3 8]
 [9 3 7 2 8 5 6 0 1 4]
 [7 3 2 4 0 9 5 8 6 1]
 [0 6 4 1 2 7 3 5 8 9]]
tt_50sample [[8 6 4 3 9 0 2 5 1 7]
 [3 2 0 1 7 9 8 4 5 6]
 [1 9 0 8 5 2 4 3 7 6]
 [6 4 7 2 3 0 1 9 5 8]
 [2 8 1 7 9 6 0 4 3 5]
 [6 3 4 5 0 9 8 1 2 7]
 [2 9 1 0 4 5 7 6 3 8]
 [9 3 7 2 8 5 6 0 1 4]
 [7 3 2 4 0 9 5 8 6 1]
 [0 6 4 1 2 7 3 5 8 9]]
vm  [-1.1  0.4  7.3 -1.  -1.6 -0.3 -0.3 -0.2 -0.8 -1.   4.8  0.  -0.1  0.5 11.8  5.1 -0.1  0.2  0.1  0.4 -1.   0.2  1.8 -0.2 -1.8  1.9  0.1 -0.1  0.3  6.7  0.3 -0.1 -0.4 11.2 -0.1 -0.4  1.5  3.5 -0.2 -0.6  1.2  6.4  4.2  1.8 -0.1  0.3 -1.2 -0.5 -0.8  5.6 -0.3 -0.   0.2  6.  -1.6 -1.1 -0.7  5.4 -2.2  0.3  5.2 -0.4 -0.4 -0.1 -0.3 -0.2 -0.2 -0.3  0.7  0.1  1.  -1.5  0.1  1.1 -4.1 -0.5 -0.1 -0.6 -0.1 -0.1 -1.  -0.5 -0.2 -0.4  0.1  6.7 -0.7  0.4 -0.1 -0.2 -0.2  0.   0.1  0.8 -0.2 -0.6 -0.2 -2.8 -0.7 -0.1  3.1  7.2 -0.4 -0.2 -0.2  0.3 -1.8  0.1  2.  -0.1 -0.3 -0.4 -0.1 -0.5 -1.8 13.  -0.1 -1.1 -0.1 -0.2 -0.1 -0.1 -0.1  0.4 -0.2 15.2 -0.1 -0.8 -1.5  1.2 -0.3 -0.  -0.2  0.4 -4.8 -0.3 -0.2  0.1 -0.8 -0.5 -0.1 -0.4 -0.3 -0.3 -0.2 -0.4 -0.2 -0.1 -0.1 -0.2  0.7  0.3 -0.3 -0.5  0.8 -0.2 -0.5 -0.4  1.9 -0.1  0.3 -1.1 -0.3 -0.  -0.1 -0.8 -0.4 -0.3 -0.1  0.6 -0.1 -0.3 -0.  -0.3 -0.1  0.6 -0.5 -0.1  0.7 -0.1 -1.9  0.3 -0.4 -1.8 -0.   0.2 -0.2 -0.5  0.5 -1.6 -0.1 -0.1  0.4 -1.  -1.5  5.8 -0.1  4.4 -0.1 -0.   0.5  0.2  0.  -0.  -0.1 -1.7 -0.1 -0.3 -2.9 -0.2 -0.7  3.3 -0.5  6.  -0.2 -0.2 -0.6 -0.8 -0.1  0.2 -0.  -0.1  0.2 -0.8  1.7  4.4 -0.2 -0.3 -0.4 -0.5  0.5  0.9  0.1 -0.8 -0.6 -1.2 -0.3 -0.2 -0.1 -4.5 -0.  -1.5 -0.1 -0.1  4.8  0.3 -0.4  0.8 -0.7 -0.6  2.1  0.  -0.1  0.2 -0.9  1.8]
vy_50sample [[7 5 1 2 4 8 6 3 3 0]
 [1 2 9 6 7 4 8 0 3 5]
 [2 6 7 4 8 5 1 1 0 3]
 [4 8 6 3 9 2 1 7 0 5]
 [1 7 5 2 8 4 6 0 3 9]
 [0 6 7 5 4 2 9 3 1 1]
 [4 5 7 8 0 2 6 1 9 3]
 [4 0 2 5 1 7 9 9 3 6]
 [2 6 0 4 1 7 3 3 9 8]
 [7 8 2 6 4 0 1 5 3 9]]
vt_50sample [[7 5 1 2 4 8 6 9 3 0]
 [1 2 9 6 7 4 8 0 3 5]
 [2 6 7 4 8 5 1 9 0 3]
 [4 8 6 3 9 2 1 7 0 5]
 [1 7 5 2 8 4 6 0 3 9]
 [0 6 7 5 4 2 9 3 1 8]
 [4 5 7 0 8 2 6 1 9 3]
 [4 0 2 5 1 7 9 8 3 6]
 [2 6 0 4 1 7 3 5 9 8]
 [7 8 2 6 4 0 1 5 3 9]]
Epoch 49210: Training cost= 0.2122, Training acc= 0.8619, Validation cost= 0.2171, Validation acc= 0.8620
Epoch 49220: Training cost= 0.2700, Training acc= 0.8619, Validation cost= 0.2915, Validation acc= 0.8620
Epoch 49230: Training cost= 0.2019, Training acc= 0.8619, Validation cost= 0.2144, Validation acc= 0.8620
Epoch 49240: Training cost= 0.2245, Training acc= 0.8619, Validation cost= 0.1937, Validation acc= 0.8620
Epoch 49250: Training cost= 0.2276, Training acc= 0.8619, Validation cost= 0.2342, Validation acc= 0.8620
Epoch 49260: Training cost= 0.2183, Training acc= 0.8620, Validation cost= 0.2025, Validation acc= 0.8620
Epoch 49270: Training cost= 0.1966, Training acc= 0.8620, Validation cost= 0.2250, Validation acc= 0.8620
Epoch 49280: Training cost= 0.2366, Training acc= 0.8620, Validation cost= 0.2100, Validation acc= 0.8621
Epoch 49290: Training cost= 0.2231, Training acc= 0.8620, Validation cost= 0.2306, Validation acc= 0.8621
Epoch 49300: Training cost= 0.2408, Training acc= 0.8620, Validation cost= 0.2282, Validation acc= 0.8621
tm  [-1.1 -0.4 -1.2 -0.9 -1.6  0.3 -0.  -0.1 -0.7 -0.2  7.7 -0.1 -0.2 -0.4  0.4 -0.1 -0.1 -0.1 -0.2  1.3 -1.5 -0.2 -0.4 -0.1 -1.7  4.5 -0.3  0.3 -1.1 -2.6  1.5 -0.3 -0.5  1.2 -0.1 -0.2  3.2 -0.1 -3.1 -0.3 -0.4  1.4 -0.7 -0.7 -0.1 -0.2 -1.3 -0.5 -1.7 -0.9  0.1 -0.1 -0.1  7.5 -0.  -0.1 -0.7  2.   5.  -0.8  7.9 -0.3  0.2  0.4  0.3 -0.2 -0.2 -0.4 -0.2 -0.1 -0.1  2.3  0.2  0.1 -3.6 -0.2 -0.1  0.3 -0.1 -0.3  1.9 -0.1 -0.2 -0.   1.8  3.4 -1.5 -0.  -0.1 -0.1 -0.2 -0.1 -0.3 -0.4 -0.4 -0.1  0.9 -3.3 -0.4 -0.4  0.7 -0.3 -0.5 -0.1 -0.2 -0.4 -2.1 -0.   0.8  0.4 -0.4  0.4 -0.1 -0.3  4.4 -1.  -0.7 -0.6  0.2 -0.2 -0.2 -0.5 -0.2 -0.1 -0.3  0.6  0.  -1.1  4.   3.9 -0.2 -0.3 -0.  -0.6 12.7 13.5 -0.2 -0.2  0.3 -0.3 -0.2 -0.7 -0.4 -0.4 -0.  -0.  -0.2 -0.2  3.8 -0.1  0.3 -0.3 -1.6 -0.2 -0.1  0.3 -0.6  0.8 -0.9  0.1  1.8  0.1 -0.2 -0.  -0.2 -0.9 -0.4 -0.3 -0.2 -0.2 -0.1 -0.2 -0.2 -0.1 -0.1 -0.7 -0.6  0.   3.7  0.1 -0.7 -0.3 -0.4 -2.2  0.1 -0.6 -0.4 -0.1 -0.1  7.2 -0.1 -0.1 -0.3 -1.1 -2.9 -1.2 -0.4 -1.2  0.2 -0.  -0.1 -0.1 -0.2 -0.6 -0.  -2.5 -0.1 -0.2 -1.9 -0.1 -1.  -1.1 -0.7  9.5 -0.9 -0.   3.7 -1.1 -0.1 -0.2 -0.1 -0.2 -0.1 -1.1  5.1 -0.9 -0.5  1.9  1.8 -0.5 -0.  -0.1  0.3 -0.6  1.2  2.2  0.2 -0.4  2.1 -1.4  0.1 -0.5 -0.2 -0.2  0.6  0.  -0.3 -0.3 -1.3 -0.7 -0.7 -0.  -1.8  0.  -0.7 -0.5]
ty_50sample [[1 6 0 2 5 4 3 9 9 8]
 [4 1 8 7 0 6 9 3 2 5]
 [0 7 2 6 4 8 1 3 5 9]
 [5 3 1 9 7 0 2 4 6 8]
 [8 3 6 4 2 1 7 5 9 0]
 [5 6 7 4 3 1 2 8 9 0]
 [4 8 1 5 0 9 2 3 7 6]
 [7 8 6 6 1 2 0 3 9 4]
 [4 6 3 1 7 8 9 9 5 0]
 [4 5 7 6 6 8 9 2 2 0]]
tt_50sample [[1 6 0 2 5 4 3 9 7 8]
 [4 1 8 0 7 6 9 3 2 5]
 [0 2 7 6 4 8 1 3 5 9]
 [5 3 1 9 7 0 2 4 6 8]
 [8 3 6 4 2 1 7 5 9 0]
 [5 6 7 4 3 1 2 8 9 0]
 [4 8 1 5 0 9 3 2 7 6]
 [7 8 6 5 1 2 0 3 9 4]
 [4 6 3 1 7 8 9 2 5 0]
 [4 5 7 6 1 3 8 9 2 0]]
vm  [ 0.6 -0.1 -2.9  1.  -0.2  0.3 -0.2 -0.1 -0.3 -0.4 14.   0.4 -0.3 -0.4 -2.6  5.7 -0.1 -0.5 -0.  -1.5 -1.  -0.2 -0.6 -0.4 -0.9  0.2 -0.1  1.   0.1 -0.2  4.4 -0.7 -0.5 10.4 -0.1 -0.2  0.4  5.1 12.5  0.8 -0.6 -1.9 -0.6  0.2 -0.3 -0.2  8.3 -0.   6.2 -3.2 -0.1 -0.   1.   1.7 -1.7  3.  -0.1 -2.1 -0.1 -4.8 -2.4 -0.4 -0.2 -0.2  1.3 -0.5 -0.2  0.7 -0.6 -0.3 -0.3 -1.3 -0.  -0.  -0.1  0.2 -0.2  1.8  0.  -0.2 30.6 -0.7 -0.4 -0.5 -1.9 -1.3  9.4 -0.2 -0.  -0.3 -0.7 -0.2 -0.1  0.7 -0.6  0.4 -0.1 -0.4 -0.1 -0.2  1.2 -0.6 -0.5 -0.3 -0.5  0.3 -0.3  1.6 -0.5 -2.5  1.8 -0.3 -0.3 -0.6 -0.4 10.  -0.  -0.4 -0.3  0.7 -0.1  9.   0.6  1.2 -0.4 -3.2 -0.2  0.5 -0.2 -1.7  0.7  0.6 -0.1  0.4  4.1 12.8 -0.1 -0.3 -0.  -0.5 -1.   0.8 -0.2 -0.2 -0.1  0.8 -0.4 -0.1 -0.4 -0.2 -0.1 -0.1  1.  -0.2 -0.1 -0.2 -0.3 -0.5 -0.4  0.6 -0.5 -0.7  0.4 -0.1 -0.1  1.6  0.1 -0.  -0.3 -0.3 -0.1 -0.1 -0.3 -0.3 -0.3  0.5 -0.5 -0.2 -1.1 -0.1 -0.1  1.1 -0.3 -1.1  0.   1.4  0.3 -0.3 -0.   1.3 -0.5  0.8 -0.3 -1.5 18.   0.1  1.   1.5 -0.1 -0.2 -0.2  0.2  0.2 -0.3 -0.3  5.7 -0.2 -0.2 -1.7 -0.4 -0.3  2.5 -0.3 -1.6  5.6 -0.2 -0.9 -1.1 -0.5 -0.7 -0.3 -0.1 -0.8 -1.  -0.2  0.1  1.1 -0.1  0.5  1.2 -0.7 -0.5 -0.2 -0.7 -0.9  4.1 -0.7 -0.1 -0.1 21.7 -0.2  5.3 -0.2 -0.3 -6.6 -2.5  0.3 -0.5 -1.   0.3 -7.6 -0.1  7.6 -0.  -0.6  7.6]
vy_50sample [[2 4 9 3 6 7 5 0 1 8]
 [5 6 8 9 3 0 1 7 2 4]
 [6 2 8 1 7 4 9 9 5 0]
 [2 1 8 0 9 4 6 3 7 5]
 [1 2 7 6 0 5 8 9 4 3]
 [0 9 7 5 3 8 1 4 6 2]
 [3 5 6 4 8 2 0 1 7 9]
 [8 4 2 9 6 3 1 7 5 0]
 [1 9 8 3 5 5 6 7 4 2]
 [3 3 6 1 0 0 2 5 4 7]]
vt_50sample [[2 4 9 3 6 7 5 0 1 8]
 [5 6 8 9 3 0 7 1 2 4]
 [6 2 8 1 7 4 9 3 5 0]
 [2 1 8 9 0 4 6 3 7 5]
 [1 2 7 6 0 5 8 9 4 3]
 [0 9 7 5 3 1 8 4 6 2]
 [3 5 6 4 8 2 0 1 9 7]
 [8 4 2 6 9 3 1 7 5 0]
 [9 1 8 3 0 5 6 7 4 2]
 [3 8 6 1 0 2 9 5 4 7]]
Epoch 49310: Training cost= 0.3196, Training acc= 0.8620, Validation cost= 0.2827, Validation acc= 0.8621
Epoch 49320: Training cost= 0.2953, Training acc= 0.8620, Validation cost= 0.2704, Validation acc= 0.8621
Epoch 49330: Training cost= 0.2973, Training acc= 0.8620, Validation cost= 0.2746, Validation acc= 0.8621
Epoch 49340: Training cost= 0.2841, Training acc= 0.8620, Validation cost= 0.2500, Validation acc= 0.8621
Epoch 49350: Training cost= 0.2570, Training acc= 0.8620, Validation cost= 0.2732, Validation acc= 0.8621
Epoch 49360: Training cost= 0.2764, Training acc= 0.8620, Validation cost= 0.2594, Validation acc= 0.8621
Epoch 49370: Training cost= 0.2326, Training acc= 0.8621, Validation cost= 0.2702, Validation acc= 0.8621
Epoch 49380: Training cost= 0.2423, Training acc= 0.8621, Validation cost= 0.2530, Validation acc= 0.8621
Epoch 49390: Training cost= 0.2399, Training acc= 0.8621, Validation cost= 0.2386, Validation acc= 0.8621
Epoch 49400: Training cost= 0.2402, Training acc= 0.8621, Validation cost= 0.2441, Validation acc= 0.8622
tm  [-1.2 -0.4  8.9  1.1 -1.5 -0.2 -0.2 -0.  -0.2 -0.5 -0.8 -0.1 -0.2 -0.1 11.6  5.6 -0.1  0.3  0.3 -0.7 -0.6 -0.2  0.6 -0.3 -1.4 -0.1 -0.5 -0.   0.8  3.8 -1.1 -0.1 -0.9  4.7 -0.1 -0.1 -0.1  7.   9.7 -0.7 -0.5  2.   1.1  2.1  0.2  0.3 -0.4 -0.1 -0.6 10.6 -0.1  0.2 -0.6  7.  -1.7 -1.1 -0.4  1.6 -0.7  5.7  2.6 -0.2 -1.  -0.3 -1.1 -0.9 -0.1 -0.3  0.7 -0.1  0.7 -1.8 -0.1  2.5 -3.4  0.5  0.  -0.3 -0.2 -0.1 -3.9 -0.1 -0.3 -0.2 -0.6  4.  -0.8 -0.1  0.3 -0.2 -0.8 -0.1 -0.2 -0.6 -0.4 -0.2 -0.1 -2.6 -0.5 -0.1  0.7  7.9 -0.2  0.2 -0.4 -0.3 -1.6 -0.5 -0.1 -1.3 -0.  -0.2 -0.1 -0.4 -1.  14.2 -0.2 -0.4 -0.2 -0.3  1.2  3.8 -0.2 -0.3 -0.1 14.7 -0.  -1.2 -0.8  0.9 -0.4  0.2 -0.1 -0.4 -7.6 -6.3 -0.4 -0.1 -0.9 -0.2 -0.3 -0.4 -0.4 -0.2 -0.1 -0.1 -0.1 -0.1 -2.  -0.  -0.1 -0.1  1.2 -0.3 -0.2 -0.1 -0.3 -0.4  2.6 -0.6  1.5 -1.4 -0.4  0.3  0.9 -0.5 -0.8 -0.3  0.1 -0.2 -0.1  0.  -0.2 -0.4 -0.2  1.8  1.8 -0.2 -1.  -0.2 -1.1  1.2 -0.6 -1.2 -0.2 -0.5 -0.4 -0.3 -0.1 -1.3  0.4 -0.2 -0.  -0.5 -0.6  2.5 -0.1  2.7 -0.3 -0.3 -0.  -0.  -0.  -0.   1.1 -1.9 -0.1 -0.2  5.9  0.1 -0.9  2.9 -0.1  3.2 -0.2  0.7 -0.9 -0.1 -0.3  0.  -0.1 -0.1 -0.  -0.7 -0.1  5.3  0.3 -0.4  0.5  0.  -0.5  0.2 -0.2  1.2 -1.1 -1.8 -0.6 -0.1 -0.3 -0.7 -0.2 -0.2 -0.1 -0.3 11.9  1.2 -0.4 -0.2 -0.8 -1.   9.8 -0.   4.9 -0.4 -1.8  1.4]
ty_50sample [[7 8 2 1 5 4 9 3 6 0]
 [6 8 7 0 9 1 2 4 5 3]
 [4 1 8 6 7 2 9 0 5 3]
 [6 5 9 3 8 7 4 0 1 2]
 [3 5 9 7 4 8 0 6 1 2]
 [0 1 1 3 7 6 2 8 4 5]
 [4 8 1 6 7 0 2 5 9 3]
 [1 5 9 6 7 2 4 0 8 3]
 [5 8 0 2 7 4 1 6 9 9]
 [8 0 2 6 7 5 4 3 9 1]]
tt_50sample [[7 8 2 1 5 4 9 3 6 0]
 [8 6 7 0 9 1 2 4 5 3]
 [4 1 8 6 7 2 9 0 3 5]
 [6 5 9 3 8 7 4 0 1 2]
 [3 5 9 7 4 8 0 6 1 2]
 [0 1 9 3 7 6 2 8 4 5]
 [4 8 1 6 7 0 2 5 3 9]
 [1 5 9 6 7 2 4 0 8 3]
 [5 8 0 2 4 7 1 6 3 9]
 [8 0 2 6 7 5 4 3 9 1]]
vm  [-1.   0.3 -1.7 18.  -0.7 -0.  -0.1 -0.1 -0.9  0.5  1.7  1.1 -0.3 -0.  -4.4  2.7 -0.7  0.9 -0.  -0.9 -1.1 -0.1 -0.6 -0.2 -0.4 -0.2 -0.2 -0.2 -0.4 -3.9 -0.6 -0.4 -0.1 -4.  -0.  -0.1  2.8  6.2 20.5 -0.6 -0.2 -1.  -0.5 -0.2 -0.6 -0.5  6.9 -0.5 -1.8 -2.9 -0.2 -0.3  0.1 -2.1 -1.7  4.7 -0.3  7.   1.6  4.5  1.7 -0.6  0.5 -0.1  0.1 -1.2  0.  -0.2 -0.7 -0.2 -0.2 -0.9 -0.2 -0.6 -1.  -0.5 -0.3 -1.5 -0.1 -0.2 13.5 -0.2  0.5 -0.8  0.  -1.  -1.9 -0.2 -0.1 -0.1 -0.3  0.  -0.3  0.9 -0.5 -0.5 -1.1 -0.8 -0.3  0.4  0.5 -3.5 -0.  -0.3 -0.1 -0.2 -0.9 -0.4  0.6 -2.4  0.3 -0.1 -0.1 -0.3 -0.6  4.5 -0.2 -0.6 -0.3 -0.1 -0.2  7.3 -0.2 -0.1 -0.3 -5.5 -0.2  7.4  5.   4.7 -0.1  0.7  1.2  1.7  4.8 -2.9  0.3 -0.3 -0.2 -0.5 -0.4  0.8 -0.6 -0.4  0.1 -0.3 -0.2 -0.2  8.1 -0.3 -1.7 -0.1 -1.2 -0.7  0.1 -0.4 -0.  -0.5  2.  -0.5 -0.2 -1.6 -0.4  0.2 -0.2  0.6 -0.3 -0.1 -0.4 -0.2 -0.3 -0.3 -0.3 -0.  -0.1 -2.1  0.8 -0.4 -2.  -0.3 -1.8 -0.4  0.3 -1.4  0.2 -0.3 -0.3  0.1 -0.1 11.5 -0.  -0.1 -0.2 -1.2  0.1 -1.4 -0.1  2.4 -0.2  0.  -0.2 -0.2 -0.3 -0.3 -0.1  2.  -0.2  0.7 -2.5 -0.3 -0.3 -0.3 -0.8  5.6  0.9  0.3 -0.2 -1.1 -0.7  2.1 -0.3 -0.3  1.2 -0.5 -2.5  1.4 -1.   0.6 -0.5 -0.8 -0.7 -0.2 -0.  -0.3 -0.7  1.3 -0.  -0.2 -0.3  0.7 -0.4 -0.5 -0.1  0.1 -2.5 -2.2 -0.3 -0.  -0.9 -0.6 -3.8 -0.2 11.9  1.3  4.1 -0.7]
vy_50sample [[3 1 5 9 8 2 0 4 6 7]
 [9 4 2 1 5 0 6 8 7 3]
 [7 9 2 4 1 5 6 0 3 8]
 [0 1 9 3 2 4 5 6 8 7]
 [9 2 3 1 4 7 5 6 0 8]
 [1 4 5 9 9 3 0 2 8 7]
 [4 2 5 1 3 6 9 9 7 0]
 [5 7 6 9 1 0 8 4 3 2]
 [0 5 2 4 6 1 3 8 7 9]
 [7 6 1 3 4 0 2 8 5 5]]
vt_50sample [[3 1 5 9 2 8 0 4 6 7]
 [9 4 2 1 5 0 6 7 8 3]
 [7 9 2 4 1 5 6 0 8 3]
 [0 1 9 3 2 4 5 6 8 7]
 [9 2 3 1 4 5 7 6 0 8]
 [1 4 5 9 6 3 0 2 8 7]
 [4 2 5 1 3 6 8 9 7 0]
 [5 7 9 6 1 0 8 4 3 2]
 [0 5 2 4 6 1 3 8 7 9]
 [7 6 1 3 4 0 2 8 9 5]]
Epoch 49410: Training cost= 0.2574, Training acc= 0.8621, Validation cost= 0.2657, Validation acc= 0.8622
Epoch 49420: Training cost= 0.2496, Training acc= 0.8621, Validation cost= 0.2318, Validation acc= 0.8622
Epoch 49430: Training cost= 0.2406, Training acc= 0.8621, Validation cost= 0.2335, Validation acc= 0.8622
Epoch 49440: Training cost= 0.3206, Training acc= 0.8621, Validation cost= 0.2452, Validation acc= 0.8622
Epoch 49450: Training cost= 0.2994, Training acc= 0.8621, Validation cost= 0.2546, Validation acc= 0.8622
Epoch 49460: Training cost= 0.2359, Training acc= 0.8621, Validation cost= 0.2721, Validation acc= 0.8622
Epoch 49470: Training cost= 0.2237, Training acc= 0.8621, Validation cost= 0.2452, Validation acc= 0.8622
Epoch 49480: Training cost= 0.2030, Training acc= 0.8621, Validation cost= 0.2518, Validation acc= 0.8622
Epoch 49490: Training cost= 0.2102, Training acc= 0.8622, Validation cost= 0.2412, Validation acc= 0.8622
Epoch 49500: Training cost= 0.2236, Training acc= 0.8622, Validation cost= 0.2364, Validation acc= 0.8622
tm  [ 1.1 -0.2  4.4 -1.2 -1.3 -0.1 -0.  -0.1 -0.2 -0.7  5.5 -0.3 -0.2 -0.4  7.5  3.2 -0.1 -0.4  1.8  2.9 -1.2  0.2  0.   0.2 -1.1  1.6 -0.4 -0.1 -0.5 -2.5 -1.4 -0.2 -0.  -3.3 -0.1 -0.2 -0.1  4.9 -4.1 -0.6 -0.2 -2.1 -0.6 -1.1 -0.1 -0.2 -2.6 -0.4  5.3 -0.2 -0.4 -0.3 -0.3 18.3 -0.7 -0.9 -0.6  4.6  4.8  6.7  3.1 -0.1 -0.4 -0.  -0.3 -0.  -0.2  0.2 -0.1 -0.2 -0.3 -0.2  0.6 -0.6 -5.2  0.5 -0.3  0.6 -0.  -0.2 -6.7 -0.1 -0.   0.9 -1.6 -1.9  0.2 -0.2 -0.1 -0.2 -0.3  0.   0.2 -0.4 -0.7 -0.3  0.7 -4.1 -0.3 -0.3  3.5 -1.2 -0.8 -0.1 -0.2 -0.2 -3.1 -0.4  1.4  4.8 -0.3 -0.  -0.1 -0.8  0.7  1.1  0.2 -0.2  0.2  0.2 -0.4 -1.9 -0.3 -0.6 -0.1  8.8 -0.3 -4.   4.4 16.4  1.5 -0.3  0.2 -0.6  6.1 -1.  -0.1 -0.3 -0.1 -0.2 -0.8 -0.8 -0.5 -0.2 -0.1 -0.1 -0.1 -0.   1.1  0.2  0.7 -0.1  3.5 -0.4 -0.2 -0.2 -0.3 -0.3 -0.5 -0.1  0.2  0.6 -0.   0.5 -0.3 -0.2 -0.  -0.3 -0.2 -0.2 -0.1 -0.3 -0.3 -0.1 -0.3  1.3 -1.  -0.3  4.6  0.1 -0.  -0.5 -0.3 -2.  -0.2  0.7  0.1 -0.4 -0.3  7.3 -0.1 -0.3 -0.1 -0.8 -0.7 -1.5 -0.4 -0.4 -0.1 -0.1 -0.1 -0.  -0.2 -0.4 -0.2 -4.  -0.3 -0.1  7.2 -0.3 -0.3 -0.5 -0.7 -1.4 -0.2 -0.1  6.3 -1.1 -0.6 -0.1 -0.1 -0.2 -0.4 -1.4 -0.4  1.5  2.1  0.5 -0.4  3.9 -1.  -0.  -0.2  1.4 -0.3 -0.8  0.3 -0.8  2.2 -2.9 -0.1 -1.  -0.1 -0.1 19.7  3.6  1.1 -0.3 -1.4 -0.1 17.6 -0.2 -2.3 -0.2  0.1 -4.1]
ty_50sample [[2 3 8 6 0 7 5 1 4 9]
 [3 2 8 5 0 4 4 6 7 1]
 [9 4 2 7 6 3 1 8 0 5]
 [9 7 0 8 3 1 6 2 4 5]
 [4 6 1 2 5 7 9 0 8 3]
 [0 8 9 4 4 5 1 3 7 2]
 [7 5 4 6 1 8 0 3 9 2]
 [4 0 1 6 8 8 3 5 9 2]
 [3 7 0 8 2 5 1 9 4 6]
 [4 9 6 2 0 1 5 7 3 8]]
tt_50sample [[2 3 8 6 0 7 5 1 4 9]
 [3 2 8 5 9 4 0 6 7 1]
 [9 4 2 7 6 3 1 8 0 5]
 [9 7 0 8 3 1 6 2 4 5]
 [4 6 1 2 5 7 9 0 8 3]
 [0 8 6 9 4 5 1 3 7 2]
 [7 5 4 6 1 8 0 3 9 2]
 [4 0 1 6 8 7 3 5 9 2]
 [3 7 0 8 2 5 1 9 4 6]
 [4 9 6 2 0 1 5 7 3 8]]
vm  [-1.3 -0.6  2.6 -1.4 -2.5 -0.2 -0.4 -0.2 -0.6 -0.  -2.  -0.1 -0.2 -0.2  6.  -2.3 -0.1 -0.4  1.2  0.  -1.4 -0.2  1.2 -0.3 -1.3  4.1 -0.4 -0.2 -1.7 -3.1  1.8 -0.3 -0.7  5.5  0.2 -0.4  1.1  2.2  8.6 -0.7  1.2  1.7 -0.7  2.8 -0.3  0.4 -1.  -0.3 -0.7  3.9 -0.1 -0.1 -0.4 -0.3  2.2 -0.7 -1.  -0.5  7.4 -0.5  5.7 -0.1 -0.2  0.2 -0.6 -0.4 -0.1 -0.5  3.  -0.1  0.2  7.6 -0.1  1.5 -3.6 -0.3 -0.3 -0.4 -0.  -0.  -0.9 -0.  -0.3 -0.4 -0.   3.2 -0.4 -0.2 -0.  -0.3 -0.6 -0.2 -0.1 -1.1 -0.3 -0.1 -0.3 -3.4 -0.8 -0.  -0.1  5.7 -0.5 -0.1 -0.3 -0.3 -1.3  0.3 -0.4 -0.5 -0.6 -0.3 -0.2 -0.3  7.9 -3.7  1.9 -0.  -0.1 -0.1 -0.2  1.4 -0.2 -0.2 -0.2  7.5  0.   3.3  6.6  1.9 -0.9 -0.  -0.1 -0.5 -5.2 -3.3 -0.1 -0.1 -0.6 -0.4  2.1 -1.2 -0.2 -0.5 -0.1 -0.3 -0.2 -0.  -0.9 -0.2  0.9 -0.2 -0.6 -0.2 -0.   0.4 -0.2 -0.3  4.2 -0.6  1.1 -2.   0.1 -0.2 -0.2 -0.9 -0.4 -0.7 -0.3 -0.1 -0.1 -0.1 -0.3 -0.1 -0.4  1.5  2.4 -0.2 -0.5 -0.2 -1.  -0.5 -0.2 -1.9 -0.1  0.3 -0.4 -0.3 -0.2  8.4 -0.1 -0.4 -0.1 -0.9 -1.9 -2.2 -0.5 -2.2 -0.  -0.1  0.6 -0.2 -0.3 -0.1 -0.2 -1.9  0.1 -0.1 -0.  -0.3 -0.8 -2.4 -0.7  5.9 -1.   0.1 -1.9 -1.1 -0.1 -0.3 -0.1 -0.2 -0.3 -1.1 -0.7 -1.7 -1.7 -0.3  1.8 -0.4 -0.1 -0.3 -0.  -0.   2.7 -0.5  0.1 -0.3  2.4 -0.9 -0.1 -0.4 -0.2 -0.   4.7  0.8  0.4  1.1 -1.1 -0.6  1.9 -0.1  4.9 -0.1  2.5  0.7]
vy_50sample [[0 1 7 4 5 8 3 9 2 6]
 [8 3 2 4 9 0 0 5 6 1]
 [7 4 1 8 3 2 5 9 0 6]
 [4 8 5 5 6 7 1 9 3 2]
 [2 5 4 0 7 1 9 3 8 6]
 [3 2 0 7 4 1 9 6 8 5]
 [4 9 9 8 6 3 2 5 1 7]
 [6 1 2 8 7 0 4 5 3 9]
 [6 5 3 4 8 1 1 7 2 0]
 [8 3 7 9 1 6 0 5 4 2]]
vt_50sample [[0 1 7 4 5 8 3 9 2 6]
 [8 3 2 4 9 0 5 7 6 1]
 [7 4 1 8 3 2 5 9 0 6]
 [4 8 5 0 6 7 9 1 3 2]
 [2 5 4 0 7 1 9 3 8 6]
 [3 2 0 7 4 1 9 6 8 5]
 [4 0 9 8 6 3 2 5 7 1]
 [6 1 2 8 7 0 4 5 3 9]
 [6 5 3 4 8 9 1 7 2 0]
 [8 3 7 9 1 6 0 5 4 2]]
Epoch 49510: Training cost= 0.2103, Training acc= 0.8622, Validation cost= 0.2529, Validation acc= 0.8623
Epoch 49520: Training cost= 0.2213, Training acc= 0.8622, Validation cost= 0.2296, Validation acc= 0.8623
Epoch 49530: Training cost= 0.2479, Training acc= 0.8622, Validation cost= 0.2921, Validation acc= 0.8623
Epoch 49540: Training cost= 0.2939, Training acc= 0.8622, Validation cost= 0.2316, Validation acc= 0.8623
Epoch 49550: Training cost= 0.2358, Training acc= 0.8622, Validation cost= 0.3244, Validation acc= 0.8623
Epoch 49560: Training cost= 0.2627, Training acc= 0.8622, Validation cost= 0.2924, Validation acc= 0.8623
Epoch 49570: Training cost= 0.2460, Training acc= 0.8622, Validation cost= 0.2644, Validation acc= 0.8623
Epoch 49580: Training cost= 0.2565, Training acc= 0.8622, Validation cost= 0.2612, Validation acc= 0.8623
Epoch 49590: Training cost= 0.2445, Training acc= 0.8622, Validation cost= 0.2395, Validation acc= 0.8623
Epoch 49600: Training cost= 0.2488, Training acc= 0.8623, Validation cost= 0.2630, Validation acc= 0.8623
tm  [-0.4 -0.2 -1.4 -1.4 -0.9 -0.  -0.5 -0.2 -0.3 -1.  12.3 -0.2 -0.1 -0.4 -0.1  4.5 -0.3 -0.2 -0.1 -1.1 -1.7 -0.4 -0.8 -0.2 -1.   0.1 -0.3  0.9 -0.1 -2.5  2.4 -0.3 -0.4  9.2 -0.2 -0.2  2.3  7.5  9.3 -0.3 -0.5 -3.8 -1.1  1.  -0.3 -0.1  2.9 -0.3 -0.4 -4.2 -0.2 -0.2 -0.3  7.  -1.2  0.1 -0.3 -2.2  5.6 -3.4  2.3 -0.6 -0.4 -0.2  2.3 -0.4 -0.  -0.1 -0.5 -0.2 -0.1 -0.4 -0.3 -0.1 -1.8  1.1 -0.4 -0.4 -0.   0.1 15.  -0.4 -0.  -0.1 -0.2 -2.9  2.  -0.2 -0.  -0.6 -0.3 -0.1 -0.3 -0.3 -0.5 -0.  -0.6 -2.4 -0.2 -0.5  5.  -1.2 -0.5 -0.1 -0.2  0.4 -1.8 -0.1 -0.2 -1.4  0.  -0.2 -0.2 -0.5  0.8  4.9 -0.4 -0.3 -0.3 -0.2 -0.3  4.  -0.2  0.2 -0.3 -0.1 -0.1 -1.2  5.6  6.3  0.6 -0.4 -0.  -0.5 -1.7  5.1 -0.3  0.1  1.1 -0.5 -1.   0.3 -0.9 -0.3 -0.   0.6 -0.2 -0.1 -1.1 -0.2  1.3 -0.1 -1.4 -1.1 -0.1 -0.  -0.2 -0.4  0.3 -0.  -0.4 -0.4 -0.1 -0.1  0.  -0.1  0.5  0.9  0.  -0.2 -0.2 -0.1 -0.6 -0.4 -0.2  2.3  0.9 -0.5 -0.9 -0.   0.3 -0.6 -0.4 -1.5 -0.  -0.1  0.5 -0.4 -0.2  7.3 -0.  -0.3 -0.2 -1.2 -0.5 -1.8 -0.5 -0.1 -0.  -0.  -0.4 -0.1 -0.2 -0.5  0.7 -2.  -0.1 -0.1 -0.2 -0.2 -0.5 -0.1 -1.1  2.5  0.6 -0.2 -1.3 -1.2 -0.4  0.3 -0.1  0.1 -0.7 -1.4 -1.6 -0.   2.6  1.8  0.7  0.8 -1.1 -0.3 -0.3 -0.   0.3  2.5 -0.  -0.6  1.2 12.  -0.2  2.9 -0.2 -0.1 -3.  -0.7 -0.1 -0.5 -1.  -0.1 -3.9  0.4  5.6  0.1 -0.  -1.2]
ty_50sample [[2 3 4 1 9 7 0 6 5 8]
 [1 8 9 4 5 6 0 2 7 3]
 [5 3 0 7 8 1 4 6 9 2]
 [1 3 0 4 2 6 8 9 7 5]
 [7 4 0 6 2 9 3 8 8 5]
 [0 4 6 6 8 7 7 5 3 2]
 [5 5 0 9 2 8 7 3 4 6]
 [9 9 1 3 7 0 8 4 5 2]
 [3 9 0 0 7 4 2 1 8 5]
 [2 0 6 7 9 8 1 3 5 4]]
tt_50sample [[2 3 4 1 9 7 0 6 5 8]
 [1 8 9 4 5 6 0 2 7 3]
 [5 3 0 7 8 1 4 6 9 2]
 [1 3 0 4 2 6 8 9 7 5]
 [7 4 0 6 2 9 3 8 1 5]
 [0 4 6 9 1 8 7 5 3 2]
 [5 1 0 9 2 8 7 3 6 4]
 [9 6 1 3 7 0 8 4 5 2]
 [3 9 6 0 7 4 2 1 8 5]
 [2 0 6 7 9 8 1 3 5 4]]
vm  [-0.9 -0.2  5.5  3.6 -1.2 -0.3  1.  -0.2 -0.1 -0.3 -2.8 -0.1 -0.2 -0.4  4.3  0.6  0.5 -0.   1.5  1.  -1.3 -0.1 -0.2 -0.2 -0.9  0.9 -0.2 -0.3 -0.3  0.2 -0.8 -0.4 -0.1 -1.5 -0.2 -0.1 -0.6 -1.  -3.2 -0.3  0.7  9.8 -0.  -0.8 -0.3 -0.4 -1.5 -0.1  2.3 13.3 -0.6 -0.1 -0.1  2.3 -1.2 -0.5 -0.8 10.6  0.9  6.2  2.2 -0.6 -0.1 -0.  -1.1 -0.9  1.1 -0.   3.  -0.1 -0.1 -1.  -0.   0.4 -5.1  0.  -0.1 -0.6 -0.3 -0.3 -3.6 -0.  -0.2 -0.7 -1.4 10.1 -0.9 -0.1 -0.2 -0.2 -0.2 -0.4  0.4 -0.8 -0.7 -0.4 -0.2 -3.4 -0.8 -0.6 -0.   6.6 -0.3  0.1 -0.4  1.3 -1.8 -0.3 -0.8 -0.6 -0.4 -0.1 -0.2 -0.8 -0.1  7.7  1.3  1.4  0.4  0.  -0.1  0.1 -0.3 -0.1  0.6  5.4 -0.1  0.6  2.6 -0.9  0.1 -0.2 -0.1 -0.3  5.6  3.7 -0.3 -0.1 -0.4 -0.8  1.3 -0.3  1.7 -0.2 -0.3  0.7 -0.1  0.5  4.2 -0.2 -0.4 -0.1  2.4  0.8 -0.4 -0.2 -0.6  0.4 -0.3 -0.3 -0.  -0.2  0.5 -0.2  0.3 -0.4 -0.4 -0.2 -0.3 -0.3 -0.  -0.  -0.3 -0.2  0.1 -0.8 -1.  -0.3  4.  -0.1 -2.2 -0.1 -0.3 -1.8 -0.2  0.1 -0.3 -0.3  0.1 -0.   0.4 -0.1 -0.4 -0.7  0.  -0.8 -0.6 -0.1 -0.3 -0.1 -0.2 -0.1  0.6 -0.3  0.1 -1.5 -0.1  0.  -2.3 -0.3  0.6  3.  -0.6  1.5 -0.2 -0.1  5.9 -0.8 -0.1  0.3 -0.2 -0.1 -0.  -1.1  6.   2.  -1.8 -0.3 -0.1  0.6  0.2 -0.1 -0.2 -0.6 -1.  -1.3 -0.1 -0.2  1.6 -6.  -0.2 -2.2 -0.2 -0.3 11.1 -0.3 -0.1 -0.2 -1.3 -0.8  8.9 -0.3 -1.8  0.1 -0.4  5.7]
vy_50sample [[5 6 8 7 1 2 0 9 4 3]
 [7 8 8 3 2 4 0 5 1 6]
 [6 7 4 0 5 2 1 3 9 8]
 [5 9 8 4 7 2 2 0 1 1]
 [2 5 5 7 1 4 9 3 8 0]
 [4 8 1 7 2 0 6 3 5 9]
 [9 5 2 8 4 0 7 6 3 1]
 [6 9 1 7 3 4 5 2 0 8]
 [9 3 6 2 7 8 0 1 4 5]
 [3 9 8 4 0 5 7 2 1 6]]
vt_50sample [[5 6 8 7 1 2 0 9 4 3]
 [7 8 9 3 2 4 0 5 1 6]
 [6 7 4 0 5 2 1 3 9 8]
 [5 9 8 4 7 0 2 6 1 3]
 [2 5 6 7 1 4 9 8 3 0]
 [4 8 1 7 2 0 6 3 5 9]
 [9 5 2 8 4 0 7 6 3 1]
 [6 9 1 7 4 5 3 2 0 8]
 [9 3 6 2 7 8 0 1 4 5]
 [3 9 8 0 4 5 7 2 1 6]]
Epoch 49610: Training cost= 0.2476, Training acc= 0.8623, Validation cost= 0.1889, Validation acc= 0.8623
Epoch 49620: Training cost= 0.2528, Training acc= 0.8623, Validation cost= 0.2442, Validation acc= 0.8623
Epoch 49630: Training cost= 0.2257, Training acc= 0.8623, Validation cost= 0.2857, Validation acc= 0.8624
Epoch 49640: Training cost= 0.2340, Training acc= 0.8623, Validation cost= 0.2127, Validation acc= 0.8624
Epoch 49650: Training cost= 0.1789, Training acc= 0.8623, Validation cost= 0.2237, Validation acc= 0.8624
Epoch 49660: Training cost= 0.2240, Training acc= 0.8623, Validation cost= 0.2437, Validation acc= 0.8624
Epoch 49670: Training cost= 0.2517, Training acc= 0.8623, Validation cost= 0.2105, Validation acc= 0.8624
Epoch 49680: Training cost= 0.2223, Training acc= 0.8623, Validation cost= 0.2178, Validation acc= 0.8624
Epoch 49690: Training cost= 0.2403, Training acc= 0.8623, Validation cost= 0.2734, Validation acc= 0.8624
Epoch 49700: Training cost= 0.2564, Training acc= 0.8623, Validation cost= 0.2299, Validation acc= 0.8624
tm  [-0.1 -0.3 -3.3 -0.2 -1.7 -0.3 -0.4 -0.3 -1.6 -0.1 -5.3 -0.  -0.2 -0.1 -2.  -2.2 -0.1 -0.5 -0.3 -0.8 -1.3 -0.1 -0.3 -0.3 -0.9  0.3  0.1 -0.2 -2.   0.8  2.8 -0.4 -0.  -0.8 -0.1 -0.1  5.5 -1.  10.1 -0.1  2.8 -0.5  1.   3.5 -0.3 -0.5  5.7 -0.3  3.6 -0.9 -0.2 -0.2  0.1 -4.9  1.   1.6 -0.9 -1.4 -2.1 -1.8 -2.  -0.7  0.7 -0.2 -1.   0.6 -0.2 -0.5 -0.   0.1 -0.   5.9 -0.6 -0.7  1.6 -0.5 -0.2 -0.4 -0.   1.6  9.7 -0.3 -0.4 -0.7 -1.2 -0.4  9.  -0.1  0.  -0.4 -0.1 -0.2 -0.1  1.4 -0.3  0.8 -0.2 -0.3  0.1 -0.  -0.3 -1.1 -0.2 -0.2 -0.1  1.1 -0.2  0.1 -1.7 -2.2 -0.1 -0.1 -0.3  0.4 -0.  -3.2 -0.1 -1.1 -0.2 -0.5 -0.1  9.4 -0.3 -0.4 -0.2 -2.6  0.4 15.7 -1.8  0.3 -0.3 -0.1 -0.1 -0.1  3.6 -0.2 -0.2  0.1  0.5 -0.2  1.  -0.6 -0.1 -0.2 -0.1 -0.1 -0.6  0.4  3.5 -0.4 -0.2  0.3  2.5 -0.7 -0.3 -0.  -0.2  1.6  0.2 -0.5  0.7 -0.9 -0.1 -0.3 -0.4  1.9 -0.6 -0.4 -0.2 -0.2  0.2  0.6 -0.2 -0.  -0.5 -0.5 -0.3 -0.3 -0.6 -0.3 -1.7  0.7 -0.  -1.6 -0.2 -0.2 -0.2 -0.2 -0.  -0.2 -0.3  0.3 -0.1 -1.2 15.4  7.8 -0.2  0.2 -0.1 -0.2 -0.3 -0.1 -0.  -0.6 -0.5  2.3 -0.2  0.1 -0.3 -0.  -0.4 -2.2 -0.2 -0.7  0.5 -0.3 -1.9 -1.  -0.5  0.6 -0.1 -0.1 -0.3 -1.4 -0.8 -1.  -1.7  0.5  0.2  1.2 -0.6 -0.6 -0.4 -0.   1.7  5.1  0.2  0.3  0.7  7.3 -0.1  1.3 -0.4  0.4 -1.6 -1.3 -0.6  1.  -0.8 -0.5 -2.5 -0.3  5.9 -0.   7.6  2.4]
ty_50sample [[4 0 3 3 5 8 6 7 1 2]
 [1 5 9 4 3 2 0 8 6 7]
 [7 4 6 5 0 3 1 2 2 9]
 [3 1 9 2 8 4 5 7 0 6]
 [9 6 6 7 0 5 1 4 2 3]
 [8 7 1 4 3 9 2 0 6 5]
 [6 5 9 4 8 1 1 7 2 3]
 [6 8 4 2 7 3 9 0 1 5]
 [9 2 8 1 4 7 0 6 5 3]
 [2 7 5 4 3 0 6 8 9 1]]
tt_50sample [[4 0 9 3 5 8 6 7 1 2]
 [1 5 9 4 3 2 0 6 8 7]
 [7 4 6 5 0 3 1 8 2 9]
 [3 1 9 2 8 4 5 0 7 6]
 [9 6 8 7 0 5 1 4 2 3]
 [8 7 1 4 9 3 2 0 6 5]
 [6 5 9 4 8 0 1 7 2 3]
 [6 8 4 2 7 3 9 0 1 5]
 [9 2 8 1 4 7 6 0 5 3]
 [2 7 5 4 3 0 6 8 9 1]]
vm  [-0.9 -0.3  6.4 13.7 -0.7 -0.1 -0.3  0.3 -1.  -0.7  9.3 -0.2 -0.1 -0.1  1.1  7.8  0.8 -0.4 -0.2 -0.6 -0.8  0.1  0.6 -0.1 -1.2 -0.2  0.3 -0.5 -0.1  7.6 -0.8 -0.1 -0.4  4.9 -0.  -0.2  4.1  3.4 -0.2 -0.3  1.4  4.9  4.4 -0.5 -0.2 -0.   2.1 -0.2 -0.3  1.  -0.1 -0.1  0.   6.9 -1.4 -0.2 -0.8  9.3 -3.1  4.5  0.8 -0.3 -0.6  0.  -0.4  1.   0.4 -0.3 -0.3 -0.  -0.  -1.8 -0.5  0.2 -1.3 -0.4 -0.3 -0.3 -0.2  1.4  6.7  0.2 -0.4 -0.2 -0.1  6.1 -0.9 -0.1 -0.1 -0.1 -0.5 -0.1 -0.1  1.6 -0.2 -0.3 -0.2 -1.1  0.1 -0.1  1.9  2.5 -0.1  0.4 -0.3  1.3 -1.4 -0.2  0.5 -1.6 -0.2  0.1 -0.1  0.3 -2.5 12.5 -0.6 -1.5 -0.1 -0.4  0.7  5.7  0.1  1.3  0.6  1.9 -0.1 -1.3 -2.4 -0.4  0.9 -0.  -0.5 -0.   3.7  7.4 -0.5 -0.3 -0.5 -0.7 -0.7 -0.1 -0.4 -0.3 -0.1 -0.1 -0.1 -0.3  5.2 -0.4 -1.6  0.4 -0.3 -0.7 -0.3 -0.2 -0.6 -0.3 -0.7 -0.4  0.5  0.6 -0.2  0.1 -0.1  0.7 -0.8 -0.5 -0.2 -0.2 -0.1 -0.2 -0.  -0.3  0.5 -0.8 -0.4 -0.1  0.2 -0.  -2.1  1.5  0.  -1.6  0.3 -0.3 -0.1 -0.7  0.5 -1.9  0.4 -0.1 -0.1 -0.7  2.1  8.9 -0.2  7.1  0.3 -0.1  0.1 -0.1  0.9 -0.5 -0.  -1.  -0.  -0.2 -3.3  0.2 -0.3  2.1 -0.1  2.2 -0.5 -0.1  4.1 -0.5 -0.5 -0.4 -0.2 -0.1  0.6 -1.   2.2  4.4  3.4 -0.4  0.2  0.1 -0.6 -0.1 -0.1 -1.  -0.6 -1.5 -0.7 -0.1 -0.1 -2.2 -0.2 -0.6 -0.2 -0.1 -0.9 -0.3 -0.4  0.3 -0.4 -0.8 -1.6 -0.  -0.4 -0.2 -1.7  3.6]
vy_50sample [[2 5 6 6 7 1 3 8 4 0]
 [7 6 3 1 9 8 0 5 2 4]
 [4 2 9 0 8 1 7 5 6 3]
 [4 5 6 9 1 8 7 3 0 2]
 [4 6 9 7 1 8 5 0 3 2]
 [4 4 8 1 5 0 9 7 6 3]
 [5 4 7 6 1 3 0 2 9 8]
 [7 3 2 0 8 9 1 4 6 5]
 [4 8 9 5 7 7 1 2 0 3]
 [1 2 4 7 8 5 9 6 0 3]]
vt_50sample [[5 2 6 7 9 1 3 8 4 0]
 [7 6 3 1 9 8 0 5 2 4]
 [4 2 9 0 8 1 7 5 6 3]
 [4 5 6 9 8 1 7 3 0 2]
 [4 6 9 7 8 1 5 0 3 2]
 [4 2 8 1 5 0 9 7 6 3]
 [5 4 7 6 1 3 0 2 9 8]
 [7 3 2 0 8 9 1 4 6 5]
 [4 8 9 5 7 6 1 2 0 3]
 [1 2 4 7 8 5 9 6 0 3]]
Epoch 49710: Training cost= 0.2599, Training acc= 0.8624, Validation cost= 0.2240, Validation acc= 0.8624
Epoch 49720: Training cost= 0.2126, Training acc= 0.8624, Validation cost= 0.2296, Validation acc= 0.8624
Epoch 49730: Training cost= 0.2154, Training acc= 0.8624, Validation cost= 0.2161, Validation acc= 0.8624
Epoch 49740: Training cost= 0.2439, Training acc= 0.8624, Validation cost= 0.2253, Validation acc= 0.8625
Epoch 49750: Training cost= 0.2732, Training acc= 0.8624, Validation cost= 0.2166, Validation acc= 0.8625
Epoch 49760: Training cost= 0.2721, Training acc= 0.8624, Validation cost= 0.2290, Validation acc= 0.8625
Epoch 49770: Training cost= 0.2465, Training acc= 0.8624, Validation cost= 0.2378, Validation acc= 0.8625
Epoch 49780: Training cost= 0.2526, Training acc= 0.8624, Validation cost= 0.1915, Validation acc= 0.8625
Epoch 49790: Training cost= 0.1953, Training acc= 0.8624, Validation cost= 0.3116, Validation acc= 0.8625
Epoch 49800: Training cost= 0.2335, Training acc= 0.8624, Validation cost= 0.2237, Validation acc= 0.8625
tm  [-1.2 -0.2  8.2 -0.9 -2.1 -0.1 -0.  -0.1 -0.4 -0.7  0.2  0.8 -0.3 -0.3 11.7 -0.5 -0.2  0.1  0.8  2.3 -1.5 -0.1 -0.3 -0.  -1.1  2.5 -0.7  0.3 -1.1 -4.3 -0.7 -0.3 -0.3  4.  -0.3 -0.  -0.1  2.9 -1.8 -0.5 -0.1 -2.8 -1.3 -1.  -0.2 -0.1 -2.8 -0.2 -1.7 -1.7 -0.2 -0.2 -0.2  9.4 -0.6 -1.2 -0.7  3.7  9.7  5.3 11.1 -0.1  0.  -0.1 -0.4 -0.4 -0.1 -0.4  2.  -0.3 -0.1  1.6 -0.2 -0.  -5.9  2.  -0.2 -0.4 -0.2 -0.4 -4.2 -0.4  0.2 -0.4  0.8 -2.4 -3.2  0.1 -0.1 -0.  -0.9 -0.2 -0.  -0.6 -0.5 -0.3  0.2 -4.2 -0.6 -0.   2.9 -0.6 -0.3 -0.1  0.2 -0.2 -2.8 -0.1  0.3  3.4 -0.1 -0.4 -0.1 -0.7  5.7 -0.8  0.5  1.4 -0.2 -0.1 -0.1 -1.6 -0.1 -0.2 -0.2 14.2 -0.1 -1.8  8.5 16.4 -0.7  0.1  0.3 -0.5 -2.5 -1.6 -0.2 -0.2 -0.4 -0.4  0.1 -0.8 -0.1 -0.3 -0.  -0.1 -0.1 -0.2 -1.3 -0.2  0.7 -0.2 -0.9 -0.2 -0.2 -0.2 -0.1 -0.2  2.1 -0.5 -0.1 -1.1 -0.  -0.1  0.2 -0.2  0.6 -0.1 -0.  -0.2 -0.1 -0.2 -0.4 -0.1 -0.4  2.5 -0.3 -0.3  2.5 -0.1 -0.3 -0.2 -0.2 -2.1 -0.3 -0.4 -0.7 -0.4 -0.1 11.8 -0.1 -0.3 -0.1 -1.3 -5.  -2.8 -0.4 -1.7 -0.3 -0.1 -0.1 -0.3 -0.4 -0.1 -0.2 -3.5 -0.1 -0.1  5.4 -0.3 -0.5 -1.3 -0.5  7.8 -0.1  0.6  2.6 -1.1  0.7 -0.3 -0.2 -0.1  0.1 -0.7 -1.5 -0.5 -1.5 -0.2  2.2 -0.8 -0.3  0.  -0.2  1.4  0.1 -1.9 -0.4 -0.9  1.2 -1.9 -0.2 -0.8 -0.2 -0.1 13.3  3.9 -0.3 -0.  -1.2 -0.1 11.  -0.3 -0.9 -0.2  4.8 -4.1]
ty_50sample [[1 3 0 7 8 2 5 6 4 9]
 [2 9 4 6 1 3 7 8 0 5]
 [0 3 5 9 7 6 2 4 1 8]
 [0 9 1 5 4 6 3 7 2 8]
 [6 3 4 8 0 2 1 7 5 9]
 [3 0 4 1 9 8 7 5 2 6]
 [9 4 0 6 5 8 1 3 7 2]
 [4 9 7 5 1 2 3 6 8 0]
 [0 5 7 7 4 1 2 8 9 6]
 [7 1 3 0 8 5 9 2 4 6]]
tt_50sample [[1 3 0 7 8 2 5 6 4 9]
 [2 9 4 6 1 3 7 8 0 5]
 [0 3 5 9 7 6 2 4 1 8]
 [9 0 1 5 4 6 3 7 2 8]
 [6 3 4 8 0 2 1 7 5 9]
 [3 0 4 1 9 8 7 2 5 6]
 [9 4 0 6 5 8 1 3 7 2]
 [4 9 7 1 5 2 3 6 8 0]
 [0 5 7 3 4 1 2 8 9 6]
 [7 1 3 0 5 8 9 2 4 6]]
vm  [-0.1 -0.3  5.3 10.7 -1.  -0.1 -0.4  0.1 -0.5 -0.2  1.3 -0.5 -0.2  0.2  0.3  2.4 -0.2 -0.1 -0.3 -0.8 -1.2 -0.   0.9 -0.1 -1.2  0.3  0.  -0.2 -0.8  0.6 -1.5 -0.3 -0.5 -2.8 -0.   0.1  2.5  3.4 -0.2 -0.7  0.  -1.8  0.9 -0.9 -0.2  0.1  3.5 -0.5  4.7 10.3 -0.3 -0.2 -0.3  6.2 -0.5 -0.2 -0.1 -0.9 -1.1  7.9 -1.1 -0.  -0.7  0.  -0.7 -0.4 -0.2 -0.1 -0.2  0.3  0.4  3.   0.3 -0.  -0.8 -0.8 -0.1 -0.5  0.3 -0.1 -2.2  0.5 -0.2  0.8 -1.6 -1.8  2.5 -0.3 -0.3  0.2 -0.3 -0.  -0.2 -0.2 -0.3 -0.1 -0.4 -2.   0.7 -0.1 -0.   3.  -0.5 -0.1 -0.2 -0.1 -0.9 -0.6  0.5 -1.5 -0.5 -0.1 -0.2 -0.1 -0.1 -0.8 -0.6 -0.8 -0.1  0.   0.2  5.4  0.2 -1.1 -0.2  0.3 -0.3 -1.  -1.8 -0.4  0.7  0.   0.5 -0.2  4.7 -1.8 -0.2 -0.1  0.2  0.3 -0.9 -0.6 -0.7 -0.2 -0.2 -0.2 -0.2 -0.2 -1.8 -0.2 -1.2 -0.1  3.3 -0.6 -0.1  0.1 -0.1  0.5 -0.9 -0.3  0.7  1.1 -0.2  0.2 -0.  -0.1 -0.4 -0.5  0.2  0.2 -0.3 -0.1 -0.1 -0.  -0.2  3.2 -0.5 -0.2  0.5 -0.   1.7 -0.2 -0.2 -1.1  0.4 -0.2 -0.2 -0.6 -0.  -0.1  0.2 -0.2 -0.2 -0.4 10.3  7.3 -0.1 -0.3  0.6 -0.   0.1 -0.1 -0.2 -0.5 -0.2 -1.1 -0.1 -0.  13.6  0.1 -0.4 -1.1 -0.7 -1.  -0.7 -0.2  5.5 -0.8 -0.3  0.8 -0.  -0.2 -0.5 -1.3  3.2  0.3  2.2  0.3 -0.6  3.2 -0.6 -0.3  0.1  1.6 -0.2 -0.8 -0.  -0.3  1.2 16.7 -0.1  4.3 -0.  -0.   8.2 -0.8 -0.5  0.2 -1.2 -0.7  5.2 -0.2 -0.  -0.2 -1.1  3.5]
vy_50sample [[8 2 0 0 9 7 3 4 1 5]
 [6 7 4 9 8 3 1 0 5 2]
 [4 1 8 7 6 0 5 9 2 3]
 [9 6 8 3 2 7 5 0 1 4]
 [7 4 9 0 8 1 2 5 6 3]
 [2 1 5 8 4 3 9 6 7 0]
 [7 5 1 1 9 0 2 4 3 6]
 [8 1 4 5 6 3 7 2 0 9]
 [5 8 0 7 6 3 1 4 9 2]
 [3 2 6 8 7 4 1 0 5 9]]
vt_50sample [[8 2 6 0 9 7 3 4 1 5]
 [6 7 4 9 8 3 1 0 5 2]
 [4 1 8 7 6 0 5 9 2 3]
 [9 6 8 3 2 7 5 0 1 4]
 [7 4 9 0 8 1 2 5 6 3]
 [2 1 8 5 4 3 9 6 7 0]
 [7 5 1 8 9 0 2 4 3 6]
 [1 8 4 5 6 3 7 2 9 0]
 [5 8 0 7 6 3 1 4 9 2]
 [3 2 8 6 7 4 1 0 9 5]]
Epoch 49810: Training cost= 0.2917, Training acc= 0.8624, Validation cost= 0.2416, Validation acc= 0.8625
Epoch 49820: Training cost= 0.2191, Training acc= 0.8625, Validation cost= 0.2117, Validation acc= 0.8625
Epoch 49830: Training cost= 0.2711, Training acc= 0.8625, Validation cost= 0.2741, Validation acc= 0.8625
Epoch 49840: Training cost= 0.2865, Training acc= 0.8625, Validation cost= 0.2912, Validation acc= 0.8625
Epoch 49850: Training cost= 0.2371, Training acc= 0.8625, Validation cost= 0.2842, Validation acc= 0.8626
Epoch 49860: Training cost= 0.3622, Training acc= 0.8625, Validation cost= 0.2483, Validation acc= 0.8626
Epoch 49870: Training cost= 0.2405, Training acc= 0.8625, Validation cost= 0.2471, Validation acc= 0.8626
Epoch 49880: Training cost= 0.2793, Training acc= 0.8625, Validation cost= 0.2336, Validation acc= 0.8626
Epoch 49890: Training cost= 0.2237, Training acc= 0.8625, Validation cost= 0.2360, Validation acc= 0.8626
Epoch 49900: Training cost= 0.1821, Training acc= 0.8625, Validation cost= 0.1960, Validation acc= 0.8626
tm  [-1.5 -0.4  8.9  7.5 -1.1 -0.2 -0.2 -0.1  0.1 -0.7 -3.2  0.  -0.4  0.6  6.6  4.4 -0.1 -0.1 -0.  -0.  -1.4 -0.2 -0.1 -0.3 -0.7  0.9 -0.2 -0.1  0.9 -1.1 -1.9 -0.3 -0.4 -2.9 -0.1 -0.3 -0.5  1.7 -1.1 -0.3  0.7 -2.  -0.4 -0.6  0.   0.6 -1.   0.1 -0.6 10.9 -0.2 -0.1 -0.7  5.9 -1.4 -0.6 -0.3 -0.2  3.5  8.5  5.1 -0.1 -0.8  0.5 -1.3 -0.7 -0.2 -0.2  2.5  0.   0.8 -1.   0.1  1.6 -3.4 -0.6 -0.  -0.5  0.1 -0.4 -5.5 -0.5 -0.4  0.8 -0.1 -1.6 -2.6 -0.  -0.2 -0.2 -0.3 -0.   0.7 -1.2 -0.7 -0.2 -0.  -3.5 -0.4 -0.6  1.6  4.8  0.2 -0.2 -0.4 -0.3 -1.4 -0.5 -0.6 -0.8 -0.4 -0.4  0.8 -0.6  1.4 11.  -0.3  0.8 -0.2 -0.  -0.   2.3  1.4 -0.1  0.3  8.  -0.2 -1.   2.4  3.7 -0.5  0.2  0.5 -0.6 -1.2 -3.9 -0.4 -0.1 -0.4  1.9  0.2 -0.4 -0.2 -0.1 -0.2 -0.  -0.3 -0.1 -2.5 -0.2 -0.8 -0.3  0.8 -0.1  0.3  0.3 -0.4 -0.1  1.6 -0.6  1.5 -0.1 -0.  -0.1  0.1 -0.7 -0.5  0.1  0.5 -0.3 -0.2 -0.2 -0.1 -0.3 -0.2  3.5 -0.6 -0.4  1.7  0.5  2.1  0.4 -0.5 -1.2 -0.2 -0.2 -0.6 -0.4  0.   2.8  0.4 -0.4 -0.5 -0.5 -1.5 -0.9 -0.3 -0.6  0.2 -0.2  0.1 -0.  -0.1 -0.4 -0.1 -2.3 -0.2 -0.2 14.8 -0.2 -0.3  3.5 -0.5  7.4 -0.7 -0.2  4.9 -0.7  0.5  0.2 -0.2 -0.2 -0.8 -1.1  2.1  3.3 -0.5 -0.1 -0.7 -0.3 -0.2 -0.3  0.6  1.2 -0.6 -1.9 -0.4 -0.1  2.1  9.1  0.1  2.4 -0.1 -0.1 16.1  0.8 -0.5  0.7 -1.2 -0.4 14.1 -0.1 -0.6 -0.3 -0.3 -0.5]
ty_50sample [[8 1 7 2 6 3 9 0 4 5]
 [6 4 9 7 1 5 8 0 2 3]
 [0 7 2 4 6 9 8 1 3 5]
 [7 3 5 2 9 6 0 8 1 4]
 [4 3 5 9 7 0 8 1 2 6]
 [4 3 8 0 7 2 9 1 5 6]
 [9 9 2 3 4 7 6 1 0 8]
 [7 6 9 3 2 5 4 1 0 8]
 [2 9 6 4 7 3 8 0 5 1]
 [4 6 1 9 2 7 0 3 5 8]]
tt_50sample [[8 1 7 2 6 3 9 0 4 5]
 [6 4 9 7 1 5 8 0 2 3]
 [0 7 2 4 6 9 8 1 3 5]
 [7 3 5 2 9 6 8 0 1 4]
 [4 3 5 9 7 0 8 1 2 6]
 [4 3 0 8 7 9 2 1 5 6]
 [9 5 2 3 4 7 6 1 8 0]
 [7 6 3 9 2 5 4 1 8 0]
 [2 9 6 4 7 3 8 0 5 1]
 [4 6 1 9 2 7 0 3 5 8]]
vm  [-1.1 -0.  -2.7 -3.2 -0.9 -0.1  0.2 -0.2 -0.4 -0.2  8.4 -0.3 -0.3  0.1 -0.1  4.1 -0.1 -0.2 -0.1 -0.2 -1.7 -0.1  1.4 -0.3 -1.5  0.7 -0.5 -0.2 -0.2 -1.7  1.3 -0.5  1.7 -2.4 -0.  -0.3  1.6  3.4 -3.6 -0.5  1.1 -1.2 -0.7 -0.2 -0.3 -0.2 -0.9 -0.3 -2.1  7.4 -0.3 -0.3 -0.6 14.8 -1.6  0.1 -0.8 -2.5  4.1 -0.8  9.2 -0.1 -0.3 -0.3  1.1 -0.7 -0.1  0.4  0.8 -0.  -0.2 -0.7  0.6 -0.6 -4.7 -0.1 -0.1  0.5 -0.  -0.3 -2.  -0.4 -0.1 -0.2  1.1 -0.9 -0.9 -0.1 -0.1 -0.2 -0.7 -0.1 -0.4  0.2 -0.7 -0.2 -0.5 -3.  -0.7 -0.6  2.2  1.6 -0.3 -0.1 -0.1 -0.  -3.1  0.2  0.1 -0.2 -0.5 -0.2 -0.1 -0.6  1.5  3.7  2.  -0.5 -0.1  0.2 -0.5 -0.3 -0.2 -0.1 -0.3 -0.1 -0.3 -3.2  1.   1.  -0.2 -0.4 -0.4  1.3 11.3  8.4 -0.3 -0.1 -0.2 -0.5 -0.5 -0.1 -0.4 -0.2 -0.1 -0.1 -0.3 -0.1 -0.7 -0.   3.6 -0.1 -0.9 -0.1 -0.2 -0.  -0.6 -0.2 -0.6 -0.5 -0.3 -0.2  0.2 -0.2 -0.3 -0.1 -0.  -0.2 -0.4 -0.1  0.  -0.3 -0.3 -0.2 -0.4  1.6 -1.4 -0.5  3.7 -0.   3.3 -0.6 -0.  -1.5 -0.1 -0.2 -0.5 -0.1 -0.1  5.6 -0.1 -0.6 -0.4 -1.  -3.6 -0.4 -0.7 -0.5 -0.1 -0.  -0.2 -0.3 -0.2 -0.3 -0.2 -2.7 -0.3 -0.1  8.8 -0.3 -0.4  0.1 -0.5  8.5  1.5 -0.2  1.2 -1.1 -0.3 -0.  -0.1  0.  -0.1 -1.4  3.3  2.4  1.3 -0.4 -0.3 -0.9 -0.3  3.5 -0.2  1.3 -0.4  2.9 -0.  -1.2 -0.   8.3 -0.1  2.2 -0.1 -0.   7.2  1.2  0.2 -0.4 -1.3  1.1  4.6 -0.2 -1.9 -0.  -1.5  2. ]
vy_50sample [[1 2 6 4 8 0 9 3 7 5]
 [0 7 5 6 8 9 1 4 2 3]
 [1 9 5 4 0 2 3 6 8 7]
 [4 9 1 3 7 0 6 8 2 5]
 [6 0 1 9 2 5 4 3 7 8]
 [5 9 8 1 1 2 3 4 6 0]
 [2 6 0 8 1 5 3 9 7 4]
 [1 2 7 5 9 4 3 8 0 6]
 [5 9 0 2 7 1 8 4 3 6]
 [3 4 5 0 7 6 9 8 1 2]]
vt_50sample [[2 1 6 4 8 0 9 3 7 5]
 [0 7 5 6 8 9 1 4 2 3]
 [1 9 5 4 0 2 3 6 8 7]
 [4 9 1 3 7 6 0 8 2 5]
 [6 0 1 9 2 5 4 3 7 8]
 [5 9 8 7 1 2 3 4 6 0]
 [2 6 0 8 1 5 3 9 7 4]
 [1 2 7 5 4 9 3 0 8 6]
 [5 9 0 2 7 1 8 4 3 6]
 [3 4 5 0 7 6 9 8 1 2]]
Epoch 49910: Training cost= 0.2003, Training acc= 0.8625, Validation cost= 0.2317, Validation acc= 0.8626
Epoch 49920: Training cost= 0.2106, Training acc= 0.8625, Validation cost= 0.2478, Validation acc= 0.8626
Epoch 49930: Training cost= 0.2446, Training acc= 0.8626, Validation cost= 0.2200, Validation acc= 0.8626
Epoch 49940: Training cost= 0.3295, Training acc= 0.8626, Validation cost= 0.2292, Validation acc= 0.8626
Epoch 49950: Training cost= 0.2475, Training acc= 0.8626, Validation cost= 0.2092, Validation acc= 0.8626
Epoch 49960: Training cost= 0.2432, Training acc= 0.8626, Validation cost= 0.2930, Validation acc= 0.8627
Epoch 49970: Training cost= 0.2399, Training acc= 0.8626, Validation cost= 0.2280, Validation acc= 0.8627
Epoch 49980: Training cost= 0.2215, Training acc= 0.8626, Validation cost= 0.2252, Validation acc= 0.8627
Epoch 49990: Training cost= 0.2053, Training acc= 0.8626, Validation cost= 0.2471, Validation acc= 0.8627
Epoch 50000: Training cost= 0.2533, Training acc= 0.8626, Validation cost= 0.2076, Validation acc= 0.8627
tm  [-0.  -0.4 -1.9 -1.  -2.1  0.2  0.2 -0.2 -0.6 -0.5 -0.3  0.3 -0.1 -0.3 -0.7 -1.5 -0.1 -0.4 -0.1 -0.2 -1.1 -0.2  1.7 -0.3 -1.3  4.4  0.8 -0.3 -1.3 -1.9  3.2 -0.2  1.3  1.3 -0.1 -0.1  2.3  4.  13.3 -0.3  2.6  3.4  0.4  3.1 -0.  -0.1  3.1 -0.5  5.5  4.4 -0.3  0.   0.3 -1.3  1.4  0.7 -0.7 -0.5  1.8 -1.8 -0.8 -0.6  2.1 -0.2 -0.1 -0.5  0.1 -0.1  2.7  0.1 -0.1  6.8 -0.3 -0.3 -1.9 -0.1 -0.2 -0.1 -0.2 -0.2  6.7 -0.2 -0.1 -0.5 -1.8  4.5  7.2  0.4  0.1 -0.  -0.3  0.1 -0.2 -0.3 -0.4 -0.1  0.3 -2.1 -0.5 -0.3  0.3  3.7 -1.1 -0.2 -0.1 -0.4 -0.7  0.3 -0.1 -0.6 -0.6  0.2 -0.1 -0.2  4.8 -3.5  2.5 -0.5 -0.2  0.4 -0.3  2.3 -0.4 -0.3 -0.2 -0.9 -0.3  5.7  1.8 -1.4 -0.5 -0.  -0.2 -0.4 -2.9 -2.4  0.   0.1 -0.4 -0.5 -0.3 -1.3 -0.2 -0.4 -0.  -0.1 -0.4 -0.2  3.1 -0.1  0.2 -0.1  3.1 -0.5 -0.3 -0.2 -0.3  1.   3.2 -0.   0.5 -2.1  0.4 -0.1 -0.2 -0.8 -0.3 -1.  -0.3 -0.2  0.  -0.  -0.2 -0.2 -0.2 -0.5 -0.4 -0.1 -0.9 -0.1 -1.3  0.1 -0.3 -1.9  0.  -0.4  0.3 -0.2  0.7  5.1 -0.1 -0.2  0.1 -1.1  9.  -0.5 -0.3 -1.6 -0.1 -0.2  0.  -0.1 -0.3  0.9 -0.4 -0.   0.  -0.3 -1.1 -0.  -0.5 -1.9 -0.4 -1.3 -0.2  0.1 -2.3 -1.  -0.1 -0.1 -0.2 -0.1 -0.6 -1.5 -0.8 -1.5 -1.6 -0.3  0.1  2.  -0.2 -0.4 -0.3 -0.1  1.9  2.   1.1 -0.1  1.   1.9 -0.2 -0.1 -0.1 -0.  -0.9 -1.8 -0.2  0.1 -1.1 -0.2 -2.1 -0.1  7.6  0.4  0.2  6.4]
ty_50sample [[0 4 9 5 8 7 2 3 1 6]
 [0 1 6 5 3 9 7 8 4 2]
 [0 7 3 4 9 6 8 8 5 2]
 [0 4 7 2 1 6 3 9 8 5]
 [3 7 8 9 6 4 4 1 5 2]
 [7 3 1 5 2 0 9 4 8 6]
 [8 3 2 1 0 7 4 5 9 6]
 [9 1 6 4 3 8 0 5 7 2]
 [6 8 4 7 5 3 2 1 0 9]
 [4 6 9 7 0 1 5 8 2 3]]
tt_50sample [[0 4 9 5 8 7 2 3 1 6]
 [0 1 6 5 3 9 7 8 4 2]
 [0 7 3 4 9 6 8 5 1 2]
 [0 4 7 2 1 6 3 9 8 5]
 [3 7 8 9 6 4 0 1 5 2]
 [7 3 1 5 2 9 0 4 8 6]
 [8 3 2 1 0 7 4 5 9 6]
 [9 1 6 4 3 8 0 5 7 2]
 [6 8 4 7 5 3 2 1 0 9]
 [4 6 9 7 0 1 5 8 2 3]]
vm  [-1.2 -0.2 -2.   3.3 -1.3 -0.1 -0.5 -0.2 -0.8 -0.1 -7.2 -0.1 -0.1 -0.4 -2.1 -1.6 -0.7 -0.   0.  -1.4 -1.3 -0.4 -0.2 -0.4 -1.   0.2 -0.1 -0.2 -0.5 -2.  -0.4 -0.3 -0.  -5.5 -0.1 -0.2  2.7 -0.  13.1 -0.3  0.7  5.6 -0.   1.8 -0.4 -0.7  6.  -0.  -2.   9.8 -0.3 -0.1 -0.7 -3.3 -1.   2.7 -1.2  4.7 -0.1  3.7  5.3 -0.8 -0.4 -0.3 -0.5 -0.5 -0.5  1.   2.7 -0.2 -0.1  1.2 -0.6 -0.5 -2.2 -0.4 -0.3 -0.9  0.2  0.6 -2.1 -0.5 -0.1 -0.4  2.3  5.4 -1.1 -0.1  0.4 -0.4 -0.3 -0.2 -0.6  0.1 -0.4  0.  -0.5 -1.8 -0.7 -0.8  1.2 -0.   0.3 -0.5 -0.1 -0.6 -1.4  0.  -1.7 -1.3 -0.1 -0.2  0.  -0.3  1.2 -0.7  2.3 -0.4 -0.4  0.1 -0.3  4.8 -0.3  0.9 -0.4 -2.4 -0.2 12.1  0.9 -1.5 -0.3 -0.2 -0.  -0.3 -0.5 -5.9  0.3  0.   0.1 -0.4  1.  -0.2 -0.2 -0.4 -0.1 -0.2 -0.4 -0.1  6.8 -0.1 -0.4 -0.2  0.1 -0.  -0.2 -0.1  1.1 -1.   1.3 -0.2 -0.8 -1.5 -0.1 -0.1 -0.2  0.9  1.  -0.4 -0.2 -0.2 -0.1 -0.  -0.3 -0.3 -0.4 -1.3 -0.3 -0.3 -1.3 -0.2 -2.  -0.4  0.2 -1.3 -0.2  1.3 -0.2  0.1 -0.2  6.2 -0.5 -0.2 -0.3 -1.5 -1.5  0.  -0.4 -0.3 -0.3 -0.1 -0.5 -0.1 -0.6 -0.  -0.4 -1.1 -0.1 -0.3 -0.6 -0.4 -0.5 -1.1 -0.7  5.9  0.3 -0.4 -1.2 -0.9  0.3  0.  -0.4 -0.1 -0.5 -1.2 -0.5 -0.1 -2.  -0.5  0.1 -0.8 -0.7  2.8 -0.4 -0.3 -0.5  1.5 -0.  -0.9  0.3 -2.6 -0.2 -1.1 -0.3 -0.1  7.3 -1.2  2.2 -0.4 -1.1  0.6  4.8 -0.2  7.8 -0.   6.1  7.2]
vy_50sample [[5 5 8 0 9 4 3 7 6 2]
 [6 2 4 1 5 8 0 3 9 7]
 [0 5 8 4 2 3 1 9 6 7]
 [2 1 4 6 0 8 5 9 7 3]
 [3 7 9 6 5 2 0 1 8 4]
 [5 6 4 3 1 8 0 2 9 7]
 [8 6 3 7 4 2 9 0 5 1]
 [7 5 6 8 0 4 3 9 1 2]
 [2 0 7 9 6 1 3 5 4 8]
 [1 2 7 9 4 8 3 5 0 0]]
vt_50sample [[1 5 8 0 9 4 3 7 6 2]
 [6 2 4 1 5 0 8 3 9 7]
 [0 5 8 4 2 3 1 9 6 7]
 [2 1 4 6 0 8 5 9 7 3]
 [3 7 9 6 5 2 0 1 8 4]
 [5 6 4 3 1 8 0 2 9 7]
 [8 6 3 7 4 2 9 0 5 1]
 [7 5 6 8 0 4 3 9 1 2]
 [2 0 7 9 6 1 3 5 4 8]
 [1 2 7 9 4 8 3 5 6 0]]
Epoch 50010: Training cost= 0.2242, Training acc= 0.8626, Validation cost= 0.2466, Validation acc= 0.8627
Epoch 50020: Training cost= 0.1960, Training acc= 0.8626, Validation cost= 0.2154, Validation acc= 0.8627
Epoch 50030: Training cost= 0.2453, Training acc= 0.8626, Validation cost= 0.2188, Validation acc= 0.8627
Epoch 50040: Training cost= 0.2331, Training acc= 0.8627, Validation cost= 0.2432, Validation acc= 0.8627
Epoch 50050: Training cost= 0.1827, Training acc= 0.8627, Validation cost= 0.2459, Validation acc= 0.8627
Epoch 50060: Training cost= 0.2245, Training acc= 0.8627, Validation cost= 0.2169, Validation acc= 0.8628
Epoch 50070: Training cost= 0.1934, Training acc= 0.8627, Validation cost= 0.2028, Validation acc= 0.8628
Epoch 50080: Training cost= 0.2163, Training acc= 0.8627, Validation cost= 0.2232, Validation acc= 0.8628
Epoch 50090: Training cost= 0.2563, Training acc= 0.8627, Validation cost= 0.2358, Validation acc= 0.8628
Epoch 50100: Training cost= 0.2042, Training acc= 0.8627, Validation cost= 0.2443, Validation acc= 0.8628
tm  [-0.4 -0.1 -2.4  6.9 -1.1 -0.2 -0.3  0.4 -0.8 -0.9 -2.4 -0.3 -0.  -0.  -3.   3.1 -0.3 -0.3 -0.  -0.8 -1.1 -0.4  0.7 -0.2 -1.3 -0.1 -0.3 -0.1  0.4  4.1 -0.4  0.3 -0.2 -4.9 -0.2 -0.1  1.9 -1.6 -1.2 -0.4 -0.   2.2  2.3 -0.8 -0.  -0.2  4.9  0.   3.   2.2 -0.3  0.  -0.2 -1.6 -1.3  2.8 -0.9  5.  -2.1  3.5 -1.  -0.3 -0.6 -0.3 -0.6 -0.2 -0.1 -0.2 -0.1 -0.  -0.  -2.  -0.4 -0.2 -0.7 -0.1 -0.1 -0.2 -0.2 -0.1  2.5 -0.3 -0.2 -0.2 -0.9  3.1  2.3 -0.2 -0.  -0.2 -0.3  0.1 -0.3  1.6 -0.3 -0.1 -0.1 -1.2 -0.2 -0.1  2.9 -1.5 -0.2 -0.1 -0.1 -0.3 -0.7 -0.2 -0.8 -1.7 -0.4 -0.2  0.2 -0.6 -1.9 13.8 -0.2 -1.3 -0.3 -0.7 -0.3  5.9 -0.4 -0.4 -0.  -3.6  0.4  6.5 -1.6 -0.  -0.4 -0.2 -0.5 -0.5 16.2  8.5 -0.3 -0.2 -0.3 -0.6 -0.  -0.3 -0.3 -0.2 -0.   0.5 -0.3 -0.1  7.9 -0.3 -0.6 -0.1  2.1 -0.1 -0.1 -0.  -0.1 -0.7 -1.  -0.6 -0.5  1.4 -0.2 -0.   0.2 -0.3 -0.1 -0.5 -0.2 -0.2 -0.1 -0.1 -0.2 -0.4 -0.2 -1.7 -1.5 -0.3  0.8 -0.  -2.   1.9 -0.1 -1.6 -0.1  0.2 -0.2 -0.   0.3 -0.8 -0.  -0.1 -0.3 -1.1  8.9  5.7 -0.   5.3 -0.1 -0.1 -0.2 -0.1 -0.   0.2  0.6 -0.5 -0.2 -0.1 -0.9  0.5 -0.4  1.8 -0.3 -0.3 -0.  -0.4  3.6 -0.7 -0.2 -0.4 -0.2 -0.3  0.3 -0.8  1.4  5.6 -1.1 -0.2 -0.7  1.5  0.5 -0.2 -0.1 -0.4 -0.7  2.  -0.3  0.5  1.3 -0.5  0.2 -0.3 -0.1 -0.3  0.8 -1.3 -0.1 -0.5 -1.  -0.3 -0.9  0.2 -0.7 -0.3  4.4  2.6]
ty_50sample [[6 5 9 8 3 4 2 1 7 0]
 [3 8 1 5 4 6 9 0 7 2]
 [8 2 5 4 7 6 9 0 1 3]
 [4 1 9 6 0 5 7 8 2 3]
 [9 4 4 3 1 0 8 5 6 2]
 [8 5 9 9 6 4 7 2 3 1]
 [0 1 5 2 8 7 3 6 9 4]
 [2 3 8 5 9 0 6 1 4 7]
 [7 6 3 4 0 9 5 8 1 2]
 [1 0 6 2 4 5 8 7 3 9]]
tt_50sample [[6 5 9 8 3 4 2 1 7 0]
 [3 8 1 5 4 6 9 7 0 2]
 [8 2 5 4 7 6 9 0 1 3]
 [1 4 9 6 0 5 7 8 2 3]
 [9 7 4 3 1 0 8 5 6 2]
 [8 5 0 9 6 4 7 2 3 1]
 [0 1 5 2 8 7 3 6 9 4]
 [2 3 8 5 9 0 6 1 4 7]
 [7 6 3 4 0 9 5 1 8 2]
 [1 0 6 2 4 5 7 8 3 9]]
vm  [-0.4 -0.1 12.   1.7 -1.7 -0.4 -0.2 -0.3 -1.3  0.3 -0.   0.1 -0.3  0.  14.8 -0.7 -0.7 -0.2 -0.6 -0.1 -0.8 -0.2 -0.3 -0.3 -1.4 -0.  -0.4  0.2 -1.5  3.3 -1.4  0.7 -0.6  4.7 -0.2 -0.2  2.   3.2 -1.8 -0.4 -0.   4.6  1.9 -0.5 -0.3 -0.5 -0.6 -0.4 -0.  11.9 -0.1 -0.  -0.8 12.4 -0.1 -1.8 -0.6  6.9 -1.7  7.2  2.5 -0.6 -1.2 -0.6 -0.3 -0.3 -0.3 -0.1  2.6 -0.5 -0.2  5.1 -0.2 -1.  -4.4 -1.  -0.1 -0.5 -0.3 -0.3 -5.9 -0.1 -0.1  0.  -0.8  4.7 -0.8  0.3 -0.2 -0.3 -0.5 -0.1 -0.1 -0.1 -0.4  1.  -0.5 -3.  -0.5 -0.  -0.   8.2 -0.8 -0.3  1.7 -0.1 -2.8 -0.1  1.   0.4 -0.  -0.5 -0.   0.7 -0.2 -3.3 -0.4 -0.6 -0.2 -0.   0.  -0.5 -0.3 -0.5 -0.2 18.9 -0.1 -2.5 -2.2  2.  -0.2 -0.1  0.2 -0.1 -4.3 -2.7  0.4  0.1 -0.4 -0.6 -0.6 -0.9 -0.4 -0.3 -0.2 -0.4 -0.2  0.1 -1.4 -0.1 -0.4  0.1  3.6 -0.  -0.1 -0.4  0.6 -0.3 -0.6 -0.3 -0.3 -0.6 -0.2 -0.3 -0.2 -0.1 -0.1 -0.5 -0.3  0.   0.2  0.1  0.   0.3 -0.3  1.9 -0.7 -0.5  1.8 -0.2 -1.8 -0.8 -0.2 -1.8 -0.2  0.2 -0.4 -0.2 -0.1 -1.  -0.3 -0.1 -0.1 -0.8 -0.3  8.8 -1.  -0.1 -0.5 -0.3 -0.1 -0.1 -0.7 -0.1 -0.2 -3.8 -0.2 -0.3  3.4 -0.3 -0.3 -2.7 -0.6 -0.6 -0.3 -0.1  3.6 -0.4 -0.1  1.  -0.1 -0.  -0.4 -1.3  2.5 -1.1  0.2 -0.4  2.2 -0.1 -0.9  2.7 -0.1  0.9  0.7 -2.5  0.6 -1.1 -0.1 -4.6 -0.1 -1.8 -0.  -0.2 17.4  3.8 -0.1  0.3 -0.8 -0.6 15.4 -0.  -1.  -0.6 -1.3  0.2]
vy_50sample [[7 0 8 2 5 6 1 3 9 4]
 [9 6 1 8 5 0 3 7 2 4]
 [9 5 1 4 2 8 0 6 3 7]
 [4 9 3 8 5 7 0 6 1 2]
 [8 9 5 3 1 4 0 7 6 2]
 [6 9 4 3 5 1 8 2 7 0]
 [6 7 7 8 4 0 2 3 9 1]
 [1 7 6 0 2 3 9 5 8 4]
 [4 3 0 8 2 6 9 5 7 1]
 [7 2 9 8 0 5 3 6 4 1]]
vt_50sample [[7 0 8 2 5 6 1 3 9 4]
 [9 6 1 8 5 0 3 7 2 4]
 [9 5 1 4 2 8 0 6 3 7]
 [4 9 3 8 5 7 6 0 1 2]
 [8 9 5 3 1 4 0 7 6 2]
 [6 9 4 3 5 1 8 2 7 0]
 [6 5 7 8 4 0 2 3 9 1]
 [1 7 6 0 2 3 9 5 8 4]
 [4 3 0 2 8 6 9 5 7 1]
 [7 2 9 8 0 5 3 6 4 1]]
Epoch 50110: Training cost= 0.1782, Training acc= 0.8627, Validation cost= 0.2496, Validation acc= 0.8628
Epoch 50120: Training cost= 0.2437, Training acc= 0.8627, Validation cost= 0.2380, Validation acc= 0.8628
Epoch 50130: Training cost= 0.2190, Training acc= 0.8627, Validation cost= 0.2463, Validation acc= 0.8628
Epoch 50140: Training cost= 0.2334, Training acc= 0.8628, Validation cost= 0.3014, Validation acc= 0.8628
Epoch 50150: Training cost= 0.2709, Training acc= 0.8628, Validation cost= 0.2931, Validation acc= 0.8628
Epoch 50160: Training cost= 0.2485, Training acc= 0.8628, Validation cost= 0.2958, Validation acc= 0.8628
Epoch 50170: Training cost= 0.3608, Training acc= 0.8628, Validation cost= 0.2383, Validation acc= 0.8629
Epoch 50180: Training cost= 0.2381, Training acc= 0.8628, Validation cost= 0.2001, Validation acc= 0.8629
Epoch 50190: Training cost= 0.2646, Training acc= 0.8628, Validation cost= 0.3049, Validation acc= 0.8629
Epoch 50200: Training cost= 0.2516, Training acc= 0.8628, Validation cost= 0.2954, Validation acc= 0.8629
tm  [-0.7  1.9 -0.6  0.3 -1.7 -0.4 -0.3 -0.1  1.7 -1.  -1.5 -0.4 -0.   0.5 -0.   3.  -0.1 -0.1  0.6  2.2 -0.8 -0.3  1.8  0.1 -1.1  2.  -0.5  1.4 -0.1 -3.6 -0.9  1.   1.1 -3.6 -0.3 -0.4 -1.  -1.  -4.2 -0.2 -0.4 -1.3 -1.3 -2.1 -0.2 -0.4 -1.6 -0.4  1.1  3.3 -0.3 -0.  -0.2  4.  -0.9 -0.2 -0.4  5.2  9.4  4.8  2.7 -0.5  2.1 -0.3 -0.3 -0.1  0.1 -0.4 -0.7 -0.3 -0.2 -1.7 -0.  -0.2 -4.6  0.9 -0.3  0.3 -0.4 -0.3 -3.1 -0.7  0.7 -0.7 -0.8 -1.  -1.9  0.5 -0.3  0.7 -0.3 -0.1 -0.1 -1.4 -0.6 -0.3  1.1 -3.8 -0.6 -0.2  2.9 -2.  -0.6 -0.4  0.5 -0.5 -1.6 -0.2 -0.6  0.7  0.3  0.8  0.3 -1.   4.2 10.8 -0.6  2.  -0.1 -0.4 -1.  -1.  -0.8  0.9 -0.  -0.2 -0.1 -0.3  8.8  5.1 -0.2 -0.7 -0.9 -0.3 15.3  8.   0.4  0.2  0.9 -0.3 -0.  -0.8 -1.  -0.1 -0.1  0.3 -0.3  0.5  5.  -0.3 -0.1 -0.2  3.1 -0.1 -0.2 -0.1 -0.7 -0.2 -0.4  0.1 -0.9 -0.2  0.5 -0.1  0.5 -0.2  0.5  0.1 -0.3 -0.1 -0.   0.4 -0.1 -0.5 -0.3 -0.7 -1.7  0.4  4.5 -0.3 -0.3 -0.2 -0.2 -2.1 -0.3 -0.7 -0.3 -0.2  0.1  9.5 -0.2 -0.3 -0.2 -1.  -0.7 -3.3 -0.4 -1.4 -0.6 -0.1 -0.3 -0.3 -0.3 -0.3 -0.2 -1.6 -0.3 -0.1  5.1  0.4 -0.2  4.6  0.   2.5 -0.2 -1.1  8.  -1.  -0.9 -0.5 -0.3  0.5  0.1 -1.5  1.   4.2 -1.4  3.3 -0.9  0.5  0.5 -0.2 -0.3  0.7 -0.6  0.2 -0.4 -0.5  3.3 -0.7 -0.1 -0.4  0.3 -0.2 10.3 -0.5 -0.5 -0.6 -1.8  3.1  7.4 -0.2 -2.5 -0.2  4.7 -0.8]
ty_50sample [[6 8 3 1 5 2 0 4 9 7]
 [0 8 3 7 5 4 6 2 1 9]
 [5 4 8 0 9 1 6 2 3 7]
 [8 0 2 9 4 7 3 1 5 6]
 [5 3 7 6 6 1 9 2 8 4]
 [4 1 8 6 2 3 7 9 5 0]
 [1 2 6 3 7 4 9 0 5 8]
 [1 6 8 7 2 9 5 4 3 0]
 [6 8 7 1 0 4 2 9 5 3]
 [6 7 2 4 9 8 5 0 3 1]]
tt_50sample [[6 8 3 1 2 5 0 4 9 7]
 [0 8 3 7 5 4 6 2 1 9]
 [5 4 8 0 9 1 6 2 3 7]
 [8 0 2 9 4 3 7 1 5 6]
 [5 3 7 6 0 1 9 2 8 4]
 [4 1 8 6 2 3 7 9 5 0]
 [1 2 6 3 7 4 9 0 5 8]
 [1 6 8 7 2 9 5 4 3 0]
 [6 8 7 1 0 2 4 9 5 3]
 [6 7 2 4 9 8 0 5 3 1]]
vm  [-0.9 -0.2  9.4  5.3 -1.  -0.4 -0.3 -0.1  0.3  0.3  5.8 -0.3 -0.3 -0.1  8.7 -0.7 -0.2 -0.3  0.1  0.3 -1.1 -0.2 -0.5 -0.1 -0.8  1.4 -0.2 -0.4 -0.7 -1.8  0.7 -0.  -0.1 14.7 -0.2 -0.4 -0.8 -2.3 -4.9 -0.   0.2  1.1 -0.9 -1.8 -0.2 -0.2 -1.1  0.2 -0.5 -1.6 -0.2 -0.2 -0.3  1.4 -0.5 -1.1 -0.8  6.   8.6  0.   4.7 -0.1  0.  -0.   0.6 -0.4 -0.3 -0.1  3.4 -0.2 -0.  -0.3 -0.2  0.  -4.5  1.1 -0.1  1.  -0.1 -0.6  6.6 -0.2 -0.3  1.   0.6  2.6 -2.1 -0.2 -0.2 -0.3 -0.1 -0.2 -0.  -1.2 -0.9 -0.1  1.3 -3.8 -1.1 -0.5  0.   5.8  0.3 -0.  -0.4 -0.9 -1.8  0.2  2.  -0.3 -0.1 -0.  -0.4 -0.8  6.8  1.4 -0.1  1.6 -0.  -0.4 -0.4 -0.2  0.7 -0.3 -0.  10.6 -0.1  1.5  8.5  2.8 -0.4 -0.6 -0.5 -0.6  6.4 22.2 -0.2 -0.1 -0.3 -0.4  1.4 -0.3  0.8 -0.1 -0.2 -0.3 -0.2 -0.1 -1.3 -0.3 -0.7 -0.1 -1.4  1.1 -0.1  0.2 -0.6 -0.6 -0.9  0.  -0.1  0.8 -0.3 -0.1 -0.5 -0.5 -0.3 -0.1 -0.1 -0.1 -0.2 -0.1 -0.3 -0.4 -0.2  1.3 -0.9  0.2  5.1 -0.3 -0.8 -0.3 -0.2 -1.4 -0.2 -0.2 -0.3 -0.6 -0.4  4.4 -0.  -0.3 -0.4 -0.7 -1.8 -2.8 -0.2 -1.8  0.3 -0.2  0.1 -0.1 -0.3 -0.2 -0.5 -2.1 -0.1 -0.2 -2.4  0.  -0.6  0.1 -0.6  3.7 -1.  -0.2  8.7 -1.1 -0.  -1.  -0.2 -0.2  0.5 -0.6  4.7 -0.6 -2.1 -0.1 -0.5 -0.   2.2 -0.  -0.2 -0.8 -0.5 -2.2 -0.3 -0.4  3.2 -0.8 -0.1 -0.3 -0.4 -0.1 -0.9 -0.  -0.2 -0.7 -1.1  0.3 -1.9 -0.1 -2.8 -0.3  3.1 -0.1]
vy_50sample [[6 7 1 0 5 3 9 2 4 8]
 [2 7 8 0 5 6 9 1 4 3]
 [5 7 1 3 2 2 9 6 4 8]
 [2 6 8 3 0 7 1 1 5 4]
 [3 4 0 9 7 5 2 8 1 6]
 [9 8 1 2 7 4 3 0 6 5]
 [5 1 0 2 9 9 4 6 7 3]
 [5 6 4 3 8 2 9 0 1 7]
 [8 0 3 9 2 5 6 1 4 7]
 [4 8 1 7 0 9 5 6 3 2]]
vt_50sample [[6 7 1 0 5 3 9 2 4 8]
 [2 7 8 5 0 6 9 1 4 3]
 [5 7 1 3 2 0 9 6 4 8]
 [2 6 8 3 0 7 9 1 5 4]
 [3 4 0 9 7 5 2 8 1 6]
 [9 8 1 7 2 4 3 0 6 5]
 [5 1 0 2 8 9 4 6 7 3]
 [5 6 4 3 8 2 9 0 1 7]
 [8 0 3 9 2 5 6 1 4 7]
 [4 8 7 1 0 9 5 6 3 2]]
Epoch 50210: Training cost= 0.2404, Training acc= 0.8628, Validation cost= 0.2494, Validation acc= 0.8629
Epoch 50220: Training cost= 0.3230, Training acc= 0.8628, Validation cost= 0.2462, Validation acc= 0.8629
Epoch 50230: Training cost= 0.2248, Training acc= 0.8628, Validation cost= 0.2533, Validation acc= 0.8629
Epoch 50240: Training cost= 0.2163, Training acc= 0.8628, Validation cost= 0.2123, Validation acc= 0.8629
Epoch 50250: Training cost= 0.2260, Training acc= 0.8628, Validation cost= 0.2206, Validation acc= 0.8629
Epoch 50260: Training cost= 0.1935, Training acc= 0.8629, Validation cost= 0.1847, Validation acc= 0.8629
Epoch 50270: Training cost= 0.3036, Training acc= 0.8629, Validation cost= 0.2390, Validation acc= 0.8629
Epoch 50280: Training cost= 0.2520, Training acc= 0.8629, Validation cost= 0.2368, Validation acc= 0.8630
Epoch 50290: Training cost= 0.3020, Training acc= 0.8629, Validation cost= 0.2117, Validation acc= 0.8630
Epoch 50300: Training cost= 0.2512, Training acc= 0.8629, Validation cost= 0.2749, Validation acc= 0.8630
tm  [-0.8 -0.1 -2.9 -1.  -1.6  0.6 -0.3 -0.1 -2.  -0.5 -0.6 -0.2 -0.1 -0.1 -1.4 -1.3  0.7 -0.7 -0.7 -0.7 -0.7 -0.1 -0.2  0.  -1.1  0.9 -0.2 -0.3 -1.4  6.8  3.5 -0.  -0.3  0.4 -0.1 -0.1  4.7 -1.2  1.4 -0.1  1.7  8.3  3.6  2.2 -0.1 -0.2  4.2  0.5 -0.1  9.2 -0.2 -0.   1.4 -1.8  0.6  1.1 -0.7 -0.3 -2.8 -2.6  0.3 -0.9 -0.4 -0.3 -0.7  0.1 -0.  -0.2  1.4 -0.2  0.1  4.  -0.2 -0.6 -1.  -0.6 -0.2 -0.7 -0.  -0.2 10.3  0.7 -0.1 -0.8 -0.2  8.   5.1  0.1 -0.1 -0.4 -0.3 -0.1 -0.1  3.3 -0.5 -0.3 -0.5 -0.7 -0.1 -0.4  0.7  3.6 -0.2 -0.2 -0.1  0.8 -1.   1.6  0.4 -1.9 -0.6 -0.1  0.1  1.  -0.7 -2.2 -0.1 -1.4 -0.2 -0.4 -0.1  7.5 -0.3  1.3 -0.2 -1.8 -0.3  7.5 -2.5 -3.9 -0.1 -0.1  0.3  0.2  6.6  8.8 -0.2  0.2 -0.1 -0.8  0.9 -0.6  0.4 -0.1 -0.1 -0.2 -0.1 -0.1  6.   1.  -0.1 -0.1 -0.4  1.7 -0.4 -0.2 -0.3  1.4 -0.4 -0.4 -0.9 -0.4 -0.1 -0.1 -0.2  1.8  0.7 -0.8 -0.1 -0.1  0.1 -0.  -0.1  0.  -0.3 -0.9 -0.8 -0.4  0.1 -0.1 -2.  -0.1 -0.1 -1.6 -0.3 -0.1 -0.6 -0.6 -0.2 -1.6  0.1 -0.1  0.2 -1.4  2.8 10.3 -0.1  1.9 -0.3  0.2 -0.2 -0.3 -0.2 -0.  -0.1  0.6 -0.1 -0.3 -3.  -0.1  1.8 -1.9 -0.5  2.8  1.4 -0.5 -1.2 -0.8 -0.5 -0.5 -0.1  0.2 -0.4 -0.8  3.6 -1.1 -2.1 -1.   0.5 -0.4 -0.4 -0.5 -0.3 -1.   2.2  3.9 -0.6 -0.3 -0.1 -0.7 -0.2 -0.6 -0.   0.2 -1.8 -1.3 -0.4 -0.3 -1.  -0.5 -2.7 -0.1  0.9  0.1 -0.  14.1]
ty_50sample [[4 5 0 6 9 1 8 8 2 3]
 [2 7 6 5 4 8 1 9 0 3]
 [9 1 4 6 7 8 2 0 3 5]
 [4 5 3 1 9 7 6 8 2 0]
 [2 6 1 5 9 8 4 3 0 7]
 [2 4 5 7 1 0 3 9 8 6]
 [5 6 8 2 7 3 0 4 9 1]
 [6 0 9 5 3 8 7 1 2 4]
 [0 9 8 1 4 2 3 5 7 6]
 [6 7 0 5 8 3 1 2 9 4]]
tt_50sample [[4 5 0 6 9 1 8 7 2 3]
 [2 7 6 5 4 8 1 9 0 3]
 [9 1 4 6 7 8 2 0 3 5]
 [4 5 3 1 9 7 8 6 2 0]
 [2 6 1 5 9 8 4 3 0 7]
 [2 4 5 7 1 0 3 9 8 6]
 [5 6 8 2 7 3 0 4 9 1]
 [6 0 9 5 3 8 7 1 2 4]
 [0 8 9 1 4 2 3 7 5 6]
 [6 7 0 5 8 3 2 1 9 4]]
vm  [-1.1 -0.2 -2.7  5.3 -0.6 -0.3 -0.3 -0.2 -0.9 -0.7  5.4  0.  -0.3 -0.2 -2.9  2.  -0.3  0.7 -0.1 -0.5 -1.4 -0.   2.1 -0.4 -1.1  1.1 -0.3 -0.2 -1.4 -2.4 -0.9 -0.5 -0.3 -7.1 -0.1  0.   5.   5.3  0.1 -0.7  0.6 -1.6 -0.2 -0.6 -0.1  0.4  2.3 -0.2 -1.2  6.7 -0.2 -0.3 -0.6  6.8 -0.3  2.9 -0.8 -0.7 -0.   5.2  3.5  0.5 -0.2 -0.  -0.8  1.2 -0.2 -0.5 -0.3  0.6 -0.1  3.2 -0.2 -0.2 -0.9 -0.3 -0.1 -0.5 -0.1 -0.  -1.7 -0.2 -0.1  1.2  1.3 -1.2 -1.4 -0.  -0.3 -0.1 -0.7 -0.2 -0.2  0.2 -0.1 -0.  -0.1 -2.2 -0.5  0.6  3.1 -1.3 -0.5 -0.3 -0.  -0.3 -1.4 -0.4  2.3 -1.1 -0.7 -0.3  0.  -0.1  0.5 -1.3 -0.1 -1.2 -0.2 -0.2 -0.3  5.1 -0.3 -0.  -0.4 -3.8 -0.2 -0.9 -0.6  0.3 -0.7 -0.3  0.4 -0.3 13.3 -1.3 -0.4  0.  -0.4 -0.2 -1.  -0.7 -1.1 -0.2 -0.1 -0.4 -0.3 -0.1  2.7 -0.2 -0.5 -0.1  1.4 -1.   0.4 -0.   1.1 -1.1 -0.5 -0.3  1.  -0.1 -0.1 -0.1 -0.1 -0.5 -0.3 -0.3 -0.5 -0.1 -0.3 -0.5 -0.2 -0.2 -0.1 -0.5 -0.6 -0.3  0.5  0.1 -0.1 -0.  -0.2 -1.6  0.  -0.1 -0.4  2.4 -0.2  6.9 -0.2 -0.3 -0.2 -0.5 -0.6  3.  -0.3 -0.3 -0.2 -0.1  0.4  0.1 -0.3 -0.4 -0.4 -1.7 -0.2 -0.1  9.8 -0.3 -0.5 -1.9 -0.3  5.3  0.  -0.1  2.9 -0.8 -0.3  0.  -0.2 -0.1 -0.2 -1.2  2.1 -0.1  4.1  1.3 -0.6  0.7 -1.  -0.4 -0.1  1.8  2.1  2.  -0.2 -0.5  0.2 10.9  0.   2.6 -0.2 -0.2  7.1 -0.4 -0.2  1.2 -1.4 -0.5  3.7 -0.1  0.1 -0.1 -1.3  2. ]
vy_50sample [[2 8 0 6 6 9 3 4 5 7]
 [3 4 0 6 2 1 8 7 9 5]
 [0 3 1 1 8 8 6 7 4 2]
 [7 0 9 5 3 4 8 2 1 6]
 [7 6 2 4 9 0 3 5 1 8]
 [6 4 1 5 2 3 9 0 8 7]
 [8 4 9 1 3 7 0 0 5 2]
 [1 3 2 5 0 9 4 7 6 8]
 [1 0 2 7 7 6 4 3 5 9]
 [8 0 9 4 5 6 7 2 3 1]]
vt_50sample [[2 8 1 0 6 9 3 4 5 7]
 [3 4 0 6 2 1 8 7 9 5]
 [0 3 1 9 5 8 6 7 4 2]
 [7 0 9 5 3 4 8 2 1 6]
 [7 6 2 4 9 0 3 5 1 8]
 [6 4 1 5 2 3 9 0 8 7]
 [8 4 9 1 3 7 6 0 5 2]
 [1 3 2 5 0 9 4 7 6 8]
 [1 0 2 8 7 6 4 5 3 9]
 [8 0 9 4 5 6 2 7 3 1]]
Epoch 50310: Training cost= 0.2229, Training acc= 0.8629, Validation cost= 0.2357, Validation acc= 0.8630
Epoch 50320: Training cost= 0.2047, Training acc= 0.8629, Validation cost= 0.2602, Validation acc= 0.8630
Epoch 50330: Training cost= 0.2638, Training acc= 0.8629, Validation cost= 0.2339, Validation acc= 0.8630
Epoch 50340: Training cost= 0.2142, Training acc= 0.8629, Validation cost= 0.1950, Validation acc= 0.8630
Epoch 50350: Training cost= 0.2085, Training acc= 0.8629, Validation cost= 0.2526, Validation acc= 0.8630
Epoch 50360: Training cost= 0.2047, Training acc= 0.8629, Validation cost= 0.2587, Validation acc= 0.8630
Epoch 50370: Training cost= 0.2264, Training acc= 0.8630, Validation cost= 0.2271, Validation acc= 0.8630
Epoch 50380: Training cost= 0.2502, Training acc= 0.8630, Validation cost= 0.2797, Validation acc= 0.8630
Epoch 50390: Training cost= 0.2359, Training acc= 0.8630, Validation cost= 0.2000, Validation acc= 0.8630
Epoch 50400: Training cost= 0.1719, Training acc= 0.8630, Validation cost= 0.2197, Validation acc= 0.8631
tm  [-1.3 -0.1 -2.1 -2.  -1.4 -0.1 -0.4 -0.2 -1.2 -0.8  5.5 -0.6  0.1 -0.  -0.5 -0.9  0.3 -0.4  1.6 -0.4 -1.  -0.5  0.5 -0.3 -1.6  2.5 -0.5  1.9 -1.1 -1.4  1.3 -0.1 -0.9 -1.4 -0.1 -0.3  2.8 -0.7 -2.8  0.2 -1.4  4.5 -0.  -0.9 -0.3  0.8 -0.7 -0.  -2.6  6.  -0.3 -0.  -0.6  7.5  0.3  0.2 -0.7  3.7  0.2 -0.9  7.2  0.4 -0.4 -0.3 -0.3  0.6 -0.3 -0.2  0.6 -0.2  0.4  5.  -0.1  0.6 -3.   0.1 -0.  -0.  -0.1 -0.4 -0.3 -0.6 -0.2 -0.3  3.4  5.6 -1.9  0.1 -0.2  0.2 -0.8 -0.3 -0.1  0.7 -0.8  1.   0.5 -3.  -0.6 -0.4  3.4  2.8 -0.1 -0.2 -0.3  0.8 -2.   0.   1.  -0.7 -0.2 -0.3 -0.3 -0.1  2.2 -1.7 -0.1 -0.8 -0.2  0.3 -0.3  2.9 -0.1 -0.2 -0.2 -0.6  0.1 -1.1 -0.1 -0.7 -0.4 -0.6 -0.5 -0.5 12.2 11.1 -0.3  0.1  1.1 -0.5 -0.3 -0.6 -0.1 -0.3 -0.4  0.4 -0.3 -0.1  4.9 -0.2  2.1 -0.2 -1.2  1.3 -0.1 -0.1 -0.1  0.7 -1.2 -0.5 -0.4  1.1  0.1 -0.  -0.3 -0.6 -0.  -0.4 -0.2 -0.1 -0.1  0.1 -0.1 -0.2 -0.2 -1.  -0.5 -0.3  2.9 -0.2 -1.5 -0.2 -0.3 -2.   0.5 -0.  -0.9 -0.4 -0.   3.6 -0.1 -0.4 -0.2 -0.9 -2.8  1.6 -0.4 -0.7 -0.3 -0.1 -0.4  0.7 -0.4 -0.   0.1 -2.9  0.3 -0.2 -1.8  0.1 -0.3 -2.1 -0.2  9.8  0.6 -0.2  3.3 -0.6 -0.3 -0.7 -0.1 -0.2 -0.1 -1.3  5.7 -0.8 -0.5  0.3 -0.  -0.5 -0.5  0.7 -0.6 -0.7  3.1  1.8 -0.4 -0.3 -0.  -2.4 -0.1 -0.8 -0.4  0.2  2.7  2.7  0.2 -0.6 -1.3 -0.3  0.1 -0.1 -1.7 -0.3 -0.8  4.4]
ty_50sample [[1 6 0 5 2 4 8 9 7 3]
 [6 4 3 0 8 2 1 5 5 7]
 [8 3 6 4 0 9 7 5 2 1]
 [8 4 1 2 0 9 3 7 6 5]
 [1 5 8 8 2 0 7 9 6 3]
 [7 0 8 5 6 1 4 3 2 9]
 [4 2 3 3 7 8 1 0 6 5]
 [8 5 7 4 9 0 2 1 6 3]
 [8 4 4 3 9 0 2 5 1 6]
 [8 8 1 2 4 7 0 6 5 3]]
tt_50sample [[1 6 0 5 2 4 8 9 7 3]
 [6 4 3 0 8 2 9 1 5 7]
 [8 3 6 4 0 9 7 5 2 1]
 [8 4 1 2 0 9 3 7 6 5]
 [1 5 8 4 2 0 7 9 6 3]
 [7 0 8 5 6 1 4 3 2 9]
 [4 2 3 9 7 8 1 0 6 5]
 [8 5 7 4 9 0 2 1 6 3]
 [4 8 7 3 0 9 2 5 1 6]
 [9 8 1 2 4 7 0 6 5 3]]
vm  [-0.3 -0.2  5.1 -1.1 -1.7 -0.5 -0.1 -0.1 -0.9 -0.4 -5.1 -0.1 -0.3 -0.4  7.2 -0.6 -0.3  0.4  1.4 -1.6 -1.4 -0.3 -0.8 -0.2 -1.2 -0.2 -0.3 -0.2 -0.7  3.5  1.2 -0.4 -0.2  8.1 -0.2 -0.2  2.8 -0.1 11.2 -0.7 -0.5 -4.4 -0.2  1.9  0.1  0.2  5.9 -0.3  0.5 -1.7 -0.3 -0.2 -0.6 -2.8 -1.1 -0.8 -0.5 -3.2 -1.6 -0.6 -0.7 -0.1 -0.9 -0.2 -1.  -0.5 -0.3 -0.2 -0.  -0.  -0.  -0.3 -0.4 -0.3 -2.   1.8 -0.2 -0.6 -0.1  0.5 -0.2 -0.5 -0.5  1.  -0.7 -4.1  4.5  0.1 -0.3 -0.3 -0.6 -0.2  0.1  1.8 -0.1 -0.2 -0.6 -1.4 -0.9 -0.5  1.5  3.2 -0.5 -0.1 -0.3 -0.  -1.6 -0.2 -1.5 -1.8  0.5  0.  -0.1 -0.3 -0.3 -0.2  1.  -0.6 -0.  -0.5 -0.5  6.2 -0.1 -0.3 -0.2  8.7 -0.1  9.9 -2.1  7.2 -0.2  0.3  0.4 -0.2 -5.8 -3.1 -0.3 -0.2  0.1 -0.3 -0.6 -0.2 -0.6 -0.4 -0.1 -0.  -0.3 -0.1 -3.7 -0.2  0.9 -0.1  1.6 -0.6 -0.1 -0.  -0.3 -0.7  1.  -0.5  0.2 -1.2 -0.1 -0.2 -0.1  0.5 -0.6  0.7 -0.4 -0.1 -0.1 -0.2 -0.4 -0.5  0.   5.   0.2 -0.2 -0.9  0.4  2.9 -0.3 -0.2 -1.  -0.2 -0.5  0.7 -0.6 -0.4 -0.8 -0.1  0.4 -0.6 -1.2  7.2  8.2 -0.5  0.1  0.3 -0.1 -0.1 -0.2  0.4 -0.2 -0.3 -0.8 -0.2 -0.2 10.9 -0.3 -0.7 -0.6 -0.7 -0.2  2.3 -0.1 -1.6 -0.6 -0.4 -0.3 -0.1 -0.1 -0.3 -0.4 -1.7  0.6 -1.2 -0.2  1.2 -0.2 -0.9  0.6  0.1  1.3 -1.1 -0.7 -0.1 -0.3 -0.7 21.3  0.1  5.6 -0.  -0.4  2.5 -1.2 -0.1 -0.5 -0.7 -0.6 -0.1 -0.2  6.6 -0.1  7.3 -1.3]
vy_50sample [[7 3 4 8 0 0 1 6 2 5]
 [2 3 3 7 0 4 8 6 1 5]
 [3 8 8 0 4 2 5 6 9 9]
 [6 8 9 4 7 3 0 5 2 1]
 [1 8 9 0 2 4 6 3 7 5]
 [1 9 9 4 8 3 6 7 5 2]
 [9 6 0 1 8 5 7 2 4 3]
 [3 7 6 5 8 0 4 2 2 1]
 [6 5 2 3 7 1 0 4 9 8]
 [5 4 3 0 6 8 9 1 2 7]]
vt_50sample [[7 3 4 8 9 0 1 6 2 5]
 [2 3 9 7 0 4 8 6 1 5]
 [3 1 8 0 4 2 5 7 6 9]
 [6 8 9 4 7 3 0 5 2 1]
 [1 8 9 0 2 4 6 3 5 7]
 [1 0 9 4 8 3 6 7 5 2]
 [9 6 0 1 8 5 2 7 4 3]
 [3 7 6 5 8 0 4 9 2 1]
 [6 5 2 3 7 1 0 4 9 8]
 [5 4 3 0 6 8 9 1 2 7]]
Epoch 50410: Training cost= 0.2275, Training acc= 0.8630, Validation cost= 0.1946, Validation acc= 0.8631
Epoch 50420: Training cost= 0.1942, Training acc= 0.8630, Validation cost= 0.2253, Validation acc= 0.8631
Epoch 50430: Training cost= 0.2306, Training acc= 0.8630, Validation cost= 0.2605, Validation acc= 0.8631
Epoch 50440: Training cost= 0.2478, Training acc= 0.8630, Validation cost= 0.2273, Validation acc= 0.8631
Epoch 50450: Training cost= 0.1888, Training acc= 0.8630, Validation cost= 0.2749, Validation acc= 0.8631
Epoch 50460: Training cost= 0.2255, Training acc= 0.8630, Validation cost= 0.2151, Validation acc= 0.8631
Epoch 50470: Training cost= 0.2696, Training acc= 0.8630, Validation cost= 0.2273, Validation acc= 0.8631
Epoch 50480: Training cost= 0.2201, Training acc= 0.8631, Validation cost= 0.2012, Validation acc= 0.8631
Epoch 50490: Training cost= 0.2532, Training acc= 0.8631, Validation cost= 0.2105, Validation acc= 0.8631
Epoch 50500: Training cost= 0.3042, Training acc= 0.8631, Validation cost= 0.2669, Validation acc= 0.8631
tm  [-0.6 -0.2  8.8 22.6 -1.7  0.1 -0.4 -0.1 -1.  -0.5  6.1 -0.3  0.1  0.3 -1.3 -1.5 -0.5 -0.6 -0.  -1.2 -1.1 -0.4 -0.5 -0.3 -0.5  2.6 -0.3 -0.1 -1.6 -2.6 -0.2 -0.3 -0.3  9.  -0.  -0.2  3.   4.4 25.2 -0.4  1.5 -0.6  0.3 -0.1 -0.2 -0.   8.3 -0.2  2.9 -2.2 -0.2  0.1  0.  -1.9  4.1  1.7 -0.6  7.2 -0.1  3.5 -1.4 -0.2 -0.3 -0.2 -0.4  0.  -0.4 -0.5  3.3 -0.2 -0.   6.5 -0.1 -0.3  5.1 -0.2 -0.3  0.3 -0.  -0.2 21.2 -0.2 -0.2 -0.4 -0.6 -0.5 -0.6 -0.1 -0.2 -0.2 -0.3  0.5 -0.1 -0.1 -0.4 -0.1  1.  -0.5 -0.2 -0.2  1.9  0.1 -0.2 -0.3 -0.4 -0.3  1.9 -0.3  1.5 -2.1 -0.5 -0.  -0.3 -0.1  2.1 -3.2  0.4 -0.9 -0.1 -0.1 -0.   9.   0.9  1.  -0.2 -1.5 -0.2  7.   1.  -1.4 -0.4 -0.4 -0.5 -0.5 -5.6 -2.2  0.1 -0.  -0.2 -0.4  0.2 -0.6  0.3 -0.2 -0.2 -0.1 -0.  -0.1 -0.1 -0.2 -2.3  0.  -0.2  1.  -0.1  0.1 -0.2 -0.5  3.7 -0.4 -0.5 -1.6 -0.1 -0.  -0.2 -0.2  0.7 -0.5 -0.1 -0.4 -0.2 -0.2 -0.1 -0.1 -0.3  0.4  2.6 -0.3 -2.2 -0.1 -1.5 -0.1 -0.  -1.2 -0.2  1.5 -0.3 -0.5  0.2  7.3 -0.2 -0.2 -0.1 -0.9 10.  -0.1 -0.2 -0.6 -0.2 -0.  -0.5 -0.1 -0.5  0.  -0.3  3.5  0.3 -0.3 -2.2 -0.1 -0.2 -2.4 -0.4 -0.3 -0.5 -0.2 -0.4 -1.3 -0.2 -0.3 -0.2 -0.1  1.4 -0.3 -2.2 -1.8 -1.2 -0.2 -0.1  0.7 -0.5 -1.5 -0.1 -0.7  4.2 -2.1 -0.4  1.9  1.7 11.8 -0.2  2.6 -0.2 -0.  -4.3 -2.2 -0.1 -0.2 -1.   0.6 -5.5 -0.1 14.6 -0.2  5.4  5.8]
ty_50sample [[9 0 3 7 5 2 1 8 4 6]
 [5 3 7 4 2 1 6 8 9 0]
 [8 6 5 9 7 1 4 3 0 2]
 [4 6 9 3 1 0 5 2 8 7]
 [7 7 3 6 6 2 0 8 4 5]
 [9 8 6 1 3 2 5 4 7 0]
 [2 6 1 0 3 4 9 5 8 7]
 [1 0 2 5 3 8 9 6 4 7]
 [4 6 2 0 3 1 5 8 8 7]
 [0 4 3 8 7 7 5 1 9 6]]
tt_50sample [[9 0 3 7 5 2 1 8 4 6]
 [5 3 7 4 2 1 6 8 9 0]
 [8 6 5 9 7 1 4 3 0 2]
 [4 6 9 3 1 0 5 2 8 7]
 [7 9 1 3 6 2 0 8 4 5]
 [9 8 6 1 3 2 5 4 7 0]
 [2 6 1 0 3 4 9 5 8 7]
 [1 0 2 5 3 8 9 4 6 7]
 [4 6 2 0 3 1 5 9 8 7]
 [0 4 3 8 7 2 5 1 9 6]]
vm  [-0.6 -0.4  9.9  6.5 -1.8 -0.1  0.3 -0.2 -1.   3.9 -8.9 -0.4 -0.1  0.1 11.4 -1.8 -0.4 -0.4 -1.8 -0.8 -1.3 -0.1 -0.7 -0.1 -1.  -0.3  0.5 -0.6 -0.9  6.5 -1.6  0.6  0.4 -0.2 -0.3 -0.5  0.1 -2.6 -4.4  0.8  4.4  4.   0.2 -0.7 -0.3 -1.1  0.4 -0.6  0.8 15.9 -0.2 -0.2 -0.6 -1.5 -0.7 -1.4 -0.9  3.  -1.   8.3  0.8 -0.9 -0.2 -0.4 -0.8 -0.2 -0.1 -0.4 -0.2 -0.2 -0.5  1.7 -1.1 -0.8 -4.5 -0.3 -0.2  1.2 -0.3  1.2 -5.8  1.4 -0.3 -0.6 -1.1  5.3 -0.2 -0.1 -0.3 -0.9  0.7 -0.3 -0.5 -0.1 -0.8 -0.3 -0.3 -2.9  0.  -0.9 -1.6  6.3 -0.1  0.1  0.2 -0.  -2.3 -0.3 -2.5 -1.3  0.3 -0.  -0.2 -0.4  2.9 -2.3 -1.5  0.3  0.4 -1.  -0.2  2.6 -0.6 -0.3 -0.4 14.6 -0.1  6.8 -1.9 -0.8  1.4 -0.4 -0.7  1.4  3.5  0.   0.3 -0.   0.2 -0.1  1.4 -0.3 -0.2 -0.4 -0.1  0.2 -0.6  0.9 -1.1 -0.2 -1.3 -0.3  1.9  0.3 -0.2 -0.2 -0.8  1.5 -1.5 -0.4 -0.2  0.4 -0.1 -0.1 -0.4  2.9 -0.4 -0.6 -0.7 -0.2 -0.1 -0.1 -0.   0.7 -0.4  0.1 -1.4 -0.2  4.8 -0.3 -0.8 -0.4  1.1 -1.1 -0.1 -1.1 -0.4 -0.7  0.5 -1.4 -0.1 -0.2 -0.1 -0.4  1.   7.3 -0.7 -0.9 -0.  -0.1 -0.4 -0.3  0.2 -0.2  0.2 -2.1 -0.4 -0.1  9.3  0.6 -0.4 -0.8 -0.4 -0.2 -0.9 -0.2  7.  -1.1 -0.8 -0.6  0.  -0.  -0.8 -1.6  5.6 -0.5 -2.1 -0.5  0.4  0.8 -0.5  2.5 -0.2 -0.  -0.8 -1.8 -0.2 -1.2  2.8 -0.2 -0.1 -0.3 -0.4 -0.  17.1 -0.1 -1.  -0.9 -1.2 -0.4 15.4 -0.2 -2.3 -0.   3.7  5. ]
vy_50sample [[8 6 7 0 5 9 9 4 3 2]
 [5 2 0 9 1 6 3 4 7 8]
 [9 3 7 0 1 4 8 5 6 2]
 [1 0 9 8 5 3 6 4 7 2]
 [2 2 7 0 5 5 6 4 3 8]
 [3 4 2 1 5 9 7 6 0 8]
 [4 2 7 1 5 8 6 0 9 3]
 [2 1 5 8 3 6 9 4 0 7]
 [2 7 7 9 5 1 1 8 4 6]
 [9 4 7 0 5 1 8 3 2 6]]
vt_50sample [[8 6 7 0 5 1 9 4 3 2]
 [5 2 0 9 1 6 3 4 7 8]
 [9 3 7 0 1 4 8 5 6 2]
 [1 0 9 8 5 3 6 4 7 2]
 [2 0 9 7 1 5 6 4 8 3]
 [3 4 2 1 5 9 7 6 0 8]
 [4 2 7 1 5 8 6 0 9 3]
 [2 1 5 8 3 6 9 4 7 0]
 [2 3 7 9 0 5 1 8 6 4]
 [9 4 7 0 5 1 8 3 2 6]]
Epoch 50510: Training cost= 0.2052, Training acc= 0.8631, Validation cost= 0.2348, Validation acc= 0.8632
Epoch 50520: Training cost= 0.2946, Training acc= 0.8631, Validation cost= 0.3155, Validation acc= 0.8632
Epoch 50530: Training cost= 0.1887, Training acc= 0.8631, Validation cost= 0.2608, Validation acc= 0.8632
Epoch 50540: Training cost= 0.3697, Training acc= 0.8631, Validation cost= 0.2402, Validation acc= 0.8632
Epoch 50550: Training cost= 0.2033, Training acc= 0.8631, Validation cost= 0.2430, Validation acc= 0.8632
Epoch 50560: Training cost= 0.2580, Training acc= 0.8631, Validation cost= 0.2128, Validation acc= 0.8632
Epoch 50570: Training cost= 0.2054, Training acc= 0.8631, Validation cost= 0.2415, Validation acc= 0.8632
Epoch 50580: Training cost= 0.2476, Training acc= 0.8631, Validation cost= 0.2424, Validation acc= 0.8632
Epoch 50590: Training cost= 0.2492, Training acc= 0.8631, Validation cost= 0.2173, Validation acc= 0.8632
Epoch 50600: Training cost= 0.2126, Training acc= 0.8632, Validation cost= 0.2069, Validation acc= 0.8632
tm  [-0.5 -0.2  3.3 -5.7 -1.6 -0.3 -0.2  0.4 -0.5 -0.9  5.2 -0.4  0.6 -0.3 16.1  2.2 -0.2 -0.2  0.7 -0.1 -1.5 -0.4 -0.8 -0.1 -1.1 -0.2 -0.4  1.1  0.4 -0.3  2.6 -0.2 -0.1 17.4 -0.1 -0.1 -0.3 -0.  -2.3 -0.1  0.2 -2.  -0.1  3.1 -0.2 -0.1 -2.2 -0.3 -0.5 -4.9 -0.2 -0.1 -0.7  7.5 -1.6 -1.8 -0.9 -0.5  3.9 -3.3  6.9 -0.6 -0.4 -0.3  0.8 -0.6 -0.2 -0.1  1.9 -0.6 -0.3 -1.8 -0.3 -0.4 -6.  -0.3  0.1 -0.1 -0.2 -0.2 -0.2 -0.3 -0.2 -0.3 -0.4 -1.9  3.3 -0.3 -0.2 -0.1 -0.4 -0.2 -0.4  0.6 -0.8 -0.3 -0.2 -3.6 -0.2 -0.   3.4 -0.3  0.6 -0.  -0.2 -0.2 -3.4 -0.   0.9  2.2  0.1 -0.4 -0.3 -1.1 -0.5 12.9  0.1  0.3 -0.3 -0.2 -0.1 -1.4 -0.   0.6  0.3 20.4  0.  -1.2  7.2 19.9 -0.1 -0.1 -0.1 -0.  -4.1  8.6 -0.2 -0.1 -0.2 -0.7  0.6  0.1 -0.1 -0.3 -0.1 -0.1 -0.1 -0.  -1.  -0.2  5.8 -0.2 -1.   0.6 -0.2 -0.  -0.  -0.2 -0.  -0.4 -0.6 -0.8 -0.1 -0.   0.6 -0.  -0.   0.   0.3 -0.2 -0.3 -0.1 -0.2 -0.1 -0.   2.3 -0.4 -0.9  1.9  0.1 -1.4 -0.1 -0.2 -2.1 -0.4 -0.1 -0.5 -0.8 -0.2  0.5 -0.2 -0.1 -0.1 -1.1 -2.8 -2.4 -0.6  1.2 -0.1 -0.  -0.6 -0.2  0.2 -0.4  0.6 -4.2 -0.  -0.2 -2.9 -0.2 -0.4  1.6 -0.5  1.4 -0.1 -0.2 -1.2 -1.1 -0.3 -0.3 -0.3 -0.3 -0.4 -1.3 -2.   1.4 -1.6 -0.6 -1.3 -0.2 -0.6  2.6 -0.1 -0.6 -0.9 -0.2  0.  -0.9  1.2 -4.7 -0.  -1.8 -0.1 -0.1  2.6  6.9  0.  -0.4 -1.  -0.1 -0.1  0.4 -1.4 -0.4  8.5 -4.7]
ty_50sample [[3 7 4 1 5 6 2 8 9 9]
 [0 5 6 3 9 8 1 4 7 2]
 [7 3 1 4 0 0 8 5 5 6]
 [1 7 5 8 8 2 6 9 3 4]
 [7 9 4 2 0 1 3 6 8 5]
 [6 7 4 9 1 0 2 8 5 3]
 [5 8 9 7 1 6 4 2 3 0]
 [1 1 0 4 8 9 6 2 3 5]
 [0 4 1 5 2 3 9 7 8 6]
 [5 1 2 7 9 0 8 3 4 6]]
tt_50sample [[3 7 4 1 5 6 2 8 9 0]
 [0 5 6 3 9 8 1 4 7 2]
 [7 3 1 4 2 0 8 9 5 6]
 [1 7 5 8 0 2 6 9 3 4]
 [7 9 4 2 0 1 3 6 8 5]
 [6 7 4 9 1 0 2 8 5 3]
 [5 8 9 7 1 6 4 2 3 0]
 [7 1 0 8 4 9 6 2 3 5]
 [0 4 1 5 2 3 9 7 8 6]
 [5 1 2 7 9 0 8 3 4 6]]
vm  [-0.7 -0.3 -2.2 10.5 -0.6 -0.3  1.4 -0.2 -1.   1.5 14.4 -0.7  0.1 -0.5 -3.9 -0.6 -0.3 -0.7  0.5 -1.5 -0.7 -0.2 -0.2 -0.2 -0.5 -0.3 -0.4  1.6 -1.1 -3.3  2.1 -0.2 -1.   3.8 -0.  -0.2  2.8  7.3 19.  -0.1 -0.8  5.  -0.8  0.2 -0.2 -0.5 10.1 -0.4 -1.5 -0.1 -0.1 -0.  -0.2  4.9 -0.2  4.3 -0.2  2.6  3.9 -2.5 -0.3 -0.3 -0.9 -0.5  2.4 -0.8 -0.3 -0.  -0.1 -0.2 -0.3  4.2 -0.5 -1.   1.3 -0.3 -0.1 -0.2 -0.4 -0.3 28.5  0.5 -0.4 -0.6 -0.1  5.8 -0.7 -0.1 -0.2 -0.1 -0.2 -0.1 -0.4 -0.2 -0.7 -0.5 -0.2 -0.6 -0.5 -0.7 -0.2  2.8  0.7  0.2 -0.4  1.6 -1.5 -0.3 -0.6 -2.4  0.5 -0.3 -0.4  0.3  4.2 -2.9  0.9 -0.4 -0.1  1.5  0.2  8.8 -0.1  0.   0.8 -4.9 -0.2 -0.6  4.3 -4.1  1.6 -0.4 -0.5 -0.1  4.3  5.9 -0.2 -0.3 -0.3 -0.5 -0.5 -0.4 -0.3 -0.5 -0.1  0.2 -0.2 -0.2  5.5 -0.4 -1.1 -0.3 -1.8 -0.1 -0.1 -0.3  0.4 -0.3 -0.7 -0.2 -0.3 -0.8 -0.2 -0.1 -0.2  0.  -0.6 -0.2 -0.5 -0.1 -0.2  0.1 -0.3 -0.3 -0.  -1.4  1.1 -0.5 -1.9 -0.3 -1.2 -0.6  0.6 -1.6 -0.1 -0.1 -0.3 -0.5  0.9  9.1 -0.2 -0.8 -0.3 -1.   4.4 -1.1 -0.4 -1.1 -0.4 -0.1 -0.1  0.3 -0.3 -0.2  0.1  0.6 -0.2 -0.1 -4.9 -0.2 -0.3 -2.3 -0.6  2.8  1.1 -0.4 -0.5 -0.7 -0.6  1.2 -0.1 -0.3 -0.4 -1.1  3.  -1.7  2.5  0.2  1.  -0.3 -2.1 -0.3 -0.7 -1.1  0.8  2.3  1.6 -0.4 -0.6  7.5 -0.1  0.9 -0.2 -0.2 -6.2 -2.1  0.5 -0.8 -0.8  0.4 -7.2 -0.2 10.4 -0.2 -2.2 15. ]
vy_50sample [[2 0 9 1 5 4 6 7 3 8]
 [1 4 0 8 7 2 6 3 9 5]
 [5 7 1 0 4 3 8 9 6 2]
 [5 2 4 1 6 8 0 3 7 9]
 [0 4 4 7 6 8 5 1 2 3]
 [7 6 0 1 8 3 4 9 2 5]
 [6 8 7 0 2 3 5 9 4 1]
 [1 8 7 3 6 5 4 9 2 0]
 [5 4 2 6 0 0 7 8 1 3]
 [7 6 3 4 2 1 0 5 8 9]]
vt_50sample [[2 0 9 1 5 4 6 7 3 8]
 [1 4 0 8 7 2 6 3 9 5]
 [5 7 1 0 4 3 8 9 6 2]
 [5 2 4 1 6 8 0 3 7 9]
 [0 9 4 7 6 8 5 1 2 3]
 [7 6 0 1 8 3 4 9 2 5]
 [6 8 7 0 2 3 5 9 4 1]
 [1 8 7 3 6 5 4 9 2 0]
 [5 4 2 6 0 9 7 1 8 3]
 [7 6 3 4 2 1 0 5 8 9]]
Epoch 50610: Training cost= 0.2162, Training acc= 0.8632, Validation cost= 0.2036, Validation acc= 0.8632
Epoch 50620: Training cost= 0.2387, Training acc= 0.8632, Validation cost= 0.2949, Validation acc= 0.8632
Epoch 50630: Training cost= 0.1799, Training acc= 0.8632, Validation cost= 0.2526, Validation acc= 0.8633
Epoch 50640: Training cost= 0.2296, Training acc= 0.8632, Validation cost= 0.2834, Validation acc= 0.8633
Epoch 50650: Training cost= 0.2296, Training acc= 0.8632, Validation cost= 0.2696, Validation acc= 0.8633
Epoch 50660: Training cost= 0.3243, Training acc= 0.8632, Validation cost= 0.2331, Validation acc= 0.8633
Epoch 50670: Training cost= 0.1806, Training acc= 0.8632, Validation cost= 0.2139, Validation acc= 0.8633
Epoch 50680: Training cost= 0.1930, Training acc= 0.8632, Validation cost= 0.2164, Validation acc= 0.8633
Epoch 50690: Training cost= 0.2231, Training acc= 0.8632, Validation cost= 0.2303, Validation acc= 0.8633
Epoch 50700: Training cost= 0.2070, Training acc= 0.8632, Validation cost= 0.1954, Validation acc= 0.8633
tm  [ 0.  -0.2  5.8  9.4 -1.2  0.2 -0.1  0.1 -0.9  0.5  3.9 -0.5  0.2  0.2  2.3 -0.6  0.4 -0.6 -0.3  0.3 -1.4 -0.2 -0.  -0.5 -0.7  1.   0.  -0.2 -1.2 -0.4 -1.3 -0.3 -0.4 -1.8 -0.  -0.2  2.  -1.3 -5.4 -0.5  0.3 -0.9 -0.1 -1.6 -0.3  0.7 -1.  -0.3  5.  -0.3 -0.1 -0.3 -0.2  9.   1.2 -0.5 -0.6  5.5 -0.5  8.1 -0.4  0.  -0.5 -0.1 -0.7 -0.2 -0.2 -0.2  0.1  0.2 -0.1  4.6 -0.2  0.2 -3.9 -0.7 -0.1  0.4 -0.1 -0.  -2.6  0.2 -0.2 -0.3 -1.4 -0.9 -0.1 -0.2 -0.2 -0.4 -0.2 -0.  -0.   0.1 -0.3  0.6 -0.3 -3.4  0.9 -0.1 -0.5 -0.8 -0.2 -0.1 -0.2 -0.1 -1.8 -0.4  1.4 -1.  -0.7  0.1 -0.4 -0.6  1.3 -2.5 -0.4 -0.4 -0.1 -0.2  0.4  2.7 -0.1 -0.8 -0.1  3.   0.  -1.6 -0.8 10.5 -0.3 -0.4 -0.2 -0.  14.4 12.7 -0.4 -0.2 -0.3 -0.8 -0.2 -0.8  0.2 -0.1 -0.1 -0.4 -0.5  0.1  2.1 -0.3 -1.  -0.   2.4  0.4 -0.1 -0.3 -0.1  1.6 -1.4 -0.8  1.2  2.  -0.3 -0.  -0.2 -0.3 -0.3 -0.6 -0.1 -0.1 -0.1 -0.1 -0.   0.7 -0.1 -0.1 -1.  -0.4  5.1 -0.2 -1.   1.  -0.3 -1.4  0.1  0.1 -0.3 -0.4 -0.1  1.8 -0.  -0.1 -0.2 -0.4  5.9  2.9 -0.7 -0.6 -0.1 -0.  -0.3 -0.  -0.1 -0.3 -0.1 -2.6 -0.2 -0.2  4.9 -0.1 -0.7 -1.8 -0.7 -1.  -0.8 -0.1 10.4 -1.3 -0.6 -0.5 -0.1 -0.2 -0.3 -1.1  2.8 -1.  -0.4 -0.1 -0.4  2.6  3.1  0.2 -0.1  1.1  1.4 -1.2  0.4 -0.7  3.1 -0.7 -0.1 -0.4 -0.1 -0.   9.1  3.  -0.3  0.5 -1.2 -0.6  6.4 -0.3 -2.9 -0.2  1.8 -2.1]
ty_50sample [[6 0 3 2 8 5 7 9 1 4]
 [3 6 5 7 2 0 4 8 9 1]
 [6 2 9 4 7 8 1 3 0 5]
 [2 4 8 0 7 1 5 9 6 3]
 [8 7 0 6 5 9 2 1 4 3]
 [8 5 7 6 4 1 0 2 3 9]
 [4 2 3 6 9 5 8 0 7 1]
 [2 5 6 7 1 9 0 4 3 8]
 [7 5 6 8 9 3 2 0 1 4]
 [3 5 1 7 0 4 2 6 8 9]]
tt_50sample [[6 0 3 2 8 5 7 9 1 4]
 [3 6 5 7 2 0 4 8 9 1]
 [6 2 9 4 7 8 1 3 0 5]
 [2 4 8 0 7 1 5 9 6 3]
 [8 7 0 6 5 9 2 1 4 3]
 [8 5 7 6 4 1 0 2 3 9]
 [4 2 3 6 9 5 8 7 0 1]
 [2 5 6 7 1 9 0 4 3 8]
 [5 7 6 8 9 3 0 2 1 4]
 [3 5 1 7 0 4 2 6 8 9]]
vm  [ 0.5 -0.   8.6 12.2 -0.8 -0.1 -0.4 -0.1 -0.9 -0.2  8.2 -0.1 -0.1  0.4  3.2  2.7 -0.1 -0.4 -0.1 -1.  -0.9 -0.3  1.3 -0.2 -0.7 -0.  -0.3 -0.3 -0.6  9.7  0.5 -0.1  1.1 12.6 -0.2 -0.1  2.1 -0.1 -0.6 -0.4  2.3  4.6  2.4 -1.5  0.  -0.2  5.9 -0.1  6.3  7.8 -0.2  0.   1.2  1.8 -0.9 -0.3 -0.5  3.4 -2.9  2.  -2.4 -0.2 -0.3 -0.3 -0.4 -0.3 -0.1 -0.6  0.3  0.1 -0.  -0.2 -0.2 -0.3 -0.7 -0.3 -0.2  0.1 -0.1 -0.3 13.5 -0.  -0.2 -0.4 -2.   5.   4.6 -0.  -0.1 -0.4 -0.8 -0.1  0.2  2.1 -0.5  1.  -0.2 -0.7 -0.7 -0.1  0.6  7.8  0.2 -0.  -0.5  0.6 -0.7 -0.3  0.9 -2.3 -0.3 -0.3 -0.1 -0.5 -1.1  3.   1.6 -1.1 -0.1 -0.2 -0.2  7.9 -0.2 -0.6 -0.3  4.4  0.   0.2 -3.1 -3.5 -0.5 -0.1 -0.4  0.5 -0.6 14.2 -0.1 -0.  -0.7 -0.8 -0.4 -0.1 -0.2 -0.1 -0.1 -0.3  0.2  0.2 -1.3 -0.1 -1.  -0.3  3.3 -0.1 -0.1 -0.  -0.3 -0.4 -0.8 -1.1 -0.4 -0.3 -0.  -0.2 -0.1  1.8 -0.1 -0.6 -0.4 -0.3 -0.  -0.2 -0.3 -0.1 -0.2  1.8 -1.1 -0.3  1.4 -0.2 -1.4  1.4 -0.1 -0.4 -0.2  0.5 -0.4 -0.3 -0.  -2.3 -0.4 -0.2 -0.1 -0.8 18.4 12.2 -0.2  2.2 -0.1 -0.2  0.4 -0.2  0.5 -0.1 -0.5  2.3 -0.  -0.2 -0.9 -0.3 -0.2 -0.3  0.7 -2.1  1.4 -0.2  6.  -1.  -0.1 -0.1 -0.3 -0.1  0.5 -0.7  4.1  0.  -0.2 -0.6 -0.2  2.3  1.4 -0.4 -0.3 -0.5 -0.8 -2.2 -0.7 -0.2 -0.3  9.  -0.2  2.2 -0.3 -0.3 -2.4 -1.7 -0.6 -0.1 -1.  -0.1 -3.6 -0.  -0.4 -0.2 -1.7 13.4]
vy_50sample [[7 6 2 9 5 0 8 4 3 1]
 [6 2 3 1 0 9 4 8 8 5]
 [7 3 2 6 4 5 0 1 9 8]
 [8 7 2 6 9 1 3 0 4 5]
 [0 6 7 9 9 4 3 1 5 2]
 [2 7 3 9 5 6 1 4 8 0]
 [4 9 2 8 7 3 0 1 5 6]
 [6 1 2 3 4 5 0 8 7 9]
 [5 8 2 0 4 3 1 9 6 7]
 [7 2 0 5 9 6 8 4 3 1]]
vt_50sample [[7 6 2 9 5 0 8 4 3 1]
 [6 2 3 1 0 9 4 7 8 5]
 [7 3 2 6 4 5 0 1 9 8]
 [8 7 2 6 1 9 3 0 4 5]
 [0 6 7 8 9 4 3 5 1 2]
 [2 7 3 9 5 6 1 4 8 0]
 [4 9 2 8 7 3 0 1 5 6]
 [6 1 2 3 4 5 0 8 7 9]
 [5 8 2 0 4 3 1 9 6 7]
 [7 2 0 5 9 6 8 4 3 1]]
Epoch 50710: Training cost= 0.2388, Training acc= 0.8633, Validation cost= 0.2828, Validation acc= 0.8633
Epoch 50720: Training cost= 0.2023, Training acc= 0.8633, Validation cost= 0.2380, Validation acc= 0.8633
Epoch 50730: Training cost= 0.2252, Training acc= 0.8633, Validation cost= 0.2514, Validation acc= 0.8633
Epoch 50740: Training cost= 0.2356, Training acc= 0.8633, Validation cost= 0.2342, Validation acc= 0.8634
Epoch 50750: Training cost= 0.2294, Training acc= 0.8633, Validation cost= 0.2434, Validation acc= 0.8634
Epoch 50760: Training cost= 0.2644, Training acc= 0.8633, Validation cost= 0.2698, Validation acc= 0.8634
Epoch 50770: Training cost= 0.2338, Training acc= 0.8633, Validation cost= 0.2176, Validation acc= 0.8634
Epoch 50780: Training cost= 0.2466, Training acc= 0.8633, Validation cost= 0.1997, Validation acc= 0.8634
Epoch 50790: Training cost= 0.2576, Training acc= 0.8633, Validation cost= 0.2384, Validation acc= 0.8634
Epoch 50800: Training cost= 0.2789, Training acc= 0.8633, Validation cost= 0.3047, Validation acc= 0.8634
tm  [-0.5 -0.3 11.7 -0.2 -1.5 -0.4 -0.2  0.1  0.2 -0.6 -0.9 -0.3 -0.5 -0.  16.1  0.4 -0.1 -0.3 -0.3  1.1 -1.  -0.1 -0.3 -0.1 -0.9  0.3 -0.6 -0.4  0.4 -0.2 -0.2 -0.3  1.6 13.2 -0.2 -0.3 -0.3 -1.3 -4.9 -0.3  0.7  3.4  0.3 -1.2 -0.1 -0.2 -2.  -0.2  0.6 -1.3 -0.4 -0.1 -0.3  3.7 -1.5 -2.  -0.8 11.2  2.7  4.   6.1 -0.4 -0.1 -0.3  1.5 -0.7 -0.1  0.6  2.1 -0.1 -0.3 -1.2 -0.4 -0.8 -5.8  0.7 -0.3 -0.  -0.2  0.2 -2.4  0.1  0.1  0.5 -0.6  3.7 -1.2 -0.3 -0.2 -0.1 -0.4 -0.1 -0.3 -0.3 -0.8 -0.4  1.  -3.9 -0.8 -0.2  2.   4.8 -0.1 -0.2 -0.3 -0.3 -3.1 -0.2 -0.3  3.   0.3 -0.2 -0.2 -1.   0.3  7.8 -0.   0.8  0.8 -0.4 -0.4 -1.5 -0.   0.7  0.3 20.2 -0.3 -0.2  5.  11.9  0.1 -0.3 -0.3 -0.4 -1.8 11.1  0.2 -0.1 -0.5 -0.6  0.6 -0.1 -0.1 -0.3 -0.1 -0.1 -0.2 -0.2 -0.  -0.2 -0.2 -0.1 -0.2  0.5 -0.4  0.1 -0.5 -0.6 -0.5 -0.8 -0.3 -0.1  0.6 -0.1 -0.1 -0.4 -0.4 -0.4 -0.6 -0.1 -0.2 -0.3 -0.2 -0.4 -0.2  0.1 -1.4 -0.3  5.1  0.4 -2.  -0.3 -0.2 -2.1 -0.1 -0.  -0.3 -0.4  0.1  0.6 -0.1 -0.3 -0.2 -0.9 -2.5 -1.6 -0.5 -0.3  0.1 -0.1 -0.2 -0.3 -0.2 -0.2 -0.6 -3.7 -0.1 -0.1 -3.2 -0.4 -0.7  1.2 -0.2  0.7 -0.5 -0.   6.2 -1.1  0.5 -0.6 -0.  -0.2  1.  -0.8  0.5  2.5 -1.5 -0.6 -0.6  0.9 -0.3  2.  -0.1 -0.8 -0.6 -2.7 -0.  -0.9  1.8 -6.8 -0.2 -2.3 -0.  -0.2  8.4  3.4  0.  -0.3 -1.1 -0.1  5.2 -0.1 -2.9 -0.1  5.4 -2.8]
ty_50sample [[7 5 6 3 1 8 0 2 4 9]
 [1 6 9 0 8 8 5 3 7 4]
 [5 7 0 1 9 6 3 2 8 4]
 [3 2 7 8 5 6 4 9 0 1]
 [3 2 7 5 0 8 4 4 1 6]
 [7 5 0 6 3 9 2 4 1 8]
 [2 0 9 8 4 6 3 7 5 1]
 [8 0 2 6 3 1 5 7 4 9]
 [6 6 1 9 4 0 3 8 2 5]
 [6 7 4 9 0 5 1 2 8 3]]
tt_50sample [[7 5 6 3 1 8 0 2 4 9]
 [1 6 9 0 2 8 5 3 7 4]
 [5 7 0 1 9 6 3 2 8 4]
 [3 2 7 8 5 6 4 9 0 1]
 [3 2 7 5 0 8 9 4 1 6]
 [7 5 6 0 3 9 2 4 1 8]
 [2 0 9 8 4 6 3 7 5 1]
 [8 0 2 6 3 1 5 7 4 9]
 [6 7 9 1 4 0 3 8 2 5]
 [6 7 4 9 0 5 1 2 8 3]]
vm  [-0.3  0.2  2.4  1.5 -1.3 -0.1 -0.1 -0.4  2.5 -0.3  4.  -0.2 -0.1 -0.1  2.3  5.2 -0.2 -0.4  1.6 -0.1 -0.4 -0.1 -0.5 -0.3 -1.2  0.9 -0.3  1.6  2.5 -4.2 -0.8 -0.4 -0.3 -2.4 -0.1 -0.1 -1.4  3.5 -1.1 -0.  -0.6 -1.5 -1.5 -1.3 -0.1 -0.  -1.3 -0.3  4.3 -2.4 -0.1 -0.2 -0.3  9.  -1.4 -0.4 -0.2  8.7 11.7  5.   0.6 -1.   0.1  0.3  0.8 -0.4 -0.   0.4 -0.6 -0.5 -0.3 -2.5 -0.7 -0.2 -5.5  2.4 -0.4  2.  -0.1 -0.2 -2.9 -0.3 -0.2 -0.3 -1.8 -0.8 -0.7  0.4  0.3 -0.2 -0.5 -0.3 -0.  -1.2 -0.7 -0.2  1.1 -4.2 -0.3  0.1  0.2 -2.7 -0.8 -0.1 -0.1 -0.2 -2.1 -0.5  1.3  2.   2.2  0.1 -0.2 -1.1  1.2 15.2 -0.1  2.5 -0.3  0.  -0.8 -0.9 -0.  -0.5 -0.3  2.2 -0.1 -1.5 13.5 15.6  0.4 -0.2 -0.3 -0.2  5.1 -0.9 -0.4 -0.1 -0.3 -0.2 -0.5 -0.3 -0.7 -0.2 -0.1 -0.2 -0.3 -0.3  6.2 -0.2 -0.2 -0.1  2.7 -0.5 -0.4 -0.1 -0.4  0.1  0.1 -0.4 -0.4 -1.  -0.1 -0.1 -0.  -0.5 -0.4 -0.5 -0.  -0.4 -0.2 -0.  -0.2 -0.6 -0.3 -1.2 -0.9 -0.2  1.2 -0.1 -1.6  0.8 -0.7 -2.4 -0.2 -0.3  0.2 -0.7 -0.1 10.6 -0.2 -0.   0.  -0.9  1.  -5.  -0.2 -0.8 -0.3 -0.3 -0.3 -0.3  0.2 -0.  -0.4 -2.2 -0.1 -0.2 -0.6 -0.  -0.8  3.9 -0.3 -1.3 -0.5  0.2  3.7 -1.  -0.5 -0.9 -0.1  0.1 -0.  -1.4 -1.4  4.4 -0.8 -0.  -0.4  1.9 -0.3 -0.1 -0.1 -0.2 -1.5 -0.4 -0.3 -0.5  1.5 -3.6 -0.  -1.2  0.1  0.   9.8  0.4  0.3 -0.6 -1.3 -0.4  7.1 -0.1 -0.7 -0.2  3.1 -3.9]
vy_50sample [[3 5 2 8 6 1 7 4 9 0]
 [0 6 8 3 4 5 1 9 7 2]
 [9 7 4 3 5 2 1 6 8 0]
 [3 9 1 4 8 5 0 7 6 2]
 [6 0 9 2 1 3 4 5 8 7]
 [8 2 1 9 7 5 3 0 6 4]
 [0 9 4 3 2 7 6 1 8 5]
 [5 2 8 3 4 1 0 9 6 7]
 [3 4 0 9 7 8 1 6 5 2]
 [5 1 9 7 3 0 6 8 2 4]]
vt_50sample [[3 5 2 8 6 1 7 4 9 0]
 [6 0 8 3 4 5 1 9 7 2]
 [9 7 4 3 5 2 1 6 8 0]
 [3 9 1 4 8 5 0 7 6 2]
 [6 0 9 2 1 3 4 5 8 7]
 [8 2 1 9 7 5 3 0 6 4]
 [0 9 4 3 2 7 6 8 1 5]
 [5 2 8 3 4 1 0 9 6 7]
 [3 4 0 7 9 8 1 6 5 2]
 [5 1 9 7 3 0 6 8 2 4]]
Epoch 50810: Training cost= 0.2250, Training acc= 0.8633, Validation cost= 0.2038, Validation acc= 0.8634
Epoch 50820: Training cost= 0.2658, Training acc= 0.8633, Validation cost= 0.2932, Validation acc= 0.8634
Epoch 50830: Training cost= 0.2200, Training acc= 0.8634, Validation cost= 0.2689, Validation acc= 0.8634
Epoch 50840: Training cost= 0.2076, Training acc= 0.8634, Validation cost= 0.1979, Validation acc= 0.8634
Epoch 50850: Training cost= 0.2834, Training acc= 0.8634, Validation cost= 0.2599, Validation acc= 0.8634
Epoch 50860: Training cost= 0.2355, Training acc= 0.8634, Validation cost= 0.2835, Validation acc= 0.8635
Epoch 50870: Training cost= 0.2451, Training acc= 0.8634, Validation cost= 0.2192, Validation acc= 0.8635
Epoch 50880: Training cost= 0.2811, Training acc= 0.8634, Validation cost= 0.2612, Validation acc= 0.8635
Epoch 50890: Training cost= 0.2352, Training acc= 0.8634, Validation cost= 0.2899, Validation acc= 0.8635
Epoch 50900: Training cost= 0.2370, Training acc= 0.8634, Validation cost= 0.2780, Validation acc= 0.8635
tm  [-1.   0.  -1.9  6.7 -1.5 -0.1 -0.3  0.7 -1.3 -0.7 -3.1 -0.2 -0.1 -0.2 -2.5 -2.2 -0.1 -0.4  0.2 -0.5 -1.4 -0.3  2.  -0.1 -1.5  2.9 -0.3 -0.  -1.9 -3.2 -0.5  0.5 -0.4 -5.1  0.   0.1  4.9 -0.3  5.3 -0.1 -0.  -0.6  0.3 -0.3 -0.2  0.9  2.7 -0.3 -1.5  1.9 -0.2 -0.2 -0.1 -1.4  2.2  2.3 -0.9  4.1 -0.2  4.3  2.9  0.3 -0.2 -0.2 -0.4  1.1 -0.2 -0.4  0.6 -0.1  0.4  6.4 -0.2 -0.3 -0.8 -0.1  0.3 -0.3  0.1  0.1 -0.4 -0.2 -0.4  0.1  1.6 -0.5 -1.5 -0.2  0.  -0.2 -0.5 -0.1 -0.1 -0.  -0.4  0.1 -0.  -2.1 -0.2  1.4  2.5 -2.  -0.3 -0.2 -0.3 -0.2 -0.9 -0.  -0.9 -1.  -0.3 -0.1 -0.1 -0.   3.5 -3.6 -0.4 -1.1 -0.2 -0.2 -0.2  4.   0.2  0.8 -0.2 -3.1 -0.1  6.5 -0.2  2.3 -0.3 -0.2 -0.3 -0.2  8.8 -1.8  0.2 -0.2  0.8 -0.2  1.4 -1.1 -0.1 -0.4 -0.1 -0.3 -0.2 -0.   5.7 -0.3 -0.7 -0.2  1.5  1.2  0.2 -0.2  0.4 -0.5 -0.  -0.2 -0.5 -0.6 -0.  -0.1 -0.2 -0.6 -0.2 -0.4 -0.1  0.3  0.3 -0.1  0.1  0.1 -0.1 -1.2 -0.3 -0.2 -0.3 -0.1 -1.1 -0.  -0.2 -2.1 -0.  -0.2 -0.3  0.6 -0.1  8.8 -0.1 -0.1 -0.4 -1.  -0.4  1.4 -0.4 -1.  -0.3 -0.  -0.1  0.1 -0.5 -0.1  0.1 -1.1 -0.2 -0.1  3.2  1.  -0.4 -2.6 -0.3  6.8 -0.2 -0.3  0.4 -1.  -0.4 -0.5 -0.1 -0.3  0.2 -1.3 -0.7 -1.  -1.5  0.9 -0.4 -0.6 -0.6 -0.6 -0.3  1.1  4.7  0.9 -0.1 -0.2  2.5  2.8 -0.1  0.  -0.2 -0.2  4.  -0.9 -0.1 -0.1 -1.2  0.4  0.1 -0.2  3.4 -0.5  7.   0.3]
ty_50sample [[0 1 8 3 9 5 6 4 2 7]
 [7 9 6 4 1 3 2 5 5 8]
 [9 7 0 5 8 8 6 3 4 1]
 [1 3 2 0 7 8 9 5 4 6]
 [6 5 0 3 1 7 9 2 4 8]
 [5 7 0 9 8 4 3 2 1 6]
 [8 1 7 0 6 9 4 5 3 2]
 [9 2 5 7 3 8 1 0 6 4]
 [3 2 9 7 4 6 8 5 1 0]
 [9 6 7 3 8 2 5 4 0 1]]
tt_50sample [[0 1 8 3 9 5 6 4 2 7]
 [7 9 6 4 3 1 2 5 0 8]
 [9 7 0 5 2 8 6 3 4 1]
 [1 3 2 0 7 8 9 5 4 6]
 [6 0 5 3 1 7 9 2 4 8]
 [5 7 0 9 4 8 3 2 1 6]
 [8 1 7 6 0 9 4 5 3 2]
 [9 2 5 7 3 8 1 0 6 4]
 [3 2 9 7 4 6 8 5 1 0]
 [6 9 7 3 8 2 5 4 0 1]]
vm  [-1.2 -0.  -4.4  1.6 -1.  -0.1 -0.2  0.4 -1.  -0.4 -5.8 -0.2 -0.2 -0.  -3.3 -0.9 -0.4 -0.5 -0.3 -1.2 -1.4 -0.3  0.9 -0.1 -1.3 -0.  -0.3  0.1 -0.9 -1.2 -0.1  0.  -0.2 -6.9 -0.   0.1  3.6 -0.2 12.2 -0.2  0.8  2.7  0.5  2.8 -0.2 -0.   6.8 -0.2 -2.5  8.9 -0.3 -0.  -0.4 -2.9 -1.   3.2 -0.8  0.4 -1.   3.4  2.4 -0.1 -0.4 -0.2 -0.6 -0.1 -0.4 -0.3 -0.1 -0.2 -0.  -0.  -0.3 -0.6 -0.3 -0.   0.5 -0.3  0.3  0.2 -0.9 -0.3 -0.1  1.3  3.   3.9 -0.7 -0.  -0.  -0.1 -0.4 -0.1 -0.2  0.7 -0.4 -0.1 -0.1 -1.2 -0.   0.7  2.1 -1.   1.  -0.1 -0.2 -0.4 -1.1 -0.2 -1.6 -1.5 -0.1 -0.  -0.2 -0.4 -0.1  1.3 -0.3 -1.1 -0.2 -0.5 -0.2  6.2  0.7  0.1 -0.2 -4.  -0.1 10.2 -0.7 -1.3 -0.3 -0.3  0.4 -0.2  7.2 -4.7  0.6 -0.3  1.   0.2  1.3 -0.2 -0.2 -0.3 -0.  -0.3 -0.2 -0.   7.4 -0.1 -0.2 -0.1  1.5  0.1 -0.  -0.1  0.7 -0.9  0.5 -0.3 -0.1 -0.6 -0.1 -0.1 -0.   0.1  0.1 -0.1 -0.1  0.1 -0.1  0.1  0.6 -0.1 -0.1 -1.4 -0.1 -0.4 -1.2 -0.  -1.3 -0.3 -0.3 -1.3 -0.1 -0.1 -0.5  0.3 -0.3  4.2 -0.2 -0.1 -0.5 -1.  -0.3  3.4  0.1  0.3 -0.2  0.3 -0.1  0.1 -0.3 -0.4 -0.1 -0.7 -0.1  0.1  4.   0.4 -0.5 -0.9 -0.3  9.  -0.  -0.1 -1.6 -1.1 -0.1 -0.2 -0.1 -0.2  0.3 -1.1 -0.1  1.5 -1.4 -0.  -0.6 -0.6 -1.  -0.3 -0.3  1.   0.6  4.3 -0.2 -0.3  2.1  2.9 -0.1  0.2  0.  -0.3  5.  -1.4  0.2 -0.2 -1.1 -0.2  1.5 -0.2  7.3 -0.5  4.4  6.4]
vy_50sample [[8 8 9 4 0 0 3 6 2 7]
 [5 2 3 1 0 9 8 8 6 7]
 [3 5 7 6 9 0 2 4 1 8]
 [6 9 8 8 0 5 4 1 7 3]
 [4 9 0 7 1 3 8 6 5 2]
 [0 6 4 8 9 5 7 2 3 1]
 [9 6 2 0 7 3 4 5 1 8]
 [7 4 8 5 6 0 3 3 2 1]
 [8 5 6 0 9 2 1 4 7 3]
 [4 2 5 7 0 6 3 8 9 1]]
vt_50sample [[1 8 4 9 5 0 3 6 2 7]
 [5 2 3 1 9 0 4 8 6 7]
 [3 5 7 6 9 0 2 4 1 8]
 [6 9 2 8 0 5 4 1 7 3]
 [4 9 0 7 1 3 8 6 5 2]
 [0 6 4 8 9 5 7 2 3 1]
 [9 6 2 0 7 3 4 5 1 8]
 [7 4 8 5 6 0 3 9 2 1]
 [8 5 6 0 9 2 1 4 7 3]
 [4 2 5 7 0 6 3 8 9 1]]
Epoch 50910: Training cost= 0.2380, Training acc= 0.8634, Validation cost= 0.2491, Validation acc= 0.8635
Epoch 50920: Training cost= 0.2330, Training acc= 0.8634, Validation cost= 0.2072, Validation acc= 0.8635
Epoch 50930: Training cost= 0.2643, Training acc= 0.8634, Validation cost= 0.2285, Validation acc= 0.8635
Epoch 50940: Training cost= 0.2030, Training acc= 0.8634, Validation cost= 0.2516, Validation acc= 0.8635
Epoch 50950: Training cost= 0.2550, Training acc= 0.8634, Validation cost= 0.1664, Validation acc= 0.8635
Epoch 50960: Training cost= 0.1920, Training acc= 0.8635, Validation cost= 0.2028, Validation acc= 0.8635
Epoch 50970: Training cost= 0.1925, Training acc= 0.8635, Validation cost= 0.2797, Validation acc= 0.8635
Epoch 50980: Training cost= 0.2738, Training acc= 0.8635, Validation cost= 0.2920, Validation acc= 0.8636
Epoch 50990: Training cost= 0.2328, Training acc= 0.8635, Validation cost= 0.2974, Validation acc= 0.8636
Epoch 51000: Training cost= 0.2715, Training acc= 0.8635, Validation cost= 0.2889, Validation acc= 0.8636
tm  [-1.  -0.6  7.6 21.9 -1.3 -0.4  0.3  0.4 -0.1 -0.1 -2.8 -0.  -0.1 -0.  -1.5 -0.3 -0.3 -0.1  0.2 -0.9 -1.4 -0.1  0.9  0.1 -0.8  2.3 -0.6 -0.5 -0.5  3.6 -0.7 -0.3  2.5  3.2 -0.2 -0.2 -0.1 -2.3 -0.9 -0.1  3.6  3.5 -0.2 -1.3 -0.1 -0.4  6.2  0.6  1.7 10.6 -0.2 -0.1  1.7 -3.6 -1.1  2.1 -0.8  3.  -0.9  6.3 -1.5 -0.  -0.2 -0.2 -1.3 -0.5  0.4 -0.2  3.  -0.4 -0.4 -1.   0.9  0.8  1.3  1.3 -0.1  0.9 -0.1 -0.1 13.1 -0.2 -0.1 -0.4 -1.   5.9 -1.3 -0.1 -0.3 -0.  -0.2 -0.1 -0.1 -0.7 -0.3 -0.5  1.  -0.8 -0.8 -0.2 -0.3  8.1  0.2  0.2 -0.3 -0.2  3.5 -0.4 -0.8 -2.2 -1.1  0.1 -0.1 -0.5  1.   3.3  2.7 -0.3  0.1 -0.6 -0.2  6.9 -0.4 -0.4  0.7 -1.9 -0.1 12.4 -1.5 -4.2 -1.1 -0.1 -0.3 -0.1  9.1 14.4 -0.1 -0.3 -0.8 -0.8  1.9 -0.5  1.2 -0.2 -0.1  0.4 -0.1  0.5 -1.6 -0.3 -2.4  0.   2.   0.6 -0.2  0.  -0.4 -0.3 -0.5 -0.5  2.7 -0.1 -0.3 -0.  -0.1 -0.9 -0.6 -0.2 -0.2 -0.  -0.  -0.2 -0.2  0.  -0.1  0.4 -1.3  0.6  1.3 -0.1  0.2 -0.2 -0.3 -0.8 -0.2 -0.6 -0.2  0.2  0.3 -1.1  0.5 -0.1 -0.4 -0.7 11.8  5.4  1.5 -0.7 -0.  -0.1 -0.2 -0.3 -0.  -0.4 -0.1  7.  -0.3 -0.1  5.4 -0.1 -0.2  1.7 -0.2  3.4 -0.7  1.   8.  -0.5  0.  -0.2 -0.3 -0.2 -0.1 -0.3  6.3  2.4 -2.1 -0.5  2.  -0.4  4.7 -1.3 -0.1  1.2 -0.5 -1.9 -0.3  2.3  1.5 20.7  0.1  5.3 -0.4 -0.2 -2.3 -3.1 -0.5 -0.1 -1.  -0.8 -3.4 -0.2 -0.5 -0.  -0.3 14.4]
ty_50sample [[6 9 7 8 1 0 5 2 4 3]
 [6 3 3 5 2 7 9 8 1 4]
 [8 5 3 6 1 4 9 0 7 2]
 [9 0 8 2 4 1 3 7 6 5]
 [5 3 9 7 2 6 0 1 8 4]
 [9 5 8 0 6 3 4 2 1 7]
 [0 1 3 7 2 9 5 8 6 4]
 [4 2 8 9 9 6 5 1 0 3]
 [9 7 8 0 1 6 3 5 2 4]
 [9 1 7 8 6 0 2 4 5 3]]
tt_50sample [[6 9 7 8 1 0 5 2 4 3]
 [6 0 3 5 2 7 9 8 1 4]
 [8 5 3 6 1 4 0 9 7 2]
 [0 9 8 2 4 1 3 7 5 6]
 [5 3 9 7 2 6 1 0 4 8]
 [9 5 8 0 6 3 4 2 1 7]
 [0 1 3 7 2 9 5 8 4 6]
 [4 2 8 9 7 6 5 1 0 3]
 [9 7 8 0 1 6 3 5 2 4]
 [9 1 7 8 6 0 2 4 5 3]]
vm  [-0.4 -0.5 -0.4  0.1 -1.3 -0.2 -0.  -0.1 -0.7 -0.1  3.9  0.7 -0.3 -0.4  1.  -0.  -0.2  0.2 -0.2 -0.2 -1.6 -0.  -0.9 -0.2 -0.8 -0.5 -0.1 -0.6 -0.4 -0.8  1.5 -0.2  2.1  8.2 -0.2 -0.3  0.4 -2.1 -5.3 -0.3  3.3 -0.8 -0.3 -0.3 -0.1 -0.3 -0.5 -0.6 -0.8 -5.2  0.4  0.2 -0.4 -1.  -1.7 -0.4 -0.7  3.3  2.3 -1.8  5.9 -0.5 -0.  -0.2  0.4 -1.5 -0.2 -0.1  0.8 -0.3 -0.4 -1.  -0.5 -0.8 -4.8 -0.9 -0.1 -1.  -0.3 -0.3 11.2 -0.  -0.2 -0.7 -0.5 -1.1 -0.5 -0.2 -0.2 -0.3  0.8  0.2 -0.4  2.2 -0.7 -0.8 -0.9 -3.1 -0.2 -0.1  0.4 -1.6 -0.3 -0.3 -0.3 -1.4 -2.9  0.1  1.3 -0.9 -0.3 -0.8 -0.1 -1.  -0.3  6.3  2.4 -0.2 -0.2  0.8 -0.2  0.8 -0.2 -0.5 -0.5  1.3 -0.4  5.1  5.3 14.1 -0.4 -0.1  1.1  0.3 15.  25.2 -0.2 -0.2 -0.7 -0.6 -0.2  0.5  0.4 -0.1 -0.2 -0.6 -0.6 -0.3  4.9  0.2  0.  -0.2 -1.7 -0.4 -0.2 -0.1  0.4 -0.3 -1.2 -0.4 -0.4  0.2 -0.3 -0.1 -0.4  1.1 -0.2 -0.3 -0.3 -0.1 -0.3 -0.3 -0.3 -0.3 -0.1 -1.  -2.3 -0.9  5.   0.3 -2.  -0.4 -0.1 -1.6 -0.4 -0.6 -0.2 -0.4 -0.5  2.  -0.4 -0.4 -0.3 -1.4 -1.9 -1.7 -0.6  0.8 -0.4 -0.2 -0.1 -0.1 -0.2 -0.4 -0.4 -2.6 -0.3 -0.1 -5.4 -0.4 -0.4 -0.  -0.7  1.7 -0.4  0.4  3.9 -1.  -0.2  0.2 -0.1 -0.2 -0.  -1.  -0.2 -0.4 -2.4 -0.7 -0.3 -0.2  1.5  4.4 -0.1 -0.8 -1.3  0.   1.3 -1.2  0.5 -4.  -0.2 -1.9 -0.1 -0.2 -2.1  0.9 -0.1 -0.4 -0.8 -0.5 -3.1 -0.1 -3.2  0.   8.  -3.1]
vy_50sample [[6 3 5 1 4 9 7 0 2 8]
 [5 3 8 2 6 6 0 4 9 1]
 [5 9 3 1 4 4 7 2 2 0]
 [6 1 0 7 8 4 9 2 3 5]
 [5 0 8 6 1 9 3 2 4 7]
 [2 5 3 8 9 6 4 0 0 1]
 [2 6 3 1 9 5 8 0 4 7]
 [4 2 8 9 7 0 1 5 3 6]
 [4 8 7 3 0 2 5 9 1 6]
 [6 3 1 4 2 9 5 0 7 8]]
vt_50sample [[6 3 5 1 4 9 7 0 2 8]
 [5 3 8 2 6 7 0 4 9 1]
 [5 9 1 3 4 8 7 6 2 0]
 [6 1 0 7 8 4 2 9 3 5]
 [5 0 8 6 1 9 3 2 4 7]
 [5 3 2 8 9 6 4 0 7 1]
 [2 6 3 1 9 5 0 8 4 7]
 [4 2 8 9 7 0 1 5 3 6]
 [4 8 7 3 0 2 5 9 1 6]
 [6 3 1 4 2 9 5 0 7 8]]
Epoch 51010: Training cost= 0.2144, Training acc= 0.8635, Validation cost= 0.2586, Validation acc= 0.8636
Epoch 51020: Training cost= 0.2343, Training acc= 0.8635, Validation cost= 0.2551, Validation acc= 0.8636
Epoch 51030: Training cost= 0.2862, Training acc= 0.8635, Validation cost= 0.2643, Validation acc= 0.8636
Epoch 51040: Training cost= 0.2537, Training acc= 0.8635, Validation cost= 0.2688, Validation acc= 0.8636
Epoch 51050: Training cost= 0.2300, Training acc= 0.8635, Validation cost= 0.2413, Validation acc= 0.8636
Epoch 51060: Training cost= 0.2247, Training acc= 0.8635, Validation cost= 0.2708, Validation acc= 0.8636
Epoch 51070: Training cost= 0.2468, Training acc= 0.8636, Validation cost= 0.2024, Validation acc= 0.8636
Epoch 51080: Training cost= 0.2273, Training acc= 0.8636, Validation cost= 0.2092, Validation acc= 0.8636
Epoch 51090: Training cost= 0.1976, Training acc= 0.8636, Validation cost= 0.2128, Validation acc= 0.8637
Epoch 51100: Training cost= 0.2536, Training acc= 0.8636, Validation cost= 0.2510, Validation acc= 0.8637
tm  [ 0.1 -0.2  0.3 -6.3 -1.4  0.5  0.2 -0.1 -0.9 -0.4 13.5 -0.2 -0.2 -0.4 15.3  1.1 -0.1 -0.4 -0.5 -0.  -1.3 -0.1  1.7 -0.3 -1.4  0.9 -0.1 -0.3 -1.3  1.7  1.9 -0.3  2.  14.2 -0.1  0.1  2.5  6.1 -4.4 -0.5  3.2  3.6  1.   1.6 -0.2 -0.3 -2.1 -0.2  1.8  4.6 -0.4 -0.1 -0.4 20.  -0.  -1.9 -1.2 -1.4 -0.  -3.6  5.3 -0.3 -0.   0.  -0.  -0.3 -0.  -0.3 -0.5 -0.1 -0.   3.5 -0.3 -0.7 -6.  -0.2 -0.3  0.6  0.1 -0.1 -1.1  0.  -0.2 -0.3 -0.9  4.5  6.4 -0.1 -0.1 -0.5 -0.7  0.   0.1  2.  -0.5 -0.2  0.6 -3.3 -0.4 -0.   1.4  6.6 -0.3 -0.4 -0.2 -0.2 -4.   0.6 -0.4  1.7 -0.2  0.  -0.2 -0.5  2.3 -2.1 -0.2 -0.7 -0.  -0.1 -0.4 -1.1 -0.   1.4 -0.3 19.5 -0.1 -4.3 -0.3  1.9 -0.  -0.2 -0.5 -0.1 -1.3 11.9 -0.2  0.  -0.4 -0.5 -1.  -0.8 -0.6 -0.1 -0.1 -0.1 -0.1 -0.2 -0.8 -0.   6.  -0.3 -0.3 -0.9 -0.1 -0.1 -1.1 -0.2 -0.4 -0.2 -0.  -0.5 -0.1 -0.1  0.   1.  -0.3 -0.6 -0.3 -0.1  0.3 -0.2 -0.4 -0.3 -0.1  1.7 -1.  -0.2  5.1 -0.3 -0.5 -0.4 -0.2 -1.7 -0.1 -0.5 -0.1 -0.8 -0.4 -0.4 -0.3 -0.3  0.5 -0.8 -1.8  1.2 -1.1 -0.9 -0.1  0.   0.3 -0.2 -0.1 -0.2 -0.4 -3.9 -0.2 -0.3 -1.5 -0.3 -0.3 -1.5  0.8 -0.6  0.9 -0.4 -0.8 -1.3 -0.4 -0.5 -0.  -0.2 -0.7 -1.7  3.1 -1.3  4.9 -0.1 -0.8  0.5 -0.6  2.5 -0.4 -0.6  0.4  1.2 -0.  -1.3  0.3 -2.9 -0.1 -1.  -0.1 -0.   4.9  4.8 -0.4 -0.5 -0.7  1.4  2.2 -0.1 -2.6 -0.3 -2.7  0.9]
ty_50sample [[2 4 7 7 6 5 1 8 3 9]
 [1 3 2 5 7 8 0 6 4 9]
 [0 9 3 5 8 2 6 7 4 1]
 [1 9 7 0 6 4 3 2 8 5]
 [6 8 5 1 0 2 7 4 3 9]
 [5 9 8 6 2 3 1 0 4 7]
 [2 0 5 4 6 8 9 7 3 1]
 [7 1 2 9 3 5 8 4 6 0]
 [6 4 3 2 5 5 0 1 7 9]
 [4 9 0 2 5 6 3 7 8 1]]
tt_50sample [[2 4 0 7 6 5 1 8 3 9]
 [1 3 2 5 7 8 0 6 4 9]
 [0 9 3 5 8 2 6 7 4 1]
 [1 9 7 0 6 4 3 2 8 5]
 [6 8 5 1 0 7 2 4 3 9]
 [5 9 8 6 2 3 1 0 4 7]
 [2 0 5 4 6 8 9 7 3 1]
 [7 1 2 9 3 5 8 4 6 0]
 [6 4 3 2 5 8 0 1 7 9]
 [4 9 2 0 5 6 3 7 1 8]]
vm  [ 2.2 -0.4  4.7 -0.3 -1.1  0.2 -0.1 -0.2 -0.4  2.2 -4.6 -0.  -0.1 -0.6  6.6 -0.3 -0.6  0.1 -0.3 -0.3 -1.  -0.3 -0.8 -0.2 -1.  -0.5 -0.7 -0.6 -0.4  2.  -1.3 -0.2  2.5 -3.3 -0.2 -0.1 -0.2 -1.5 -6.7 -0.6  1.8  7.5 -0.8 -1.1 -0.2 -0.7 -0.8 -0.3  5.6 14.9 -0.5  0.1 -0.9  4.  -0.9 -1.  -1.   6.7  1.2  6.6  0.5 -1.4 -0.5 -0.1 -0.3 -0.6  0.9  0.8  4.  -0.5 -0.5 -0.4 -0.8 -1.  -5.7 -0.5 -0.5 -1.1 -0.1 -0.1 -6.9  0.2 -0.1  1.2 -2.   8.7  3.1 -0.  -0.1 -0.6 -0.2 -0.1 -0.3 -0.7 -0.5  0.4 -0.8 -3.6 -0.5 -0.7 -0.8  6.2 -0.3 -0.3 -0.1 -0.7 -2.9 -0.3 -1.2  1.  -0.5  1.  -0.1 -0.5  1.  -0.6  0.8  1.5 -0.2 -0.3 -0.7 -1.  -0.5 -0.7 -0.3  8.3 -0.1 -0.3  2.  -0.1  0.1 -0.4 -0.1 -0.5 10.6  6.1 -0.1 -0.2 -0.2 -0.7 -0.4 -0.3 -0.1 -0.3 -0.1  0.2 -0.3 -0.2  2.9 -0.1 -0.4 -0.2  2.8 -0.8 -0.6  0.4  0.2 -0.4 -1.6 -0.6 -0.2  0.6 -0.4 -0.  -0.2  0.4 -0.1 -0.3 -0.6 -0.3 -0.2 -0.  -0.3  0.2 -0.  -0.8 -2.4 -0.3  5.5 -0.1 -2.1 -1.1 -0.1 -1.6 -0.1 -0.2  0.8 -0.4 -0.3 -0.6 -0.1 -0.3 -0.5 -0.6  2.  -0.6 -0.8 -0.4 -0.  -0.2 -0.4 -0.1  0.2 -0.6  0.4 -3.4  0.1 -0.3 -0.2 -0.2 -0.1 -0.7 -1.  -2.6 -0.6 -0.3  7.8 -0.5 -0.4  1.3  0.4 -0.3 -0.8 -2.   6.3 -0.1 -1.   0.5 -0.2  2.8 -0.1  3.8 -0.4 -0.1 -1.2 -1.3  2.1 -0.9  2.4 -7.2 -0.1 -2.6 -0.1  0.4 19.2  1.2  2.6 -0.5 -1.  -0.3 18.2 -0.1 -3.6  1.1 -0.9  3.1]
vy_50sample [[6 5 8 0 7 2 4 9 1 3]
 [5 1 8 0 4 2 7 3 9 6]
 [6 5 4 1 0 8 2 9 3 7]
 [6 3 2 7 9 4 8 1 0 5]
 [2 8 7 6 4 1 3 5 0 9]
 [9 2 8 5 6 1 0 7 3 4]
 [1 8 3 2 4 7 0 6 9 5]
 [4 1 8 7 6 5 3 2 0 9]
 [0 3 7 1 5 4 6 8 9 2]
 [8 9 0 1 4 5 7 2 6 3]]
vt_50sample [[6 5 8 0 7 2 4 9 1 3]
 [5 1 8 0 4 2 7 3 9 6]
 [6 5 4 1 0 8 9 2 3 7]
 [6 3 2 7 9 4 8 1 0 5]
 [2 8 7 6 4 1 3 5 0 9]
 [9 2 8 5 6 1 0 7 3 4]
 [1 8 3 2 4 7 0 6 9 5]
 [4 1 8 7 6 5 3 2 0 9]
 [0 3 7 1 5 4 6 8 9 2]
 [8 9 0 1 4 5 7 2 6 3]]
Epoch 51110: Training cost= 0.2727, Training acc= 0.8636, Validation cost= 0.2233, Validation acc= 0.8637
Epoch 51120: Training cost= 0.2158, Training acc= 0.8636, Validation cost= 0.2051, Validation acc= 0.8637
Epoch 51130: Training cost= 0.2408, Training acc= 0.8636, Validation cost= 0.2504, Validation acc= 0.8637
Epoch 51140: Training cost= 0.2442, Training acc= 0.8636, Validation cost= 0.2120, Validation acc= 0.8637
Epoch 51150: Training cost= 0.1903, Training acc= 0.8636, Validation cost= 0.2470, Validation acc= 0.8637
Epoch 51160: Training cost= 0.2192, Training acc= 0.8636, Validation cost= 0.2335, Validation acc= 0.8637
Epoch 51170: Training cost= 0.2477, Training acc= 0.8636, Validation cost= 0.2009, Validation acc= 0.8637
Epoch 51180: Training cost= 0.2565, Training acc= 0.8637, Validation cost= 0.1968, Validation acc= 0.8637
Epoch 51190: Training cost= 0.2580, Training acc= 0.8637, Validation cost= 0.2291, Validation acc= 0.8637
Epoch 51200: Training cost= 0.2294, Training acc= 0.8637, Validation cost= 0.2063, Validation acc= 0.8638
tm  [ 1.3 -0.2  4.7  7.2 -1.1 -0.2 -0.5  0.5 -1.  -0.2  2.5 -0.2 -0.1 -0.1  1.8 -0.4 -0.2 -0.1 -0.5 -0.9 -1.2 -0.3  2.1 -0.1 -1.1  2.3 -0.3 -0.4 -0.8 10.4  1.2  0.3 -0.3 10.3  0.  -0.2  2.6 -1.7 -1.2 -0.3  0.4  4.6  3.2 -0.7 -0.   0.6  4.9  0.5  6.1  3.6 -0.4  0.3  0.5 -1.6 -0.4 -0.3 -0.5  2.8 -3.1 -0.6 -1.9  0.  -0.4 -0.1 -0.2 -0.1 -0.1 -0.5  1.3  0.3 -0.   0.1 -0.2  0.7 -0.3 -0.2 -0.1  0.6  0.1 -0.2 12.8  1.1 -0.3 -0.  -1.4  5.4  6.5  0.  -0.  -0.2 -0.5 -0.1 -0.1  1.3 -0.5  0.4  0.5 -1.  -0.4 -0.2  0.4  6.2 -0.   0.2 -0.6 -0.1 -0.2 -0.2  1.1 -1.6 -0.1 -0.4 -0.2 -0.2 -0.8 -0.  -0.3 -1.3 -0.2 -0.5 -0.3  6.2  0.7 -0.5 -0.   2.6 -0.1  7.2 -2.9 -1.9 -0.2 -0.1 -0.1 -0.3  4.7 15.1 -0.  -0.2 -0.5 -0.5  0.4 -0.4  0.7 -0.1 -0.1 -0.2  0.7 -0.1 -0.3 -0.2 -0.9 -0.2  2.   0.3 -0.2 -0.1 -0.4 -0.3 -1.2 -0.7  0.4  1.4 -0.1 -0.1 -0.1 -0.2 -0.2 -0.6 -0.1 -0.  -0.  -0.1 -0.1 -0.1 -0.1  0.4 -0.9 -0.   1.1 -0.1 -1.4 -0.1 -0.4 -1.3 -0.2 -0.1 -0.2 -0.5 -0.1 -2.6 -0.1 -0.2 -0.3 -0.9 16.  11.2  0.7  1.8 -0.  -0.1  0.8 -0.1 -0.1 -0.2 -0.3  1.2 -0.1 -0.2 -2.1 -0.1 -0.7 -0.7 -0.1 -1.5 -0.3 -0.2  4.  -0.8 -0.  -0.8 -0.1 -0.2 -0.3 -0.6  4.5 -0.2 -1.4 -0.5 -0.3  2.3  1.6 -0.7 -0.4 -0.7 -0.3 -1.  -0.7  1.3  1.   4.2 -0.2  0.6 -0.4 -0.2 -2.2 -1.6 -0.4 -0.3 -0.7 -0.5 -3.3  0.6 -0.7 -0.1  0.4  8.5]
ty_50sample [[6 7 9 5 0 0 2 8 3 1]
 [0 9 2 1 6 4 7 5 3 8]
 [9 2 4 5 0 6 1 7 7 8]
 [9 8 4 6 1 5 2 7 0 3]
 [5 6 3 2 8 4 7 9 0 0]
 [8 0 9 4 1 3 6 5 7 2]
 [4 5 8 9 3 1 2 6 7 0]
 [5 2 6 4 7 0 8 3 9 1]
 [7 5 8 9 3 6 4 2 0 1]
 [5 0 8 3 2 6 7 4 9 9]]
tt_50sample [[6 7 9 5 0 4 2 8 3 1]
 [9 0 2 1 6 4 7 5 3 8]
 [9 2 4 5 0 6 1 3 7 8]
 [9 8 4 6 1 5 2 7 0 3]
 [5 6 3 2 8 4 7 9 0 1]
 [8 0 9 4 1 3 6 5 7 2]
 [4 5 8 9 3 1 2 6 7 0]
 [5 2 6 4 7 0 8 3 9 1]
 [7 5 8 9 3 6 4 2 0 1]
 [5 0 8 3 2 6 7 4 1 9]]
vm  [-1.  -0.  -2.8 -3.5 -1.3 -0.  -0.5  0.3 -1.1 -0.8  4.6 -0.3  0.1 -0.   2.8  5.2 -0.2 -0.4 -0.9 -0.5 -1.1 -0.1 -0.1 -0.3 -1.6 -0.1  0.3 -0.3  0.   5.9  2.  -0.1 -0.7 -0.  -0.  -0.2  3.1  2.5 -0.9 -0.3  3.9  6.   3.3  4.9 -0.   0.5 -0.6 -0.5 -1.1  6.9 -0.1 -0.2 -0.2  5.9 -1.4 -0.6 -0.9 -0.3 -1.8 -1.8  5.2 -0.8 -0.3  0.4 -0.3  1.1 -0.1 -0.3 -0.2 -0.1  0.8 -1.7 -0.6  0.8 -3.1 -0.9 -0.1 -0.4 -0.2  0.4 -1.   0.1 -0.4 -0.5  1.3  6.4  3.5  0.3 -0.3 -0.4 -0.1  0.  -0.2  0.9 -0.7  0.3 -0.3 -2.3  0.8 -0.2  2.   2.4 -0.3 -0.2 -0.1  1.4 -2.   0.9  1.5 -0.8 -0.3 -0.2 -0.1 -0.3 -1.7 13.7 -0.9 -1.2 -0.3 -0.6 -0.3  2.5  0.6  0.3 -0.2  4.1 -0.1 -0.9 -1.  -0.6  0.2 -0.3 -0.2 -0.1  3.1  2.1 -0.2 -0.1 -0.2 -0.3 -0.2 -0.3 -0.5 -0.3 -0.1 -0.3 -0.4 -0.3  6.5 -0.1  2.4 -0.1 -0.5 -0.6 -0.2 -0.2 -0.8  1.1  0.1 -0.1 -0.4 -0.4 -0.4  0.6 -0.   0.3 -0.2 -0.4  0.1 -0.1 -0.1 -0.3  0.4 -0.1 -0.2 -1.  -0.6 -0.2  0.8 -0.1 -1.9  0.8 -0.3 -2.2  0.1 -0.6 -0.3 -0.8 -0.  -1.5  0.4  0.1 -0.  -1.3 -1.6  4.  -0.3  4.8 -0.1 -0.2 -0.2 -0.3 -0.1 -0.3 -0.  -2.2 -0.2 -0.1 -2.5  0.6 -0.1  2.2 -0.3  6.3 -0.6 -0.8 -2.1 -1.  -0.7 -0.3  0.1 -0.2 -0.5 -1.4  1.3  4.8 -0.1 -0.3 -0.1 -0.2 -0.7  1.1 -0.2 -0.7 -0.3  4.6 -0.6 -0.4  1.9 -3.8 -0.1 -1.3 -0.3 -0.1  4.8  2.  -0.6  0.5 -0.7 -0.4  2.6  0.8 -0.6 -0.3 -0.9  4.6]
vy_50sample [[4 5 1 2 6 8 7 9 3 0]
 [4 5 9 1 6 2 8 3 7 0]
 [8 6 1 7 0 5 5 2 9 3]
 [8 7 9 3 6 5 4 0 2 1]
 [0 6 2 4 1 8 3 9 5 7]
 [5 2 8 1 7 0 4 9 6 3]
 [5 7 3 4 9 0 1 2 6 8]
 [1 5 4 3 8 6 2 7 9 0]
 [2 8 0 6 4 4 7 5 1 3]
 [1 4 6 6 2 3 8 5 9 0]]
vt_50sample [[4 5 1 2 6 8 7 9 3 0]
 [4 5 9 1 6 2 8 3 7 0]
 [8 6 1 7 0 5 4 2 3 9]
 [8 7 9 3 6 5 4 0 2 1]
 [0 6 2 4 1 8 3 9 5 7]
 [5 2 8 1 7 0 4 6 9 3]
 [5 7 3 4 9 0 1 2 6 8]
 [1 5 4 3 8 6 2 7 9 0]
 [2 8 0 6 9 4 7 1 5 3]
 [1 4 7 6 3 2 8 5 9 0]]
Epoch 51210: Training cost= 0.2337, Training acc= 0.8637, Validation cost= 0.3412, Validation acc= 0.8638
Epoch 51220: Training cost= 0.2689, Training acc= 0.8637, Validation cost= 0.2955, Validation acc= 0.8638
Epoch 51230: Training cost= 0.2401, Training acc= 0.8637, Validation cost= 0.2652, Validation acc= 0.8638
Epoch 51240: Training cost= 0.2363, Training acc= 0.8637, Validation cost= 0.2306, Validation acc= 0.8638
Epoch 51250: Training cost= 0.2165, Training acc= 0.8637, Validation cost= 0.2024, Validation acc= 0.8638
Epoch 51260: Training cost= 0.1925, Training acc= 0.8637, Validation cost= 0.2000, Validation acc= 0.8638
Epoch 51270: Training cost= 0.2281, Training acc= 0.8637, Validation cost= 0.2459, Validation acc= 0.8638
Epoch 51280: Training cost= 0.2621, Training acc= 0.8637, Validation cost= 0.2274, Validation acc= 0.8638
Epoch 51290: Training cost= 0.1846, Training acc= 0.8638, Validation cost= 0.2388, Validation acc= 0.8638
Epoch 51300: Training cost= 0.2306, Training acc= 0.8638, Validation cost= 0.2620, Validation acc= 0.8638
tm  [-0.2 -0.   7.  10.9 -1.4 -0.2 -0.6  0.2 -0.8 -0.7 -0.6  0.1 -0.2 -0.2  1.3  2.4 -0.2 -0.2 -0.1 -1.2 -0.7 -0.2 -0.6 -0.1 -1.  -0.1 -0.5  0.4 -1.   9.4 -0.5 -0.3 -0.3  4.5 -0.2 -0.1  2.4  2.8  8.6 -0.6  1.1  7.5  3.4 -0.5 -0.1 -0.3  5.8  0.3  4.5 12.8 -0.2 -0.   0.5 -1.1 -0.7 -0.2 -0.6  6.7 -3.5  5.2 -1.9 -0.4 -0.6 -0.2 -1.5  0.8  0.6 -0.6  0.3 -0.1 -0.1 -0.   0.4 -0.2  2.4  0.7 -0.2 -0.6 -0.1 -0.2  4.3 -0.7 -0.1 -0.3 -1.3  9.3  3.  -0.2 -0.2 -0.  -0.8 -0.1 -0.   1.5 -0.1  0.6  1.4 -0.3 -0.7  0.5  3.   7.4 -0.3 -0.  -0.2  0.6  0.2 -0.6  0.1 -2.1 -0.4 -0.1 -0.   0.1 -1.7  1.5  0.7 -1.3 -0.1 -0.6 -0.4  8.6 -0.4 -0.8 -0.1  1.7 -0.1  4.6 -3.4 -4.3 -0.3 -0.4  0.1 -0.7 -2.9 -1.4  0.1 -0.2 -0.6 -0.3 -0.3 -0.1 -0.2 -0.2 -0.1  0.4 -0.2 -0.2  0.4 -0.  -1.1 -0.2  2.7 -0.8 -0.3 -0.  -0.5 -0.4 -0.  -0.3  0.1 -0.3 -0.4 -0.1 -0.3  0.8  0.3 -0.3 -0.3 -0.1 -0.3 -0.2 -0.3 -0.4 -0.4  0.3 -0.3 -0.1 -0.7 -0.2 -2.3  0.3 -0.1 -0.9 -0.2  0.3 -0.2 -0.3 -0.1 -2.3 -0.2 -0.  -0.2 -0.6 13.4 13.6  0.4  4.5 -0.2 -0.2 -0.2 -0.1 -0.1 -0.4  0.   2.1 -0.2 -0.1 -0.8 -0.2  0.7 -0.9 -0.  -1.1  1.  -0.1  1.9 -0.6 -0.   0.   0.2 -0.1 -0.  -0.6  3.4  1.7  0.3 -0.2  2.   2.6 -0.7 -0.9 -0.1 -0.4 -0.  -1.6 -0.6  0.4 -0.5  1.  -0.2 -0.2  0.3 -0.3 -0.4 -1.6 -0.5 -0.1 -0.9 -0.5 -1.3  0.4  4.4 -0.3 -1.8 14.5]
ty_50sample [[7 5 9 8 2 6 0 4 1 3]
 [4 9 2 0 6 3 3 8 1 5]
 [7 5 0 4 2 9 8 6 3 3]
 [5 0 4 9 2 6 8 1 3 7]
 [5 1 4 0 0 2 6 8 7 3]
 [0 7 3 8 9 1 4 6 2 5]
 [1 0 6 5 7 3 8 2 9 4]
 [3 9 1 4 2 6 8 7 0 5]
 [1 1 6 0 8 5 3 2 4 9]
 [5 3 4 9 7 6 1 1 8 2]]
tt_50sample [[7 5 9 8 2 6 0 4 1 3]
 [4 9 2 0 6 3 7 8 1 5]
 [7 5 0 4 2 9 8 6 1 3]
 [5 0 4 9 6 2 8 1 3 7]
 [5 1 4 9 0 2 6 8 7 3]
 [0 7 3 8 9 1 4 6 2 5]
 [1 0 6 5 7 3 8 2 9 4]
 [3 9 1 4 2 6 8 7 0 5]
 [7 1 6 0 8 5 3 2 4 9]
 [5 3 4 9 7 6 0 1 8 2]]
vm  [-0.7 -0.3  4.2  9.7 -1.6 -0.4 -0.2 -0.  -0.1 -0.7 -3.6 -0.4 -0.2 -0.5 -0.3 -1.2 -0.1 -0.6  1.8 -0.6 -1.  -0.2  0.7 -0.2 -1.1  3.8 -0.1  0.6 -0.7 -0.1  1.2 -0.2 -1.3  5.3 -0.  -0.2  1.1 -2.4  0.9  0.4 -1.6  3.8 -0.3 -1.4 -0.3  0.2  3.9 -0.   2.4  4.6 -0.3 -0.2  1.  -3.8 -0.1  0.2 -0.5  5.7  1.2  2.  -0.4  0.1 -0.3  0.  -0.5  1.2 -0.  -0.4  1.4  0.5 -0.2  0.8 -0.1  1.5  1.3  2.7 -0.2  0.1  0.5  1.9  9.7 -0.3 -0.2  0.6  0.1  7.3 -0.3 -0.  -0.2 -0.1 -0.5 -0.1 -0.1 -1.4 -0.6  0.1  0.9 -2.2 -0.6 -0.4  2.3  4.9 -0.5 -0.1 -0.4  1.2 -0.  -0.1 -1.1 -1.5  0.   0.2 -0.  -0.4  2.7  1.4 -0.8 -0.5 -0.  -0.4 -0.4  7.3  1.5  1.9 -0.1 -0.6 -0.2 13.4  0.6 -2.2  0.7 -0.3 -0.3 -1.2  5.8  8.9  0.6 -0.1  0.  -0.   1.9 -0.4  0.8  0.2  0.   0.4  0.5 -0.1  2.  -0.1 -1.  -0.1 -0.1  0.1 -0.2 -0.1 -0.4 -0.5 -1.1 -0.3  0.8  3.   0.1 -0.1  0.3 -0.4 -0.5  0.1 -0.1 -0.3 -0.1 -0.2 -0.  -0.5 -0.3 -0.1  1.   0.3 -0.2 -0.1 -1.3 -0.3 -0.5 -1.8  0.1  0.4 -0.1 -0.4 -0.1  1.  -0.1 -0.1 -0.4 -0.8  5.1 -0.1  0.5 -0.7 -0.  -0.1 -0.2  0.2 -0.2 -0.4 -0.  -0.2  0.9 -0.1 -1.4 -0.  -0.6 -0.1 -0.5  2.9 -0.8 -0.3  5.4 -1.1 -0.  -0.8 -0.  -0.2  0.5 -0.9  6.8 -0.3 -1.5  0.9  2.4  2.7 -0.1 -1.3 -0.1 -0.5  1.5 -1.2 -0.5  1.4  4.6  4.  -0.1  0.9 -0.2 -0.  -1.6 -1.6 -0.2 -0.3 -1.4 -0.6 -2.6  0.   0.9 -0.   3.1  9.5]
vy_50sample [[6 9 5 7 0 1 8 4 3 2]
 [3 4 5 6 2 1 9 7 8 0]
 [8 9 5 1 4 3 6 0 7 2]
 [1 1 2 3 8 5 6 4 7 9]
 [8 3 2 0 1 6 9 4 5 7]
 [2 8 4 6 7 9 1 0 5 3]
 [6 1 2 3 8 4 0 9 7 5]
 [2 5 6 1 8 9 0 4 7 3]
 [5 3 1 7 6 2 4 0 8 8]
 [9 6 7 5 3 2 4 0 8 1]]
vt_50sample [[9 6 5 7 0 1 8 4 3 2]
 [3 4 5 2 6 1 9 7 8 0]
 [8 9 5 1 4 3 6 0 7 2]
 [1 0 2 3 5 8 6 7 4 9]
 [8 3 2 0 1 6 9 4 7 5]
 [2 8 4 6 7 9 1 0 5 3]
 [6 1 2 3 8 4 9 0 7 5]
 [2 5 6 1 8 9 4 0 7 3]
 [5 3 1 7 6 2 4 0 8 9]
 [9 6 7 5 3 2 4 8 0 1]]
Epoch 51310: Training cost= 0.2288, Training acc= 0.8638, Validation cost= 0.2126, Validation acc= 0.8638
Epoch 51320: Training cost= 0.2409, Training acc= 0.8638, Validation cost= 0.3683, Validation acc= 0.8639
Epoch 51330: Training cost= 0.2418, Training acc= 0.8638, Validation cost= 0.2744, Validation acc= 0.8639
Epoch 51340: Training cost= 0.2776, Training acc= 0.8638, Validation cost= 0.2057, Validation acc= 0.8639
Epoch 51350: Training cost= 0.2692, Training acc= 0.8638, Validation cost= 0.2717, Validation acc= 0.8639
Epoch 51360: Training cost= 0.2525, Training acc= 0.8638, Validation cost= 0.2426, Validation acc= 0.8639
Epoch 51370: Training cost= 0.2147, Training acc= 0.8638, Validation cost= 0.2824, Validation acc= 0.8639
Epoch 51380: Training cost= 0.2742, Training acc= 0.8638, Validation cost= 0.2656, Validation acc= 0.8639
Epoch 51390: Training cost= 0.2125, Training acc= 0.8638, Validation cost= 0.2772, Validation acc= 0.8639
Epoch 51400: Training cost= 0.2265, Training acc= 0.8638, Validation cost= 0.1965, Validation acc= 0.8639
tm  [-0.8 -0.2 -1.6  1.9 -1.8  0.2 -0.  -0.1 -0.5 -0.1 -0.7 -0.2 -0.2 -0.1 -1.  -1.4 -0.1 -0.2 -0.2 -0.5 -1.3 -0.1  0.8 -0.2 -1.3  4.3 -0.  -0.1 -1.  -2.6  1.2 -0.4 -0.3 -0.9 -0.1 -0.1  1.6 -1.  -1.1 -0.2 -0.   4.3 -0.7 -0.4 -0.1  0.2  0.9 -0.3 -1.5  6.1 -0.2  0.1 -0.1 -1.  -0.   0.5 -0.6  2.6  5.  -0.3  5.6 -0.1  0.  -0.1  1.5 -0.4  0.  -0.1  0.6  0.1  0.1  3.  -0.2  0.5 -2.5 -0.1 -0.1  0.2  0.1 -0.   4.   0.3 -0.3 -0.2  1.1  6.1 -1.4  0.2 -0.1 -0.1 -0.2 -0.1 -0.  -0.7 -0.6 -0.1 -0.1 -3.  -0.1 -0.3 -0.2  2.8 -0.4 -0.  -0.3  0.1 -1.2  0.5 -0.3 -0.4 -0.3 -0.2 -0.  -0.4  6.1 -1.7 -0.3 -0.3 -0.1 -0.2 -0.2  1.5 -0.1 -0.   0.2 -1.3 -0.1  5.3  4.2 -1.3 -0.  -0.1 -0.1 -0.4 11.   9.1 -0.3 -0.1  0.6 -0.2  0.3 -0.7  0.1 -0.3 -0.3 -0.  -0.2 -0.1  4.7 -0.2 -0.3 -0.1 -1.4  0.2 -0.2 -0.1 -0.6  1.1 -0.5 -0.4  0.8 -0.4 -0.1 -0.  -0.  -0.9 -0.4 -0.3 -0.2 -0.2  0.2 -0.2 -0.1 -0.  -0.1 -1.  -1.  -0.   1.3 -0.1 -0.9 -0.4 -0.4 -2.3  0.2 -0.6 -0.2 -0.5 -0.1  7.5  0.4 -0.2 -0.4 -0.9 -1.8 -1.3 -0.4 -1.8  0.5 -0.2 -0.  -0.1 -0.2 -0.2  0.6 -1.2 -0.2 -0.1 -1.5 -0.1 -0.3 -1.2 -0.4  8.3 -1.1  0.5  1.3 -0.9 -0.1 -0.4 -0.  -0.1 -0.1 -1.2  5.1 -0.7 -1.8  0.1 -0.2 -0.6 -0.1 -0.3 -0.1 -0.2  0.7  1.1 -0.1 -0.2  3.3 -0.5 -0.  -0.4 -0.3 -0.2 -0.3 -1.  -0.5 -0.1 -1.4 -0.5 -1.4 -0.1 -0.6 -0.1 -0.1  7. ]
ty_50sample [[1 0 6 5 9 4 8 2 7 3]
 [8 7 0 4 1 2 9 6 5 3]
 [3 8 0 0 2 9 5 7 7 4]
 [7 2 1 3 6 0 4 5 8 9]
 [5 6 8 0 0 2 9 7 3 4]
 [6 4 2 8 7 1 9 0 5 3]
 [9 7 1 2 5 3 8 6 4 0]
 [1 8 3 6 9 2 4 7 5 0]
 [5 3 8 8 2 1 0 6 7 4]
 [8 8 5 1 9 6 3 4 7 2]]
tt_50sample [[1 0 6 5 9 4 8 2 7 3]
 [8 7 0 4 1 2 9 6 5 3]
 [3 8 6 0 2 5 9 7 4 1]
 [7 2 1 3 6 0 4 5 9 8]
 [5 6 1 8 0 2 9 7 3 4]
 [6 4 2 8 7 1 9 0 5 3]
 [9 7 1 2 5 3 8 6 4 0]
 [1 8 3 6 9 2 4 7 5 0]
 [5 3 9 8 2 1 0 6 7 4]
 [8 0 5 1 9 6 3 4 7 2]]
vm  [-0.4 -0.3  5.6 15.8 -1.1 -0.2 -0.2  0.1  0.8 -1.2  7.  -0.3 -0.1 -0.3 -0.7  7.2  1.  -0.4  0.6 -0.6 -0.8  0.2  1.4 -0.3 -1.1  2.7 -0.   0.4  1.5 -0.  -0.6 -0.4 -0.2  2.6 -0.2  0.1  1.1  3.6  5.7 -0.1 -0.2  3.5  0.5 -0.9 -0.   0.1  4.3 -0.2  3.8  5.1 -0.3 -0.1 -0.   1.6 -0.8  0.7 -0.2  8.2 -0.4  4.8 -1.1 -0.4 -0.5  1.  -0.3  1.4  1.  -0.1 -0.1  0.2 -0.  -1.7 -0.3  0.9  1.   1.8 -0.2  0.5 -0.2  0.3  8.6 -0.2 -0.1  0.1 -0.8  6.4 -0.9 -0.1 -0.1  0.3 -0.1 -0.2 -0.  -0.8 -0.6 -0.3  1.6 -1.7 -0.3  0.8  3.7  4.  -0.7  0.7 -0.2  0.7  0.4 -0.2  1.  -0.9 -0.3 -0.1  0.3 -0.4 -1.1 15.  -0.4 -0.8 -0.1 -0.1 -0.3  5.1  0.4 -0.1  0.7 -1.  -0.   0.8 -0.4 -1.9  0.1 -0.2 -0.1 -1.1  1.9  3.3 -0.3 -0.  -0.1 -0.3 -0.5 -0.4 -0.4 -0.2  0.1  0.6 -0.1 -0.1  2.9 -0.2 -1.6 -0.1  1.9 -0.8 -0.2  0.  -0.5 -0.4 -0.1 -0.1  1.3  0.6 -0.1 -0.   0.4 -0.9 -0.7 -0.4  0.7 -0.3 -0.  -0.1 -0.1 -0.2 -0.1 -0.5 -0.5  0.6 -0.5 -0.2 -1.3  0.2 -0.6 -1.9  0.2 -0.4  0.2 -0.5  0.   0.2  0.1 -0.1 -0.1 -0.6  9.2  1.2  0.2  2.3  0.3 -0.1 -0.2 -0.1  0.2 -0.3  0.4  0.9  0.3  0.4 -1.2  0.1 -0.3  3.9 -0.3  0.8 -0.7 -0.3  4.9 -0.7 -0.2 -0.4 -0.2 -0.  -0.1 -1.   3.3  3.9  2.2  0.7  1.6  2.5 -0.5 -1.3  0.  -0.2 -0.2 -1.2 -0.1  1.2  2.3  3.5  0.3  1.1 -0.1 -0.1 -1.4 -1.6 -0.1  0.6 -1.3 -0.7 -2.4 -0.   3.1 -0.2 -1.5  7.9]
vy_50sample [[9 2 5 6 6 8 1 3 4 0]
 [8 4 6 0 1 2 7 3 9 5]
 [1 4 5 8 7 0 2 9 6 3]
 [1 0 4 9 2 8 6 5 3 7]
 [5 8 6 0 9 2 3 1 4 7]
 [0 8 6 3 1 5 7 9 2 4]
 [6 4 0 5 1 3 2 9 8 7]
 [1 4 0 9 8 7 3 5 6 2]
 [4 1 7 7 8 9 9 5 3 2]
 [1 0 6 8 3 7 9 5 4 2]]
vt_50sample [[9 2 5 6 7 8 1 3 4 0]
 [8 4 6 0 1 2 7 3 9 5]
 [1 4 5 8 7 0 2 9 6 3]
 [1 0 4 9 2 8 6 5 3 7]
 [5 8 6 0 9 2 3 1 4 7]
 [0 8 6 3 5 1 7 9 2 4]
 [6 4 0 5 3 1 2 9 8 7]
 [1 4 0 9 8 7 3 5 6 2]
 [4 1 7 8 6 0 9 5 3 2]
 [1 0 6 8 3 7 9 5 4 2]]
Epoch 51410: Training cost= 0.2424, Training acc= 0.8639, Validation cost= 0.2275, Validation acc= 0.8639
Epoch 51420: Training cost= 0.2547, Training acc= 0.8639, Validation cost= 0.1921, Validation acc= 0.8639
Epoch 51430: Training cost= 0.2246, Training acc= 0.8639, Validation cost= 0.2606, Validation acc= 0.8639
Epoch 51440: Training cost= 0.2284, Training acc= 0.8639, Validation cost= 0.2368, Validation acc= 0.8640
Epoch 51450: Training cost= 0.2663, Training acc= 0.8639, Validation cost= 0.2990, Validation acc= 0.8640
Epoch 51460: Training cost= 0.1948, Training acc= 0.8639, Validation cost= 0.2356, Validation acc= 0.8640
Epoch 51470: Training cost= 0.1874, Training acc= 0.8639, Validation cost= 0.2257, Validation acc= 0.8640
Epoch 51480: Training cost= 0.2648, Training acc= 0.8639, Validation cost= 0.2384, Validation acc= 0.8640
Epoch 51490: Training cost= 0.2363, Training acc= 0.8639, Validation cost= 0.1784, Validation acc= 0.8640
Epoch 51500: Training cost= 0.2684, Training acc= 0.8639, Validation cost= 0.2603, Validation acc= 0.8640
tm  [-1.2 -0.1 -2.1  8.7 -1.  -0.1 -0.3 -0.1 -0.4 -1.1 -0.8 -0.2  0.2 -0.1 -3.2  5.9  1.3 -0.2  0.3 -1.6 -1.3 -0.3 -0.5 -0.2 -1.2 -0.2 -0.3 -0.3  2.3 -2.6 -0.1 -0.1 -0.1 -4.7  0.5  0.3  1.5  5.2 19.1 -0.4  1.5 -3.5 -0.4  1.2 -0.2  0.4  8.3 -0.6 -1.3 -1.8 -0.1 -0.2 -0.7 -1.3 -1.4  3.7 -0.5 -0.7  2.4  3.7  0.5 -0.3 -0.5  0.6 -0.8  1.2 -0.1 -0.4 -0.  -0.2  0.5 -2.5 -0.6 -0.1  0.   1.9 -0.4  0.6 -0.2 -0.1  4.7 -0.5 -0.5 -0.   1.1 -3.  -1.  -0.2  0.1 -0.1 -0.6 -0.  -0.1 -0.  -0.4 -0.3  0.4 -1.2 -0.4  0.7  4.1 -2.5 -0.4 -0.1 -0.4 -0.6 -0.4 -0.2 -0.1 -1.7 -0.4 -0.4  0.4 -0.7 -1.1 15.9  1.3 -0.6 -0.2 -0.4 -0.1  6.8 -0.   1.7  0.1 -4.1 -0.1  5.7  2.8  3.7 -0.5 -0.2 -0.4 -0.9 -0.6 -4.6 -0.3 -0.1 -0.1 -0.2 -0.6 -0.3 -0.7 -0.2  0.6 -0.3 -0.2  0.3  3.3 -0.1 -1.  -0.3 -0.3 -0.6 -0.2 -0.2 -0.3 -0.7  2.5 -0.2 -0.4 -1.3 -0.5  0.  -0.2 -0.3 -0.2 -0.4  0.9 -0.2 -0.3 -0.1  0.  -0.2  0.3 -0.2 -0.2 -0.5 -1.9 -0.2 -0.5  1.8 -0.6 -0.9 -0.1  0.1 -0.5 -0.4 -0.2  7.   0.3  0.5 -0.  -1.   1.8 -1.1 -0.   2.8 -0.1  0.5 -0.3 -0.2  0.3 -0.4 -0.2  0.5 -0.3 -0.2  7.4  0.9 -0.3  2.8 -0.3  4.4 -0.1 -0.5 -1.5 -0.6 -0.6 -0.4 -0.1 -0.2  0.2 -0.6 -2.9  5.4 -0.6 -0.2 -0.3 -0.2 -0.7 -0.6 -0.   1.1 -0.5  2.  -0.4  0.3 -0.2 18.3 -0.1  5.2 -0.1  0.2 -0.3 -1.9  0.4 -0.5 -1.  -0.1 -1.4  0.5 10.7 -0.3  3.9 -0.5]
ty_50sample [[3 9 1 8 2 4 5 7 6 0]
 [6 9 8 4 1 2 5 0 3 7]
 [7 8 1 0 5 9 4 6 2 3]
 [0 0 2 2 9 3 6 1 5 7]
 [4 0 6 3 1 9 5 8 7 2]
 [4 4 1 1 9 0 7 3 6 2]
 [0 3 8 4 7 9 1 6 2 5]
 [7 3 6 9 5 4 1 2 0 8]
 [0 9 6 3 8 1 7 5 4 2]
 [9 9 2 3 7 5 8 0 6 1]]
tt_50sample [[3 9 1 8 2 4 5 7 6 0]
 [6 9 8 4 1 2 5 0 3 7]
 [7 8 1 0 5 9 4 6 2 3]
 [0 8 4 2 9 3 6 1 5 7]
 [4 0 6 3 1 9 5 8 7 2]
 [8 5 4 1 9 0 7 3 6 2]
 [0 8 3 4 7 9 1 6 2 5]
 [7 3 6 9 5 4 1 2 0 8]
 [0 9 6 3 8 1 7 5 4 2]
 [4 9 2 3 7 5 8 0 6 1]]
vm  [ 0.9  0.1  2.8 12.7 -1.5 -0.2 -0.3 -0.2 -0.8 -0.2  1.1 -0.1 -0.2  0.1 -1.6 -1.2 -0.5 -0.4  1.4 -1.4 -1.4 -0.3 -0.9 -0.2 -0.3  0.1 -0.3  0.1 -1.1 -1.   1.  -0.   0.7 12.3  0.2 -0.3  1.3 -1.6  6.2 -0.   0.  -2.7 -0.6 -0.6 -0.1 -0.2  9.7 -0.1  5.4 -4.9 -0.1 -0.1 -0.4 -4.6  0.6  1.6 -0.2  0.2  0.2 -2.4 -2.1 -0.9 -0.5 -0.2  0.2 -0.2  0.1 -0.3  1.7 -0.2 -0.1  3.5  0.3 -0.4  3.5 -0.5 -0.3 -0.6 -0.1 -0.2 29.1 -0.4 -0.2 -0.2 -1.3 -2.3  4.  -0.2  0.1  0.3 -0.4 -0.  -0.  -0.  -0.7 -0.  -0.  -1.  -0.1  0.8  2.1 -1.3 -0.1 -0.1 -0.1 -0.6  1.1 -0.2  0.3 -2.3 -0.2 -0.4 -0.1 -0.5  2.9 -1.5  0.1 -0.4 -0.  -0.2 -0.4  9.6 -0.1  0.8 -0.1 -2.1 -0.2 15.1  1.5  0.  -0.  -0.3  0.9 -0.5  4.8 16.7 -0.1  0.3  0.3 -0.5  0.4 -0.4 -0.1 -0.2 -0.2 -0.3 -0.4 -0.1 -0.2 -0.1 -1.4 -0.3  0.2 -0.1  0.1 -0.4  0.9 -0.4 -0.7 -0.3 -0.9 -0.1 -0.4 -0.1 -0.2  2.2  0.7 -0.1 -0.1 -0.3 -0.1 -0.  -0.1 -0.1 -0.2  2.1 -0.8 -0.8 -0.5 -0.2 -1.  -0.2 -0.3 -1.1 -0.2  0.2 -0.1 -0.6 -0.3  3.6 -0.2  0.9 -0.1 -1.  16.5 -0.4 -0.1 -0.7 -0.3 -0.1 -0.1 -0.1 -0.3 -0.5 -0.5  2.7 -0.2  0.3 -2.3 -0.2 -0.1 -1.5 -0.4 -1.5  0.3 -0.3  2.5 -1.3 -0.5 -0.  -0.1 -0.1 -0.2 -0.6 -0.9 -1.6 -2.2  0.3 -0.7  2.6 -0.4 -0.9  0.1 -0.4  1.2 -0.4 -0.4  0.6  1.  16.6 -0.1  3.6 -0.  -0.  -6.  -1.9 -0.2 -0.6 -1.2  0.9 -7.4 -0.2  3.7 -0.3 10.3  2.1]
vy_50sample [[9 9 0 6 7 4 5 1 8 8]
 [5 1 9 8 3 0 7 4 6 2]
 [3 7 0 5 8 6 2 2 1 9]
 [2 5 3 7 0 9 6 1 1 4]
 [9 4 0 1 8 7 3 5 2 6]
 [1 4 0 3 9 5 6 7 2 8]
 [4 7 5 1 3 0 9 2 6 8]
 [4 7 3 0 1 6 2 5 8 9]
 [2 3 4 0 1 6 5 8 8 7]
 [0 9 6 1 4 8 7 3 2 5]]
vt_50sample [[9 3 0 6 7 4 5 1 2 8]
 [5 1 9 8 3 0 7 4 6 2]
 [3 7 0 5 8 6 2 4 1 9]
 [2 5 3 7 9 0 8 6 1 4]
 [9 4 0 1 8 7 3 5 2 6]
 [1 4 0 3 9 5 6 7 2 8]
 [4 7 5 1 3 0 9 2 8 6]
 [4 7 3 0 1 6 2 5 8 9]
 [2 3 4 0 1 6 5 8 9 7]
 [0 9 6 1 4 8 7 3 2 5]]
Epoch 51510: Training cost= 0.2406, Training acc= 0.8639, Validation cost= 0.2357, Validation acc= 0.8640
Epoch 51520: Training cost= 0.2378, Training acc= 0.8639, Validation cost= 0.2732, Validation acc= 0.8640
Epoch 51530: Training cost= 0.2355, Training acc= 0.8640, Validation cost= 0.2229, Validation acc= 0.8640
Epoch 51540: Training cost= 0.2158, Training acc= 0.8640, Validation cost= 0.2523, Validation acc= 0.8640
Epoch 51550: Training cost= 0.2658, Training acc= 0.8640, Validation cost= 0.2666, Validation acc= 0.8640
Epoch 51560: Training cost= 0.2891, Training acc= 0.8640, Validation cost= 0.2131, Validation acc= 0.8641
Epoch 51570: Training cost= 0.2027, Training acc= 0.8640, Validation cost= 0.2327, Validation acc= 0.8641
Epoch 51580: Training cost= 0.1939, Training acc= 0.8640, Validation cost= 0.2174, Validation acc= 0.8641
Epoch 51590: Training cost= 0.2923, Training acc= 0.8640, Validation cost= 0.2539, Validation acc= 0.8641
Epoch 51600: Training cost= 0.2503, Training acc= 0.8640, Validation cost= 0.3310, Validation acc= 0.8641
tm  [-0.7 -0.3  8.6  9.  -1.7 -0.3  0.9  0.5 -1.2 -0.2 -0.7 -0.1 -0.  -0.2  4.9 -0.9 -0.3 -0.2 -0.2 -1.1 -1.3 -0.2 -0.3 -0.1 -1.   1.3 -0.2 -0.2 -1.6  4.4 -0.4 -0.1 -0.6  5.5 -0.2  0.2  3.  -0.3  2.1 -0.5  0.5 -1.1  1.6 -0.8 -0.  -0.1  5.5 -0.2  1.1 11.2 -0.2 -0.1 -0.2 -0.1  1.4 -0.6 -0.4 -2.1 -1.6  5.  -0.8  0.8 -0.8 -0.2 -1.4  0.5 -0.  -0.4  1.7 -0.  -0.1  5.1 -0.7 -0.5 -0.  -0.5 -0.  -0.1 -0.2 -0.3  0.9  0.1 -0.4 -0.  -0.6 -0.7  0.6 -0.2 -0.2 -0.2 -0.6 -0.1 -0.2 -0.2 -0.1 -0.3  0.5 -1.2 -0.6 -0.2  0.4  7.7 -0.4  0.  -0.2  0.2 -0.5 -0.4 -0.  -2.2 -0.9 -0.4  0.3  0.3  2.3 -3.  -0.5 -0.7 -0.1 -0.4 -0.1  8.1  0.1 -0.2 -0.2  5.8 -0.3  3.  -2.9 -2.7 -0.2 -0.5 -0.5 -0.4 -1.8 -0.1 -0.2  0.2 -0.6 -0.6 -0.1 -0.9 -0.  -0.2  0.3 -0.1 -0.2  0.  -3.6 -0.  -1.  -0.3  2.   0.7 -0.1 -0.1 -0.2 -0.4 -0.8 -0.2  0.2  0.9 -0.2 -0.1  0.1 -0.2 -0.2 -0.8 -0.2 -0.  -0.2 -0.  -0.3 -0.2 -0.   3.7 -0.2 -0.4  0.1 -0.1  2.8 -0.  -0.  -1.2 -0.4 -0.7 -0.3 -0.4 -0.  -1.2 -0.1 -0.2 -0.3 -0.3  7.7 11.2 -0.4 -0.9  0.1  0.3 -0.  -0.2  0.1  0.2 -0.1 -0.5 -0.2 -0.1 13.3  0.1 -0.2 -2.1 -0.3 -0.1 -0.6 -0.1  3.6 -0.5 -0.3 -0.8 -0.1 -0.   0.1 -0.7  4.4 -0.8 -0.4 -0.4  1.6  0.6 -0.5 -0.8 -0.1  1.   2.1 -1.9 -0.4 -0.  -0.1 25.4  0.2  7.1 -0.  -0.2  1.7 -1.1 -0.7 -0.3 -1.1 -0.5 -0.4 -0.2  1.  -0.1 -0.9 10.2]
ty_50sample [[7 0 8 9 9 2 4 1 3 5]
 [5 7 2 6 9 4 0 3 8 1]
 [6 9 5 2 4 1 0 3 7 8]
 [3 3 6 8 2 2 1 0 5 4]
 [4 7 0 9 6 2 8 1 5 3]
 [0 6 4 2 5 9 9 7 3 1]
 [4 1 2 5 6 8 3 0 9 7]
 [9 8 6 2 4 1 5 0 3 3]
 [2 6 1 7 5 4 3 9 0 8]
 [0 4 1 2 5 6 9 7 3 8]]
tt_50sample [[7 0 8 9 6 2 4 1 3 5]
 [5 7 2 6 9 4 0 3 8 1]
 [6 9 5 2 4 1 0 3 7 8]
 [3 9 6 8 2 1 7 0 5 4]
 [4 7 0 9 6 2 1 8 5 3]
 [0 6 4 2 5 8 9 7 3 1]
 [4 1 2 5 6 8 3 0 9 7]
 [9 8 6 2 4 1 5 0 3 7]
 [2 6 1 7 5 4 3 9 0 8]
 [0 4 1 2 5 6 9 7 3 8]]
vm  [ 1.5 -0.6 -1.6  1.2 -0.5 -0.4 -0.3 -0.1  0.2  1.  -1.1 -0.2 -0.2 -0.4 -1.2  2.  -0.2 -0.1 -0.2 -0.4 -1.3 -0.1 -0.5 -0.1 -0.9  1.8 -0.4 -0.2 -0.7 -1.6 -1.6 -0.3 -0.7 -7.9 -0.3 -0.1 -0.1  4.9 -1.2 -0.8 -0.2  1.8 -0.5 -0.5 -0.3 -0.4 -0.5 -0.2  7.5 12.6 -0.4 -0.2 -0.7 11.  -1.   0.6 -0.5  2.   2.9  7.4 -0.6 -0.2 -0.3 -0.1 -1.  -0.4 -0.  -0.2 -0.1 -0.1 -0.4  2.1 -0.3  1.1 -3.6 -0.6 -0.2  0.8 -0.  -0.2 -5.8 -0.2 -0.2 -0.  -2.3  4.1  4.3 -0.2 -0.3 -0.2  0.1 -0.3 -0.4 -0.6 -0.7 -0.3  0.8 -3.4 -0.3 -0.2 -0.1 -0.4 -0.4  0.6 -0.1 -0.1 -1.9 -0.7 -0.3 -0.9 -0.2 -0.3 -0.2 -0.2  2.6 -0.5 -0.6 -0.1 -0.1 -0.  -0.3  2.3  0.4 -1.3 -0.1 -1.4 -0.  -2.   2.   0.9 -0.1 -0.3  0.8 -0.2 11.2 -3.8 -0.2 -0.3 -0.2  2.1 -1.  -0.6 -0.4 -0.2 -0.2 -0.3 -0.4 -0.3  4.7 -0.  -0.2 -0.1  3.3 -0.7 -0.1 -0.2 -0.2 -1.4 -0.5 -0.3  1.  -0.4 -0.1 -0.  -0.2 -0.5 -0.4 -0.3 -0.3 -0.1 -0.3 -0.  -0.3 -0.  -0.  -1.1 -0.8 -0.4  1.3  0.2 -1.1 -0.6 -0.2 -1.5 -0.1 -0.   0.6  0.7 -0.5  4.1 -0.2 -0.2 -0.4 -0.3  7.7 -0.8 -0.3 -0.8 -0.1 -0.2  0.1 -0.1  0.1 -0.3 -0.3 -2.1 -0.1 -0.1  9.6 -0.3 -0.6 -0.7 -0.6 -2.1 -0.9 -0.1  2.9 -0.8 -0.4 -0.3  0.1 -0.2 -0.5 -1.6  4.2  0.   1.9  0.2 -0.8  3.5 -0.4 -0.2 -0.1  0.9 -0.3  1.1 -0.2 -0.5  2.4 -0.9  0.  -0.6  0.1 -0.1 16.8 -0.2 -0.  -0.4 -1.  -0.8 14.5 -0.2 -0.6 -0.3 -1.8  1.7]
vy_50sample [[8 2 0 6 5 4 9 3 7 1]
 [1 1 4 4 5 6 3 0 7 9]
 [8 1 7 6 2 9 4 0 3 5]
 [9 2 2 3 8 6 4 7 0 1]
 [7 4 9 0 8 1 3 6 5 2]
 [1 1 8 5 2 3 0 9 6 7]
 [3 4 9 6 2 7 0 1 8 5]
 [3 2 5 1 0 0 7 4 8 6]
 [5 2 7 9 1 8 3 4 6 0]
 [5 6 8 2 1 3 4 7 9 9]]
vt_50sample [[8 2 0 6 5 4 9 3 1 7]
 [1 8 4 2 5 6 3 0 7 9]
 [8 1 7 6 9 2 4 0 3 5]
 [9 5 2 3 8 6 4 0 7 1]
 [7 4 9 8 0 1 3 6 5 2]
 [1 4 5 8 2 3 0 9 6 7]
 [3 4 9 6 7 2 0 1 8 5]
 [3 2 5 1 0 9 7 4 8 6]
 [5 2 7 9 1 8 3 4 6 0]
 [5 6 2 8 1 3 4 7 9 0]]
Epoch 51610: Training cost= 0.2231, Training acc= 0.8640, Validation cost= 0.2103, Validation acc= 0.8641
Epoch 51620: Training cost= 0.2404, Training acc= 0.8640, Validation cost= 0.2587, Validation acc= 0.8641
Epoch 51630: Training cost= 0.2325, Training acc= 0.8640, Validation cost= 0.2266, Validation acc= 0.8641
Epoch 51640: Training cost= 0.2566, Training acc= 0.8640, Validation cost= 0.2520, Validation acc= 0.8641
Epoch 51650: Training cost= 0.2234, Training acc= 0.8641, Validation cost= 0.2655, Validation acc= 0.8641
Epoch 51660: Training cost= 0.2103, Training acc= 0.8641, Validation cost= 0.3797, Validation acc= 0.8641
Epoch 51670: Training cost= 0.2486, Training acc= 0.8641, Validation cost= 0.2248, Validation acc= 0.8641
Epoch 51680: Training cost= 0.2739, Training acc= 0.8641, Validation cost= 0.2806, Validation acc= 0.8641
Epoch 51690: Training cost= 0.2264, Training acc= 0.8641, Validation cost= 0.2690, Validation acc= 0.8642
Epoch 51700: Training cost= 0.2455, Training acc= 0.8641, Validation cost= 0.2583, Validation acc= 0.8642
tm  [-0.5 -0.1 -1.9 -4.2 -1.8 -0.2  0.2 -0.2 -1.8 -0.4  5.6 -0.  -0.3 -0.1  6.6 -0.2  0.4 -0.2 -0.9  2.  -1.5 -0.4 -0.2 -0.1 -1.6  3.7 -0.  -0.4 -1.6  6.9  2.5 -0.1 -1.5  3.5 -0.2 -0.1  5.  -0.3 -3.2 -0.6 -0.1 -2.2  3.6  1.7 -0.3 -0.1 -1.6 -0.6  2.9 -0.3 -0.   0.2  0.4  9.3 -0.  -1.  -0.5 -3.7 -1.8 -1.8  3.7  1.7 -0.2 -0.1 -1.1  1.8 -0.4 -0.3 -0.3 -0.1 -0.1  4.9 -0.5  0.3 -2.8 -0.3 -0.1 -0.2 -0.3 -0.1 -1.7  0.1 -0.5 -0.  -0.4 -1.6  8.8  0.2 -0.1 -0.3 -0.   0.1 -0.4 -0.  -0.1 -0.3 -0.  -2.4  0.4 -0.5  0.5  0.4 -0.6 -0.2  0.4  1.2 -2.   0.4  1.6 -0.8 -0.6 -0.3 -0.2  0.8 -0.2 -2.  -1.5 -1.6  0.4 -0.7  0.5  1.6 -0.2  0.8  0.4  8.4 -0.2 -1.6 -2.7  8.2  2.4 -0.8 -0.5 -0.   7.2  8.  -0.1  0.5 -0.3 -0.4 -0.5 -1.  -0.4 -0.2 -0.2 -0.4 -0.4 -0.  -1.2 -0.1  2.9 -0.2  0.3  0.1 -0.  -0.2 -0.7 -0.5 -1.2 -0.4  0.3  2.2 -0.  -0.2  0.3 -0.2 -0.4 -0.7 -0.3 -0.2 -0.1 -0.2  0.2  0.2 -0.1  1.5  0.5 -0.3  3.3 -0.2  2.9 -0.  -0.3 -2.4 -0.2 -0.5 -0.1 -0.4 -0.2 -1.8 -0.1 -0.3 -0.2 -1.2 -0.5  9.6 -0.4  0.6 -0.1 -0.2 -0.3 -0.2 -0.3 -0.3 -0.1 -2.9  0.2 -0.4  6.9  0.2 -0.5 -1.5 -0.8  1.5 -1.  -0.4 -0.7 -1.  -0.5 -0.7 -0.2 -0.1 -0.4 -1.4  3.2 -0.6 -0.3 -0.2  2.6  0.7 -0.6 -0.4 -0.3  1.   2.5  3.5 -0.2 -0.3  3.4  8.2 -0.2  2.4 -0.  -0.3  6.9  2.4 -0.4 -0.1 -0.9 -1.   4.5 -0.  -1.9  0.1  0.1 -1.3]
ty_50sample [[4 6 0 2 3 7 1 8 9 5]
 [3 6 7 2 4 8 0 5 1 9]
 [2 0 5 6 9 3 1 7 8 4]
 [3 4 7 6 0 8 9 2 5 1]
 [2 4 8 7 5 9 1 3 6 0]
 [9 1 8 0 3 6 5 7 2 4]
 [1 0 7 2 4 3 8 9 9 6]
 [9 4 3 0 8 2 7 6 5 1]
 [6 3 5 8 4 0 9 2 7 1]
 [2 8 7 0 3 5 4 1 9 6]]
tt_50sample [[4 6 0 2 3 7 1 8 9 5]
 [3 6 7 2 4 8 0 1 5 9]
 [2 0 5 6 3 9 1 7 8 4]
 [3 4 7 6 0 8 9 2 5 1]
 [2 4 8 7 5 9 1 3 6 0]
 [9 1 8 0 3 6 5 7 2 4]
 [1 0 7 2 4 3 8 9 5 6]
 [9 4 3 0 8 2 7 6 5 1]
 [6 3 5 8 4 0 9 2 7 1]
 [2 8 7 0 3 5 4 1 9 6]]
vm  [-0.9 -0.3 -2.3  0.6 -1.7 -0.4 -0.2 -0.2  1.7  0.7 -1.2 -0.2 -0.2  1.5 -1.1  1.3 -0.2 -0.1 -0.4 -0.4 -1.5  0.4  1.3 -0.4 -0.9  1.8 -0.4 -0.6 -0.3 -1.   0.4 -0.3  0.9 -1.8 -0.2 -0.4 -0.6 -1.3 -3.1 -0.7  4.4  2.1 -1.1 -0.2 -0.1  0.4  0.1 -0.1  1.8 10.8  0.3 -0.1 -0.  -0.8 -1.2  0.9 -0.6 -2.2  6.8 -0.1 -0.4 -0.2  0.6 -0.2 -0.8 -1.   0.2  0.1 -0.1 -0.1  0.3 -1.1  0.7  1.2 -2.8 -0.3 -0.4 -0.1 -0.3 -0.1  2.7 -0.1 -0.4 -0.3 -1.1  4.7  2.4  0.3 -0.2 -0.1 -0.3 -0.2  1.  -1.7 -0.3 -0.3 -0.6 -3.1 -0.2 -0.2 -0.9  5.2 -0.2  0.  -0.1 -0.5 -0.3 -0.4 -0.6 -0.8 -0.9  0.1 -0.1 -0.9  5.   6.3  1.6  1.4 -0.2 -0.1 -0.2  2.1 -0.7 -0.4  0.6 -1.5  0.6  4.9  5.  -1.7 -0.9 -0.   0.8 -0.2 14.4 13.6 -0.4 -0.2 -0.6 -0.3  1.2 -0.6 -0.1  0.2 -0.1 -0.1 -0.4  0.1 -0.1 -0.2 -0.3  0.2  1.8 -0.2 -0.3 -0.  -0.7  0.4 -0.3 -0.8  3.9 -0.3 -0.2  0.3  1.2 -0.8 -0.9 -0.1 -0.   0.4  0.3 -0.2  0.2 -0.  -0.2  0.8 -1.5  0.6  3.3 -0.1  0.6 -0.1 -0.4 -1.6 -0.  -0.4 -0.  -0.1  0.7  2.4  0.4 -0.2 -0.1 -0.6  5.8 -2.   0.7 -1.8 -0.1 -0.1 -0.1 -0.3 -0.2 -0.6 -0.1 -0.4 -0.1 -0.1  7.4 -0.2 -0.3  3.  -0.8  3.8 -1.4  0.6  1.2 -0.9 -0.2  1.5 -0.1 -0.2 -0.2 -1.3  6.   3.7 -1.7 -0.1 -0.7  0.   3.9 -0.6  0.1  1.5 -0.6  3.1 -0.1  1.   4.6 11.6 -0.1  2.6  0.4 -0.2  0.4 -1.6 -0.4  1.6 -1.8 -1.1 -0.9 -0.1 -1.8 -0.5 -1.1  8.6]
vy_50sample [[6 4 9 8 1 0 2 5 5 3]
 [1 0 2 5 8 3 6 4 9 7]
 [2 7 3 4 5 0 6 9 1 8]
 [3 5 6 7 8 0 2 4 1 1]
 [3 7 1 0 9 2 4 8 6 5]
 [2 9 3 4 6 7 1 5 5 8]
 [5 8 9 6 0 2 3 4 7 7]
 [0 1 3 7 9 2 5 6 8 4]
 [2 2 0 3 8 4 6 9 5 1]
 [3 8 9 0 1 7 4 6 2 5]]
vt_50sample [[6 4 9 8 1 2 0 7 5 3]
 [1 0 2 5 8 3 6 4 9 7]
 [2 7 3 4 5 6 9 0 1 8]
 [3 5 6 7 8 0 4 2 9 1]
 [3 7 1 0 9 2 4 8 6 5]
 [2 9 3 4 6 7 1 0 5 8]
 [5 8 9 6 2 0 3 4 1 7]
 [0 1 3 7 9 2 5 6 8 4]
 [7 2 0 8 3 4 6 9 5 1]
 [3 8 9 0 1 7 4 6 2 5]]
Epoch 51710: Training cost= 0.2134, Training acc= 0.8641, Validation cost= 0.2201, Validation acc= 0.8642
Epoch 51720: Training cost= 0.2289, Training acc= 0.8641, Validation cost= 0.3226, Validation acc= 0.8642
Epoch 51730: Training cost= 0.2602, Training acc= 0.8641, Validation cost= 0.1922, Validation acc= 0.8642
Epoch 51740: Training cost= 0.2276, Training acc= 0.8641, Validation cost= 0.2325, Validation acc= 0.8642
Epoch 51750: Training cost= 0.2105, Training acc= 0.8641, Validation cost= 0.1806, Validation acc= 0.8642
Epoch 51760: Training cost= 0.1838, Training acc= 0.8642, Validation cost= 0.2133, Validation acc= 0.8642
Epoch 51770: Training cost= 0.2473, Training acc= 0.8642, Validation cost= 0.2263, Validation acc= 0.8642
Epoch 51780: Training cost= 0.2381, Training acc= 0.8642, Validation cost= 0.1866, Validation acc= 0.8642
Epoch 51790: Training cost= 0.1786, Training acc= 0.8642, Validation cost= 0.1957, Validation acc= 0.8643
Epoch 51800: Training cost= 0.2483, Training acc= 0.8642, Validation cost= 0.1893, Validation acc= 0.8643
tm  [-0.5 -0.1  5.3  1.  -1.8 -0.2 -0.1  0.6 -1.2 -0.   3.6 -0.1 -0.1 -0.4  5.3 -1.3 -0.4 -0.2  0.7 -1.2 -1.2 -0.4  0.9 -0.  -1.   2.2 -0.3 -0.1 -1.7  3.8  2.2  0.4 -0.7 11.4  0.5  0.3  3.9  1.9 12.4 -0.5  1.2 -0.5  1.7  3.3 -0.3 -0.2  6.1 -0.3 -0.8  6.9 -0.2 -0.2 -0.1 -0.4  1.3 -0.6 -0.7 -3.4 -1.6 -1.2 -0.   1.3 -0.6 -0.2 -0.6  0.4 -0.4 -0.   1.5 -0.1 -0.2  4.8 -0.5 -0.6 -0.  -0.5 -0.  -0.1  0.1 -0.5  8.8 -0.1 -0.4  0.3  0.8 -0.5  1.7 -0.2 -0.1 -0.3 -0.3  0.1 -0.1  0.1 -0.1 -0.2  0.8 -0.9 -0.6 -0.1  0.6  8.5 -0.3 -0.1 -0.3 -0.3 -0.7 -0.1  1.9 -1.9 -0.4 -0.3  0.3  0.7  2.1 -3.1 -0.2 -1.  -0.4  0.  -0.1  6.2  0.9  0.9 -0.3  6.7 -0.1  3.4 -2.5 -2.9 -0.5 -0.2 -0.6 -0.  -5.6 -1.5 -0.1 -0.1 -0.5 -0.4  0.6 -1.   0.6  0.4 -0.1 -0.6 -0.2 -0.1 -3.5 -0.  -0.2 -0.2 -0.2  1.7  0.  -0.1 -0.1 -0.5  0.8 -0.3 -0.3 -1.1 -0.3 -0.2 -0.5 -0.4 -0.1 -0.6 -0.  -0.2 -0.1 -0.1 -0.1 -0.3 -0.1  4.2  0.4 -0.3 -1.2 -0.2  2.6 -0.2 -0.1 -1.4 -0.3 -0.4 -0.2 -0.5 -0.2 -1.1 -0.4 -0.2 -0.4 -0.6  3.7 10.1 -0.5 -0.6 -0.1 -0.   0.4 -0.1 -0.5  1.1 -0.4 -0.   0.5 -0.3  7.9  0.  -0.3 -2.  -0.3  3.3 -0.2 -0.1 -1.8 -1.  -0.2 -0.6 -0.1 -0.2 -0.2 -0.6  2.2 -1.4 -0.7 -0.5 -0.2 -0.6 -0.5 -0.4 -0.1  1.4  2.4 -0.7 -0.  -0.2  0.1 23.5 -0.   6.7 -0.2 -0.1 -1.4 -1.3 -0.4 -0.4 -0.6  0.1 -2.4 -0.4  7.  -0.2 -0.3 11. ]
ty_50sample [[7 0 4 9 1 2 8 6 3 5]
 [7 0 3 8 4 6 2 9 5 1]
 [9 1 0 7 6 8 3 2 4 5]
 [9 8 6 3 7 1 0 0 4 2]
 [3 2 6 5 0 9 9 7 8 1]
 [7 3 2 0 9 9 6 5 4 1]
 [4 0 7 3 5 1 2 6 9 8]
 [5 9 6 8 3 4 1 0 7 2]
 [0 1 5 6 4 2 9 7 3 8]
 [2 4 6 9 3 7 5 8 0 1]]
tt_50sample [[7 0 4 9 1 2 8 6 3 5]
 [0 7 3 8 4 6 2 9 5 1]
 [9 1 0 7 6 8 3 2 4 5]
 [9 8 6 3 7 1 0 5 4 2]
 [3 2 6 5 0 9 4 7 8 1]
 [7 3 2 0 8 9 6 5 4 1]
 [4 0 7 3 5 1 2 6 9 8]
 [5 9 6 3 8 4 1 0 7 2]
 [1 0 5 6 4 2 9 3 7 8]
 [2 4 6 9 3 7 5 8 0 1]]
vm  [-0.4 -0.2 -1.3 -0.3 -1.  -0.2 -0.1 -0.2 -0.1 -0.   0.6 -0.4  0.1 -0.2 -0.1  3.4 -0.2 -0.2 -0.5  0.4 -1.5 -0.2  0.1 -0.2 -1.   1.  -0.5 -0.5 -0.5 -1.7 -1.2 -0.3  2.  -4.9 -0.4 -0.  -0.7 -0.6 -6.9 -0.4  3.4  5.  -0.7 -1.4 -0.  -0.3 -1.9  0.   4.  10.6 -0.2 -0.1 -0.2  9.9 -0.9 -0.4 -0.9  5.7  6.9  6.   2.3 -0.1  1.2 -0.1 -0.9 -0.5  0.6 -0.3 -0.9 -0.1 -0.3 -0.7 -0.6 -0.2 -5.8 -0.3 -0.1  1.  -0.3 -0.  -4.3  0.4 -0.2 -0.5 -1.5  6.6 -0.2  0.1 -0.3 -0.4 -0.2 -0.3  0.5 -0.9 -0.4 -0.3 -0.1 -3.9 -0.2 -0.  -0.5 -0.1 -0.3  0.1 -0.2 -0.5 -2.  -0.3  0.1  0.5 -0.9 -0.2  0.3 -0.9  3.7  2.5  0.   1.4 -0.2 -0.7 -0.4 -0.8 -0.6 -0.4  0.5 -0.2 -0.  -1.8  6.9  2.1 -0.8 -0.1 -0.2 -0.2 20.5 12.7 -0.4 -0.3 -0.5 -0.6 -0.6 -0.5 -0.6 -0.4  0.  -0.  -0.  -0.   6.9 -0.1 -0.2  0.   2.8 -0.7 -0.2 -0.  -0.6 -0.6 -0.7 -0.8  0.3 -0.2 -0.1 -0.2  0.4 -0.2 -0.4 -0.4 -0.3  0.1 -0.  -0.2 -0.3 -0.1  0.5 -1.6 -2.  -0.3  6.8 -0.1 -1.3 -0.3 -0.2 -1.3 -0.3 -0.7 -0.1 -0.  -0.2  4.7  0.4 -0.1 -0.2 -0.6 -0.5 -2.7 -0.3 -1.5 -0.4 -0.1 -0.3 -0.1 -0.  -0.3 -0.  -2.7 -0.4 -0.2  0.8 -0.  -0.3 -0.2 -0.4 -0.5 -1.  -0.1  7.  -0.8 -0.7 -0.7 -0.1 -0.2  0.  -1.1  4.4  2.3 -0.7 -0.1 -0.8  0.1  3.5 -0.1 -0.2 -0.  -0.6  1.4 -0.3 -0.4  3.9 -4.2 -0.1 -1.6  0.  -0.2 13.7  1.1 -0.4 -0.4 -1.4 -0.5 11.1 -0.2 -3.9 -0.3 -1.4  0.7]
vy_50sample [[6 5 8 2 0 1 4 3 9 7]
 [3 1 0 6 5 2 7 8 4 9]
 [5 3 7 6 2 0 9 8 4 1]
 [2 0 5 4 3 1 9 8 7 6]
 [5 6 1 0 9 4 8 7 2 3]
 [9 0 4 8 6 7 5 1 2 3]
 [1 9 6 4 7 8 0 2 5 3]
 [3 2 8 0 7 9 4 1 5 6]
 [5 2 0 6 9 4 3 8 1 7]
 [1 8 4 3 7 6 5 9 2 0]]
vt_50sample [[6 5 8 2 0 1 4 3 9 7]
 [3 1 0 6 5 2 7 8 4 9]
 [5 3 7 6 2 9 0 8 4 1]
 [2 0 5 4 3 1 9 8 7 6]
 [5 6 1 0 9 4 8 7 2 3]
 [9 0 4 8 6 7 5 1 2 3]
 [1 6 9 4 7 8 0 2 5 3]
 [3 2 8 0 7 9 4 1 5 6]
 [5 2 0 6 9 4 3 8 1 7]
 [1 4 8 3 7 6 5 9 2 0]]
Epoch 51810: Training cost= 0.2423, Training acc= 0.8642, Validation cost= 0.2050, Validation acc= 0.8643
Epoch 51820: Training cost= 0.2219, Training acc= 0.8642, Validation cost= 0.2178, Validation acc= 0.8643
Epoch 51830: Training cost= 0.2537, Training acc= 0.8642, Validation cost= 0.2675, Validation acc= 0.8643
Epoch 51840: Training cost= 0.2671, Training acc= 0.8642, Validation cost= 0.2651, Validation acc= 0.8643
Epoch 51850: Training cost= 0.2703, Training acc= 0.8642, Validation cost= 0.2353, Validation acc= 0.8643
Epoch 51860: Training cost= 0.2629, Training acc= 0.8642, Validation cost= 0.2285, Validation acc= 0.8643
Epoch 51870: Training cost= 0.2131, Training acc= 0.8643, Validation cost= 0.1687, Validation acc= 0.8643
Epoch 51880: Training cost= 0.2137, Training acc= 0.8643, Validation cost= 0.2160, Validation acc= 0.8643
Epoch 51890: Training cost= 0.2554, Training acc= 0.8643, Validation cost= 0.2581, Validation acc= 0.8643
Epoch 51900: Training cost= 0.1800, Training acc= 0.8643, Validation cost= 0.2444, Validation acc= 0.8644
tm  [-0.6 -0.1  3.2  6.6 -1.8 -0.  -0.1 -0.  -0.7 -0.4 -4.7 -0.6 -0.2  0.3 -0.5 -1.2 -0.1 -0.2  2.2  0.3 -1.6 -0.4 -0.1 -0.2 -1.   2.5 -0.2  1.  -1.3 -1.9 -1.5 -0.2 -0.2 -5.1 -0.2 -0.2  1.1 -0.8 -1.2 -0.4 -0.7 -2.9 -0.5 -1.5 -0.2 -0.2 -0.2 -0.7  2.8  8.3 -0.1 -0.  -0.2 -0.1 -0.   0.4 -0.2 -0.2  0.7  7.1  0.9 -0.1  1.3 -0.3 -1.1 -0.4 -0.4 -0.4  0.  -0.2  0.   5.5  1.4  0.2 -2.4 -0.2 -0.1 -0.5 -0.2 -0.2 -3.9 -0.7 -0.2 -0.3 -1.1 -2.6 -1.  -0.3 -0.4 -0.1 -0.1  0.1 -0.3 -0.5 -0.6 -0.3 -0.  -3.1 -0.3 -0.6  1.5 -0.9 -0.9 -0.2 -0.2 -0.4 -1.  -0.4 -1.1 -1.1 -0.3 -0.3  0.1 -0.1  4.4 -2.1 -0.7 -0.3  0.3 -0.2 -0.2  2.8 -0.3 -0.3 -0.2 -0.5 -0.1  2.6 -0.7  1.7  0.7 -0.2 -0.1 -0.5  9.7 -2.  -0.3 -0.1  1.2  2.9 -0.  -0.8 -0.2 -0.4 -0.1 -0.2 -0.5 -0.1 -0.9 -0.2 -0.6 -0.1  2.4  0.7 -0.1 -0.  -0.6 -0.4 -0.5 -0.  -0.4 -0.2  0.1 -0.1 -0.4 -0.3  0.1 -0.2 -0.2 -0.  -0.1 -0.4  0.3 -0.3 -0.3  1.9 -0.5  0.3  1.6  0.2  3.1 -0.2 -0.2 -1.8  0.3 -0.   0.6 -0.4  0.7  5.8 -0.4 -0.2 -0.4 -0.7  1.9  2.9 -0.6 -1.5 -0.  -0.  -0.2 -0.1 -0.3 -0.2 -0.4 -1.  -0.2 -0.1 15.5 -0.1 -0.1 -1.1 -0.7  1.8 -0.4 -0.6  6.2 -0.8 -0.3 -0.2  0.2 -0.3 -0.6 -1.2  2.1 -0.6 -1.2  2.2 -0.8 -0.1 -0.1 -0.6 -0.   0.9  1.8 -0.6 -0.3 -0.   2.  15.5 -0.1  3.9 -0.2 -0.3 12.1 -1.1 -0.4 -0.4 -1.3  1.4  9.5 -0.1 -0.7 -0.1  4.4  0.7]
ty_50sample [[8 0 6 3 9 1 2 7 4 5]
 [1 0 9 5 2 4 6 3 7 8]
 [6 3 0 0 7 8 1 2 4 5]
 [1 0 3 4 7 2 5 9 8 6]
 [1 6 2 0 7 3 3 9 5 4]
 [8 2 9 4 1 7 5 3 6 0]
 [4 5 7 1 9 0 2 3 6 8]
 [9 8 0 7 1 6 3 4 2 5]
 [3 2 6 4 0 9 7 5 1 8]
 [9 9 0 7 2 6 1 5 4 8]]
tt_50sample [[8 0 6 3 1 9 2 7 4 5]
 [1 0 9 5 2 4 6 3 7 8]
 [6 3 0 9 7 8 1 2 4 5]
 [1 0 3 4 7 2 5 9 8 6]
 [1 6 2 0 8 7 3 9 5 4]
 [8 2 9 4 1 7 5 3 6 0]
 [4 5 7 1 9 0 2 3 6 8]
 [9 8 0 7 1 6 3 4 2 5]
 [3 2 6 4 0 9 7 5 1 8]
 [3 9 0 7 2 6 1 5 4 8]]
vm  [-1.4  1.  -1.6  5.2 -1.8 -0.2 -0.1 -0.1 -0.8  0.3  0.6 -0.3 -0.1 -0.  -1.8 -0.7 -0.2 -0.6 -0.5 -1.3 -1.1 -0.4 -0.4 -0.2 -0.4  0.8 -0.1  1.4 -1.5 -1.7  1.8  0.5 -1.  -1.4 -0.1 -0.1  2.7  3.7 19.   0.7 -0.   0.9 -0.6  2.1 -0.4  1.   8.9 -0.4 -2.2 12.7  0.8 -0.3 -0.2 -1.1  1.8  1.7 -0.1 -2.7  2.   0.6  0.5  0.2 -0.6 -0.3 -0.6  1.1 -0.5 -0.4 -0.5 -0.2 -0.1  3.1 -0.7 -0.5  4.9 -0.4  0.3  1.3 -0.1 -0.1  7.4 -0.2 -0.4  0.2  4.4  3.2 -0.7 -0.2 -0.2  0.5 -0.3  0.1 -0.  -0.8 -0.4 -0.3  0.5 -1.1  0.5 -0.1 -0.   4.6 -0.  -0.3 -0.3  0.1  0.1  0.4  0.5 -2.5  0.  -0.4 -0.1 -0.2  5.5 -2.4 -0.6 -0.7 -0.3 -0.3 -0.3  9.8  0.9  0.5 -0.3 -2.3 -0.   5.2 -0.6 -4.4 -0.5 -0.3 -0.4 -0.6 -1.5 -3.8 -0.1  0.5  0.2 -0.3 -0.1 -0.6 -0.1 -0.3 -0.1 -0.4 -0.3  0.5 -0.9  0.3 -0.6 -0.1 -0.1  1.7  0.2 -0.4 -0.3  1.7  0.8 -0.4 -0.3 -0.5 -0.2 -0.1 -0.   0.7  0.5 -0.2 -0.1 -0.2 -0.   0.1  0.1 -0.1 -0.1  1.   2.4 -0.8 -1.8 -0.   0.9 -0.2 -0.  -1.5 -0.2 -0.4 -0.7 -0.5  0.8  4.8 -0.3  0.  -0.3 -0.4  2.7  2.4 -0.3 -1.5 -0.4  0.  -0.4 -0.  -0.5 -0.2  0.1  0.6 -0.1 -0.1 10.1  0.8 -0.3 -1.8 -0.2  8.2 -0.5  0.  -1.8 -0.9 -0.2 -0.7 -0.2 -0.2  0.4 -0.5  3.9 -0.8 -0.4  0.5 -0.3 -0.6 -1.2 -1.1 -0.   1.4  3.5  2.2 -0.4  0.1  3.3 25.7 -0.2  6.9 -0.1 -0.1 -1.  -1.5 -0.4 -0.2 -1.2 -0.2 -2.  -0.3 11.  -0.4 -1.2 16.4]
vy_50sample [[9 1 0 4 8 2 7 6 5 3]
 [4 0 2 6 5 5 3 8 7 1]
 [0 2 1 9 3 4 4 5 7 8]
 [2 7 8 6 9 1 0 4 5 3]
 [2 5 9 7 8 4 6 1 0 3]
 [0 6 3 9 1 2 8 7 4 5]
 [4 8 5 6 9 3 2 1 7 0]
 [1 3 5 9 4 6 2 7 8 0]
 [4 2 0 6 8 9 5 7 1 3]
 [6 2 2 9 4 5 0 1 7 8]]
vt_50sample [[9 1 0 4 8 2 7 6 5 3]
 [4 0 2 6 5 9 8 3 1 7]
 [0 2 1 9 6 3 4 5 7 8]
 [2 7 8 6 1 9 0 4 5 3]
 [2 5 9 7 8 4 6 1 0 3]
 [0 6 3 1 9 2 8 7 4 5]
 [4 8 5 6 9 3 2 1 7 0]
 [1 3 5 9 4 6 7 2 8 0]
 [4 2 0 6 8 9 5 7 1 3]
 [3 6 2 9 4 5 0 1 7 8]]
Epoch 51910: Training cost= 0.2158, Training acc= 0.8643, Validation cost= 0.2322, Validation acc= 0.8644
Epoch 51920: Training cost= 0.2748, Training acc= 0.8643, Validation cost= 0.2691, Validation acc= 0.8644
Epoch 51930: Training cost= 0.2624, Training acc= 0.8643, Validation cost= 0.2500, Validation acc= 0.8644
Epoch 51940: Training cost= 0.2393, Training acc= 0.8643, Validation cost= 0.2788, Validation acc= 0.8644
Epoch 51950: Training cost= 0.2609, Training acc= 0.8643, Validation cost= 0.2279, Validation acc= 0.8644
Epoch 51960: Training cost= 0.2531, Training acc= 0.8643, Validation cost= 0.1945, Validation acc= 0.8644
Epoch 51970: Training cost= 0.2180, Training acc= 0.8643, Validation cost= 0.2279, Validation acc= 0.8644
Epoch 51980: Training cost= 0.2455, Training acc= 0.8644, Validation cost= 0.1995, Validation acc= 0.8644
Epoch 51990: Training cost= 0.2244, Training acc= 0.8644, Validation cost= 0.2616, Validation acc= 0.8644
Epoch 52000: Training cost= 0.2189, Training acc= 0.8644, Validation cost= 0.2352, Validation acc= 0.8644
tm  [-0.  -0.1  0.4  9.8 -2.  -0.1 -0.4 -0.  -1.  -0.9  4.6 -0.3 -0.2 -0.1 -1.6 -0.7 -0.7 -0.1 -0.1 -0.7 -1.3  0.2 -0.5 -0.1 -0.7  1.9 -0.4 -0.2 -1.5 -1.6  2.4 -0.1 -0.7  5.8 -0.1  0.1  4.   4.9 24.8 -0.4  1.5 -2.2  0.3  2.1 -0.2  0.1  7.1 -0.1  5.9 -2.2 -0.3 -0.1  1.3 -1.9  0.2  1.7 -0.3 -1.1 -0.3 -1.2 -2.  -0.5 -0.4 -0.  -0.7 -0.1 -0.3 -0.3  2.2 -0.3 -0.   3.4 -0.  -0.   7.  -0.8 -0.1 -0.9  0.3 -0.3 18.1  0.1 -0.2  0.2 -1.2 -2.   6.2 -0.2 -0.3 -0.4  0.4 -0.2 -0.1 -0.6 -0.4  0.3 -0.6 -0.5 -0.1  0.   3.3 -0.5 -0.3 -0.2 -0.3 -0.4  2.7 -0.   1.6 -1.8 -1.  -0.4 -0.1 -0.  -0.2 -1.5  0.2 -1.2 -0.4 -0.4 -0.1  7.4  0.2 -0.2 -0.2 -1.9 -0.1  7.4  0.2 -0.9 -0.4 -0.3 -0.1 -0.9 -4.7 -2.9 -0.1 -0.1 -0.1 -0.5 -0.  -0.4 -0.   0.2 -0.1 -0.2 -0.1 -0.1 -1.  -0.  -1.3 -0.4  1.5 -0.  -0.1 -0.   1.  -0.3  2.6 -0.1 -0.6 -1.2 -0.3  0.1 -0.5 -0.1  0.7 -0.2  0.2 -0.1 -0.1 -0.3 -0.2  0.4 -0.3  2.4  2.6 -0.4 -2.1 -0.1 -0.7 -0.4 -0.2 -1.6 -0.2  0.3 -0.1 -0.3 -0.3  4.1 -0.1 -0.1 -0.3 -1.4 14.5  0.8  1.2  0.9  0.3 -0.2 -0.4 -0.2 -0.7 -0.5 -0.1  3.1 -0.1 -0.1 -0.4  0.1 -0.3 -1.5 -1.1 -1.  -0.8 -0.5 -2.2 -1.2 -0.2  1.3  0.1 -0.  -0.3 -1.  -2.5 -0.7 -0.8  0.1  1.   2.4 -0.4 -1.7 -0.1 -0.2  2.6 -0.2 -0.4  2.3  2.9 15.7 -0.2  3.1 -0.1  0.2 -3.5 -2.3 -0.2  1.2 -0.9  0.8 -4.8 -0.1 14.2 -0.2  5.9  4.4]
ty_50sample [[9 3 0 4 7 2 5 8 1 6]
 [6 8 9 9 1 4 0 7 2 5]
 [0 1 6 4 5 2 3 9 8 7]
 [5 1 4 8 6 2 0 3 9 7]
 [6 8 5 0 2 3 9 4 7 1]
 [1 1 3 4 0 8 5 2 6 7]
 [2 5 9 4 6 7 1 0 8 3]
 [1 5 2 8 0 4 3 9 7 6]
 [9 5 7 3 2 6 0 8 1 4]
 [7 6 4 5 3 1 0 8 2 9]]
tt_50sample [[9 3 0 4 7 2 5 8 1 6]
 [6 3 8 9 1 4 0 7 2 5]
 [0 1 6 4 5 3 2 9 8 7]
 [1 5 4 8 6 2 0 3 9 7]
 [6 8 5 0 3 2 9 4 7 1]
 [1 9 3 4 0 8 5 2 6 7]
 [2 5 9 4 6 7 1 0 8 3]
 [1 5 2 8 0 4 3 9 7 6]
 [9 5 7 3 2 6 0 8 1 4]
 [7 6 4 5 3 1 0 8 2 9]]
vm  [-0.7 -0.2  8.8 10.7 -1.5 -0.3 -0.1  0.1 -0.7 -0.4  0.4 -0.5 -0.2 -0.   5.4 -0.9 -0.7 -0.2 -0.1 -0.5 -1.3 -0.4  0.4 -0.1 -1.2  2.3 -0.2 -0.4 -0.4  1.6  1.2  0.  -0.2 13.  -0.2 -0.2  1.9 -2.1 -2.2 -0.  -0.1  2.7  0.5 -1.2 -0.2 -0.1  3.7 -0.2 -0.6  0.5 -0.2 -0.1  0.2 -1.6 -0.8 -0.7 -0.4  4.8 -0.6  1.7  3.1 -0.1 -0.2 -0.3  2.5 -0.6 -0.3 -0.1  2.  -0.2 -0.2 -0.1  0.3 -0.5 -1.3 -0.4 -0.1 -0.2  0.3 -0.2 10.6  0.8 -0.2  0.1 -0.   3.4 -1.1 -0.1 -0.2 -0.1 -0.  -0.  -0.3 -0.5 -0.9 -0.2 -0.3 -2.4 -0.2 -0.3  1.4  5.8 -0.  -0.1 -0.2 -0.3 -1.4 -0.1  0.7 -0.7 -0.1 -0.3 -0.1 -0.5  1.6  0.8 -0.8 -0.9  0.4 -0.6 -0.3  1.8  0.3  0.6 -0.2  6.8 -0.1  7.1 -0.7 -1.2  0.8 -0.3 -0.5 -0.4  4.1 16.5 -0.1 -0.1 -0.1 -0.4  1.5 -0.5  0.4 -0.  -0.2  0.1 -0.2 -0.1 -0.8 -0.1 -1.2 -0.1 -0.9  2.8 -0.1 -0.1 -0.5 -0.5 -1.3 -0.1 -0.6  1.3 -0.2 -0.1 -0.2 -0.4 -0.1 -0.2 -0.2  0.1 -0.  -0.3  0.1 -0.2 -0.3  1.6 -0.8  0.1  1.5 -0.1 -1.  -0.4 -0.  -2.1  0.1 -0.1 -0.1 -0.6 -0.  -0.4 -0.1 -0.2 -0.3 -1.3 -0.4  3.1 -0.2 -0.5 -0.1 -0.2 -0.1 -0.  -0.8 -0.3 -0.3 -1.2  0.   0.1 -2.   0.1 -0.6  0.1 -0.5  4.7 -1.2 -0.2  6.3 -1.4  0.2 -0.2  0.2 -0.1  0.7 -1.   4.1 -0.2 -2.  -0.4 -0.4 -0.1 -0.   0.1 -0.2 -0.6 -0.3 -2.  -0.2 -0.1  3.4  1.2 -0.1 -0.2 -0.2 -0.1 -1.8 -1.4 -0.3 -0.5 -1.1  0.9 -3.2 -0.  -1.1 -0.2  4.8  6.3]
vy_50sample [[6 7 1 0 0 0 3 4 8 2]
 [6 5 0 1 3 7 8 2 9 4]
 [6 1 7 9 5 3 4 8 2 0]
 [1 2 9 0 3 6 7 4 5 8]
 [6 4 9 0 1 2 5 7 8 3]
 [0 5 2 4 8 7 9 3 6 1]
 [9 4 1 7 3 0 2 5 8 6]
 [2 4 1 0 5 7 6 3 9 8]
 [1 4 2 3 0 8 8 7 5 6]
 [2 8 4 3 1 7 5 6 0 9]]
vt_50sample [[6 7 1 5 9 0 3 8 4 2]
 [6 5 0 1 3 7 8 2 9 4]
 [6 7 1 9 5 3 4 8 0 2]
 [1 2 9 0 3 6 7 4 5 8]
 [6 4 0 9 1 2 5 7 8 3]
 [0 5 2 4 8 7 9 3 6 1]
 [9 4 1 7 3 0 2 5 8 6]
 [2 4 1 0 5 7 6 3 9 8]
 [1 4 2 3 0 8 9 7 5 6]
 [2 8 4 3 1 7 5 6 0 9]]
Epoch 52010: Training cost= 0.2601, Training acc= 0.8644, Validation cost= 0.2660, Validation acc= 0.8644
Epoch 52020: Training cost= 0.2476, Training acc= 0.8644, Validation cost= 0.3837, Validation acc= 0.8645
Epoch 52030: Training cost= 0.2185, Training acc= 0.8644, Validation cost= 0.2358, Validation acc= 0.8645
Epoch 52040: Training cost= 0.2265, Training acc= 0.8644, Validation cost= 0.2567, Validation acc= 0.8645
Epoch 52050: Training cost= 0.2085, Training acc= 0.8644, Validation cost= 0.2384, Validation acc= 0.8645
Epoch 52060: Training cost= 0.2518, Training acc= 0.8644, Validation cost= 0.2795, Validation acc= 0.8645
Epoch 52070: Training cost= 0.2278, Training acc= 0.8644, Validation cost= 0.2830, Validation acc= 0.8645
Epoch 52080: Training cost= 0.2175, Training acc= 0.8644, Validation cost= 0.2096, Validation acc= 0.8645
Epoch 52090: Training cost= 0.2439, Training acc= 0.8644, Validation cost= 0.2878, Validation acc= 0.8645
Epoch 52100: Training cost= 0.2155, Training acc= 0.8645, Validation cost= 0.2178, Validation acc= 0.8645
tm  [-0.9 -0.2  9.9 14.5 -1.9 -0.1 -0.3  0.2 -0.1 -0.8 -4.6 -0.3  0.1  0.   4.7 -0.9  0.1 -0.  -0.5 -0.5 -1.2 -0.3  1.1 -0.3 -0.6 -0.1 -0.2 -0.3 -0.5 -1.  -1.4 -0.3 -0.2  2.   0.2 -0.2  0.1 -0.3  6.4 -0.2  1.1  4.3  0.1 -0.5 -0.   0.7  1.1  0.8  3.1  4.7 -0.4 -0.2 -0.4 -1.5 -0.6 -0.6 -0.8 12.   0.4  7.6 -0.2 -0.3 -0.3 -0.2 -1.  -0.   0.4 -0.2  1.6  0.4 -0.  -0.2  0.2  1.2 -2.2 -0.3 -0.  -0.   0.1 -0.2 -1.4 -0.4 -0.2 -0.1 -0.8  3.3 -1.4 -0.2 -0.2 -0.4 -0.7 -0.  -0.1 -0.6 -0.8  0.4  0.5 -2.8 -0.3 -0.1  2.6  3.1 -0.3  0.  -0.5 -0.2 -1.1 -0.  -1.5 -1.5 -0.6 -0.1 -0.2 -0.5  0.3  2.8  0.1 -0.  -0.  -0.6 -0.2  5.7 -0.2 -0.6 -0.3  6.  -0.1  6.3  2.8  0.7 -0.5 -0.4 -0.6 -0.4 -3.5 -3.1 -0.4 -0.3 -0.3 -0.3  1.1 -0.4 -0.1 -0.2 -0.2  1.  -0.3 -0.3  2.7 -0.2 -1.7 -0.1  2.6 -0.  -0.2  0.4 -0.1 -0.   2.3 -0.2 -0.3 -0.6 -0.2 -0.2 -0.5  0.1 -0.2 -0.3 -0.1 -0.2  0.1 -0.2 -0.3 -0.3 -0.1 -0.3 -0.3 -0.2 -0.4 -0.1 -2.6 -0.2 -0.4 -1.5  0.2 -0.5 -0.2 -0.4 -0.2  3.  -0.1 -0.2 -0.1 -0.5  4.6 -0.9 -0.3 -0.2  0.7 -0.2 -0.1 -0.1 -0.5 -0.4  0.2 -1.3 -0.1 -0.2 -1.2 -0.1 -0.7  0.1 -0.3 -0.2 -0.5 -0.5  2.6 -1.  -0.2 -0.7  0.5 -0.3 -0.4 -1.3 -0.9  2.6 -1.4 -0.5  1.2  1.8 -0.5 -0.4 -0.1 -0.2 -0.  -2.5 -0.6  0.3  2.8 -2.8 -0.1 -1.3 -0.2 -0.   5.5 -0.5 -0.6  0.4 -0.9  0.4  2.8  0.2  3.6 -0.4  6.7  1.4]
ty_50sample [[5 7 8 9 3 0 1 6 2 4]
 [9 7 6 1 2 8 0 3 4 5]
 [1 9 2 6 7 8 4 5 0 3]
 [1 7 3 5 0 6 8 9 2 4]
 [6 1 4 5 8 2 3 7 9 0]
 [7 9 3 2 8 1 5 6 4 0]
 [5 4 3 6 0 8 1 9 7 2]
 [2 9 1 6 3 8 5 7 4 0]
 [9 6 1 0 3 5 7 8 2 4]
 [6 3 7 0 8 5 9 1 2 4]]
tt_50sample [[5 7 8 9 3 0 1 6 2 4]
 [9 7 6 1 2 8 3 0 5 4]
 [1 9 2 6 7 8 5 4 3 0]
 [1 7 3 5 0 6 8 9 2 4]
 [6 4 5 1 8 2 3 7 9 0]
 [7 9 3 2 8 1 5 6 4 0]
 [5 4 3 6 0 8 1 9 7 2]
 [2 9 1 6 3 8 5 7 4 0]
 [9 6 1 3 0 5 7 8 2 4]
 [6 3 7 0 8 5 9 1 2 4]]
vm  [ 0.2 -0.2 -1.4 -1.  -1.8 -0.1 -0.4 -0.2 -0.8 -1.2 -1.4 -0.2  0.1  0.4  0.1  2.6 -0.4 -0.1 -0.5 -0.7 -1.2 -0.1  1.6 -0.2 -1.  -0.5 -0.2 -0.4 -0.1  1.8  1.5 -0.  -0.7 -1.1  0.   0.   0.7  2.8 10.8 -0.5  1.5 -1.5  1.6  3.2 -0.4  0.7  3.3 -0.1  6.7  3.9 -0.5 -0.2 -0.4 -0.2 -1.2 -0.1 -0.3 -2.1 -0.6 -0.2 -1.5 -0.6 -0.8 -0.  -0.4 -0.1 -0.3 -0.3  2.  -0.1  0.6 -1.1  0.2  1.3 -0.5 -1.1 -0.  -0.5 -0.1 -0.3 -0.7 -0.2 -0.1  0.1 -1.4 -1.5 10.5 -0.2 -0.4 -0.3 -0.4 -0.1 -0.3 -0.7 -0.8  1.  -0.5 -2.1  0.1  0.3  3.5 -0.2  0.3 -0.2 -0.1 -0.1 -0.4  0.2 -0.1 -1.5 -0.8 -0.3 -0.1 -0.5 -1.3 11.7 -0.2 -0.7 -0.3 -0.5 -0.1  6.4 -0.2 -1.1 -0.1  0.3 -0.   2.9 -0.1  0.7 -0.1 -0.5 -0.  -0.7 -2.6 -3.6  0.   0.4 -0.2 -0.3 -0.3 -0.2 -0.1 -0.1 -0.1 -0.2 -0.1 -0.2 -0.6 -0.1  0.1 -0.3  4.1  0.1 -0.  -0.3  1.1  1.3  1.2 -0.3 -0.7 -0.5  0.3 -0.2 -0.6  0.4  0.7 -0.3 -0.1 -0.1 -0.1 -0.1 -0.2  0.8 -0.   1.9 -0.2 -0.9 -1.  -0.2 -1.5 -0.2 -0.6 -2.2 -0.2  0.2 -0.4 -0.3 -0.1 -0.5 -0.1 -0.1 -0.  -1.3 13.5  0.7  1.   3.6 -0.2 -0.1 -0.2 -0.1 -0.9 -0.4 -0.  -1.1  0.2 -0.   5.8  0.1 -0.5  1.3 -0.8 -2.  -0.8 -0.6 -2.2 -0.9 -0.1  0.4 -0.1 -0.1 -0.2 -1.4 -1.7  5.5 -0.9 -0.1 -0.4  4.3 -0.8 -0.8  0.   1.4 -0.4  1.8 -0.6  0.3  3.2  5.8 -0.3  0.1 -0.2  0.1  4.3 -0.7 -0.2  1.7 -0.9 -0.   0.2 -0.1  6.2 -0.2  4.8  1.9]
vy_50sample [[4 8 9 9 7 2 5 6 0 1]
 [9 7 0 0 8 5 4 2 1 3]
 [7 4 8 8 0 1 2 9 3 5]
 [3 6 1 8 0 7 4 5 9 2]
 [5 9 1 0 7 4 2 3 6 8]
 [4 2 1 5 0 9 8 3 3 6]
 [5 7 8 6 1 3 2 0 4 9]
 [8 1 3 7 4 5 2 0 9 6]
 [3 5 0 8 7 2 6 4 1 9]
 [8 6 1 1 2 7 0 3 4 5]]
vt_50sample [[4 8 3 9 7 2 5 6 0 1]
 [9 7 0 6 8 5 4 2 1 3]
 [7 4 8 0 1 6 2 9 3 5]
 [3 6 1 8 0 7 4 5 9 2]
 [5 9 1 0 7 4 2 3 6 8]
 [4 2 1 5 9 0 8 3 7 6]
 [5 7 8 6 1 3 2 0 4 9]
 [8 1 3 7 4 5 2 0 9 6]
 [3 5 0 7 8 2 6 4 1 9]
 [8 6 1 9 2 7 0 3 4 5]]
Epoch 52110: Training cost= 0.1946, Training acc= 0.8645, Validation cost= 0.2621, Validation acc= 0.8645
Epoch 52120: Training cost= 0.2770, Training acc= 0.8645, Validation cost= 0.2426, Validation acc= 0.8645
Epoch 52130: Training cost= 0.2872, Training acc= 0.8645, Validation cost= 0.2496, Validation acc= 0.8645
Epoch 52140: Training cost= 0.2682, Training acc= 0.8645, Validation cost= 0.2271, Validation acc= 0.8645
Epoch 52150: Training cost= 0.2172, Training acc= 0.8645, Validation cost= 0.1883, Validation acc= 0.8646
Epoch 52160: Training cost= 0.2535, Training acc= 0.8645, Validation cost= 0.2489, Validation acc= 0.8646
Epoch 52170: Training cost= 0.2651, Training acc= 0.8645, Validation cost= 0.2389, Validation acc= 0.8646
Epoch 52180: Training cost= 0.2566, Training acc= 0.8645, Validation cost= 0.2755, Validation acc= 0.8646
Epoch 52190: Training cost= 0.2058, Training acc= 0.8645, Validation cost= 0.2354, Validation acc= 0.8646
Epoch 52200: Training cost= 0.1878, Training acc= 0.8645, Validation cost= 0.2268, Validation acc= 0.8646
tm  [-0.9 -0.3  5.3 20.  -1.5 -0.3 -0.  -0.1  0.6 -1.5 -4.5 -0.2 -0.1 -0.2 -2.3  3.4  0.1 -0.1  0.2 -0.8 -1.1 -0.1 -0.5 -0.2 -0.6  1.9 -0.  -0.5 -0.1 -0.4 -1.6 -0.2  1.5 -4.2 -0.3  0.3  0.1  5.2 23.2 -0.3  3.9  3.   2.1  1.3 -0.  -0.1  8.6  0.3 -0.6 12.1 -0.6 -0.2 -0.1 -2.4 -0.9  3.2 -0.2  7.5 -1.6  7.3 -0.8 -0.5 -0.2 -0.1 -1.  -0.3 -0.  -0.2  2.  -0.  -0.1 -1.3  0.  -0.2  6.2  0.1 -0.2  0.9  0.4 -0.4  1.3 -0.5  0.1 -0.2 -0.4  5.5 -2.   0.1 -0.2 -0.  -0.  -0.2 -0.1 -0.3 -0.6 -0.3  1.8 -0.8  0.2 -0.3  5.8  3.5 -0.1 -0.  -0.1 -1.2  3.8 -0.6 -0.7 -1.4 -0.8  0.4 -0.  -0.2 -0.9 11.9  2.1 -0.9 -0.1 -0.2 -0.2  6.6  0.1 -0.1  0.5 -2.9 -0.1  9.  -1.2 -3.5 -1.  -0.1 -0.4 -1.  -3.7 -7.7 -0.1 -0.  -0.3  3.3 -0.2 -0.4 -0.2 -0.1 -0.1  0.5 -0.1 -0.   3.4 -0.2 -2.3  0.1  0.7 -0.4 -0.1 -0.2 -0.4 -0.3  5.  -0.   1.3 -1.6  0.8 -0.1  0.8 -0.7 -0.5 -0.2 -0.1 -0.2  0.1 -0.1 -0.  -0.1 -0.1 -0.5 -0.3 -0.  -2.  -0.  -1.1 -0.2 -0.3 -1.  -0.2 -0.2  0.1 -0.5  0.5  0.4 -0.1 -0.  -0.2 -0.1  7.6  4.8  1.   2.7 -0.3 -0.2 -0.1  0.1 -0.1 -0.2 -0.2  5.8  0.4 -0.1  6.7 -0.2 -0.3  3.   0.3  5.9 -0.4 -0.1 -0.7 -0.3  0.6 -0.4 -0.1 -0.2 -0.5 -0.5 -1.1  2.2 -0.3 -0.4 -0.8 -0.2 -0.3 -1.7 -0.1  1.2 -0.3 -1.1 -0.8  2.2  0.3 12.6 -0.1  2.9 -0.1 -0.2  0.7 -2.9 -0.5 -0.4 -0.9 -0.  -0.7 -0.3 13.2 -0.2 -0.  11.9]
ty_50sample [[9 8 5 5 7 2 3 4 0 6]
 [7 3 4 5 9 2 1 6 8 0]
 [4 7 5 3 9 6 1 1 0 2]
 [4 1 9 5 8 7 0 6 3 2]
 [6 3 7 5 1 1 8 2 4 0]
 [0 8 6 3 2 5 4 7 1 9]
 [3 2 1 9 6 4 7 5 8 0]
 [9 6 8 5 1 3 0 2 7 4]
 [6 1 8 3 2 9 0 4 5 7]
 [5 4 0 8 6 9 2 3 1 7]]
tt_50sample [[9 8 5 1 7 2 3 4 0 6]
 [7 3 4 5 9 2 1 6 8 0]
 [4 7 5 3 9 6 1 0 8 2]
 [4 1 5 9 8 7 0 6 3 2]
 [6 3 7 5 1 9 8 2 4 0]
 [0 8 6 3 2 5 4 7 1 9]
 [3 2 1 9 6 4 7 5 8 0]
 [9 6 8 5 1 3 0 2 4 7]
 [6 1 8 3 2 9 0 4 5 7]
 [5 4 0 8 6 9 2 1 3 7]]
vm  [-0.8 -0.1 -2.2  0.6 -1.6 -0.1 -0.  -0.2 -0.5 -0.2  8.5 -0.2 -0.3 -0.4 -1.3  3.8  1.7 -0.2 -0.7  1.  -1.6 -0.3  1.6 -0.3 -1.6  5.  -0.2 -0.7 -0.4 -0.3  1.5 -0.2 -0.4 -1.9 -0.2 -0.4  1.6 -0.2 -4.2 -0.6  2.9  3.7  0.  -1.  -0.1 -0.3 -1.3 -0.3  5.1  4.2 -0.3  0.  -0.1  8.6 -0.7  0.7 -0.5  1.7  1.6 -0.3  1.5  0.1  2.7 -0.  -0.5 -0.2 -0.3 -0.6 -1.  -0.  -0.1 -0.6 -0.4  2.2 -3.8  1.1 -0.3  3.2 -0.3  0.3  3.3  1.1 -0.3 -0.6 -1.4  6.7  2.8 -0.1 -0.  -0.3 -0.6 -0.2 -0.  -0.1 -0.1 -0.1  1.9 -2.8 -0.6 -0.1 -0.5 -0.2 -0.5 -0.2 -0.3 -0.4 -0.9 -0.3  0.2 -0.6 -0.5 -0.2 -0.1 -0.7  0.7  4.9 -0.1 -0.5 -0.1 -0.4 -0.1  0.3 -0.7  1.1 -0.2 -1.6 -0.  -1.4  0.2 -0.2 -0.6 -0.1 -0.5 -0.1 18.8 18.3 -0.3 -0.1 -0.2 -0.6 -0.3 -0.9 -0.6 -0.1 -0.  -0.4 -0.2 -0.   6.5 -0.2 -0.5 -0.3  1.2 -0.4 -0.2  0.3 -1.2  0.8 -0.7 -1.2  1.5 -0.4 -0.1 -0.2  0.1 -0.7 -0.9 -0.7 -0.2  0.4 -0.  -0.1 -0.  -0.2 -0.2 -1.1 -1.   0.8  4.1 -0.2 -0.6  1.2 -0.2 -1.5 -0.2 -0.3  0.3  0.7 -0.2  1.5 -0.1 -0.3  0.1 -1.   1.4 -0.3  0.  -0.5  0.1 -0.1  0.8 -0.2 -0.2 -0.3 -0.2 -0.8 -0.3 -0.3 -0.7  0.1 -0.7  0.7 -0.3  1.4 -1.2  0.6  4.7 -1.1 -0.4 -0.7 -0.  -0.1 -0.3 -0.5  5.1  0.4 -0.5 -0.1 -0.1  0.5  4.1 -0.6 -0.5 -0.4 -0.5  2.9 -0.2  0.3  3.6  0.5 -0.2  0.1  0.2  0.1  0.1 -1.1 -0.8 -0.3 -1.5 -0.3 -1.1 -0.2 -2.3  0.1 -1.6  3.9]
vy_50sample [[6 2 5 4 9 1 8 8 3 7]
 [1 3 7 2 8 4 0 6 9 5]
 [5 8 2 2 9 3 1 4 7 0]
 [1 9 5 6 2 4 7 8 0 3]
 [9 2 5 7 1 3 6 4 0 8]
 [0 1 7 6 5 9 3 8 2 4]
 [7 3 6 6 1 0 0 5 4 2]
 [8 6 4 9 7 2 1 3 5 0]
 [1 3 9 0 6 5 7 2 8 4]
 [5 6 0 9 1 4 4 7 3 2]]
vt_50sample [[6 2 5 4 9 0 1 8 3 7]
 [1 3 7 2 8 4 0 6 9 5]
 [5 8 2 6 9 3 1 4 7 0]
 [1 9 5 6 2 4 7 0 8 3]
 [9 2 5 7 1 3 6 4 8 0]
 [0 1 7 6 5 9 3 8 2 4]
 [7 3 6 9 1 0 8 5 4 2]
 [8 6 4 9 2 7 1 3 5 0]
 [1 3 9 0 6 5 7 2 8 4]
 [5 6 0 9 1 4 8 7 3 2]]
Epoch 52210: Training cost= 0.2771, Training acc= 0.8645, Validation cost= 0.2114, Validation acc= 0.8646
Epoch 52220: Training cost= 0.2786, Training acc= 0.8645, Validation cost= 0.1737, Validation acc= 0.8646
Epoch 52230: Training cost= 0.2511, Training acc= 0.8646, Validation cost= 0.2864, Validation acc= 0.8646
Epoch 52240: Training cost= 0.2109, Training acc= 0.8646, Validation cost= 0.2147, Validation acc= 0.8646
Epoch 52250: Training cost= 0.2740, Training acc= 0.8646, Validation cost= 0.2201, Validation acc= 0.8646
Epoch 52260: Training cost= 0.2900, Training acc= 0.8646, Validation cost= 0.2606, Validation acc= 0.8647
Epoch 52270: Training cost= 0.2346, Training acc= 0.8646, Validation cost= 0.2621, Validation acc= 0.8647
Epoch 52280: Training cost= 0.2163, Training acc= 0.8646, Validation cost= 0.2333, Validation acc= 0.8647
Epoch 52290: Training cost= 0.2097, Training acc= 0.8646, Validation cost= 0.2002, Validation acc= 0.8647
Epoch 52300: Training cost= 0.1751, Training acc= 0.8646, Validation cost= 0.2315, Validation acc= 0.8647
tm  [-1.6 -0.3  2.8 -0.2 -1.8  0.3 -0.1 -0.1 -0.  -0.1 -3.5 -0.2 -0.  -0.1  4.1  2.1 -0.2 -0.1  1.1 -1.1 -0.8 -0.2 -0.5 -0.5 -1.3 -0.5 -0.1  0.5  1.7 -0.4 -0.3 -0.3 -0.5 -0.8 -0.  -0.2  0.4  2.4  8.9 -0.3 -0.6  6.2 -0.5  1.4 -0.2  0.2  2.  -0.3 -3.  13.6 -0.1  0.  -0.8 -0.4 -1.3 -0.4 -0.6  3.4  0.3  3.6  6.9 -0.8 -0.6  0.4 -0.5  0.2  0.1 -0.2  0.4 -0.1  0.6 -2.  -0.2 -0.1 -2.5 -0.1 -0.1 -0.1 -0.1 -0.  -2.7 -0.4 -0.3 -0.1  3.9  8.2 -2.  -0.2 -0.  -0.3 -0.3 -0.2 -0.2 -0.8 -0.7 -0.  -0.4 -2.7 -0.1 -0.1  0.7  4.7 -0.1 -0.1 -0.2 -0.5 -1.7 -0.4 -0.9 -1.1  1.2 -0.1 -0.2 -0.5 -0.5 12.6 -0.2 -0.4 -0.2 -0.1  0.1  3.5 -0.2  0.  -0.2  5.6  0.9  3.3  0.9 -1.7 -0.1 -0.2 -0.  -0.5 -3.5 -4.9 -0.5 -0.  -0.1 -0.1  0.2  0.  -0.1 -0.  -0.4  0.3 -0.3 -0.   2.9 -0.3  0.6  0.1 -0.3 -0.  -0.1  0.1 -0.2  1.2  0.3 -0.2 -0.4 -1.  -0.2 -0.1 -0.1 -0.1 -0.2  0.2 -0.1 -0.1  0.  -0.1 -0.1 -0.3 -0.  -0.   0.7 -0.4 -1.2 -0.  -2.2  1.2 -0.3 -1.6 -0.1 -0.3 -0.5 -0.6  0.3  1.2 -0.3  0.1 -0.2 -0.7 -2.5 -0.2 -0.4  1.3 -0.3 -0.  -0.1 -0.2 -0.2 -0.6  0.1 -1.8 -0.1 -0.  -0.2 -0.   0.   2.7 -0.4 10.5 -0.3  0.2 -1.2 -0.7 -0.   0.2 -0.1 -0.2 -0.  -1.3  3.6  4.9 -0.6  0.  -0.1 -0.6 -0.7  2.3 -0.2 -0.1 -0.9 -0.4 -0.2 -0.6  1.9 -2.7 -0.  -1.  -0.1 -0.2  8.6 -0.1 -0.  -0.3 -1.1 -0.5  6.6 -0.   5.6 -0.2 -1.   8.5]
ty_50sample [[1 5 8 7 4 9 2 6 0 3]
 [9 2 3 8 6 4 0 7 5 1]
 [2 5 4 6 3 7 9 8 1 0]
 [6 9 5 7 0 8 3 1 4 2]
 [8 1 4 0 5 7 9 2 3 6]
 [9 5 4 0 6 2 7 1 8 3]
 [1 4 9 7 5 3 8 6 2 0]
 [9 3 8 6 5 1 4 7 2 0]
 [8 6 1 5 7 3 2 0 9 4]
 [7 5 2 1 0 3 6 9 8 4]]
tt_50sample [[1 5 8 7 4 9 2 6 3 0]
 [9 2 3 8 6 4 0 7 5 1]
 [2 4 5 6 3 7 9 8 1 0]
 [6 9 5 7 0 8 3 1 4 2]
 [8 1 4 0 5 7 9 2 3 6]
 [9 5 4 0 6 2 7 1 8 3]
 [1 4 9 7 5 3 8 6 2 0]
 [9 3 8 6 1 5 4 7 2 0]
 [8 1 6 5 3 7 2 0 4 9]
 [7 5 2 1 0 3 6 9 8 4]]
vm  [-0.3 -0.3  5.5 -0.7 -1.8 -0.5  0.5 -0.2 -1.  -0.6  5.5 -0.3 -0.3 -0.1  8.4 -1.5 -0.1 -0.4  1.8  1.5 -1.4 -0.2 -0.9 -0.2 -1.1  2.9 -0.2  0.4 -1.2 -1.3  0.9 -0.1 -1.  12.4  0.3 -0.3  0.5 -1.2 -3.3 -0.3 -0.9 -2.1 -0.2 -1.  -0.2 -0.4 -1.9 -0.3  4.4 -5.3 -0.4 -0.1 -0.3  3.5  0.3 -1.  -0.3  4.9  2.7 -1.3  3.7 -0.3 -0.2 -0.3 -0.5 -0.2 -0.2  0.2  2.4 -0.3 -0.4  4.   1.6  0.6 -4.5  0.1 -0.2 -0.2  0.3 -0.7  5.5 -0.2 -0.5 -0.6 -1.  -1.7  0.2 -0.2 -0.1 -0.1 -0.3 -0.1 -0.1  0.4 -0.8 -0.5 -0.1 -3.6 -0.2 -0.4  2.5 -1.  -0.5 -0.2 -0.3 -0.4 -2.3 -0.2  1.5  0.7 -0.1 -0.4 -0.1 -0.5  2.3 -1.3 -0.5 -0.3 -0.1 -0.2 -0.3 -0.5 -0.3  0.1 -0.2 10.4 -0.2 -0.1  3.8 16.8  1.  -0.3 -0.2 -0.4  4.1 15.4 -0.3  0.   0.2 -0.1  1.2 -0.7  0.8  0.   0.  -0.2 -0.4 -0.1 -0.2 -0.1  0.8 -0.1 -0.9  3.3 -0.3 -0.1 -0.1 -0.5 -0.8  1.1 -0.4  0.6 -0.2 -0.1 -0.4 -0.2 -0.1 -0.3  0.2 -0.2 -0.2 -0.4 -0.1 -0.3 -0.4  1.5 -0.2 -0.7  3.8 -0.3 -0.9 -0.5 -0.2 -2.3 -0.2  0.9 -0.2 -0.5 -0.5  4.5 -0.1 -0.1 -0.1 -1.3 -1.1 -1.3 -0.2 -0.7  0.3 -0.3 -0.1 -0.1 -0.3 -0.3 -0.2 -2.7 -0.2 -0.4 -3.3 -0.2 -0.3 -1.6 -1.   0.1 -0.3 -0.1  4.8 -1.4 -0.1 -0.2 -0.1 -0.2  0.  -1.  -0.4 -1.6 -2.2 -0.3 -0.7  1.1 -0.4 -0.1  0.2 -0.8  0.9 -1.2  0.6 -0.4  2.6 -2.5 -0.2 -1.1 -0.3  0.3 -0.6  2.3 -0.2 -0.5 -1.3 -0.3 -1.7 -0.2 -1.8 -0.  10.5 -3.9]
vy_50sample [[3 0 6 7 5 1 4 2 9 8]
 [8 6 3 3 7 4 9 2 5 1]
 [8 3 2 0 4 6 5 9 7 1]
 [5 7 2 3 9 8 4 6 1 0]
 [6 1 4 8 9 5 3 2 7 0]
 [4 7 8 8 9 5 6 1 3 2]
 [4 9 7 6 2 1 5 0 3 8]
 [7 3 0 0 6 1 8 5 2 4]
 [6 3 7 9 2 5 1 4 0 8]
 [4 1 0 5 6 7 2 8 9 9]]
vt_50sample [[3 0 6 7 5 1 4 2 9 8]
 [8 6 3 0 7 4 9 2 5 1]
 [8 3 2 0 4 6 5 9 7 1]
 [5 7 2 3 9 8 4 6 1 0]
 [6 1 8 4 9 5 3 2 7 0]
 [4 7 0 8 9 5 6 1 3 2]
 [4 9 7 6 2 1 5 0 3 8]
 [7 3 9 0 6 1 8 5 2 4]
 [6 3 7 9 2 5 1 4 0 8]
 [4 1 0 5 7 6 2 3 8 9]]
Epoch 52310: Training cost= 0.2235, Training acc= 0.8646, Validation cost= 0.2400, Validation acc= 0.8647
Epoch 52320: Training cost= 0.2156, Training acc= 0.8646, Validation cost= 0.2220, Validation acc= 0.8647
Epoch 52330: Training cost= 0.2135, Training acc= 0.8646, Validation cost= 0.2456, Validation acc= 0.8647
Epoch 52340: Training cost= 0.2257, Training acc= 0.8646, Validation cost= 0.2410, Validation acc= 0.8647
Epoch 52350: Training cost= 0.2086, Training acc= 0.8647, Validation cost= 0.2115, Validation acc= 0.8647
Epoch 52360: Training cost= 0.2482, Training acc= 0.8647, Validation cost= 0.2779, Validation acc= 0.8647
Epoch 52370: Training cost= 0.2105, Training acc= 0.8647, Validation cost= 0.2214, Validation acc= 0.8648
Epoch 52380: Training cost= 0.2732, Training acc= 0.8647, Validation cost= 0.2599, Validation acc= 0.8648
Epoch 52390: Training cost= 0.2394, Training acc= 0.8647, Validation cost= 0.2204, Validation acc= 0.8648
Epoch 52400: Training cost= 0.2271, Training acc= 0.8647, Validation cost= 0.2009, Validation acc= 0.8648
tm  [-1.6  1.   4.9  7.5 -2.1 -0.2 -0.3 -0.3 -1.6 -0.  -4.3  0.4 -0.3 -0.1  0.4 -1.6 -0.5 -0.4  0.2 -1.2 -1.2 -0.  -0.5 -0.  -1.1  1.   0.6 -0.  -1.8  3.7 -0.3 -0.1 -0.  -0.8 -0.1  1.2  4.5 -0.8  2.6 -0.3  2.7 -0.9  2.2 -0.1 -0.2  0.2  6.8 -0.1 -2.8 12.8  0.6 -0.2 -0.2 -1.9  1.1 -0.2 -0.7 -2.1 -2.8  5.3  2.9  0.7 -0.2 -0.2 -1.2  0.9 -0.3 -0.4  0.1 -0.3  0.4  5.8 -0.5 -0.8  1.8 -0.4  0.6 -0.4  0.1 -0.1 -0.2 -0.5 -0.4 -0.1  2.8 -0.6 -1.6 -0.1  0.1  0.1 -0.9 -0.   0.6  2.2 -0.3 -0.3 -0.  -0.5 -0.3  0.6  0.3  5.9  0.1 -0.4 -0.  -0.1 -0.7 -0.3 -1.  -2.2 -0.7 -0.4 -0.   1.1  1.1 -3.5  1.2 -1.4 -0.6 -0.1 -0.1  8.2 -0.3  0.8 -0.5  0.3 -0.3  7.5 -4.1 -3.1 -0.7 -0.  -0.4 -0.  -0.3 -1.3 -0.1 -0.1 -0.4 -0.1 -0.2 -0.6 -0.1 -0.1 -0.  -0.4 -0.2  0.4 -2.3 -0.  -0.7 -0.5 -0.  -0.2 -0.1 -0.2 -0.1  2.2 -0.5 -0.5 -0.5 -0.4 -0.2 -0.2 -0.1  1.4  0.2 -0.6 -0.2 -0.2 -0.3 -0.  -0.2 -0.4 -0.3  2.2 -0.5 -0.2 -0.   0.1  1.6  0.4  0.9 -1.2 -0.3 -0.4 -0.8 -0.7 -0.1 -1.  -0.5  1.1 -0.1 -0.8 -0.3 15.4 -0.3 -0.6 -0.3 -0.1 -0.2 -0.2 -0.1 -0.1 -0.3 -0.2 -0.3 -0.1 14.4 -0.1  0.2 -2.7  0.4  9.8  0.4 -0.3  1.3 -0.6 -0.4 -0.6 -0.2  0.1  0.6 -0.5  3.5 -1.1 -1.1 -0.7 -0.1 -1.3 -0.3 -0.3  0.1  1.3  2.5 -0.7 -0.5  0.3 -0.6 25.9 -0.1  7.3  0.3 -0.1  2.6 -1.  -0.6 -0.3 -1.2 -0.5 -0.1 -0.3  2.  -0.3 -0.1 11.7]
ty_50sample [[1 0 8 9 7 6 4 2 3 5]
 [8 8 4 7 7 3 0 1 2 5]
 [4 6 1 5 5 3 2 8 7 7]
 [7 0 4 6 1 3 5 9 8 2]
 [7 1 6 4 5 3 9 2 0 8]
 [9 0 8 1 1 3 5 4 7 6]
 [3 9 1 1 6 5 7 2 4 0]
 [6 8 0 3 1 4 9 5 2 7]
 [8 1 4 9 3 6 5 2 7 0]
 [4 5 5 3 0 8 1 7 6 9]]
tt_50sample [[1 0 8 9 7 6 4 2 3 5]
 [8 6 4 9 7 3 0 1 2 5]
 [4 6 1 5 0 3 2 8 7 9]
 [7 0 4 6 1 3 5 9 8 2]
 [7 1 6 4 5 3 2 9 0 8]
 [9 0 8 1 2 3 5 4 7 6]
 [3 9 8 6 1 5 7 2 4 0]
 [6 8 0 3 1 4 9 5 2 7]
 [8 1 4 9 3 6 5 2 7 0]
 [4 2 5 3 0 8 1 7 6 9]]
vm  [-0.6 -0.2 -2.8 -4.9 -1.1  0.5 -0.3  0.1 -0.6 -1.2 10.9 -0.1  0.4 -0.2  4.4  5.9  1.2 -0.3 -0.7 -0.8 -1.7 -0.1 -0.2 -0.3 -1.2 -0.2 -0.2 -0.2  0.1 -0.2  2.8 -0.3  0.5  9.8  0.   0.4  0.6  4.4 -0.8 -0.1  2.5 -2.8  0.3  4.8 -0.   0.3 -0.4  0.6 -0.5 -2.7 -0.4 -0.1 -0.6 11.2 -1.5 -0.6 -0.8 -3.8  3.9 -4.7  4.3 -0.3 -0.4 -0.1 -0.2  0.  -0.   0.1 -0.5 -0.1  0.6 -1.5 -0.3  1.2 -3.7  0.6 -0.2  1.1 -0.  -0.3  9.1 -0.2 -0.2 -0.5 -0.5 -2.3  5.9 -0.3  0.5 -0.4 -0.5  0.1 -0.2  1.  -0.7 -0.1  0.1 -2.7  0.1  0.3  3.8 -0.5 -0.1 -0.  -0.  -0.2 -2.4  0.8 -0.5 -1.1 -0.5 -0.2 -0.  -0.8 -0.3 13.3  1.  -0.4 -0.5 -0.1 -0.2  3.4 -0.2 -0.  -0.2  5.6 -0.3 -2.1  3.3  7.  -0.3 -0.1 -0.4 -0.2 -0.5 10.1 -0.4 -0.2 -0.1 -0.2 -0.7 -0.  -0.3 -0.3 -0.1 -0.2 -0.3 -0.2 -1.   0.4  4.7 -0.2 -0.8 -0.5 -0.2  0.1 -0.2 -0.4 -0.  -0.6 -0.3 -0.6 -0.2 -0.  -0.   1.3 -0.3 -0.7  1.5 -0.1 -0.1 -0.  -0.3 -0.2 -0.   2.3 -0.9 -0.3  0.9  0.1  0.1  1.3 -0.6 -1.7 -0.1 -0.5 -0.2 -0.9 -0.3  1.  -0.1  0.2  0.3 -1.  -1.2 -1.4 -0.4 -0.   0.1 -0.1 -0.4 -0.1  0.3 -0.   0.7 -2.6 -0.3 -0.3  3.2 -0.2 -0.7  1.7 -0.3  2.2  0.5 -0.3 -2.2 -1.1 -0.4 -0.6 -0.1  0.4 -0.7 -1.4 -1.   2.9  0.7 -0.6 -0.3  0.2 -0.4  0.7 -0.1  1.6 -0.3  5.1 -0.3 -0.7  1.1 11.  -0.2  2.8 -0.  -0.1 -1.5  2.8 -0.5 -0.4 -1.4  0.  -2.5 -0.  -0.5 -0.4 -0.1 -1.2]
vy_50sample [[4 2 3 1 7 6 9 8 5 0]
 [5 4 9 0 7 6 2 1 8 3]
 [2 0 6 7 9 1 3 8 5 4]
 [3 1 2 6 9 7 0 8 5 4]
 [6 3 3 5 4 7 8 0 2 1]
 [6 1 8 5 2 9 3 4 0 7]
 [6 2 2 4 1 3 5 0 7 9]
 [7 5 9 0 4 3 6 2 1 8]
 [1 1 4 6 5 2 7 3 0 9]
 [6 3 3 5 7 0 2 1 9 4]]
vt_50sample [[4 2 3 1 7 6 9 8 5 0]
 [5 4 9 0 7 6 2 1 8 3]
 [2 0 6 7 1 9 3 8 5 4]
 [3 1 2 6 9 0 7 8 5 4]
 [6 3 9 5 4 7 8 0 2 1]
 [6 1 8 5 2 9 3 4 0 7]
 [6 2 8 4 1 3 5 0 7 9]
 [7 5 9 0 4 3 6 2 1 8]
 [1 8 4 6 5 2 7 3 0 9]
 [6 8 3 5 7 0 1 2 9 4]]
Epoch 52410: Training cost= 0.2211, Training acc= 0.8647, Validation cost= 0.1876, Validation acc= 0.8648
Epoch 52420: Training cost= 0.2287, Training acc= 0.8647, Validation cost= 0.2188, Validation acc= 0.8648
Epoch 52430: Training cost= 0.1903, Training acc= 0.8647, Validation cost= 0.1965, Validation acc= 0.8648
Epoch 52440: Training cost= 0.2438, Training acc= 0.8647, Validation cost= 0.2343, Validation acc= 0.8648
Epoch 52450: Training cost= 0.1975, Training acc= 0.8647, Validation cost= 0.2061, Validation acc= 0.8648
Epoch 52460: Training cost= 0.1816, Training acc= 0.8648, Validation cost= 0.1579, Validation acc= 0.8648
Epoch 52470: Training cost= 0.2115, Training acc= 0.8648, Validation cost= 0.2057, Validation acc= 0.8648
Epoch 52480: Training cost= 0.2128, Training acc= 0.8648, Validation cost= 0.2286, Validation acc= 0.8648
Epoch 52490: Training cost= 0.2264, Training acc= 0.8648, Validation cost= 0.2248, Validation acc= 0.8649
Epoch 52500: Training cost= 0.1946, Training acc= 0.8648, Validation cost= 0.2398, Validation acc= 0.8649
tm  [ 0.8 -0.3  5.2  1.2 -1.3 -0.3 -0.2  0.  -0.5  0.7 10.3 -0.3 -0.3 -0.1  6.2 -0.  -0.2 -0.2  1.   0.6 -1.1 -0.2  1.7 -0.3 -1.2  3.8 -0.1  0.8 -0.8 -1.8  0.4 -0.4 -0.9  7.2 -0.1 -0.3  1.1  5.5 -0.2 -0.9 -1.2 -1.1 -0.9 -1.  -0.1 -0.3 -0.8 -0.5  5.6  5.7 -0.1 -0.2  0.7 11.8 -0.1 -0.7 -0.2 -1.6  5.4  1.9 -0.1 -0.1 -0.3  0.2 -0.  -0.4  0.  -0.1 -0.2 -0.2 -0.2  4.4 -0.1  0.1 -3.4 -0.3 -0.2 -0.8 -0.2 -0.1  0.2 -0.1 -0.3 -0.6 -1.7 -0.3  2.5  0.1 -0.  -0.2 -0.2 -0.1 -0.1 -1.1 -0.3 -0.3 -0.6 -3.1 -0.6 -0.2 -0.4  5.7 -0.8 -0.1 -0.3  1.9 -1.4 -0.3 -0.  -0.6 -0.  -0.1 -0.  -0.1  5.1 -2.2 -0.6 -0.1 -0.   0.9 -0.2  0.5 -0.1 -0.1 -0.1  7.5 -0.2 -2.4  2.  -0.4  1.4 -0.1 -0.   0.4 -1.2  4.1 -0.2 -0.  -0.3 -0.3 -0.4 -1.1 -0.5 -0.2 -0.  -0.3 -0.2  0.4 -2.5 -0.2 -0.1 -0.1  2.3 -0.5 -0.  -0.3 -0.2 -0.4 -0.6 -0.3  1.  -0.5  0.9 -0.1  0.3 -0.8 -0.4 -0.4 -0.3 -0.1 -0.1 -0.1 -0.2  0.2 -0.1  3.7 -0.2 -0.3  0.5 -0.1  2.3 -0.4 -0.2 -2.2 -0.1 -0.1  0.2  0.   0.4  5.4 -0.2 -0.2 -0.3 -1.1  3.9 -0.7 -0.3 -1.8 -0.1  0.2 -0.  -0.1 -0.4 -0.5 -0.1 -1.3 -0.1 -0.2  6.7 -0.3 -0.3 -1.4 -0.9 -0.7 -0.7 -0.1  3.3 -1.1 -0.2  1.3 -0.1 -0.2  0.7 -1.5  5.4 -1.2  2.   2.1  0.8  1.  -0.5 -0.3 -0.1  1.3  0.1 -1.1  1.5 -0.4  3.   9.7 -0.1  1.9 -0.2 -0.3  2.2 -0.6 -0.5  0.5 -1.3 -0.5 -0.3 -0.2 -0.   0.  -2.1  3.6]
ty_50sample [[2 0 7 6 8 8 4 1 3 5]
 [9 2 1 0 5 8 4 7 6 3]
 [8 2 3 1 4 6 9 0 7 5]
 [1 6 8 4 9 9 7 0 3 2]
 [7 8 5 3 6 2 0 1 4 9]
 [5 4 6 1 2 7 9 3 0 8]
 [9 3 4 6 1 5 0 7 8 2]
 [4 2 9 6 3 8 5 7 0 1]
 [0 3 4 8 5 2 9 7 6 1]
 [0 4 2 1 3 9 7 5 6 8]]
tt_50sample [[2 0 7 6 8 9 4 1 3 5]
 [9 2 1 0 5 8 4 7 6 3]
 [8 2 3 1 4 6 9 0 7 5]
 [1 6 8 4 5 9 7 0 3 2]
 [7 8 5 3 6 2 0 1 4 9]
 [5 4 6 1 2 7 9 3 0 8]
 [9 3 4 6 1 5 7 8 0 2]
 [2 4 9 6 3 8 5 7 0 1]
 [0 3 4 8 5 2 9 7 6 1]
 [0 4 2 1 3 9 7 5 6 8]]
vm  [-1.6  0.6 -0.8 13.1 -1.6  0.1 -0.1 -0.1 -0.9 -1.   2.7 -0.  -0.2 -0.1 -2.7  2.3 -0.1 -0.2 -0.1 -0.2 -1.4 -0.3 -0.4 -0.1 -1.   2.7 -0.2 -0.4 -0.8 -3.2 -0.3 -0.2 -0.3 -2.7 -0.1  0.1  3.6  6.1 20.7 -0.1  1.4 -1.1  0.4  0.1 -0.2 -0.   3.6 -0.2 -1.9 -1.5 -0.2 -0.1  1.  -1.  -0.7  3.4 -0.6  5.8  0.1  3.6  2.  -0.1  1.4 -0.1 -1.   0.7 -0.2 -0.7 -0.3  0.2 -0.2 -0.4  0.4  0.8  1.2 -0.  -0.2  1.  -0.  -0.3  8.8 -0.2  0.1 -0.3  1.7 -0.4 -2.2 -0.2  0.2 -0.  -0.5 -0.3 -0.   0.  -0.5 -0.1  1.4 -1.2 -0.4  0.5  3.8 -2.2  0.2 -0.2 -0.2 -0.5  0.2 -0.2  1.3 -1.6 -0.6 -0.  -0.1 -0.4 -0.4  4.6  0.9 -1.2 -0.1 -0.6 -0.1  6.5 -0.2 -0.  -0.3 -3.4  0.1  5.3  1.4  1.6 -0.6 -0.3 -0.4 -0.5 -1.2 -4.2  0.3 -0.2 -0.1 -0.3  0.4 -0.4 -0.4 -0.3  0.3  0.3  0.4 -0.1  5.9 -0.2 -1.2 -0.2 -0.6 -0.2 -0.1 -0.2 -0.5 -0.2  3.6 -0.3 -0.  -1.4 -0.1 -0.1 -0.2 -0.   0.1 -0.4 -0.1 -0.3 -0.1 -0.  -0.2 -0.2 -0.1 -0.9  2.9 -0.2 -1.9 -0.2 -1.   0.2 -0.3 -1.2 -0.1 -0.3 -0.6 -0.  -0.1  9.2 -0.2 -0.1 -0.  -0.9 -0.2 -0.2  0.6  1.7 -0.2 -0.1 -0.3 -0.2 -0.2 -0.3 -0.3  1.4 -0.2 -0.   0.2 -0.3 -0.3 -0.3 -0.1 10.5 -0.3 -0.2 -1.  -1.  -0.3 -0.4 -0.2 -0.3 -0.  -0.5 -2.5  1.4 -0.6  0.6 -0.2 -0.6 -0.2 -1.2 -0.2  0.5  1.1  0.8 -0.5  0.5  0.9  8.6 -0.2  1.8 -0.  -0.2 -1.3 -1.7 -0.5 -0.2 -1.3 -0.4 -2.6 -0.2 11.8 -0.3  3.7  0.3]
vy_50sample [[1 9 9 5 2 8 0 4 7 6]
 [1 0 2 9 9 6 8 5 4 7]
 [1 5 2 3 9 9 8 0 6 4]
 [1 9 3 8 7 4 5 0 2 6]
 [8 7 0 4 5 2 1 3 9 6]
 [9 4 7 8 1 5 6 2 3 0]
 [3 9 4 6 1 8 7 0 5 2]
 [4 8 6 3 9 7 5 1 0 2]
 [4 1 2 5 9 6 0 7 3 8]
 [2 8 6 5 7 0 1 4 3 9]]
vt_50sample [[1 3 9 5 2 8 0 4 7 6]
 [1 2 0 9 3 6 8 5 4 7]
 [1 5 2 3 7 9 8 0 6 4]
 [1 9 3 8 7 4 5 0 2 6]
 [8 7 0 4 5 2 1 3 9 6]
 [9 4 7 8 1 5 6 2 3 0]
 [3 9 4 6 1 8 7 0 5 2]
 [4 8 6 3 9 7 5 1 0 2]
 [4 1 2 5 9 6 0 7 3 8]
 [2 8 6 5 7 0 1 4 3 9]]
Epoch 52510: Training cost= 0.2510, Training acc= 0.8648, Validation cost= 0.2616, Validation acc= 0.8649
Epoch 52520: Training cost= 0.2551, Training acc= 0.8648, Validation cost= 0.3695, Validation acc= 0.8649
Epoch 52530: Training cost= 0.2718, Training acc= 0.8648, Validation cost= 0.2826, Validation acc= 0.8649
Epoch 52540: Training cost= 0.2860, Training acc= 0.8648, Validation cost= 0.2235, Validation acc= 0.8649
Epoch 52550: Training cost= 0.2420, Training acc= 0.8648, Validation cost= 0.2051, Validation acc= 0.8649
Epoch 52560: Training cost= 0.2331, Training acc= 0.8648, Validation cost= 0.2351, Validation acc= 0.8649
Epoch 52570: Training cost= 0.2639, Training acc= 0.8648, Validation cost= 0.2628, Validation acc= 0.8649
Epoch 52580: Training cost= 0.2291, Training acc= 0.8649, Validation cost= 0.2215, Validation acc= 0.8649
Epoch 52590: Training cost= 0.2527, Training acc= 0.8649, Validation cost= 0.3042, Validation acc= 0.8649
Epoch 52600: Training cost= 0.2420, Training acc= 0.8649, Validation cost= 0.2508, Validation acc= 0.8649
tm  [-0.3  0.4 -5.6 -8.2 -1.1 -0.3 -0.2 -0.1 -1.8 -0.4  7.5 -0.1 -0.3 -0.2  4.1  1.1 -0.5  0.3 -1.   4.  -1.7 -0.2 -0.3 -0.1 -1.7  0.8 -0.2 -0.6 -1.1 -1.7  3.4 -0.2 -0.1 -3.  -0.  -0.2  2.   5.6 -3.1 -0.6  3.   3.6  2.   4.7 -0.1 -0.1 -3.7 -0.2  2.7 -0.6 -0.6 -0.3  0.2 18.8 -1.7 -0.6 -0.9 -0.3  0.9 -2.6  5.7 -1.1  0.3 -0.1 -0.4 -0.8 -0.3  0.  -0.2 -0.3 -0.1  0.4 -0.  -0.2 -7.5 -1.3 -0.1 -0.8 -0.1 -0.5 -4.8 -0.2 -0.2 -0.6 -1.4  1.8  7.7 -0.1  0.3 -0.3 -0.1 -0.2 -0.3  3.3 -0.7 -0.1 -0.6 -3.6 -0.  -0.2  0.6 -1.6 -0.3 -0.5 -0.1  0.3 -3.7  0.9  0.6  4.2 -0.7 -0.2 -0.1 -0.5 -0.5 -0.   1.7 -0.5 -0.4 -0.  -0.3 -1.9 -0.1  0.8 -0.3  5.  -0.1 -4.   5.1 13.4 -0.4 -0.1  0.1  1.9  6.1 -0.7 -0.3 -0.1 -0.4 -0.9 -0.2 -0.7 -0.6 -0.2 -0.1 -0.4 -0.7 -0.1  8.5 -0.2  8.3 -0.3  1.6 -0.1 -0.1  0.1 -0.3 -0.2  2.  -0.6 -0.4 -1.6 -0.3 -0.1 -0.1 -0.2 -0.2 -0.4  0.5 -0.2 -0.2 -0.3 -0.2  0.2 -0.2 -2.  -0.9 -0.2  3.6  0.2 -1.8 -0.1  0.5 -2.2 -0.3 -0.1 -0.2  0.7 -0.2  4.2 -0.4 -0.3 -0.  -1.9 -2.1 -1.5 -0.3  0.9 -0.1 -0.3 -0.1 -0.2 -0.3 -0.4 -0.6 -3.8 -0.4 -0.1 -3.5 -0.4 -0.3 -0.7 -1.1  0.3  0.8 -0.2 -2.7 -1.2 -0.7  0.1 -0.1 -0.1 -0.4 -1.3 -1.5 -0.1 -0.4 -0.6 -0.1 -0.3 -0.5  1.4 -0.4 -0.7 -0.3  6.6 -0.3 -0.6  0.8 -9.  -0.1 -3.4 -0.3 -0.  14.7  5.1 -0.6  0.6 -1.1  1.3 11.8 -0.1 -1.8 -0.4  0.7 -3.1]
ty_50sample [[4 5 2 3 0 8 1 6 7 9]
 [1 0 7 9 3 4 5 2 8 6]
 [2 4 9 6 1 3 3 7 8 0]
 [7 6 1 0 4 9 3 8 8 2]
 [7 9 5 8 0 2 4 6 1 3]
 [8 5 7 6 4 3 0 9 2 1]
 [7 9 6 4 5 3 8 1 0 2]
 [1 3 3 6 0 2 5 8 4 7]
 [3 5 6 8 7 0 4 9 2 1]
 [9 1 0 3 6 4 5 8 7 2]]
tt_50sample [[4 5 2 3 0 8 1 6 7 9]
 [1 0 7 9 3 4 5 2 8 6]
 [2 4 9 6 1 3 5 7 8 0]
 [7 6 1 4 0 9 3 8 5 2]
 [7 9 5 8 0 2 4 6 1 3]
 [8 5 7 6 4 3 9 0 2 1]
 [7 9 6 4 5 3 8 1 0 2]
 [1 3 9 6 0 2 5 8 4 7]
 [3 5 8 6 7 0 4 9 2 1]
 [9 1 0 3 6 4 5 8 7 2]]
vm  [-0.3 -0.2 -1.3 -5.4 -2.2 -0.2 -0.4  0.  -1.1  0.9  1.9 -0.3 -0.1 -0.2  9.5 -2.5 -0.5 -0.5 -0.   0.8 -1.4 -0.3 -0.3 -0.2 -1.4  3.3 -0.4  0.7 -1.3 -2.5  3.1 -0.  -0.4  9.2 -0.1 -0.3  0.8 -0.4 -1.1 -0.6 -0.5 -1.8 -1.   2.3 -0.2 -0.5 -1.5 -0.7 -1.1 -1.  -0.2 -0.   0.3  3.6 -0.2 -1.3 -0.7 -3.1  7.7 -2.9  8.  -0.6  0.8 -0.4  3.1 -0.7 -0.4  0.2  2.7 -0.6 -0.2  5.9 -0.3 -0.8 -5.5 -0.8 -0.1 -0.5 -0.1 -0.4 -1.  -0.1 -0.1 -0.4 -0.5 -1.6  1.9 -0.2 -0.3 -0.3 -0.2 -0.2 -0.3 -0.6 -0.6 -0.3 -1.2 -3.7 -0.3 -0.3 -0.6  2.9 -0.5 -0.1 -0.   0.4 -2.8  1.1  1.1  1.8 -0.1 -0.3  0.2 -0.3  8.3 -4.1 -0.3  0.7 -0.2  1.  -0.2 -1.4 -0.4  0.3 -0.1 12.4 -0.1 -0.2  5.9  6.   1.4 -0.4 -0.3  0.4 -2.2  3.7 -0.1 -0.2  0.5 -0.4  1.  -1.1  0.2 -0.4 -0.  -0.2 -0.4  0.4 -1.7 -0.3  5.7 -0.2 -1.3  2.3 -0.2 -0.2 -0.3 -0.4 -0.3 -0.4 -0.6 -1.6  0.3 -0.1 -0.1 -0.3  0.8 -0.4 -0.4 -0.  -0.1 -0.2 -0.2  0.3 -0.3  3.3 -0.5 -0.3  0.9 -0.1  1.1 -0.4  0.5 -2.8  0.1 -0.1 -0.1 -0.5  1.   6.6 -0.1 -0.5 -0.3 -1.7 -3.6 -1.8 -0.7 -2.4 -0.4 -0.1 -0.5 -0.2 -0.7 -0.2 -0.1 -2.8 -0.2  0.4  2.9 -0.3 -0.2 -2.4 -1.   4.7 -0.2 -0.3 -1.9 -1.4 -0.4  0.7 -0.3 -0.2 -0.5 -1.7 -0.3 -1.8 -2.5  0.1 -0.2 -0.8 -0.6  2.2 -0.5  2.1  0.9  1.9  0.3 -0.9  2.  -0.3 -0.2 -0.6 -0.2 -0.1  4.4  1.3 -0.  -0.2 -1.2  2.1  1.3 -0.1 -0.6  0.3  5.7 -1.2]
vy_50sample [[0 4 1 7 3 6 8 2 5 9]
 [1 5 4 2 9 0 3 8 6 7]
 [8 0 4 6 7 9 5 3 1 2]
 [9 4 8 6 1 5 2 7 3 0]
 [2 6 3 5 7 1 8 9 0 4]
 [7 3 2 6 9 0 1 4 5 8]
 [4 3 7 0 9 5 1 8 6 2]
 [7 8 5 1 1 0 2 3 6 4]
 [1 4 0 2 7 9 3 6 6 5]
 [9 2 6 5 0 7 8 1 4 3]]
vt_50sample [[0 4 1 7 3 6 8 5 2 9]
 [5 1 2 4 9 0 3 8 6 7]
 [8 0 4 6 7 9 5 3 1 2]
 [9 4 8 6 1 5 2 7 3 0]
 [6 2 3 5 7 1 8 9 0 4]
 [7 3 2 6 9 0 1 4 5 8]
 [4 3 7 0 5 9 1 8 6 2]
 [7 8 5 9 1 0 2 3 6 4]
 [1 4 0 7 2 9 8 3 6 5]
 [9 2 6 5 0 7 8 1 4 3]]
Epoch 52610: Training cost= 0.2184, Training acc= 0.8649, Validation cost= 0.2567, Validation acc= 0.8649
Epoch 52620: Training cost= 0.2354, Training acc= 0.8649, Validation cost= 0.2163, Validation acc= 0.8650
Epoch 52630: Training cost= 0.2342, Training acc= 0.8649, Validation cost= 0.2509, Validation acc= 0.8650
Epoch 52640: Training cost= 0.2425, Training acc= 0.8649, Validation cost= 0.2270, Validation acc= 0.8650
Epoch 52650: Training cost= 0.2493, Training acc= 0.8649, Validation cost= 0.2275, Validation acc= 0.8650
Epoch 52660: Training cost= 0.2051, Training acc= 0.8649, Validation cost= 0.1990, Validation acc= 0.8650
Epoch 52670: Training cost= 0.1965, Training acc= 0.8649, Validation cost= 0.2556, Validation acc= 0.8650
Epoch 52680: Training cost= 0.2082, Training acc= 0.8649, Validation cost= 0.1876, Validation acc= 0.8650
Epoch 52690: Training cost= 0.2116, Training acc= 0.8649, Validation cost= 0.1862, Validation acc= 0.8650
Epoch 52700: Training cost= 0.2615, Training acc= 0.8650, Validation cost= 0.2107, Validation acc= 0.8650
tm  [-0.6  0.6  2.3 23.9 -1.6 -0.1 -0.3  0.4 -0.2 -0.5  4.2 -0.1 -0.  -0.2 -3.9 -0.7  0.3 -0.1  1.9 -1.  -0.8 -0.2 -0.7 -0.1 -0.6  4.6 -0.3  2.1 -0.8 -3.6 -0.1 -0.2 -0.9  1.7 -0.  -0.2  0.1 -0.7 15.8 -0.  -1.4 -2.7 -1.3 -1.6 -0.1  0.2  7.5 -0.1 -0.  -4.1 -0.1 -0.   2.2 -3.8 -0.3  4.7  0.4  5.9  3.   2.  -1.1 -0.5  0.8 -0.2  0.4  0.1 -0.1 -0.  -0.3 -0.3 -0.  -0.3  0.4  0.8  3.9  1.3 -0.1 -0.1 -0.2 -0.2 26.1 -0.3 -0.2 -0.5 -0.5 -2.1 -2.  -0.2 -0.4 -0.2 -0.2 -0.1  1.1 -0.7 -0.6 -0.2 -0.  -0.7 -0.4 -0.3  1.3 -2.5 -0.4 -0.  -0.4  1.5  3.8  0.2  2.1 -1.9  2.   0.6 -0.  -0.1  2.8  1.6 -0.5 -0.2 -0.4  0.8 -0.5  6.9  0.2  1.  -0.2 -4.9 -0.  13.2  3.2 -0.2  0.8  0.  -0.1 -0.2  8.6  8.3 -0.4 -0.2  2.2 -0.3  0.4 -0.2 -0.1 -0.1 -0.  -0.1 -0.  -0.1  3.9 -0.2 -2.4 -0.2 -0.4  1.8 -0.1  0.4 -0.5  0.3 -0.2  0.1 -0.3 -0.6 -0.  -0.   0.4 -0.2 -0.1  0.1  0.4 -0.   0.4 -0.1 -0.1 -0.3  0.3 -0.3  0.5 -0.2 -1.4 -0.  -0.5 -0.  -0.3 -2.1 -0.2 -0.4 -0.3 -0.4 -0.1 10.2 -0.1  0.3 -0.2 -1.5 10.1 -1.1  0.8 -0.5 -0.2 -0.1 -0.1 -0.  -0.2 -0.2  0.6  7.8 -0.3 -0.3 -1.4  0.7 -0.4 -0.1 -0.6  5.1 -0.1 -0.1  5.6 -0.9 -0.4  0.2 -0.2 -0.1  1.2 -0.3 -0.5 -0.4 -2.1  1.9  2.1 -0.5 -0.1 -1.6  0.4 -0.4 -0.3 -0.3 -0.3  2.3  2.1 19.4 -0.2  4.9 -0.  -0.2 -5.3 -3.2 -0.6 -0.3 -1.3 -0.4 -6.5 -0.2  8.3 -0.1  8.3  2.4]
ty_50sample [[9 3 1 6 0 5 2 7 4 4]
 [5 3 2 9 0 6 1 7 4 8]
 [1 6 9 7 4 0 2 3 8 5]
 [0 8 2 3 3 7 5 6 1 4]
 [1 5 3 7 0 8 4 2 9 6]
 [6 0 5 9 7 2 4 3 8 1]
 [7 4 1 3 3 0 9 9 2 8]
 [4 7 2 1 8 3 0 9 6 5]
 [6 2 8 0 3 7 4 5 9 1]
 [3 9 4 1 6 5 0 2 8 7]]
tt_50sample [[9 3 1 0 6 5 2 7 4 8]
 [5 3 2 9 0 6 1 7 4 8]
 [1 6 9 7 4 0 2 3 8 5]
 [8 0 2 9 3 7 5 6 1 4]
 [1 5 3 7 0 8 4 2 9 6]
 [6 0 5 9 7 2 4 3 8 1]
 [7 4 1 0 5 3 6 9 2 8]
 [4 7 2 1 8 3 0 9 6 5]
 [6 2 8 0 3 7 4 5 9 1]
 [3 9 4 1 6 5 0 2 8 7]]
vm  [-0.7 -0.   1.9  3.5 -1.5 -0.2 -0.4 -0.  -0.1 -0.6 -0.3 -0.2 -0.1 -0.2  0.1 -1.2  0.5 -0.2  1.1 -1.1 -1.3 -0.1 -0.7 -0.1 -0.7  1.7 -0.4  0.9 -0.7 -2.8  0.4 -0.2 -0.6  9.5  0.1 -0.1 -0.5 -1.9 -0.6 -0.3 -1.2 -4.1 -1.3 -1.   0.1  0.9  1.  -0.1  1.5 -4.7 -0.  -0.1 -0.2 -2.5 -0.2 -0.  -0.2 -0.8  9.6 -1.9  1.7 -0.5 -0.3 -0.1 -0.5  0.1 -0.1 -0.3  0.1 -0.2  0.4  1.4 -0.1  3.  -2.1  1.1 -0.2 -0.1 -0.3 -0.1 15.8 -0.4 -0.4 -0.4 -0.3 -3.3 -0.5 -0.3 -0.3 -0.2 -0.5 -0.1 -0.1 -0.8 -0.7 -0.2  0.8 -3.1 -0.4 -0.1  2.7 -1.5 -0.1 -0.  -0.2 -0.3 -0.8 -0.3 -0.1 -2.  -0.2  0.   0.1 -0.7  7.2  1.4 -0.4  2.  -0.4 -0.2 -0.5  6.9  0.1 -0.  -0.1  0.3 -0.2  9.6  8.9  8.4  0.5 -0.3  0.3 -0.6  6.7 15.2 -0.4 -0.3  0.9  0.2 -0.  -0.2 -0.6 -0.2 -0.1 -0.2 -0.1 -0.1 -1.1 -0.  -0.3 -0.2 -0.7  0.5 -0.2 -0.1 -0.5 -0.4 -0.9 -0.5 -0.3  1.  -0.3  0.2  0.5  1.5 -0.2 -0.1  0.4 -0.1  0.3 -0.1 -0.2 -0.3 -0.1  3.7 -0.  -0.4  0.1 -0.1  0.2 -0.  -0.6 -1.5 -0.2 -0.5 -0.1 -0.7 -0.4  8.1  0.2 -0.2 -0.  -1.   0.6 -3.2 -0.2 -1.9 -0.3 -0.1 -0.  -0.  -0.1 -0.3 -0.  -1.3 -0.3 -0.2  2.7  0.6 -0.8 -0.4 -0.5  2.6 -0.1 -0.3  3.9 -1.4 -0.4 -0.5 -0.2  0.5 -0.2 -0.9 -0.2 -0.6 -2.3  0.8 -0.2  1.4 -0.4 -0.6  0.1  1.1  1.6 -0.2 -0.4 -0.1  3.  17.5 -0.3  4.5  0.3 -0.1 -2.9 -0.3 -0.4 -0.6 -1.8 -0.6 -4.1  0.1 -0.4 -0.2 10.4 -1.5]
vy_50sample [[3 6 0 1 9 7 4 8 5 2]
 [8 2 1 6 4 3 7 5 9 0]
 [7 3 0 0 9 4 1 6 8 2]
 [6 5 7 9 4 3 0 2 1 8]
 [5 9 6 4 3 8 7 1 2 0]
 [0 7 5 2 1 4 9 3 6 8]
 [2 4 6 5 7 0 1 3 8 9]
 [5 9 4 8 1 3 6 0 2 7]
 [3 5 7 6 2 8 8 9 4 4]
 [5 8 0 0 7 1 4 9 3 2]]
vt_50sample [[3 6 0 1 9 7 4 8 5 2]
 [8 2 1 6 4 3 7 5 9 0]
 [7 3 0 9 5 4 1 6 8 2]
 [6 5 7 9 3 4 0 2 1 8]
 [5 9 6 4 8 3 7 1 2 0]
 [0 7 5 2 1 9 4 3 6 8]
 [2 6 4 5 7 0 1 3 8 9]
 [5 9 4 8 1 3 6 0 2 7]
 [3 5 7 6 2 8 1 9 0 4]
 [5 8 0 6 7 1 4 9 3 2]]
Epoch 52710: Training cost= 0.2183, Training acc= 0.8650, Validation cost= 0.2115, Validation acc= 0.8650
Epoch 52720: Training cost= 0.2239, Training acc= 0.8650, Validation cost= 0.2283, Validation acc= 0.8650
Epoch 52730: Training cost= 0.2178, Training acc= 0.8650, Validation cost= 0.2311, Validation acc= 0.8651
Epoch 52740: Training cost= 0.2350, Training acc= 0.8650, Validation cost= 0.1968, Validation acc= 0.8651
Epoch 52750: Training cost= 0.2381, Training acc= 0.8650, Validation cost= 0.2521, Validation acc= 0.8651
Epoch 52760: Training cost= 0.2254, Training acc= 0.8650, Validation cost= 0.2565, Validation acc= 0.8651
Epoch 52770: Training cost= 0.2594, Training acc= 0.8650, Validation cost= 0.2915, Validation acc= 0.8651
Epoch 52780: Training cost= 0.2913, Training acc= 0.8650, Validation cost= 0.2572, Validation acc= 0.8651
Epoch 52790: Training cost= 0.2701, Training acc= 0.8650, Validation cost= 0.2602, Validation acc= 0.8651
Epoch 52800: Training cost= 0.3456, Training acc= 0.8650, Validation cost= 0.2246, Validation acc= 0.8651
tm  [-0.5 -0.1  2.  -1.2 -1.8 -0.2  0.2 -0.1 -0.7 -0.6  5.1 -0.1 -0.1 -0.3  5.  -0.3 -0.6 -0.3  0.8 -1.1 -1.5 -0.3 -0.6 -0.1 -0.8  0.8 -0.2  0.7 -0.3  5.   2.6 -0.4 -0.3 19.5 -0.3 -0.1  1.2 -0.1 12.7 -0.3  0.1 -0.   1.6  4.3 -0.3 -0.3  5.3 -0.2 -0.3 -3.2 -0.4 -0.1 -0.  -2.4 -1.9 -0.5 -0.5 -1.  -1.3 -4.2 -0.5 -0.3 -0.4 -0.3  2.3 -0.6 -0.3 -0.1  1.1 -0.1 -0.3 -1.3  0.3 -0.6 -1.7 -0.3  0.1  0.5 -0.  -0.  20.5 -0.3 -0.2 -0.  -0.8 -0.1  5.5 -0.3 -0.3 -0.3 -0.3  0.  -0.   1.  -0.5 -0.4 -0.4 -1.3 -0.1 -0.3  1.2  3.9  0.1 -0.2  0.3  0.2 -1.5  0.2  2.3 -1.4  0.  -0.3 -0.2 -0.5 -0.8  6.8  0.4 -0.5  0.1 -0.  -0.1  4.  -0.2  1.6 -0.1  6.8 -0.2  8.9 -0.4  1.4 -0.1 -0.  -0.1  1.1 -5.7  6.5  0.3 -0.1 -0.3 -0.8 -0.1  0.1  0.7 -0.3 -0.2  0.1  0.   0.  -0.9 -0.1  0.9  0.  -0.7  1.1 -0.1 -0.3 -0.3 -0.3  0.6 -0.2 -0.6 -1.3  0.3 -0.2 -0.1 -0.  -0.2 -0.2 -0.2  0.1 -0.2  0.1 -0.1 -0.2 -0.   1.1 -0.3 -0.3 -1.2 -0.1 -1.2 -0.5 -0.  -1.3 -0.1  0.5  0.5 -0.4 -0.  -1.1 -0.3 -0.2 -0.4 -1.1  6.9  2.2 -0.1  2.9 -0.   0.2 -0.4 -0.1 -0.1 -0.1 -0.1 -0.3  0.4 -0.1 -3.7 -0.5 -0.4  1.4 -0.2  1.4  0.7 -0.  -2.5 -1.2 -0.3 -0.2 -0.2 -0.3 -0.6 -0.9 -1.4 -0.1 -2.2 -0.9 -1.3 -0.2 -0.4  0.5 -0.2 -0.6 -0.9  1.1 -0.4 -0.5  1.   2.9  0.1 -0.2  0.3 -0.4 -4.2 -1.5 -0.2 -0.4 -0.8 -0.3 -5.3 -0.2  7.8 -0.3  7.5  1.2]
ty_50sample [[7 4 3 9 5 1 6 0 2 8]
 [3 1 2 7 6 0 4 5 9 8]
 [6 3 0 1 5 4 7 9 2 8]
 [0 3 7 4 8 6 2 9 1 5]
 [2 8 6 4 3 1 0 9 5 7]
 [4 9 3 5 1 6 0 7 8 2]
 [6 2 7 5 1 4 0 3 8 9]
 [9 4 3 1 2 5 0 7 6 8]
 [8 9 3 2 5 4 7 1 6 0]
 [9 1 6 5 0 4 8 3 2 7]]
tt_50sample [[7 4 3 9 5 1 6 0 2 8]
 [3 1 2 7 6 0 4 5 9 8]
 [6 3 0 1 5 4 7 9 2 8]
 [0 3 7 4 8 6 2 9 1 5]
 [2 8 6 4 3 1 0 9 5 7]
 [4 9 3 5 1 6 0 7 8 2]
 [6 2 7 5 1 4 0 3 8 9]
 [9 4 1 3 2 5 0 7 6 8]
 [8 9 3 2 5 4 7 1 6 0]
 [9 1 6 5 0 4 8 3 2 7]]
vm  [-0.9 -0.1 -1.3 -6.3 -1.8 -0.1 -0.1 -0.2 -0.2 -0.4 -1.3  0.6 -0.1 -0.3 11.9  1.9 -0.4 -0.2 -0.1  1.5 -1.2 -0.1 -0.1 -0.1 -1.2  0.9 -0.1 -0.2 -0.3  3.6  2.  -0.3 -0.4  7.  -0.1 -0.  -0.5 -0.3 -2.6 -0.4 -0.   2.3 -0.4  2.6 -0.3 -0.2 -2.1 -0.2 -0.5 11.6 -0.3 -0.1  0.   5.1 -1.8 -1.4 -0.9 -3.4  3.5 -2.4  5.9 -0.2 -0.3 -0.2 -0.8 -0.2 -0.  -0.1  1.  -0.1 -0.1 -1.4 -0.2  0.3 -5.4 -0.1  0.  -0.4 -0.1 -0.2 -3.2 -0.4  0.2 -0.6 -0.6  4.1  3.6 -0.2 -0.3 -0.5 -0.5 -0.1  0.2 -0.6 -0.5 -0.4 -0.5 -3.5 -0.5 -0.2 -0.2  7.7 -0.2 -0.2 -0.2  1.  -2.2  1.4 -0.3 -0.4 -0.2 -0.2 -0.2 -0.7  1.2  9.7  0.7  1.3 -0.5 -0.1 -0.2 -0.2 -0.3  1.  -0.1 14.7 -0.3 -0.6  1.6 -0.6 -0.2 -0.1 -0.3 -0.1 -1.9  1.7 -0.   0.4 -0.6 -0.6  1.1 -0.4 -0.1 -0.1 -0.2 -0.   0.4  0.  -2.2 -0.   6.5 -0.2  0.2 -0.2 -0.1 -0.2 -0.4 -0.3  0.4 -0.5 -0.2 -0.6 -0.1 -0.2 -0.2 -0.3 -0.1 -0.  -0.  -0.  -0.1  0.1 -0.4 -0.3 -0.3  2.9 -0.5 -0.1  2.7 -0.1 -0.1  1.  -0.2 -1.9 -0.2 -0.2 -0.2 -0.1  0.2 -0.8 -0.3 -0.1 -0.1 -1.3 -2.3 -0.9 -0.4 -0.4 -0.1 -0.1 -0.1 -0.4 -0.4 -0.4 -0.2 -2.1 -0.  -0.2  6.4 -0.7  1.3  2.5 -0.6  5.5  1.  -0.  -1.7 -0.9 -0.1  0.2 -0.1 -0.1 -0.5 -1.3  4.8  4.  -1.3 -0.3  1.6 -0.4  0.2 -0.1 -0.2  1.5 -0.9  2.4 -0.3 -0.6  1.8 -0.5 -0.  -0.4 -0.  -0.1 10.4  1.7 -0.7  1.5 -1.2 -0.4  8.3 -0.2 -1.3 -0.2 -1.2  4.4]
vy_50sample [[4 7 1 8 6 2 5 0 9 3]
 [8 1 0 4 5 6 2 9 3 7]
 [3 7 1 4 2 9 0 5 6 8]
 [0 8 7 6 1 9 4 5 3 2]
 [9 7 0 1 3 8 4 6 2 5]
 [8 0 2 6 1 9 3 7 4 5]
 [2 9 7 5 3 4 6 8 1 0]
 [1 4 0 5 8 7 2 6 9 9]
 [7 8 5 9 3 6 0 4 1 2]
 [8 4 1 6 2 7 5 9 3 0]]
vt_50sample [[4 7 1 8 6 2 5 0 9 3]
 [8 1 0 4 5 6 2 9 3 7]
 [3 1 7 4 2 9 0 5 6 8]
 [0 8 7 6 1 9 4 5 3 2]
 [9 7 0 1 3 8 4 6 2 5]
 [8 0 2 6 1 9 3 7 4 5]
 [2 9 7 5 3 4 6 8 1 0]
 [1 4 0 5 8 7 2 6 9 3]
 [7 8 5 3 9 6 0 4 1 2]
 [8 4 1 6 7 2 5 9 3 0]]
Epoch 52810: Training cost= 0.1907, Training acc= 0.8650, Validation cost= 0.2568, Validation acc= 0.8651
Epoch 52820: Training cost= 0.2598, Training acc= 0.8650, Validation cost= 0.3122, Validation acc= 0.8651
Epoch 52830: Training cost= 0.2360, Training acc= 0.8651, Validation cost= 0.1978, Validation acc= 0.8651
Epoch 52840: Training cost= 0.2200, Training acc= 0.8651, Validation cost= 0.2801, Validation acc= 0.8651
Epoch 52850: Training cost= 0.2418, Training acc= 0.8651, Validation cost= 0.1948, Validation acc= 0.8651
Epoch 52860: Training cost= 0.2661, Training acc= 0.8651, Validation cost= 0.2140, Validation acc= 0.8652
Epoch 52870: Training cost= 0.2036, Training acc= 0.8651, Validation cost= 0.2526, Validation acc= 0.8652
Epoch 52880: Training cost= 0.2816, Training acc= 0.8651, Validation cost= 0.2249, Validation acc= 0.8652
Epoch 52890: Training cost= 0.2139, Training acc= 0.8651, Validation cost= 0.1959, Validation acc= 0.8652
Epoch 52900: Training cost= 0.2219, Training acc= 0.8651, Validation cost= 0.2619, Validation acc= 0.8652
tm  [ 1.6  0.8 -0.4 -2.1 -1.1 -0.3 -0.5 -0.3  0.4 -0.9  9.1 -0.3 -0.1 -0.3  4.8  1.9 -0.1 -0.4 -0.1  2.1 -1.  -0.  -0.6 -0.  -1.3  2.2 -0.7 -0.  -0.9 -4.1  1.7 -0.1  0.   5.6 -0.2 -0.2 -1.1  2.  -2.5  0.8  0.7  1.7 -0.8 -0.8 -0.3 -0.2 -2.2  0.1 10.2 -3.2 -0.2 -0.2 -0.5  9.6 -0.3 -0.7 -0.7  8.1 13.5 -1.5 -0.1 -0.6  0.2  0.  -0.1  0.4 -0.1 -0.4 -0.4 -0.3 -0.5 -0.3 -0.5  0.4 -4.6  0.7 -0.2  2.2  0.3 -0.4  1.5 -0.4 -0.1 -0.2 -1.6  2.3  4.5 -0.2 -0.2 -0.5 -0.4 -0.1 -0.1 -1.4 -0.7 -0.4  4.  -4.5 -0.4 -0.3  3.  -1.5 -0.4  0.2 -0.  -0.4 -1.6  0.3  0.4  1.7 -0.2  0.9 -0.2 -0.8  5.7  4.8 -0.2  1.7 -0.3 -0.8 -0.5 -0.6  0.8  0.5 -0.1  5.7 -0.2 -1.7 17.7 10.   1.  -0.5 -0.4 -0.9  5.4 10.   0.1  0.3  0.3 -0.2  0.2 -0.6 -0.7 -0.2 -0.1 -0.1  0.5  0.   7.2 -0.1  1.4 -0.2  1.3 -0.6 -0.2 -0.4 -0.6 -0.4  0.8  1.  -0.8 -0.6  0.5 -0.1 -0.2  0.6  0.2 -0.4 -0.2 -0.2 -0.3  0.4 -0.3 -0.3 -0.2 -1.5 -0.8 -0.3  2.9 -0.2 -1.7 -0.4 -0.3 -2.2 -0.2 -0.6 -0.3 -0.4 -0.4 10.7 -0.   0.4 -0.  -0.9  4.5 -6.  -0.1 -1.6 -0.3 -0.2 -0.2 -0.2  0.4 -0.6 -0.3 -2.7 -0.1 -0.4 -4.8  0.7 -0.7  0.6 -0.4 -2.5 -0.7 -0.5  1.4 -1.2 -0.8 -1.5 -0.2  0.1 -0.1 -1.  -1.1 -0.5 -0.8  1.3  1.3  3.8 -0.5 -0.8 -0.2 -1.1  0.6 -0.1 -0.7 -0.1  3.8 -5.2 -0.  -1.8  0.2 -0.2  1.4  1.7 -0.2 -0.7 -1.3  2.1 -0.4 -0.2 -1.5 -0.   3.6 -2.1]
ty_50sample [[5 3 2 6 4 7 7 9 8 8]
 [0 5 1 9 4 6 8 7 3 2]
 [6 5 0 7 1 9 8 2 4 3]
 [1 3 8 2 7 9 0 4 6 5]
 [6 2 0 8 7 5 3 4 1 9]
 [1 9 4 0 5 2 8 3 6 7]
 [5 2 7 9 1 6 8 0 3 4]
 [3 7 8 9 5 6 2 4 0 1]
 [6 1 0 2 4 9 7 8 5 3]
 [8 1 9 5 6 2 4 3 0 7]]
tt_50sample [[5 3 2 6 0 4 7 9 8 1]
 [0 5 1 9 4 6 8 7 3 2]
 [6 5 0 7 1 9 8 2 4 3]
 [1 3 8 2 7 9 0 4 6 5]
 [6 2 0 8 7 5 3 4 1 9]
 [1 9 4 0 5 2 8 3 6 7]
 [5 2 7 9 1 6 8 0 3 4]
 [3 7 8 9 5 6 2 4 0 1]
 [6 1 2 0 4 9 7 8 5 3]
 [8 1 9 5 6 4 2 3 0 7]]
vm  [-1.  -0.  -3.3 -1.9 -1.7 -0.1 -0.1  0.3 -0.5 -0.3 -0.1 -0.2 -0.1  0.4 -0.5  2.5 -0.1 -0.3 -0.8  0.1 -1.5 -0.5  1.6 -0.1 -1.1  2.4 -0.  -0.2 -0.9 -0.3  2.1 -0.2 -0.8 -1.7 -0.  -0.2  1.9 -0.4 -1.1 -0.4  0.6 -1.5 -0.4  1.3 -0.1  1.  -0.4 -0.4 -0.1  6.4  0.2 -0.1  0.2  1.5 -0.8 -0.  -0.2 -4.   3.5 -1.1  2.9  0.3 -0.1  0.2 -0.6  1.  -0.2 -0.2 -0.2 -0.   0.  -0.3  0.4  1.  -1.6 -0.6  0.2 -0.3 -0.1  0.4 -0.3 -0.1 -0.1 -0.   0.2 -0.9  4.2 -0.1 -0.1 -0.3  0.1 -0.  -0.1 -1.  -0.5 -0.4 -0.5 -2.8  1.1 -0.4  0.1  0.1 -0.2 -0.  -0.1  0.4 -0.9  0.7 -0.  -1.2 -0.7  0.4 -0.  -0.4  2.2  5.3 -1.3 -0.3 -0.1 -0.6  0.   3.4 -0.1  1.7 -0.1 -0.7 -0.1  1.4  1.3 -0.2  0.3 -0.3 -0.2 -0.5  9.9  5.6  0.1 -0.1  0.3 -0.3  0.3 -0.5 -0.4  0.2 -0.1 -0.1 -0.1 -0.1 -0.7  0.1  1.  -0.   0.9 -0.2 -0.1 -0.  -0.7  0.6 -0.5 -0.3  1.3  1.4 -0.2  0.2 -0.  -0.3 -0.3 -0.2  0.1  0.3 -0.  -0.1  0.6  0.6 -0.2  1.8 -0.2 -0.1  0.9  0.1  3.  -0.2 -0.3 -2.1 -0.1 -0.5 -0.1 -0.1 -0.   1.4  0.  -0.3 -0.1 -1.2 -0.2 -0.6 -0.  -0.7 -0.  -0.1 -0.1 -0.2 -0.4 -0.7  0.5 -1.4 -0.2 -0.1  9.9  0.3 -0.6  1.2 -0.9  6.6 -1.2 -0.3 -0.7 -1.2 -0.5  0.4 -0.1 -0.1 -0.3 -1.5  4.9  2.9 -0.8  1.6 -0.2  0.2 -0.1 -0.6  0.1  1.2  0.1  5.4 -0.1  0.6  5.3 15.5 -0.1  4.3  0.6 -0.1  3.  -0.6 -0.7  1.4 -1.6 -0.7  0.1  0.2 -0.6 -0.1 -0.2  3.9]
vy_50sample [[4 6 1 8 2 9 0 3 7 5]
 [3 8 9 1 5 7 4 2 6 0]
 [2 0 3 5 7 9 8 1 6 4]
 [6 5 7 0 3 4 1 2 8 8]
 [8 3 0 2 6 1 4 5 7 9]
 [1 6 0 9 4 7 5 3 2 8]
 [7 0 3 9 2 8 4 1 5 6]
 [8 5 6 1 7 4 2 9 0 3]
 [3 0 7 4 5 9 2 8 6 1]
 [9 8 7 1 2 5 4 3 6 0]]
vt_50sample [[4 6 1 8 9 2 0 3 7 5]
 [3 8 9 5 1 7 4 2 0 6]
 [2 0 3 5 7 9 8 1 6 4]
 [6 5 7 0 3 4 1 9 2 8]
 [8 3 0 2 6 4 1 5 7 9]
 [1 6 0 9 4 7 5 3 2 8]
 [7 0 3 9 2 8 4 1 5 6]
 [8 5 6 1 7 4 9 2 0 3]
 [3 0 7 4 5 9 2 8 6 1]
 [9 8 7 1 2 5 4 3 6 0]]
Epoch 52910: Training cost= 0.2052, Training acc= 0.8651, Validation cost= 0.2299, Validation acc= 0.8652
Epoch 52920: Training cost= 0.2751, Training acc= 0.8651, Validation cost= 0.2647, Validation acc= 0.8652
Epoch 52930: Training cost= 0.2469, Training acc= 0.8651, Validation cost= 0.3404, Validation acc= 0.8652
Epoch 52940: Training cost= 0.2767, Training acc= 0.8651, Validation cost= 0.2713, Validation acc= 0.8652
Epoch 52950: Training cost= 0.2803, Training acc= 0.8651, Validation cost= 0.3010, Validation acc= 0.8652
Epoch 52960: Training cost= 0.2231, Training acc= 0.8652, Validation cost= 0.1876, Validation acc= 0.8652
Epoch 52970: Training cost= 0.2446, Training acc= 0.8652, Validation cost= 0.2581, Validation acc= 0.8652
Epoch 52980: Training cost= 0.2823, Training acc= 0.8652, Validation cost= 0.3003, Validation acc= 0.8652
Epoch 52990: Training cost= 0.2860, Training acc= 0.8652, Validation cost= 0.2431, Validation acc= 0.8653
Epoch 53000: Training cost= 0.2269, Training acc= 0.8652, Validation cost= 0.2344, Validation acc= 0.8653
tm  [ 2.3 -0.2 -0.5 -2.4 -1.1 -0.4 -0.3 -0.2 -0.8 -0.4 11.8 -0.  -0.3 -0.3  4.3  2.7  0.2 -0.1  0.6  1.4 -1.3 -0.1 -0.4 -0.  -1.7  1.1 -0.3 -0.2 -0.3 -0.8  2.  -0.2 -0.2  2.9 -0.1 -0.3  1.3  3.9 -4.4 -0.3 -0.3  3.8  1.2 -0.8 -0.4 -0.3 -2.  -0.4  6.9 -2.  -0.3 -0.1 -0.5 18.1 -1.2 -0.7 -0.6  6.9 -0.1 -0.8  0.4 -1.  -0.6 -0.2  0.8 -0.8 -0.2  0.3 -0.5 -0.3 -0.1  0.4 -0.1 -0.  -5.6 -0.5 -0.3 -0.8 -0.1 -0.6 -0.8 -0.4 -0.3 -0.6 -1.7  2.7  4.7 -0.2 -0.1 -0.6 -0.1 -0.  -0.2  0.8 -0.1 -0.7 -0.3 -3.4 -0.6 -0.2  1.8 -0.8 -0.7 -0.1 -0.1 -0.2 -3.1 -0.  -0.4  1.4  0.4 -0.  -0.  -0.6 -0.5  1.4  0.6 -0.7 -0.1  0.9 -0.2 -0.8 -0.1 -0.2 -0.   5.4 -0.2 -4.   3.  10.3  0.1 -0.1  0.5 -0.   9.9 12.8 -0.1 -0.1 -0.2 -0.7 -0.7 -0.5 -0.5 -0.2 -0.2 -0.3 -0.4  0.1  6.5 -0.2  2.4 -0.   1.4 -0.6 -0.1 -0.3 -0.  -0.4 -0.7 -0.3 -0.4 -0.2 -0.   0.1 -0.1 -0.2 -0.3 -0.1 -0.1 -0.  -0.2  0.2 -0.5 -0.1 -0.2 -1.6 -1.5 -0.3  4.4 -0.  -2.1 -0.4 -0.1 -1.9 -0.3 -0.2 -0.3 -0.4 -0.4  2.8 -0.2 -0.2 -0.3 -1.6  3.  -0.9 -0.2  1.4 -0.  -0.1  0.  -0.3 -0.1 -0.4 -0.1 -3.4 -0.2 -0.4 -5.1 -0.2 -0.7 -0.7 -1.  -1.8 -0.2 -0.2  3.2 -1.2 -0.5 -0.1 -0.3  0.3  0.5 -0.7  0.7 -0.6  2.4 -0.1  2.3  2.  -0.5  1.7 -0.4 -0.8 -0.5 -0.  -0.  -0.5  0.4 -7.1 -0.  -2.7 -0.2  0.1  4.1  2.3  0.3 -0.3 -1.2  0.7  1.4 -0.1 -2.4 -0.1 -0.8 -2.4]
ty_50sample [[2 5 6 3 0 4 7 8 1 9]
 [5 1 2 4 6 3 0 9 7 8]
 [0 3 9 2 7 8 1 5 5 6]
 [1 4 3 7 8 2 5 0 6 9]
 [8 5 6 1 0 4 3 7 9 2]
 [2 4 5 6 8 1 3 7 9 9]
 [0 9 6 7 3 2 8 4 5 1]
 [2 8 9 5 4 7 7 6 1 0]
 [1 5 3 7 0 6 9 4 8 2]
 [7 4 9 2 6 5 3 8 0 1]]
tt_50sample [[2 5 6 3 0 4 7 8 1 9]
 [5 1 2 4 6 3 0 9 7 8]
 [0 9 3 2 7 8 1 4 5 6]
 [1 4 3 7 8 2 5 0 6 9]
 [8 5 6 1 0 4 3 7 9 2]
 [2 4 5 6 8 1 3 7 0 9]
 [0 9 6 7 3 2 8 4 5 1]
 [2 8 9 5 4 3 7 6 1 0]
 [1 5 3 7 0 6 9 4 8 2]
 [7 4 9 2 6 5 3 8 0 1]]
vm  [ 1.4 -0.5 -4.5 -2.7 -0.9  0.5 -0.2 -0.1 -0.6 -0.6  5.4 -0.1  0.2 -0.4 -1.9  0.8  0.8 -0.1 -0.2 -0.5 -1.5  0.5 -0.5 -0.2 -1.   0.  -0.4  0.1 -0.6 -0.3  2.7 -0.2  1.9 -1.4 -0.1 -0.2  1.8 -0.4 -2.5 -0.5  2.  -3.1 -0.4  0.  -0.3 -0.1  1.1 -0.5  5.7 -3.7 -0.2 -0.2 -0.1  2.  -1.3  2.3 -0.8 -2.4 -0.3 -2.8 -1.4 -0.3  1.  -0.3 -0.6 -0.9  0.1  0.2 -0.2 -0.  -0.1 -0.2 -0.2  0.1 -3.2 -0.  -0.2 -0.1 -0.2 -0.2  7.7 -0.5 -0.3 -0.8 -1.9 -3.   9.5  0.3 -0.3 -0.2 -0.8 -0.2 -0.3  2.1 -0.2  0.  -0.4 -2.2 -0.3 -0.1  1.  -2.  -0.6 -0.2 -0.2 -0.6 -2.  -0.3  1.  -1.8 -0.5 -0.1 -0.  -0.8 -0.2  1.8  2.9 -0.5 -0.1 -0.3 -0.1  4.9 -0.5 -0.5 -0.2 -2.4 -0.1  0.4 -0.1 11.  -0.6 -0.1  0.2  0.8 13.6 14.6 -0.1 -0.1 -0.3 -0.9 -0.9  0.1 -0.4 -0.  -0.3 -0.4 -0.2 -0.2  3.2 -0.2  2.7  0.   2.8 -0.6 -0.2 -0.3  0.2  0.8 -0.6 -0.8 -0.1 -0.7 -0.1  0.1  0.3  0.2 -0.6 -0.2 -0.4 -0.3 -0.1 -0.  -0.1 -0.2 -0.  -0.3 -1.8 -0.4  2.1 -0.1 -0.7  0.5  0.1 -1.4 -0.1 -0.4 -0.1  0.1 -0.2  1.  -0.  -0.1 -0.2 -1.3 13.7 -0.  -0.4  0.2 -0.1 -0.1 -0.  -0.2 -0.1 -0.5 -0.3 -1.2  0.2  0.5  1.6 -0.3 -0.8 -0.5 -0.3 -2.3  1.4  0.7 -0.6 -1.  -0.3  0.5 -0.2 -0.1 -0.4 -1.4 -1.2 -0.2 -1.3 -0.5 -0.5  1.7  1.1  3.  -0.   1.2 -0.8  5.  -0.3 -0.6 -0.5  7.8 -0.2  0.8 -0.4 -0.  -1.2 -0.9 -0.3 -0.2 -1.1 -0.8 -2.3 -0.1 -1.4  0.1  3.9 -2.3]
vy_50sample [[3 4 6 2 9 0 8 5 7 1]
 [5 8 4 6 9 3 7 0 1 2]
 [3 1 7 7 2 6 0 9 5 4]
 [6 0 1 4 9 7 8 5 2 3]
 [6 0 2 2 4 1 9 3 5 7]
 [5 6 2 3 8 4 1 7 9 0]
 [8 5 9 3 3 2 2 0 6 4]
 [4 9 6 7 0 2 3 1 5 8]
 [1 5 9 7 0 4 8 2 6 3]
 [4 2 1 0 7 8 5 9 3 6]]
vt_50sample [[3 4 6 9 2 0 8 5 7 1]
 [5 8 4 6 9 3 7 0 1 2]
 [3 1 7 8 2 6 0 9 5 4]
 [6 0 4 1 9 7 8 5 2 3]
 [6 0 2 8 4 1 9 3 5 7]
 [5 6 2 3 8 4 1 7 9 0]
 [8 5 9 3 7 1 2 0 6 4]
 [4 9 6 7 0 2 3 1 5 8]
 [1 5 9 7 0 4 8 2 6 3]
 [4 2 1 0 7 8 5 9 3 6]]
Epoch 53010: Training cost= 0.1992, Training acc= 0.8652, Validation cost= 0.2282, Validation acc= 0.8653
Epoch 53020: Training cost= 0.2515, Training acc= 0.8652, Validation cost= 0.2885, Validation acc= 0.8653
Epoch 53030: Training cost= 0.2174, Training acc= 0.8652, Validation cost= 0.2982, Validation acc= 0.8653
Epoch 53040: Training cost= 0.2050, Training acc= 0.8652, Validation cost= 0.2315, Validation acc= 0.8653
Epoch 53050: Training cost= 0.2653, Training acc= 0.8652, Validation cost= 0.2866, Validation acc= 0.8653
Epoch 53060: Training cost= 0.2514, Training acc= 0.8652, Validation cost= 0.2165, Validation acc= 0.8653
Epoch 53070: Training cost= 0.2616, Training acc= 0.8652, Validation cost= 0.2277, Validation acc= 0.8653
Epoch 53080: Training cost= 0.1975, Training acc= 0.8652, Validation cost= 0.2514, Validation acc= 0.8653
Epoch 53090: Training cost= 0.1992, Training acc= 0.8653, Validation cost= 0.2462, Validation acc= 0.8653
Epoch 53100: Training cost= 0.2519, Training acc= 0.8653, Validation cost= 0.2450, Validation acc= 0.8653
tm  [-0.5 -0.3 -5.7 -2.2 -1.2 -0.3 -0.4 -0.1 -1.2  0.2  6.2 -0.  -0.4  0.3 -3.  -0.6 -0.9 -0.1 -0.5 -0.8 -1.4 -0.4 -0.3 -0.2 -0.9 -0.2 -0.3 -0.  -0.8 -2.6  3.3 -0.2 -0.4  1.6 -0.1 -0.3  1.8  3.6 15.9 -0.6 -0.4  5.5 -0.3  4.9 -0.4  0.1  3.6 -0.3 -0.9 -1.9 -0.3 -0.1 -0.4 -1.8 -2.1  3.1 -0.3 -0.6  2.6 -5.   0.9 -1.1 -0.4 -0.4  0.9 -1.6 -0.4 -0.   0.1 -0.3  1.   0.9 -0.1  1.2 -2.9 -1.4 -0.3 -1.8 -0.3 -0.3 20.1 -0.2 -0.2 -1.  -0.8  2.8  3.6 -0.2 -0.2 -0.3 -0.1 -0.2 -0.4  1.2 -0.6 -0.6 -1.2 -1.8  0.1 -0.5 -0.1 -1.  -0.1 -0.3  0.3  0.4 -1.5  1.4  1.4 -1.7 -0.2  0.  -0.1 -0.3  0.8 -0.   0.3  0.2 -0.3  0.1 -0.2  6.1 -0.2  0.5 -0.5 -3.6 -0.1  7.   7.7 -1.1 -0.1  0.4  0.7  0.6  1.7  1.8 -0.1 -0.1 -0.  -1.   0.1 -0.3 -0.5 -0.4 -0.1 -0.5 -0.5  0.   8.5 -0.2  2.2  0.2 -1.5 -0.4 -0.1 -0.6  0.9  0.2  2.9 -0.3 -0.  -1.4 -0.2 -0.1  0.8  0.5  1.   0.4 -0.1 -0.2 -0.2  0.3 -0.3 -0.1 -0.5 -1.8 -0.2 -0.4 -1.4 -0.2 -2.2 -0.  -0.  -1.4 -0.1 -0.4 -0.1 -0.1 -0.1  7.5 -0.1 -0.3 -0.4 -2.   2.3 -2.1 -0.  -0.3 -0.4 -0.1 -0.4 -0.1 -0.4 -0.7 -0.3 -0.2 -0.2  0.7 -6.7 -0.2 -0.2 -1.1 -1.4  5.3  3.4 -0.7 -3.  -1.3 -0.4  2.4 -0.2 -0.1 -1.  -1.1 -1.1 -1.3 -1.8  0.5  0.5 -0.5 -0.7  1.  -0.3 -1.1 -0.4  7.7  0.6 -0.4  0.7 -2.8 -0.  -1.7 -0.4 -0.1 -4.  -1.4 -0.6  1.2 -1.5  0.4 -5.2 -0.   9.3 -0.   2.6  5.7]
ty_50sample [[4 5 1 9 0 3 2 6 7 8]
 [3 8 5 4 9 0 2 7 1 6]
 [9 8 3 7 1 2 5 6 4 0]
 [3 6 2 7 1 8 4 5 9 0]
 [6 4 3 8 2 5 1 0 9 7]
 [3 6 2 4 5 7 8 1 0 9]
 [6 0 7 5 4 1 9 9 2 8]
 [9 1 3 2 5 0 0 8 7 6]
 [3 7 8 9 1 4 6 0 2 5]
 [5 8 2 3 7 1 4 6 9 0]]
tt_50sample [[4 5 9 1 0 3 2 6 7 8]
 [3 8 5 4 9 0 2 7 1 6]
 [9 8 3 7 1 2 5 6 4 0]
 [3 6 2 7 1 8 4 5 9 0]
 [6 4 3 8 2 5 1 0 9 7]
 [3 6 2 4 5 7 8 1 0 9]
 [6 0 7 5 4 1 9 3 2 8]
 [9 1 3 2 5 4 0 8 7 6]
 [3 7 8 9 1 4 6 0 2 5]
 [5 8 2 3 7 1 4 6 9 0]]
vm  [ 0.  -0.   5.8 12.8 -2.  -0.2 -0.1 -0.1 -1.1 -0.9  3.9 -0.1 -0.2  0.  -0.4 -0.2 -0.4 -0.2  0.1 -0.7 -1.2 -0.1 -0.4  0.2 -1.   2.3 -0.3 -0.3 -1.  -1.2  0.9  0.1  0.5  6.9 -0.2 -0.2  3.8  4.3 18.7 -0.2  1.7 -0.3  1.6 -0.1 -0.1 -0.   6.  -0.2  5.9 -2.3 -0.3 -0.1  0.1 -1.6  0.7  0.5 -0.5  5.9 -1.1  1.4 -1.9 -0.3  0.3 -0.  -0.3 -0.1 -0.1 -0.5  2.1 -0.2 -0.   2.9 -0.3 -0.3  3.1 -0.2 -0.2 -0.1 -0.1 -0.6 14.  -0.2 -0.2  0.2 -1.4 -0.2  3.6 -0.  -0.3 -0.  -0.2 -0.1 -0.1 -0.1 -0.5 -0.3  1.2 -1.2 -0.3 -0.1  4.4 -0.4 -0.8 -0.  -0.1 -0.6 -0.2 -0.1  1.7 -1.3 -0.5  0.1 -0.1 -0.2 -0.5 -1.1  0.  -1.3 -0.2 -0.5 -0.3  5.9 -0.3 -0.3 -0.3 -0.6 -0.   6.6 -0.4  0.2 -0.4 -0.4 -0.4 -0.7 -4.5 -2.1  0.2 -0.1 -0.  -0.2 -0.2 -0.6 -0.1 -0.  -0.  -0.2 -0.1 -0.1  2.5  0.1 -1.4 -0.2  2.6 -0.4 -0.1 -0.2 -0.2 -0.4  2.  -0.2 -0.4 -1.1 -0.3 -0.1 -0.1 -0.2  0.3 -0.4 -0.1  0.2 -0.1 -0.1 -0.2 -0.1 -0.2 -0.2 -0.  -0.1 -1.6 -0.2 -1.7 -0.  -0.1 -1.4 -0.2 -0.2 -0.2 -0.4 -0.2  2.9 -0.1 -0.1 -0.1 -1.  14.9  2.6 -0.1  1.3 -0.3 -0.2 -0.2 -0.2 -0.4 -0.5 -0.4  0.5 -0.1 -0.1 -2.2  0.1 -0.1 -1.3 -0.5 -1.5 -0.3 -0.5 -0.7 -1.2 -0.3 -0.4 -0.2 -0.1 -0.1 -0.6 -2.3 -0.9 -0.9  0.2 -0.   2.7 -0.5 -0.9 -0.1 -0.4  1.6 -1.3 -0.2  1.2  1.4  4.4 -0.1  0.1 -0.2 -0.  -2.6 -1.8 -0.2 -0.1 -1.1  0.1 -3.8 -0.1 11.  -0.2  5.4  1.5]
vy_50sample [[9 3 5 0 7 2 4 8 1 1]
 [4 8 8 7 3 5 2 1 6 9]
 [8 1 3 2 6 0 7 5 9 4]
 [7 2 5 3 6 8 4 9 0 1]
 [9 5 7 1 0 2 3 6 4 8]
 [1 3 5 8 0 9 4 6 7 2]
 [1 0 5 3 7 9 6 8 2 4]
 [7 4 0 6 5 3 2 9 8 1]
 [4 9 3 0 2 5 7 6 1 8]
 [1 7 3 9 2 6 0 0 4 5]]
vt_50sample [[9 3 5 7 0 2 4 8 1 6]
 [4 0 8 7 3 5 1 2 6 9]
 [8 1 3 2 6 0 7 5 9 4]
 [7 2 5 3 6 8 4 9 0 1]
 [9 5 7 1 0 3 2 6 4 8]
 [1 3 8 5 0 9 4 6 7 2]
 [1 0 5 3 7 9 6 8 2 4]
 [7 4 0 6 5 3 2 9 8 1]
 [4 9 3 0 2 5 7 6 1 8]
 [1 7 3 9 2 6 0 8 4 5]]
Epoch 53110: Training cost= 0.2875, Training acc= 0.8653, Validation cost= 0.2832, Validation acc= 0.8653
Epoch 53120: Training cost= 0.2425, Training acc= 0.8653, Validation cost= 0.2353, Validation acc= 0.8654
Epoch 53130: Training cost= 0.2515, Training acc= 0.8653, Validation cost= 0.2625, Validation acc= 0.8654
Epoch 53140: Training cost= 0.2140, Training acc= 0.8653, Validation cost= 0.2284, Validation acc= 0.8654
Epoch 53150: Training cost= 0.2227, Training acc= 0.8653, Validation cost= 0.2422, Validation acc= 0.8654
Epoch 53160: Training cost= 0.2425, Training acc= 0.8653, Validation cost= 0.2342, Validation acc= 0.8654
Epoch 53170: Training cost= 0.2055, Training acc= 0.8653, Validation cost= 0.1754, Validation acc= 0.8654
Epoch 53180: Training cost= 0.1977, Training acc= 0.8653, Validation cost= 0.2717, Validation acc= 0.8654
Epoch 53190: Training cost= 0.2175, Training acc= 0.8653, Validation cost= 0.2808, Validation acc= 0.8654
Epoch 53200: Training cost= 0.2584, Training acc= 0.8653, Validation cost= 0.2380, Validation acc= 0.8654
tm  [-0.3 -0.4 -6.   0.6 -0.9 -0.1 -0.1  0.1 -0.5 -0.8  4.  -0.1 -0.1 -0.2 -4.6  6.8 -0.  -0.1 -0.6 -1.  -0.7 -0.2  1.  -0.2 -1.  -0.1  0.1 -0.1  1.   1.4  1.8 -0.3 -0.2 -5.2  0.1 -0.1  1.5  4.6 17.  -0.1  1.5  1.1  1.2  2.9 -0.2 -0.   7.8 -0.2  3.4  5.5 -0.3 -0.1 -0.1 -1.1 -1.5  5.1 -0.2 -1.5 -1.4 -1.7 -1.6 -0.4 -0.1  0.1 -0.4  0.6 -0.2 -0.  -0.5 -0.4 -0.1 -2.2 -0.5 -0.   4.3  0.  -0.1  0.8 -0.2 -0.2 11.  -0.1 -0.3 -0.  -1.4  2.6  7.8 -0.1 -0.2 -0.2 -0.1 -0.3 -0.2  0.5 -0.6 -0.3  0.5  1.1  0.4  1.1  2.1 -0.9 -0.5 -0.2 -0.1 -0.5  1.7  0.6  2.2 -1.8 -0.4 -0.3 -0.1 -0.3 -1.7 14.9  0.5 -1.2 -0.1 -0.4 -0.   8.2 -0.3 -0.5  0.3 -5.9 -0.   4.7 -1.6 -2.7 -0.1 -0.1 -0.1 -0.2  7.3 -2.2 -0.3 -0.3 -0.3 -0.5 -0.9 -0.4 -0.9 -0.2 -0.2 -0.5 -0.3 -0.   6.  -0.2 -0.2 -0.   2.9 -0.6 -0.2 -0.1 -0.2 -0.8  1.1 -0.4  0.3 -0.9 -0.3 -0.  -0.1 -0.2 -0.6 -0.2  0.1 -0.2 -0.1 -0.3 -0.3 -0.  -0.2 -1.3 -0.7 -0.1 -1.6 -0.1 -0.9  1.7 -0.  -1.  -0.1 -0.1 -0.3 -0.1 -0.2 -0.3 -0.1 -0.2 -0.1 -1.1 13.1  5.1  2.   5.1 -0.3 -0.1 -0.1 -0.1 -0.2 -0.3  0.   5.6 -0.  -0.3  3.2 -0.2 -0.4  1.5 -0.1 -0.5  1.1 -0.4 -2.3 -0.5 -0.5 -0.4 -0.2 -0.1 -0.6 -0.9 -0.4  6.1 -0.  -0.2 -0.3  0.6 -0.7 -1.2 -0.   1.5 -0.8  7.1 -0.3  1.3  0.3 14.7 -0.2  3.8 -0.2  0.2 -1.7 -2.1 -0.2 -0.  -1.1 -0.2 -2.9 -0.   8.9 -0.2 -0.7 10.1]
ty_50sample [[4 9 2 8 5 3 6 1 7 0]
 [7 2 8 9 6 3 4 0 5 1]
 [5 4 4 1 7 0 9 2 8 3]
 [7 5 9 1 6 0 3 8 2 4]
 [4 1 6 3 0 9 7 5 8 2]
 [2 7 0 3 4 1 8 9 5 6]
 [3 1 2 4 5 8 0 6 7 9]
 [2 4 7 8 1 0 6 3 5 9]
 [6 1 0 2 7 4 9 5 8 3]
 [9 4 4 3 6 8 5 0 7 2]]
tt_50sample [[4 9 2 8 5 3 6 1 7 0]
 [7 2 8 9 6 3 4 0 5 1]
 [5 6 4 1 7 0 9 2 8 3]
 [7 5 9 1 6 0 3 8 2 4]
 [4 1 6 3 0 9 7 5 8 2]
 [2 7 0 3 4 1 8 9 5 6]
 [3 1 2 4 5 8 0 6 9 7]
 [2 4 7 8 1 0 6 3 5 9]
 [6 1 0 2 7 4 9 5 8 3]
 [9 4 1 3 6 8 5 0 7 2]]
vm  [-0.8  0.  10.9  6.9 -1.7  0.1 -0.5 -0.2 -1.6  1.3 -0.7 -0.1 -0.4  0.5 10.9 -1.4 -0.9  0.3 -0.6 -0.7 -1.3 -0.1  0.3 -0.1 -1.4  0.1 -0.3 -0.6 -1.2  4.5 -0.4 -0.1  3.  12.2 -0.2 -0.2  2.8 -1.2 -4.1 -0.7  3.2  4.3  1.  -1.  -0.2 -0.1  0.5 -0.5 -1.4  9.1 -0.2 -0.1 -0.3 -0.1 -0.3 -1.3 -0.9  4.1 -2.   4.9  5.6 -0.5 -0.2 -0.1  0.9 -1.   0.5 -0.3  0.5 -0.3  0.2  6.8 -0.2 -0.5 -4.1 -0.9 -0.3 -1.1 -0.1 -0.3 -0.1 -0.1 -0.3 -0.8 -0.2  5.2 -1.5 -0.1  0.  -0.3 -0.3 -0.2 -0.3  1.9 -0.   0.  -0.7 -2.4 -0.3  0.9 -0.3  7.9 -0.4 -0.2  0.5 -0.7 -2.2 -0.4 -0.4 -0.8 -0.8 -0.4 -0.1 -0.2  1.6 -3.7  0.2 -0.9 -0.2 -0.2 -0.   1.4 -0.4  0.9 -0.7 14.2 -0.1  2.2 -2.6 -1.6 -0.2  1.  -0.1  1.2 -0.3 14.1 -0.  -0.  -0.3 -0.9 -0.3 -0.7 -0.6 -0.3  0.  -0.2 -0.5 -0.1 -1.3 -0.1 -0.9 -0.3 -0.9 -0.2 -0.2 -0.3 -0.7 -0.7 -0.9 -0.6 -0.6 -0.6 -0.3 -0.1 -0.1  1.5 -0.1 -0.6 -0.4 -0.3 -0.2 -0.3 -0.1  0.3 -0.4  1.7 -1.8 -0.3  4.2 -0.2 -1.3 -0.4 -0.1 -1.6 -0.2 -0.2 -0.1 -0.5  0.2 -1.3 -0.4 -0.3 -0.1 -1.1 -1.8 10.3 -0.8 -0.7 -0.1 -0.   0.3 -0.3 -0.4  0.5 -0.6 -1.9 -0.3 -0.1 -0.7 -0.3 -0.1 -2.2 -0.2  4.4 -0.3 -0.1  5.8 -1.1 -0.3  1.3 -0.2 -0.2  1.7 -1.2  3.5 -1.4 -1.4 -0.8 -0.6 -0.9  1.2  3.7  0.1  0.3  0.1 -2.3  0.6 -1.  -0.3 -1.7 -0.2 -0.9 -0.3 -0.   2.2 -0.3 -0.5  0.4 -0.7 -0.2 -0.4 -0.1 -2.4 -0.2 -0.6  7.6]
vy_50sample [[7 0 6 1 5 8 9 2 4 3]
 [8 2 5 9 4 4 6 0 3 1]
 [0 7 2 6 8 9 1 5 3 4]
 [9 7 4 3 6 1 0 2 8 5]
 [3 7 8 1 4 4 6 2 5 9]
 [6 4 9 1 1 8 2 5 7 0]
 [5 7 3 9 1 6 2 0 8 4]
 [4 5 1 0 3 8 9 6 2 7]
 [8 3 0 2 4 7 6 9 9 1]
 [0 0 1 7 4 5 6 8 2 3]]
vt_50sample [[7 0 6 1 5 8 9 2 4 3]
 [8 2 5 9 7 4 6 0 3 1]
 [0 7 6 2 8 9 1 5 3 4]
 [9 7 4 3 6 1 0 2 8 5]
 [3 7 8 1 0 4 6 2 5 9]
 [6 4 9 1 3 8 2 5 7 0]
 [5 7 3 9 1 6 2 0 8 4]
 [4 5 1 0 3 8 9 6 2 7]
 [3 8 0 2 4 7 6 9 5 1]
 [0 9 1 7 4 5 6 8 2 3]]
Epoch 53210: Training cost= 0.2502, Training acc= 0.8653, Validation cost= 0.2369, Validation acc= 0.8654
Epoch 53220: Training cost= 0.2310, Training acc= 0.8654, Validation cost= 0.2361, Validation acc= 0.8654
Epoch 53230: Training cost= 0.1893, Training acc= 0.8654, Validation cost= 0.2676, Validation acc= 0.8654
Epoch 53240: Training cost= 0.2005, Training acc= 0.8654, Validation cost= 0.2184, Validation acc= 0.8655
Epoch 53250: Training cost= 0.2410, Training acc= 0.8654, Validation cost= 0.2772, Validation acc= 0.8655
Epoch 53260: Training cost= 0.2414, Training acc= 0.8654, Validation cost= 0.2106, Validation acc= 0.8655
Epoch 53270: Training cost= 0.2213, Training acc= 0.8654, Validation cost= 0.2104, Validation acc= 0.8655
Epoch 53280: Training cost= 0.2265, Training acc= 0.8654, Validation cost= 0.2169, Validation acc= 0.8655
Epoch 53290: Training cost= 0.2320, Training acc= 0.8654, Validation cost= 0.2246, Validation acc= 0.8655
Epoch 53300: Training cost= 0.2321, Training acc= 0.8654, Validation cost= 0.2395, Validation acc= 0.8655
tm  [-0.5 -0.1 -3.   3.4 -1.5 -0.2 -0.4 -0.3 -1.1  0.3 -8.4  0.5 -0.2 -0.3 -2.8 -0.7 -0.2 -0.1 -0.3 -1.5 -0.8 -0.   0.6 -0.2 -0.9 -0.3 -0.1 -0.2 -0.4  1.8 -0.1 -0.6 -0.3 -5.5 -0.2 -0.   2.7  0.2 24.3 -0.7 -0.7  4.2  1.1  2.7 -0.4 -0.2  6.7  0.8  1.5  5.6 -0.2 -0.3 -0.2 -5.1 -1.5  3.4 -0.5  4.  -2.3  3.4 -1.2 -0.7 -0.2  0.4 -0.7 -0.4 -0.1 -0.4  0.2 -0.3 -0.4 -0.2 -0.2 -0.2 -0.2  0.6 -0.2 -0.6 -0.2  1.8 -0.5 -0.2 -0.2 -0.3 -1.1  5.2  4.8  0.2  0.3 -0.1 -0.3 -0.1 -0.1  2.3 -0.8 -0.  -0.1 -0.4 -0.4  0.  -0.  -1.  -0.3 -0.3 -0.1 -0.6 -0.4 -0.4 -2.2 -2.2 -0.1 -0.3 -0.  -0.2 -1.2  2.1 -0.  -0.8 -0.3 -0.3 -0.2  8.8 -0.4 -0.5 -0.1 -3.4 -0.2 15.9 -1.9 -0.5 -0.3 -0.   0.8 -0.3 -2.2 -7.6 -0.5 -0.4 -0.1 -0.1 -0.3 -0.2 -0.2 -0.3  0.3 -0.4 -0.3 -0.2  7.7  0.  -0.5 -0.1  1.9 -0.4 -0.3 -0.2 -0.6 -0.7  1.8 -1.2  1.9 -1.1 -0.2 -0.1  0.1  1.7 -0.6 -0.5 -0.3 -0.2 -0.   0.2 -0.2 -0.5 -0.1 -1.3  3.5 -0.  -2.4 -0.2 -2.5 -0.3 -0.1 -0.6 -0.1  0.7 -0.1 -0.2 -0.4 -0.3 -0.1 -0.3 -0.  -1.1  9.8  7.5  0.2  4.3 -0.3 -0.2 -0.   0.2 -0.2 -0.6 -0.   2.5 -0.2 -0.3  0.1 -0.5 -0.8 -0.7 -0.5  0.6  3.3  0.  -2.3 -0.5 -0.1 -0.3 -0.2 -0.2 -0.  -0.7 -1.7  1.2 -1.9 -0.2 -0.5  0.1 -0.7 -0.3 -0.4 -0.1 -0.9  2.5 -0.   0.1 -0.1 -0.4 -0.2 -0.5 -0.  -0.1  3.4 -1.8 -0.4 -0.2 -0.9 -0.7 -0.  -0.1 13.2  0.1  7.   3.6]
ty_50sample [[5 8 9 4 3 0 1 7 6 2]
 [1 0 8 3 5 6 9 2 4 7]
 [1 8 9 6 2 3 4 7 0 5]
 [9 6 3 5 0 1 8 2 7 4]
 [9 9 8 0 6 1 2 7 3 4]
 [4 5 7 0 3 9 2 6 1 1]
 [5 9 7 4 2 8 3 1 6 0]
 [6 0 1 7 8 9 3 5 4 2]
 [0 9 4 3 7 8 6 1 5 2]
 [7 1 0 8 5 2 9 9 3 6]]
tt_50sample [[5 8 9 4 3 0 1 7 6 2]
 [1 0 8 3 5 6 9 2 4 7]
 [1 8 9 6 2 3 4 7 0 5]
 [9 6 3 5 0 1 8 2 7 4]
 [9 5 8 0 6 1 2 7 3 4]
 [4 5 7 0 3 9 2 8 6 1]
 [5 9 7 4 2 8 3 1 6 0]
 [6 0 1 7 9 8 3 5 4 2]
 [0 9 4 3 7 8 6 1 2 5]
 [7 1 0 8 5 2 9 4 3 6]]
vm  [-0.5  0.1 -0.6  2.8 -1.7  0.1 -0.3  0.  -1.5 -1.2 -4.7 -0.3 -0.1 -0.2 -0.7 -0.3 -0.3  0.3 -0.3 -0.8 -1.5  0.2  0.9 -0.1 -0.7  0.7  0.5 -0.7 -0.7  4.1 -0.4 -0.1 -0.3 -2.8 -0.   0.2  2.6  1.7 16.1 -0.3  1.6 -3.6  3.4  3.4 -0.   0.4  3.9  0.5  2.4  4.6 -0.5 -0.2  0.5 -1.5 -1.1  0.5 -0.3 -2.9 -2.8  4.2 -0.9  0.6 -0.3 -0.2 -0.7 -0.2 -0.1 -0.2  2.4 -0.1 -0.2 -0.1  2.   0.7  1.6 -0.3 -0.1 -0.3 -0.  -0.3 -1.1 -0.4 -0.1 -0.2 -1.3 -3.7  4.6  0.1 -0.1 -0.2 -0.2 -0.1 -0.1  2.8 -0.9 -0.5 -0.1 -1.  -0.6  0.1  4.  -0.5  0.2  0.4 -0.4 -0.5 -0.2 -0.5 -1.1 -1.7 -1.1 -0.4 -0.   0.3 -1.5  3.3  0.5 -1.5 -0.3 -0.4 -0.3  6.4 -0.1 -0.6 -0.2 -0.8 -0.3  6.3 -3.   0.6 -0.2 -0.1 -0.3 -0.2 -3.2 -6.2 -0.2 -0.5 -0.1  1.7 -0.2 -0.5  0.4  0.  -0.1 -0.1  0.4 -0.2 -1.9 -0.  -0.5 -0.1  1.4  1.9 -0.4 -0.  -0.2  0.   2.4 -0.7 -0.6 -0.8 -0.2 -0.1 -0.6 -0.  -0.1 -0.6  0.2 -0.2  0.1 -0.2 -0.2 -0.3 -0.1  2.6  1.  -0.1 -1.3 -0.1  1.7 -0.1 -0.3 -1.5 -0.2 -0.  -0.1 -0.6 -0.2 -1.1 -0.1 -0.  -0.2 -0.8  6.8 11.5  0.1  4.6 -0.  -0.1 -0.1 -0.  -0.6 -0.4  0.2  0.9 -0.1 -0.1 14.9 -0.3 -0.2 -0.5 -0.6  0.7  0.  -0.6 -2.  -0.5 -0.1 -0.2 -0.  -0.2 -0.  -0.7 -2.4  2.  -1.6 -0.7 -0.5 -0.1 -0.2 -1.1 -0.3  0.4 -0.2 -0.  -0.9  1.3  0.1 23.5 -0.1  5.9 -0.3 -0.1  5.2 -1.7 -0.9 -0.2 -0.9  0.8  1.3 -0.2  8.9 -0.3  8.8  1.1]
vy_50sample [[8 9 3 4 7 0 0 2 6 5]
 [4 7 6 1 3 9 5 2 0 8]
 [4 5 2 8 7 1 6 0 9 3]
 [4 6 0 2 7 8 5 3 9 1]
 [2 8 1 5 6 3 0 4 7 9]
 [8 5 0 0 9 7 1 6 2 3]
 [7 4 2 2 5 1 1 6 0 3]
 [3 4 1 7 0 6 9 5 2 8]
 [2 5 9 0 4 3 7 1 8 6]
 [8 7 3 2 1 0 4 6 5 9]]
vt_50sample [[8 9 3 4 7 0 1 2 6 5]
 [4 7 6 1 3 9 5 2 0 8]
 [4 5 2 8 7 1 6 0 9 3]
 [4 6 0 2 7 8 5 3 9 1]
 [2 8 1 5 6 3 0 4 7 9]
 [8 5 4 0 9 7 1 6 2 3]
 [7 4 2 8 5 9 1 6 3 0]
 [3 4 1 7 0 9 6 5 2 8]
 [2 9 5 0 4 3 7 1 8 6]
 [8 7 3 2 1 0 4 6 5 9]]
Epoch 53310: Training cost= 0.1881, Training acc= 0.8654, Validation cost= 0.2166, Validation acc= 0.8655
Epoch 53320: Training cost= 0.1961, Training acc= 0.8654, Validation cost= 0.2172, Validation acc= 0.8655
Epoch 53330: Training cost= 0.2493, Training acc= 0.8655, Validation cost= 0.2475, Validation acc= 0.8655
Epoch 53340: Training cost= 0.1895, Training acc= 0.8655, Validation cost= 0.1965, Validation acc= 0.8655
Epoch 53350: Training cost= 0.2308, Training acc= 0.8655, Validation cost= 0.2252, Validation acc= 0.8655
Epoch 53360: Training cost= 0.2323, Training acc= 0.8655, Validation cost= 0.2063, Validation acc= 0.8656
Epoch 53370: Training cost= 0.2183, Training acc= 0.8655, Validation cost= 0.1648, Validation acc= 0.8656
Epoch 53380: Training cost= 0.2908, Training acc= 0.8655, Validation cost= 0.2298, Validation acc= 0.8656
Epoch 53390: Training cost= 0.2267, Training acc= 0.8655, Validation cost= 0.2208, Validation acc= 0.8656
Epoch 53400: Training cost= 0.2212, Training acc= 0.8655, Validation cost= 0.2517, Validation acc= 0.8656
tm  [ 0.4 -0.1  4.3 10.5 -1.7 -0.3 -0.2 -0.  -0.  -0.4 -2.9 -0.2 -0.3 -0.5 -0.6 -1.3  0.1 -0.2  1.  -0.6 -1.3 -0.2 -0.6 -0.2 -1.   2.5 -0.5 -0.4 -0.3 -1.3 -0.3 -0.3  1.4  3.  -0.2 -0.2  0.1 -2.1 -1.6 -0.   1.3 -1.5 -0.2 -1.4 -0.1 -0.2  2.1  0.4  7.6 -3.  -0.3 -0.1  0.1 -2.9 -0.7  0.5 -0.6  5.9  1.5  3.5 -1.2 -0.4  0.4 -0.2 -0.4 -0.1  0.5 -0.1  2.2  0.2 -0.2  0.6 -0.2  0.8 -2.2  1.4 -0.2  1.3 -0.1 -0.1  7.6 -0.3 -0.2 -0.2 -1.9 -1.2  2.7 -0.2 -0.1 -0.4 -0.6 -0.2 -0.  -0.2 -0.7 -0.1  0.9 -2.5 -0.5 -0.2  1.1 -1.3 -0.6  0.6 -0.4 -0.  -0.9 -0.3 -0.9 -1.5 -0.3  0.1  0.  -0.5  2.   1.5  2.1 -0.1 -0.  -0.1 -0.2  4.8 -0.2 -0.3 -0.1 -0.8 -0.1 10.2  3.1  7.5 -0.4 -0.3 -0.5 -0.2  8.2 12.2 -0.2 -0.  -0.2 -0.5  1.  -0.3  0.9 -0.2 -0.2  0.  -0.  -0.2  3.1 -0.  -1.1  0.   3.1  0.2 -0.2 -0.1 -0.3 -0.2 -0.5 -0.6 -0.4 -0.2 -0.  -0.2 -0.2 -0.2 -0.1 -0.7 -0.3 -0.1 -0.1 -0.2 -0.3 -0.6 -0.1 -0.3 -1.3 -0.   2.2  0.1 -1.4  0.6 -0.2 -1.9 -0.1 -0.4  0.4 -0.  -0.2  3.6 -0.3 -0.  -0.1 -1.1 11.9 -1.1 -0.3 -0.7 -0.1 -0.3 -0.1 -0.2 -0.  -0.  -0.2 -0.6  0.6 -0.  -0.9 -0.3 -0.4 -0.2 -0.  -1.9 -0.2  0.3  5.6 -1.  -0.1 -0.5 -0.1 -0.1  0.7 -1.  -0.6 -0.1 -2.5 -0.6  2.2  3.   1.3  0.3 -0.3 -0.3 -0.5 -1.2 -0.3 -0.1  1.6  3.1  0.   0.7 -0.2 -0.2 -1.1 -1.4 -0.3 -0.4 -1.2 -0.2 -2.2 -0.1 -0.9 -0.1 10.1 -1.3]
ty_50sample [[3 6 9 5 0 7 8 4 1 2]
 [9 1 6 8 4 5 7 2 0 3]
 [0 9 8 5 7 3 2 1 6 4]
 [7 4 8 5 6 2 9 1 0 3]
 [1 2 4 9 5 0 8 6 3 7]
 [9 9 4 2 8 0 5 6 3 1]
 [4 0 3 1 2 5 7 9 8 6]
 [2 8 1 4 0 5 6 7 9 3]
 [3 6 9 2 1 5 8 0 7 4]
 [7 0 4 2 5 6 3 9 1 8]]
tt_50sample [[3 6 9 5 0 7 8 4 1 2]
 [9 1 6 8 4 5 7 2 0 3]
 [0 9 8 5 7 3 2 1 6 4]
 [7 4 8 5 6 2 9 1 0 3]
 [1 2 4 9 5 0 8 6 3 7]
 [9 7 4 2 8 0 5 6 3 1]
 [4 0 3 1 2 5 7 9 8 6]
 [2 8 1 4 0 5 6 7 9 3]
 [3 6 9 2 1 5 8 0 7 4]
 [7 0 4 2 5 6 3 9 1 8]]
vm  [-0.9  0.7 -2.2 -2.9 -1.5 -0.2 -0.  -0.1 -1.  -1.1  1.5 -0.  -0.2 -0.1  1.2  0.6  0.4 -0.2 -0.4  0.1 -1.8 -0.4 -0.5 -0.2 -1.1  2.6  0.  -0.1 -0.5  1.   2.  -0.5 -1.   3.2 -0.1 -0.1  1.6 -0.5 -0.1  0.1 -0.1 -4.7  0.8  1.8 -0.1  0.5 -0.6 -0.2 -0.3 -2.6 -0.3 -0.1  1.3  0.7 -1.4 -0.3 -0.4 -3.3 -0.8 -2.1  3.   0.6 -0.1 -0.3 -0.5  1.3 -0.4 -0.3  1.4  0.2  0.  -1.1 -0.1  2.5 -2.9 -0.3 -0.1  0.2 -0.2 -0.3  2.6 -0.2  0.6 -0.6 -0.4 -4.5  2.9 -0.  -0.2 -0.3 -0.6 -0.1 -0.   1.8 -0.8 -0.4  0.3 -2.3 -0.4 -0.4  2.4 -1.6 -0.   0.3 -0.1  3.  -1.2  1.4  1.1 -1.5 -0.4 -0.1  0.2 -0.3 -0.4  9.8 -0.2 -0.6 -0.2 -0.3 -0.1  3.9 -0.2  0.7 -0.   1.6 -0.2  2.2 -1.1 10.2  0.8 -0.3 -0.2  0.5  3.   4.7 -0.1  0.1  1.  -0.7  0.6 -0.6  0.1 -0.  -0.2 -0.2 -0.  -0.  -1.5  0.4  3.4  0.3 -0.2  2.7 -0.1 -0.3 -0.4  0.1  0.4 -0.4 -0.4 -0.4  0.8 -0.  -0.2  0.1  0.5 -0.3  0.9 -0.1  0.  -0.1  0.4 -0.1 -0.1  2.2  0.5 -0.4  0.4 -0.1  3.6  1.9 -0.2 -2.  -0.2 -0.7 -0.2 -0.4 -0.  -0.1 -0.1  0.  -0.1 -1.8 -0.3  3.5 -0.   1.4 -0.5 -0.1 -0.1  0.2 -0.2 -0.4 -0.1 -0.8 -0.2 -0.1  9.7 -0.  -0.   1.8 -0.7  6.3  0.8 -0.4 -1.2 -0.9 -0.5 -0.6 -0.2 -0.  -0.4 -0.8 -1.2  3.  -2.4 -0.5  3.  -0.6 -0.1 -0.4 -0.5  0.6 -0.6  3.1 -0.8 -0.1  0.5 18.9 -0.1  5.1 -0.1 -0.2  0.4 -0.5 -0.9 -0.1 -1.2 -0.2 -0.7 -0.2 -0.  -0.1  9.  -2. ]
vy_50sample [[3 4 1 6 7 9 8 2 0 5]
 [5 9 2 0 7 4 1 6 3 8]
 [7 4 2 5 6 9 8 1 0 3]
 [3 7 0 2 9 4 5 6 8 1]
 [6 9 7 1 5 0 3 4 8 2]
 [5 1 2 3 9 4 7 6 0 8]
 [8 4 6 0 5 1 9 2 3 7]
 [1 3 0 4 7 9 6 8 2 5]
 [7 1 8 4 0 9 2 3 6 5]
 [4 5 6 7 9 2 3 8 0 1]]
vt_50sample [[3 4 1 6 7 9 2 8 0 5]
 [5 9 2 0 7 4 1 3 6 8]
 [7 4 2 5 6 9 8 1 0 3]
 [7 3 0 2 9 4 5 6 8 1]
 [6 9 7 1 5 0 3 4 8 2]
 [1 5 2 3 9 4 7 6 0 8]
 [8 4 6 0 5 1 9 2 3 7]
 [1 3 0 4 9 7 6 8 2 5]
 [7 1 8 4 0 9 2 3 6 5]
 [4 5 6 7 9 2 3 8 0 1]]
Epoch 53410: Training cost= 0.2846, Training acc= 0.8655, Validation cost= 0.2159, Validation acc= 0.8656
Epoch 53420: Training cost= 0.2082, Training acc= 0.8655, Validation cost= 0.2013, Validation acc= 0.8656
Epoch 53430: Training cost= 0.2554, Training acc= 0.8655, Validation cost= 0.2113, Validation acc= 0.8656
Epoch 53440: Training cost= 0.2017, Training acc= 0.8655, Validation cost= 0.1999, Validation acc= 0.8656
Epoch 53450: Training cost= 0.2261, Training acc= 0.8656, Validation cost= 0.2379, Validation acc= 0.8656
Epoch 53460: Training cost= 0.3081, Training acc= 0.8656, Validation cost= 0.2459, Validation acc= 0.8656
Epoch 53470: Training cost= 0.2692, Training acc= 0.8656, Validation cost= 0.2385, Validation acc= 0.8656
Epoch 53480: Training cost= 0.2220, Training acc= 0.8656, Validation cost= 0.2225, Validation acc= 0.8657
Epoch 53490: Training cost= 0.2121, Training acc= 0.8656, Validation cost= 0.3132, Validation acc= 0.8657
Epoch 53500: Training cost= 0.2216, Training acc= 0.8656, Validation cost= 0.2185, Validation acc= 0.8657
tm  [-0.9  0.6 -4.7 -1.8 -1.5 -0.2  0.1 -0.2 -0.5 -0.7 -2.3 -0.3  0.3 -0.1 -2.1 -0.2 -0.  -0.2 -0.7  0.5 -1.6 -0.3  0.8 -0.1 -1.4  3.  -0.6  0.1 -0.6 -0.5  2.  -0.1 -0.8 -4.8 -0.1 -0.2  0.7 -1.6 -2.  -0.4 -0.3  4.   0.3 -0.3  0.3  0.9 -0.3  0.1  2.3  8.7 -0.3  0.1  0.5 -0.7 -0.5  1.8 -0.5 -0.5  2.  -0.8  0.9  1.5 -0.1 -0.3 -1.  -0.1 -0.1 -0.4 -0.   0.2 -0.2 -0.1 -0.3  1.5 -1.9  0.3 -0.1  1.4 -0.3 -0.  -0.6  0.1 -0.2  0.6 -0.4  5.9  4.2  0.1 -0.2 -0.1 -0.5 -0.  -0.  -0.9 -0.6 -0.   0.1 -2.8 -0.2 -0.2  1.9 -0.2 -0.4  0.2 -0.1  0.5 -0.9 -0.  -0.5 -1.2 -0.7 -0.1  0.3 -0.6  1.7  3.9 -0.4 -0.4  0.5 -0.7 -0.2  3.9 -0.2  0.4  0.  -2.7 -0.   4.8  2.  -0.9 -0.3 -0.4 -0.5 -0.3 16.1  7.6 -0.1  0.2 -0.2 -0.3  1.3 -0.6 -0.3 -0.2 -0.1  0.  -0.1 -0.   6.4 -0.1  1.2 -0.1  3.   1.1 -0.1 -0.1 -0.5 -0.7 -0.7 -0.7  1.4  1.7 -0.1 -0.   0.4 -0.4 -0.2 -0.3 -0.2 -0.  -0.3 -0.1 -0.1 -0.2 -0.1 -1.  -0.6 -0.1  1.8 -0.  -0.8  0.1 -0.1 -1.9 -0.2 -0.2 -0.1  1.7 -0.1  1.7 -0.1 -0.2 -0.1 -0.9  2.5 -0.7  0.5 -0.7 -0.2 -0.1 -0.1 -0.3 -0.1 -0.3  0.5 -1.3 -0.  -0.1  2.6  0.3 -0.4  0.4 -0.3  3.8 -0.6 -0.2 -0.  -1.1 -0.1 -0.5 -0.1  0.  -0.5 -1.3  5.6  2.8 -1.7 -0.3 -0.5  1.2  0.8 -0.7 -0.4  1.1  0.6  4.7 -0.5  0.4  5.5  0.9 -0.  -0.2  0.9 -0.2  4.2 -0.9 -0.6 -0.  -1.7 -0.8  0.6  0.  -1.  -0.1  1.4  5.9]
ty_50sample [[6 4 8 5 9 9 9 2 3 7]
 [1 0 8 2 3 6 9 7 5 4]
 [0 6 2 8 5 3 1 9 4 7]
 [2 4 8 5 7 0 3 6 1 9]
 [5 1 2 9 0 4 6 8 7 3]
 [9 5 1 4 8 8 3 0 0 2]
 [9 7 2 5 6 3 4 1 0 8]
 [6 5 8 1 4 2 3 7 0 9]
 [7 8 9 2 6 1 4 3 5 0]
 [6 1 4 0 0 8 2 7 5 9]]
tt_50sample [[6 4 8 5 1 0 9 2 3 7]
 [1 0 8 2 3 6 9 7 5 4]
 [0 6 2 8 5 3 1 9 4 7]
 [2 4 8 5 7 0 3 6 1 9]
 [5 1 2 9 0 4 6 8 7 3]
 [9 5 1 4 8 7 6 3 0 2]
 [9 7 2 5 6 3 1 4 0 8]
 [6 5 8 1 4 2 3 7 0 9]
 [7 8 9 2 6 1 4 3 5 0]
 [6 1 4 0 3 8 7 2 5 9]]
vm  [ 0.6 -0.1 -2.6 -5.5 -1.7 -0.1 -0.6 -0.3 -1.7  0.4 -1.6 -0.3  0.4 -0.2  7.1 -1.7  0.  -0.8 -0.3  1.9 -1.4 -0.2  1.9 -0.3 -1.3  1.1 -0.  -0.3 -1.8 -2.1 -0.1 -0.2 -0.6 -5.   0.  -0.   2.   2.8 -2.3 -0.4  1.2 -0.7 -0.1  1.6 -0.4 -0.  -2.8 -0.6  4.9  2.2 -0.2 -0.2 -0.3 13.6  2.8 -1.2 -0.8 -0.2  2.2  3.8  1.2 -0.4  0.9 -0.1 -0.4  0.9 -0.1 -0.2  0.2 -0.2 -0.4  7.3 -0.7 -0.6 -5.7 -0.7 -0.  -0.1 -0.1 -0.1 -8.3 -0.  -0.3 -0.1 -1.4 -0.9  8.2 -0.3  0.8 -0.1 -0.4 -0.1 -0.3  0.7 -0.7  0.7 -0.6 -4.   1.   0.9 -0.3 -1.7 -0.7 -0.  -0.1 -0.1 -3.1 -0.1 -0.2  3.3 -0.1 -0.2 -0.2 -0.5  2.7 -4.3 -0.4 -0.3 -0.4 -0.2 -0.1 -1.3 -0.3 -1.4 -0.3  8.7 -0.1 -2.7  2.1 17.2 -0.4 -0.6 -0.2 -0.3  3.2 -4.4 -0.1 -0.2  0.6 -0.2 -0.2 -1.1 -0.2 -0.5 -0.1 -0.4 -0.5 -0.1  5.7 -0.2  6.2 -0.1  4.1  1.2 -0.2 -0.2 -0.  -0.3 -0.  -0.3 -0.  -1.1 -0.1 -0.1 -0.5 -0.   0.4 -0.7 -0.4 -0.3 -0.1  0.1 -0.2  0.1 -0.2 -0.9 -0.1 -0.3  2.7 -0.3 -1.5 -0.1 -0.1 -2.2 -0.2  0.1 -0.5 -0.1 -0.1  5.8 -0.5  0.4 -0.3 -1.2  0.9 -0.7 -0.8 -0.8 -0.2 -0.1 -0.1 -0.1 -0.4 -0.4 -0.1 -4.2 -0.2 -0.1  4.8 -0.2 -0.4 -3.3 -0.5 -2.  -0.6 -0.2 -1.5 -1.1 -0.6 -0.2 -0.4 -0.3  0.2 -1.8 -1.7 -1.3 -1.1  0.9 -0.5  0.9 -0.8  1.  -0.4  1.2  3.   2.4 -0.  -0.7  3.3 -5.9 -0.1 -2.3 -0.2 -0.1 24.   6.1  0.1 -0.1 -1.2 -0.3 21.4 -0.3 -1.2 -0.3  4.9 -4. ]
vy_50sample [[0 8 3 4 5 2 6 7 1 9]
 [2 8 1 9 6 4 3 0 7 7]
 [5 0 7 2 4 3 9 8 6 1]
 [6 2 5 3 9 4 1 7 7 8]
 [8 5 3 0 0 2 4 9 6 1]
 [2 9 7 3 3 1 6 8 5 4]
 [7 1 2 4 5 0 6 3 8 9]
 [8 6 5 4 1 1 2 3 0 7]
 [7 3 4 0 9 2 5 8 1 6]
 [5 1 6 0 3 2 4 9 8 7]]
vt_50sample [[0 8 3 4 5 2 6 7 1 9]
 [2 8 1 9 6 4 0 3 5 7]
 [5 0 7 2 4 3 8 9 6 1]
 [6 2 5 3 9 4 1 0 7 8]
 [8 5 3 7 0 2 4 9 6 1]
 [2 9 7 0 3 1 6 8 5 4]
 [7 1 2 4 5 0 6 3 8 9]
 [8 6 5 4 9 1 2 3 0 7]
 [7 3 4 0 9 2 5 8 1 6]
 [5 1 6 0 3 2 4 9 8 7]]
Epoch 53510: Training cost= 0.2169, Training acc= 0.8656, Validation cost= 0.2433, Validation acc= 0.8657
Epoch 53520: Training cost= 0.2620, Training acc= 0.8656, Validation cost= 0.2233, Validation acc= 0.8657
Epoch 53530: Training cost= 0.2402, Training acc= 0.8656, Validation cost= 0.2492, Validation acc= 0.8657
Epoch 53540: Training cost= 0.2948, Training acc= 0.8656, Validation cost= 0.2585, Validation acc= 0.8657
Epoch 53550: Training cost= 0.2407, Training acc= 0.8656, Validation cost= 0.2474, Validation acc= 0.8657
Epoch 53560: Training cost= 0.2081, Training acc= 0.8656, Validation cost= 0.2486, Validation acc= 0.8657
Epoch 53570: Training cost= 0.2338, Training acc= 0.8656, Validation cost= 0.2401, Validation acc= 0.8657
Epoch 53580: Training cost= 0.2787, Training acc= 0.8656, Validation cost= 0.3386, Validation acc= 0.8657
Epoch 53590: Training cost= 0.2407, Training acc= 0.8657, Validation cost= 0.2423, Validation acc= 0.8657
Epoch 53600: Training cost= 0.1957, Training acc= 0.8657, Validation cost= 0.2275, Validation acc= 0.8657
tm  [-0.8 -0.1  6.2 -5.7 -1.7 -0.2  0.2 -0.2 -0.3 -0.6 -3.3 -0.2 -0.  -0.4 18.7 -0.7 -0.4 -0.2  1.4  0.1 -1.3 -0.1 -0.2 -0.1 -1.3  0.6 -0.5 -0.4 -0.5  4.5  2.2 -0.3 -0.7 13.2 -0.1  0.5 -0.  -2.  -5.6 -0.6 -0.1 -1.5 -0.3  0.9 -0.2 -0.  -2.4  1.3 -1.5 -1.1 -0.5 -0.1 -0.9  2.1 -1.  -2.1 -1.2 -1.9  2.9 -1.6  9.1  0.7 -0.9  0.3 -0.8  0.4 -0.1 -0.2  1.7  0.7 -0.2 -0.5 -0.5 -0.2 -5.1  0.9 -0.1  0.7 -0.   0.3 -3.6 -0.2 -0.2  0.8  2.3 -0.9 -0.2 -0.1 -0.1 -0.5 -0.7 -0.  -0.1 -0.3 -0.7 -0.1  1.  -3.8 -0.9 -0.3  2.5  6.2  0.7 -0.4 -0.1  0.4 -2.9 -0.1 -0.8  0.4 -0.3 -0.3 -0.2 -0.7  2.9  4.   0.7  0.3 -0.3 -0.2 -0.3 -0.4 -0.1  0.   0.4 23.2 -0.2  0.8  1.7 14.8 -0.4 -0.2 -0.4 -0.5 -2.3 10.5 -0.1  0.2 -0.9 -0.4  0.4 -0.3  0.  -0.2 -0.1 -0.2  0.2 -0.  -3.  -0.2  6.  -0.3 -1.  -0.4 -0.1 -0.2 -0.2 -0.6 -0.9 -1.1  2.6  0.8  0.3 -0.1  0.2 -0.  -0.5 -0.2 -0.2 -0.2 -0.3  0.8 -0.6 -0.5 -0.2  4.2 -0.4 -0.5  5.7 -0.   0.4  0.1 -0.4 -1.5 -0.3 -0.1 -0.5 -0.1 -0.6 -1.   0.  -0.2 -0.2 -0.6 -4.1 -0.7 -0.4 -0.7 -0.1 -0.   0.2 -0.2  0.4 -0.2 -0.3 -4.5 -0.1 -0.3  6.1 -0.2 -1.  -0.5 -0.3  6.9 -0.3  0.   0.3 -0.8 -0.  -0.8 -0.1  0.  -0.3 -0.5  3.1 -0.1 -1.1 -0.6 -0.  -0.  -0.5  0.3 -0.4  0.8  0.  -0.7 -0.3 -0.7  0.9 -0.8 -0.1 -0.4  0.  -0.2 11.8  7.7 -0.1 -0.1 -1.  -1.1  9.6 -0.3 -3.2 -0.   5.1 -3.5]
ty_50sample [[7 1 6 4 3 0 8 5 9 9]
 [5 6 0 7 1 8 3 4 9 2]
 [9 4 7 3 1 0 5 2 6 8]
 [3 6 8 9 1 7 0 4 5 2]
 [3 3 7 2 4 1 9 8 6 0]
 [5 2 9 7 4 8 1 0 3 6]
 [8 2 1 9 9 3 0 5 7 4]
 [7 9 0 6 5 1 3 4 8 2]
 [5 1 4 2 0 7 3 9 8 6]
 [3 9 6 7 2 5 8 1 4 0]]
tt_50sample [[7 1 6 4 3 0 8 5 9 2]
 [5 6 0 7 1 8 3 4 9 2]
 [9 4 7 3 1 0 5 2 6 8]
 [3 6 8 9 1 7 0 4 5 2]
 [3 5 7 2 4 1 9 8 6 0]
 [5 2 9 7 4 8 1 0 3 6]
 [2 8 1 9 6 3 0 5 7 4]
 [7 9 0 6 5 1 3 4 8 2]
 [5 1 4 2 0 7 3 9 8 6]
 [3 9 6 7 2 5 8 1 4 0]]
vm  [-0.7 -0.1 -2.7  6.4 -1.6 -0.3 -0.  -0.4 -0.9  0.8 -5.8 -0.  -0.1  0.7 -3.2 -2.1 -0.5 -0.4 -0.1 -1.7 -1.1 -0.5  0.3 -0.3 -0.6  0.2 -0.2 -0.1 -1.6 -2.5  0.5 -0.1 -0.2 -4.8 -0.3 -0.1  2.6  0.1 21.4 -0.5 -0.1 -2.2 -0.9  1.7 -0.1 -0.4  9.7 -0.1 -0.5  8.5 -0.2 -0.1 -0.3 -4.1  0.6  3.8 -0.4 -3.6  1.6  2.3 -0.9 -0.1 -0.9 -0.4 -0.7 -0.4 -0.  -0.2  2.6 -0.2  0.1  6.8 -0.3 -0.6  3.  -0.  -0.2 -1.  -0.1 -0.   3.3 -0.2 -0.3 -0.1 -0.5 -1.9  0.9 -0.2  0.1 -0.1  0.  -0.2 -0.  -0.6 -0.5 -0.5 -0.7 -1.  -0.4 -0.1 -0.1  0.4 -0.3 -0.4 -0.2 -0.4  0.3 -0.4 -1.3 -2.  -0.  -0.3 -0.2  0.6  6.1 -4.1  1.  -0.2 -0.2  0.7 -0.2  7.8 -0.2 -0.1 -0.  -3.9 -0.1 13.  -0.4 -2.6 -0.5  0.1  0.4 -0.7 -1.4 -5.8 -0.   0.2 -0.2 -0.3 -0.1 -0.5 -0.2 -0.5  0.1 -0.2 -0.3 -0.  -1.3 -0.2 -0.8 -0.3  1.6 -0.4 -0.2 -0.2  0.2 -0.7  0.8 -0.5  1.1 -1.1 -0.  -0.1 -0.  -0.2 -0.   0.1 -0.4 -0.1 -0.3  0.2 -0.2 -0.2 -0.   2.5  0.6  0.1 -1.8 -0.2  1.9 -0.3 -0.1 -1.1 -0.3  1.6 -0.3 -0.2  0.8  6.1 -0.1 -0.2 -0.3 -0.9  7.6  2.3 -0.2 -1.6 -0.1  0.1 -0.1 -0.1 -0.4 -0.1 -0.3  2.9 -0.2 -0.4 13.3 -0.3 -1.  -2.7 -0.7  2.9  1.  -0.2 -1.6 -0.7  0.5  1.  -0.2 -0.1  1.  -0.8 -0.7 -1.7 -1.5  0.8 -0.3 -0.5 -0.8 -1.  -0.1  0.1  1.6  2.6  1.  -0.   0.4 27.6 -0.1  7.3 -0.2 -0.3 -0.  -2.4  0.2  0.  -1.2 -0.3 -1.2 -0.3 12.  -0.4  3.4  9.3]
vy_50sample [[0 9 8 4 1 3 7 6 2 5]
 [0 6 9 4 5 2 8 7 3 1]
 [2 2 6 5 9 7 1 4 3 8]
 [7 2 8 6 0 5 9 9 3 4]
 [1 5 4 0 9 8 3 6 2 7]
 [7 5 6 2 1 9 3 0 4 8]
 [8 2 9 4 1 7 3 0 5 6]
 [2 5 0 8 7 3 4 1 6 9]
 [3 2 6 1 9 7 5 8 0 0]
 [8 2 4 9 9 1 3 6 5 7]]
vt_50sample [[0 9 8 4 1 3 7 2 6 5]
 [0 6 9 5 4 2 8 7 3 1]
 [0 2 6 5 9 7 1 4 3 8]
 [7 2 8 6 0 5 1 9 3 4]
 [1 5 4 0 9 8 3 6 2 7]
 [7 5 6 2 1 9 3 0 4 8]
 [8 2 9 4 1 7 3 0 5 6]
 [2 0 5 8 7 3 4 1 6 9]
 [3 2 6 1 9 7 5 8 0 4]
 [8 2 4 9 0 1 3 6 5 7]]
Epoch 53610: Training cost= 0.2629, Training acc= 0.8657, Validation cost= 0.2052, Validation acc= 0.8658
Epoch 53620: Training cost= 0.2310, Training acc= 0.8657, Validation cost= 0.2041, Validation acc= 0.8658
Epoch 53630: Training cost= 0.3025, Training acc= 0.8657, Validation cost= 0.2657, Validation acc= 0.8658
Epoch 53640: Training cost= 0.2380, Training acc= 0.8657, Validation cost= 0.3398, Validation acc= 0.8658
Epoch 53650: Training cost= 0.3017, Training acc= 0.8657, Validation cost= 0.2056, Validation acc= 0.8658
Epoch 53660: Training cost= 0.2597, Training acc= 0.8657, Validation cost= 0.2513, Validation acc= 0.8658
Epoch 53670: Training cost= 0.1755, Training acc= 0.8657, Validation cost= 0.2053, Validation acc= 0.8658
Epoch 53680: Training cost= 0.1966, Training acc= 0.8657, Validation cost= 0.2356, Validation acc= 0.8658
Epoch 53690: Training cost= 0.2466, Training acc= 0.8657, Validation cost= 0.2178, Validation acc= 0.8658
Epoch 53700: Training cost= 0.1841, Training acc= 0.8657, Validation cost= 0.1931, Validation acc= 0.8658
tm  [-0.5 -0.4  3.3  9.4 -1.5 -0.2 -0.2 -0.1  0.5 -0.2 -0.6  0.6 -0.4 -0.1 -0.7  2.1 -0.4  0.1  1.4 -1.1 -1.5 -0.2 -0.7 -0.3 -0.7 -0.1 -0.  -0.7  2.9 -0.5  0.7 -0.5  1.3  3.7  0.2 -0.2 -0.4 -2.  -3.  -0.4  3.2 -3.5 -0.9 -0.8  0.1  0.2  4.4 -0.8 -0.7 -3.  -0.3 -0.2 -0.6 -1.8 -2.1  0.8 -0.3 -1.4  3.7  1.4  4.1 -0.6 -0.4 -0.3  1.5 -1.4  0.2  0.8  3.2 -0.3 -0.1 -2.2 -0.2 -0.5 -2.9  0.1 -0.1 -0.1 -0.2 -0.4  9.9  0.1 -0.2 -0.1 -0.3 -2.8 -0.7 -0.2  0.3 -0.4 -0.3  0.2 -0.5 -0.3 -1.1 -0.1 -0.8 -2.5 -0.5  0.   0.6 -0.7 -0.7 -0.3 -0.1 -0.8 -1.6 -0.4 -0.1 -1.1 -0.2 -0.8 -0.2 -0.8 -0.2 14.9  3.7 -0.2 -0.   1.2 -0.5  3.1 -0.5 -0.2 -0.2 -1.  -0.3  7.6  1.7  8.2 -0.4  0.2  0.6  0.4 11.1 18.3 -0.4 -0.1 -0.8 -0.7 -0.2 -0.1  1.2 -0.2 -0.3 -0.4 -0.5 -0.3 -1.2  0.3 -1.2 -0.3 -0.8 -0.5  0.2 -0.2 -0.1 -0.6 -1.2 -0.5 -0.4 -0.5 -0.2  0.1 -0.2 -0.5 -0.5 -0.6 -0.1 -0.1 -0.2 -0.4 -0.2 -0.3 -0.5  2.9 -1.9 -0.4  2.6 -0.   0.4  0.6 -0.2 -2.3  0.3  0.9  0.8 -0.8 -0.1  0.9 -0.3 -0.5 -0.2 -1.2 -0.9 -1.  -0.4  0.3 -0.1 -0.3 -0.1 -0.1 -0.1  0.  -0.6 -0.7 -0.  -0.2  5.8 -0.5 -0.8  4.5 -0.6  1.5 -0.7  1.8  4.4 -0.9  1.2  1.5  0.2  0.5  0.5 -0.9 -0.2  4.7 -2.2 -1.3  2.4 -0.2  2.5  2.4  0.6  1.2 -2.1 -0.8  1.  -0.8 -0.  15.9 -0.3  4.  -0.2 -0.  -1.6 -1.3  1.3 -0.4 -0.9 -0.8 -2.8  0.  -1.6 -0.2  6.  -1.5]
ty_50sample [[6 3 1 9 7 8 4 2 5 0]
 [2 6 7 5 4 3 1 8 0 9]
 [8 7 3 1 6 9 0 4 2 5]
 [3 8 7 4 5 9 2 6 0 1]
 [4 3 8 5 0 1 9 6 7 2]
 [9 9 3 6 4 8 2 1 7 5]
 [0 5 4 8 3 6 9 2 7 1]
 [9 4 0 1 3 2 5 8 7 6]
 [4 3 1 7 8 6 0 2 5 9]
 [2 1 6 0 7 5 3 9 9 4]]
tt_50sample [[6 3 1 9 7 4 8 2 5 0]
 [2 6 7 5 4 3 8 1 0 9]
 [8 7 3 1 6 9 0 4 2 5]
 [3 8 7 4 5 9 2 6 0 1]
 [4 3 8 5 0 1 9 6 7 2]
 [0 9 3 6 4 8 1 2 7 5]
 [0 5 4 8 3 6 9 2 7 1]
 [9 4 0 1 3 2 5 8 7 6]
 [4 3 1 7 8 6 0 2 5 9]
 [2 1 6 0 7 5 3 9 8 4]]
vm  [-1.2  0.3 -3.6  1.3 -1.4  0.2 -0.5 -0.3 -1.8 -0.8 -3.9 -0.2 -0.1 -0.1 -2.8 -2.3 -0.5 -0.3 -0.3 -0.5 -1.3 -0.1  1.5 -0.1 -1.4  1.6 -0.4 -0.2 -2.3 -3.   0.4 -0.1 -0.2 -5.5 -0.1 -0.   6.1 -0.3  5.4 -0.4  3.9 -1.   0.8  1.2 -0.3  0.   2.  -0.3 -1.2  0.2 -0.2 -0.1 -0.1 -2.2  2.4  2.6 -1.1 -0.2 -0.4  2.7  2.1 -0.2  0.4 -0.1 -0.8  0.9 -0.2 -0.7  0.2  0.  -0.   8.9 -0.5 -0.1 -0.6 -0.7 -0.3 -0.9 -0.1  1.  -0.3 -0.3 -0.3  0.2  1.  -0.9 -0.4 -0.2 -0.  -0.1 -0.5 -0.1 -0.3  0.6 -0.3  1.2 -0.2 -1.9 -0.1  2.1  2.2 -1.8 -0.5 -0.1 -0.2 -0.2 -0.8 -0.1 -1.  -1.2 -0.8 -0.  -0.4 -0.   2.7 -4.3  0.6 -1.2 -0.5 -0.4  0.2  5.6 -0.1  0.7 -0.2 -3.5  0.   8.4 -0.1  2.8 -0.8 -0.2 -0.1 -0.5  7.6 -1.9 -0.1 -0.  -0.1 -0.3  0.7 -1.  -0.6 -0.4 -0.1 -0.2 -0.2 -0.1  5.3 -0.4 -0.2 -0.1  0.8 -0.4  0.  -0.1  1.7 -0.6  2.  -0.2 -0.3 -1.  -0.1 -0.1 -0.2 -0.4 -0.2 -0.2 -0.4  0.  -0.1  0.2 -0.1  0.3 -0.3 -1.2 -0.2 -0.3 -0.2 -0.3 -1.4  0.5 -0.1 -2.  -0.1 -0.  -0.3  2.4 -0.2  7.5 -0.2 -0.  -0.2 -1.1 -0.2  1.7 -0.5 -0.7 -0.1 -0.1 -0.  -0.1 -0.5 -0.2 -0.4 -1.2 -0.2  0.   3.4  0.5 -0.2 -3.2 -0.5  6.2 -0.2 -0.6 -1.1 -1.  -0.4  1.1 -0.2 -0.2  0.6 -1.4 -1.6 -1.3 -1.2  1.6 -0.4 -0.5 -0.3 -0.4 -0.3  1.3  5.2  2.4 -0.1 -0.   1.2  1.7  0.2 -0.3 -0.3 -0.1  3.7 -0.3 -0.5  1.9 -1.1 -0.2  0.1 -0.1  3.  -0.2  7.1 -0.2]
vy_50sample [[0 3 3 8 4 5 5 6 2 7]
 [3 0 4 6 9 2 5 1 7 8]
 [0 7 8 6 1 5 4 2 9 3]
 [2 9 5 8 7 3 0 0 6 1]
 [1 0 5 4 7 3 8 9 9 2]
 [5 0 6 7 3 1 4 8 9 2]
 [8 6 4 3 5 1 7 9 0 2]
 [9 3 3 7 5 6 2 8 0 4]
 [1 9 7 0 2 3 3 5 4 8]
 [1 6 8 4 5 3 9 2 7 0]]
vt_50sample [[0 1 3 8 4 5 9 6 2 7]
 [3 0 4 6 9 2 5 1 7 8]
 [0 7 8 6 1 5 4 2 9 3]
 [2 9 5 8 7 3 0 4 6 1]
 [1 0 5 7 4 3 8 9 2 6]
 [5 0 6 7 3 1 4 8 9 2]
 [8 6 4 3 5 1 7 0 9 2]
 [1 9 3 7 5 6 2 8 0 4]
 [1 9 7 0 2 6 3 5 4 8]
 [6 1 8 4 5 3 9 2 7 0]]
Epoch 53710: Training cost= 0.2348, Training acc= 0.8658, Validation cost= 0.2327, Validation acc= 0.8658
Epoch 53720: Training cost= 0.1897, Training acc= 0.8658, Validation cost= 0.2262, Validation acc= 0.8658
Epoch 53730: Training cost= 0.2559, Training acc= 0.8658, Validation cost= 0.2263, Validation acc= 0.8658
Epoch 53740: Training cost= 0.2298, Training acc= 0.8658, Validation cost= 0.2204, Validation acc= 0.8659
Epoch 53750: Training cost= 0.2599, Training acc= 0.8658, Validation cost= 0.1637, Validation acc= 0.8659
Epoch 53760: Training cost= 0.2422, Training acc= 0.8658, Validation cost= 0.2362, Validation acc= 0.8659
Epoch 53770: Training cost= 0.2016, Training acc= 0.8658, Validation cost= 0.2126, Validation acc= 0.8659
Epoch 53780: Training cost= 0.2223, Training acc= 0.8658, Validation cost= 0.2486, Validation acc= 0.8659
Epoch 53790: Training cost= 0.2205, Training acc= 0.8658, Validation cost= 0.2362, Validation acc= 0.8659
Epoch 53800: Training cost= 0.2496, Training acc= 0.8658, Validation cost= 0.2709, Validation acc= 0.8659
tm  [-0.1 -0.3 -1.6 12.5 -1.5 -0.1  0.1  0.  -1.   0.1  3.9 -0.4 -0.1  0.4 -3.2 -1.8 -0.4 -0.2 -0.6 -1.  -1.5 -0.2 -0.8 -0.4 -0.6  2.3  0.1 -0.7 -1.5 -2.7  0.8  0.   2.2 -0.4 -0.1 -0.3  2.8 -1.2 -0.5 -0.5  5.4 -0.9 -0.1 -0.3 -0.1 -0.2  6.2 -0.7  0.5 -4.2 -0.1 -0.  -0.1 -2.5  1.3  3.5 -0.4  3.4  0.4 -0.6 -0.6 -0.3  0.5 -0.3 -0.1 -0.8 -0.  -0.2 -0.1 -0.2 -0.2  5.3 -0.8 -1.  -1.7 -0.6 -0.2 -0.1 -0.  -0.2 19.4  1.4 -0.3 -0.5 -0.8 -1.1  0.6  0.1 -0.4 -0.3  1.3 -0.2 -0.   2.1 -0.6 -0.2 -0.1 -1.7  0.1 -0.2 -0.3 -2.1 -0.2 -0.1 -0.1 -0.4 -1.2  0.1  1.8 -1.2 -0.2 -0.4 -0.2 -0.3  3.5 -3.5  1.8 -0.4  0.1  0.8 -0.1  4.3 -0.6  0.8  0.4 -3.9 -0.   9.5  2.8  6.  -0.5 -0.1 -0.1  0.5 15.4 17.2 -0.3 -0.  -0.3 -0.7 -0.1 -0.5  0.4 -0.4 -0.2 -0.4 -0.5 -0.1  6.8 -0.2 -1.4 -0.1 -0.4 -0.   0.5 -0.2 -0.1  1.9 -0.4 -0.4 -0.2 -0.8 -0.2 -0.  -0.1 -0.3 -0.3 -0.6 -0.3  0.   0.6 -0.2  0.4  0.6 -0.  -1.5 -1.5 -0.4  0.9 -0.2 -1.5 -0.3 -0.2 -1.7 -0.  -0.6 -0.1 -0.1  0.4  6.7 -0.1 -0.2 -0.4 -1.1  7.6 -0.8 -0.4 -1.  -0.2  0.3 -0.1 -0.  -0.4  0.1 -0.2 -0.2  0.1  0.  -3.2  0.2 -0.3 -1.9 -0.2 -0.2 -0.8  1.   2.3 -1.2 -0.1  0.1  0.1 -0.1  0.3 -0.8 -0.9 -1.9 -2.1 -0.4 -0.2 -0.2  0.8  0.6  0.3 -0.3 -0.2  2.1  1.6 -0.4  1.5  4.5  0.3 -0.1 -0.1 -0.3 -3.8 -1.8 -0.6 -0.5 -0.9 -0.8 -5.1 -0.1 -0.2 -0.2  7.1 -1. ]
ty_50sample [[3 3 6 9 5 1 4 2 8 7]
 [7 5 6 9 0 4 8 1 3 2]
 [2 1 7 4 9 6 5 3 0 8]
 [0 1 9 8 5 2 3 6 7 4]
 [5 8 2 7 4 0 1 3 6 9]
 [9 7 6 8 1 2 4 0 5 3]
 [2 8 4 5 1 9 3 7 0 6]
 [9 5 7 1 3 2 4 6 0 8]
 [9 6 5 3 4 2 8 7 0 1]
 [5 0 1 2 2 7 4 6 9 8]]
tt_50sample [[3 0 6 9 5 1 4 2 8 7]
 [7 5 6 9 0 4 8 1 3 2]
 [2 1 7 4 9 6 5 3 0 8]
 [0 9 1 8 5 2 3 6 7 4]
 [5 8 2 7 4 0 1 3 6 9]
 [9 7 6 8 1 2 4 0 5 3]
 [2 8 4 5 1 9 3 7 0 6]
 [9 5 7 1 3 2 4 6 0 8]
 [9 6 5 3 4 2 8 0 7 1]
 [5 0 3 1 2 7 4 6 9 8]]
vm  [-0.9  0.2 -2.1 -3.3 -1.7  0.  -0.3 -0.1 -0.7 -0.8  9.1 -0.3  0.2 -0.3  5.7  4.2 -0.4 -0.2 -1.6  3.7 -1.9 -0.3 -0.9  0.5 -0.7  1.6 -0.1 -0.5 -1.1 -4.1  2.1 -0.  -0.2  7.1 -0.2 -0.1 -0.3  6.5 -0.2 -0.2  7.5 -1.8 -0.8  4.2 -0.3 -0.4 -2.5 -0.4  3.9 -3.1  0.  -0.1 -0.2  9.7 -0.6 -0.9 -0.5 -2.4 15.3 -3.   4.3 -0.7  1.3  0.4 -0.9 -0.2  0.  -0.4 -0.8 -0.1 -0.4 -0.5 -0.5  0.8 -4.5 -1.1 -0.2 -0.8  0.  -0.1  2.9  0.5 -0.1 -0.5 -0.4 -1.6  4.9 -0.1 -0.2 -0.6  2.1 -0.1 -0.  -1.7 -0.4 -0.1 -0.4 -4.1  1.3 -0.4  1.3 -1.5 -0.  -0.3 -0.  -0.3 -1.6  1.1  0.4  0.4 -1.2  1.  -0.1 -0.5  4.   6.3 -0.6  0.8 -0.2 -0.8 -0.4 -0.8 -0.1  2.  -0.2  6.9 -0.  -1.5 18.1  8.8 -0.1 -0.5 -0.3 -0.7 -1.   4.2 -0.   0.3  1.3 -0.4  0.4 -0.7 -0.7 -0.5 -0.1 -0.1 -0.1 -0.2  3.6  0.2  1.4  0.  -0.9 -1.  -0.  -0.3 -0.7 -0.4  4.4  1.6 -0.5 -1.1 -0.1  0.5  0.6  2.1 -0.1 -0.2  0.8 -0.1  0.2 -0.1 -0.4 -0.1 -0.2  0.1 -0.2 -0.5  0.7 -0.1 -0.5 -0.9 -0.2 -2.4 -0.2 -0.7 -0.3 -0.4 -0.5 10.3  0.   0.2  0.8 -1.4 -1.5 -6.4 -0.1 -1.  -0.2  0.3 -0.4 -0.1 -0.1 -0.9 -0.2 -2.5 -0.1 -0.3 -2.8  0.6 -0.3  1.8 -1.2  1.3 -2.5 -1.2 -2.5 -1.6 -1.1  1.4 -0.2  0.3 -0.6 -2.  -2.1 -0.8 -0.7  1.5 -0.1  1.2 -0.2 -1.2 -0.4 -0.6  0.1  4.4 -0.3 -0.2  7.4 -2.5 -0.2 -1.2  0.2 -0.3 -0.   1.4 -0.7  1.3 -1.4  1.4 -0.9 -0.  -0.2  0.9  3.4 -1.8]
vy_50sample [[4 3 2 1 5 0 7 6 9 8]
 [1 4 9 8 0 2 7 3 6 5]
 [4 4 7 3 0 8 6 5 2 1]
 [4 8 7 3 6 0 2 5 9 1]
 [2 5 9 3 4 8 0 7 6 1]
 [8 2 4 6 1 7 0 9 3 3]
 [1 0 4 5 2 6 9 7 3 8]
 [6 4 0 5 2 1 3 9 7 8]
 [3 4 6 2 1 9 7 0 8 5]
 [2 1 7 6 9 8 5 5 4 0]]
vt_50sample [[4 3 2 1 0 5 7 6 9 8]
 [1 4 9 8 0 2 7 3 6 5]
 [9 4 7 3 0 8 6 5 2 1]
 [4 8 7 3 6 0 2 5 9 1]
 [2 5 9 3 4 8 0 7 6 1]
 [8 2 4 6 1 7 0 9 5 3]
 [1 0 4 5 2 6 9 7 3 8]
 [6 4 0 5 2 1 3 9 7 8]
 [3 4 6 2 1 9 7 0 8 5]
 [2 1 7 6 9 8 3 5 4 0]]
Epoch 53810: Training cost= 0.2154, Training acc= 0.8658, Validation cost= 0.2151, Validation acc= 0.8659
Epoch 53820: Training cost= 0.2458, Training acc= 0.8658, Validation cost= 0.2814, Validation acc= 0.8659
Epoch 53830: Training cost= 0.2545, Training acc= 0.8659, Validation cost= 0.1939, Validation acc= 0.8659
Epoch 53840: Training cost= 0.2677, Training acc= 0.8659, Validation cost= 0.2422, Validation acc= 0.8659
Epoch 53850: Training cost= 0.2370, Training acc= 0.8659, Validation cost= 0.1904, Validation acc= 0.8659
Epoch 53860: Training cost= 0.2691, Training acc= 0.8659, Validation cost= 0.2671, Validation acc= 0.8660
Epoch 53870: Training cost= 0.2336, Training acc= 0.8659, Validation cost= 0.2338, Validation acc= 0.8660
Epoch 53880: Training cost= 0.2337, Training acc= 0.8659, Validation cost= 0.3119, Validation acc= 0.8660
Epoch 53890: Training cost= 0.2293, Training acc= 0.8659, Validation cost= 0.2451, Validation acc= 0.8660
Epoch 53900: Training cost= 0.1869, Training acc= 0.8659, Validation cost= 0.2483, Validation acc= 0.8660
tm  [-0.4 -0.2 -2.3 -2.2 -1.6 -0.2 -0.  -0.1 -0.4  1.9 -4.2 -0.3 -0.2  0.1  0.8 -1.9 -0.6 -0.5 -0.4  0.5 -1.3 -0.3 -0.  -0.3 -0.7  1.8 -0.1  0.1 -1.2 -4.2 -0.   0.1 -0.8 -3.8 -0.2 -0.3 -0.9 -1.4 -2.6 -0.4 -0.4 -1.4 -1.9 -0.6 -0.1 -0.2 -1.4 -0.3  3.4  8.9 -0.1 -0.1 -0.2  0.3  1.2 -0.5 -0.3 -2.6 15.5  3.   3.3 -0.3 -0.5 -0.1 -0.7 -0.3  0.  -0.1  0.5 -0.1 -0.1  3.4  0.2  0.2 -4.4 -1.  -0.2 -0.8 -0.2 -0.5 -3.9 -0.3  0.  -0.5 -0.7 -1.   1.7 -0.1 -0.2 -0.3  0.8 -0.1 -0.2 -2.3 -0.8 -0.3 -0.9 -4.2  0.1 -0.1 -0.7 -0.1 -0.4 -0.3  0.1 -0.  -1.5 -0.4 -1.3 -0.1 -0.3  0.1 -0.1 -0.6 11.7 -2.2 -1.   3.8 -0.1 -0.1 -0.3 -0.4 -0.1 -0.4 -0.2  1.3 -0.4  2.  12.9  1.6  0.9 -0.5 -0.3 -0.4 11.3 -0.2 -0.3 -0.1 -0.1 -0.   1.8 -0.9 -0.2  0.1  0.4 -0.  -0.3 -0.2 -0.2 -0.2  2.3  0.1  1.8  0.7 -0.1 -0.  -0.3 -0.2 -0.6  0.4 -0.4 -0.2 -0.1  0.  -0.  -0.3 -0.1  0.   0.3 -0.2 -0.1 -0.2 -0.2  0.7  0.2  2.2 -0.5 -0.1  2.4 -0.1  1.2 -0.5 -0.4 -2.5 -0.1  0.3 -0.3 -0.2  0.1 11.1 -0.2  0.3 -0.2 -1.  -1.1 -4.6 -0.2 -3.5 -0.2  0.5 -0.4 -0.1 -0.5 -0.2 -0.3 -2.5 -0.2 -0.3 11.  -0.4  0.1 -1.4 -1.2 -0.1 -1.3 -0.6  1.5 -1.4 -0.4  2.  -0.2 -0.   1.2 -2.1  4.2 -0.6 -2.   2.  -0.7  0.  -0.3 -0.9 -0.1  0.7  2.   2.3  0.3 -0.2  7.1  4.   0.3 -0.2  0.1 -0.1 12.4  1.2 -0.4 -0.1 -1.5 -0.2  9.4 -0.1 -1.5 -0.6  3.9  1. ]
ty_50sample [[0 8 6 4 1 3 9 7 5 5]
 [4 0 7 9 1 1 6 3 5 2]
 [7 6 0 4 1 2 8 9 5 3]
 [0 6 4 2 7 1 9 5 3 8]
 [4 5 9 6 6 8 7 3 1 0]
 [9 7 5 3 2 0 1 6 4 8]
 [4 3 2 0 6 9 7 1 8 5]
 [8 6 9 7 5 0 3 1 4 2]
 [3 7 6 0 8 4 2 9 5 1]
 [2 0 5 8 6 9 4 1 7 3]]
tt_50sample [[0 8 6 4 1 3 9 7 2 5]
 [4 0 7 9 8 1 6 3 5 2]
 [7 6 0 4 1 2 8 5 9 3]
 [0 6 4 7 2 1 9 5 3 8]
 [4 5 9 6 2 8 7 3 1 0]
 [9 7 5 3 2 0 1 6 4 8]
 [4 3 2 0 6 9 7 1 8 5]
 [8 6 9 7 5 0 3 1 4 2]
 [3 7 6 0 8 4 2 9 5 1]
 [2 0 5 8 6 9 4 1 7 3]]
vm  [ 0.9 -0.5 -0.6 -2.5 -1.3 -0.2 -0.1 -0.2 -1.1  2.2  3.3 -0.2 -0.3 -0.2  5.  -1.1 -0.3 -0.6 -0.1  0.3 -1.4 -0.1 -0.2 -0.5 -0.9  0.8 -0.1 -0.2 -1.3 -1.1 -0.5  0.1  0.6 -3.3 -0.1 -0.4  0.9 -0.3 -5.8 -0.5  1.8 -1.3 -0.6 -0.8 -0.4 -0.4 -1.5 -0.7  5.2  9.1 -0.3 -0.3 -0.8 14.3  1.6 -0.7 -0.6 -2.6  4.   4.4  0.2  0.8 -0.5 -0.1 -0.6 -0.1  0.  -0.   0.8 -0.  -0.4  6.2 -0.4 -0.5 -5.4 -0.9 -0.4  0.1  0.  -0.3 -5.7 -0.1 -0.2 -0.5 -1.9 -1.5  5.4 -0.2 -0.  -0.5 -0.1 -0.1 -0.4 -0.3 -0.3 -0.3 -0.5 -3.6 -0.3 -0.4 -0.8  3.7 -0.5 -0.3  0.2  0.  -2.5 -0.3  1.4 -0.5 -0.6 -0.2 -0.2 -0.3  6.1 -4.2  0.8  0.5 -0.1  0.3 -0.1 -0.2 -0.7 -1.1 -0.1  6.4 -0.2 -3.   0.1  3.9 -0.1 -0.5 -0.5  0.4 11.4  6.  -0.4  0.2 -0.3 -0.8 -0.7 -0.8 -0.1 -0.4 -0.3 -0.5 -0.4 -0.1 -1.4 -0.4  2.9  0.7  3.2 -0.1 -0.3 -0.2  0.1 -0.1 -1.  -0.3 -0.3 -0.2 -0.1 -0.2 -0.5 -0.4 -0.2 -0.7 -0.5 -0.4  0.1 -0.2 -0.3  0.1 -0.2  2.2 -1.3 -0.6  6.1 -0.2  2.  -0.1  0.1 -1.4 -0.  -0.2 -0.2 -0.1  0.6  2.3 -0.2  0.  -0.2 -0.9  2.8 -0.2 -0.7 -2.  -0.1 -0.  -0.2 -0.   0.3  0.1 -0.4 -3.2 -0.1 -0.4 12.4 -0.3 -0.3 -2.8 -0.9 -2.2 -0.6 -0.3  4.1 -0.8 -0.5  0.8 -0.3 -0.3  0.8 -1.3  2.9 -1.6 -0.5 -0.1 -0.3  1.9  0.9  2.6 -0.3 -0.1  0.2 -0.   1.5 -0.8  1.8  5.   0.2  0.5 -0.2 -0.2 16.8  3.4  0.7 -0.4 -1.1 -0.4 14.7 -0.4 -3.3 -0.3 -1.  -0.4]
vy_50sample [[0 6 2 8 4 7 3 9 1 5]
 [5 0 4 3 7 6 2 9 1 8]
 [4 9 5 1 7 2 0 8 3 6]
 [6 4 5 3 7 1 2 9 8 0]
 [9 5 1 6 3 7 4 8 2 0]
 [6 8 5 1 1 7 4 0 3 2]
 [4 7 1 6 8 5 0 2 3 9]
 [7 1 6 4 9 8 3 2 0 5]
 [7 8 1 3 2 9 6 5 0 4]
 [7 2 0 4 6 9 8 1 3 5]]
vt_50sample [[0 6 2 8 4 7 3 9 1 5]
 [5 0 4 3 7 6 2 9 1 8]
 [4 9 5 7 2 1 0 8 3 6]
 [6 4 5 3 7 1 2 9 8 0]
 [9 5 1 6 3 7 4 8 2 0]
 [6 8 5 1 9 7 4 0 3 2]
 [4 7 1 6 8 5 0 2 3 9]
 [7 1 6 4 9 8 3 2 5 0]
 [7 8 1 3 2 9 6 5 0 4]
 [7 2 0 4 6 9 8 1 3 5]]
Epoch 53910: Training cost= 0.2179, Training acc= 0.8659, Validation cost= 0.1897, Validation acc= 0.8660
Epoch 53920: Training cost= 0.2026, Training acc= 0.8659, Validation cost= 0.2331, Validation acc= 0.8660
Epoch 53930: Training cost= 0.2310, Training acc= 0.8659, Validation cost= 0.2156, Validation acc= 0.8660
Epoch 53940: Training cost= 0.2187, Training acc= 0.8659, Validation cost= 0.2368, Validation acc= 0.8660
Epoch 53950: Training cost= 0.2310, Training acc= 0.8659, Validation cost= 0.2418, Validation acc= 0.8660
Epoch 53960: Training cost= 0.2943, Training acc= 0.8660, Validation cost= 0.2174, Validation acc= 0.8660
Epoch 53970: Training cost= 0.2560, Training acc= 0.8660, Validation cost= 0.2225, Validation acc= 0.8660
Epoch 53980: Training cost= 0.2715, Training acc= 0.8660, Validation cost= 0.2156, Validation acc= 0.8660
Epoch 53990: Training cost= 0.2291, Training acc= 0.8660, Validation cost= 0.2337, Validation acc= 0.8661
Epoch 54000: Training cost= 0.2476, Training acc= 0.8660, Validation cost= 0.2063, Validation acc= 0.8661
tm  [ 1.8 -0.3 -2.1  5.9 -1.9 -0.3 -0.1 -0.1 -0.6  0.3 -4.4 -0.1 -0.2 -0.4 -3.1 -2.8 -0.1 -0.6  1.  -1.1 -0.6  0.1  1.5 -0.2 -0.6  2.  -0.2  0.5 -1.5 -1.4  1.6 -0.3 -0.1 -1.   0.4 -0.2  0.5 -0.5 22.8 -0.2 -0.2  2.7 -0.5  1.4 -0.  -0.1  9.8 -0.2  7.5  5.5 -0.2 -0.2  0.4 -5.3  1.6  3.6 -0.5 -0.7 -0.2 -1.4 -2.8 -0.2  0.7 -0.1 -0.3 -0.1 -0.1 -0.1  2.4 -0.  -0.2  6.1 -0.4 -0.5  4.4 -0.1 -0.3  1.4 -0.2 -0.1 15.8 -0.5 -0.2 -0.8 -2.1  3.   8.9 -0.2 -0.1 -0.1 -0.6 -0.1 -0.4 -0.4 -0.6 -0.5  0.2 -0.2 -0.7 -0.  -0.2  3.6 -0.7 -0.4 -0.2 -0.2  2.7 -0.2 -1.2 -2.2 -0.4 -0.1 -0.  -0.   4.9 -3.7  2.4 -0.1 -0.1  0.6 -0.   9.9 -0.3 -0.9 -0.3 -4.  -0.5 16.1 -0.4 -3.8 -0.  -0.  -0.6 -0.  -1.8 -2.8 -0.3  0.  -0.6 -0.1  0.6 -0.6  0.1  0.   0.1 -0.2 -0.3 -0.2  2.5 -0.2 -0.7  0.   3.7  0.6 -0.2 -0.3 -0.1  1.8  0.4 -0.4 -0.2 -1.7 -0.1 -0.1 -0.3  0.7 -0.1 -0.4 -0.3 -0.2 -0.  -0.2 -0.5 -0.1 -0.1 -0.5 -0.2 -0.4 -1.9 -0.1 -1.3 -0.  -0.2 -1.3 -0.   0.  -0.  -0.1  0.2  2.6 -0.2 -0.1 -0.2 -0.8 21.   1.8  0.4 -1.5  0.2 -0.   0.2  0.2 -0.1  1.  -0.3  7.8 -0.1 -0.4  2.1 -0.2 -0.4 -2.5 -0.  -2.8  3.1 -0.1 -1.7 -0.7 -0.2 -0.5 -0.1 -0.2 -0.3 -1.2 -0.5 -1.4 -2.3 -0.3 -0.3  0.9 -0.6 -1.   0.   0.9  1.3  1.8 -0.   0.6  0.3 17.6 -0.2  3.8 -0.2  0.3 -3.1 -2.6 -0.1 -0.3 -0.9 -0.  -4.2 -0.3 12.9 -0.2  4.7 13.4]
ty_50sample [[9 0 4 8 5 7 3 6 2 1]
 [5 6 9 0 2 1 3 8 4 7]
 [0 9 1 6 3 3 7 5 2 4]
 [2 6 1 3 4 9 7 0 8 5]
 [8 2 6 9 3 1 4 7 0 5]
 [5 2 2 4 7 6 3 3 0 8]
 [3 7 4 9 2 8 5 0 6 1]
 [4 4 3 9 9 2 0 1 7 8]
 [4 6 2 0 7 3 9 8 1 5]
 [1 6 7 4 0 8 2 9 5 3]]
tt_50sample [[9 0 4 8 5 7 3 6 2 1]
 [5 6 9 0 2 1 3 8 4 7]
 [0 9 1 6 3 8 7 5 2 4]
 [2 1 6 3 4 9 7 0 8 5]
 [8 2 9 6 3 1 4 7 0 5]
 [5 9 2 4 7 6 3 1 0 8]
 [3 7 4 9 8 2 5 0 6 1]
 [4 6 5 3 9 2 0 1 7 8]
 [4 6 2 0 7 3 9 8 1 5]
 [1 6 7 4 0 8 2 9 3 5]]
vm  [ 1.7 -0.4 -1.8  2.1 -0.6 -0.1 -0.  -0.2 -1.3  1.9  8.9 -0.3 -0.1 -0.3 -1.3 -0.  -0.9 -0.1 -1.  -0.2 -1.1 -0.   2.1 -0.  -1.  -0.3 -0.3 -1.  -0.6 -1.2 -0.2  0.4  3.  -3.4  0.3 -0.1  1.9  2.  -5.2 -0.6  6.7  8.2  1.1 -0.5 -0.3 -0.9 -0.3 -0.2  4.8  5.2 -0.5 -0.  -0.5 15.7 -1.1  0.8 -0.6  6.   0.6  3.9 -0.  -0.7 -0.7 -0.2  2.2 -1.5  1.3 -0.1 -0.6 -0.2 -0.5  2.5 -0.5 -0.9 -5.2 -1.8 -0.1 -0.6 -0.2 -0.5 -0.8  0.6 -0.3 -0.9 -2.2  4.1  4.5 -0.1 -0.  -0.5 -0.  -0.2 -0.6  2.  -0.9 -0.5 -0.7 -2.7 -0.1 -0.  -0.7 -0.8 -0.4 -0.  -0.2 -0.6 -3.5 -0.6 -0.4 -0.9 -0.8 -0.4 -0.  -0.4 -0.1 -1.6  3.5 -0.5 -0.4  0.2 -0.3  1.4 -0.6 -0.4 -0.3 -1.4 -0.1 -3.4  3.6  0.7 -0.4 -0.2 -0.3  2.9 17.1 14.3 -0.2  0.3 -1.2 -1.5 -0.9 -0.2 -0.3 -0.2 -0.2 -0.3 -0.1 -0.1  9.4 -0.2 -0.5 -0.   3.8 -0.3 -0.2 -0.3  1.3 -0.2 -0.7 -1.3 -1.1 -0.6 -0.1 -0.2 -0.2  1.   0.2 -1.  -0.4 -0.  -0.  -0.2 -0.2 -0.  -0.3 -2.5 -2.6 -0.6  4.6 -0.1 -3.  -0.4  1.3 -1.5  0.  -0.7  0.2  0.4 -0.   2.9 -0.3 -0.6 -0.3 -1.   5.  -1.1 -0.7 -0.2 -0.5 -0.1 -0.2 -0.4 -0.6  0.6 -0.4 -2.8 -0.3 -0.1 -4.3 -0.1 -0.7 -1.3 -0.6 -2.8 -0.8 -0.1  2.8 -1.3 -0.3 -0.  -0.2  0.3  1.4 -1.5  0.1 -1.1  0.2 -1.2 -0.5  1.3 -0.1  6.5 -0.5 -0.8 -1.1 -0.   0.7 -1.1  0.8 -6.5 -0.  -2.7 -0.  -0.   4.3  1.5 -0.  -0.4 -0.9  2.5  0.6 -0.2 -2.9 -0.3 -0.9  1.8]
vy_50sample [[5 2 6 0 8 9 4 3 1 7]
 [1 4 9 2 8 0 6 5 7 3]
 [8 9 4 0 1 6 3 7 2 5]
 [5 6 3 1 4 4 7 0 8 2]
 [2 4 8 1 5 9 7 3 6 0]
 [6 4 1 0 3 2 8 9 5 7]
 [3 8 5 9 7 1 6 2 4 0]
 [3 0 4 5 2 1 9 7 8 6]
 [7 8 0 5 6 1 4 2 9 3]
 [6 4 7 5 9 8 1 2 0 3]]
vt_50sample [[5 2 6 0 8 9 4 3 1 7]
 [1 4 9 2 8 0 5 6 7 3]
 [8 9 4 0 1 6 3 7 2 5]
 [5 6 3 1 9 4 7 0 8 2]
 [2 4 8 1 9 5 7 3 6 0]
 [6 4 1 0 3 8 2 9 5 7]
 [3 8 5 9 7 1 6 2 4 0]
 [3 0 4 5 2 1 9 7 8 6]
 [7 8 0 5 6 1 4 2 9 3]
 [6 4 7 5 9 8 1 2 0 3]]
Epoch 54010: Training cost= 0.2317, Training acc= 0.8660, Validation cost= 0.2421, Validation acc= 0.8661
Epoch 54020: Training cost= 0.2437, Training acc= 0.8660, Validation cost= 0.2008, Validation acc= 0.8661
Epoch 54030: Training cost= 0.2582, Training acc= 0.8660, Validation cost= 0.2548, Validation acc= 0.8661
Epoch 54040: Training cost= 0.2909, Training acc= 0.8660, Validation cost= 0.2271, Validation acc= 0.8661
Epoch 54050: Training cost= 0.2175, Training acc= 0.8660, Validation cost= 0.2489, Validation acc= 0.8661
Epoch 54060: Training cost= 0.2199, Training acc= 0.8660, Validation cost= 0.2127, Validation acc= 0.8661
Epoch 54070: Training cost= 0.2395, Training acc= 0.8660, Validation cost= 0.1774, Validation acc= 0.8661
Epoch 54080: Training cost= 0.1782, Training acc= 0.8660, Validation cost= 0.2268, Validation acc= 0.8661
Epoch 54090: Training cost= 0.2667, Training acc= 0.8661, Validation cost= 0.2405, Validation acc= 0.8661
Epoch 54100: Training cost= 0.2351, Training acc= 0.8661, Validation cost= 0.2283, Validation acc= 0.8661
tm  [-0.8 -0.2 -0.2 20.1 -0.9 -0.   0.  -0.3 -0.4  1.6 -3.7  0.3 -0.2 -0.3 -3.5 -1.  -0.5 -0.2  0.5 -1.5 -1.1 -0.2  1.8 -0.3 -0.3  0.5  0.3 -0.  -1.3 -4.2 -1.1 -0.3 -0.5 -5.7 -0.4 -0.   1.8 -0.4  6.8 -0.7  0.4 -2.7 -2.  -0.8 -0.5 -0.3  8.1 -0.4 -2.4  5.4 -0.2 -0.2 -0.7 -2.7 -0.6  3.8 -0.5 -1.1  7.4  6.   5.7 -0.6 -0.3 -0.  -0.3 -0.6 -0.1 -0.3 -0.4  0.5 -0.1  3.2 -0.5 -0.7 -1.  -0.9 -0.1 -0.9 -0.3  0.5  2.8 -0.3  0.3 -0.3  3.  -2.3 -3.  -0.2  0.  -0.4  0.6 -0.1 -0.4 -0.9 -0.5 -0.2 -0.8 -2.1 -0.6 -0.5 -0.6 -1.  -0.5 -0.8  1.1  0.  -0.6 -0.  -1.  -2.  -0.  -0.7 -0.3 -0.1  7.  -2.4 -0.5  0.4 -0.3 -0.3 -0.1  7.  -0.2  0.2 -0.1 -4.6 -0.3  9.7  3.1 -1.  -0.   0.4  0.  -0.  12.7 -0.8 -0.5  0.8 -0.1 -0.6 -0.8 -0.5 -0.6 -0.5 -0.2 -0.5 -0.4 -0.2 -0.2 -0.2 -2.4  0.3 -1.6 -1.2  0.2 -0.1 -0.1 -0.6 -0.8 -0.1 -0.  -0.9 -0.2 -0.1 -0.1  0.1 -0.3 -0.1 -0.5 -0.3 -0.  -0.3 -0.5 -0.2 -0.1  1.4 -0.7 -0.9 -0.7 -0.3  1.2 -0.4 -0.2 -1.6 -0.   0.8 -0.2 -0.3 -0.  11.1 -0.3  0.2 -0.2 -0.8 -1.8 -1.3 -0.4 -2.1 -0.2 -0.   0.   1.   0.2 -0.2 -0.4  1.5 -0.3 -0.4 11.9 -0.1 -0.9 -1.6 -1.1  7.5 -0.5 -0.5  4.6 -0.8 -0.2  1.7 -0.1 -0.  -0.4 -1.1  2.6 -1.2 -0.9  2.2 -0.5 -1.  -0.6 -0.2  0.6  0.7 -0.4  0.3  1.5 -0.7  0.5 23.2 -0.1  5.4 -0.3 -0.  -0.  -1.7  0.6  0.4 -0.8 -0.5 -0.9 -0.2  3.4  1.8  0.8  6.1]
ty_50sample [[1 0 9 8 6 3 2 4 7 5]
 [4 3 7 2 0 5 1 9 6 8]
 [6 4 3 2 8 5 9 7 0 1]
 [4 8 1 2 5 9 6 0 3 7]
 [9 0 6 4 5 1 1 8 3 2]
 [4 7 2 9 3 5 6 6 8 1]
 [6 9 5 7 8 2 3 0 1 4]
 [1 8 5 4 7 6 3 2 9 0]
 [7 2 5 1 1 6 8 8 4 3]
 [0 3 9 8 7 2 6 5 1 4]]
tt_50sample [[1 0 9 8 6 3 2 4 7 5]
 [4 3 7 2 0 5 1 9 6 8]
 [6 4 3 2 8 5 9 7 0 1]
 [4 8 1 2 5 9 6 0 3 7]
 [9 0 6 4 5 1 7 8 2 3]
 [4 7 9 2 5 3 0 6 8 1]
 [6 9 5 7 8 2 3 0 1 4]
 [1 8 5 4 7 6 3 2 9 0]
 [7 2 5 1 9 6 8 0 4 3]
 [0 3 9 8 7 2 6 5 1 4]]
vm  [-0.7  0.1 -1.  15.3 -1.4 -0.2  0.2 -0.1 -0.6  0.2 -0.6 -0.3  0.3 -0.3 -3.3 -1.  -0.  -0.3 -0.3 -0.9 -1.2 -0.  -0.  -0.  -0.7  3.3 -0.2 -0.  -1.1 -1.1 -0.1 -0.3 -0.1 -1.7 -0.1 -0.   1.5 -1.8  0.3 -0.1  0.7  4.4 -0.6 -1.1 -0.2 -0.1  7.  -0.2 -0.7  9.7 -0.1 -0.   0.3 -2.8  0.2  3.2 -0.4  1.7  0.5  2.7  0.7 -0.   0.7 -0.4 -0.2 -0.6 -0.1 -0.4 -0.3  0.1 -0.1  2.4 -0.4 -0.4  1.3 -0.1 -0.1  0.8 -0.2 -0.2 15.3  0.5  0.  -0.6 -0.1  6.2 -0.8 -0.1 -0.2 -0.1 -0.3 -0.1 -0.4 -0.6 -0.7 -0.2 -0.  -1.2 -0.2 -0.2 -0.1  3.7 -0.3 -0.1 -0.3 -0.2  0.6 -0.2 -0.1 -1.9 -0.7 -0.2 -0.  -0.4  4.6 -1.3 -0.1 -0.7  0.  -0.6 -0.1  7.2 -0.3  0.3 -0.1 -4.2 -0.2 10.1 -0.6 -4.6  0.1  0.2 -0.4 -0.  15.8 13.6 -0.2 -0.  -0.2 -0.5  0.5 -0.3 -0.2 -0.  -0.  -0.1 -0.  -0.1  4.5 -0.2 -1.8 -0.2 -0.8  1.3  0.1 -0.1 -0.7  1.3 -1.1 -0.4 -0.2 -0.1 -0.2 -0.1  0.5 -0.1 -0.4 -0.4 -0.3 -0.3 -0.  -0.2 -0.2 -0.1 -0.  -0.5 -0.8 -0.3 -0.2 -0.2 -0.7  0.2 -0.5 -1.3 -0.  -0.2 -0.3 -0.6 -0.2  2.9 -0.  -0.1 -0.2 -0.6  3.1  2.4 -0.  -1.5 -0.2 -0.1 -0.3  0.4 -0.3 -0.1  0.   3.5  0.1 -0.1  0.8  0.3  0.5 -0.9 -0.3  5.  -0.7 -0.1  5.4 -1.1 -0.2 -0.4 -0.  -0.1  0.7 -0.6  6.4 -0.5 -1.8 -0.2 -0.4 -0.5  2.2 -1.  -0.1  0.9 -0.   0.7 -0.2  0.3  3.  15.5 -0.2  3.2 -0.1 -0.2 -2.9 -2.4 -0.6 -0.6 -1.3 -0.2 -4.1 -0.1  1.  -0.  -0.3 17.3]
vy_50sample [[6 9 1 1 8 5 4 2 7 3]
 [6 4 9 5 3 7 1 8 0 2]
 [7 8 2 6 4 3 0 9 1 1]
 [1 4 5 8 6 3 0 2 7 9]
 [1 5 3 8 9 2 4 0 6 7]
 [4 1 6 8 3 0 5 9 9 7]
 [4 1 0 8 5 9 6 3 2 7]
 [1 5 9 6 7 4 0 2 8 3]
 [9 8 4 6 6 3 7 1 0 5]
 [7 0 4 1 6 9 8 3 5 2]]
vt_50sample [[6 9 1 0 5 8 4 2 7 3]
 [6 4 9 5 3 7 1 8 0 2]
 [7 8 2 4 6 3 0 9 5 1]
 [1 4 5 6 8 3 0 2 7 9]
 [1 5 3 8 9 2 4 0 6 7]
 [4 1 6 8 3 0 5 9 2 7]
 [4 1 0 8 5 9 6 3 2 7]
 [1 5 9 6 7 4 0 2 3 8]
 [9 8 4 2 6 3 7 1 5 0]
 [7 0 4 1 6 9 8 3 5 2]]
Epoch 54110: Training cost= 0.2849, Training acc= 0.8661, Validation cost= 0.2323, Validation acc= 0.8661
Epoch 54120: Training cost= 0.2301, Training acc= 0.8661, Validation cost= 0.2677, Validation acc= 0.8662
Epoch 54130: Training cost= 0.2420, Training acc= 0.8661, Validation cost= 0.2645, Validation acc= 0.8662
Epoch 54140: Training cost= 0.2344, Training acc= 0.8661, Validation cost= 0.2281, Validation acc= 0.8662
Epoch 54150: Training cost= 0.2442, Training acc= 0.8661, Validation cost= 0.2572, Validation acc= 0.8662
Epoch 54160: Training cost= 0.2145, Training acc= 0.8661, Validation cost= 0.2526, Validation acc= 0.8662
Epoch 54170: Training cost= 0.1959, Training acc= 0.8661, Validation cost= 0.2467, Validation acc= 0.8662
Epoch 54180: Training cost= 0.2401, Training acc= 0.8661, Validation cost= 0.1889, Validation acc= 0.8662
Epoch 54190: Training cost= 0.2614, Training acc= 0.8661, Validation cost= 0.2219, Validation acc= 0.8662
Epoch 54200: Training cost= 0.2245, Training acc= 0.8661, Validation cost= 0.2101, Validation acc= 0.8662
tm  [-0.4 -0.1  0.4 -0.1 -2.2 -0.  -0.1 -0.  -0.9 -0.   3.1 -0.3 -0.  -0.5  1.5 -2.3 -0.3 -0.5 -0.  -0.4 -1.1 -0.3  1.5 -0.2 -1.3  4.6 -0.3  0.6 -1.9  2.2  2.3 -0.2 -0.3 11.8 -0.1 -0.1  4.2 -0.5  9.1 -0.2  0.5  2.7  1.1  2.6 -0.3 -0.4  5.1 -0.6 -0.4  4.7 -0.4 -0.3  2.1 -2.   2.  -0.2 -0.6 -1.7 -1.7 -2.6 -0.6 -0.2 -0.  -0.3  1.   0.5  0.  -0.2  2.3 -0.2 -0.1  6.7 -0.3 -0.9 -0.3 -0.2 -0.1  1.  -0.   0.3 15.2  0.4 -0.3 -0.1 -0.4  4.8  3.8 -0.3  0.1  0.4 -0.2 -0.1 -0.1  0.7 -0.5  0.3 -0.3 -1.1 -0.3 -0.  -0.5  6.4 -0.2 -0.  -0.4  0.5 -0.6  0.5  1.5 -1.1 -0.2 -0.4  0.2  0.1  3.3 -4.6 -0.4 -0.9 -0.1 -0.1 -0.1  3.7 -0.2  1.7 -0.2  2.4  0.1  7.9 -2.3 -2.8  0.3 -0.  -0.5  0.4 -2.4  5.6 -0.3 -0.2 -0.1 -0.5  1.6 -1.   0.6 -0.  -0.1  0.4 -0.1  0.  -1.5 -0.3 -0.1 -0.1 -0.3  2.2 -0.   0.1 -0.8 -0.3 -0.2 -0.1  0.6 -0.8 -0.  -0.2  0.  -0.7 -0.4 -0.4 -0.3 -0.2  0.  -0.  -0.1 -0.2 -0.3  1.9 -0.4  0.2 -0.7 -0.1  0.1 -0.3 -0.2 -2.1 -0.2 -0.1 -0.1 -0.3  0.5 -0.6 -0.3 -0.2 -0.3 -1.1  6.4  9.2 -0.5 -1.1 -0.  -0.   0.3  0.3 -0.5  0.   0.9  1.6 -0.1 -0.  -0.3 -0.3 -0.1 -2.7 -0.3  3.8 -0.   0.6 -1.3 -1.  -0.2 -0.2 -0.2 -0.4 -0.6 -0.9  4.  -1.9 -1.6 -0.5 -0.4 -0.7 -0.4 -0.6 -0.2 -0.   1.7  0.8  1.1 -0.   0.8 13.2 -0.3  3.  -0.3  0.  -2.8 -2.1 -0.4 -0.2 -0.9 -0.6 -4.  -0.3  5.3 -0.1 -0.  11.2]
ty_50sample [[0 4 7 9 1 6 5 2 8 3]
 [1 8 5 6 2 3 7 4 9 0]
 [8 1 7 9 0 6 5 3 4 2]
 [0 5 3 1 6 7 4 8 9 2]
 [4 9 5 0 6 7 8 2 3 1]
 [9 8 5 1 7 6 2 3 0 4]
 [8 4 1 9 2 7 5 6 3 0]
 [3 1 2 8 9 6 5 0 4 7]
 [3 7 5 9 0 8 6 4 1 2]
 [7 9 0 5 2 6 4 3 8 8]]
tt_50sample [[0 4 7 9 1 6 5 2 8 3]
 [1 8 5 6 2 3 7 4 0 9]
 [8 1 7 9 0 6 5 3 4 2]
 [0 5 3 6 1 7 4 8 9 2]
 [4 9 5 0 6 7 8 2 3 1]
 [9 8 5 1 7 6 2 3 0 4]
 [8 4 9 1 2 7 5 6 3 0]
 [3 1 2 8 9 6 5 0 4 7]
 [7 3 5 9 0 8 6 4 1 2]
 [7 9 0 5 2 6 4 3 1 8]]
vm  [-0.8 -0.  -1.6  0.4 -1.6 -0.4 -0.2 -0.2 -0.3 -0.2 -1.4 -0.3 -0.3 -0.2 -1.1 -0.8 -0.1 -0.2 -0.5 -0.4 -1.6 -0.2  1.2 -0.  -1.   3.  -0.3 -0.3 -0.4 -0.1  2.  -0.1 -0.1  4.3 -0.2 -0.4 -0.2 -2.6 -3.   0.   1.5  4.9 -0.3 -0.6 -0.2 -0.1  1.9  0.1  1.9  4.3 -0.3  0.2  0.3 -2.9 -0.8  1.2 -0.6  0.4  2.5 -2.2 -0.  -0.4 -0.1 -0.4  0.1 -0.9 -0.2 -0.2  1.6  0.1 -0.1 -0.2 -0.3  0.5 -2.  -0.2 -0.1  0.2 -0.1  0.4 12.7  0.  -0.1 -0.3 -0.5  6.1  2.4  0.  -0.  -0.2 -0.5 -0.1 -0.1 -0.9 -0.7  0.2 -0.2 -2.7 -0.4 -0.5  1.3  4.3  0.2 -0.1 -0.3 -0.5 -0.9  0.2 -0.5 -1.4 -0.6 -0.  -0.1 -0.8  4.4  3.8  0.9 -0.1  0.2 -0.3 -0.2  4.5 -0.1  0.8 -0.1 -1.4  0.1 10.5  3.4 -2.2 -0.5 -0.1 -0.4 -0.4 14.5 20.7 -0.2  0.3 -0.3 -0.8  1.9 -0.5 -0.2  0.4 -0.1 -0.2 -0.2 -0.2  4.5 -0.2 -0.4 -0.1 -0.1 -0.1 -0.1 -0.  -0.6 -0.3 -0.8 -0.5 -0.2  0.5 -0.1 -0.1  0.4 -0.2 -0.5 -0.2 -0.  -0.1 -0.  -0.  -0.2 -0.3 -0.2 -0.5 -1.1  0.   2.6 -0.  -1.2 -0.  -0.5 -1.5 -0.1 -0.3 -0.1 -0.3 -0.2  0.3 -0.2 -0.4 -0.1 -1.1  4.3 -1.1  0.  -1.2 -0.  -0.2  0.2 -0.  -0.1 -0.3 -0.4 -0.7  0.2 -0.1 -2.7 -0.1 -0.4  0.9 -0.4  2.8 -0.7 -0.4  2.7 -1.3 -0.2 -0.5 -0.   0.2 -0.7 -1.1  5.  -0.3 -2.6 -0.6  2.4  0.5  3.4 -0.5 -0.5 -0.6 -0.6  1.4 -0.6  0.4  4.3  1.  -0.1 -0.2  0.1  0.1 -2.2 -1.4 -0.5 -0.4 -1.5 -0.1 -3.4 -0.1 -1.5 -0.2  3.6 10.4]
vy_50sample [[6 4 4 9 1 0 7 8 3 2]
 [1 6 8 8 7 3 2 0 4 9]
 [9 8 2 7 4 5 0 3 6 1]
 [4 4 1 3 9 5 8 7 6 2]
 [4 6 1 3 3 8 2 9 5 7]
 [3 6 4 1 8 2 0 7 9 5]
 [5 2 8 6 4 4 7 9 9 0]
 [1 2 8 5 7 0 3 9 4 6]
 [3 9 7 0 4 8 6 2 1 5]
 [5 4 0 3 9 6 1 2 8 7]]
vt_50sample [[6 5 4 9 1 0 7 8 3 2]
 [6 1 5 8 7 3 2 0 4 9]
 [9 8 2 7 4 5 0 3 6 1]
 [0 4 1 3 9 5 8 7 6 2]
 [4 6 1 3 0 8 2 9 5 7]
 [3 6 4 1 8 2 0 7 9 5]
 [5 2 8 6 4 1 7 3 9 0]
 [1 2 5 8 7 0 3 9 4 6]
 [3 9 7 0 4 8 6 2 1 5]
 [5 4 0 3 9 6 1 2 8 7]]
Epoch 54210: Training cost= 0.2403, Training acc= 0.8662, Validation cost= 0.2511, Validation acc= 0.8662
Epoch 54220: Training cost= 0.2538, Training acc= 0.8662, Validation cost= 0.2241, Validation acc= 0.8662
Epoch 54230: Training cost= 0.2140, Training acc= 0.8662, Validation cost= 0.2780, Validation acc= 0.8662
Epoch 54240: Training cost= 0.2348, Training acc= 0.8662, Validation cost= 0.1934, Validation acc= 0.8663
Epoch 54250: Training cost= 0.2138, Training acc= 0.8662, Validation cost= 0.2492, Validation acc= 0.8663
Epoch 54260: Training cost= 0.2416, Training acc= 0.8662, Validation cost= 0.1998, Validation acc= 0.8663
Epoch 54270: Training cost= 0.3191, Training acc= 0.8662, Validation cost= 0.2498, Validation acc= 0.8663
Epoch 54280: Training cost= 0.2773, Training acc= 0.8662, Validation cost= 0.2760, Validation acc= 0.8663
Epoch 54290: Training cost= 0.1776, Training acc= 0.8662, Validation cost= 0.2254, Validation acc= 0.8663
Epoch 54300: Training cost= 0.2030, Training acc= 0.8662, Validation cost= 0.2447, Validation acc= 0.8663
tm  [-1.   0.3 10.8 15.5 -1.7 -0.2 -0.1  0.5  0.6 -1.3 -5.3 -0.3 -0.2 -0.2  3.7 -0.5 -0.4 -0.3  0.5 -0.2 -1.1 -0.1  2.3 -0.2 -0.8  1.6 -0.5  0.2 -0.1 -0.  -0.7 -0.4 -0.4  7.4 -0.  -0.2 -0.2 -1.2  8.7 -0.2 -0.2 -1.  -0.1 -0.8 -0.2 -0.1  3.9 -0.1 -0.2  2.8 -0.3 -0.1  0.4 -3.8 -1.3 -0.4 -0.7  4.  -0.4  5.2 -0.1 -0.1 -0.3 -0.3 -1.2 -0.3  0.3 -0.3  1.3  0.5 -0.2 -1.3 -0.   0.2 -0.2  0.3 -0.   0.1 -0.1  0.2  4.9 -0.4 -0.1 -0.2 -0.3 -0.8 -1.8 -0.3 -0.1 -0.3 -0.3 -0.2 -0.1 -0.7 -0.7 -0.3  0.4 -1.9 -0.9  0.2  3.8  4.6  0.  -0.1 -0.5  0.   0.1 -0.1 -1.6 -1.7 -0.4 -0.1  0.1 -0.3  0.  10.8 -0.2 -0.2  0.7 -0.3 -0.2  6.6  0.6  1.1 -0.1  4.2 -0.2 13.  -0.4 -0.6 -0.4  0.4 -0.6 -0.3 -3.4 -1.1 -0.1 -0.2 -0.6 -0.3  2.3 -0.4 -0.3 -0.2 -0.1  0.6 -0.1 -0.1 -2.2 -0.3 -1.7 -0.   1.6  0.9  0.2 -0.  -0.2 -0.5  0.5 -0.2 -0.5 -0.4 -0.  -0.2 -0.3 -0.4 -0.3 -0.  -0.2 -0.2 -0.1 -0.3 -0.3 -0.3 -0.1  2.  -0.2 -0.1 -0.8  0.4 -0.5 -0.  -0.1 -1.9 -0.1 -0.3 -0.1  0.1  0.5  0.4 -0.3 -0.2 -0.3 -0.8  4.2  1.5  1.  -0.1  0.7 -0.1  0.4 -0.2 -0.3 -0.1 -0.3  1.8  0.4  0.8  6.2 -0.4 -0.7  3.2 -0.   4.8 -0.  -0.3  3.  -0.9 -0.2 -0.3 -0.2 -0.3 -0.2 -0.7 -0.2  3.9 -1.9  0.4  0.1 -0.1 -0.4 -1.  -0.1  1.2 -0.3 -2.4 -0.8  1.4  1.3 13.6 -0.1  3.3 -0.2 -0.2 -0.4 -1.7 -0.7 -0.2 -1.2 -0.1 -1.6 -0.2  5.  -0.3  8.2  4.2]
ty_50sample [[7 9 8 1 3 6 5 0 4 2]
 [0 9 6 1 2 4 7 5 8 3]
 [1 2 0 7 9 4 5 8 3 6]
 [1 1 6 6 0 7 4 3 5 8]
 [5 4 9 2 7 0 8 6 3 1]
 [6 0 1 3 7 5 2 9 4 8]
 [0 6 4 2 8 7 5 1 3 9]
 [9 7 8 3 0 0 5 1 6 4]
 [0 9 2 7 6 5 4 8 1 3]
 [4 7 0 8 3 5 9 2 6 1]]
tt_50sample [[7 9 8 1 3 6 5 0 4 2]
 [0 9 6 1 2 4 7 5 8 3]
 [1 2 0 7 9 4 5 8 3 6]
 [1 2 9 6 0 7 4 3 5 8]
 [5 4 9 2 7 0 8 6 3 1]
 [0 6 1 3 7 5 2 9 4 8]
 [0 6 4 2 8 7 5 1 3 9]
 [9 7 8 3 0 2 5 1 6 4]
 [0 9 2 7 6 5 4 8 1 3]
 [4 7 0 8 3 9 5 2 6 1]]
vm  [-0.8  0.7  4.6  4.6 -1.8 -0.   0.1 -0.   1.3 -1.  -2.2 -0.2 -0.2 -0.4  2.5 -0.6  0.9 -0.4  1.3  2.7 -1.1 -0.2  1.7  0.3 -1.   4.6  0.1  1.   0.2 -3.9 -0.6 -0.2 -1.3 -1.6 -0.1  0.2 -1.4 -0.8 -1.3  1.1 -0.8  1.7 -1.  -1.5 -0.2 -0.2 -2.  -0.3 -0.5  5.7 -0.3  0.1  1.4  1.9 -0.8 -0.4 -0.6 10.1 11.4  5.8  9.4 -0.1  2.  -0.4 -0.1  0.1 -0.1 -0.2  1.5 -0.1 -0.3 -1.2 -0.1  0.1 -4.6  1.7 -0.2  4.  -0.2 -0.6 -2.4 -0.2  0.  -0.7 -0.2  4.3 -3.4 -0.2 -0.1 -0.  -1.  -0.1 -0.3 -1.5 -1.4 -0.8  1.9 -4.2 -0.8 -0.4  1.9 -0.1 -0.6 -0.3 -0.2 -0.1 -1.1 -0.3 -0.5  1.4 -0.1 -0.1  0.1 -0.8  6.4  8.4 -0.4  2.5 -0.1 -0.1 -0.5 -0.9 -0.2 -0.   0.   3.1 -0.3  1.4 10.9  2.4  0.8 -0.5 -0.9 -0.1  6.  -0.1 -0.1  0.1 -0.1  0.1  1.2 -0.9 -0.   0.2  0.3 -0.   0.5 -0.   4.9 -0.  -0.6 -0.2 -0.8  3.7 -0.2  0.1 -1.   1.4 -0.4  0.1 -0.7 -0.7  0.7 -0.3 -0.1 -0.4 -0.1 -0.5 -0.1 -0.1 -0.1 -0.1 -0.4 -0.3 -0.1 -0.7 -0.5 -0.   1.5  0.2 -0.9 -0.2 -0.4 -3.2 -0.1 -0.2 -0.4 -0.6  0.6 10.4 -0.1 -0.4  0.2 -0.7 -4.  -4.   0.4 -1.9 -0.1 -0.1 -0.1 -0.1 -0.2 -0.1 -0.2 -1.  -0.1 -0.2  2.3 -0.2 -0.5  2.8  0.3  7.  -0.7 -0.4  4.9 -1.  -0.1 -1.2 -0.3 -0.1 -0.2 -1.2  2.8  3.3 -2.9 -0.  -0.6 -0.7 -0.5 -1.1 -0.2  0.8 -0.4 -1.2 -1.2 -0.1  3.6 -1.9 -0.1 -0.9  0.4 -0.1  8.6 -0.4 -0.6 -0.7 -1.5  2.3  5.2 -0.3 -0.7  0.4  5.9  0.1]
vy_50sample [[1 8 5 6 3 0 7 2 9 4]
 [1 0 8 9 6 7 2 4 5 3]
 [3 5 9 1 1 6 2 4 8 7]
 [8 4 3 9 6 0 5 2 7 1]
 [8 7 5 0 4 4 6 3 1 2]
 [8 2 6 7 9 0 4 5 1 3]
 [2 0 5 3 8 6 1 9 7 4]
 [5 2 8 3 7 9 0 6 1 1]
 [7 1 5 2 0 6 3 8 9 4]
 [9 6 1 7 2 8 4 5 3 3]]
vt_50sample [[1 8 5 6 3 0 7 2 9 4]
 [1 0 8 9 6 7 2 4 5 3]
 [3 5 9 1 0 6 4 2 8 7]
 [8 4 3 9 6 0 2 5 7 1]
 [8 7 5 4 0 9 6 3 1 2]
 [8 2 6 7 9 0 4 5 1 3]
 [2 0 3 5 8 6 1 9 7 4]
 [5 2 8 3 7 9 6 0 1 4]
 [7 1 5 2 0 6 3 8 9 4]
 [9 6 1 7 2 8 4 5 0 3]]
Epoch 54310: Training cost= 0.2541, Training acc= 0.8662, Validation cost= 0.2500, Validation acc= 0.8663
Epoch 54320: Training cost= 0.2765, Training acc= 0.8662, Validation cost= 0.2474, Validation acc= 0.8663
Epoch 54330: Training cost= 0.2175, Training acc= 0.8662, Validation cost= 0.2204, Validation acc= 0.8663
Epoch 54340: Training cost= 0.2006, Training acc= 0.8663, Validation cost= 0.2586, Validation acc= 0.8663
Epoch 54350: Training cost= 0.2740, Training acc= 0.8663, Validation cost= 0.2601, Validation acc= 0.8663
Epoch 54360: Training cost= 0.2311, Training acc= 0.8663, Validation cost= 0.2211, Validation acc= 0.8664
Epoch 54370: Training cost= 0.2333, Training acc= 0.8663, Validation cost= 0.2676, Validation acc= 0.8664
Epoch 54380: Training cost= 0.2672, Training acc= 0.8663, Validation cost= 0.1932, Validation acc= 0.8664
Epoch 54390: Training cost= 0.2183, Training acc= 0.8663, Validation cost= 0.2356, Validation acc= 0.8664
Epoch 54400: Training cost= 0.2080, Training acc= 0.8663, Validation cost= 0.2239, Validation acc= 0.8664
tm  [-1.4 -0.1  2.4  9.  -1.6  0.4 -0.6 -0.1 -0.5 -0.8  5.8 -0.2 -0.1 -0.2 -0.8  0.3 -0.3 -0.1  1.1  0.4 -1.7 -0.2 -0.1  0.3 -1.2  3.4 -0.4 -0.1 -1.3 -4.3 -0.8  0.  -0.1 -2.5  0.1 -0.3  3.8  4.8  1.2 -0.3  1.9 -0.7 -0.4 -0.5 -0.3  0.7 -0.7 -0.1 -1.3 -0.2 -0.1 -0.1 -0.3  5.8  0.5  0.5 -0.9  5.8  5.   5.7  4.5 -0.3 -0.1  0.8 -0.7  1.1 -0.1 -0.2 -0.  -0.2  0.6  3.6  0.6  1.8 -1.9 -0.2 -0.  -0.7 -0.  -0.2 -0.6 -0.6 -0.3  1.   2.8 -0.1 -2.6  0.  -0.1  0.2 -0.3  0.2 -0.  -0.9 -0.4  1.1  0.3 -3.4 -0.2  0.6  3.2 -0.8 -0.5  0.1 -0.2 -0.3 -1.2 -0.1  2.  -0.5 -0.8  0.3 -0.3 -0.1  3.3 -1.4  0.6 -0.9 -0.4 -0.2 -0.2  2.5  0.9  0.9 -0.1 -1.   0.8 -0.7  6.1  4.6 -0.7 -0.3 -0.1 -1.   4.8 -0.8 -0.  -0.3  0.6 -0.2 -0.2 -0.9 -0.7 -0.1 -0.1  0.4 -0.  -0.   3.1 -0.1 -1.1 -0.1 -0.1 -0.5  0.2 -0.  -0.1 -0.   2.4 -0.1  1.1 -0.7 -0.2 -0.  -0.2 -0.7 -0.1 -0.1 -0.1 -0.  -0.2 -0.1 -0.2 -0.3 -0.2 -0.6 -0.4 -0.   0.5 -0.1 -1.   0.4 -0.2 -2.2  0.  -0.3 -0.3  0.1 -0.3 11.4  0.   0.  -0.2 -0.9 -1.1 -1.9 -0.3 -1.1 -0.2 -0.1 -0.4 -0.1 -0.3 -0.9  0.4 -2.  -0.1  0.5  0.7 -0.1 -0.4 -1.3 -0.5  8.8 -1.2 -0.5  2.5 -1.1 -0.4 -0.1 -0.1 -0.1 -0.1 -1.2 -0.4 -0.3  1.3  3.5 -0.2 -0.2 -0.3 -0.7 -0.2  0.5  4.2 -0.4 -0.2  0.6  3.3 -0.7 -0.  -0.6 -0.1 -0.   4.3  0.3  0.1  2.  -1.4 -0.3  1.  -0.1  0.9 -0.3 -0.1 -0.5]
ty_50sample [[1 0 2 3 5 8 6 9 7 4]
 [5 2 1 3 8 7 0 9 6 4]
 [6 2 9 0 1 3 5 4 8 7]
 [3 6 7 4 1 8 9 9 2 5]
 [4 9 1 0 8 6 2 7 5 3]
 [8 7 2 9 3 5 1 6 0 4]
 [7 8 4 0 2 5 1 6 9 3]
 [7 4 9 8 3 5 2 0 1 6]
 [8 9 7 5 1 4 3 2 0 6]
 [5 7 4 4 0 8 1 9 9 2]]
tt_50sample [[1 0 2 3 5 8 6 9 7 4]
 [5 2 1 3 8 0 7 9 6 4]
 [6 2 9 0 1 3 5 4 8 7]
 [3 6 7 4 1 0 8 9 2 5]
 [4 9 1 0 8 6 2 7 5 3]
 [8 7 2 9 5 3 1 6 0 4]
 [7 8 4 0 2 5 1 6 9 3]
 [7 4 9 8 3 5 2 0 1 6]
 [8 9 7 5 1 4 3 2 0 6]
 [5 7 4 6 0 8 1 3 9 2]]
vm  [-0.2 -0.3 -4.4 -1.7 -0.9 -0.  -0.6 -0.4 -1.4 -0.4 -3.5 -0.2  0.2 -0.1 -2.5 -1.6 -0.  -0.1 -0.3 -0.8 -1.6 -0.1  0.9 -0.2 -1.5  0.5 -0.  -0.4 -1.9 -1.3 -0.3 -0.1  0.6 -8.7 -0.2 -0.1  4.2 -0.5 -2.  -0.6  0.3 -2.4  0.4 -0.4 -0.1  0.2  1.4 -0.4  1.8  4.6 -0.3 -0.4 -0.5  2.4  1.3  1.9 -0.9 -1.6 -0.9  4.7 -0.3  1.  -0.4 -0.1 -0.5  0.8 -0.3 -0.2 -0.1 -0.  -0.2  7.9 -0.1 -0.7 -2.5 -0.2  0.  -0.1 -0.1 -0.  -4.4 -0.5 -0.7  0.6 -1.2 -2.4  4.6  0.2 -0.1 -0.1 -0.9 -0.  -0.4  2.7 -0.2 -0.3 -0.  -2.5 -0.5 -0.2  1.5 -2.  -0.8 -0.3 -0.2 -0.6 -1.9 -0.5 -0.6 -1.3 -0.4 -0.3 -0.3 -0.1  1.2 -4.5  0.6 -1.  -0.2 -0.4 -0.   3.9 -0.5 -0.8 -0.2 -3.  -0.3 -0.  -1.5  7.8 -0.3 -0.2 -0.3 -0.3 15.7 -1.4 -0.3 -0.  -0.4  0.2 -0.8 -1.  -0.6 -0.5 -0.2 -0.4 -0.2 -0.2  4.2 -0.3  1.6  1.   3.  -0.5  0.  -0.2  0.2 -1.2 -0.7 -0.5 -0.  -0.3  0.5 -0.2 -0.6 -0.3 -0.2 -0.6 -0.6 -0.1 -0.  -0.  -0.3 -0.3 -0.  -0.7 -1.  -0.6  2.2 -0.1 -0.3 -0.2 -0.2 -1.3 -0.2  0.5 -0.2  1.3 -0.2  3.5 -0.1  0.1 -0.6 -0.7  4.5  5.8 -1.  -0.9 -0.2 -0.1 -0.2 -0.1  0.2 -0.1 -0.2 -2.5 -0.3 -0.1 11.6 -0.1 -0.6 -3.3 -0.6 -1.1  1.4 -0.4 -0.1 -0.4 -0.5 -0.5 -0.1 -0.4 -0.  -1.4 -0.5 -1.2 -0.6 -0.  -0.7  0.1 -0.4  1.6 -0.1  0.1  3.6  3.4  0.5 -0.4 -0.3  8.5 -0.1  1.2 -0.2 -0.3 13.6 -0.  -0.1  0.3 -1.  -0.7 10.7 -0.2 -1.3 -0.2  3.3 -1.3]
vy_50sample [[0 8 3 6 4 2 9 1 5 7]
 [9 2 7 4 3 0 5 8 1 6]
 [2 3 1 6 5 4 0 7 8 9]
 [8 2 6 5 0 9 1 7 7 3]
 [4 9 2 1 0 5 6 3 7 8]
 [7 2 4 0 9 1 6 5 3 8]
 [1 9 3 8 2 6 4 0 7 5]
 [1 7 8 6 5 9 2 3 0 4]
 [7 9 4 2 6 3 1 0 5 8]
 [6 3 9 4 7 1 5 0 8 2]]
vt_50sample [[0 8 6 3 4 2 9 1 5 7]
 [9 7 2 4 3 0 5 8 1 6]
 [2 3 1 6 5 4 0 7 8 9]
 [8 2 6 5 9 0 1 7 4 3]
 [4 9 2 1 5 0 6 3 7 8]
 [7 2 4 0 9 1 5 6 3 8]
 [1 9 3 8 2 6 4 0 7 5]
 [1 7 8 6 5 9 2 3 0 4]
 [7 9 4 2 6 3 1 0 5 8]
 [6 3 9 4 7 1 5 0 8 2]]
Epoch 54410: Training cost= 0.2227, Training acc= 0.8663, Validation cost= 0.2254, Validation acc= 0.8664
Epoch 54420: Training cost= 0.2241, Training acc= 0.8663, Validation cost= 0.2203, Validation acc= 0.8664
Epoch 54430: Training cost= 0.1623, Training acc= 0.8663, Validation cost= 0.1933, Validation acc= 0.8664
Epoch 54440: Training cost= 0.1785, Training acc= 0.8663, Validation cost= 0.1729, Validation acc= 0.8664
Epoch 54450: Training cost= 0.2393, Training acc= 0.8663, Validation cost= 0.2168, Validation acc= 0.8664
Epoch 54460: Training cost= 0.2770, Training acc= 0.8664, Validation cost= 0.2604, Validation acc= 0.8664
Epoch 54470: Training cost= 0.2410, Training acc= 0.8664, Validation cost= 0.2089, Validation acc= 0.8664
Epoch 54480: Training cost= 0.2458, Training acc= 0.8664, Validation cost= 0.2573, Validation acc= 0.8665
Epoch 54490: Training cost= 0.2113, Training acc= 0.8664, Validation cost= 0.2605, Validation acc= 0.8665
Epoch 54500: Training cost= 0.2216, Training acc= 0.8664, Validation cost= 0.2155, Validation acc= 0.8665
tm  [ 0.1 -0.3  7.9 17.6 -1.4 -0.5 -0.1 -0.3 -0.7 -0.2  7.7 -0.  -0.3 -0.2 -0.3 -0.8 -0.2 -0.3 -0.2 -1.1 -1.  -0.2 -0.6 -0.2 -0.5  0.8  0.7 -0.2 -1.1 -2.2  0.9 -0.2 -0.3 14.7 -0.2 -0.2  0.7  4.5 20.7 -0.5  1.5  5.7  0.3  0.  -0.5  0.1  6.9 -0.2  4.4 -2.7 -0.1 -0.2 -0.1 -1.8 -0.  -0.  -0.5 10.3  1.7 -0.5 -1.  -0.5 -0.3 -0.2  2.  -0.6 -0.5 -0.1  2.7 -0.2 -0.4  3.8 -0.3 -0.3 -0.6 -0.8 -0.3 -0.4 -0.3  0.3 25.2 -0.2 -0.4 -0.2 -1.3  3.7  0.2 -0.1 -0.5 -0.3 -0.4 -0.2 -0.3 -0.3 -0.4 -1.2 -0.2 -1.6 -0.5 -0.3  0.4  3.2 -0.2 -0.2  0.1 -0.  -0.5 -0.2  0.8 -1.7 -0.2 -0.1 -0.3 -0.3  1.7 -1.9 -0.  -0.2 -0.5 -0.3 -0.2  5.8 -0.1  1.5 -0.2 -0.4 -0.3  6.7  6.1 -1.1 -0.5 -0.3 -0.2 -0.4 -5.8  1.2 -0.  -0.  -0.4 -0.6 -0.3 -0.2 -0.3 -0.3 -0.3 -0.4 -0.2 -0.1  4.9 -0.3 -2.1  0.1 -0.6 -0.5 -0.  -0.4  0.3 -0.3  2.2 -0.3 -0.1 -1.5 -0.2 -0.3 -0.1  0.4 -0.4 -0.3 -0.3 -0.  -0.2 -0.1 -0.2 -0.3 -0.3 -0.8  1.7 -0.8 -1.8 -0.1 -2.3 -0.3 -0.1 -1.2  0.4 -0.1 -0.1 -0.4 -0.   5.9  0.6 -0.  -0.3 -0.7  9.7 -1.7 -0.3 -0.4 -0.2 -0.1 -0.4 -0.1  0.1 -0.2 -0.1  0.5 -0.  -0.3 -6.9 -0.  -0.6 -1.6 -1.1 -1.3 -0.5 -0.4 -0.5 -1.3 -0.3 -0.1 -0.1 -0.2 -0.1 -0.5 -1.5 -1.4 -1.2 -0.1 -0.9  1.  -0.6 -0.7 -0.1 -1.1  0.  -1.7  0.3  0.2  1.8 -1.3 -0.1 -1.  -0.2 -0.1 -5.1 -1.8 -0.5 -0.2 -1.1 -0.3 -6.3 -0.3 12.   0.2  2.8  5.3]
ty_50sample [[5 9 0 7 3 2 1 4 6 6]
 [3 1 5 9 6 7 2 4 0 0]
 [4 8 6 9 0 1 3 5 7 2]
 [0 2 3 4 9 5 7 6 1 8]
 [0 0 2 4 8 1 9 3 7 5]
 [3 1 9 7 8 0 6 2 5 4]
 [8 1 9 5 6 3 0 4 2 7]
 [8 1 6 3 4 7 5 9 2 9]
 [1 2 5 0 8 3 7 9 6 4]
 [3 4 1 5 9 2 7 6 6 0]]
tt_50sample [[5 9 0 7 3 2 1 4 6 8]
 [3 1 5 6 9 7 2 4 0 8]
 [4 8 6 9 0 1 3 5 7 2]
 [0 2 3 4 9 5 7 6 1 8]
 [0 6 2 4 8 1 9 3 7 5]
 [3 1 9 8 7 0 6 2 5 4]
 [8 9 1 5 6 3 0 4 2 7]
 [8 1 6 3 4 7 5 9 0 2]
 [1 2 5 0 8 3 7 9 6 4]
 [3 4 1 5 9 2 7 6 8 0]]
vm  [-0.5 -0.  -1.2 -1.9 -0.9 -0.2 -0.1 -0.  -0.4 -1.  12.  -0.1 -0.1  0.   1.3  4.9  0.2 -0.1 -0.1 -0.2 -1.6  0.1 -0.7 -0.2 -0.9  1.4 -0.3 -0.4 -0.  -1.5  1.1 -0.3 -0.1  6.8 -0.2 -0.4  1.6  3.7 -2.  -0.3 -0.1 -4.9 -0.6 -0.5 -0.2 -0.4 -0.7 -0.5  1.4 -4.6 -0.2 -0.2 -0.1 12.4 -1.4 -0.2 -0.4 -2.4  4.4 -2.5  1.1 -0.4 -0.1 -0.1 -0.1 -0.6 -0.1 -0.1 -0.4 -0.1 -0.3 -1.1 -0.2 -0.  -3.9 -0.  -0.2 -0.3 -0.  -0.   8.2 -0.3 -0.1 -0.6 -1.  -4.4  2.6 -0.1 -0.2 -0.4 -0.5 -0.1  0.3  1.1 -0.6 -0.  -0.4 -2.9 -0.3 -0.2  3.2 -1.8 -0.5  0.  -0.3 -0.1 -2.4  0.2 -0.3 -1.1  0.2 -0.1 -0.2 -0.6 -0.1  8.5  0.5 -0.4  0.3  1.  -0.3  1.7 -0.1  0.9 -0.1  1.6 -0.2 -2.4  3.7 13.3  0.2 -0.1  0.8  0.6  7.  13.5  0.2  0.2 -0.  -0.3 -0.6 -0.2 -0.5 -0.  -0.1 -0.2 -0.2 -0.  -1.4 -0.1  1.7 -0.1 -0.1 -0.3 -0.4 -0.1 -0.1 -0.2 -0.4 -0.4 -0.2 -0.5  0.4 -0.2 -0.2 -0.1 -0.3 -0.  -0.3 -0.1 -0.1 -0.2 -0.2 -0.4 -0.2  2.7 -0.6 -0.2  1.8 -0.1  2.6 -0.3 -0.  -1.9 -0.3 -0.4  0.1 -0.5 -0.3  5.  -0.1 -0.  -0.4 -1.5  0.8 -1.5 -0.4  0.3  0.  -0.1 -0.  -0.2 -0.4 -0.3 -0.1 -2.1  0.  -0.3  5.  -0.2 -0.3  2.  -0.5  0.2 -0.   0.7  1.4 -1.2 -0.3  0.1 -0.  -0.1 -0.3 -1.1 -1.1  0.2  0.  -0.3  2.  -0.1 -0.2  2.  -0.1  1.2 -0.9  1.9 -0.3 -0.4 -0.1 13.4 -0.1  2.9 -0.3 -0.1 -1.3 -0.3 -0.2 -0.6 -1.2 -0.3 -2.2  0.1 -1.2  0.1  1.3 -3. ]
vy_50sample [[3 2 6 4 1 1 9 0 8 5]
 [9 8 5 5 7 3 1 2 0 6]
 [7 9 3 6 2 1 8 0 4 5]
 [2 3 1 9 0 5 4 8 6 7]
 [1 7 3 8 2 5 6 4 9 0]
 [3 7 6 0 9 5 2 8 1 4]
 [3 1 5 5 8 7 6 2 4 0]
 [7 1 0 9 6 4 8 2 5 3]
 [6 7 2 8 1 0 5 4 9 3]
 [8 9 5 6 4 2 3 0 1 7]]
vt_50sample [[3 2 6 4 1 7 9 0 8 5]
 [9 8 5 4 7 3 1 2 6 0]
 [7 9 3 6 2 1 8 0 4 5]
 [2 3 1 9 0 5 4 8 6 7]
 [1 7 8 3 2 5 6 4 9 0]
 [3 7 6 0 9 5 2 8 1 4]
 [3 1 5 9 8 7 6 2 0 4]
 [7 1 0 9 6 4 8 5 2 3]
 [6 7 2 8 1 5 0 4 9 3]
 [8 9 5 6 4 2 3 0 1 7]]
Epoch 54510: Training cost= 0.2835, Training acc= 0.8664, Validation cost= 0.2823, Validation acc= 0.8665
Epoch 54520: Training cost= 0.2289, Training acc= 0.8664, Validation cost= 0.2651, Validation acc= 0.8665
Epoch 54530: Training cost= 0.2058, Training acc= 0.8664, Validation cost= 0.2657, Validation acc= 0.8665
Epoch 54540: Training cost= 0.1979, Training acc= 0.8664, Validation cost= 0.1919, Validation acc= 0.8665
Epoch 54550: Training cost= 0.2046, Training acc= 0.8664, Validation cost= 0.2106, Validation acc= 0.8665
Epoch 54560: Training cost= 0.2685, Training acc= 0.8664, Validation cost= 0.2553, Validation acc= 0.8665
Epoch 54570: Training cost= 0.2343, Training acc= 0.8664, Validation cost= 0.2125, Validation acc= 0.8665
Epoch 54580: Training cost= 0.2916, Training acc= 0.8664, Validation cost= 0.2687, Validation acc= 0.8665
Epoch 54590: Training cost= 0.2810, Training acc= 0.8665, Validation cost= 0.2315, Validation acc= 0.8665
Epoch 54600: Training cost= 0.2744, Training acc= 0.8665, Validation cost= 0.2392, Validation acc= 0.8665
tm  [-1.  -0.3 -3.1 -2.9 -1.4  0.4 -0.3 -0.1 -0.1 -0.8  8.9  0.  -0.1 -0.2 -0.3  3.7  0.4 -0.2 -0.4 -0.7 -1.2 -0.1  1.7 -0.3 -1.2  1.5 -0.2 -0.3  0.1  0.7  2.3 -0.4 -0.1  7.1 -0.2  0.4  1.   4.3  6.1 -0.5  2.6  3.6 -0.3  3.5 -0.1 -0.3  1.7 -0.2 -1.3  6.2 -0.4 -0.1  0.2  4.2 -1.7  0.4 -0.9 -2.6  0.3 -4.4  2.6 -0.3 -0.1 -0.3  0.3 -0.6 -0.1 -0.1 -0.2 -0.   0.4 -1.3  0.6  0.4 -2.4  1.  -0.1  0.2 -0.1 -0.4 13.  -0.1 -0.1 -0.5 -0.3  5.1  2.6 -0.1 -0.1 -0.6 -0.8 -0.1  1.1 -0.1 -0.6  0.3 -0.3 -2.2 -0.3 -0.4  1.2  5.7 -0.2 -0.1 -0.3 -0.  -1.1  1.3  0.1 -1.3 -0.4 -0.2 -0.1 -0.6 -0.4 11.   2.3 -0.6 -0.3 -0.  -0.1  4.  -0.2 -0.1  0.3 -0.4  0.1 -0.4 -0.  -2.9 -0.4  0.5 -0.2  0.6 -1.2  6.1 -0.3 -0.1 -0.2 -0.5 -0.3 -0.3 -0.3 -0.1 -0.1 -0.1  0.3 -0.2  0.1 -0.2  2.9  0.1 -1.3 -0.4 -0.2 -0.1 -0.6 -0.4  2.  -0.7  0.  -1.1  0.  -0.3 -0.  -0.4 -0.6 -0.3  0.4 -0.1 -0.1 -0.2 -0.3 -0.2 -0.1  0.3 -1.   1.2 -0.5 -0.1 -0.7  0.9 -0.2 -1.7 -0.2  0.7 -0.2 -0.3  0.2  0.  -0.3 -0.3 -0.2 -1.2 -0.6  0.   0.1  0.9 -0.1 -0.2 -0.1 -0.2 -0.4 -0.1 -0.  -0.2 -0.  -0.2 -1.1 -0.4 -0.   1.5 -0.6  7.4  1.  -0.4 -2.3 -1.  -0.2 -0.4 -0.1 -0.1 -0.8 -1.   2.2  2.3 -0.6 -0.7  0.7 -0.6 -0.3 -0.2 -0.1 -0.3 -0.6  5.3 -0.8 -0.4 -0.1  6.3 -0.1  1.1 -0.1  0.3 -2.4 -1.3 -0.3  0.3 -1.2 -0.1 -3.4 -0.   3.1 -0.2 -1.8 11.7]
ty_50sample [[4 1 2 9 7 5 6 8 0 3]
 [7 9 1 2 0 8 6 5 4 3]
 [0 0 6 5 8 7 1 3 2 4]
 [9 6 4 7 8 8 3 5 2 1]
 [3 2 8 0 6 4 9 5 7 1]
 [9 5 0 4 7 1 3 6 8 2]
 [2 1 3 5 0 9 6 8 4 7]
 [4 1 6 5 7 2 9 0 8 3]
 [9 2 8 4 1 7 5 6 0 3]
 [0 5 2 7 8 9 3 3 4 1]]
tt_50sample [[4 1 2 9 7 5 6 8 0 3]
 [7 9 1 2 0 8 6 5 4 3]
 [0 6 9 5 8 7 1 3 2 4]
 [9 6 4 0 7 8 3 5 2 1]
 [3 2 8 0 4 6 9 5 7 1]
 [9 5 0 4 7 1 3 6 2 8]
 [2 1 3 5 0 9 6 8 4 7]
 [4 1 6 5 7 2 9 0 8 3]
 [9 2 8 4 1 7 5 6 0 3]
 [0 5 2 7 8 9 3 6 4 1]]
vm  [-1.  -0.4  3.6 10.9 -1.8 -0.  -0.2 -0.2  0.  -0.7 -0.2 -0.1 -0.3 -0.4 -0.6 -0.6 -0.5 -0.3 -0.3 -0.8 -1.4 -0.1  1.  -0.3 -0.9  3.7  0.1 -0.6 -0.4 -2.1  1.9 -0.4 -0.1 10.2 -0.2  0.1 -0.1  2.  19.9 -0.5  6.4  2.5 -0.3  3.4 -0.2 -0.3  6.1 -0.1 -1.2  1.7 -0.3 -0.   1.9 -3.5 -1.   0.8 -1.  -0.2  4.8 -1.2  1.7 -0.2  0.9 -0.2  0.4 -0.4 -0.1 -0.4  1.2  0.5 -0.1 -0.8 -0.1 -0.1 -0.4  0.6 -0.1  1.6  0.1 -0.4 19.3 -0.3 -0.1 -0.   0.2  4.1 -1.1 -0.2 -0.1 -0.6 -0.4 -0.2 -0.1 -0.6 -0.7 -0.1  0.6 -1.8 -0.7 -0.6  0.7  5.8 -0.1 -0.1 -0.3 -0.2  1.1 -0.   0.2 -1.5 -0.6 -0.3 -0.1 -0.5  2.8  5.2  3.  -0.4 -0.3 -0.5 -0.1  5.5 -0.1 -0.3 -0.2 -0.9 -0.2 11.8  5.5 -3.2 -0.9 -0.  -0.6 -0.2 -5.1 -0.8 -0.2 -0.1 -0.7 -0.4  0.9 -0.2  0.2  0.1 -0.1 -0.1  0.  -0.2 -0.6 -0.  -1.4 -0.  -1.9 -0.2 -0.   0.5 -0.6 -0.5  4.8 -0.6 -0.  -1.9 -0.1 -0.2 -0.3 -0.8 -0.4 -0.6 -0.   0.1  0.  -0.3 -0.4 -0.1 -0.1  0.1 -0.4  0.  -1.6 -0.1 -0.8 -0.3 -0.3 -1.8 -0.1 -0.1 -0.2 -0.  -0.2  5.1 -0.1 -0.4 -0.3 -1.  -0.3 -1.7  0.3 -0.9 -0.1 -0.2 -0.1 -0.2 -0.3 -0.1 -0.2  4.5 -0.1 -0.3 -1.4 -0.2 -0.4  0.8 -0.5  7.2 -1.1 -0.3 -2.2 -1.2 -0.  -0.6 -0.1  0.1 -0.4 -0.6 -1.   0.2 -2.3 -0.8 -0.  -0.6  0.3 -1.2 -0.2 -0.4 -0.4 -0.7 -1.   0.1  2.1 13.4 -0.1  2.8 -0.2 -0.1 -3.7 -2.6 -0.3 -0.3 -1.  -0.1 -5.  -0.1 11.  -0.   2.8 11.8]
vy_50sample [[1 9 7 4 5 0 8 3 2 6]
 [7 0 5 8 4 3 6 1 2 9]
 [6 3 7 9 1 8 4 0 5 2]
 [3 6 8 1 9 2 0 4 5 7]
 [3 1 8 9 6 7 0 4 2 5]
 [2 6 0 0 1 3 8 5 9 4]
 [8 6 0 3 5 9 7 2 1 4]
 [6 0 9 1 8 2 7 3 5 4]
 [8 7 3 6 5 9 2 0 4 1]
 [4 6 5 7 1 1 2 0 9 8]]
vt_50sample [[1 9 7 4 5 0 8 3 2 6]
 [7 0 5 8 4 3 6 1 9 2]
 [6 3 9 7 1 8 4 5 0 2]
 [3 6 1 8 9 2 0 4 5 7]
 [3 1 8 9 6 7 0 4 2 5]
 [2 6 0 7 1 3 8 5 9 4]
 [8 6 0 3 5 9 7 2 1 4]
 [6 0 9 1 2 8 7 3 5 4]
 [8 7 3 6 5 9 2 0 4 1]
 [4 6 5 7 1 2 3 0 9 8]]
Epoch 54610: Training cost= 0.2776, Training acc= 0.8665, Validation cost= 0.2130, Validation acc= 0.8665
Epoch 54620: Training cost= 0.2231, Training acc= 0.8665, Validation cost= 0.2197, Validation acc= 0.8666
Epoch 54630: Training cost= 0.2305, Training acc= 0.8665, Validation cost= 0.2263, Validation acc= 0.8666
Epoch 54640: Training cost= 0.2204, Training acc= 0.8665, Validation cost= 0.1742, Validation acc= 0.8666
Epoch 54650: Training cost= 0.2031, Training acc= 0.8665, Validation cost= 0.1932, Validation acc= 0.8666
Epoch 54660: Training cost= 0.2362, Training acc= 0.8665, Validation cost= 0.2048, Validation acc= 0.8666
Epoch 54670: Training cost= 0.2632, Training acc= 0.8665, Validation cost= 0.2467, Validation acc= 0.8666
Epoch 54680: Training cost= 0.2594, Training acc= 0.8665, Validation cost= 0.2832, Validation acc= 0.8666
Epoch 54690: Training cost= 0.2913, Training acc= 0.8665, Validation cost= 0.2374, Validation acc= 0.8666
Epoch 54700: Training cost= 0.2576, Training acc= 0.8665, Validation cost= 0.2215, Validation acc= 0.8666
tm  [-0.4 -0.1 -1.9  5.6 -0.6 -0.2  0.2  0.2 -0.9 -0.4  9.3 -0.2 -0.2 -0.2 -2.5  1.4 -0.6  0.3 -0.1 -0.7 -1.4 -0.3  0.5 -0.4 -1.3  1.3 -0.4 -0.6 -0.6 -2.4 -0.   0.2  1.3 -3.2  0.  -0.1  4.5  5.  -1.5 -0.5  4.2  7.4  1.4 -0.3 -0.2 -0.   1.3 -0.2 -1.5  1.  -0.5 -0.1 -0.7 10.3 -1.1  3.1 -0.6  9.9 -0.4  2.3  6.  -0.5 -0.9 -0.2  1.2 -0.7 -0.  -0.2 -0.3  0.6 -0.1  2.8 -0.2 -0.2 -3.1 -0.5 -0.1 -0.6 -0.1 -0.2  4.8 -0.4  0.3 -0.3  0.4  5.7 -1.6 -0.1 -0.3 -0.2 -0.1 -0.2 -0.3  2.5 -0.7 -0.5  0.4 -2.6 -0.6 -0.5  3.7 -0.6  0.7 -0.2 -0.1  0.3 -2.8 -0.5 -0.1 -0.6 -0.6 -0.3 -0.1 -0.3 -0.4 -0.6  3.3 -1.1  0.7  0.7 -0.4  2.1  0.5  0.7 -0.1 -3.  -0.1 -1.9  2.5 -0.  -0.3  0.1 -0.2 -0.1 13.4  9.4 -0.1  0.3 -0.6 -0.7 -0.7 -0.3 -0.4 -0.3 -0.3  0.  -0.1 -0.1 10.1 -0.2 -0.6  0.3 -1.3 -0.5  0.  -0.1 -0.2 -0.1  0.9 -0.6 -0.2 -0.5 -0.1  0.1 -0.2 -0.2 -0.  -0.4 -0.3 -0.1  0.4 -0.  -0.3 -0.3 -0.3 -2.5 -1.3 -0.3  1.5  0.3 -2.3 -0.1 -0.  -1.7  0.3 -0.2 -0.2  0.7  0.3  7.6 -0.3 -0.2 -0.4 -1.1 -1.7 -0.5 -0.6  1.  -0.3 -0.1 -0.1 -0.2 -0.3  0.8 -0.1 -2.3  0.2 -0.1 -5.1 -0.1 -0.5 -0.8 -0.5  5.2 -0.  -0.3  2.5 -1.3  0.3 -0.5 -0.1 -0.1  1.4 -0.7  0.8 -0.9  3.1 -0.3 -0.2 -0.5 -0.5  2.5 -0.5 -1.  -0.2  0.9 -0.1 -0.5 -0.1 -4.8  0.1 -1.8 -0.  -0.2 -0.5 -0.2 -0.  -0.5 -1.1  0.3 -1.5 -0.2 -0.6 -0.1 -1.2  3.2]
ty_50sample [[5 2 1 0 6 9 3 8 4 7]
 [0 5 4 3 6 9 2 1 7 8]
 [0 9 5 2 6 8 3 4 1 7]
 [0 9 6 8 4 7 5 3 1 2]
 [0 8 5 2 1 4 9 7 6 3]
 [1 2 8 5 6 4 0 7 9 3]
 [9 5 8 1 4 6 0 7 2 3]
 [2 4 8 3 5 0 7 6 1 9]
 [7 4 9 5 8 0 1 6 3 2]
 [2 3 0 6 9 5 7 8 4 4]]
tt_50sample [[5 2 1 0 6 9 8 3 4 7]
 [0 5 4 3 6 9 2 1 7 8]
 [0 5 9 2 8 6 3 4 1 7]
 [0 9 6 8 4 7 5 3 1 2]
 [8 0 5 2 1 4 9 7 6 3]
 [1 2 8 5 6 4 0 7 9 3]
 [5 9 8 1 4 6 0 7 2 3]
 [2 4 8 3 5 7 0 6 1 9]
 [7 4 5 9 8 0 1 6 3 2]
 [2 3 0 6 9 5 7 8 4 1]]
vm  [-1.  -0.  -0.3 -5.9 -1.7 -0.2 -0.  -0.1 -0.7 -0.7  6.8  0.1 -0.3  0.4 14.2  4.7 -0.1 -0.3 -0.3  0.3 -1.6 -0.3 -0.3 -0.  -1.6 -0.   0.  -0.4 -0.5  0.9  1.9  0.6 -0.6  4.8 -0.2 -0.2  2.2  5.7 -1.3 -0.5  2.1 -2.7 -0.   4.3 -0.  -0.2 -1.3 -0.4 -3.1 -0.1 -0.1 -0.1 -0.8 15.8 -1.1 -1.9 -0.8 -3.4  0.3 -1.  10.   1.7 -0.7 -0.2 -0.2  1.2 -0.4 -0.2  0.3 -0.1 -0.1 -1.7 -0.9 -0.8 -4.3  1.   0.1  1.5 -0.2 -0.  -5.1  0.  -0.2  3.6  4.6 -2.1 -0.6  0.3 -0.2  0.2 -0.6 -0.2 -0.  -0.  -0.5 -0.3  0.4 -3.3 -0.5 -0.4  2.3  2.8 -0.1 -0.2 -0.1 -0.2 -3.5  0.3  2.2  1.   0.8 -0.1 -0.2 -0.3 -0.3  7.2 -0.4 -0.9 -0.4 -0.5 -0.2 -0.9 -0.3  0.3 -0.1 17.2 -0.2 -3.1 -0.5 13.4 -0.4 -0.4 -0.5 -0.3 -3.5 -2.5 -0.3 -0.1 -0.3 -0.5 -0.6 -0.3 -0.4 -0.2  0.2 -0.5 -0.1  0.1 -2.  -0.1  5.7 -0.2 -0.4 -0.3 -0.  -0.2 -0.7 -0.1 -0.1 -0.7  1.4 -0.8  0.  -0.1  0.1 -0.3 -0.2 -0.1 -0.4  0.3 -0.1 -0.1  0.2 -0.2  0.1  2.9 -0.2 -0.6  0.7 -0.1  2.3 -0.3  0.  -2.  -0.1 -0.8 -0.4 -0.5 -0.2 -0.3 -0.1 -0.5 -0.5 -0.9 -4.2  1.  -0.7  1.1 -0.4 -0.1  0.1 -0.2 -0.1 -0.6  0.1 -4.5 -0.1 -0.2  9.7  0.2 -1.   0.4 -0.3 10.1 -0.7  0.1 -2.2 -0.7 -0.5 -0.6 -0.  -0.2 -0.3 -1.1 -0.5  3.6  2.9 -0.2  2.7 -0.4 -1.3  2.8 -0.4  1.  -0.6  1.2 -0.2 -0.7  0.7  3.5 -0.1  0.2 -0.2 -0.3 15.1  5.6 -0.  -0.4 -0.7 -0.5 13.3 -0.3 -0.7 -0.2 -0.8 -2.9]
vy_50sample [[1 2 7 7 3 8 6 0 9 5]
 [8 1 7 4 3 5 6 2 2 0]
 [6 5 5 1 0 2 7 4 3 8]
 [4 9 2 6 7 8 0 3 1 5]
 [6 1 2 5 4 0 3 7 9 8]
 [9 7 3 2 0 8 1 5 6 4]
 [4 6 9 3 0 1 1 2 7 5]
 [1 3 5 6 2 9 8 4 7 0]
 [7 7 6 9 8 3 0 5 1 4]
 [4 2 3 9 6 7 5 1 0 8]]
vt_50sample [[1 2 4 7 3 8 6 0 9 5]
 [1 8 7 4 3 5 6 2 9 0]
 [6 5 9 1 0 2 7 4 3 8]
 [4 9 2 6 7 8 3 0 1 5]
 [6 1 2 5 4 0 3 7 9 8]
 [9 7 3 2 0 8 1 5 6 4]
 [4 6 9 3 0 1 8 2 7 5]
 [1 3 5 6 2 9 8 4 7 0]
 [2 7 6 9 8 3 0 5 1 4]
 [4 2 3 9 6 7 5 1 8 0]]
Epoch 54710: Training cost= 0.2087, Training acc= 0.8665, Validation cost= 0.1884, Validation acc= 0.8666
Epoch 54720: Training cost= 0.2218, Training acc= 0.8666, Validation cost= 0.1863, Validation acc= 0.8666
Epoch 54730: Training cost= 0.2326, Training acc= 0.8666, Validation cost= 0.1944, Validation acc= 0.8666
Epoch 54740: Training cost= 0.2148, Training acc= 0.8666, Validation cost= 0.2578, Validation acc= 0.8667
Epoch 54750: Training cost= 0.2444, Training acc= 0.8666, Validation cost= 0.2236, Validation acc= 0.8667
Epoch 54760: Training cost= 0.2720, Training acc= 0.8666, Validation cost= 0.2339, Validation acc= 0.8667
Epoch 54770: Training cost= 0.2293, Training acc= 0.8666, Validation cost= 0.2475, Validation acc= 0.8667
Epoch 54780: Training cost= 0.2815, Training acc= 0.8666, Validation cost= 0.2294, Validation acc= 0.8667
Epoch 54790: Training cost= 0.1826, Training acc= 0.8666, Validation cost= 0.2821, Validation acc= 0.8667
Epoch 54800: Training cost= 0.2062, Training acc= 0.8666, Validation cost= 0.1931, Validation acc= 0.8667
tm  [-0.8  0.   2.7 19.  -1.4  0.6 -0.3 -0.  -1.  -0.9  5.  -0.1 -0.3 -0.2 -2.7 -0.5 -0.3 -0.2  0.4 -0.7 -1.4 -0.1 -0.6 -0.1 -0.8  1.7 -0.2 -0.1 -1.1 -3.6 -0.6 -0.2  0.4 -1.7 -0.1 -0.1  4.3  2.5  8.8 -0.1  2.  -1.1  0.7 -0.7 -0.1  0.   5.5 -0.2 -1.4 -2.8 -0.2 -0.  -0.1 -1.  -0.1  3.1 -0.6  9.  -0.2  5.   2.1 -0.5 -0.4 -0.1  0.   0.   0.2 -0.5  0.2 -0.2  0.1  3.5 -0.1 -0.1 -0.3 -0.  -0.2 -0.4 -0.1 -0.3 12.3 -0.4 -0.2 -0.3  1.2 -1.  -2.3 -0.1 -0.  -0.1 -0.3 -0.1  0.1  0.6 -0.7 -0.2 -0.2 -1.6 -0.1 -0.2  4.1 -2.2 -0.   0.4 -0.1  0.2 -0.9 -0.2  1.3 -1.3 -0.7 -0.1 -0.1 -0.1 -0.1 -1.2  0.6 -1.1 -0.2 -0.2 -0.4  5.7  0.1  0.8 -0.  -3.5  0.1  5.2  1.9  3.7 -0.2 -0.3 -0.2 -0.6  5.5  3.  -0.  -0.2  0.9 -0.4 -0.3 -0.5 -0.4 -0.4 -0.1 -0.   0.9 -0.1  5.9 -0.1 -2.1 -0.1 -0.9 -0.1 -0.  -0.1  0.6  0.2  1.5 -0.1 -0.6 -0.6 -0.1 -0.  -0.1 -0.3  0.9 -0.4 -0.1 -0.  -0.  -0.1 -0.1 -0.1 -0.  -1.2 -0.4 -0.4 -0.6  0.3 -1.5 -0.1 -0.2 -1.9 -0.  -0.4 -0.2 -0.1  0.1 10.1  0.3 -0.  -0.1 -1.1  0.2 -0.4 -0.2  0.4 -0.3  0.  -0.3 -0.1 -0.1  0.3 -0.  -0.6  0.1  0.  -2.2  0.1 -0.1 -1.4 -0.5  6.2 -0.3 -0.3  3.5 -1.2 -0.4 -0.3 -0.1 -0.2  0.6 -0.7 -1.8 -0.8 -1.   0.9  0.3 -0.4 -0.4 -0.6 -0.1 -0.4  1.9 -0.6 -0.1 -0.   0.5  2.7 -0.1 -0.1 -0.1 -0.2 -2.1 -1.1  0.3 -0.1 -1.3 -0.3 -3.3 -0.1  5.2 -0.   6.1 -0.3]
ty_50sample [[3 1 0 5 5 2 6 8 7 4]
 [9 0 6 2 5 4 7 3 8 1]
 [0 1 5 4 8 3 6 9 2 7]
 [3 8 5 2 6 7 1 4 0 9]
 [0 9 3 8 7 1 2 4 6 5]
 [5 9 6 7 8 3 2 0 4 1]
 [8 3 1 6 7 2 0 4 9 5]
 [3 6 4 9 0 5 2 1 8 7]
 [5 0 2 9 4 1 7 6 3 8]
 [4 0 7 1 3 9 2 8 5 6]]
tt_50sample [[3 1 0 9 5 2 6 8 7 4]
 [9 6 0 2 5 4 7 3 8 1]
 [0 1 5 4 8 3 6 9 2 7]
 [3 8 5 2 6 7 1 4 0 9]
 [0 9 3 8 7 1 2 4 6 5]
 [5 9 6 7 8 3 2 0 4 1]
 [8 3 1 6 7 2 0 4 9 5]
 [3 6 4 9 0 5 2 1 8 7]
 [5 0 2 9 4 1 7 6 3 8]
 [4 0 7 1 3 2 9 8 5 6]]
vm  [ 1.7 -0.4 -0.6 11.5 -1.3 -0.  -0.  -0.1 -1.  -0.  -4.5 -0.  -0.4 -0.  -3.  -2.1 -0.2 -0.4  0.7 -1.3 -1.1 -0.2 -0.  -0.3 -1.1  1.3  0.  -0.  -1.3 -0.  -0.5 -0.2  1.1 -4.4 -0.2 -0.2  2.2 -1.1  6.7 -0.2 -0.1 -2.2 -0.1 -0.8 -0.2 -0.2  8.3 -0.5  7.6  6.2 -0.3 -0.2 -0.1 -3.5  1.7  3.5 -0.1 -1.2 -2.2  4.3 -2.5 -0.4 -0.5 -0.1 -0.3  0.3 -0.1 -0.3  3.2 -0.1 -0.2  7.8 -0.3 -1.   2.7 -0.3 -0.5 -0.2 -0.2 -0.3  2.8 -0.5 -0.4 -0.3 -2.  -2.2  7.1 -0.3  0.7 -0.1 -0.  -0.  -0.4  0.7 -0.5 -0.4 -0.1 -0.4 -0.4 -0.3  0.3 -0.6 -0.7 -0.4 -0.1 -0.2  0.7 -0.3 -1.1 -1.7 -0.1 -0.4 -0.2  0.5  2.1 -4.4  0.2 -0.8 -0.1 -0.2 -0.1  7.1 -0.3 -1.1 -0.2 -3.6 -0.3 10.9 -3.1 -1.9  1.2 -0.2 -0.2 -0.4  8.5 -1.  -0.   0.1 -0.2 -0.3 -0.5 -0.6  0.1 -0.3  0.4 -0.3 -0.4 -0.2 -0.8 -0.4 -1.2 -0.   3.8  0.1 -0.3 -0.2 -0.  -0.5 -0.9 -0.1 -0.7 -0.5 -0.  -0.2 -0.5 -0.   0.8 -0.5 -0.3 -0.1 -0.1 -0.2 -0.4 -0.1 -0.2  1.7 -1.  -0.3 -0.5 -0.1  1.4 -0.1  0.9 -1.  -0.2  1.4 -0.1 -0.4  0.7  0.4 -0.4  0.1 -0.2 -1.  19.1 12.1 -0.3 -0.8 -0.1  0.2  0.1 -0.   0.8 -0.  -0.6  5.1 -0.3 -0.5 12.1 -0.3 -0.4 -2.9 -0.6 -2.5  2.5 -0.5  3.6 -0.6 -0.1  0.9 -0.4 -0.2 -0.2 -0.7  0.4 -2.  -1.6  0.7 -0.3  1.3 -0.  -1.  -0.  -0.1  0.2 -0.1  0.3 -0.1  0.6 26.7  0.   6.7 -0.3  0.3 -0.  -2.5  0.3 -0.6 -0.9  0.4 -1.  -0.3  4.1  0.1  5.4  7.8]
vy_50sample [[0 9 8 6 3 4 7 2 5 1]
 [9 3 8 6 2 5 7 4 0 1]
 [1 9 3 6 7 4 2 5 8 0]
 [1 1 5 2 0 6 4 9 7 8]
 [8 6 7 4 3 5 1 2 0 9]
 [0 7 8 9 4 3 6 5 2 1]
 [4 4 8 1 2 6 7 0 9 3]
 [9 7 1 3 2 6 4 8 5 0]
 [8 4 5 0 2 6 1 7 9 3]
 [2 9 3 4 1 8 7 0 6 5]]
vt_50sample [[0 9 8 6 3 4 7 2 5 1]
 [9 3 8 6 2 5 7 4 0 1]
 [1 9 3 6 7 4 2 5 8 0]
 [1 3 5 2 0 6 4 9 7 8]
 [8 6 7 4 3 5 1 2 0 9]
 [0 7 8 9 4 3 6 5 2 1]
 [4 5 8 1 2 6 7 0 9 3]
 [9 7 1 3 2 6 4 8 5 0]
 [8 4 5 0 2 6 1 7 9 3]
 [2 3 9 4 8 1 7 0 6 5]]
Epoch 54810: Training cost= 0.2387, Training acc= 0.8666, Validation cost= 0.3083, Validation acc= 0.8667
Epoch 54820: Training cost= 0.3717, Training acc= 0.8666, Validation cost= 0.2511, Validation acc= 0.8667
Epoch 54830: Training cost= 0.2742, Training acc= 0.8666, Validation cost= 0.3211, Validation acc= 0.8667
Epoch 54840: Training cost= 0.3006, Training acc= 0.8666, Validation cost= 0.2614, Validation acc= 0.8667
Epoch 54850: Training cost= 0.2977, Training acc= 0.8666, Validation cost= 0.2584, Validation acc= 0.8667
Epoch 54860: Training cost= 0.2202, Training acc= 0.8667, Validation cost= 0.2024, Validation acc= 0.8667
Epoch 54870: Training cost= 0.2095, Training acc= 0.8667, Validation cost= 0.2007, Validation acc= 0.8667
Epoch 54880: Training cost= 0.1928, Training acc= 0.8667, Validation cost= 0.2212, Validation acc= 0.8668
Epoch 54890: Training cost= 0.2480, Training acc= 0.8667, Validation cost= 0.2852, Validation acc= 0.8668
Epoch 54900: Training cost= 0.2486, Training acc= 0.8667, Validation cost= 0.2198, Validation acc= 0.8668
tm  [ 1.3 -0.5 -0.4  3.3 -1.6 -0.1 -0.1  0.1 -0.8  0.4 -4.4 -0.2 -0.  -0.4 -0.7 -2.8 -0.2 -0.5 -0.2 -0.8 -1.3 -0.2  1.3 -0.4 -1.   1.9 -0.2 -0.3 -1.2 -1.9 -0.5 -0.3  0.1 -2.9 -0.2 -0.2 -0.1 -2.4 -3.7 -0.1  1.9  3.3 -0.4 -0.7 -0.1  0.   0.   0.6  7.2  4.  -0.1 -0.2 -0.6 -1.4  2.8  0.1 -1.   4.6  3.9  4.  -0.5 -0.7 -0.5 -0.1 -0.3  0.   1.  -0.1  3.  -0.1 -0.1  7.2 -0.7 -0.3 -3.6 -0.6 -0.4  0.2  0.4 -0.3 -1.6 -0.5 -0.4 -0.3 -1.7  2.   4.7 -0.2  0.6 -0.8 -0.1  0.3 -0.1 -0.6 -0.7  0.2 -0.1 -3.6 -0.3 -0.2 -0.5 -0.6 -0.4 -0.2 -0.3 -0.1 -1.5 -0.3 -1.2 -0.7 -0.5 -0.2 -0.  -0.3  7.3 -4.   0.5  1.1 -0.3 -0.1 -0.4  2.8 -0.1 -0.8 -0.3 -0.7 -0.3  6.   4.8  2.1 -0.2 -0.4 -0.5 -0.5 13.6  9.4 -0.3  0.  -0.5 -0.6  0.4 -0.9  0.5 -0.3 -0.2 -0.2 -0.2 -0.3  5.  -0.1 -0.5  0.2  2.7  0.5 -0.2 -0.2  0.2  0.  -0.8 -0.4 -0.8 -0.2 -0.1 -0.2 -0.5 -0.2  0.6 -0.5 -0.2 -0.3  0.   0.2 -0.5 -0.2  0.2 -1.1 -1.4 -0.4  3.9 -0.2 -1.9 -0.  -0.5 -2.  -0.1 -0.2 -0.  -0.  -0.2  4.9 -0.3  0.1 -0.2 -0.9  7.3 -1.6 -0.8 -2.1 -0.4  0.  -0.2  0.1 -0.2  1.7 -0.1 -1.9 -0.1 -0.3 -0.6  0.3 -0.9 -2.6 -0.4 -2.5 -0.9 -0.3  4.3 -1.2 -0.2 -0.5 -0.1 -0.1  0.1 -1.4  1.3 -1.6 -2.3 -0.2 -0.4  1.9  1.2 -0.1 -0.2 -0.3  1.6 -0.3 -0.1 -0.5  4.3 -2.2 -0.  -1.2 -0.2 -0.2  6.6  0.2  0.2 -0.6 -0.9  0.5  3.3 -0.2 -1.9 -0.3  7.3  0.4]
ty_50sample [[0 6 5 8 3 9 4 7 1 2]
 [4 9 8 6 2 5 7 0 1 3]
 [6 0 4 3 1 9 8 5 7 2]
 [2 9 6 5 8 7 3 1 0 4]
 [9 4 1 3 2 6 5 7 0 8]
 [8 7 0 9 5 2 4 6 1 3]
 [4 1 9 2 7 0 8 6 3 5]
 [8 0 6 1 2 2 3 7 4 5]
 [4 3 0 6 9 5 2 1 7 8]
 [5 3 3 2 6 7 9 8 0 1]]
tt_50sample [[0 6 5 8 3 9 4 7 1 2]
 [4 9 8 6 2 5 7 0 1 3]
 [6 0 4 3 1 9 8 5 7 2]
 [2 9 6 5 8 7 3 1 0 4]
 [9 4 1 3 2 6 5 7 0 8]
 [8 7 0 9 5 2 4 6 1 3]
 [4 1 9 2 7 0 8 6 3 5]
 [8 0 9 6 1 2 3 7 4 5]
 [4 3 0 6 9 5 2 1 7 8]
 [5 3 4 2 6 7 9 8 0 1]]
vm  [ 0.3 -0.5  8.1  9.5 -0.7 -0.5  0.2  0.   1.9  0.9  5.4 -0.2 -0.2 -0.5  4.6  2.3 -0.2 -0.3  1.2 -0.4 -1.   0.1 -0.1 -0.2 -0.7  2.1 -0.1 -0.1 -0.4 -2.5 -1.4 -0.4 -1.1 -1.9 -0.1 -0.3 -1.   5.6  2.3 -0.7 -0.9  1.6 -1.5 -0.9 -0.  -0.1 -0.1 -0.2  4.8 13.8 -0.1 -0.1 -0.3 12.4 -0.5 -0.5 -0.6  4.   9.9  8.5 -0.1 -0.1 -0.4 -0.3 -1.  -0.8 -0.2  0.5  0.6 -0.3 -0.2 -0.4  0.7 -0.2 -3.6 -0.  -0.2  1.  -0.2 -0.6 -3.6 -0.1 -0.1  0.8 -1.5  5.9 -0.9 -0.2 -0.3 -0.1 -0.2 -0.  -0.3 -1.8 -0.9 -0.1  0.3 -3.6 -0.4 -0.7 -0.4  7.3 -0.5 -0.2 -0.  -0.2 -1.8 -0.6  1.5 -0.6  0.4 -0.1  0.1 -0.5  6.3  1.  -0.1  2.  -0.2 -0.  -0.3  0.3 -0.2 -0.9 -0.2  5.6 -0.3 -2.3  7.4 -0.8  0.1 -0.3 -0.2 -0.6 -1.4 -3.5 -0.5 -0.1 -0.4  0.5 -0.5 -0.7 -0.2 -0.  -0.1 -0.1 -0.   0.1 -1.2  0.1 -1.2 -0.1  2.6 -0.1 -0.   0.1 -0.5  0.6 -0.6  0.1  2.2 -0.6 -0.1  0.1 -0.1 -0.8 -0.8 -0.2 -0.4 -0.1 -0.1 -0.  -0.2  0.3 -0.1  0.3 -0.5 -0.2 -0.4 -0.1 -0.4 -0.7 -0.4 -1.9 -0.  -0.2 -0.  -0.1 -0.2  6.5 -0.  -0.2 -0.2 -0.2  4.7 -2.8 -0.4 -2.2  0.   0.4 -0.2 -0.2 -0.2 -0.3 -0.2 -1.6 -0.1 -0.3  8.9 -0.1 -0.4 -0.1 -0.4 -1.4 -1.  -0.1  3.6 -0.8 -0.1 -0.2 -0.1 -0.3 -0.3 -1.   6.5  2.1  1.4 -0.1 -0.5  2.2 -0.9 -0.5  0.3  0.6 -0.6 -1.7 -0.1 -0.4  3.2  3.6 -0.2 -0.1 -0.1 -0.2 11.2 -0.7 -0.1 -0.3 -1.1 -1.2  8.5 -0.2  1.  -0.4 -2.6  5.6]
vy_50sample [[2 8 7 0 9 6 5 1 4 3]
 [7 1 3 2 6 4 0 8 9 5]
 [5 0 7 6 1 3 4 2 9 8]
 [3 2 5 4 8 9 1 1 6 0]
 [7 3 4 5 8 0 2 1 9 6]
 [9 0 4 7 2 6 1 5 3 8]
 [4 0 2 9 6 3 1 5 7 8]
 [2 8 4 9 3 5 7 6 1 0]
 [9 5 3 1 6 7 2 4 0 8]
 [5 7 0 6 1 8 4 2 9 3]]
vt_50sample [[2 8 7 0 9 6 5 1 3 4]
 [7 1 3 2 6 4 0 8 9 5]
 [5 0 7 6 1 3 4 2 9 8]
 [3 2 5 4 8 9 1 7 6 0]
 [7 3 4 5 8 0 2 1 9 6]
 [9 0 4 7 2 6 1 5 3 8]
 [4 0 2 9 6 3 1 5 7 8]
 [2 8 4 9 3 5 7 6 0 1]
 [9 5 3 1 6 7 2 4 0 8]
 [5 7 0 6 1 8 4 2 9 3]]
Epoch 54910: Training cost= 0.2049, Training acc= 0.8667, Validation cost= 0.2253, Validation acc= 0.8668
Epoch 54920: Training cost= 0.2243, Training acc= 0.8667, Validation cost= 0.2033, Validation acc= 0.8668
Epoch 54930: Training cost= 0.2443, Training acc= 0.8667, Validation cost= 0.2147, Validation acc= 0.8668
Epoch 54940: Training cost= 0.2462, Training acc= 0.8667, Validation cost= 0.2178, Validation acc= 0.8668
Epoch 54950: Training cost= 0.2635, Training acc= 0.8667, Validation cost= 0.2029, Validation acc= 0.8668
Epoch 54960: Training cost= 0.2595, Training acc= 0.8667, Validation cost= 0.2291, Validation acc= 0.8668
Epoch 54970: Training cost= 0.2475, Training acc= 0.8667, Validation cost= 0.2210, Validation acc= 0.8668
Epoch 54980: Training cost= 0.2589, Training acc= 0.8668, Validation cost= 0.2703, Validation acc= 0.8668
Epoch 54990: Training cost= 0.2694, Training acc= 0.8668, Validation cost= 0.2356, Validation acc= 0.8668
Epoch 55000: Training cost= 0.2455, Training acc= 0.8668, Validation cost= 0.2136, Validation acc= 0.8669
tm  [-0.7 -0.1  5.5 -0.4 -1.8  0.3 -0.2 -0.  -0.8 -0.2 -4.3 -0.1 -0.1 -0.2  8.4 -1.8  0.7 -0.2  0.1  1.8 -1.5 -0.3  2.2 -0.2 -0.9  1.4 -0.1  0.5 -1.5 -1.2 -1.  -0.3 -0.1 -2.3  0.1 -0.   0.9 -2.2 -7.  -0.1 -0.4  1.8 -0.3 -1.6 -0.1  0.8 -2.6  0.  -0.4  5.8 -0.  -0.1 -0.2  4.1  1.  -1.3 -1.   7.8  2.4  7.1  8.1 -0.2  0.1 -0.  -0.5 -0.1  0.2 -0.2  1.1 -0.2 -0.3  4.8 -0.2  0.3 -5.5 -0.1  0.  -0.1 -0.   0.5 -5.9 -0.4 -0.2 -0.4 -0.   2.4 -2.  -0.2 -0.2 -0.5 -0.5 -0.1 -0.1 -0.3 -0.4 -0.4 -0.1 -4.2  0.5  0.5 -0.  -0.1 -0.3 -0.2 -0.1 -0.1 -2.5 -0.1 -1.3  3.  -0.6  0.1 -0.1 -0.5  5.  -2.5 -0.7  0.1 -0.2 -0.3 -0.  -0.9 -0.1  1.6 -0.1 10.3 -0.2 -0.2  1.9  9.7 -0.1 -0.2 -0.2 -0.3 12.5  8.9 -0.1 -0.2 -0.1 -0.7 -0.  -0.8 -0.2 -0.2 -0.2  0.  -0.1  0.   3.2  0.   0.2 -0.   0.5  0.6 -0.1 -0.1 -0.3  0.6 -0.8 -0.3 -0.1  1.1 -0.1 -0.2 -0.  -0.1 -0.1 -0.3 -0.1 -0.3  0.1 -0.  -0.2 -0.  -0.2 -0.4 -0.6 -0.3  6.7 -0.1 -1.1  0.3 -0.4 -2.1 -0.2 -0.3 -0.4 -0.2 -0.   3.3 -0.2 -0.2 -0.3 -0.9 -3.6 -0.6 -0.4 -1.4 -0.3 -0.1 -0.1 -0.1 -0.  -0.1  0.1 -3.4 -0.2 -0.1  2.9 -0.2 -0.6 -1.7 -0.6  5.2 -0.2 -0.2  9.2 -1.1 -0.4 -0.3 -0.1 -0.2 -0.2 -1.3  3.6 -0.7 -1.6  0.9 -0.8 -0.3  1.8 -0.2 -0.1  0.7  2.3 -0.9 -0.3 -0.5  3.  -4.9 -0.3 -1.9  0.  -0.1 17.7  5.  -0.4  0.7 -1.1 -0.1 15.5 -0.2 -3.6 -0.3  4.6 -2.1]
ty_50sample [[6 0 1 8 5 3 7 2 4 9]
 [3 3 8 8 9 0 7 2 5 4]
 [5 8 6 2 0 3 7 4 9 1]
 [8 1 5 7 4 3 9 6 2 0]
 [4 7 3 5 0 9 8 2 6 1]
 [6 1 5 9 2 7 3 0 4 8]
 [5 8 4 3 9 6 1 2 7 0]
 [7 8 6 4 5 9 3 0 2 1]
 [8 4 5 6 3 9 0 1 7 2]
 [1 9 5 2 7 3 8 0 4 6]]
tt_50sample [[6 0 1 8 5 3 7 2 4 9]
 [3 1 6 8 9 0 7 2 5 4]
 [5 8 6 2 0 3 7 4 9 1]
 [8 1 5 7 4 3 9 6 2 0]
 [4 7 3 5 0 9 8 2 6 1]
 [6 1 5 9 2 7 3 0 4 8]
 [5 8 4 3 9 6 1 2 7 0]
 [7 8 6 4 5 9 3 0 2 1]
 [8 4 5 6 3 9 0 1 7 2]
 [1 9 5 2 7 3 8 0 4 6]]
vm  [ 0.9 -0.1 10.6 12.7 -1.1 -0.1  0.4 -0.2 -0.  -0.3 -2.3 -0.3 -0.4 -0.4  7.  -0.2 -0.4 -0.1 -1.2 -0.8 -1.   0.1  0.4 -0.3 -1.   0.7 -0.3 -0.2  1.4  4.8 -0.4 -0.5 -0.2 13.3 -0.1  0.1 -0.6 -1.6 -0.1 -0.4  0.9 -0.6  0.7 -1.  -0.3  0.1  3.9  0.5  9.9  0.9 -0.1 -0.2  0.4 -2.6 -1.3 -0.7 -0.3  2.8 -0.6  3.9 -1.4 -0.3  0.1  0.2  0.  -0.4  0.8  0.3  0.1  0.2 -0.1 -1.3 -0.2  1.  -2.  -0.3 -0.2  1.9 -0.1 -0.3  8.1 -0.2  0.7 -0.4 -2.3 -0.4  5.9 -0.4 -0.1 -0.6 -0.5 -0.3 -0.  -0.5 -0.8 -0.2 -0.3 -2.3 -0.2 -0.1 -0.4  4.4 -0.3 -0.1 -0.4  1.3  0.4 -0.2 -0.9 -1.4 -0.3 -0.5 -0.  -0.7  0.1 10.1 -0.9  0.5 -0.  -0.5 -0.2  5.1 -0.3 -0.7 -0.1  9.  -0.4  9.7 -0.5 -0.8  1.  -0.2 -0.5  1.1 -2.   9.6 -0.1 -0.1 -0.2 -0.3 -0.1 -0.3 -0.2 -0.2 -0.2 -0.   0.5 -0.1 -1.6 -0.2 -1.4 -0.   3.5  0.5 -0.1 -0.1 -0.5 -0.5 -0.5 -0.4 -0.7 -0.1  0.4 -0.1 -0.1  1.7 -0.  -0.6 -0.1 -0.  -0.1 -0.1 -0.4 -0.1 -0.   2.  -1.  -0.2 -0.1 -0.2 -0.8 -0.2 -0.6 -1.7 -0.1 -0.6  0.1 -0.2 -0.  -1.1  0.2 -0.1 -0.3 -0.6 14.6  1.8  0.4 -0.4 -0.2 -0.  -0.  -0.1 -0.3  0.3 -0.2  1.8 -0.3 -0.1  3.2 -0.1 -0.5  2.6 -0.2 -2.6 -0.7 -0.3  4.6 -1.2 -0.4 -0.6 -0.2 -0.1  0.2 -0.8  0.5  4.  -2.2 -0.3 -0.8  2.7  0.3 -0.4 -0.2  1.4 -1.  -2.1 -0.7 -0.1  3.4 10.7 -0.1  2.2 -0.1 -0.2 -1.2 -1.5 -0.7 -0.4 -1.3  0.5 -2.3 -0.2  0.1  0.   6.8  5.1]
vy_50sample [[7 6 9 3 8 5 4 0 2 1]
 [1 5 3 7 6 8 0 9 2 4]
 [6 9 3 8 5 2 1 0 7 4]
 [6 7 3 1 8 0 9 2 4 5]
 [8 6 0 3 4 2 1 9 7 5]
 [2 7 0 8 1 5 4 9 6 3]
 [8 1 7 2 9 0 5 6 3 4]
 [3 1 7 6 5 4 0 2 8 9]
 [4 0 9 3 1 7 6 5 8 2]
 [1 8 7 6 9 3 3 5 2 2]]
vt_50sample [[7 6 9 3 8 5 4 0 2 1]
 [1 5 3 7 6 8 0 9 2 4]
 [6 9 3 8 5 2 1 0 7 4]
 [6 7 3 1 8 0 9 2 4 5]
 [8 6 3 0 4 2 9 1 7 5]
 [2 7 0 8 1 5 4 9 6 3]
 [8 1 2 7 9 0 5 6 3 4]
 [1 3 7 6 5 4 0 2 8 9]
 [4 0 9 3 1 7 6 5 8 2]
 [1 8 7 6 9 3 4 0 5 2]]
Epoch 55010: Training cost= 0.1995, Training acc= 0.8668, Validation cost= 0.2162, Validation acc= 0.8669
Epoch 55020: Training cost= 0.2320, Training acc= 0.8668, Validation cost= 0.2280, Validation acc= 0.8669
Epoch 55030: Training cost= 0.2469, Training acc= 0.8668, Validation cost= 0.2390, Validation acc= 0.8669
Epoch 55040: Training cost= 0.2167, Training acc= 0.8668, Validation cost= 0.2049, Validation acc= 0.8669
Epoch 55050: Training cost= 0.2140, Training acc= 0.8668, Validation cost= 0.2371, Validation acc= 0.8669
Epoch 55060: Training cost= 0.2237, Training acc= 0.8668, Validation cost= 0.2555, Validation acc= 0.8669
Epoch 55070: Training cost= 0.2933, Training acc= 0.8668, Validation cost= 0.2548, Validation acc= 0.8669
Epoch 55080: Training cost= 0.2844, Training acc= 0.8668, Validation cost= 0.2535, Validation acc= 0.8669
Epoch 55090: Training cost= 0.2423, Training acc= 0.8668, Validation cost= 0.2699, Validation acc= 0.8669
Epoch 55100: Training cost= 0.2135, Training acc= 0.8668, Validation cost= 0.2576, Validation acc= 0.8669
tm  [-0.4 -0.1  9.5 17.4 -1.6 -0.1 -0.   0.4 -0.6 -1.2  1.9 -0.1 -0.3 -0.3 -0.   1.4 -0.2 -0.2  1.2 -0.4 -1.  -0.2  2.2 -0.2 -0.8 -0.  -0.5 -0.2 -0.8 -0.4 -0.8 -0.3 -0.5  2.8 -0.1  0.2  3.2  7.5 25.6 -0.6 -0.1 -1.1  2.1  0.4  0.   0.   5.6  0.6  3.5  2.9 -0.3 -0.1  0.8 -0.6 -0.7 -0.1 -0.5  4.2 -1.7  6.8 -1.2  0.5 -0.4 -0.4 -1.1 -0.4 -0.4 -0.2  2.7 -0.  -0.   0.9  0.9 -0.1  4.7 -0.2 -0.  -0.5 -0.1  0.4  5.2 -0.2  0.3  1.5 -1.1 -0.7 -0.3 -0.4 -0.2  0.4 -0.7 -0.1 -0.3 -0.1 -0.6 -0.3  0.  -0.6 -0.5  0.4  4.7  4.4 -0.3 -0.2 -0.2 -0.5  0.5 -0.2  1.  -2.  -0.9 -0.5  0.  -0.1 -1.1  1.1  0.9 -0.9 -0.  -0.3 -0.1  8.  -0.4 -0.5 -0.3 -0.1 -0.2  3.3 -1.8 -0.8 -0.3 -0.  -0.2 -0.5 -7.3 -6.4 -0.2 -0.3 -0.3 -0.3 -0.7 -0.4 -0.4 -0.2 -0.1 -0.1 -0.1 -0.2 -1.7  1.2 -2.  -0.2  3.2 -0.4  0.1 -0.   0.6 -0.4  2.8 -0.4 -0.1 -0.9 -0.2 -0.2 -0.1 -0.2 -0.2 -0.2 -0.2 -0.3 -0.  -0.2 -0.2 -0.3 -0.4  1.5  4.2 -0.3 -2.5  0.1 -1.1 -0.1 -0.3 -0.7 -0.1 -0.1 -0.   0.1 -0.2  0.4 -0.1 -0.2 -0.1 -0.7 10.5  7.3  0.   2.9 -0.2 -0.2  0.3 -0.1 -0.2 -0.3 -0.   1.3 -0.3 -0.1  5.6 -0.3 -0.7 -1.  -0.5 -0.5  0.2 -0.3 -1.  -0.5  0.4 -0.  -0.1 -0.2 -0.3 -0.6 -2.1  2.3  0.3 -0.4  2.1  1.5 -0.6 -1.   0.2  1.1  0.1 -2.2 -0.4  1.6  0.1 13.7 -0.2  2.9  0.5 -0.3 -0.4 -1.6 -0.3  0.9 -0.8 -0.4 -1.6 -0.  14.  -0.3  0.4  3.9]
ty_50sample [[9 7 8 2 3 0 5 1 4 6]
 [5 5 0 6 7 9 9 4 3 3]
 [1 4 0 2 5 9 7 8 6 3]
 [2 9 5 0 4 6 8 7 3 1]
 [9 8 1 7 3 5 4 2 6 0]
 [8 2 4 3 7 6 1 0 5 9]
 [0 8 9 5 1 3 7 6 2 4]
 [9 0 1 7 8 4 6 3 3 2]
 [4 8 5 6 2 0 9 3 7 1]
 [3 8 0 9 7 6 4 1 2 5]]
tt_50sample [[9 7 8 2 3 0 5 1 4 6]
 [5 2 0 6 7 9 1 4 8 3]
 [1 4 0 2 5 9 7 8 6 3]
 [2 9 5 0 4 6 8 7 3 1]
 [9 8 1 7 3 5 4 2 6 0]
 [8 2 4 3 7 6 1 0 5 9]
 [0 8 9 5 1 3 7 6 2 4]
 [9 0 1 7 8 4 6 5 3 2]
 [4 8 5 6 2 0 9 3 7 1]
 [3 8 0 9 7 6 4 1 2 5]]
vm  [-0.8 -0.1  8.4  3.  -1.2  0.5 -0.   0.1 -0.  -0.5  7.7 -0.1 -0.2 -0.3 10.6  4.9  0.3 -0.4 -0.4  0.1 -1.1 -0.1  1.5 -0.1 -0.9 -0.3 -0.2 -0.1 -0.2 -1.7 -1.3 -0.5 -0.6 -0.3 -0.  -0.1  0.7  8.3 -0.2 -0.3 -0.2  3.1 -0.1 -0.3 -0.1  0.6 -1.6  0.5 -1.2  4.6 -0.1 -0.1 -0.6 18.6 -0.9 -1.4 -0.8 11.   2.7  7.3  7.7 -0.2 -0.5  0.2 -0.2 -0.2 -0.1 -0.  -0.4  0.3 -0.1 -1.4 -0.3 -0.3 -4.8 -0.1 -0.1  0.5  0.5 -0.  -5.1  0.3 -0.3  0.8  0.7  4.3 -2.5 -0.3  0.2  0.2 -0.7 -0.2  0.5 -0.3 -0.5 -0.1  0.1 -3.6 -0.1 -0.2  2.1  2.5 -0.2 -0.3 -0.3 -0.5 -3.  -0.   0.5  0.5  0.4  0.3 -0.2 -0.6 -0.5  8.9 -0.4 -0.3 -0.4 -0.1 -0.2 -0.6  0.6  1.3 -0.4 13.1 -0.1 -3.8  4.5  9.3 -0.  -0.  -0.3 -0.4 -3.2 -3.8 -0.4 -0.2  0.  -0.6 -0.6 -0.3 -0.5 -0.1 -0.1 -0.3  0.1 -0.2  4.   0.5 -0.7 -0.1  0.1 -0.2 -0.1 -0.  -0.4  1.6  0.6 -0.5 -0.2 -0.6 -0.2 -0.1  0.2  0.1 -0.5 -0.3 -0.2 -0.2  0.2 -0.  -0.2 -0.3 -0.2 -0.6  1.5 -0.5 -0.3  0.3 -2.1 -0.3 -0.4 -1.6  0.  -0.4 -0.3 -0.5 -0.3  4.5  0.1 -0.1 -0.3 -0.8 -3.3 -1.6 -0.2  1.5 -0.1 -0.1  1.1  0.5 -0.2 -0.4 -0.1 -3.9 -0.1 -0.3 -1.2  0.  -1.1  0.4 -0.2  4.9 -0.6 -0.2  1.9 -1.  -0.5 -0.5 -0.2 -0.2 -0.3 -1.  -0.4  3.5  3.5 -0.4  0.   0.4 -0.9  1.6 -0.1 -0.3 -0.2 -1.7 -0.6 -0.4  1.4 -6.4 -0.1 -2.2  0.9  0.3 15.4  5.1 -0.1 -0.  -0.8 -0.2 13.2 -0.1 -0.2 -0.2 -1.2 -1.9]
vy_50sample [[2 5 1 8 7 3 0 0 9 4]
 [4 1 2 3 0 6 5 9 8 7]
 [3 2 6 4 9 7 0 8 5 1]
 [0 2 5 8 6 9 1 3 4 7]
 [9 4 1 6 7 5 2 8 0 3]
 [3 1 4 7 0 8 2 6 5 9]
 [8 4 5 5 3 9 7 0 6 2]
 [8 6 5 2 3 1 0 4 9 7]
 [8 5 6 4 2 3 9 0 1 1]
 [9 5 3 0 2 4 7 8 1 6]]
vt_50sample [[2 5 1 8 7 3 6 0 9 4]
 [4 1 2 3 0 6 5 9 8 7]
 [3 2 6 4 0 9 7 8 5 1]
 [0 2 5 8 6 9 1 3 4 7]
 [9 4 1 6 7 5 2 0 8 3]
 [3 1 4 7 0 8 2 6 5 9]
 [8 1 4 5 3 9 7 6 0 2]
 [8 6 5 2 3 1 0 4 9 7]
 [8 5 6 2 4 3 0 9 7 1]
 [9 5 3 0 2 4 7 8 1 6]]
Epoch 55110: Training cost= 0.2164, Training acc= 0.8668, Validation cost= 0.2383, Validation acc= 0.8669
Epoch 55120: Training cost= 0.2301, Training acc= 0.8669, Validation cost= 0.2454, Validation acc= 0.8669
Epoch 55130: Training cost= 0.2374, Training acc= 0.8669, Validation cost= 0.2343, Validation acc= 0.8669
Epoch 55140: Training cost= 0.1941, Training acc= 0.8669, Validation cost= 0.2255, Validation acc= 0.8670
Epoch 55150: Training cost= 0.2084, Training acc= 0.8669, Validation cost= 0.2236, Validation acc= 0.8670
Epoch 55160: Training cost= 0.2310, Training acc= 0.8669, Validation cost= 0.1710, Validation acc= 0.8670
Epoch 55170: Training cost= 0.2478, Training acc= 0.8669, Validation cost= 0.2221, Validation acc= 0.8670
Epoch 55180: Training cost= 0.2075, Training acc= 0.8669, Validation cost= 0.3379, Validation acc= 0.8670
Epoch 55190: Training cost= 0.1897, Training acc= 0.8669, Validation cost= 0.3787, Validation acc= 0.8670
Epoch 55200: Training cost= 0.2945, Training acc= 0.8669, Validation cost= 0.2544, Validation acc= 0.8670
tm  [-1.2 -0.1  9.6 13.6 -2.1 -0.1 -0.2  0.  -1.1 -1.6 -2.1 -0.1 -0.1 -0.   3.  -0.  -0.3 -0.2 -0.1 -0.3 -1.1 -0.1  1.7 -0.  -1.2  2.8 -0.4 -0.6 -0.9  3.1 -0.6 -0.1  2.6  6.2 -0.2 -0.2  3.2  3.1 14.9 -0.6  5.1  0.3  4.4  1.3  0.1  0.2  3.7  0.2 -2.3  4.2 -0.3 -0.1 -0.  -1.9 -0.9 -0.4 -0.9  7.  -3.9  5.4  3.1  0.9 -0.  -0.2 -1.1  0.3 -0.  -0.7  1.6 -0.1  0.1 -0.4  0.8 -0.1  0.5  1.5 -0.2  0.6 -0.2 -0.4  4.7 -0.5  0.  -0.3  1.4  1.8 -2.9 -0.2 -0.1  0.1 -0.9 -0.1 -0.   2.9 -0.5 -0.4  3.6 -0.6 -0.9 -0.   4.8  4.9 -0.1  0.3 -0.  -0.7 -0.1 -0.2 -0.5 -0.8 -1.1 -0.2  0.3  0.2 -1.6  3.6  3.  -2.  -0.3 -0.4 -0.3  4.4 -0.3  0.2 -0.2  3.6 -0.1  7.4 -4.  -1.3 -1.   0.3 -0.6 -0.3 -5.8 -3.4 -0.4 -0.2 -0.4 -0.6 -0.4 -0.4 -0.2 -0.3 -0.  -0.2 -0.1 -0.  -0.8 -0.2 -1.5 -0.2 -0.4  0.5  0.2 -0.1 -0.4 -0.6  4.8 -0.2 -0.1 -1.4 -0.2 -0.1 -0.3 -0.5  0.5 -0.5 -0.3 -0.1  0.5 -0.1 -0.1 -0.3  0.1 -0.3 -0.5 -0.2 -1.  -0.1 -1.   0.3  0.1 -1.4 -0.2 -0.5 -0.3 -0.1 -0.1 -1.  -0.2 -0.  -0.1 -0.8 -0.5 15.4  0.7  4.  -0.2  0.5  0.  -0.  -0.1 -0.  -0.2  2.7  0.  -0.   3.4 -0.2 -0.4 -0.4  0.1 10.9  1.6 -0.4 -0.8 -0.4  0.3 -0.7 -0.2 -0.  -0.2 -0.  -1.9  2.1 -1.2 -0.6  1.3 -1.1 -0.  -1.  -0.3  0.8 -0.2 -2.1 -0.9  1.4 -0.8 10.1 -0.   2.   0.3 -0.2 -0.4 -2.  -0.7 -0.2 -1.1 -0.1 -1.5 -0.4  7.9 -0.2  3.5  5.7]
ty_50sample [[7 7 9 8 5 3 0 2 4 6]
 [6 7 8 1 0 5 2 3 4 9]
 [6 5 2 0 4 7 8 1 3 9]
 [8 5 4 9 6 2 1 3 7 0]
 [2 3 5 9 6 1 4 0 8 7]
 [3 0 6 6 4 5 1 2 7 9]
 [7 0 0 2 8 5 6 1 3 9]
 [6 2 7 5 3 9 0 1 4 8]
 [6 4 5 9 1 2 7 3 0 8]
 [0 2 6 6 9 3 4 8 5 7]]
tt_50sample [[1 7 9 8 5 3 0 2 4 6]
 [6 7 8 1 0 5 2 3 4 9]
 [6 5 2 0 4 7 8 1 3 9]
 [8 5 4 9 2 6 1 3 7 0]
 [2 3 5 9 6 1 8 0 4 7]
 [3 0 8 6 4 5 2 1 7 9]
 [7 4 0 2 8 5 6 1 3 9]
 [2 6 7 5 3 9 1 0 4 8]
 [6 4 5 9 1 2 7 3 0 8]
 [0 2 6 1 9 3 4 8 5 7]]
vm  [ 2.3 -0.4 -3.8 -6.3 -1.6 -0.1 -0.1 -0.2 -0.2  0.2 -6.3  0.1 -0.2 -0.5  4.5 -1.7  0.7 -0.4 -0.5 -0.4 -1.2  0.1  1.8 -0.1 -1.3 -0.2 -0.2 -0.2 -0.9 -1.8  1.8 -0.1 -0.4 -4.5  0.2 -0.  -0.2 -0.1  1.3 -0.4 -0.2 -0.6 -0.7  3.  -0.2 -0.1 -0.8 -0.2  7.   4.6 -0.3 -0.1 -0.9  0.6 -0.2 -0.6 -0.8 -2.1  8.  -0.6  0.3 -0.3 -0.3 -0.1 -0.6  0.1 -0.2 -0.   1.7 -0.2 -0.2  2.5 -0.7 -0.8 -4.8  1.2 -0.3  1.8 -0.2  0.  -6.6 -0.2 -0.2  0.7 -1.8 -0.5 11.5 -0.  -0.  -0.4 -0.6 -0.  -0.4 -0.6 -0.8 -0.5 -0.2 -4.  -0.6 -0.6 -0.2 -0.6 -0.4 -0.5  0.2 -0.7 -2.7  0.1 -1.7  0.3  1.6 -0.1 -0.3 -0.4  5.2 -1.7  0.3  1.6 -0.2 -0.5 -0.5 -0.3 -0.3 -1.1 -0.2  5.2 -0.5  1.8  7.6 10.6  0.6 -0.5 -0.5 -0.7 -1.5 -5.7 -0.  -0.  -0.5  0.1 -0.4 -0.6  0.3 -0.3 -0.2 -0.3 -0.1 -0.1  3.2 -0.2  6.3 -0.1  3.8 -0.3 -0.2 -0.5 -0.2 -0.1 -0.3 -0.1  0.4 -0.9 -0.   0.1 -0.2 -0.   0.4 -0.5 -0.4 -0.1 -0.1  0.4 -0.3 -0.1 -0.2 -0.2 -0.4 -0.7 -0.3 -0.1 -0.9 -0.5 -0.6 -1.4 -0.1  0.5 -0.3 -0.2 -0.5  5.3  0.5 -0.1 -0.3 -0.8  3.3 -2.7 -0.8 -1.5 -0.2 -0.1 -0.  -0.1  0.3  0.3 -0.2 -3.3 -0.1 -0.3  7.6  0.  -1.3 -1.5 -0.3 -3.1 -0.2 -0.2 -2.5 -0.7 -0.2 -0.8 -0.1 -0.2 -0.2 -1.5 -1.3 -0.4 -1.5 -0.6 -0.6  2.8 -0.9  1.2 -0.2  0.2 -0.5  3.5 -0.3 -1.1  2.5 -1.9 -0.3 -1.1 -0.2  0.  18.9  1.8  0.7 -0.5 -1.  -0.3 16.6 -0.4  1.4 -0.   5.6 -2.3]
vy_50sample [[4 8 0 3 5 7 9 6 2 1]
 [8 3 9 2 7 0 1 6 4 5]
 [7 4 6 3 1 2 5 5 8 9]
 [8 5 9 7 1 6 0 3 4 2]
 [6 2 3 9 5 0 8 4 1 7]
 [2 9 1 1 6 8 0 3 4 5]
 [0 4 6 6 8 9 7 3 5 2]
 [8 5 3 7 2 1 4 9 9 6]
 [1 2 7 6 5 4 3 0 0 8]
 [7 2 8 4 0 3 1 5 6 9]]
vt_50sample [[4 8 0 3 5 7 9 6 2 1]
 [8 3 9 2 0 7 1 6 4 5]
 [7 4 6 3 1 2 0 5 8 9]
 [8 5 9 7 1 6 0 3 4 2]
 [6 2 3 9 5 0 8 4 1 7]
 [2 9 1 7 6 8 0 3 4 5]
 [0 4 1 6 8 9 7 3 5 2]
 [8 5 3 7 2 1 4 0 9 6]
 [1 2 7 6 5 4 3 8 0 9]
 [7 2 4 8 0 3 1 5 6 9]]
Epoch 55210: Training cost= 0.2201, Training acc= 0.8669, Validation cost= 0.2622, Validation acc= 0.8670
Epoch 55220: Training cost= 0.1847, Training acc= 0.8669, Validation cost= 0.2724, Validation acc= 0.8670
Epoch 55230: Training cost= 0.2205, Training acc= 0.8669, Validation cost= 0.2607, Validation acc= 0.8670
Epoch 55240: Training cost= 0.2754, Training acc= 0.8670, Validation cost= 0.2563, Validation acc= 0.8670
Epoch 55250: Training cost= 0.3031, Training acc= 0.8670, Validation cost= 0.3340, Validation acc= 0.8670
Epoch 55260: Training cost= 0.2342, Training acc= 0.8670, Validation cost= 0.3089, Validation acc= 0.8670
Epoch 55270: Training cost= 0.2114, Training acc= 0.8670, Validation cost= 0.1830, Validation acc= 0.8670
Epoch 55280: Training cost= 0.2117, Training acc= 0.8670, Validation cost= 0.2620, Validation acc= 0.8670
Epoch 55290: Training cost= 0.2102, Training acc= 0.8670, Validation cost= 0.2277, Validation acc= 0.8671
Epoch 55300: Training cost= 0.2246, Training acc= 0.8670, Validation cost= 0.2388, Validation acc= 0.8671
tm  [-0.9 -0.2 10.4 -0.1 -2.2 -0.  -0.4  0.1 -0.6  1.  -1.  -0.2 -0.2  0.3 15.9 -1.4 -0.8 -0.1 -0.8 -0.2 -1.2 -0.3  0.9 -0.2 -1.1  0.8 -0.6 -0.2 -0.5 -1.7  1.1 -0.1  0.9 17.9 -0.1 -0.1  0.2 -0.1  1.7 -0.4  2.4  3.6 -0.5  0.9 -0.3 -0.4 -1.  -0.2 -2.5  0.3 -0.2  0.1 -0.3 -0.2 -1.6 -2.1 -0.9  4.8  4.1  1.9 10.2 -0.5  1.1 -0.3  2.9 -1.1 -0.4 -0.1  0.  -0.4 -0.1 -0.3 -0.4 -0.8 -5.7 -0.8 -0.  -0.2 -0.2 -0.4 -0.2 -0.3  0.7 -0.7  0.2  1.6 -2.2 -0.2 -0.2 -0.4 -0.1  0.  -0.4 -0.3 -0.6 -0.4 -0.7 -3.4 -0.3 -0.4 -0.9  5.8 -0.3 -0.4 -0.  -0.2 -2.6 -0.  -0.3 -0.2  0.5 -0.5 -0.3 -0.7  3.3 -0.3 -0.7 -0.2 -0.1 -0.1 -0.2 -0.5 -0.4 -0.1 -0.3 19.9 -0.1  2.7  5.   2.5 -0.1 -0.2 -0.8  1.8 -7.  -0.3  0.3 -0.3 -0.5 -0.8 -0.1 -0.2 -0.3 -0.3 -0.2 -0.2 -0.3 -0.1 -0.6 -0.2 -0.1 -0.2 -1.8  1.7  0.2 -0.2 -0.1 -0.5  1.4 -0.8 -0.9 -2.  -0.1 -0.  -0.3  0.9  0.6 -0.5 -0.2 -0.  -0.2 -0.2 -0.3 -0.2 -0.1  0.9 -0.8 -0.4 -0.3  0.  -1.8 -0.2  0.7 -2.1 -0.1 -0.4 -0.4 -0.3  0.   4.6 -0.3 -0.2 -0.3 -1.2 -4.4 -1.5 -0.3 -1.1 -0.1 -0.1 -0.1 -0.2 -0.4  0.4 -0.3 -2.1 -0.2 -0.1 -2.9 -0.2 -0.3 -0.2 -0.5  7.8 -0.5 -0.4 -0.8 -1.4 -0.1 -0.1 -0.1 -0.2 -0.  -0.9 -1.  -0.3 -2.6 -0.1 -1.1 -1.  -0.2  2.7  0.3 -0.4 -1.2 -2.2 -0.4 -0.6  1.4 -4.5 -0.  -2.1 -0.  -0.   3.  -0.  -0.6 -0.1 -1.2  3.  -0.2 -0.3  1.4 -0.1  5.8  0. ]
ty_50sample [[1 7 5 0 3 3 4 9 6 2]
 [2 3 7 9 0 6 8 1 5 4]
 [0 9 5 6 2 8 4 7 3 3]
 [5 2 9 7 4 3 8 1 6 0]
 [2 5 9 0 3 7 4 6 1 8]
 [0 6 4 1 7 2 9 5 3 8]
 [7 5 9 2 4 8 8 1 6 0]
 [2 3 8 4 5 7 1 0 9 6]
 [7 6 3 8 4 2 0 1 9 5]
 [4 3 1 8 6 6 0 5 9 9]]
tt_50sample [[1 7 5 0 3 8 4 9 6 2]
 [2 3 7 9 0 6 1 8 5 4]
 [0 9 5 6 2 8 4 3 1 7]
 [5 2 9 7 4 3 8 1 6 0]
 [2 5 9 0 3 7 4 6 1 8]
 [0 6 4 1 7 2 9 5 3 8]
 [7 5 9 2 4 3 8 1 6 0]
 [2 3 8 4 5 7 1 0 9 6]
 [7 6 3 8 4 2 0 1 9 5]
 [4 3 1 8 6 2 0 5 7 9]]
vm  [-1.1 -0.5 -0.5 11.3 -1.5  0.3 -0.1  0.8 -0.4 -0.4 -4.  -0.2 -0.1 -0.2 -2.1 -0.7  1.1 -0.2 -0.3 -0.8 -1.8 -0.2  1.4 -0.1 -1.   3.   0.1 -0.8 -0.5 -4.  -0.8 -0.   1.9 -4.5 -0.1 -0.   0.9  3.5 14.3 -0.3  6.6 -0.8 -0.5  1.4 -0.1 -0.1  3.2 -0.4 -1.7  5.4 -0.1  0.2 -0.3 -2.2 -0.8  1.9 -1.   2.7  4.2  4.9  5.4 -0.4  2.5 -0.3 -0.9 -0.3 -0.4 -0.5 -0.2 -0.2 -0.2  0.   0.3 -0.1 -1.9  0.2 -0.2  1.9 -0.1 -0.3 -0.2 -0.1 -0.  -0.6  1.6 -0.3 -2.3 -0.1 -0.2 -0.2 -0.4 -0.1 -0.3 -0.5 -0.8 -0.6  1.4 -2.3 -0.6 -0.4  1.2 -1.2 -0.1  0.2  0.  -0.7 -0.4 -0.1 -1.2 -1.1 -0.8 -0.2  0.4 -0.5  4.1 -0.   0.8 -0.4 -0.1 -0.7 -0.2  3.1 -0.4  0.3 -0.1 -2.6 -0.4  8.   3.1 -0.9 -0.7 -0.1 -0.5 -0.1 -0.4 -4.8 -0.2 -0.1  0.5 -0.  -0.1 -0.6 -0.3 -0.3 -0.1 -0.1 -0.3 -0.   5.2 -0.1 -1.3 -0.1 -0.7 -0.1 -0.1 -0.1 -0.8 -0.5  4.3  1.6 -0.1 -1.9 -0.3 -0.1 -0.4 -0.3  0.8 -0.6 -0.2 -0.1  0.2 -0.4 -0.1 -0.   0.4 -0.8 -0.8 -0.  -1.2 -0.1 -0.6  0.2 -0.3 -1.6 -0.  -0.6  0.2 -0.2 -0.3 10.8 -0.1 -0.1 -0.1 -0.8 -1.7 -1.1  0.1 -1.2 -0.3  0.   0.  -0.2 -0.2 -0.1 -0.1  1.6 -0.3 -0.2  6.4  0.5 -0.2  0.1 -0.1  8.  -0.7 -0.6 -1.  -0.9 -0.3 -0.6  0.  -0.2 -0.5 -0.9 -1.9  0.2 -1.8 -0.1 -0.8 -1.1  1.  -0.5 -0.1  0.4 -0.5  0.2 -0.6 -0.3  1.6 11.5 -0.   2.3 -0.2 -0.1  2.8 -2.  -0.7 -0.3 -1.2  2.2 -0.3  0.   7.8  0.3  5.3  5.5]
vy_50sample [[1 8 9 0 3 5 4 2 7 6]
 [1 6 3 2 8 9 4 5 0 0]
 [6 1 9 0 5 8 3 2 7 4]
 [3 7 7 1 0 5 6 2 8 9]
 [0 6 5 3 4 7 2 2 8 9]
 [2 4 7 6 3 9 8 1 0 0]
 [2 0 7 8 4 3 6 9 1 5]
 [7 3 1 4 9 5 8 8 6 0]
 [1 0 2 4 7 8 3 5 9 6]
 [0 5 9 8 6 7 4 3 1 2]]
vt_50sample [[1 8 9 0 3 5 4 2 7 6]
 [1 6 3 2 8 9 4 5 7 0]
 [6 1 9 0 5 8 3 2 7 4]
 [3 7 4 1 0 5 6 2 8 9]
 [0 6 5 3 4 7 2 1 8 9]
 [2 4 7 6 3 9 8 1 0 5]
 [2 0 7 8 4 3 6 1 9 5]
 [7 3 1 4 9 5 8 2 6 0]
 [1 0 2 4 7 8 3 5 9 6]
 [0 5 9 8 6 7 4 3 1 2]]
Epoch 55310: Training cost= 0.2481, Training acc= 0.8670, Validation cost= 0.2224, Validation acc= 0.8671
Epoch 55320: Training cost= 0.2401, Training acc= 0.8670, Validation cost= 0.2385, Validation acc= 0.8671
Epoch 55330: Training cost= 0.2083, Training acc= 0.8670, Validation cost= 0.2874, Validation acc= 0.8671
Epoch 55340: Training cost= 0.2152, Training acc= 0.8670, Validation cost= 0.2506, Validation acc= 0.8671
Epoch 55350: Training cost= 0.2379, Training acc= 0.8670, Validation cost= 0.2822, Validation acc= 0.8671
Epoch 55360: Training cost= 0.2835, Training acc= 0.8670, Validation cost= 0.3050, Validation acc= 0.8671
Epoch 55370: Training cost= 0.2515, Training acc= 0.8670, Validation cost= 0.3172, Validation acc= 0.8671
Epoch 55380: Training cost= 0.2683, Training acc= 0.8671, Validation cost= 0.2719, Validation acc= 0.8671
Epoch 55390: Training cost= 0.2358, Training acc= 0.8671, Validation cost= 0.2181, Validation acc= 0.8671
Epoch 55400: Training cost= 0.1783, Training acc= 0.8671, Validation cost= 0.2414, Validation acc= 0.8671
tm  [-0.9 -0.3  6.7 -1.  -2.2 -0.1 -0.4 -0.1 -1.2 -1.2 -0.6 -0.2 -0.  -0.1 11.  -1.1  0.4 -0.4 -0.2  2.5 -1.4 -0.1 -0.1  0.3 -1.7  3.5  0.2 -0.5 -1.1 -1.1 -0.   0.1  1.9  5.4 -0.2 -0.3  3.4 -0.5 -3.8 -0.3  4.1  3.9  3.3 -0.4 -0.  -0.2 -2.3 -0.2 -1.3 -1.1 -0.2 -0.1 -0.2  6.1  0.9 -1.6 -1.1 11.6 -0.8  4.4  8.2 -0.2 -0.1 -0.2 -0.4  1.9 -0.2 -0.1  2.  -0.3 -0.   4.4  0.  -0.3 -4.2  1.3 -0.   1.1 -0.2 -0.4 -3.3 -0.3 -0.3 -0.1  1.4  4.6 -2.2 -0.1 -0.2  0.3 -0.7 -0.2 -0.2  0.1 -0.5 -0.3  2.  -3.7 -0.4 -0.3  3.6 -0.1 -0.4  0.4 -0.1 -0.1 -2.7 -0.  -0.1  3.3 -0.7  0.6 -0.  -0.1  0.6 -1.8  0.7 -1.3 -0.1 -0.3 -0.3 -1.1 -0.1  1.   0.6 13.8 -0.  -0.8 -0.2 13.3 -0.6 -0.2 -0.8 -0.9 -0.5  4.9  0.1 -0.2 -0.4 -0.4 -0.1 -0.7  0.2 -0.1 -0.2  0.3 -0.1 -0.   5.8 -0.2  0.9 -0.2 -0.6  1.6 -0.3 -0.1 -0.7 -0.3  1.5 -0.2  0.6 -0.5 -0.1 -0.1 -0.1 -0.8 -0.1 -0.6 -0.3 -0.1 -0.   0.  -0.1 -0.4 -0.1 -1.  -1.1 -0.1  4.9  0.3 -1.9 -0.1 -0.  -2.6 -0.2 -0.4 -0.4 -0.4 -0.1  2.9 -0.1 -0.1 -0.1 -1.2 -3.6  1.3 -0.6 -0.2 -0.3 -0.1 -0.3 -0.2 -0.2 -0.3 -0.1 -3.7  0.1 -0.1 -3.3  0.  -0.  -1.6 -0.2  9.4 -0.9 -0.2  2.6 -0.9 -0.2 -0.9 -0.2 -0.2  0.2 -1.  -0.5 -0.7 -1.3 -0.3  1.4 -0.7 -0.4  0.8 -0.2 -0.8  2.4 -1.6 -0.3 -0.2  0.6 -6.8 -0.1 -2.3 -0.  -0.2 10.4  3.9 -0.3  0.1 -1.3 -0.4  8.1 -0.  -2.2 -0.3  4.7 -3. ]
ty_50sample [[5 1 0 3 7 6 8 2 4 9]
 [7 6 5 2 3 8 0 4 1 9]
 [5 8 1 3 4 2 6 9 7 0]
 [7 6 0 1 8 3 9 4 5 2]
 [1 2 3 6 0 8 7 7 9 4]
 [5 7 9 1 8 0 4 3 6 2]
 [8 3 7 9 1 0 5 2 6 4]
 [9 7 5 2 2 6 0 1 4 3]
 [0 5 8 3 7 6 2 1 9 4]
 [3 9 2 8 0 7 6 4 1 5]]
tt_50sample [[5 1 0 3 7 6 8 2 4 9]
 [7 6 5 2 3 8 0 4 1 9]
 [5 8 1 3 4 2 6 9 7 0]
 [7 6 0 1 8 3 9 4 5 2]
 [1 2 3 6 0 8 7 5 9 4]
 [5 7 9 1 8 0 4 3 6 2]
 [8 3 7 9 1 0 5 2 6 4]
 [9 7 5 8 2 6 0 1 4 3]
 [0 5 8 3 7 6 2 1 9 4]
 [3 9 2 8 0 7 6 4 1 5]]
vm  [ 1.7 -0.5  3.4  4.9 -1.4 -0.2 -0.2 -0.2 -1.2  0.6  9.5 -0.1 -0.2 -0.1  1.4 -1.3 -0.4 -0.3 -0.  -0.5 -1.4 -0.  -0.4 -0.4 -1.1  1.6  0.1 -0.7 -1.2 -1.2  0.8 -0.2  1.4  7.1 -0.2 -0.4  2.8  0.7 -3.2 -0.5  4.3  4.7  1.2 -0.5 -0.  -0.2  0.3 -0.6  5.5 -2.4 -0.3 -0.2 -0.6  9.9  2.6 -0.5 -0.7  8.2 -0.1 -0.3 -0.3 -0.3 -0.7  0.2  1.5 -0.4 -0.2  0.   1.3 -0.1 -0.3  7.7 -0.7 -0.4 -3.9 -0.7 -0.2 -0.3 -0.2 -0.3  8.1  0.5 -0.3 -0.2 -1.6  3.3  3.4 -0.3 -0.1 -0.2  0.1 -0.1 -0.4  1.  -0.7 -0.6 -0.6 -3.2 -0.1 -0.2 -0.3 -0.3 -0.7 -0.1 -0.2 -0.5 -2.6 -0.4 -0.3 -0.4 -0.2 -0.2 -0.2 -0.1  2.3 -4.2  2.2 -0.6  0.1  0.9 -0.2  1.  -0.4 -0.1 -0.   1.8 -0.1 -1.8  2.9  6.9 -0.3 -0.2 -0.1 -0.1  8.6 16.2  0.1  0.2 -0.8 -0.6 -0.4 -0.4  0.2 -0.2 -0.2 -0.6 -0.6 -0.1  6.5 -0.2 -0.6 -0.1  0.6 -0.  -0.2 -0.1  0.7 -0.2 -0.6 -0.6 -0.2 -0.9 -0.1 -0.3 -0.5 -0.5 -0.2 -0.9 -0.5  0.1 -0.2 -0.1 -0.   0.5 -0.2 -1.6 -1.6 -0.6  3.7 -0.  -2.1 -0.2 -0.1 -2.  -0.1 -0.4 -0.2 -0.4 -0.1  3.7 -0.4 -0.2 -0.4 -0.8  6.7 -0.6 -1.2 -0.7  0.  -0.2 -0.1 -0.3 -0.2  0.5 -0.5 -2.6 -0.  -0.4 -5.8 -0.1 -0.4 -2.6 -0.7 -2.1 -0.9  1.5  4.  -1.3 -0.3 -0.3 -0.1 -0.3  0.6 -1.   0.3 -2.3 -0.2 -0.6  1.3  0.9 -0.3  3.9 -0.1 -0.6  0.3 -1.1  1.4 -0.6  0.6 -4.9 -0.  -1.9 -0.2 -0.2 -1.3  1.2  0.8 -0.5 -0.9 -0.5 -2.3 -0.2 -1.7  0.  -0.2 -1.3]
vy_50sample [[0 5 6 6 3 7 9 4 8 1]
 [2 5 0 0 4 3 8 1 9 7]
 [8 7 6 1 0 2 9 3 5 4]
 [2 6 4 3 8 0 7 9 5 1]
 [1 6 7 2 3 0 4 9 5 8]
 [5 0 2 9 9 4 7 8 6 1]
 [6 7 3 4 0 8 1 9 2 5]
 [6 7 4 2 1 5 9 0 8 3]
 [1 4 0 0 3 7 5 2 8 6]
 [8 5 4 9 1 2 6 7 0 3]]
vt_50sample [[0 5 6 2 3 7 9 4 1 8]
 [2 5 6 0 4 3 8 1 9 7]
 [8 7 6 1 2 0 9 3 5 4]
 [2 6 4 3 8 7 0 9 5 1]
 [1 6 7 2 3 4 0 9 5 8]
 [5 0 2 3 9 4 7 8 6 1]
 [6 7 3 4 0 8 1 9 2 5]
 [6 7 2 4 1 5 9 0 8 3]
 [1 4 9 0 3 7 5 2 8 6]
 [8 5 4 9 1 2 6 7 0 3]]
Epoch 55410: Training cost= 0.2227, Training acc= 0.8671, Validation cost= 0.2317, Validation acc= 0.8671
Epoch 55420: Training cost= 0.2348, Training acc= 0.8671, Validation cost= 0.2392, Validation acc= 0.8671
Epoch 55430: Training cost= 0.2759, Training acc= 0.8671, Validation cost= 0.2212, Validation acc= 0.8671
Epoch 55440: Training cost= 0.2598, Training acc= 0.8671, Validation cost= 0.2507, Validation acc= 0.8672
Epoch 55450: Training cost= 0.2787, Training acc= 0.8671, Validation cost= 0.2322, Validation acc= 0.8672
Epoch 55460: Training cost= 0.2171, Training acc= 0.8671, Validation cost= 0.2044, Validation acc= 0.8672
Epoch 55470: Training cost= 0.2171, Training acc= 0.8671, Validation cost= 0.2297, Validation acc= 0.8672
Epoch 55480: Training cost= 0.2012, Training acc= 0.8671, Validation cost= 0.2368, Validation acc= 0.8672
Epoch 55490: Training cost= 0.2527, Training acc= 0.8671, Validation cost= 0.2208, Validation acc= 0.8672
Epoch 55500: Training cost= 0.2308, Training acc= 0.8671, Validation cost= 0.2632, Validation acc= 0.8672
tm  [-0.4 -0.2 -0.4 15.2 -1.5 -0.  -0.2 -0.1 -0.7 -0.5  8.8  0.1 -0.1 -0.1 -3.1 -0.3 -0.5 -0.2 -0.1 -1.2 -1.8 -0.1 -0.9 -0.1 -0.8  1.1 -0.3 -0.  -1.3 -4.6  0.1 -0.2 -0.   6.6 -0.1  0.7  2.5  5.2 20.6 -0.7  4.2 -3.4 -1.   0.5 -0.2 -0.3  8.2 -0.2 -0.3 -4.8 -0.1 -0.   0.6 -2.5  0.1  4.  -0.5 -0.6  7.1 -1.8 -0.6 -0.9 -0.1 -0.3 -0.2 -0.3 -0.  -0.4 -0.  -0.3  0.2  2.4  0.4 -0.6  3.   1.2 -0.1 -0.3 -0.3 -0.  29.  -0.2 -0.2 -0.2 -0.3 -2.6 -0.5 -0.1 -0.1 -0.5 -0.6 -0.2 -0.  -0.4 -0.5 -0.  -0.2 -1.3 -0.5 -0.5  3.2 -1.5 -0.3 -0.1  0.2 -0.2  0.6 -0.1  0.4 -1.8 -0.7  0.1 -0.1 -0.4  3.2 -1.5  2.5 -0.4 -0.3 -0.6 -0.3  6.3 -0.4  0.1 -0.2 -4.   0.2  8.5  7.2  0.4 -0.4 -0.2  0.  -0.3 -1.1  5.  -0.4 -0.4  0.8 -0.4 -0.3 -0.6 -0.6 -0.4  0.6 -0.1 -0.1 -0.2 -0.2 -0.4 -1.7  0.2 -1.4 -0.6 -0.  -0.1 -0.4 -0.3  2.7  0.7  0.2 -1.6 -0.2 -0.   0.3 -0.1 -0.1 -0.2 -0.2 -0.1 -0.2 -0.2 -0.2 -0.1 -0.2  0.5 -0.3  0.2 -1.5 -0.1 -0.  -0.3  0.4 -1.6  0.  -0.1  0.  -0.3  0.8 13.   0.  -0.  -0.  -1.2  6.4 -2.5 -0.  -1.1  0.3 -0.  -0.3 -0.2 -0.  -0.3  0.1  3.2 -0.3 -0.2 -0.9  0.5 -0.2 -1.3 -0.6  2.3 -0.3  0.2 -0.9 -1.3 -0.4  1.4 -0.3 -0.1 -0.4 -0.7 -2.4 -1.2 -1.   0.8  1.4 -0.6 -0.2 -1.1  0.6 -0.2  0.4  1.1 -0.1 -0.   1.4 23.6 -0.   6.1 -0.1  0.5 -6.  -2.7 -0.2  0.4 -1.3 -0.4 -7.3  0.5 11.5 -0.2  4.7  1.8]
ty_50sample [[9 3 0 1 2 4 7 5 6 8]
 [7 4 1 5 3 0 8 2 9 6]
 [1 5 0 8 9 7 3 2 6 4]
 [0 7 1 1 5 8 3 4 2 9]
 [0 4 6 5 8 2 7 1 9 3]
 [8 0 0 4 1 1 9 5 2 3]
 [7 1 9 0 6 4 5 8 2 3]
 [9 1 0 7 4 3 6 8 2 5]
 [1 2 5 3 6 4 7 8 0 9]
 [7 8 2 3 9 4 1 6 5 0]]
tt_50sample [[9 3 0 1 2 4 7 5 6 8]
 [7 4 1 3 5 0 8 2 9 6]
 [1 5 0 8 9 7 3 2 6 4]
 [0 7 6 1 5 8 3 4 2 9]
 [0 4 6 5 8 7 2 1 9 3]
 [8 7 4 6 0 1 9 5 2 3]
 [7 1 9 0 6 4 5 8 2 3]
 [9 1 0 7 4 3 8 6 2 5]
 [1 2 5 3 6 4 7 8 0 9]
 [7 8 2 3 9 4 1 6 5 0]]
vm  [-0.4 -0.3  7.6  8.  -1.3 -0.1 -0.4 -0.  -0.5 -1.5  6.5 -0.1  0.1 -0.3  4.9  4.7  0.4 -0.3  0.3 -0.7 -1.2 -0.1 -0.6 -0.1 -1.1  0.3 -0.  -0.2  0.8 -0.3 -0.  -0.2 -0.   9.6 -0.2 -0.1  2.4  3.3  4.4 -0.1  1.4 -0.3  1.7 -0.6 -0.1  0.3  0.7 -0.2  1.5 -3.3 -0.2 -0.  -0.3  2.5 -1.  -0.6 -0.9  9.2 -0.6  2.6  1.4 -0.4 -0.3  0.3  0.5  1.2 -0.1 -0.3  2.1 -0.   0.1 -1.9 -0.3  0.6 -2.  -0.  -0.2 -0.  -0.2 -0.   7.  -0.5 -0.3 -0.2 -0.6 -0.3 -0.6 -0.1 -0.2 -0.3 -0.7 -0.  -0.2 -0.1 -0.5 -0.3  0.6 -2.5 -0.5 -0.2  4.6 -0.7 -0.4  0.2 -0.1  0.4 -1.5 -0.   1.1 -1.  -0.2 -0.2 -0.  -0.5 -1.8 14.3 -0.1 -1.  -0.1 -0.3 -0.2  3.4  0.   1.7 -0.1  5.7 -0.1  0.1  1.4  8.8 -0.1 -0.3 -0.5 -0.6 -3.   3.4 -0.2 -0.1 -0.1 -0.3 -0.5 -0.1 -0.2 -0.4 -0.  -0.1 -0.  -0.   3.4 -0.1 -1.   0.3 -0.2 -0.4 -0.2 -0.2 -0.3 -0.3  1.  -0.2 -0.6 -0.3 -0.2 -0.1 -0.3 -0.3 -0.  -0.3 -0.2 -0.1 -0.1 -0.2 -0.1 -0.2  0.1 -0.5 -0.2 -0.3 -0.4  0.2 -2.3  1.3 -0.2 -2.  -0.  -0.2  0.4 -0.7 -0.1  1.   0.8  0.3 -0.1 -1.   0.7 -0.4 -0.4  5.8 -0.2 -0.  -0.1 -0.1 -0.3 -0.2  0.6 -1.9  0.1 -0.2 -3.5  0.9 -0.1  2.5 -0.6 -0.2 -0.3 -0.5  1.4 -1.  -0.4 -0.4 -0.1 -0.2  0.7 -0.9 -1.9  3.8 -0.4 -0.  -0.1  1.5 -0.4  0.7 -0.1 -0.6 -0.4 -1.7 -0.3 -0.1  1.3 -2.7 -0.1 -1.2 -0.2 -0.2 -1.  -0.  -0.3 -0.2 -1.  -0.  -1.9  0.2  2.5 -0.   4.2 -1.6]
vy_50sample [[3 5 7 2 1 9 6 8 4 0]
 [4 9 5 3 2 8 0 0 7 6]
 [1 3 5 2 8 7 4 9 0 6]
 [7 8 4 3 6 5 0 1 2 9]
 [0 0 3 8 2 9 7 4 6 1]
 [1 5 2 3 7 4 8 6 9 0]
 [1 2 3 0 8 6 7 9 4 5]
 [7 8 3 6 2 5 4 1 0 9]
 [1 8 0 9 7 6 2 4 3 5]
 [5 8 3 7 1 0 2 6 4 9]]
vt_50sample [[3 5 7 2 1 9 6 8 4 0]
 [4 9 5 3 8 2 0 1 7 6]
 [1 3 5 2 8 7 4 9 0 6]
 [7 8 4 3 6 0 5 1 2 9]
 [0 3 5 8 2 9 7 6 4 1]
 [1 5 2 3 7 4 8 6 9 0]
 [1 2 3 0 8 6 7 9 4 5]
 [7 8 3 6 2 5 4 1 0 9]
 [1 8 0 9 7 6 2 4 3 5]
 [5 8 3 7 1 0 2 6 4 9]]
Epoch 55510: Training cost= 0.1975, Training acc= 0.8672, Validation cost= 0.2552, Validation acc= 0.8672
Epoch 55520: Training cost= 0.2303, Training acc= 0.8672, Validation cost= 0.2077, Validation acc= 0.8672
Epoch 55530: Training cost= 0.2279, Training acc= 0.8672, Validation cost= 0.2399, Validation acc= 0.8672
Epoch 55540: Training cost= 0.2187, Training acc= 0.8672, Validation cost= 0.2674, Validation acc= 0.8672
Epoch 55550: Training cost= 0.2328, Training acc= 0.8672, Validation cost= 0.2217, Validation acc= 0.8672
Epoch 55560: Training cost= 0.2412, Training acc= 0.8672, Validation cost= 0.2376, Validation acc= 0.8672
Epoch 55570: Training cost= 0.2315, Training acc= 0.8672, Validation cost= 0.2357, Validation acc= 0.8672
Epoch 55580: Training cost= 0.2382, Training acc= 0.8672, Validation cost= 0.2731, Validation acc= 0.8673
Epoch 55590: Training cost= 0.2119, Training acc= 0.8672, Validation cost= 0.2386, Validation acc= 0.8673
Epoch 55600: Training cost= 0.2512, Training acc= 0.8672, Validation cost= 0.2264, Validation acc= 0.8673
tm  [-0.9  0.3 -0.5  1.6 -2.  -0.1 -0.3 -0.  -0.9 -0.6 -4.2 -0.2 -0.1  0.4 -0.2 -1.3  1.1 -0.2 -0.4  0.3 -1.7 -0.3 -0.2 -0.1 -1.4  3.  -0.3 -0.3 -0.8 -0.  -0.6  0.  -0.3 -4.  -0.  -0.1  2.6 -2.2 -3.8 -0.2 -0.1 -1.5  1.1 -1.   0.5 -0.  -0.8 -0.3  0.8 -0.3 -0.1 -0.1  0.3 -0.3 -0.7 -0.1 -0.5  3.6 -1.5  5.4  1.9 -0.1 -0.1 -0.1 -0.5 -0.2 -0.4 -0.2  1.6 -0.4 -0.   1.2  1.   0.6 -3.2 -0.1 -0.1  1.  -0.3 -0.3 -3.2 -0.5 -0.1  0.4 -0.5 -1.5 -0.4 -0.2 -0.2 -0.3 -0.3 -0.1 -0.2 -0.1 -0.4 -0.4  0.4 -3.  -0.2 -0.3  0.8 -1.7 -0.5  0.8 -0.2 -0.1 -1.9 -0.  -1.1 -0.3 -0.6 -0.3 -0.1 -0.1 -0.  -0.4 -0.8 -0.8 -0.2 -0.4 -0.1  0.5 -0.4 -0.1 -0.1 -0.2 -0.   3.3 -1.5  9.9 -0.3 -0.4 -0.4 -0.2 14.3  6.4 -0.3 -0.3  0.1 -0.2  0.8 -0.6  0.6 -0.2 -0.1  0.4 -0.2 -0.1  4.5  0.1 -0.3 -0.1  2.6  2.4 -0.1 -0.1 -0.7 -0.2 -0.9 -0.2 -0.6  1.4 -0.3 -0.  -0.3 -0.4  0.1 -0.3 -0.  -0.2 -0.1 -0.3 -0.  -0.2 -0.2 -0.3 -1.  -0.   3.7  0.2 -0.7  0.1 -0.2 -2.4 -0.  -0.3  0.1 -0.3 -0.2  0.2 -0.1 -0.2 -0.2 -1.2  0.1  6.4 -0.2 -0.1 -0.1 -0.2 -0.4 -0.2 -0.1 -0.4  0.7 -1.9 -0.2  0.2  5.6 -0.1 -0.2 -0.8 -0.9  4.1 -0.6 -0.4  5.4 -0.8 -0.2 -0.3 -0.1 -0.  -0.3 -1.   1.   1.6 -2.2 -0.1 -0.8 -0.3  1.4  0.3 -0.1  0.6  0.   0.3 -0.5  0.4  2.7 -0.3 -0.1 -0.5 -0.  -0.3 10.9 -0.5 -0.7 -0.1 -1.3 -0.2  7.3  0.5 -2.2 -0.4  9.4 -2. ]
ty_50sample [[6 3 8 0 1 5 4 9 7 2]
 [8 7 6 9 3 5 0 1 4 2]
 [8 1 7 9 0 6 5 4 2 3]
 [7 1 0 5 4 3 8 9 6 2]
 [2 9 6 0 5 5 3 7 1 4]
 [7 8 1 2 3 3 0 6 9 5]
 [8 2 4 0 6 9 7 5 1 3]
 [5 3 7 6 9 4 8 1 2 0]
 [9 7 0 1 6 5 2 3 4 8]
 [9 3 7 0 6 8 4 2 1 5]]
tt_50sample [[6 3 8 0 1 5 4 9 7 2]
 [8 7 6 9 3 5 0 1 4 2]
 [8 1 7 9 0 6 5 4 2 3]
 [7 1 0 5 4 3 8 9 6 2]
 [2 9 6 0 5 8 3 7 1 4]
 [7 8 1 2 3 0 4 6 9 5]
 [8 2 4 0 6 9 7 5 1 3]
 [5 3 7 6 9 4 8 1 2 0]
 [9 7 0 1 6 5 2 3 4 8]
 [9 3 7 0 6 8 4 2 1 5]]
vm  [-0.1 -0.4  3.1 -6.  -1.7 -0.5 -0.7  0.3 -0.4  0.1 -5.3 -0.2 -0.3 -0.4 16.6  2.2 -0.   2.3  1.4 -0.7 -1.  -0.4  0.4 -0.2 -1.1 -0.5 -0.4 -0.4  0.2  7.4  0.2 -0.2  0.5  4.  -0.  -0.3 -0.5  0.5 -1.3 -0.7 -0.7 -3.  -0.5  0.7 -0.4 -0.3 -0.9 -0.4  6.1  6.5 -0.2 -0.3 -1.   2.4 -2.1 -1.8 -0.5 -4.  -0.5 -0.5 -0.2 -0.3 -0.3  0.5 -1.1 -0.2 -0.1 -0.5 -0.4 -0.1 -0.  -1.7 -0.8  0.3 -5.9  0.7 -0.2 -0.5 -0.1  0.3 -6.7 -0.7 -0.4 -0.7 -2.1 -3.1  9.4 -0.3 -0.  -0.7 -0.7 -0.5 -0.3 -0.  -0.7 -0.6 -0.2 -3.2 -0.5 -0.8 -0.3  4.1 -0.3 -0.2 -0.4 -0.  -2.3  0.2 -1.2 -1.   1.5  0.   0.1 -0.2 -0.4  9.1 -0.   0.7 -0.3 -0.6 -0.6  0.9 -0.9 -1.  -0.1 20.2  0.3  0.2 -1.5  7.7 -0.2 -0.1 -0.1 -0.  -4.7 -3.6 -0.6 -0.4 -0.1 -0.3 -0.9  0.1 -0.8 -0.4 -0.2 -0.5 -0.4 -0.4 -3.5 -0.5  6.9 -0.2  1.2 -1.  -0.3 -0.1 -0.9 -0.5 -0.1 -0.1  0.8 -1.2  0.1 -0.1 -0.2  2.3 -0.5 -0.2 -0.6 -0.3 -0.1 -0.2 -0.5 -0.7  0.4  3.4 -0.8 -0.1  0.6 -0.2  2.5  0.1  0.9 -0.9 -0.3 -1.2  0.3 -0.6 -0.1 -1.9  0.2 -0.3 -0.  -1.3  5.7  4.3 -0.6  0.5 -0.5 -0.4  0.4 -0.2  2.  -0.4 -0.2 -1.8  0.2 -0.2 13.8  0.8 -1.   1.8 -0.6 -2.1  3.3 -0.5 -1.6 -0.1 -0.8 -0.7 -0.1 -0.3 -0.2 -1.3 -0.7  2.  -0.7  1.1  1.1  0.6 -0.5  3.  -0.4 -0.1 -2.3 -0.4 -0.4 -0.9 -0.8  8.2  0.2  1.6 -0.3 -0.4 18.8  1.2 -0.3 -0.5 -0.7 -0.1 17.6  0.3 -0.9  0.3  2.2 -1.2]
vy_50sample [[7 4 8 3 3 2 9 0 1 1]
 [9 8 3 5 6 7 1 1 2 4]
 [5 1 7 3 0 2 8 6 9 9]
 [2 8 0 7 4 3 1 5 9 6]
 [3 9 1 7 4 8 6 5 0 2]
 [4 8 5 9 6 1 7 0 2 3]
 [5 7 3 0 4 9 2 1 6 8]
 [2 4 8 7 6 5 9 3 1 0]
 [7 8 0 9 3 4 5 2 6 1]
 [7 5 6 0 3 4 9 8 1 2]]
vt_50sample [[7 4 8 3 6 2 9 0 1 5]
 [9 8 3 5 6 7 1 0 2 4]
 [5 1 7 3 0 2 8 6 4 9]
 [2 8 0 7 4 3 1 5 9 6]
 [3 9 1 7 4 6 8 5 0 2]
 [4 8 5 9 6 1 7 0 2 3]
 [5 7 3 0 9 4 2 1 6 8]
 [2 4 8 7 6 5 9 3 1 0]
 [7 8 0 9 3 4 5 2 6 1]
 [7 5 6 0 3 9 4 8 2 1]]
Epoch 55610: Training cost= 0.2049, Training acc= 0.8672, Validation cost= 0.2026, Validation acc= 0.8673
Epoch 55620: Training cost= 0.1973, Training acc= 0.8672, Validation cost= 0.2132, Validation acc= 0.8673
Epoch 55630: Training cost= 0.2031, Training acc= 0.8673, Validation cost= 0.2057, Validation acc= 0.8673
Epoch 55640: Training cost= 0.2254, Training acc= 0.8673, Validation cost= 0.2075, Validation acc= 0.8673
Epoch 55650: Training cost= 0.2297, Training acc= 0.8673, Validation cost= 0.2355, Validation acc= 0.8673
Epoch 55660: Training cost= 0.2370, Training acc= 0.8673, Validation cost= 0.2801, Validation acc= 0.8673
Epoch 55670: Training cost= 0.2171, Training acc= 0.8673, Validation cost= 0.2225, Validation acc= 0.8673
Epoch 55680: Training cost= 0.2455, Training acc= 0.8673, Validation cost= 0.2723, Validation acc= 0.8673
Epoch 55690: Training cost= 0.2368, Training acc= 0.8673, Validation cost= 0.2405, Validation acc= 0.8673
Epoch 55700: Training cost= 0.1726, Training acc= 0.8673, Validation cost= 0.2123, Validation acc= 0.8673
tm  [-0.3 -0.5  7.2  9.  -0.7 -0.1 -0.1 -0.1 -0.8 -0.6  9.5 -0.3 -0.4 -0.5  3.3 -0.2 -0.2 -0.2  0.4 -0.8 -1.3 -0.1 -0.6 -0.4 -0.9  0.9  0.2 -0.4 -1.   3.4  0.2 -0.6 -0.4 19.1 -0.1 -0.1  2.6 -0.7 -1.3 -0.3 -0.3 -2.1 -0.1 -1.3 -0.1 -0.2  3.6 -0.2  4.3 -3.1 -0.2 -0.1 -0.   0.3  0.6 -0.6 -0.4 -0.7 -0.7 -2.3 -0.7 -0.1 -0.2  0.3 -0.8 -0.2 -0.2 -0.3  1.4 -0.1 -0.1  2.6 -0.3  0.3 -0.8 -0.  -0.  -0.1  0.4 -0.2 24.5 -0.1 -0.1 -0.2 -1.  -1.3  2.8 -0.5 -0.2 -0.3 -0.1 -0.2 -0.2  0.9 -0.4 -0.2 -0.1 -1.8 -0.  -0.3  2.4  4.3 -0.2 -0.1 -0.3 -0.7 -0.7 -0.2 -0.3 -1.7 -0.2 -0.1 -0.2 -0.4  1.3 -1.  -0.8 -0.7  0.5 -0.4 -0.1  5.1  0.1  0.2 -0.3  4.5 -0.   1.8 -1.4 -0.6  0.9 -0.2 -0.1 -0.2  4.8 23.  -0.4 -0.3  1.  -0.1 -0.4 -0.7 -0.3  0.2 -0.1 -0.  -0.2 -0.3 -2.6 -0.1 -1.1 -0.1 -0.6 -0.  -0.3  0.2 -0.4 -0.4 -1.3  1.  -0.1  1.9  0.1  0.  -0.2  0.6 -0.2 -0.3 -0.1 -0.3 -0.  -0.2 -0.2 -0.3 -0.3  4.3 -0.  -0.   0.7  0.   0.9 -0.1 -0.4 -0.9  0.1 -0.5  0.4 -0.6 -0.4 -0.9 -0.3  0.2 -0.2 -0.6  7.9  5.3 -0.2 -0.7 -0.1 -0.2 -0.2 -0.1 -0.3 -0.4 -0.5 -0.3 -0.1 -0.2 -1.1 -0.1 -0.7 -1.1 -0.6 -0.7 -0.2 -0.3  6.1 -1.1 -0.2 -0.1 -0.  -0.3 -0.2 -0.9  3.5 -1.4 -0.4  0.1 -1.2  0.6  1.1 -0.6 -0.3 -0.4  1.3 -1.5 -0.2 -0.1  1.3 19.4 -0.1  5.4 -0.2  0.2 -5.  -1.3 -0.3 -0.4 -0.8 -0.5 -6.3 -0.  -0.8 -0.1  0.7  3.9]
ty_50sample [[6 7 0 0 2 3 4 1 5 8]
 [4 5 2 3 0 7 9 8 6 1]
 [2 8 1 6 3 9 5 7 0 4]
 [7 9 4 5 6 2 2 0 3 1]
 [3 8 6 5 9 1 1 2 7 4]
 [6 2 0 9 3 1 7 8 4 5]
 [3 9 4 0 2 7 7 8 1 5]
 [1 0 6 2 3 8 7 4 9 5]
 [8 3 4 7 1 0 9 9 6 5]
 [2 5 0 9 3 8 6 1 7 4]]
tt_50sample [[6 7 0 9 2 3 4 1 5 8]
 [4 5 2 3 0 7 9 8 6 1]
 [2 8 1 6 9 3 5 7 0 4]
 [7 9 4 5 6 2 8 0 3 1]
 [3 8 6 5 9 1 0 2 7 4]
 [6 2 0 9 3 1 7 8 4 5]
 [3 9 4 0 2 6 7 8 1 5]
 [1 0 6 2 3 8 7 4 9 5]
 [8 3 4 7 1 0 2 9 6 5]
 [2 0 5 9 3 8 6 1 7 4]]
vm  [-0.6 -0.3 -0.4 -2.4 -2.2  0.2 -0.6 -0.2 -1.4 -0.3  7.2 -0.1 -0.2 -0.3  6.3 -1.5 -0.4 -0.5 -0.2  0.5 -1.4 -0.2  1.3 -0.2 -1.5  3.6  0.  -0.4 -1.8 -1.   1.8 -0.1 -0.4  9.8 -0.3 -0.   4.3  3.6  0.7 -0.5  4.4  3.1  1.   3.9 -0.1 -0.  -0.7 -0.7 -0.2  3.7 -0.1 -0.1 -0.3  6.4  3.1 -0.9 -1.1 -1.6  1.3 -2.6  4.9 -0.4 -0.3  0.1 -0.2  0.4 -0.2 -0.2  2.  -0.3  0.1  9.6  0.2  0.3 -2.6 -0.8 -0.2 -0.6 -0.  -0.4  4.7 -0.  -0.2 -0.  -0.3  4.2  3.  -0.2 -0.2 -0.2 -0.1 -0.2 -0.1 -0.4 -0.4 -0.1 -0.8 -3.1  0.1 -0.3  0.6  6.5 -0.5 -0.  -0.3 -0.1 -1.4  0.   0.1 -0.1 -0.9 -0.2 -0.1 -0.   3.9 -4.4 -0.1 -0.9 -0.1 -0.1  0.3  0.7 -0.2  0.1  0.3  8.4 -0.  -0.8  0.8 -0.6 -0.4 -0.1 -0.3 -0.6 -2.6  4.4 -0.2  0.2 -0.3 -0.2 -0.2 -1.1 -0.1 -0.3 -0.2 -0.1 -0.2 -0.1 -0.7 -0.1  1.7 -0.1 -0.9 -0.3 -0.1  0.2  0.2 -0.3  1.5 -0.2  0.5 -0.9  0.4 -0.1 -0.3 -0.9 -0.1 -0.6 -0.1 -0.2 -0.  -0.2 -0.   0.3 -0.1  0.9 -0.1 -0.2  0.4 -0.1 -0.8 -0.4 -0.3 -2.5 -0.1 -0.1 -0.2 -0.2 -0.2  2.7 -0.2 -0.3 -0.3 -1.  -1.4 -0.  -0.6 -1.2 -0.1 -0.2 -0.  -0.1 -0.2 -0.1  0.2 -2.4  0.1 -0.2 -1.9 -0.  -0.3 -3.2 -0.9  4.8 -1.2 -0.5 -1.9 -1.3 -0.3  1.1 -0.1 -0.2 -0.5 -1.4  2.  -1.9 -0.2  0.6 -0.1 -0.3 -0.3 -0.3 -0.2 -0.2  4.4  1.6  0.9 -0.2  3.  -1.2 -0.1 -0.8 -0.1  0.4 -0.4  1.1 -0.1  1.8 -1.1 -0.6 -1.2 -0.   0.7 -0.  -1.1  4.3]
vy_50sample [[0 4 1 2 2 5 6 6 8 3]
 [8 9 5 0 6 3 2 1 4 7]
 [0 6 9 1 5 8 2 3 7 4]
 [8 2 5 1 9 7 4 3 0 6]
 [3 4 1 6 9 0 7 2 8 5]
 [0 3 9 4 7 8 2 6 1 5]
 [7 3 9 2 0 4 8 6 1 5]
 [0 5 9 6 4 1 7 2 8 3]
 [5 3 8 4 6 0 2 7 9 1]
 [3 4 6 2 1 5 9 8 0 7]]
vt_50sample [[0 4 1 2 7 5 6 9 8 3]
 [8 9 5 0 6 3 2 1 4 7]
 [0 6 9 1 5 8 2 3 7 4]
 [8 2 5 9 1 7 4 3 0 6]
 [3 4 1 6 9 0 7 2 8 5]
 [0 3 9 4 7 8 2 6 1 5]
 [7 3 9 2 0 4 8 6 1 5]
 [0 5 9 6 4 1 7 2 8 3]
 [5 3 8 4 6 0 2 7 9 1]
 [3 4 6 2 1 5 9 8 0 7]]
Epoch 55710: Training cost= 0.2130, Training acc= 0.8673, Validation cost= 0.2056, Validation acc= 0.8673
Epoch 55720: Training cost= 0.1951, Training acc= 0.8673, Validation cost= 0.2848, Validation acc= 0.8674
Epoch 55730: Training cost= 0.2484, Training acc= 0.8673, Validation cost= 0.3383, Validation acc= 0.8674
Epoch 55740: Training cost= 0.2158, Training acc= 0.8673, Validation cost= 0.2761, Validation acc= 0.8674
Epoch 55750: Training cost= 0.2092, Training acc= 0.8674, Validation cost= 0.2685, Validation acc= 0.8674
Epoch 55760: Training cost= 0.2410, Training acc= 0.8674, Validation cost= 0.1904, Validation acc= 0.8674
Epoch 55770: Training cost= 0.2091, Training acc= 0.8674, Validation cost= 0.2776, Validation acc= 0.8674
Epoch 55780: Training cost= 0.2518, Training acc= 0.8674, Validation cost= 0.2856, Validation acc= 0.8674
Epoch 55790: Training cost= 0.2288, Training acc= 0.8674, Validation cost= 0.2945, Validation acc= 0.8674
Epoch 55800: Training cost= 0.2282, Training acc= 0.8674, Validation cost= 0.2613, Validation acc= 0.8674
tm  [-1.3 -0.   3.  -1.2 -2.1 -0.1 -0.3 -0.2 -0.8 -0.1 -4.4 -0.3 -0.1 -0.3  7.2 -1.2 -0.5  0.1  1.4 -1.4 -0.8 -0.5 -0.5 -0.2 -1.  -0.7 -0.6  1.6 -0.8 -0.2  2.7 -0.3 -0.9 11.9 -0.2 -0.1  1.5 -0.4 14.1 -0.3 -1.1  4.  -0.7  0.5 -0.3 -0.5  5.7 -0.3 -2.2  8.5 -0.2 -0.2 -0.8 -3.5 -1.3 -1.  -0.6 -1.   1.3 -1.7  4.1 -0.6 -0.5 -0.2  0.7 -0.6 -0.3 -0.3 -0.7 -0.1 -0.1  0.4 -0.4 -0.5 -1.7 -0.4 -0.2 -1.   0.  -0.2  5.4 -0.8  0.1 -0.7  2.2  4.5 -0.6 -0.3  0.1 -0.5 -0.3 -0.1 -0.4 -0.9 -0.5  1.4 -0.7 -2.2 -0.3 -0.5  1.4  7.1 -0.3 -0.3  0.1  0.4 -1.6  0.5 -1.1 -2.2  1.2 -0.2 -0.2 -0.5  2.3  0.6 -1.  -0.3 -0.1 -0.6 -0.4  7.9  0.8  1.1 -0.1  8.3 -0.  11.8  0.3 -3.4 -0.1 -0.4 -0.2 -0.3 -6.  -2.4 -0.   0.3 -0.1 -0.6  0.  -0.2 -0.4 -0.2 -0.2 -0.  -0.3 -0.2 -1.1 -0.   1.2 -0.  -1.  -0.5 -0.1 -0.2  0.4 -0.6 -0.1 -0.4 -1.1 -1.  -0.2 -0.2 -0.3  3.5  1.6  1.3 -0.1 -0.2 -0.1 -0.1 -0.5 -0.6 -0.2  2.2  1.2 -0.4 -1.7 -0.2 -1.7 -0.1 -0.  -1.5 -0.1 -0.  -0.1 -0.2 -0.3  0.4 -0.4 -0.3 -0.4 -1.4 -1.3  0.2 -0.2 -0.8 -0.5 -0.1 -0.5 -0.3 -0.  -0.1 -0.4 -1.5 -0.1 -0.2 -1.  -0.2 -0.4 -0.5 -0.8  7.6  1.6 -0.7 -1.8 -1.5 -0.4 -0.1 -0.2  0.1 -0.5 -1.   2.9 -0.5 -1.3  2.  -0.2 -0.3 -1.1  0.8 -0.3 -0.3 -0.5 -0.4 -0.4 -0.6  0.9  0.3 -0.  -0.5 -0.  -0.2 -0.6 -0.5  0.4 -0.2 -0.9  0.9 -1.5 -0.   7.7 -0.1  2.  13. ]
ty_50sample [[1 7 4 5 0 8 8 6 3 2]
 [9 5 6 7 0 4 1 3 2 8]
 [4 2 7 6 0 3 5 1 9 9]
 [8 5 2 9 1 7 6 0 3 4]
 [5 1 3 4 2 9 0 7 6 8]
 [5 9 2 3 4 8 6 0 1 7]
 [7 8 5 4 1 3 2 6 0 9]
 [8 5 3 1 4 0 6 7 7 2]
 [8 2 6 4 3 0 9 5 1 7]
 [6 1 8 5 0 7 2 3 4 9]]
tt_50sample [[1 7 4 5 0 9 8 6 3 2]
 [9 5 6 7 0 4 3 1 2 8]
 [4 2 7 6 0 3 5 1 9 8]
 [8 5 2 1 9 7 6 0 3 4]
 [5 1 3 4 2 9 0 7 6 8]
 [5 9 2 3 4 8 6 0 1 7]
 [7 8 5 4 1 3 2 0 6 9]
 [8 5 3 1 4 0 6 7 9 2]
 [8 2 6 4 3 0 9 5 1 7]
 [6 1 8 5 0 7 2 3 4 9]]
vm  [ 0.1  0.   6.1 17.8 -1.6  0.4 -0.2 -0.2 -0.5  2.2 -8.3 -0.1  0.3 -0.2 -0.2 -1.2 -0.2 -0.3 -1.  -1.8 -1.2 -0.3  2.2 -0.3 -0.5 -0.6 -0.3 -0.5 -0.4  3.4 -1.3 -0.6 -0.1 -2.3 -0.   0.4  2.  -0.5 17.7 -0.4  2.4  3.8  1.3  1.1 -0.1  0.1  9.4 -0.   3.9  5.1 -0.2 -0.4 -0.6 -4.1 -1.1 -0.2 -0.5  8.3 -2.6  7.6 -1.8 -0.8 -0.8 -0.1  0.7 -0.9 -0.2 -0.2 -0.1 -0.1 -0.2 -0.  -0.4 -0.9 -0.3 -0.8 -0.3  0.9 -0.1  1.3 -1.3  0.3 -0.4 -0.3 -1.5  2.4  3.6 -0.1 -0.  -0.5 -0.1 -0.  -0.   0.8 -0.9  0.1 -0.2 -1.1  1.6 -0.5 -0.8 -0.3  0.3 -0.2 -0.2 -0.4 -1.  -0.2 -2.1 -1.7  0.4 -0.2 -0.3 -0.1 -0.8 -0.3 -0.7 -0.7 -0.4 -0.7 -0.2  6.3 -0.2 -1.2 -0.2 -0.4 -0.2 13.2 -2.2  0.9  0.6 -0.4 -0.  -0.  -3.7 -6.6 -0.2 -0.2 -0.2  0.2  0.3 -0.2  0.2  0.3 -0.2 -0.5 -0.  -0.   5.5 -0.  -2.4 -0.   2.1 -0.1 -0.  -0.3 -0.1  1.1 -0.2 -0.5 -0.3 -0.8 -0.4 -0.2 -0.2  2.3 -0.1 -0.1  0.  -0.2 -0.   0.2 -0.1  0.2  0.3 -0.8 -0.2 -0.4 -1.9 -0.  -2.5 -0.7 -0.8 -1.3 -0.  -0.4 -0.1 -0.4 -0.6 -0.7 -0.3 -0.1 -0.4 -0.6 14.5  8.8 -0.   2.6 -0.3 -0.  -0.2  0.1 -0.3 -0.4  0.3 -0.1 -0.2 -0.1  1.9 -0.1 -1.1 -0.8 -0.6 -1.6 -0.7 -0.6 -0.5 -1.1 -0.2 -0.5 -0.2 -0.1 -1.  -0.8 -1.6  0.4 -1.5 -0.6 -0.4  0.9 -0.5 -0.   0.   0.4 -0.9 -0.9 -0.2 -0.3  1.9 -0.7 -0.1 -0.8  0.   0.   5.6 -1.8 -0.4 -0.4 -0.8 -0.2  2.2 -0.3 10.1 -0.3  9.7  1.5]
vy_50sample [[8 5 3 9 0 7 4 6 1 2]
 [4 7 8 6 5 3 1 0 9 2]
 [8 3 1 9 2 0 7 5 6 4]
 [2 9 3 7 6 5 4 1 8 0]
 [0 8 4 5 3 7 1 6 9 2]
 [4 0 1 8 2 5 7 9 3 6]
 [8 3 4 5 6 0 1 9 9 7]
 [1 9 8 0 5 4 6 7 3 2]
 [6 8 9 4 1 2 5 7 0 3]
 [2 0 3 6 8 4 1 5 7 9]]
vt_50sample [[8 5 9 3 0 7 4 6 1 2]
 [7 4 8 6 5 3 1 0 2 9]
 [8 3 1 9 2 0 7 5 6 4]
 [2 9 3 7 6 5 4 1 8 0]
 [0 8 4 5 3 7 1 6 9 2]
 [4 0 1 8 2 5 7 9 3 6]
 [8 3 4 5 6 0 1 9 2 7]
 [1 9 8 0 5 4 6 7 3 2]
 [6 8 9 4 1 2 5 7 0 3]
 [2 0 3 6 8 4 1 5 7 9]]
Epoch 55810: Training cost= 0.2195, Training acc= 0.8674, Validation cost= 0.2327, Validation acc= 0.8674
Epoch 55820: Training cost= 0.2148, Training acc= 0.8674, Validation cost= 0.2626, Validation acc= 0.8674
Epoch 55830: Training cost= 0.2145, Training acc= 0.8674, Validation cost= 0.2380, Validation acc= 0.8674
Epoch 55840: Training cost= 0.2421, Training acc= 0.8674, Validation cost= 0.2466, Validation acc= 0.8674
Epoch 55850: Training cost= 0.2872, Training acc= 0.8674, Validation cost= 0.2160, Validation acc= 0.8674
Epoch 55860: Training cost= 0.2029, Training acc= 0.8674, Validation cost= 0.2375, Validation acc= 0.8674
Epoch 55870: Training cost= 0.2984, Training acc= 0.8674, Validation cost= 0.2046, Validation acc= 0.8674
Epoch 55880: Training cost= 0.2104, Training acc= 0.8675, Validation cost= 0.2309, Validation acc= 0.8675
Epoch 55890: Training cost= 0.2594, Training acc= 0.8675, Validation cost= 0.2787, Validation acc= 0.8675
Epoch 55900: Training cost= 0.1946, Training acc= 0.8675, Validation cost= 0.2231, Validation acc= 0.8675
tm  [-0.3 -0.   6.6  7.2 -1.3 -0.1  0.2 -0.  -1.1 -0.7  8.4 -0.3 -0.  -0.1  4.8 -0.9 -0.1 -0.4 -0.2 -0.3 -1.6 -0.3 -0.9 -0.1 -1.1  2.2 -0.2 -0.1 -0.9 -2.1 -0.4 -0.2 -0.1  7.  -0.1 -0.3  3.5 -0.  -3.  -0.1 -0.3 -4.  -0.4 -1.4 -0.   0.3 -0.6 -0.2  1.5 -4.5 -0.   0.5 -0.2  9.6  2.6 -0.9 -0.3  3.1  1.3  4.   4.3 -0.5 -0.2  0.2 -0.   0.3 -0.1 -0.1 -0.4 -0.2  0.3  5.4 -0.3  0.6 -3.3 -0.1 -0.3 -0.  -0.1 -0.3  3.4 -0.3 -0.2 -0.6 -0.5 -3.3 -0.9 -0.2  0.2 -0.1 -0.3 -0.2 -0.   1.1 -0.6  0.4 -0.1 -3.1  1.1 -0.2  2.  -1.9 -0.6 -0.2 -0.2 -0.1 -2.4 -0.2 -0.1 -0.5 -0.3 -0.  -0.  -0.4  2.1 -2.5 -0.8 -0.7 -0.3 -0.2  0.1  1.   0.   1.1 -0.1  6.3 -0.1 -1.7  0.1 15.1  1.3 -0.1 -0.1 -0.3  7.1 13.2 -0.1 -0.1  1.5 -0.2 -0.3 -0.4 -0.5 -0.2 -0.  -0.3 -0.3 -0.1 -0.3 -0.2 -1.   0.1 -0.5  0.4 -0.2  0.  -0.3 -0.2 -1.  -0.3 -0.8  0.2 -0.  -0.1  0.7  0.7 -0.1 -0.3 -0.  -0.1 -0.2 -0.  -0.1 -0.1 -0.1  1.8 -0.4 -0.6  3.2 -0.1 -0.2 -0.1 -0.4 -2.1 -0.2 -0.3 -0.2 -0.8 -0.2  6.3 -0.1 -0.  -0.2 -1.  -1.2 -0.3 -0.7 -0.5 -0.2  0.2 -0.4 -0.3 -0.4 -0.1 -0.1 -2.8  0.1 -0.2  1.7 -0.  -0.2 -1.9 -0.7  1.1 -0.6 -0.1  7.6 -1.4 -0.5 -0.2 -0.1 -0.1  1.1 -0.9 -0.9 -1.3 -0.5  0.6  0.  -0.2 -0.2  1.  -0.2  0.7  2.3 -1.5  0.4 -0.5  1.3  4.1  0.1  0.3  0.5 -0.2 -0.1  1.8 -0.1 -0.5 -1.2 -0.4 -1.1  0.5 -1.6 -0.1  5.6 -3.4]
ty_50sample [[3 0 6 2 1 7 9 8 5 4]
 [1 5 4 6 8 3 2 9 7 0]
 [1 7 9 6 4 8 2 5 0 3]
 [6 8 0 4 5 2 2 7 3 1]
 [8 4 3 1 2 6 6 5 0 0]
 [6 4 3 7 1 9 0 5 8 2]
 [8 7 0 6 3 9 5 4 1 2]
 [2 5 8 3 0 9 1 6 4 4]
 [3 4 7 9 6 8 2 0 1 5]
 [3 5 0 8 6 1 9 4 7 2]]
tt_50sample [[3 0 6 2 1 7 9 5 8 4]
 [1 5 4 6 8 3 2 9 7 0]
 [1 7 9 6 4 8 2 5 0 3]
 [6 8 0 4 5 9 2 7 3 1]
 [8 4 3 1 2 6 7 9 5 0]
 [6 4 3 7 1 9 0 5 8 2]
 [8 7 0 6 3 9 5 4 1 2]
 [2 5 8 3 0 9 1 6 7 4]
 [3 4 7 9 6 8 2 0 5 1]
 [3 5 0 8 6 1 9 4 7 2]]
vm  [-0.  -0.2  8.4 19.6 -0.8 -0.3 -0.1  0.1  0.6 -1.2 -1.5 -0.1 -0.4 -0.3 -0.7  5.7 -0.2 -0.1  1.8 -0.7 -0.5 -0.2  0.1 -0.1 -0.7  1.4 -0.2 -0.   0.3  2.4 -1.5 -0.4 -0.4 -3.2 -0.2 -0.1  0.2  3.6  8.1 -0.2 -0.6  0.1  0.9 -1.3 -0.2 -0.2  5.8 -0.3  4.7 11.1 -0.2 -0.2  0.1  0.7 -1.3  1.3  0.1  6.6 -1.9  9.1 -1.6 -0.1 -0.4 -0.3 -0.6 -0.6 -0.2 -0.1  0.8 -0.1  0.1 -1.1 -0.  -0.2  1.1  0.3 -0.1  0.5 -0.1 -0.3 -1.2 -0.3 -0.  -0.3 -1.6  2.2 -0.7 -0.2 -0.3 -0.1 -0.4 -0.1 -0.1 -0.3 -0.9 -0.5  1.7 -1.7 -0.5 -0.4  3.8  4.  -0.4 -0.2 -0.2 -0.4  0.  -0.2 -0.1 -1.3 -0.1 -0.1  0.2 -0.1 -1.1 11.8 -0.2 -0.9  0.4 -0.1 -0.3  5.7 -0.1 -1.   0.  -1.  -0.1  1.7 -2.4 -2.2  0.9 -0.1  0.2 -0.2 -0.4 -3.7 -0.1 -0.1  0.3  2.2 -0.7 -0.4 -0.6 -0.1 -0.   0.2 -0.1 -0.1 -0.8 -0.2 -2.2 -0.1  1.8 -0.2  0.2  0.  -0.5  0.3 -0.5 -0.2  0.7 -0.   1.1 -0.1  0.6 -0.4 -0.3 -0.1 -0.2 -0.1 -0.1 -0.1 -0.4 -0.3 -0.2  0.4 -0.6  0.1 -0.8  0.  -0.5 -0.3 -0.2 -1.2 -0.2 -0.  -0.2 -0.4  0.3 -0.6 -0.  -0.3 -0.2 -0.3 13.1  9.1  0.5  2.6 -0.1 -0.1  0.6  0.5 -0.1 -0.2 -0.1  2.7 -0.1 -0.1 10.3  0.2 -0.6  2.4 -0.3 -1.   0.4 -0.5  6.9 -0.4 -0.1 -0.1 -0.1 -0.3 -0.7 -0.7  2.9  2.7  1.6  0.1 -0.5  1.9 -0.8 -1.3 -0.1  0.3 -0.7 -1.7 -0.4 -0.1 -0.1 14.4 -0.3  3.6 -0.3 -0.   5.  -2.  -0.3 -0.3 -1.2 -0.3  1.6 -0.2  4.3 -0.2 -0.8  8.2]
vy_50sample [[8 9 2 7 6 5 3 1 0 4]
 [5 1 3 2 9 9 7 8 4 6]
 [2 1 6 9 5 7 3 0 4 4]
 [2 5 4 6 7 9 9 0 1 3]
 [5 4 7 6 8 2 0 3 1 9]
 [0 8 3 5 6 7 4 2 1 9]
 [9 6 0 5 2 1 4 3 8 7]
 [3 1 5 7 4 8 2 9 0 6]
 [6 3 2 0 5 7 9 4 8 1]
 [3 9 1 0 5 4 8 7 6 2]]
vt_50sample [[8 9 2 7 6 3 5 1 0 4]
 [5 1 3 2 0 9 7 8 4 6]
 [2 1 6 9 5 7 3 0 4 8]
 [2 5 4 6 7 8 9 0 1 3]
 [5 4 7 6 8 2 0 3 1 9]
 [0 8 3 5 6 7 4 2 1 9]
 [9 6 0 5 2 1 4 3 8 7]
 [3 1 5 7 4 8 2 9 0 6]
 [6 3 2 0 5 7 9 4 1 8]
 [3 9 1 0 5 4 8 7 6 2]]
Epoch 55910: Training cost= 0.2989, Training acc= 0.8675, Validation cost= 0.2298, Validation acc= 0.8675
Epoch 55920: Training cost= 0.2810, Training acc= 0.8675, Validation cost= 0.2045, Validation acc= 0.8675
Epoch 55930: Training cost= 0.2028, Training acc= 0.8675, Validation cost= 0.2241, Validation acc= 0.8675
Epoch 55940: Training cost= 0.2204, Training acc= 0.8675, Validation cost= 0.1929, Validation acc= 0.8675
Epoch 55950: Training cost= 0.2101, Training acc= 0.8675, Validation cost= 0.2233, Validation acc= 0.8675
Epoch 55960: Training cost= 0.2631, Training acc= 0.8675, Validation cost= 0.2023, Validation acc= 0.8675
Epoch 55970: Training cost= 0.3039, Training acc= 0.8675, Validation cost= 0.2488, Validation acc= 0.8675
Epoch 55980: Training cost= 0.1683, Training acc= 0.8675, Validation cost= 0.2326, Validation acc= 0.8675
Epoch 55990: Training cost= 0.1854, Training acc= 0.8675, Validation cost= 0.2244, Validation acc= 0.8675
Epoch 56000: Training cost= 0.2379, Training acc= 0.8676, Validation cost= 0.2420, Validation acc= 0.8675
tm  [-0.8  0.6 13.6  0.4 -1.4 -0.  -0.3 -0.2 -0.4 -1.2  4.9 -0.1 -0.1 -0.5 17.7  1.5 -0.  -0.2 -0.3  2.6 -1.2 -0.1 -0.6 -0.2 -1.3  3.  -0.5 -0.2 -0.3 -1.  -0.4 -0.2 -0.2 15.6 -0.4  0.1 -0.2  0.9 -2.3 -0.2  1.3 -0.7  0.9 -0.8 -0.3 -0.4 -2.6  0.3 -1.4 -1.5 -0.5 -0.  -0.2  8.2 -1.3 -2.2 -0.9  8.9  0.7  4.4  9.7  0.1  1.9 -0.3 -0.3 -0.1  0.2 -0.4  1.6  0.1 -0.1 -1.2 -0.2  0.7 -5.7  1.  -0.1  1.8 -0.  -0.5 -2.3 -0.5 -0.  -0.6 -0.1 -0.3 -3.2  0.  -0.1 -0.3 -1.1 -0.1  0.9 -0.2 -0.5  0.1  3.1 -3.6 -1.1 -0.4  3.2  4.2 -0.2 -0.1 -0.3  0.8 -2.  -0.   1.9  1.8 -0.1  0.4 -0.3 -0.6 -0.4  9.3 -0.3 -0.6 -0.1 -0.4 -0.2 -1.1 -0.1  0.5  0.2 22.3  0.2 -1.2  2.  10.1 -0.3 -0.2 -1.1 -0.  -5.3  3.7 -0.1  0.2  0.  -0.6 -0.2 -0.4 -0.3 -0.5 -0.1  0.4  0.  -0.2 -1.4 -0.3 -0.3  0.1 -1.3  1.1 -0.2 -0.3 -0.9 -0.6  2.  -0.3 -0.7 -1.1  1.2 -0.3 -0.1  0.3  0.8 -0.4 -0.3 -0.2 -0.3 -0.1 -0.5 -0.7  0.6  0.9 -0.5 -0.4  2.5  0.3 -1.  -0.   0.1 -2.  -0.2 -0.3 -0.4 -0.3 -0.1  2.5 -0.   0.4 -0.2 -1.  -4.4 -0.6 -0.4  0.9 -0.4 -0.  -0.3  0.3 -0.   0.8 -0.2 -2.4  0.3 -0.1 -1.1 -0.1 -0.6  2.7  0.   8.3 -0.1 -0.5  3.6 -0.9 -0.2 -1.1 -0.3 -0.2  0.2 -0.6 -1.2  1.6 -1.3 -0.  -0.6 -0.8 -0.1  0.1 -0.6 -0.4 -0.4 -2.8 -0.9 -0.3 -0.1 -3.5 -0.1 -1.2 -0.2 -0.1  8.1  1.7 -0.6 -0.3 -1.3  1.9  5.5 -0.4 -1.2  0.2  4.5 -2.1]
ty_50sample [[7 1 3 5 2 6 8 0 4 9]
 [8 1 6 5 0 3 9 2 7 4]
 [9 8 0 3 2 4 5 7 1 6]
 [7 3 4 2 9 5 0 1 8 6]
 [4 3 7 9 9 5 6 0 1 8]
 [8 9 5 7 6 2 3 1 0 4]
 [1 7 7 4 2 5 9 0 6 8]
 [0 9 1 3 2 4 8 5 7 6]
 [2 4 0 6 5 7 9 8 3 1]
 [2 9 9 3 4 6 0 5 8 1]]
tt_50sample [[7 1 3 5 2 6 8 0 4 9]
 [1 8 6 5 0 3 9 2 7 4]
 [9 8 0 3 2 4 5 7 1 6]
 [7 3 4 2 9 5 0 1 8 6]
 [4 3 7 2 9 5 6 1 0 8]
 [8 9 5 7 6 2 3 1 4 0]
 [1 3 7 4 2 5 0 9 6 8]
 [0 9 1 3 2 4 8 5 7 6]
 [2 4 0 6 5 7 9 8 3 1]
 [2 7 9 3 4 6 0 5 8 1]]
vm  [-0.3 -0.2  9.6  4.2 -1.7 -0.1 -0.2 -0.1 -0.9 -0.1 -5.1 -0.3 -0.1 -0.2 10.7 -1.7 -0.7 -0.3 -0.5 -0.4 -1.3 -0.2 -0.1 -0.4 -1.1 -0.2 -0.4 -0.2 -1.   3.1 -0.7 -0.4 -0.4  6.3 -0.1 -0.   0.7 -2.7 -5.6 -0.1 -0.1  2.9  0.  -1.4 -0.1 -0.2 -0.6  0.1  1.5  7.4 -0.3 -0.  -0.7 -1.  -0.2 -1.6 -0.9  6.3 -0.5  5.4  4.3 -0.7 -0.6 -0.3 -0.4 -0.3  0.3 -0.2  1.3 -0.  -0.1  4.5 -0.4 -0.4 -3.8 -0.3 -0.  -0.8 -0.   0.2 -2.9 -0.2 -0.  -0.5 -0.5  4.6 -0.7 -0.2  0.3 -0.5 -0.2 -0.1 -0.1 -0.6 -0.3  1.  -0.5 -3.2 -0.1 -0.2  0.1  5.9 -0.2 -0.4 -0.1 -0.1 -1.8 -0.1 -1.5 -0.6 -0.4 -0.1 -0.3 -0.3  2.8 -1.8 -0.6 -0.3 -0.2 -0.7 -0.1  1.5  0.7  1.1 -0.2 13.4 -0.   5.1 -0.7  0.6  0.4 -0.1 -0.3 -0.2  6.2 11.4 -0.4  0.2  0.5 -0.8  0.2 -0.7 -0.2 -0.3 -0.1 -0.1 -0.3 -0.1 -0.7 -0.1 -0.7  0.1  0.5 -0.2  0.1 -0.1 -0.3 -0.5 -1.3 -0.3 -0.9  1.6 -0.1 -0.2 -0.   2.1  0.  -0.2 -0.1 -0.2 -0.2 -0.1 -0.3 -0.2 -0.3  0.9 -0.7 -0.5  4.9 -0.3 -1.8 -0.2 -0.3 -1.7 -0.1  0.4 -0.2 -0.3 -0.3 -0.6 -0.2 -0.1 -0.1 -1.2 -1.5  2.7 -0.6 -0.9 -0.1 -0.2 -0.3  0.1 -0.2 -0.2 -0.5 -3.  -0.1 -0.3 -0.4 -0.1 -0.5 -1.7 -0.7  0.3 -0.8 -0.5  8.7 -1.3 -0.4 -0.1 -0.1 -0.1 -0.1 -1.5  4.2 -0.8 -1.5 -0.1  1.4  0.7  1.2  0.2 -0.3 -0.3  0.5 -2.3 -0.3 -0.4  3.6 -3.6 -0.1 -1.6 -0.1 -0.   9.9  2.8 -0.5  0.  -1.1  0.3  7.6 -0.1 -2.9 -0.1  4.2  2.1]
vy_50sample [[6 7 0 5 8 8 9 3 4 2]
 [4 5 8 9 6 3 7 2 0 1]
 [4 9 0 3 8 5 7 2 6 1]
 [0 8 6 2 5 3 1 9 4 7]
 [9 5 2 4 6 0 1 8 7 3]
 [1 4 8 7 9 0 2 5 6 3]
 [0 0 9 4 2 3 7 1 6 5]
 [6 1 7 5 3 8 9 4 2 0]
 [8 5 3 7 1 2 4 0 0 9]
 [1 6 5 0 8 8 4 9 3 7]]
vt_50sample [[6 7 0 5 8 1 9 3 4 2]
 [4 5 8 9 6 3 7 2 0 1]
 [4 9 0 3 8 7 2 5 6 1]
 [0 8 6 2 5 3 1 9 4 7]
 [9 5 2 4 6 0 1 8 7 3]
 [1 4 8 9 7 0 2 5 6 3]
 [0 8 9 4 2 3 7 1 6 5]
 [6 1 7 5 3 8 9 4 2 0]
 [8 5 3 7 1 2 4 0 9 6]
 [1 6 5 0 2 8 4 9 3 7]]
Epoch 56010: Training cost= 0.1998, Training acc= 0.8676, Validation cost= 0.2671, Validation acc= 0.8675
Epoch 56020: Training cost= 0.2020, Training acc= 0.8676, Validation cost= 0.2349, Validation acc= 0.8676
Epoch 56030: Training cost= 0.2433, Training acc= 0.8676, Validation cost= 0.2696, Validation acc= 0.8676
Epoch 56040: Training cost= 0.2350, Training acc= 0.8676, Validation cost= 0.2615, Validation acc= 0.8676
Epoch 56050: Training cost= 0.2277, Training acc= 0.8676, Validation cost= 0.2245, Validation acc= 0.8676
Epoch 56060: Training cost= 0.2887, Training acc= 0.8676, Validation cost= 0.2146, Validation acc= 0.8676
Epoch 56070: Training cost= 0.2681, Training acc= 0.8676, Validation cost= 0.3070, Validation acc= 0.8676
Epoch 56080: Training cost= 0.2704, Training acc= 0.8676, Validation cost= 0.2926, Validation acc= 0.8676
Epoch 56090: Training cost= 0.2796, Training acc= 0.8676, Validation cost= 0.2325, Validation acc= 0.8676
Epoch 56100: Training cost= 0.1893, Training acc= 0.8676, Validation cost= 0.2647, Validation acc= 0.8676
tm  [-1.2 -0.2 -0.7 -0.  -1.3 -0.2 -0.3 -0.2 -0.6 -0.6 -3.5  0.5 -0.1 -0.2 -0.1 -0.1 -0.2 -0.1 -0.2  0.1 -1.5 -0.4  1.6 -0.1 -1.2  1.8 -0.3 -0.  -0.9 -0.8 -1.1 -0.3 -0.4 -6.4 -0.1  0.6  2.6 -0.9 -4.3 -0.4 -0.1  2.5  0.2 -0.9 -0.   0.  -1.2 -0.3 -2.3  6.7 -0.2 -0.2 -0.2  5.1 -0.9 -0.2 -1.1  7.7 -0.8  7.2  8.8  0.1 -0.2 -0.  -0.5 -0.3 -0.1 -0.2 -0.  -0.2 -0.1  0.9 -0.  -0.3 -3.7 -0.3  1.1  0.3  0.  -0.2 -5.7 -0.4 -0.1  1.8  3.1  3.9 -2.5 -0.2 -0.1 -0.1 -0.5 -0.1 -0.3  0.7 -0.5 -0.3  1.4 -3.4 -0.4  0.7  2.1 -0.7 -0.3 -0.2 -0.3 -0.4 -2.5 -0.3 -0.9 -0.  -0.4 -0.5 -0.  -0.4 -0.2 -0.  -0.4 -1.1 -0.3 -0.3 -0.2 -0.1 -0.2  0.5 -0.1 -0.2 -0.  -0.5 -0.8  9.6 -0.3 -0.1 -0.  -0.4 15.2  0.2 -0.3 -0.2 -0.1 -0.3 -0.3 -0.6 -0.2 -0.1 -0.  -0.2  0.2 -0.1  6.8 -0.3 -0.2 -0.1  0.4 -0.1 -0.1 -0.  -0.2 -0.8 -1.  -0.5  0.2  1.3 -0.1 -0.1 -0.2 -0.6 -0.1 -0.2 -0.2 -0.2 -0.2  0.  -0.1 -0.3  0.2 -1.2 -0.9 -0.3  4.   0.1 -1.6 -0.1 -0.1 -2.2 -0.2  0.3 -0.2  0.5 -0.   2.4 -0.2 -0.2 -0.4 -0.9 -3.6  3.1 -0.2  0.4 -0.1 -0.2 -0.  -0.1 -0.1 -0.4  0.2 -3.5 -0.1  0.1  4.  -0.3 -0.7 -0.9 -0.3 10.3 -0.5  0.7  5.6 -0.9  0.7 -0.2 -0.1 -0.2 -0.5 -0.9  3.5  1.9 -0.6 -0.1 -0.6 -0.8 -0.2  0.9  0.3  1.1  0.3  0.8 -0.3 -0.5  1.9 -4.1 -0.2 -1.9 -0.2 -0.1 17.   3.  -0.2  0.2 -1.1 -1.1 14.5 -0.2 -2.3 -0.3  1.9 -1.8]
ty_50sample [[1 8 6 5 0 3 2 4 9 7]
 [6 8 3 1 4 2 5 0 7 9]
 [0 8 3 4 7 5 2 1 9 6]
 [2 7 8 9 1 3 5 6 0 4]
 [2 5 6 3 4 1 8 0 9 7]
 [9 3 4 0 6 8 7 1 2 5]
 [2 5 4 0 8 7 1 3 9 9]
 [3 5 1 4 0 7 7 2 2 6]
 [7 6 0 4 2 9 8 3 1 5]
 [7 2 4 4 8 0 9 5 6 6]]
tt_50sample [[1 8 6 5 0 3 2 4 9 7]
 [6 8 3 1 4 2 5 0 7 9]
 [0 3 8 4 7 5 2 1 9 6]
 [2 7 8 9 1 3 5 6 0 4]
 [2 5 6 3 4 1 8 0 9 7]
 [9 3 4 0 6 8 7 1 2 5]
 [2 5 4 0 8 7 1 3 6 9]
 [3 5 1 4 0 7 9 8 2 6]
 [7 6 0 4 2 9 8 3 1 5]
 [7 2 1 4 8 0 9 5 3 6]]
vm  [-0.3 -0.2 -0.3 -1.5 -1.9 -0.  -0.3 -0.1 -0.7 -0.9 -0.5 -0.2 -0.2 -0.3  2.8 -1.8 -0.3 -0.3 -0.3 -0.2 -1.7 -0.2 -0.8 -0.3 -1.4  2.  -0.5 -0.3 -1.2 -3.4  0.9 -0.2  0.7  5.2 -0.2 -0.1  1.5 -1.4 -2.7 -0.   1.2 -2.8 -0.7 -0.3 -0.1 -0.2 -0.8 -0.3 -0.2 -3.7 -0.2 -0.  -0.3 -0.6  1.3 -0.6 -0.8 -0.2  7.7 -1.3  5.7 -0.8 -0.1  0.1  1.  -0.2 -0.1 -0.2  2.4 -0.1 -0.2  5.4 -0.  -0.6 -3.4 -0.3 -0.2 -0.3  0.2 -0.4  2.5 -0.3 -0.  -0.2 -0.1 -2.5 -0.5 -0.2 -0.  -0.3 -0.1 -0.2 -0.1 -0.2 -1.   1.1 -0.1 -3.7 -0.4 -0.1  2.4 -1.7 -0.4 -0.2 -0.3 -0.4 -2.2 -0.1 -0.1  0.  -0.3 -0.2 -0.3 -0.4  6.1 -2.8 -0.2 -0.2 -0.2 -0.1 -0.4 -0.2 -0.2 -0.1 -0.3  4.  -0.2  4.   8.4 12.3 -0.1 -0.3 -0.  -0.5  7.  11.8 -0.3 -0.1  0.5 -0.2  0.9 -0.7 -0.1 -0.3 -0.1 -0.1 -0.3 -0.1  0.4 -0.1  1.3 -0.1 -1.   0.4 -0.3  0.1 -0.3 -0.3 -0.3 -0.1 -0.9 -0.3 -0.1 -0.2 -0.3 -0.1  0.2 -0.2 -0.3 -0.2  0.3 -0.2 -0.3 -0.4 -0.3  1.  -1.1 -0.6  3.  -0.2 -0.5 -0.4 -0.2 -2.7 -0.1 -0.2 -0.3 -0.3 -0.3  9.2 -0.2 -0.2 -0.2 -1.5 -2.3 -2.8 -0.8 -1.7 -0.1 -0.2 -0.2 -0.3 -0.4  0.  -0.2 -2.9 -0.2 -0.2 -0.7  0.3 -0.4 -1.7 -0.6  3.6 -0.8  0.1  1.4 -1.5 -0.3  0.3 -0.1 -0.2 -0.1 -1.4 -1.  -1.4 -2.1  0.2  1.1 -0.3 -0.2  0.6 -0.2 -0.1  1.3  0.2  0.2 -0.2  2.9 -0.5  0.1 -0.5 -0.3  0.4  0.4  0.6 -0.2 -0.4 -1.1  0.3 -0.9  0.  -1.6 -0.2  9.8 -2.8]
vy_50sample [[0 3 1 6 4 7 5 9 8 2]
 [1 6 4 4 8 3 9 2 5 0]
 [8 9 0 2 6 1 4 3 7 5]
 [0 7 3 5 1 2 8 8 6 4]
 [3 7 6 4 5 2 8 1 9 0]
 [9 6 2 8 7 0 4 5 3 1]
 [1 8 6 4 3 5 0 9 2 7]
 [4 3 8 9 6 0 1 5 2 2]
 [8 5 6 4 0 7 9 2 1 3]
 [3 4 4 0 7 6 8 2 9 5]]
vt_50sample [[0 3 1 6 4 7 5 9 8 2]
 [1 6 4 7 8 3 9 2 5 0]
 [8 9 0 2 6 1 4 3 7 5]
 [0 7 3 5 1 2 9 8 6 4]
 [3 7 6 4 5 2 8 1 9 0]
 [9 6 2 8 7 0 4 5 3 1]
 [1 8 6 4 3 5 0 9 2 7]
 [4 3 8 9 6 0 1 5 2 7]
 [8 5 6 4 0 7 9 2 1 3]
 [3 1 4 0 6 7 8 2 9 5]]
Epoch 56110: Training cost= 0.2955, Training acc= 0.8676, Validation cost= 0.2709, Validation acc= 0.8676
Epoch 56120: Training cost= 0.2310, Training acc= 0.8676, Validation cost= 0.2254, Validation acc= 0.8676
Epoch 56130: Training cost= 0.2674, Training acc= 0.8676, Validation cost= 0.2937, Validation acc= 0.8676
Epoch 56140: Training cost= 0.1906, Training acc= 0.8677, Validation cost= 0.2551, Validation acc= 0.8676
Epoch 56150: Training cost= 0.2036, Training acc= 0.8677, Validation cost= 0.2834, Validation acc= 0.8676
Epoch 56160: Training cost= 0.2063, Training acc= 0.8677, Validation cost= 0.2421, Validation acc= 0.8676
Epoch 56170: Training cost= 0.3195, Training acc= 0.8677, Validation cost= 0.2598, Validation acc= 0.8676
Epoch 56180: Training cost= 0.2541, Training acc= 0.8677, Validation cost= 0.2873, Validation acc= 0.8677
Epoch 56190: Training cost= 0.1885, Training acc= 0.8677, Validation cost= 0.2703, Validation acc= 0.8677
Epoch 56200: Training cost= 0.2075, Training acc= 0.8677, Validation cost= 0.2649, Validation acc= 0.8677
tm  [ 1.  -0.4  7.3  9.5 -1.3 -0.   0.6 -0.1 -0.2 -0.6  0.8  0.1 -0.1 -0.3  3.8 -0.1  0.1 -0.   0.2 -0.8 -1.2 -0.1 -0.6 -0.1 -0.9  0.8 -0.2 -0.1 -0.6 -1.6 -0.2 -0.4 -0.3  8.1 -0.1 -0.1  0.8  2.7 12.8 -0.3  0.6 -0.4 -0.1 -0.3 -0.  -0.1  2.2  0.7  8.7 -3.  -0.1  0.3 -0.1 -0.9 -0.1 -0.6 -0.7  7.2  2.4  3.1 -1.2 -0.2 -0.3  0.1 -0.5 -0.2  0.2 -0.5  1.2 -0.  -0.2  0.6 -0.2 -0.  -1.6 -0.2 -0.2  0.  -0.  -0.3  6.7 -0.2 -0.2 -0.4 -1.7 -0.4  5.1 -0.1 -0.1 -0.5 -0.8 -0.1 -0.2 -0.7 -0.6 -0.4  0.6 -2.6 -0.4 -0.2  1.7 -0.6 -0.5 -0.2 -0.3 -0.2 -1.5 -0.3 -0.1 -1.6 -0.3 -0.3  0.  -0.5  0.1  1.6 -0.2 -0.4 -0.1 -0.6 -0.   5.6 -0.2 -0.8 -0.4  4.6 -0.3  4.1  6.4  8.2 -0.  -0.3 -0.3 -0.7 -5.  -2.1 -0.1  0.1 -0.3 -0.4 -0.5 -0.1 -0.4  0.3 -0.2 -0.1 -0.  -0.1  2.5 -0.  -1.1 -0.1  2.6 -1.  -0.1 -0.1 -0.1 -0.6  1.7 -0.3 -0.2 -0.9 -0.2 -0.3 -0.1 -0.1 -0.1 -0.3 -0.3 -0.1 -0.1 -0.  -0.3 -0.4 -0.1 -0.2  0.9 -0.4 -1.2 -0.2 -2.3 -0.3 -0.4 -1.4 -0.  -0.1  0.2 -0.3 -0.4  4.1 -0.2 -0.  -0.5 -0.7 11.6 -2.  -0.3  0.  -0.1 -0.  -0.2 -0.1  0.2 -0.2 -0.3 -1.5  0.1 -0.2 -2.4 -0.  -0.6 -0.4 -0.5 -2.8 -0.6 -0.  -0.5 -1.2 -0.2 -0.6  0.1 -0.1  1.2 -1.1 -2.4 -0.3 -1.  -0.3 -0.1  4.  -0.5 -0.1  0.3 -0.3 -0.1 -1.9 -0.2 -0.2  2.1 -1.3  0.  -0.7  0.1 -0.2 -0.9 -0.6 -0.3 -0.6 -0.8 -0.7 -2.  -0.1  7.4 -0.   5.6 -1.7]
ty_50sample [[3 5 7 9 0 8 2 4 6 1]
 [5 0 8 4 7 2 9 3 1 6]
 [4 8 1 9 6 3 2 5 7 0]
 [4 0 1 8 3 5 9 2 7 6]
 [2 1 8 4 5 6 9 0 3 7]
 [5 2 1 9 3 8 6 7 0 4]
 [4 1 0 6 8 2 5 3 9 7]
 [3 2 6 4 9 0 1 5 8 7]
 [4 1 6 5 9 3 0 8 2 7]
 [3 7 8 2 0 5 1 9 6 4]]
tt_50sample [[3 5 7 0 9 8 2 4 6 1]
 [5 0 8 4 7 2 9 3 1 6]
 [4 8 1 9 6 3 2 5 0 7]
 [4 0 1 3 8 5 9 2 7 6]
 [2 1 8 4 5 6 0 9 3 7]
 [2 5 1 9 3 8 6 7 0 4]
 [4 1 0 6 8 2 5 3 9 7]
 [3 2 6 4 9 0 1 5 8 7]
 [4 1 6 5 9 3 0 8 2 7]
 [3 7 8 2 0 5 1 9 6 4]]
vm  [-0.3 -0.5  4.3 20.3 -0.8 -0.4 -0.1 -0.3 -1.2  2.7  6.9  0.4 -0.3 -0.4 -2.3 -0.2 -0.8 -0.1  0.1 -1.  -1.1 -0.3  1.9 -0.3 -0.4 -0.3 -0.4 -0.9 -1.7 -0.1 -1.9 -0.   0.3 -6.4 -0.2 -0.4  4.8  3.7 -2.2 -0.8  6.6  3.   0.  -0.2 -0.4 -0.3  6.  -0.4  2.1  7.7 -0.3 -0.6 -1.  10.6 -0.5  2.2 -1.   6.6 -2.6  9.7 -1.7 -0.1 -1.3 -0.3 -0.4 -0.1 -0.2  0.6  1.1 -0.  -0.5  6.6 -0.9 -1.  -1.9 -1.6 -0.4 -1.   0.1 -0.  -2.3  0.  -0.4  1.4 -1.3  1.3  0.3  0.1  0.3 -0.5 -0.  -0.1  0.   2.1 -0.3  2.1 -1.5 -1.9 -0.1 -0.5 -0.9 -0.1 -0.2 -0.3  0.1  0.9 -2.2 -0.2  2.2 -2.  -0.7 -0.5 -0.2  0.8 -0.9 -4.   4.  -0.8 -0.2  1.8  0.7  6.5 -0.6 -0.9 -0.3 -2.9  0.2 -1.9 -2.4  1.3 -0.7  0.7  1.   1.1 12.5  3.1 -0.2  0.1 -0.9 -1.3 -1.  -0.5 -0.3 -0.3 -0.4 -0.7 -0.6 -0.2  3.5 -0.5 -2.6  0.8  2.4 -0.5 -0.  -0.3  3.3 -0.7 -0.7 -1.1  1.1 -0.1 -0.3 -0.2 -0.7 -0.3 -0.4 -0.2 -0.6 -0.4 -0.1 -0.2  0.1  0.2 -0.3 -1.2 -2.  -0.6  2.5 -0.2 -2.  -0.5  2.3 -1.2 -0.1  1.2 -0.2  1.3 -0.7 -0.  -0.4  0.5 -0.2 -0.7 15.   9.3 -0.9  2.8 -0.2 -0.2  0.2  0.5  1.  -0.4 -0.1 -1.5 -0.1 -0.   1.9 -0.5 -0.5 -2.7 -0.7 -2.4 -0.7 -0.1  6.  -0.9 -0.3  1.3 -0.2 -0.1 -0.7 -1.4  1.7 -1.5  1.9 -0.9 -0.   0.3 -0.7  4.9 -0.2  1.4 -0.3 -1.1  1.5 -1.3 -0.  -1.7  0.2 -1.1 -0.4  0.6  8.1 -0.2  2.6  2.1 -0.8 -1.3  5.6 -0.2 -1.2 -0.1 -1.6  2.3]
vy_50sample [[2 0 6 8 5 9 3 7 1 4]
 [1 2 3 6 4 7 5 5 0 8]
 [1 2 8 9 7 0 5 3 4 6]
 [6 5 2 4 7 1 3 8 0 9]
 [1 5 2 6 3 8 0 0 7 9]
 [7 8 5 6 1 3 9 4 0 2]
 [0 7 3 6 8 9 4 5 2 1]
 [8 0 9 3 7 6 4 2 2 1]
 [3 8 5 5 4 6 7 9 2 2]
 [7 0 8 1 6 9 2 4 5 3]]
vt_50sample [[2 0 6 5 8 9 3 7 1 4]
 [1 2 3 6 4 7 5 9 0 8]
 [1 2 8 9 7 0 5 3 4 6]
 [6 5 2 4 7 1 3 8 0 9]
 [1 5 2 6 3 8 0 4 7 9]
 [7 8 5 6 1 3 9 4 0 2]
 [0 7 3 6 8 9 4 5 2 1]
 [8 0 9 3 7 6 4 5 2 1]
 [3 8 0 5 4 6 7 9 1 2]
 [7 0 8 1 6 9 2 4 5 3]]
Epoch 56210: Training cost= 0.2086, Training acc= 0.8677, Validation cost= 0.2181, Validation acc= 0.8677
Epoch 56220: Training cost= 0.2330, Training acc= 0.8677, Validation cost= 0.2634, Validation acc= 0.8677
Epoch 56230: Training cost= 0.2362, Training acc= 0.8677, Validation cost= 0.2449, Validation acc= 0.8677
Epoch 56240: Training cost= 0.2345, Training acc= 0.8677, Validation cost= 0.2539, Validation acc= 0.8677
Epoch 56250: Training cost= 0.2478, Training acc= 0.8677, Validation cost= 0.2418, Validation acc= 0.8677
Epoch 56260: Training cost= 0.1834, Training acc= 0.8678, Validation cost= 0.1893, Validation acc= 0.8677
Epoch 56270: Training cost= 0.2075, Training acc= 0.8678, Validation cost= 0.2261, Validation acc= 0.8677
Epoch 56280: Training cost= 0.2405, Training acc= 0.8678, Validation cost= 0.2084, Validation acc= 0.8677
Epoch 56290: Training cost= 0.2507, Training acc= 0.8678, Validation cost= 0.2412, Validation acc= 0.8677
Epoch 56300: Training cost= 0.1504, Training acc= 0.8678, Validation cost= 0.2119, Validation acc= 0.8677
tm  [-0.2 -0.2 -0.9 -2.1 -0.7  0.1 -0.8 -0.2 -0.7 -0.1 -3.  -0.3 -0.  -0.1  4.3  6.9  0.9 -0.4 -0.  -0.4 -1.7 -0.1  1.4 -0.3 -1.2  0.   0.3 -0.  -0.   5.4 -0.9 -0.3 -0.9 -4.9  0.1 -0.  -0.   4.1 -1.2 -0.6  0.7 -2.8  0.7  0.9 -0.5  0.6 -1.3 -0.5  6.4  3.  -0.1 -0.2 -0.7  7.5 -2.1 -0.8 -0.5 -0.9 -2.2  5.7  0.5 -0.8 -0.3 -0.  -0.4 -0.3 -0.3 -0.4 -0.8 -0.1 -0.1 -1.6  0.5  3.  -4.2 -1.4 -0.2 -0.6 -0.1  0.  -6.5 -0.3 -0.1 -0.9 -1.8 -2.9  6.7 -0.1 -0.2 -0.4  0.1 -0.  -0.3  1.  -0.9 -0.  -0.  -3.2  0.2 -0.1 -0.2 -2.  -0.5 -0.4 -0.1 -0.1 -1.6 -0.5 -0.5 -0.9 -0.2 -0.6 -0.2 -0.2 -2.4 17.  -0.8 -1.  -0.4 -0.8  0.5  2.3 -0.2 -1.1 -0.2  5.8  0.3 -1.2 -2.2 14.4  2.1 -0.   0.3  0.7  4.8 -4.4 -0.5 -0.1  0.9  2.3 -0.7 -0.6 -0.7 -0.3 -0.1 -0.3 -0.5 -0.2  0.9 -0.2  2.2 -0.   1.2 -0.6 -0.1 -0.3 -0.7 -0.2  0.7 -0.4 -0.2 -0.6 -0.5 -0.2 -0.5  0.2 -0.3 -0.6  0.4 -0.3  0.4 -0.1 -0.3 -0.3 -0.2  1.1 -0.5 -0.4  0.5 -0.4 -1.   1.  -0.3 -2.   0.2 -0.  -0.1 -0.6 -0.1 -1.3 -0.   0.2  0.  -1.   3.8  7.4 -0.   7.7 -0.   0.5  0.  -0.3 -0.6 -0.6 -0.1 -1.8 -0.2 -0.2 11.3  0.1 -0.1  3.2 -1.1 -1.4 -0.1 -0.8 -0.6 -0.7 -0.6  1.9 -0.1 -0.1 -0.2 -1.5 -1.4  5.1 -0.   2.  -1.   1.  -0.1 -0.  -0.  -0.1 -1.2  1.  -0.5 -0.2  0.7 -0.8 -0.1 -0.6 -0.4 -0.2 19.   2.4 -1.   1.  -0.5 -0.5 17.   0.1 -0.8  0.1  2.6 -3. ]
ty_50sample [[8 3 4 4 6 7 5 9 1 0]
 [9 8 7 2 1 5 6 3 0 4]
 [1 9 7 8 4 6 3 0 2 5]
 [1 4 9 0 6 8 7 2 3 5]
 [4 6 3 7 5 0 1 2 8 9]
 [8 8 4 6 5 0 7 1 3 9]
 [1 0 9 3 8 7 5 4 2 6]
 [1 7 4 2 5 6 3 8 0 9]
 [2 7 8 0 1 6 9 3 4 5]
 [4 3 1 0 2 8 7 9 5 6]]
tt_50sample [[8 3 4 2 6 7 5 9 1 0]
 [9 8 7 2 1 5 6 3 0 4]
 [1 9 7 8 4 6 3 0 2 5]
 [1 4 9 0 6 8 7 2 3 5]
 [4 6 3 7 5 0 1 2 8 9]
 [2 8 4 6 5 0 7 1 3 9]
 [1 0 9 3 8 7 5 4 2 6]
 [1 7 4 2 5 6 3 8 0 9]
 [2 7 8 0 1 6 9 3 4 5]
 [4 3 1 0 2 8 7 9 5 6]]
vm  [-1.3 -0.2  2.6  0.9 -2.1  0.6 -0.2 -0.1 -0.7 -0.4 -2.2 -0.1 -0.1 -0.4  2.2 -0.7 -0.1 -0.2  1.7 -0.  -1.3 -0.1 -0.1 -0.2 -1.1  1.9 -0.1 -0.3 -0.7 -2.1  0.3 -0.3 -0.5 -0.3  0.1 -0.   1.3  3.8 13.3 -0.4  0.5  6.9  0.3  1.8 -0.3  0.5 -0.6 -0.1 -1.6  9.2 -0.3 -0.1  0.1 -0.4 -0.6 -0.2 -1.   4.7  2.1  3.2  7.3 -0.4  0.3 -0.1 -0.9 -0.7 -0.1 -0.4  2.  -0.1  0.2  1.6  0.8  2.  -3.1 -0.4 -0.1 -0.8 -0.  -0.2 -0.8 -0.3 -0.1 -0.7  0.7  6.7 -1.6 -0.2  0.  -0.3 -0.6 -0.1 -0.3 -0.5 -0.5 -0.3 -0.4 -2.7 -0.6 -0.1  1.9  4.6 -0.2 -0.3 -0.2 -0.5 -1.4 -0.2 -0.6 -1.3 -1.  -0.2 -0.2 -0.6  1.   0.6  0.7 -0.4 -0.   0.  -0.1  3.7 -0.2 -0.1 -0.4  2.9 -0.3  3.   3.8 -1.5 -0.5 -0.3 -0.3 -0.2 -4.6 -4.7 -0.1 -0.  -0.4 -0.2 -0.  -0.4 -0.1 -0.1 -0.1 -0.1 -0.1 -0.2  4.   0.2 -0.1 -0.2 -0.7  0.3 -0.2 -0.2 -0.4  1.7  3.4 -0.4 -0.1 -1.4 -0.1  0.1 -0.2 -0.1 -0.1 -0.3 -0.1 -0.3 -0.1 -0.3 -0.2 -0.4 -0.2 -0.5  2.  -0.3 -1.3 -0.1 -2.2  0.2 -0.1 -1.8 -0.  -0.3 -0.2 -0.3 -0.3  5.5 -0.1 -0.1 -0.2 -0.8 -2.8 -1.  -0.4 -0.4 -0.1 -0.2 -0.3 -0.2 -0.5  0.3 -0.3 -1.3 -0.2 -0.1 -1.9 -0.4 -0.2 -0.5 -0.5  9.5 -0.3 -0.1 -1.6 -1.2 -0.3  0.  -0.1 -0.1  0.5 -0.9 -0.4  0.9 -1.3 -0.5 -0.5 -0.6 -0.2 -0.1 -0.2 -0.3  0.4 -0.6 -0.6 -0.1  1.2 -3.3 -0.3 -1.6 -0.2 -0.   4.4 -0.3 -0.4  0.2 -1.3 -0.1  1.1 -0.1  7.7 -0.   0.3  6.9]
vy_50sample [[1 5 8 0 7 4 9 2 3 6]
 [2 6 3 5 7 8 9 0 1 4]
 [0 9 7 2 8 6 5 1 3 4]
 [8 9 2 0 5 6 1 7 3 4]
 [1 8 6 2 3 7 9 5 4 0]
 [3 1 9 8 6 5 4 2 0 7]
 [4 4 0 5 1 7 6 2 3 9]
 [4 2 1 8 9 5 3 0 6 7]
 [8 3 1 4 7 2 9 0 0 5]
 [7 9 3 2 1 0 6 8 4 5]]
vt_50sample [[1 5 8 7 0 4 9 2 3 6]
 [2 6 3 5 7 8 9 0 1 4]
 [0 9 7 8 2 6 5 1 3 4]
 [8 9 2 0 5 6 1 7 3 4]
 [1 8 6 2 3 7 9 5 4 0]
 [3 1 9 8 6 5 4 2 0 7]
 [4 8 5 0 1 7 6 2 3 9]
 [4 2 1 8 9 5 3 0 6 7]
 [8 3 1 4 7 2 9 6 0 5]
 [7 9 3 2 1 0 6 8 4 5]]
Epoch 56310: Training cost= 0.2407, Training acc= 0.8678, Validation cost= 0.2423, Validation acc= 0.8677
Epoch 56320: Training cost= 0.2552, Training acc= 0.8678, Validation cost= 0.2397, Validation acc= 0.8677
Epoch 56330: Training cost= 0.2551, Training acc= 0.8678, Validation cost= 0.3075, Validation acc= 0.8678
Epoch 56340: Training cost= 0.2361, Training acc= 0.8678, Validation cost= 0.2807, Validation acc= 0.8678
Epoch 56350: Training cost= 0.2020, Training acc= 0.8678, Validation cost= 0.2371, Validation acc= 0.8678
Epoch 56360: Training cost= 0.2370, Training acc= 0.8678, Validation cost= 0.2279, Validation acc= 0.8678
Epoch 56370: Training cost= 0.1702, Training acc= 0.8678, Validation cost= 0.2141, Validation acc= 0.8678
Epoch 56380: Training cost= 0.1978, Training acc= 0.8678, Validation cost= 0.1954, Validation acc= 0.8678
Epoch 56390: Training cost= 0.1911, Training acc= 0.8679, Validation cost= 0.2273, Validation acc= 0.8678
Epoch 56400: Training cost= 0.2285, Training acc= 0.8679, Validation cost= 0.2349, Validation acc= 0.8678
tm  [-1.1 -0.6  3.3 14.5 -1.7 -0.  -0.3  0.3  0.3 -0.3 -6.2 -0.  -0.2 -0.6 -1.5 -0.6 -0.3 -0.5  0.8 -1.  -1.2  0.  -0.2 -0.4 -0.6  1.1 -0.3 -0.2  0.  -1.  -0.2 -0.5 -0.6 -0.7 -0.1 -0.3 -0.5 -0.9 14.9 -0.4  2.5  3.9 -0.9  0.6 -0.2 -0.2  6.6 -0.2 -1.4 11.5 -0.2 -0.   0.8 -4.8 -1.3  2.1 -0.8  1.6  2.9  3.3  3.6 -0.1 -0.5 -0.1 -0.6 -0.7 -0.3 -0.1  2.3 -0.1 -0.4 -1.7  0.7 -0.3 -0.3  1.  -0.3  1.6 -0.4 -0.1  7.9  0.4  0.2 -0.6  1.5  6.3 -1.6 -0.5 -0.1 -0.7 -0.4 -0.1 -0.7 -0.9 -1.1 -0.4 -0.3 -1.7 -0.7 -0.3  0.2  6.2  0.8 -0.2 -0.1 -0.1  0.4 -0.3 -1.9 -2.  -0.8 -0.1  0.5 -0.5  1.8 11.2  2.4  0.2 -0.1 -0.2  0.2  7.7 -0.3  0.1 -0.1 -2.  -0.5 15.2  1.9 -4.3 -0.3 -0.3 -0.3 -0.1 -1.8 -2.3 -0.1 -0.3 -0.6 -0.2  1.1  0.3  0.6 -0.  -0.  -0.3 -0.   0.4 -0.3 -0.1 -1.6 -0.2 -1.1  1.1 -0.1 -0.2 -0.4  1.2  1.2 -0.4 -0.1 -1.   0.3 -0.  -0.3 -0.  -0.1 -0.3 -0.1 -0.  -0.1 -0.2 -0.4  0.1 -0.2 -0.  -0.5 -0.4 -1.4 -0.1 -1.1  0.3 -0.1 -1.9 -0.1  1.1 -0.3 -0.3 -0.   2.7 -0.  -0.2 -0.3 -0.7 -0.7 -0.7  1.  -0.6  0.1  0.5 -0.2 -0.1 -0.1 -0.  -0.2  5.4 -0.3 -0.1  4.6 -0.3  0.1  2.7 -0.3  7.1 -0.5  0.2 -0.5 -1.  -0.1 -0.3 -0.  -0.2 -0.2 -0.7  3.2  4.3 -2.2 -0.9 -0.1 -0.7 -0.4 -0.9 -0.   0.2 -0.9 -0.6 -0.7 -0.6  2.1 14.  -0.2  3.1 -0.1  0.1 -1.1 -2.3  0.5 -0.4 -1.  -0.2 -2.1 -0.3  8.5  0.2  3.6 16. ]
ty_50sample [[1 9 8 7 5 4 6 0 3 2]
 [9 7 1 1 5 8 3 2 0 4]
 [6 9 2 4 0 8 1 7 3 5]
 [9 7 5 8 0 4 2 3 1 6]
 [7 1 8 2 3 6 5 4 9 0]
 [3 1 0 8 7 2 5 6 4 9]
 [6 7 8 9 4 1 2 3 5 0]
 [5 2 7 3 9 1 8 4 6 0]
 [2 5 8 6 7 1 3 9 0 4]
 [4 3 2 7 0 1 5 5 9 6]]
tt_50sample [[1 9 8 7 5 4 6 0 3 2]
 [9 7 6 1 5 8 3 2 0 4]
 [6 9 2 4 0 8 1 7 3 5]
 [9 7 5 8 0 4 2 3 1 6]
 [7 1 8 2 3 6 5 4 9 0]
 [3 1 0 8 7 2 5 6 4 9]
 [6 7 8 9 4 1 2 3 5 0]
 [5 2 7 3 9 1 8 4 6 0]
 [2 5 8 6 7 1 3 0 9 4]
 [4 3 2 7 0 1 5 8 9 6]]
vm  [-0.3 -0.3 -0.1  5.  -2.1 -0.   1.9 -0.2 -1.6 -0.5  6.6 -0.3 -0.  -0.3 -0.5 -1.9 -0.  -0.3 -0.1  0.3 -1.6 -0.2 -0.7 -0.1 -1.   3.2  0.9 -0.5 -1.7 -0.2 -0.2 -0.1 -0.1 10.  -0.1 -0.1  3.2 -1.3 -1.4 -0.2  1.6  1.8  2.4 -0.3 -0.  -0.   1.2 -0.6  4.4 -3.3 -0.2 -0.  -0.2 -0.6  4.6  0.2 -0.4  4.4 -0.8 -2.6 -0.2 -0.6 -0.1  0.1 -0.9 -0.1  0.3 -0.1  2.1 -0.1 -0.3  8.4 -0.  -0.1 -1.4 -0.4 -0.2  0.3  0.1 -0.4 20.1  0.  -0.3 -0.6 -0.8  2.8  3.3 -0.   0.2 -0.1  0.1 -0.  -0.3  0.9 -0.7 -0.7 -0.2 -2.5  0.9 -0.1  0.9 -0.4 -0.6 -0.1 -0.2 -0.8 -1.  -0.1  0.7 -0.6 -0.5 -0.3 -0.1 -0.1  2.2 -4.  -0.4 -1.  -0.2 -0.3  0.1  2.7 -0.4 -0.  -0.2 -0.7 -0.2  4.5 -0.5  1.   0.7 -0.3 -0.4 -0.3 10.2 20.  -0.2 -0.3  0.2 -0.1  1.1 -1.1  0.7 -0.2 -0.2 -0.4 -0.4 -0.2  5.6 -0.3 -0.6 -0.1 -0.7  2.1 -0.4 -0.  -0.4 -0.4 -0.8  3.3 -0.3 -0.  -0.  -0.2 -0.2 -0.5 -0.4 -0.6 -0.2 -0.1  0.  -0.2 -0.3 -0.2 -0.2 -1.  -0.3 -0.8  0.9 -0.1 -1.5 -0.2 -0.5 -1.8 -0.1 -0.4  0.1 -0.2  0.  -0.   0.1 -0.3 -0.2 -0.8  4.1  2.8 -0.9 -0.5 -0.2 -0.2 -0.1 -0.2 -0.1  0.2 -0.2 -1.  -0.3 -0.3 -5.3  0.1 -0.4 -2.6 -0.8 -0.1 -0.9 -0.   2.8 -1.1 -0.3 -0.4 -0.2 -0.  -0.3 -1.   2.7 -2.6 -1.8 -0.1 -0.6  0.4  0.9 -0.3 -0.2 -0.7  3.2  0.   1.2 -0.2  3.  -0.7 -0.2 -0.8 -0.1  0.5 -4.  -0.8 -0.6 -0.3 -1.1 -0.1 -5.3 -0.1 -1.  -0.1  5.7  1.4]
vy_50sample [[0 6 5 9 3 4 4 2 8 8]
 [2 3 6 0 9 1 5 7 4 8]
 [9 0 2 7 6 5 4 1 3 8]
 [7 7 5 9 2 6 3 4 1 8]
 [4 3 2 5 8 7 1 0 9 6]
 [1 4 5 0 7 6 6 2 3 9]
 [6 5 3 1 2 7 8 4 9 0]
 [1 7 9 8 3 6 2 5 0 4]
 [3 4 7 9 2 8 6 5 1 0]
 [7 7 5 4 8 6 3 1 9 2]]
vt_50sample [[0 6 5 9 3 4 7 1 2 8]
 [2 3 6 9 0 1 5 7 4 8]
 [9 0 2 7 6 5 4 1 3 8]
 [7 0 5 9 6 2 3 4 1 8]
 [4 3 2 5 8 7 1 0 9 6]
 [1 4 5 0 7 6 2 8 3 9]
 [6 5 3 1 2 7 8 4 0 9]
 [7 1 9 8 3 2 6 5 0 4]
 [3 4 7 2 9 8 6 5 1 0]
 [0 7 5 4 8 6 3 1 9 2]]
Epoch 56410: Training cost= 0.2088, Training acc= 0.8679, Validation cost= 0.2529, Validation acc= 0.8678
Epoch 56420: Training cost= 0.2446, Training acc= 0.8679, Validation cost= 0.2632, Validation acc= 0.8678
Epoch 56430: Training cost= 0.1965, Training acc= 0.8679, Validation cost= 0.2666, Validation acc= 0.8678
Epoch 56440: Training cost= 0.2685, Training acc= 0.8679, Validation cost= 0.2259, Validation acc= 0.8678
Epoch 56450: Training cost= 0.2451, Training acc= 0.8679, Validation cost= 0.2124, Validation acc= 0.8678
Epoch 56460: Training cost= 0.2767, Training acc= 0.8679, Validation cost= 0.2294, Validation acc= 0.8678
Epoch 56470: Training cost= 0.2903, Training acc= 0.8679, Validation cost= 0.2103, Validation acc= 0.8679
Epoch 56480: Training cost= 0.2495, Training acc= 0.8679, Validation cost= 0.2477, Validation acc= 0.8679
Epoch 56490: Training cost= 0.2529, Training acc= 0.8679, Validation cost= 0.2379, Validation acc= 0.8679
Epoch 56500: Training cost= 0.2852, Training acc= 0.8679, Validation cost= 0.2461, Validation acc= 0.8679
tm  [-0.8 -0.3  6.5 -1.6 -1.3 -0.2 -0.  -0.2 -1.1  1.7 12.6 -0.  -0.2 -0.2 13.7 -0.3 -0.2 -0.1 -0.6  0.  -1.6 -0.5 -0.2 -0.2 -0.9  2.   0.1 -0.4 -1.1 -1.4  1.4 -0.1 -0.7 18.3 -0.1 -0.3  2.7  9.3  9.3 -0.1  2.4  1.3 -0.4  3.2 -0.1 -0.4 -0.7 -0.4 -0.2 -0.3 -0.2 -0.2 -0.1 15.3 -0.3 -1.8 -0.6 -1.3  3.8 -1.8  2.4 -0.3 -0.3 -0.3  0.5 -0.8 -0.2 -0.   0.1 -0.4 -0.2  3.3 -0.7 -0.4 -4.3 -0.7 -0.1  0.4  0.  -0.3  4.2  0.4 -0.3  0.4 -0.7  2.5  2.6  0.   0.1 -0.5 -0.1 -0.2 -0.1 -0.5 -0.3 -0.  -0.6 -3.2 -0.4 -0.6 -0.7  7.2 -0.4 -0.3 -0.6 -0.2 -3.   0.3 -0.2 -0.5  0.6 -0.3 -0.3 -0.5  3.8 -2.4 -0.7 -0.4  0.2 -0.   0.  -0.1 -0.1  1.1  0.3 17.4 -0.  -2.8  4.2  2.4 -0.4 -0.1 -0.5  0.6 -7.9 -1.3 -0.   0.  -0.7 -0.2 -0.1 -0.6 -0.1 -0.2 -0.1  0.4 -0.2 -0.3 -2.1 -0.4  0.7 -0.1 -0.6 -0.1 -0.  -0.2 -0.5 -0.2  2.  -0.9  0.7 -1.7  0.  -0.1 -0.1 -0.2 -0.7 -0.4 -0.2 -0.1  0.1  0.1 -0.1 -0.2 -0.1  2.2  1.2 -0.1 -0.9 -0.1 -0.7 -0.5  0.8 -1.6 -0.1 -0.2 -0.1 -0.4 -0.   3.6 -0.1 -0.4 -0.3 -0.8 -0.4 -1.3 -0.6 -1.2  0.1 -0.1 -0.1 -0.2 -0.3 -0.2  1.2 -2.4 -0.  -0.2 -1.2 -0.2 -0.6 -1.1 -0.5  1.8 -0.8  0.3 -2.  -1.5  0.2 -0.1 -0.2 -0.2 -0.3 -1.  -0.2 -1.3  1.4 -0.  -1.  -0.7 -0.5  2.  -0.3 -0.3 -0.3 -1.1 -0.1 -0.7  2.4 -0.7 -0.1 -0.7 -0.4 -0.1 -0.3 -0.2 -0.5 -0.1 -0.7 -0.2 -1.3 -0.   5.2 -0.2 -1.6 -0. ]
ty_50sample [[7 7 0 4 1 5 3 9 8 6]
 [4 1 3 2 0 5 6 7 9 8]
 [4 5 8 1 1 6 2 2 3 7]
 [3 5 1 8 9 0 2 6 4 7]
 [1 6 0 7 3 5 4 8 9 2]
 [9 0 2 3 6 7 8 1 5 4]
 [9 0 3 8 6 7 2 1 4 5]
 [7 3 5 2 6 1 4 8 0 9]
 [2 3 6 4 8 9 9 0 7 5]
 [3 0 9 4 5 2 6 8 1 7]]
tt_50sample [[7 2 0 4 1 5 3 9 8 6]
 [4 1 3 2 0 5 6 7 8 9]
 [4 5 8 1 0 6 2 9 7 3]
 [3 5 1 8 9 0 2 6 4 7]
 [1 6 0 7 3 5 4 8 2 9]
 [9 0 2 3 6 7 8 1 5 4]
 [9 0 3 8 6 7 2 1 4 5]
 [7 3 5 2 6 1 4 8 9 0]
 [3 2 6 4 8 9 1 0 7 5]
 [3 0 9 4 5 6 2 8 1 7]]
vm  [-0.  -0.2  3.5  1.9 -1.9 -0.1 -0.1 -0.1 -0.7 -0.4 -1.8 -0.1 -0.  -0.4  2.2 -2.2 -0.4 -0.3  0.6 -0.1 -1.2 -0.2  1.1 -0.1 -0.9  1.5 -0.  -0.2 -1.3 -3.7 -0.3  0.3  1.3 -1.2 -0.1 -0.1 -0.  -1.6 -4.2 -0.2  3.3  5.5 -0.3 -0.5  0.1 -0.1 -1.  -0.4 -0.1  1.9 -0.3 -0.  -0.3  1.4  1.6 -0.5 -0.9 10.   9.5  4.   6.2 -0.8 -0.4 -0.3  2.2 -0.  -0.  -0.2  3.1 -0.2 -0.2  4.9 -0.5 -1.2 -4.4 -0.3 -0.2 -0.2 -0.2 -0.3 -2.  -0.2 -0.1  0.5 -0.3  4.4 -1.5 -0.  -0.1 -0.1 -0.4 -0.  -0.5 -0.7 -1.2 -0.5 -0.3 -4.3 -0.5 -0.2  1.3 -0.4 -0.5 -0.2 -0.  -0.1 -2.6 -0.3 -0.4  2.  -0.4  0.3 -0.2 -0.7  7.6 -3.2  2.1  1.6 -0.3  0.7 -0.5 -0.9 -0.3  1.  -0.2  3.2 -0.6  1.5 12.2  5.5 -0.2 -0.4 -0.5 -0.7  9.6  9.6  0.3 -0.2 -0.4 -0.6 -0.  -0.6 -0.  -0.1 -0.2 -0.2 -0.2 -0.1  7.5 -0.1 -0.4 -0.2 -0.1  0.3 -0.2 -0.1 -0.1  1.9 -0.3 -0.3 -0.9 -0.4 -0.  -0.1 -0.1 -0.3 -0.1 -0.5 -0.2 -0.1  0.1 -0.1 -0.  -0.3 -0.1 -1.6 -1.4 -0.5  4.4 -0.1 -2.4 -0.2 -0.2 -2.5 -0.2 -0.2 -0.  -0.5 -0.   9.9 -0.2 -0.4 -0.  -0.9 -2.6 -4.2 -0.7 -2.3 -0.4 -0.1 -0.2 -0.2 -0.6  0.7 -0.2 -3.5 -0.2 -0.3 -3.8 -0.1 -0.5 -2.  -0.3 -0.1 -1.2 -0.2  4.2 -1.4 -0.2 -0.3 -0.1 -0.2  0.5 -1.4  1.4 -1.4 -1.8 -0.4 -0.4  0.7 -0.6  0.9 -0.3 -0.6  0.8 -0.7  0.6 -0.6  4.1 -6.7  0.3 -2.8 -0.1 -0.1  7.4  2.2  0.5 -0.4 -1.2  2.8  4.  -0.2 -2.2 -0.3  5.8 -0.7]
vy_50sample [[0 5 6 1 3 8 7 7 4 9]
 [5 1 7 2 4 6 8 3 0 9]
 [0 6 5 7 4 9 9 8 3 3]
 [0 0 1 2 2 8 4 7 6 5]
 [4 2 9 5 1 0 6 3 8 7]
 [0 6 2 8 5 9 1 7 4 3]
 [0 6 3 4 4 7 5 5 8 2]
 [1 2 9 7 5 3 0 6 4 8]
 [6 2 4 0 3 9 8 1 7 5]
 [4 2 6 8 5 7 1 9 0 3]]
vt_50sample [[5 0 6 1 8 3 7 2 4 9]
 [5 1 7 2 4 6 8 3 0 9]
 [0 6 5 7 4 9 1 2 8 3]
 [9 3 0 1 2 8 4 7 6 5]
 [4 2 9 5 1 0 6 3 8 7]
 [0 6 2 8 5 9 1 7 4 3]
 [0 6 3 9 4 7 1 5 8 2]
 [1 2 9 7 5 3 0 6 4 8]
 [6 2 4 0 3 9 8 1 7 5]
 [4 2 6 8 5 7 1 9 0 3]]
Epoch 56510: Training cost= 0.1729, Training acc= 0.8680, Validation cost= 0.2533, Validation acc= 0.8679
Epoch 56520: Training cost= 0.1924, Training acc= 0.8680, Validation cost= 0.2354, Validation acc= 0.8679
Epoch 56530: Training cost= 0.2352, Training acc= 0.8680, Validation cost= 0.2592, Validation acc= 0.8679
Epoch 56540: Training cost= 0.2636, Training acc= 0.8680, Validation cost= 0.2658, Validation acc= 0.8679
Epoch 56550: Training cost= 0.2447, Training acc= 0.8680, Validation cost= 0.2839, Validation acc= 0.8679
Epoch 56560: Training cost= 0.2191, Training acc= 0.8680, Validation cost= 0.2213, Validation acc= 0.8679
Epoch 56570: Training cost= 0.2003, Training acc= 0.8680, Validation cost= 0.2165, Validation acc= 0.8679
Epoch 56580: Training cost= 0.2270, Training acc= 0.8680, Validation cost= 0.2713, Validation acc= 0.8679
Epoch 56590: Training cost= 0.2459, Training acc= 0.8680, Validation cost= 0.2916, Validation acc= 0.8679
Epoch 56600: Training cost= 0.2505, Training acc= 0.8680, Validation cost= 0.2918, Validation acc= 0.8679
tm  [ 0.4 -0.1  9.2 -1.5 -1.1  0.  -0.1 -0.  -0.7 -0.1  2.4 -0.2 -0.3 -0.5 15.8 -0.5 -0.4 -0.3 -0.5  2.5 -1.4 -0.2 -0.4 -0.1 -0.8  0.4 -0.3 -0.4 -0.7  0.3 -0.3 -0.3 -0.2  7.9  0.  -0.  -0.1 -1.5 -7.6 -0.2 -0.  -3.6 -0.6 -1.2 -0.2  0.2 -2.5 -0.3  6.5 -1.2 -0.3 -0.2 -0.2 11.2 -0.6 -2.1 -0.4 -1.4  4.5  5.   2.7  0.4 -0.3  0.  -0.6 -0.3 -0.1 -0.1  1.9 -0.  -0.2  0.5 -0.6 -0.  -5.5 -0.6 -0.  -0.4 -0.1 -0.4 -4.6 -0.  -0.1  0.3 -1.4 -3.4  3.2 -0.1 -0.1 -0.1  0.  -0.1 -0.1 -0.6 -0.6 -0.4 -0.2 -4.1 -0.  -0.1 -0.3  3.  -0.3 -0.1 -0.4 -0.2 -2.5 -0.3  1.3  1.5 -0.5 -0.1 -0.2 -0.7  3.9 -0.1 -0.7  0.6  0.2 -0.4 -0.1 -1.   0.1 -0.5 -0.1 20.  -0.2 -2.1  3.  15.1  0.1 -0.2  0.8 -0.   6.1 13.4 -0.2 -0.1 -0.2 -0.5 -0.  -0.4 -0.1 -0.2  0.  -0.3 -0.2 -0.2 -3.  -0.1  1.  -0.3  1.8  0.5 -0.1 -0.1 -0.2 -0.5 -1.1 -0.3 -0.4  1.9 -0.3 -0.  -0.3  0.7 -0.1 -0.2  0.4 -0.3 -0.1 -0.2 -0.1 -0.1 -0.2  5.5 -0.7 -0.6  6.9 -0.2  3.2 -0.1 -0.1 -1.5 -0.1 -0.4 -0.2 -0.6 -0.2 -0.1 -0.2 -0.1 -0.3 -1.  -0.4 -1.1 -0.3 -1.2 -0.  -0.2 -0.1 -0.2 -0.1 -0.4 -0.5 -3.5 -0.1 -0.2  9.5 -0.2 -0.6 -0.6 -0.8 -1.6 -0.9 -0.3  7.5 -1.1 -0.2 -0.3 -0.  -0.   0.5 -1.2  1.6 -0.3 -1.  -0.3  0.7  1.6  2.1  0.6 -0.1  0.8 -0.1 -2.   0.  -0.3  3.4  1.5 -0.2 -0.1 -0.3 -0.1 14.2  4.5 -0.2 -0.2 -1.2 -0.2 11.9 -0.1 -4.  -0.2  4.5 -3.6]
ty_50sample [[6 7 3 0 2 8 4 1 9 5]
 [7 7 1 5 3 8 0 2 6 9]
 [9 1 3 7 4 8 0 5 2 6]
 [1 8 7 9 5 6 2 0 3 4]
 [8 7 1 3 2 0 5 6 9 4]
 [0 4 9 5 7 1 3 2 8 6]
 [4 6 1 0 9 8 5 7 3 2]
 [3 8 5 2 0 1 4 9 6 7]
 [6 1 9 8 7 3 2 5 0 4]
 [5 5 6 1 9 8 0 2 4 7]]
tt_50sample [[6 7 3 0 8 2 4 1 9 5]
 [7 4 1 5 3 8 0 6 2 9]
 [9 1 3 7 4 8 0 5 2 6]
 [1 8 7 9 5 6 2 0 3 4]
 [8 7 1 3 2 0 5 6 9 4]
 [0 4 9 5 7 1 3 2 8 6]
 [4 6 1 0 9 8 5 7 3 2]
 [3 8 5 2 0 1 4 9 6 7]
 [6 1 9 8 7 3 2 5 0 4]
 [5 3 6 1 9 8 0 2 4 7]]
vm  [ 1.   0.1 -2.3 -3.4 -1.4 -0.1  0.4 -0.3 -0.4 -1.1  7.9 -0.3 -0.1 -0.3  2.5  5.1  0.1 -0.3 -0.5  2.3 -1.6  0.1 -0.1 -0.  -1.9  2.2 -0.  -0.3 -0.2 -0.9  0.9 -0.1 -0.3 -2.2 -0.1 -0.2  1.7  7.  -1.2 -0.4  1.5  1.7  1.4  0.8  0.4 -0.3 -1.7 -0.2  8.1 -0.2 -0.2  0.1 -0.2 15.3 -0.7 -0.5 -0.8  3.3  0.5 -0.3  0.5 -0.5  0.7 -0.  -0.1  0.5  0.6  0.  -0.8  0.  -0.2 -0.5 -0.2 -0.2 -3.6 -0.  -0.2  1.2 -0.  -0.2 -3.  -0.1 -0.  -0.  -1.6  3.3  7.6 -0.1  0.1 -0.1 -0.4 -0.2 -0.3 -0.3 -0.6 -0.1  1.7 -3.3 -0.4 -0.1  2.6 -1.  -0.8 -0.2 -0.2 -0.2 -2.3 -0.3  0.   1.3 -0.3  0.4 -0.3 -0.6 -0.8  5.8 -0.3 -1.2 -0.2 -0.4 -0.3 -0.7 -0.3 -0.8 -0.1  2.9 -0.1 -3.1  2.7  9.3  0.8 -0.5 -0.3 -0.4  4.9 -1.   0.3 -0.   0.4 -0.1 -0.5 -0.5 -0.6 -0.1 -0.   0.4 -0.2 -0.1  6.6 -0.1  3.1 -0.2  3.2 -0.8 -0.1  0.  -1.   0.3 -0.1 -0.3  0.6 -0.4  0.1 -0.  -0.1 -0.6 -0.2 -0.5 -0.1 -0.1 -0.1 -0.1 -0.4 -0.2 -0.2 -1.3 -0.6 -0.1  0.9 -0.2 -1.4 -0.5 -0.3 -2.2 -0.1 -0.5 -0.  -0.2 -0.4  3.3  0.2 -0.2 -0.1 -1.   2.8 -0.8 -0.1  2.8 -0.  -0.1 -0.2 -0.1 -0.3 -0.4 -0.1 -3.  -0.2 -0.1 -1.   0.2 -0.6 -0.  -0.5 -1.7 -0.8 -0.4 -0.7 -1.5 -0.7 -0.5 -0.1 -0.1 -0.  -1.4 -0.5  2.4  3.2  0.4 -0.3  2.9 -0.9 -0.4 -0.2 -0.2 -0.1  2.4 -0.  -0.2  3.8 -4.1  0.1 -1.7 -0.2 -0.1  9.7  1.1 -0.3 -0.5 -1.4 -0.1  6.8 -0.3 -0.6  0.5 -0.6 -1.9]
vy_50sample [[2 5 4 3 8 6 0 7 9 1]
 [2 4 5 0 6 1 3 3 9 9]
 [0 4 8 2 3 1 6 6 5 7]
 [3 8 4 6 0 1 5 7 9 2]
 [7 7 5 9 2 8 1 6 4 0]
 [9 7 5 1 2 4 8 6 0 3]
 [5 7 8 2 1 0 6 9 4 3]
 [4 8 2 5 7 9 6 3 0 1]
 [6 9 7 3 3 0 0 8 5 4]
 [2 6 4 8 3 1 0 5 7 9]]
vt_50sample [[2 5 4 3 8 6 0 7 9 1]
 [2 4 5 0 6 1 3 7 8 9]
 [0 4 8 2 3 1 9 6 5 7]
 [3 8 4 6 0 1 5 7 9 2]
 [7 3 5 9 2 8 1 6 4 0]
 [9 7 5 1 2 4 8 6 0 3]
 [5 7 8 1 2 0 6 9 4 3]
 [4 8 2 5 7 9 6 3 0 1]
 [6 9 7 3 1 0 2 8 5 4]
 [2 6 4 8 3 1 0 5 7 9]]
Epoch 56610: Training cost= 0.2169, Training acc= 0.8680, Validation cost= 0.2874, Validation acc= 0.8679
Epoch 56620: Training cost= 0.2221, Training acc= 0.8680, Validation cost= 0.2531, Validation acc= 0.8679
Epoch 56630: Training cost= 0.2043, Training acc= 0.8680, Validation cost= 0.2851, Validation acc= 0.8680
Epoch 56640: Training cost= 0.3109, Training acc= 0.8680, Validation cost= 0.2413, Validation acc= 0.8680
Epoch 56650: Training cost= 0.2168, Training acc= 0.8681, Validation cost= 0.2333, Validation acc= 0.8680
Epoch 56660: Training cost= 0.2450, Training acc= 0.8681, Validation cost= 0.2430, Validation acc= 0.8680
Epoch 56670: Training cost= 0.1765, Training acc= 0.8681, Validation cost= 0.2050, Validation acc= 0.8680
Epoch 56680: Training cost= 0.2295, Training acc= 0.8681, Validation cost= 0.2491, Validation acc= 0.8680
Epoch 56690: Training cost= 0.2649, Training acc= 0.8681, Validation cost= 0.2535, Validation acc= 0.8680
Epoch 56700: Training cost= 0.2724, Training acc= 0.8681, Validation cost= 0.2239, Validation acc= 0.8680
tm  [-0.  -0.   4.8 -0.9 -1.7 -0.1 -0.   0.  -1.  -0.5 -0.1 -0.4  0.1  0.2  8.2 -0.5 -0.4 -0.3 -0.5 -0.8 -1.4 -0.2 -0.5 -0.2 -1.4 -0.3 -0.1 -0.2 -0.9  1.  -0.6  0.5  0.8 -0.8 -0.3 -0.   2.6  2.2 -2.7 -0.5  1.4 -1.8  1.  -0.6 -0.2 -0.2  1.  -0.6  3.6 11.7 -0.1 -0.1 -0.9 10.2  1.6 -1.2 -0.4 -2.2 -1.   5.9 -0.3 -0.1 -0.6 -0.2 -0.6  0.8 -0.1 -0.1 -0.3 -0.2 -0.1  5.7 -0.5 -0.7 -2.4 -0.6 -0.  -0.4 -0.2 -0.5 -4.5 -0.2 -0.3 -0.2 -1.5 -1.5  4.6  0.  -0.2  0.7 -0.9 -0.  -0.2 -0.2 -0.2 -0.3 -0.2 -2.7 -0.1 -0.2  1.2  3.8 -0.6 -0.2 -0.  -0.2 -2.1 -0.4  0.1 -1.2 -0.6  0.4 -0.1 -0.1  2.3 -3.3 -0.4 -0.8 -0.3 -0.3 -0.3  2.4 -0.4 -1.2 -0.2 10.4 -0.3 -1.9 -2.1 -0.3  0.1 -0.3 -0.4 -0.4  0.5 -0.9 -0.1 -0.  -0.2 -0.  -1.  -0.7 -0.8 -0.2  0.2 -0.2 -0.4  0.2 -2.4 -0.2  0.5 -0.3  4.2 -0.5 -0.2 -0.2 -0.3  3.  -0.9 -0.4 -0.3 -0.1 -0.2 -0.1 -0.2  0.  -0.1 -0.5 -0.3 -0.  -0.   0.  -0.3 -0.2 -0.1  2.7 -0.6 -0.6  3.  -0.2  1.5 -0.3 -0.1 -1.4 -0.1 -0.9 -0.2 -0.7 -0.1 -0.3  0.3  0.3 -0.2 -0.5  5.7  7.8 -0.9 -1.3 -0.2  0.1 -0.3 -0.1 -0.3 -0.4 -0.2 -3.1 -0.3  0.1 14.7  0.9 -0.2 -2.6 -0.3 -1.6 -0.8 -0.5  2.7 -0.6 -0.4 -0.3 -0.1 -0.1  0.1 -1.4  1.8 -0.5  1.4  0.1 -0.1  0.9 -0.9  1.2 -0.   0.3  1.4 -0.8  0.2 -0.6  0.8 13.7  0.2  3.4 -0.1 -0.1 13.7  1.6 -0.7 -0.2 -1.4 -0.1 10.8 -0.1 -1.4 -0.1 -1.3  3.1]
ty_50sample [[8 0 2 7 6 4 9 3 1 5]
 [8 8 5 7 1 4 0 2 9 6]
 [8 0 7 6 2 9 5 4 1 3]
 [3 7 6 5 1 2 4 9 8 0]
 [7 9 2 5 4 1 6 0 8 3]
 [9 1 5 8 8 4 6 3 7 2]
 [6 8 1 5 7 2 4 9 0 3]
 [9 3 8 1 2 7 0 5 6 4]
 [2 0 4 6 3 7 5 1 1 9]
 [7 1 0 5 3 6 8 2 4 9]]
tt_50sample [[8 0 2 7 6 4 9 3 1 5]
 [8 3 5 7 1 4 0 2 9 6]
 [8 0 7 6 2 9 5 4 1 3]
 [3 7 6 5 1 4 2 9 8 0]
 [7 9 2 5 4 1 6 0 8 3]
 [9 1 5 8 6 4 0 3 7 2]
 [6 8 1 5 7 2 4 9 0 3]
 [9 3 8 1 2 7 0 5 6 4]
 [2 0 4 6 3 7 5 8 9 1]
 [7 1 0 5 6 3 8 2 4 9]]
vm  [ 1.1  0.2 -6.8 -6.6 -1.3 -0.2 -0.  -0.1  0.1 -0.3 -1.  -0.  -0.3 -0.  -0.9 -0.3  0.7 -0.2 -0.7 -0.2 -1.4  0.8 -0.1 -0.1 -1.7  2.  -0.2  0.  -0.5 -4.3  1.5 -0.5  0.7 -2.6 -0.1 -0.  -0.9  3.9  5.3 -0.2 -0.  -1.6 -1.2  2.  -0.  -0.2 -1.1 -0.2  8.1 -1.4 -0.1 -0.3 -0.  -0.1 -1.6 -0.1 -0.8 -1.8 13.1 -3.8 -0.1 -0.5  4.2 -0.3 -0.1 -0.4 -0.1 -0.  -0.8 -0.5 -0.2 -0.7 -0.3 -0.1 -5.8  0.7 -0.2  2.7 -0.3 -0.2 -0.5 -0.6 -0.2 -1.1 -2.6 -1.2  9.8 -0.1  0.3  0.9 -1.2 -0.4 -0.2 -0.7 -0.6 -0.4  0.8 -3.8 -0.2 -0.3 -0.3 -2.3 -1.  -0.2  0.6 -0.2 -1.7  0.7 -0.4 -0.3  0.3  1.2 -0.  -0.9  7.5  1.1 -0.1  2.2 -0.5 -0.6 -0.3 -0.3 -0.3 -0.  -0.3 -1.2 -0.1  2.5 13.7  7.6 -0.  -0.1 -0.4  1.1  3.9 -2.1 -0.1 -0.4  0.9 -0.4 -0.5 -0.6 -0.7 -0.3 -0.2 -0.4 -0.6 -0.   7.1  0.2  7.4 -0.2  4.2 -0.8 -0.3 -0.2 -1.2  1.4  1.7 -0.1 -0.1 -2.3 -0.2 -0.   0.5  0.8 -0.4 -0.4 -0.3 -0.1 -0.3 -0.3 -0.4 -0.2 -0.3 -1.3 -0.9 -0.1 -0.6  0.  -0.4  0.1 -0.3 -1.8 -0.1 -1.2  0.4 -0.1 -0.2 11.9  0.5 -0.1 -0.1 -1.4  5.1 -5.1  0.1 -2.3 -0.2 -0.3 -0.5 -0.1  0.1 -0.3 -0.5 -0.9 -0.5 -0.3  3.3  0.2 -0.2 -0.1 -0.4 -2.6  3.5 -0.4 -3.2 -1.3 -1.  -1.  -0.1 -0.2 -0.8 -2.1 -2.3  1.5 -2.1 -0.1 -0.8 -0.  -0.3  0.3 -0.3  1.1 -1.   7.3 -0.6 -0.6  0.2  1.3 -0.1 -0.4 -0.   0.6  3.8 -0.8 -1.2 -0.7 -1.5  2.7  0.4 -0.   2.9  0.2  4.9 -1.3]
vy_50sample [[4 3 0 8 5 9 2 6 6 7]
 [3 8 9 2 6 0 5 7 4 4]
 [7 5 4 3 8 2 1 0 9 6]
 [9 8 2 7 4 6 5 1 0 3]
 [9 2 5 4 7 3 1 6 0 8]
 [6 8 4 7 0 5 3 2 1 9]
 [8 2 4 0 5 9 6 3 7 1]
 [4 5 7 1 2 6 8 9 0 3]
 [1 5 9 0 8 7 4 6 3 2]
 [5 4 1 9 3 2 0 7 8 6]]
vt_50sample [[4 3 8 0 5 9 2 1 6 7]
 [3 8 9 2 6 0 5 7 1 4]
 [7 5 4 3 8 2 1 0 9 6]
 [9 8 2 7 4 6 5 1 0 3]
 [9 2 5 4 7 3 1 6 0 8]
 [6 8 4 7 0 5 3 2 1 9]
 [8 2 4 0 5 9 6 3 7 1]
 [4 1 5 7 2 6 8 9 0 3]
 [1 5 9 0 8 7 4 6 3 2]
 [5 4 1 9 3 2 0 7 8 6]]
Epoch 56710: Training cost= 0.2683, Training acc= 0.8681, Validation cost= 0.3105, Validation acc= 0.8680
Epoch 56720: Training cost= 0.2296, Training acc= 0.8681, Validation cost= 0.2399, Validation acc= 0.8680
Epoch 56730: Training cost= 0.1970, Training acc= 0.8681, Validation cost= 0.2805, Validation acc= 0.8680
Epoch 56740: Training cost= 0.2472, Training acc= 0.8681, Validation cost= 0.2489, Validation acc= 0.8680
Epoch 56750: Training cost= 0.2138, Training acc= 0.8681, Validation cost= 0.2507, Validation acc= 0.8680
Epoch 56760: Training cost= 0.2503, Training acc= 0.8681, Validation cost= 0.2805, Validation acc= 0.8680
Epoch 56770: Training cost= 0.2141, Training acc= 0.8681, Validation cost= 0.2282, Validation acc= 0.8680
Epoch 56780: Training cost= 0.2431, Training acc= 0.8682, Validation cost= 0.2131, Validation acc= 0.8681
Epoch 56790: Training cost= 0.3177, Training acc= 0.8682, Validation cost= 0.3219, Validation acc= 0.8681
Epoch 56800: Training cost= 0.2060, Training acc= 0.8682, Validation cost= 0.2844, Validation acc= 0.8681
tm  [-0.4 -0.4  4.2 -1.1 -1.8  0.3 -0.6 -0.1 -0.5  0.6 -7.8 -0.  -0.  -0.5  7.7 -1.9  0.1 -0.2  0.7  0.1 -1.6 -0.3  1.  -0.1 -0.7  0.8 -0.4 -0.2 -1.5 -2.9 -1.  -0.2  1.6 -4.1 -0.1 -0.2 -0.   2.2  3.3 -0.7  1.5  2.9 -0.4  1.5 -0.1 -0.4 -1.6 -0.2  2.3  7.7 -0.  -0.1 -0.7 -0.   0.3 -1.  -1.4  7.7  6.   7.3  3.3 -0.3 -0.   0.1 -1.1 -0.4 -0.  -0.4  1.6 -0.2 -0.4  5.6 -0.1 -0.6 -4.9  0.5 -0.2 -0.3 -0.1  0.8 -7.8 -0.5 -0.4 -0.3 -1.2  3.3 -0.5 -0.3  0.7 -0.2 -0.4  0.5 -0.3 -0.5 -0.5 -0.1 -0.1 -3.9 -0.1  0.  -0.1 -0.3 -0.4 -0.2 -0.2 -0.9 -2.2 -0.  -2.   0.4 -0.3  0.2  0.  -0.4  5.4 -3.3  2.4  1.2 -0.2 -0.1  0.1 -0.4 -0.5 -0.6 -0.3  9.8 -0.3  1.6  7.4  9.9 -0.7 -0.1 -0.  -0.4 -4.  -7.9 -0.2 -0.3 -0.5 -0.1  0.1 -0.8 -0.2 -0.5 -0.2 -0.  -0.4 -0.1  4.9 -0.2  0.2 -0.2  2.8 -0.2 -0.1  0.2 -0.1 -0.2  3.8 -0.5 -0.2 -1.5 -0.2 -0.  -0.2 -0.1  0.2 -0.4 -0.5 -0.2 -0.  -0.1 -0.2  0.1 -0.3 -0.7  1.2 -0.3 -0.6 -0.1 -1.8 -0.4 -0.2 -1.1 -0.1 -0.5 -0.3 -0.  -0.6  8.9 -0.1 -0.4 -0.2 -0.3 -1.2 -2.5 -0.7 -1.7 -0.1  0.  -0.1 -0.1  0.4 -0.3 -0.1 -3.  -0.4 -0.2  4.3 -0.2 -0.7 -2.  -0.3 -0.6 -0.4 -0.2 -0.9 -1.2 -0.5 -0.2 -0.  -0.3 -0.7 -1.6 -2.  -0.9 -1.4  0.7 -0.3 -0.1 -0.   0.7 -0.2  1.5  1.1 -0.9  0.1 -0.5  2.8 -5.6 -0.2 -2.3 -0.2 -0.3 22.   2.7 -0.1 -0.3 -1.1  0.3 20.3 -0.2  2.7  0.5  6.2 -2. ]
ty_50sample [[8 0 5 3 7 1 4 9 2 6]
 [6 4 1 3 7 5 2 0 8 9]
 [6 7 1 0 8 3 4 2 9 5]
 [5 0 6 7 3 4 8 1 2 9]
 [9 1 0 5 6 3 2 8 4 7]
 [4 5 0 6 7 3 8 9 1 2]
 [6 0 8 4 1 7 5 3 9 9]
 [7 3 2 8 9 0 1 4 6 5]
 [6 2 2 0 4 5 8 1 3 9]
 [3 2 4 0 1 6 5 8 7 9]]
tt_50sample [[8 0 5 3 7 1 4 9 2 6]
 [6 4 1 3 7 5 2 0 8 9]
 [6 7 1 0 8 3 4 2 9 5]
 [5 0 6 7 3 8 4 1 2 9]
 [9 1 0 5 6 3 2 8 4 7]
 [4 5 0 6 7 3 8 9 1 2]
 [6 0 8 4 1 7 5 3 2 9]
 [7 3 2 8 9 0 1 4 6 5]
 [6 2 7 0 4 8 5 1 3 9]
 [3 2 4 0 1 6 5 8 7 9]]
vm  [-0.3 -0.2  2.8 -1.3 -1.7  0.2 -0.6  0.6 -0.9 -1.1 10.  -0.2 -0.  -0.2  6.   0.3 -0.7 -0.2  1.2  0.9 -1.8 -0.3 -0.9  0.1 -1.1  1.5 -0.5 -0.2 -0.9 -4.8  0.5 -0.2 -0.2  8.8 -0.2 -0.2  0.3  5.2 -0.5 -0.6  0.7 -4.2 -1.3 -0.2 -0.  -0.3 -1.6 -0.5  1.3 -4.6  0.1  0.1 -0.6 10.2  0.4 -0.6 -0.9 -1.1 13.5 -1.5  4.6 -0.8 -0.2  1.  -0.4  0.2 -0.1 -0.1 -0.1 -0.5 -0.2  3.4  0.9  0.5 -3.7 -0.1 -0.2 -1.  -0.  -0.5  3.5 -0.4 -0.  -0.2 -0.4 -3.3 -0.5 -0.3 -0.1 -0.5 -0.2  0.1 -0.2 -0.9 -0.4  0.6 -0.5 -4.3 -0.3 -0.3  4.  -1.3 -0.4 -0.1 -0.2 -0.3 -1.9  0.3 -0.1  0.8 -0.6  1.   0.3 -0.5  5.5 -1.1  0.2 -0.  -0.3 -0.5 -0.4 -0.6 -0.1  0.4 -0.2  7.4 -0.  -1.7 14.1 13.9 -0.4 -0.5 -0.  -0.9 -1.5  6.4 -0.3 -0.2  1.1 -0.1 -0.2 -0.4 -0.9 -0.2  0.1 -0.2 -0.4  0.1 -1.1 -0.1  0.8 -0.1 -1.  -0.5 -0.1  0.3  0.1 -0.5  2.1  0.  -0.5 -0.9 -0.3 -0.  -0.2 -0.3  0.3  0.1 -0.  -0.1 -0.  -0.3  0.  -0.1 -0.1  2.6 -0.4 -0.5  0.7 -0.1  0.2 -0.6 -0.3 -2.  -0.1 -0.1 -0.2 -0.3 -0.3 13.4 -0.1 -0.1 -0.1 -1.2 -2.  -5.1 -0.4 -1.5 -0.1 -0.  -0.1 -0.2 -0.2 -0.5  0.5 -3.1 -0.  -0.3 -0.5  0.2 -0.2 -1.4 -1.1  2.  -1.1 -0.3 -0.2 -1.5 -0.6  1.3 -0.2  0.3 -0.3 -1.2 -1.9 -1.1 -0.3  3.1  1.2 -0.1 -0.4 -0.8 -0.1 -0.2  2.7 -0.5 -0.2 -0.1  3.6  0.9 -0.2 -0.3 -0.1 -0.1 -0.1  1.2 -0.  -0.1 -1.6 -0.2 -1.1  0.8 -0.2 -0.   3.6 -3.2]
vy_50sample [[3 0 2 1 7 4 6 5 9 8]
 [4 8 6 3 0 7 9 1 2 5]
 [4 6 1 0 8 5 9 7 2 3]
 [4 6 0 1 3 7 8 5 9 2]
 [6 8 1 9 4 0 5 2 3 7]
 [9 8 5 0 4 2 7 1 6 3]
 [7 9 4 0 5 2 3 1 8 6]
 [2 4 8 0 3 7 5 9 1 6]
 [7 8 0 2 5 6 4 1 9 3]
 [6 4 0 7 9 8 2 1 3 5]]
vt_50sample [[3 0 2 1 7 4 6 5 9 8]
 [4 8 6 3 0 7 9 1 2 5]
 [4 6 1 0 8 5 9 7 2 3]
 [4 6 0 1 3 7 5 8 9 2]
 [6 8 9 1 4 0 5 2 3 7]
 [9 8 5 0 4 2 7 1 6 3]
 [7 9 4 0 5 2 3 1 8 6]
 [4 2 8 0 3 7 5 9 6 1]
 [7 8 0 2 5 6 4 1 9 3]
 [6 4 0 7 9 8 2 1 3 5]]
Epoch 56810: Training cost= 0.2685, Training acc= 0.8682, Validation cost= 0.2957, Validation acc= 0.8681
Epoch 56820: Training cost= 0.2043, Training acc= 0.8682, Validation cost= 0.2227, Validation acc= 0.8681
Epoch 56830: Training cost= 0.2348, Training acc= 0.8682, Validation cost= 0.2564, Validation acc= 0.8681
Epoch 56840: Training cost= 0.2180, Training acc= 0.8682, Validation cost= 0.2186, Validation acc= 0.8681
Epoch 56850: Training cost= 0.2191, Training acc= 0.8682, Validation cost= 0.1723, Validation acc= 0.8681
Epoch 56860: Training cost= 0.2169, Training acc= 0.8682, Validation cost= 0.2166, Validation acc= 0.8681
Epoch 56870: Training cost= 0.2273, Training acc= 0.8682, Validation cost= 0.2192, Validation acc= 0.8681
Epoch 56880: Training cost= 0.2123, Training acc= 0.8682, Validation cost= 0.2302, Validation acc= 0.8681
Epoch 56890: Training cost= 0.2254, Training acc= 0.8682, Validation cost= 0.2448, Validation acc= 0.8681
Epoch 56900: Training cost= 0.1874, Training acc= 0.8682, Validation cost= 0.2405, Validation acc= 0.8681
tm  [ 0.3 -0.2  4.4 -3.6 -1.9 -0.1 -0.2 -0.2 -0.5 -1.1 -1.6 -0.1 -0.3 -0.5 13.7  4.2 -0.1  0.2 -0.1  2.  -1.4  0.7  0.2 -0.1 -1.7  1.8 -0.2 -0.6  0.6  6.1 -0.  -0.2 -0.3  4.2 -0.2 -0.   0.1  3.5 -0.5 -0.8  2.1  0.1  3.3  3.2 -0.4 -0.3 -1.8 -0.3  6.9  6.6 -0.3 -0.1 -0.1  7.6 -1.1 -1.6 -0.9 -1.2 -1.1  2.5  1.9 -0.4 -0.3 -0.1 -0.8 -0.4  0.3 -0.2  0.7 -0.2 -0.  -1.1  0.2  1.  -3.8 -0.4 -0.1 -0.4 -0.1 -0.4 -5.1 -0.1  0.3 -0.3 -1.7  1.2  7.4 -0.2  0.1 -0.3 -0.4 -0.1 -0.4 -0.6 -0.6 -0.5 -0.3 -3.3 -0.5 -0.1  2.4  5.7 -0.6 -0.2 -0.2 -0.2 -1.7 -0.4 -0.5  0.4 -0.9 -0.1 -0.1 -0.4 -1.4 12.4  1.2 -1.1 -0.1 -0.4 -0.1 -0.4 -0.4 -1.  -0.2 17.4 -0.1 -1.3 -1.   6.6 -0.1 -0.2 -0.2 -0.5 -4.9 -3.5  0.7 -0.  -0.7 -0.2 -0.3 -0.5 -0.4 -0.2 -0.   0.   0.5  0.  -1.4 -0.1  3.7 -0.1  4.  -0.4  0.2 -0.  -0.3 -0.7  1.6 -0.4  0.3 -0.7  0.4 -0.1 -0.2 -0.9 -0.2 -0.3  0.  -0.1 -0.2  0.1 -0.3 -0.3 -0.2  1.5 -0.8 -0.3  0.2 -0.2 -0.8 -0.5 -0.6 -2.3 -0.2 -0.2 -0.1 -0.3 -0.2 -1.6 -0.1 -0.4 -0.1 -0.9  1.1  3.6 -0.2  3.9 -0.2 -0.1 -0.2 -0.1 -0.3 -0.2 -0.4 -2.5 -0.  -0.2  5.4 -0.6 -0.4  1.8 -0.6 -1.1 -1.  -0.2 -1.7 -0.9 -0.3  0.4 -0.2 -0.1  0.7 -1.1 -0.7  3.9 -0.2 -0.3  1.3  2.  -0.2 -0.3 -0.3  1.4 -0.7 -0.6  0.7 -0.4  2.3 -2.3 -0.  -1.1  0.2 -0.1 15.1  1.3 -0.1  0.2 -1.1 -0.4 12.3 -0.1 -0.2  0.2  0.4 -1. ]
ty_50sample [[7 8 4 2 3 3 6 1 0 9]
 [0 5 4 2 1 6 3 9 8 7]
 [1 0 6 4 4 7 5 8 3 2]
 [0 6 2 1 9 8 7 3 4 5]
 [8 5 7 3 9 6 2 4 0 1]
 [1 7 3 6 4 4 2 8 0 5]
 [3 7 4 0 2 8 9 5 6 1]
 [8 1 0 6 3 7 9 5 2 4]
 [3 5 8 0 2 4 6 9 1 7]
 [7 0 8 1 1 6 5 2 3 9]]
tt_50sample [[7 8 4 2 5 3 6 1 0 9]
 [0 5 4 2 1 6 3 9 7 8]
 [1 0 6 4 7 9 5 3 8 2]
 [0 6 2 1 9 8 7 3 4 5]
 [8 5 7 3 9 6 2 4 0 1]
 [1 7 3 6 4 9 2 8 0 5]
 [3 7 4 0 2 8 9 5 6 1]
 [8 1 0 6 3 7 9 5 2 4]
 [3 5 8 0 2 4 9 6 1 7]
 [7 0 8 4 1 6 2 5 3 9]]
vm  [ 0.1  0.5  2.9 13.  -1.3 -0.3 -0.3  0.1 -0.  -0.2  3.5 -0.3 -0.1  0.5 -1.6  0.1 -0.7  0.1  3.9  0.1 -1.  -0.1  3.1  0.  -0.8  4.5 -0.3  3.1 -0.4 -4.7 -0.3 -0.2 -0.9 -1.8 -0.1 -0.4 -0.9 -0.2  1.7 -0.6 -2.3 -2.7 -2.  -2.1  0.3  0.   0.1 -0.6  8.7  4.4  0.4  0.1  0.9 -0.5 -0.4  2.1  0.3 -0.5 13.4  4.6 -0.9 -0.8  1.   0.2  0.2 -0.5 -0.2 -0.2 -0.4 -0.3 -0.   2.5  2.3  3.1 -1.8 -1.  -0.1 -1.6  0.1 -0.4  6.8 -0.8  0.1 -0.8 -1.3 -1.8 -0.5  0.1 -0.2 -0.1  0.3 -0.2 -0.1 -2.3 -0.6 -0.1 -0.9 -3.7  0.1 -0.2  0.6 -0.6 -1.  -0.4  0.8  1.4  1.1 -0.1  0.9 -0.9 -0.2  0.3  0.3 -0.4  8.1  1.4 -1.3  2.4 -0.4  0.2 -0.3  2.8 -0.2 -0.  -0.1 -2.  -0.2  3.8 11.1 -1.1  1.7 -0.2  0.8 -0.3 11.1  7.3  0.2 -0.1  1.   0.1 -0.1 -0.7 -1.4  0.   0.3 -0.1 -0.1 -0.1 -0.9 -0.  -1.2  0.   3.2 -0.3 -0.1 -0.2 -0.5  0.9 -0.9  0.6 -0.5 -0.3 -0.  -0.1 -0.  -0.6 -0.   0.6  0.1  0.1 -0.1 -0.2 -0.2 -0.2 -0.1  3.1 -0.2  0.3 -0.2 -0.1  1.  -0.5 -0.5 -2.5 -0.3 -0.1 -0.  -0.3 -0.  13.3 -0.3 -0.1  0.1 -1.2  9.3 -4.1  0.6 -2.8 -0.3 -0.  -0.2 -0.1 -0.6 -0.4 -0.1  1.2 -0.2 -0.2  8.7 -0.2  0.3  0.4 -1.2 -0.5 -0.6 -0.8  8.  -1.2 -0.5  3.9  0.2  0.2  0.3 -1.7  4.3 -0.  -0.9  5.6 -1.   0.1  0.1 -1.6  0.7  1.6  0.7 -0.7 -0.1  0.5  5.2 16.7  0.4  3.6  0.3 -0.1 -0.7 -1.6 -0.2  1.1 -1.9  0.8 -2.1  0.3  0.6 -0.3  0.1  6.6]
vy_50sample [[9 6 0 8 2 3 1 7 4 5]
 [9 2 4 8 6 5 1 0 0 7]
 [1 2 7 0 5 6 9 4 8 3]
 [7 6 2 8 1 4 3 0 9 5]
 [0 6 4 2 3 5 7 8 9 9]
 [7 2 0 4 9 3 5 1 8 6]
 [8 0 2 1 4 7 5 6 9 3]
 [9 6 4 8 3 2 0 1 7 5]
 [9 6 7 0 8 1 2 3 5 4]
 [1 6 5 8 2 3 0 4 7 9]]
vt_50sample [[9 6 0 8 2 3 1 7 4 5]
 [9 2 4 8 6 5 1 3 0 7]
 [1 2 7 0 5 6 9 4 8 3]
 [7 6 2 8 1 4 3 0 9 5]
 [0 6 4 2 3 5 7 8 1 9]
 [7 2 0 4 9 3 5 1 8 6]
 [8 0 2 1 4 7 5 9 6 3]
 [9 6 4 8 3 2 0 1 7 5]
 [9 6 7 0 8 1 2 3 5 4]
 [1 6 5 8 2 3 0 4 7 9]]
Epoch 56910: Training cost= 0.1896, Training acc= 0.8683, Validation cost= 0.2737, Validation acc= 0.8681
Epoch 56920: Training cost= 0.2366, Training acc= 0.8683, Validation cost= 0.1986, Validation acc= 0.8681
Epoch 56930: Training cost= 0.2694, Training acc= 0.8683, Validation cost= 0.2803, Validation acc= 0.8681
Epoch 56940: Training cost= 0.2690, Training acc= 0.8683, Validation cost= 0.2787, Validation acc= 0.8682
Epoch 56950: Training cost= 0.2205, Training acc= 0.8683, Validation cost= 0.2739, Validation acc= 0.8682
Epoch 56960: Training cost= 0.2259, Training acc= 0.8683, Validation cost= 0.3030, Validation acc= 0.8682
Epoch 56970: Training cost= 0.1999, Training acc= 0.8683, Validation cost= 0.2194, Validation acc= 0.8682
Epoch 56980: Training cost= 0.1852, Training acc= 0.8683, Validation cost= 0.2366, Validation acc= 0.8682
Epoch 56990: Training cost= 0.2201, Training acc= 0.8683, Validation cost= 0.2138, Validation acc= 0.8682
Epoch 57000: Training cost= 0.2335, Training acc= 0.8683, Validation cost= 0.2780, Validation acc= 0.8682
tm  [-1.1  0.2  8.6 21.6 -1.3  0.2 -0.  -0.1 -0.6 -0.7 -2.3 -0.  -0.4 -0.  -0.9  3.  -0.5 -0.1 -0.7 -0.6 -1.1 -0.1  0.8 -0.1 -0.6 -0.2 -0.4 -0.1 -0.2  0.8 -1.  -0.3 -0.2 -1.1 -0.2 -0.   1.5  6.1 26.2 -0.3  2.1 -0.9  1.8  1.7 -0.2 -0.   6.8  0.2 -2.   6.7 -0.2 -0.1 -0.  -1.8 -1.3  0.5 -0.5  3.9 -2.7  7.8  1.  -0.4 -0.7 -0.2 -0.9 -0.9 -0.2 -0.1  1.7 -0.2 -0.1 -1.4  1.3 -0.2  6.2 -1.   0.1 -0.6 -0.1 -0.   3.1  0.7 -0.1 -0.2  2.1 -0.7 -2.5 -0.3 -0.2 -0.4 -0.1 -0.1  0.1  0.4 -0.2 -0.2 -0.6  0.2 -0.1 -0.   2.   3.6  1.5 -0.3 -0.2 -0.4  0.7 -0.2 -0.5 -2.  -0.6 -0.6 -0.  -0.1 -1.7  9.5  0.2 -1.  -0.3 -0.3  0.8  7.6 -0.3  0.5 -0.  -1.  -0.2  6.1 -2.5 -1.6 -0.3  0.7  0.4 -0.4 -6.1 -7.3 -0.1 -0.1 -0.3 -0.3 -0.2 -0.1 -0.2 -0.2 -0.1 -0.2 -0.1  0.1 -1.2 -0.1 -2.7 -0.2 -0.   0.6  0.4 -0.3 -0.   1.5  3.6 -0.5 -0.1 -1.  -0.1 -0.  -0.2  0.6 -0.1 -0.  -0.1 -0.2 -0.  -0.   0.1  0.1 -0.2  1.6  3.  -0.5 -2.6 -0.  -0.9 -0.3  0.  -0.8 -0.3  0.1 -0.5 -0.4  0.5 -0.2 -0.1 -0.2 -0.  -0.8  1.4 10.2  1.   5.6 -0.3 -0.1 -0.2 -0.2 -0.5 -0.4 -0.   2.7 -0.  -0.2  7.6 -0.1 -0.4  0.7 -0.5 10.1  0.1 -0.1 -0.8 -0.7 -0.3  1.  -0.2  0.4 -0.7 -0.7 -1.9  3.7 -0.4 -0.3 -0.7 -0.7 -0.5 -1.1 -0.   1.5 -0.3 -1.6 -0.4  0.5  0.6 14.  -0.3  3.1 -0.1 -0.1 -0.1 -1.6 -0.4  1.6 -0.7 -0.3 -1.1 -0.2 15.1 -0.1  2.3  6.5]
ty_50sample [[9 1 8 7 3 2 5 4 0 6]
 [3 0 9 9 7 6 1 4 2 8]
 [2 8 4 7 0 6 3 5 9 1]
 [8 5 3 0 7 4 6 1 9 2]
 [3 9 7 6 4 2 8 0 5 1]
 [8 2 0 3 7 7 1 4 6 5]
 [5 4 8 2 6 3 3 1 7 0]
 [8 7 2 5 4 6 1 0 9 3]
 [1 3 9 6 2 0 5 7 4 8]
 [2 3 9 7 5 1 0 8 6 4]]
tt_50sample [[9 1 8 7 3 2 5 4 0 6]
 [3 0 9 5 7 6 1 4 2 8]
 [2 8 4 7 0 6 3 5 9 1]
 [8 5 3 0 7 4 6 1 9 2]
 [3 9 7 4 6 2 8 0 5 1]
 [8 2 0 3 9 7 1 4 6 5]
 [5 4 8 2 6 3 9 1 7 0]
 [8 7 2 5 4 6 1 0 9 3]
 [1 3 6 9 2 0 5 7 4 8]
 [2 3 9 7 5 1 0 8 6 4]]
vm  [ 1.2 -0.3 -2.8 -6.8 -1.9 -0.1 -0.4 -0.1 -1.5 -0.1  7.2 -0.2 -0.  -0.3  9.1 -1.3  0.1 -0.6 -0.9  1.7 -1.5  0.1 -0.3 -0.4 -1.7  2.4  0.  -0.2 -1.7 -0.5  0.7 -0.1 -0.1  4.1  0.  -0.1  2.7  1.  -5.1 -0.2  3.9  3.8  1.5  2.7 -0.  -0.4 -2.5 -0.5  5.5 -0.9 -0.  -0.3 -0.6 14.4  2.9 -1.3 -1.  -0.5  0.2 -3.   1.2 -0.4 -0.1 -0.  -0.2  1.3 -0.1 -0.3 -0.2 -0.3  0.1  7.9 -0.6 -0.6 -5.3 -0.7 -0.1  0.7 -0.2 -0.3 -2.6  0.1 -0.4 -0.3 -1.6  3.8  9.5  0.4  0.3 -0.1 -0.3 -0.2 -0.4  0.5 -0.6  0.   0.1 -3.8 -0.1 -0.3 -0.3 -0.3 -0.5 -0.2 -0.1 -0.2 -2.8 -0.1  0.9  3.3 -0.5  0.6 -0.3 -0.1  2.7 -4.6 -0.2 -0.9 -0.1 -0.4 -0.  -1.1 -0.3 -0.6 -0.  11.4  0.5 -2.8  1.3 11.1 -0.3 -0.2 -0.4 -0.2  6.3  9.9 -0.2 -0.2 -0.4 -0.1 -0.3 -1.  -0.2 -0.4 -0.2 -0.2 -0.1 -0.2  5.6 -0.4  7.1 -0.1  1.4 -0.2 -0.3 -0.  -0.3 -0.1 -0.2 -0.4  0.2 -0.9 -0.1 -0.4 -0.1 -0.6 -0.3 -0.8 -0.1 -0.3 -0.1 -0.3 -0.   0.1 -0.1 -1.2 -1.2 -0.6  5.6 -0.4 -1.7 -0.3 -0.1 -2.4 -0.1 -0.5 -0.5 -0.3 -0.2  0.6 -0.1 -0.2  0.  -1.   0.8 -0.4 -0.9 -1.  -0.  -0.2 -0.1 -0.3  0.2 -0.2 -0.1 -3.9 -0.1  0.1 -3.  -0.2 -0.3 -3.4 -0.3 -1.6 -0.8 -0.3 -1.2 -1.1 -0.4 -0.5 -0.1 -0.1 -0.3 -1.4  0.5 -2.1 -0.7 -0.2  1.5 -0.1 -0.4  1.2 -0.2 -0.5  2.8  3.8 -0.1 -0.4  1.3 -6.3 -0.1 -2.4 -0.2 -0.1  9.1  5.3 -0.5 -0.4 -1.2 -0.3  6.6 -0.1 -2.9 -0.1 -0.2 -2.5]
vy_50sample [[0 4 5 2 6 3 7 8 1 9]
 [3 2 4 5 5 7 1 1 6 0]
 [3 1 1 6 0 5 2 4 7 8]
 [9 1 5 0 7 7 2 6 4 3]
 [7 5 4 0 1 1 8 3 2 6]
 [7 7 2 2 3 6 1 5 4 9]
 [9 7 8 1 5 4 0 6 2 3]
 [0 5 8 7 1 3 6 2 9 4]
 [7 1 3 5 6 4 8 9 0 2]
 [4 5 1 2 9 3 7 8 0 6]]
vt_50sample [[0 4 5 2 6 3 7 8 1 9]
 [3 4 2 8 5 7 1 9 6 0]
 [3 9 1 6 0 5 2 4 7 8]
 [9 1 5 8 0 7 2 6 4 3]
 [7 5 4 9 0 1 8 3 2 6]
 [7 8 2 0 3 6 1 5 4 9]
 [9 7 8 1 5 4 6 0 2 3]
 [0 5 8 7 1 3 6 2 9 4]
 [7 1 3 6 5 4 8 9 0 2]
 [4 5 1 2 9 3 7 8 0 6]]
Epoch 57010: Training cost= 0.2181, Training acc= 0.8683, Validation cost= 0.2578, Validation acc= 0.8682
Epoch 57020: Training cost= 0.2043, Training acc= 0.8683, Validation cost= 0.2338, Validation acc= 0.8682
Epoch 57030: Training cost= 0.2214, Training acc= 0.8683, Validation cost= 0.2472, Validation acc= 0.8682
Epoch 57040: Training cost= 0.2144, Training acc= 0.8684, Validation cost= 0.2393, Validation acc= 0.8682
Epoch 57050: Training cost= 0.1949, Training acc= 0.8684, Validation cost= 0.2010, Validation acc= 0.8682
Epoch 57060: Training cost= 0.2146, Training acc= 0.8684, Validation cost= 0.1866, Validation acc= 0.8682
Epoch 57070: Training cost= 0.2170, Training acc= 0.8684, Validation cost= 0.2529, Validation acc= 0.8682
Epoch 57080: Training cost= 0.2068, Training acc= 0.8684, Validation cost= 0.2525, Validation acc= 0.8683
Epoch 57090: Training cost= 0.3008, Training acc= 0.8684, Validation cost= 0.2687, Validation acc= 0.8683
Epoch 57100: Training cost= 0.2277, Training acc= 0.8684, Validation cost= 0.2781, Validation acc= 0.8683
tm  [-0.5 -0.2  2.4 27.9 -0.6  0.1 -0.2 -0.  -0.2 -0.6  6.1 -0.2 -0.2 -0.4 -4.7  4.6 -0.6 -0.7  0.8 -1.6 -0.9 -0.3  0.4 -0.3 -0.4 -0.2 -0.2 -0.3 -0.4 -3.  -1.3 -0.3 -0.8 -4.9  0.1  0.   0.9  8.  28.2 -0.4  2.7  1.8 -0.1 -0.2 -0.2 -0.2 10.2  2.4 -0.5  0.5 -0.3 -0.1 -0.1 -0.7 -1.3  5.8 -0.8 10.7  0.7  6.6 -1.  -0.5 -0.9 -0.1 -1.  -0.1 -0.  -0.2 -0.1 -0.  -0.1 -1.5 -0.3 -0.3  7.2  0.  -0.   0.2 -0.  -0.  12.8 -0.1 -0.3  2.9  0.4  2.9 -1.9 -0.3 -0.2 -0.4 -0.7 -0.1 -0.  -0.  -0.6  0.6  1.1 -0.1 -0.5 -0.3  2.5 -1.1  0.9  0.2 -0.6 -0.4  0.1 -0.4  1.4 -2.5 -0.7 -0.3 -0.3 -0.3 -1.1  9.2  3.6 -0.7 -0.4 -0.4 -0.   9.6  0.2  0.7 -0.2 -6.  -0.1  3.7  3.3 -1.8 -0.7 -0.  -0.5 -0.8 -1.2 -5.1 -0.3 -0.2 -0.5 -0.4 -0.4 -0.3 -0.3 -0.1 -0.2 -0.1  0.5 -0.2  6.9 -0.1 -3.5 -0.1 -0.3 -0.3  0.1  0.4 -0.2 -0.8  1.6 -0.7  0.2 -0.8 -0.2 -0.1 -0.  -0.  -0.3 -0.4 -0.  -0.   0.   0.1 -0.2 -0.1 -0.1 -1.6  1.8 -0.5 -2.7 -0.1 -2.  -0.  -0.2 -0.9 -0.2  1.4 -0.4 -0.2 -0.3  8.  -0.2 -0.2 -0.3 -0.6  8.1 -1.2  0.2  3.6 -0.2 -0.2  0.   0.1 -0.5 -0.4  0.   2.5 -0.2 -0.3 -1.4 -0.3 -0.7 -0.1 -0.2  1.8 -0.5 -0.3  0.1 -0.8 -0.4 -0.8 -0.1 -0.2 -0.5 -0.7 -1.6  3.6  2.4 -0.6 -0.3  0.1 -0.8 -1.3 -0.2 -0.5 -0.3 -0.6 -0.6  0.6 -0.   7.8 -0.1  1.6 -0.1 -0.  -2.2 -2.   1.7 -0.1 -0.6 -0.5 -3.3 -0.  14.9 -0.3 -0.4  7.3]
ty_50sample [[9 2 5 3 8 8 7 0 4 6]
 [8 6 7 1 5 9 3 0 4 2]
 [6 2 1 7 0 8 3 4 9 5]
 [7 3 6 8 4 1 9 0 2 5]
 [4 5 1 3 9 7 6 2 0 8]
 [8 9 0 3 5 1 4 6 7 7]
 [4 2 7 3 5 9 6 1 8 0]
 [9 1 7 6 4 5 2 0 3 8]
 [4 2 6 8 1 5 5 3 9 9]
 [3 0 9 8 1 7 5 6 4 2]]
tt_50sample [[9 2 5 3 1 8 0 7 4 6]
 [8 6 7 1 5 9 3 0 4 2]
 [6 2 1 7 8 0 3 4 9 5]
 [7 3 6 8 4 1 9 0 2 5]
 [4 5 1 3 9 7 6 2 0 8]
 [8 9 0 3 5 1 4 6 7 2]
 [4 2 7 3 5 9 6 1 8 0]
 [9 1 7 6 5 4 2 0 3 8]
 [4 2 6 8 1 5 3 7 0 9]
 [3 0 9 8 1 7 5 6 4 2]]
vm  [-0.3 -0.1 -0.8  8.8 -1.3  0.  -0.4 -0.3 -0.2 -0.4 -8.7  0.1 -0.  -0.3 -1.7  1.2  1.1 -0.7 -0.4 -0.7 -1.2  0.  -0.3 -0.2 -0.9  1.8  0.2 -0.5  1.6  3.4 -0.9 -0.3 -1.  -6.6  0.2  0.8 -0.7 -0.8  8.   1.9  1.2 -0.8  2.   0.4 -0.1 -0.2  4.1  0.   8.   9.6 -0.3 -0.2 -0.6 -2.9 -1.3  1.5 -0.1  0.9 -1.6  5.6 -1.1 -1.  -0.2  0.  -0.1 -0.2 -0.  -0.   0.7  0.4 -0.2 -1.8 -0.   3.5 -0.8 -0.6 -0.1  2.  -0.  -0.3 -3.2  0.1 -0.2 -1.1 -1.8 -0.6  5.9 -0.4 -0.1 -0.6  1.3 -0.  -0.2 -0.6 -1.2 -0.3  0.3 -2.5  0.4 -0.4 -0.  -1.1 -0.3  0.2 -0.4 -0.2  1.9 -0.5 -2.1 -1.   0.2 -0.3 -0.  -0.1 -1.2 19.1 -0.8 -0.5 -0.2 -0.5  0.1  5.4  1.7 -0.5  0.2 -2.1 -0.1 10.5 -1.4 -1.   1.8  0.4 -0.2 -0.2  5.6 -5.4  0.4  0.2  1.7  5.8  1.2 -0.3  1.2 -0.1 -0.  -0.3  1.  -0.1  5.  -0.1 -1.1 -0.  -0.1  2.8 -0.1 -0.2 -0.8 -0.8  0.5 -0.1 -1.  -0.4  0.4 -0.1 -0.  -0.3  0.  -0.3  0.7 -0.2  0.5 -0.1 -0.4 -0.3 -0.2 -0.4 -0.7 -0.3 -0.8 -0.2 -0.8 -0.2 -0.6 -2.1 -0.1  0.  -0.5 -0.8 -0.5 -0.7 -0.  -0.1 -0.2 -0.6 11.7  5.   1.   3.8 -0.2 -0.2 -0.2  0.4 -0.  -0.4 -0.   2.9 -0.1 -0.4 10.6 -0.  -0.2  4.8 -0.8 -1.2 -0.9 -0.7 -0.2 -0.7 -0.4 -0.5 -0.   0.3 -0.6 -1.  -0.4  2.5 -2.2  0.  -0.9  2.3 -0.1 -1.7  0.1 -0.3 -1.3  1.2 -0.8  1.   3.6 10.1 -0.3  2.3 -0.2  0.3  9.9 -1.7 -0.8 -0.4 -1.   3.4  7.1 -0.1  5.  -0.2  9.6  5.5]
vy_50sample [[8 9 3 4 5 5 7 1 2 0]
 [4 8 0 5 1 7 6 3 9 2]
 [9 2 0 5 7 8 6 1 4 3]
 [1 3 8 2 6 7 9 5 4 0]
 [7 0 5 4 8 9 3 6 2 1]
 [6 1 9 5 7 3 2 0 8 4]
 [6 8 0 1 3 5 9 2 4 7]
 [0 0 8 1 5 4 7 6 2 3]
 [4 3 5 0 8 1 7 6 9 2]
 [3 4 8 2 2 1 5 0 7 6]]
vt_50sample [[8 9 3 4 5 6 7 1 2 0]
 [4 8 0 1 5 7 6 3 2 9]
 [9 2 0 5 7 8 1 6 4 3]
 [1 3 8 2 6 7 9 5 4 0]
 [7 0 5 4 8 9 3 6 2 1]
 [6 1 9 5 3 7 2 0 8 4]
 [6 8 0 1 3 5 9 2 4 7]
 [0 9 8 1 5 4 7 6 2 3]
 [4 3 5 0 8 1 7 6 2 9]
 [3 4 8 2 9 1 0 5 7 6]]
Epoch 57110: Training cost= 0.3111, Training acc= 0.8684, Validation cost= 0.2367, Validation acc= 0.8683
Epoch 57120: Training cost= 0.2481, Training acc= 0.8684, Validation cost= 0.2663, Validation acc= 0.8683
Epoch 57130: Training cost= 0.2603, Training acc= 0.8684, Validation cost= 0.2172, Validation acc= 0.8683
Epoch 57140: Training cost= 0.2022, Training acc= 0.8684, Validation cost= 0.2100, Validation acc= 0.8683
Epoch 57150: Training cost= 0.2318, Training acc= 0.8684, Validation cost= 0.2302, Validation acc= 0.8683
Epoch 57160: Training cost= 0.2009, Training acc= 0.8684, Validation cost= 0.2272, Validation acc= 0.8683
Epoch 57170: Training cost= 0.2074, Training acc= 0.8684, Validation cost= 0.2398, Validation acc= 0.8683
Epoch 57180: Training cost= 0.1655, Training acc= 0.8685, Validation cost= 0.2379, Validation acc= 0.8683
Epoch 57190: Training cost= 0.2261, Training acc= 0.8685, Validation cost= 0.2412, Validation acc= 0.8683
Epoch 57200: Training cost= 0.2293, Training acc= 0.8685, Validation cost= 0.2665, Validation acc= 0.8683
tm  [-1.2 -0.   8.2 22.6 -1.3 -0.4 -0.4  0.2  0.2 -0.1 -0.4 -0.3 -0.3  0.3 -0.6 -0.9 -0.5 -0.2 -0.6 -1.3 -1.2 -0.   0.  -0.2 -0.3  0.9 -0.5 -0.6 -0.1 -3.   1.1 -0.1 -0.2 15.  -0.1 -0.3 -1.1 -0.5 21.7 -0.3  5.8  2.6 -0.8  0.2 -0.3 -0.2  8.9 -0.1 -0.9 -0.2 -0.1 -0.1  1.  -4.7 -1.3  0.5 -0.6  4.7  8.6  0.3 -0.4 -0.5  0.1 -0.2  2.  -0.3 -0.4 -0.2  2.  -0.4 -0.3 -1.9  0.1 -0.1 -0.4 -0.7 -0.1  2.2 -0.1 -0.4 26.  -0.2  0.2 -0.4 -0.1  2.3 -2.  -0.3 -0.2 -0.6 -0.  -0.3 -0.2 -1.2 -1.   0.2 -0.  -2.  -0.5 -0.6 -0.2  4.7  1.5 -0.1 -0.1  0.8  2.1 -0.1  0.2 -2.  -0.1 -0.2 -0.1 -0.6  3.9 10.   0.9  1.4 -0.2 -0.6 -0.6  7.2 -0.5  0.2  0.1 -0.8 -0.2 15.  10.8 -4.1 -0.8 -0.5 -0.9  0.3 -5.5  2.6 -0.3 -0.1 -0.4 -0.4  1.4 -0.1  0.2 -0.3 -0.2 -0.1 -0.3 -0.2 -0.3 -0.1 -2.7 -0.1 -1.3  3.4 -0.2 -0.1 -0.1 -0.4  3.1 -0.3 -1.3 -1.6  0.2 -0.1 -0.7 -0.1 -0.  -0.5 -0.5  0.  -0.1 -0.2 -0.  -0.2  0.4 -0.1 -0.6 -0.1 -1.9  0.1 -1.  -0.4 -0.2 -1.8 -0.3 -0.4 -0.3 -0.1 -0.2  7.9 -0.1 -0.2 -0.5 -0.7  5.9 -3.7  0.6 -1.4 -0.1 -0.2 -0.2  0.5 -0.1 -0.2  0.1  6.4 -0.1 -0.4 -3.  -0.1 -0.3  4.3 -0.2  4.3 -1.4 -0.7 -0.8 -1.4 -0.5 -1.  -0.1 -0.  -0.2 -0.6 -1.   2.6 -3.1 -0.9 -0.6 -0.8 -0.3 -1.1 -0.3 -0.7 -0.7 -2.  -1.1 -0.2  4.  13.  -0.1  2.5 -0.  -0.2 -5.2 -3.  -0.5 -0.4 -1.2  2.7 -6.5 -0.  12.3 -0.2  8.1 14.4]
ty_50sample [[9 7 5 5 3 3 4 8 2 2]
 [6 9 7 4 1 0 3 5 2 8]
 [9 4 3 8 6 0 2 2 7 1]
 [0 9 7 5 1 2 4 8 6 3]
 [3 0 4 1 7 2 9 8 5 6]
 [6 5 5 7 0 4 8 3 1 2]
 [2 6 7 4 8 5 1 0 3 9]
 [5 2 1 6 7 3 9 4 4 8]
 [1 0 4 7 8 3 5 6 2 9]
 [8 0 7 9 3 6 5 1 2 4]]
tt_50sample [[9 7 1 5 3 4 0 8 6 2]
 [6 9 7 4 1 0 3 5 2 8]
 [9 4 3 8 6 0 5 2 7 1]
 [0 9 7 5 1 2 4 8 6 3]
 [3 0 4 1 7 2 9 8 5 6]
 [6 9 5 7 0 4 8 3 1 2]
 [2 6 7 4 8 5 1 0 3 9]
 [5 2 1 6 7 3 9 4 8 0]
 [1 0 4 7 8 3 5 6 2 9]
 [8 0 7 9 3 6 5 1 2 4]]
vm  [-0.7 -0.1 -3.  -4.4 -1.8 -0.3 -0.7  0.2 -0.5  0.7  6.9 -0.2 -0.2 -0.2  4.7  0.1 -0.5 -0.2 -0.8  2.1 -2.1 -0.4 -0.5  0.7 -0.8  1.6 -0.4 -0.5 -0.8 -1.7  0.7 -0.3  0.3  2.5 -0.1 -0.1 -0.6 -1.6 -7.3 -0.4  3.1 -2.3 -1.  -0.2  0.  -0.  -2.9 -0.   2.5 -2.2  0.  -0.1 -0.   7.3 -0.9 -0.8 -0.6 -3.   9.5 -2.6  5.  -0.7  1.   0.6 -0.1 -0.3  0.3 -0.2 -0.4 -0.3 -0.  -0.4 -0.   2.2 -6.3 -0.7 -0.1 -0.2 -0.  -0.5 -0.9  0.2 -0.1 -0.7 -0.8 -2.   3.8 -0.4 -0.1 -0.4 -0.   0.1  0.8 -0.7 -0.4  0.9 -1.  -4.4  0.6  0.  -0.6 -1.2 -0.4 -0.1 -0.3 -0.8 -1.8  1.   1.9  1.9 -0.8 -0.2  0.  -0.9  4.8  3.7 -0.2  1.1 -0.5 -0.4 -0.2 -1.3 -0.2  1.  -0.2  5.3  0.  -1.   9.2 11.5 -0.5 -0.   0.6 -0.1 17.6 21.9 -0.2 -0.2  0.4 -1.1  1.7 -0.5 -0.5 -0.2 -0.1 -0.4  0.3 -0.2  1.1 -0.1  3.9 -0.2 -0.5  0.3  0.1 -0.  -0.4 -0.2 -0.1 -0.4 -0.5 -0.3 -0.1 -0.1 -0.2 -0.   0.  -0.   0.7 -0.1 -0.2 -0.1 -0.4 -0.  -0.   2.1 -1.3  0.3  6.8 -0.1  0.9 -0.4 -0.1 -2.  -0.3 -0.2 -0.2 -0.3 -0.3  5.1 -0.1 -0.3  0.4 -1.6 -1.9 -3.4 -0.  -1.3 -0.1 -0.1 -0.2 -0.1 -0.1 -0.7 -0.3 -2.5 -0.2 -0.2  0.8 -0.3 -0.6 -0.2 -1.3  3.5 -1.  -0.4  1.4 -1.6 -0.6  1.4 -0.3  0.3 -0.4 -0.9  1.4 -0.6 -2.2 -0.1  2.2 -0.4  4.5 -0.7 -0.1 -0.  -0.4  5.5 -0.2 -0.1  6.  -0.9 -0.1 -0.9  0.5 -0.   4.9  1.8 -0.8  1.3 -1.7  0.9  1.9  0.8 -3.9 -0.4  5.6 -2.5]
vy_50sample [[6 4 3 1 0 2 7 5 8 9]
 [2 4 7 1 6 0 9 8 3 5]
 [5 1 0 0 6 2 3 7 4 9]
 [6 7 7 3 8 2 4 1 5 0]
 [5 3 2 6 1 7 9 9 0 4]
 [1 4 5 3 7 9 9 0 2 6]
 [5 8 0 7 9 4 2 3 1 6]
 [8 6 3 4 0 1 9 5 7 2]
 [9 6 8 3 4 1 5 0 7 2]
 [8 6 3 2 9 1 7 5 0 4]]
vt_50sample [[6 4 3 1 0 2 7 5 8 9]
 [2 4 7 1 6 0 9 8 3 5]
 [5 1 0 8 6 2 3 7 4 9]
 [6 9 7 3 8 2 1 4 5 0]
 [5 3 2 6 1 7 9 8 0 4]
 [1 4 5 3 7 9 8 0 2 6]
 [5 8 0 7 9 2 4 3 1 6]
 [8 6 3 4 0 1 9 5 7 2]
 [9 6 8 3 4 1 5 0 2 7]
 [8 3 6 2 1 9 7 5 0 4]]
Epoch 57210: Training cost= 0.2376, Training acc= 0.8685, Validation cost= 0.2330, Validation acc= 0.8683
Epoch 57220: Training cost= 0.2202, Training acc= 0.8685, Validation cost= 0.2699, Validation acc= 0.8683
Epoch 57230: Training cost= 0.2428, Training acc= 0.8685, Validation cost= 0.2483, Validation acc= 0.8683
Epoch 57240: Training cost= 0.2254, Training acc= 0.8685, Validation cost= 0.2263, Validation acc= 0.8684
Epoch 57250: Training cost= 0.2551, Training acc= 0.8685, Validation cost= 0.2153, Validation acc= 0.8684
Epoch 57260: Training cost= 0.2545, Training acc= 0.8685, Validation cost= 0.2803, Validation acc= 0.8684
Epoch 57270: Training cost= 0.2504, Training acc= 0.8685, Validation cost= 0.2824, Validation acc= 0.8684
Epoch 57280: Training cost= 0.2447, Training acc= 0.8685, Validation cost= 0.2570, Validation acc= 0.8684
Epoch 57290: Training cost= 0.2456, Training acc= 0.8685, Validation cost= 0.2049, Validation acc= 0.8684
Epoch 57300: Training cost= 0.2788, Training acc= 0.8685, Validation cost= 0.2427, Validation acc= 0.8684
tm  [-0.6 -0.1  3.7 14.2 -1.4 -0.5  0.7  1.  -0.6 -0.1 -0.6  0.3 -0.1 -0.1 -1.6 -0.6 -0.1 -0.1  0.8 -1.7 -1.3 -0.2 -0.9 -0.1 -0.2 -0.4 -0.3  1.1 -0.6 -0.8  0.3 -0.5 -0.5 13.9 -0.2 -0.1  1.6 -0.1 25.5 -0.3 -0.2  0.3  0.8  2.  -0.1 -0.3 10.   1.4 -1.2 -5.  -0.1 -0.1 -0.2 -5.8 -1.3  1.1 -0.4  6.5 -0.7 -2.1 -0.6 -0.8 -0.6 -0.3  1.2 -0.6 -0.5 -0.   0.4 -0.3 -0.2 -0.6 -0.1 -0.7  2.9 -0.  -0.1 -0.3 -0.1 -0.2 31.8 -0.3 -0.3 -0.5 -0.  -0.2 -0.5 -0.2 -0.6 -0.2 -0.2  0.1  0.4  1.9 -0.9 -0.7 -0.1  0.1 -0.2 -0.1  1.4 -1.   2.5  0.2 -0.2 -0.1 -0.7  0.3 -0.1 -2.4  0.2  0.  -0.1 -0.4 -0.7  3.7  0.9 -0.3 -0.1 -0.4 -0.3  9.7 -0.2  0.3  0.5 -2.2 -0.1 17.1  2.2  1.  -0.1  0.  -0.1 -0.1 -4.4  2.2 -0.1 -0.1  0.  -0.7 -0.   0.3  1.  -0.3 -0.  -0.2 -0.2 -0.   5.2 -0.2 -1.5  0.2 -1.5 -0.1  0.1 -0.2  0.1 -0.5  1.1 -0.5 -0.4 -0.8 -0.2 -0.   0.9  2.  -0.1 -0.4 -0.2  0.2 -0.2 -0.1 -0.1  0.7  0.2 -0.6  2.2 -0.5 -2.4  0.  -2.4 -0.3 -0.1 -1.1 -0.3  0.3 -0.4 -0.3 -0.4  2.7 -0.   0.  -0.3 -1.   6.9 -0.6 -0.1  2.6 -0.2 -0.  -0.3 -0.   2.2 -0.5  1.   2.2  0.4 -0.1 -5.8 -0.1 -0.5 -0.6 -0.4  4.4  1.5  0.2 -1.2 -1.  -0.6 -0.3 -0.1 -0.2  0.4 -0.3 -2.1 -0.3 -2.1 -0.4 -0.9 -0.2 -0.6 -0.6  0.  -0.7 -0.6 -0.4 -0.1 -0.3  0.8  4.3 -0.  -0.3  0.4 -0.2 -6.6 -1.7 -0.3 -0.4 -0.8 -0.6 -7.9 -0.1 14.8 -0.3 10.4  1.1]
ty_50sample [[9 3 5 1 7 4 0 6 8 2]
 [2 3 7 0 1 4 9 8 5 6]
 [8 7 0 6 9 1 2 3 5 4]
 [7 4 0 5 6 9 3 2 8 1]
 [2 0 7 3 9 5 8 4 1 6]
 [7 0 0 1 5 6 2 8 3 4]
 [0 0 6 6 4 2 8 8 5 3]
 [8 3 4 6 5 9 2 1 0 7]
 [3 6 9 1 5 4 2 0 7 8]
 [8 5 9 4 7 2 3 0 1 6]]
tt_50sample [[9 3 5 1 7 4 0 8 6 2]
 [2 3 7 0 4 1 9 8 5 6]
 [8 7 0 6 9 1 2 3 5 4]
 [7 4 0 5 6 9 3 2 8 1]
 [2 0 7 3 9 5 8 4 1 6]
 [7 9 0 1 5 6 2 8 3 4]
 [7 0 1 6 4 2 8 5 3 9]
 [8 3 4 6 5 9 2 1 0 7]
 [3 6 9 1 5 4 2 0 7 8]
 [8 5 9 4 7 2 3 0 1 6]]
vm  [-1.   0.1 -0.6 16.6 -2.1 -0.3 -0.1  0.6 -0.7  0.1 -1.   0.6 -0.3 -0.4 -3.4 -0.9 -0.5 -0.2 -0.5 -1.  -1.7 -0.2 -0.5  0.2 -0.6  3.1 -0.4 -0.5 -0.8 -2.5  1.7 -0.2 -0.5  5.2 -0.1 -0.   1.1  0.8 26.6 -0.2  5.2 -1.6 -0.4  3.2 -0.1 -0.3  9.1  0.9 -1.3 -2.1 -0.2  0.2  1.8 -5.5 -1.   3.9 -0.4 -1.4  1.3 -1.2 -0.3 -0.9 -0.2 -0.3  0.3 -0.3 -0.2 -0.1  1.1 -0.2 -0.3 -0.5  0.8 -0.2  7.3 -0.2 -0.  -0.2 -0.  -0.5 27.3  0.5  0.  -0.4  0.5 -1.4 -0.6 -0.4 -0.2 -0.4  1.   0.   0.1 -0.3 -0.7  1.1 -0.6  0.8 -0.2 -0.  -0.  -0.6  1.4 -0.2 -0.2 -0.   3.9  0.5 -0.3 -1.7 -0.4 -0.2 -0.1 -0.2  0.6  2.5  2.1 -0.7 -0.1 -0.4 -0.3  7.2 -0.1 -0.2 -0.1 -4.3  0.1 16.3  1.6 -2.2 -0.5  0.2 -0.1 -0.2 -2.1 -0.9 -0.1 -0.   0.4 -0.5  1.4 -0.2  1.1 -0.1  0.1 -0.1  0.2 -0.  -0.2 -0.1 -2.3 -0.1 -1.6  0.8 -0.   0.4 -0.3 -0.4  3.  -0.5 -0.3 -1.4 -0.2 -0.1 -0.1 -0.1 -0.  -0.2  0.6 -0.  -0.2 -0.1 -0.4  0.8 -0.2  1.3 -0.2 -0.2 -2.2 -0.1 -0.4 -0.4  0.1 -2.  -0.4  0.9 -0.5 -0.3 -0.3  7.  -0.2 -0.1 -0.1 -1.6  4.9 -0.6  1.7 -0.1  0.1 -0.2 -0.1 -0.1 -0.  -0.4 -0.   8.3 -0.1 -0.3 -0.5 -0.3 -0.3 -0.4 -0.6  8.8 -1.  -0.2 -1.9 -1.1 -0.1  0.7 -0.1 -0.1 -0.2 -0.5 -1.8 -0.2 -2.5 -0.4  2.7 -0.8  0.1 -1.7 -0.  -0.4 -0.7  1.8 -0.5  1.5  3.5 23.9 -0.1  6.2 -0.1  0.2 -5.4 -3.2 -0.5  0.3 -1.  -0.  -6.7  0.1 14.7 -0.2  8.7  8. ]
vy_50sample [[9 1 3 4 0 7 5 8 6 2]
 [6 0 3 9 4 2 8 1 7 5]
 [6 2 1 8 3 9 7 0 5 5]
 [4 8 9 3 6 7 1 5 0 2]
 [3 6 4 2 7 5 1 0 8 9]
 [5 2 1 7 7 3 8 4 9 9]
 [0 7 9 3 4 2 5 6 8 1]
 [1 6 4 7 0 8 2 9 3 5]
 [6 1 8 7 3 9 9 2 5 4]
 [1 9 4 7 5 2 8 0 3 6]]
vt_50sample [[9 1 3 4 0 7 5 8 6 2]
 [6 0 3 9 4 2 8 1 7 5]
 [6 2 1 8 3 9 7 0 4 5]
 [4 8 9 3 6 7 1 5 0 2]
 [3 6 4 2 7 5 1 0 8 9]
 [5 2 1 0 7 3 8 4 9 6]
 [0 7 9 3 4 2 5 6 8 1]
 [1 4 6 7 8 0 2 9 3 5]
 [6 1 8 7 3 9 2 0 5 4]
 [1 9 4 7 5 2 8 3 0 6]]
Epoch 57310: Training cost= 0.2196, Training acc= 0.8686, Validation cost= 0.2522, Validation acc= 0.8684
Epoch 57320: Training cost= 0.2275, Training acc= 0.8686, Validation cost= 0.2878, Validation acc= 0.8684
Epoch 57330: Training cost= 0.2141, Training acc= 0.8686, Validation cost= 0.2510, Validation acc= 0.8684
Epoch 57340: Training cost= 0.2436, Training acc= 0.8686, Validation cost= 0.2690, Validation acc= 0.8684
Epoch 57350: Training cost= 0.2483, Training acc= 0.8686, Validation cost= 0.2582, Validation acc= 0.8684
Epoch 57360: Training cost= 0.2736, Training acc= 0.8686, Validation cost= 0.2769, Validation acc= 0.8684
Epoch 57370: Training cost= 0.2635, Training acc= 0.8686, Validation cost= 0.1935, Validation acc= 0.8684
Epoch 57380: Training cost= 0.2248, Training acc= 0.8686, Validation cost= 0.2054, Validation acc= 0.8684
Epoch 57390: Training cost= 0.2179, Training acc= 0.8686, Validation cost= 0.2449, Validation acc= 0.8684
Epoch 57400: Training cost= 0.2204, Training acc= 0.8686, Validation cost= 0.2813, Validation acc= 0.8685
tm  [-0.4 -0.3 -0.3 14.5 -0.9 -0.2  0.  -0.4 -1.1 -0.1 10.  -0.3 -0.2 -0.1 -2.6 -0.3 -0.4 -0.3 -0.3 -1.2 -1.3 -0.1 -0.  -0.2 -0.6  1.  -0.1 -0.7 -0.8 -2.1  0.6 -0.  -0.5  6.5 -0.  -0.2  2.5  2.5  7.2 -0.2  3.3  8.8  1.7  0.6 -0.1  0.2  6.1 -0.2 -1.7 -0.6 -0.  -0.2 -0.3 -0.  -0.5  3.3 -0.4  8.8  1.3 -1.6  1.5 -0.3 -0.8 -0.1  1.4 -0.7  0.  -0.2 -0.  -0.1  0.3  2.9 -0.2 -0.3 -0.5 -0.6 -0.1 -0.6 -0.1 -0.5 26.2 -0.1 -0.3 -0.2  1.4  8.1 -1.5 -0.1 -0.3 -0.4  0.6 -0.1  0.2 -0.  -1.  -1.1 -0.1 -1.8 -0.4 -0.6  1.4  3.8  1.4  0.  -0.3  0.2 -1.1 -0.3 -0.3 -1.5 -0.6 -0.2 -0.1 -0.3  1.6 -1.2  2.3 -0.7 -0.   0.2 -0.3  6.4  0.3 -0.4  0.3 -3.4  0.1  2.6  4.1 -3.  -0.4 -0.1 -0.3 -0.4  6.9 14.2 -0.3 -0.2 -0.5 -0.4 -0.3 -0.3 -0.  -0.2 -0.1 -0.5 -0.1 -0.2  8.3 -0.3 -1.8 -0.1 -1.9 -0.1 -0.1 -0.2 -0.  -0.2 -0.1 -0.1  0.3 -0.6 -0.2 -0.  -0.5 -0.3 -0.3 -0.3  0.1  0.3 -0.1 -0.   0.3 -0.   0.2 -1.9 -0.8 -0.5 -0.5 -0.1 -2.2 -0.1 -0.5 -1.4  0.1 -0.1 -0.2 -0.5  1.2  6.1  0.1 -0.2 -0.3 -0.6  0.8 -1.  -0.  -0.4 -0.1  0.1  0.2 -0.2 -0.1  0.5 -0.3 -0.5 -0.2 -0.  -7.5 -0.2 -0.5 -1.3 -0.3  5.9 -0.6 -0.6  1.2 -1.1  0.3 -0.3  0.1 -0.2 -0.1 -0.5  3.1 -1.6 -0.1 -0.4  1.  -0.4 -0.6 -0.5 -0.1 -1.2  0.8 -0.1  0.3 -0.2  0.5 -1.5  0.5 -1.2 -0.1 -0.  -5.5 -1.1  0.4 -0.4 -1.3 -0.1 -6.6 -0.4  3.9 -0.1 -0.8 11.8]
ty_50sample [[5 1 0 0 2 6 4 7 3 8]
 [4 1 3 7 6 5 0 8 9 2]
 [2 7 8 5 3 3 9 4 1 0]
 [6 9 7 8 4 3 0 5 5 2]
 [4 6 3 8 8 7 9 5 0 2]
 [4 1 2 8 7 0 6 9 5 3]
 [9 4 8 7 5 1 3 0 6 2]
 [1 5 9 6 0 4 2 8 7 3]
 [0 4 1 5 3 7 8 2 9 6]
 [2 5 7 4 8 9 1 6 3 0]]
tt_50sample [[5 1 0 9 2 6 4 7 3 8]
 [4 1 3 7 6 5 0 8 9 2]
 [2 7 8 5 3 6 9 4 1 0]
 [6 9 7 8 4 3 0 1 5 2]
 [4 6 3 8 1 7 9 5 0 2]
 [4 1 2 8 7 0 6 9 5 3]
 [9 4 8 7 5 1 3 0 6 2]
 [5 1 9 6 0 4 2 8 7 3]
 [0 4 1 5 3 7 8 2 9 6]
 [2 5 7 4 8 9 1 6 3 0]]
vm  [-0.2 -0.4  7.6 -1.3 -1.  -0.1 -0.2  0.6 -0.3  0.6  7.7 -0.5 -0.2 -0.2 13.8  5.4 -0.2 -0.5 -0.6 -0.7 -1.6 -0.3  1.5 -0.1 -1.1 -0.4 -0.3 -0.7  1.5  4.4 -0.9  0.3  2.2  4.6 -0.1 -0.1 -0.3  1.5 -6.9 -0.6  4.7 -2.7 -0.3 -0.6 -0.1 -0.3 -1.5 -0.7  3.1  3.6 -0.3  0.2 -0.8 20.6 -1.7 -1.9 -1.  -1.4 -0.2  5.2  2.8 -0.2 -0.6  0.1 -0.6 -0.1  0.5 -0.  -0.6 -0.2 -0.2 -2.2 -0.5 -0.4 -5.7 -0.5 -0.   0.9 -0.1 -0.5 -5.1  0.6 -0.3  0.3 -1.2 -2.6  1.9 -0.3 -0.1 -0.1 -0.5 -0.  -0.1  0.9 -0.8 -0.3 -0.3 -3.5 -0.2 -0.3 -0.3  2.5 -0.4 -0.  -0.3 -0.1 -3.1 -0.2  0.1 -0.2 -0.2 -0.2 -0.2 -0.7 -0.8 11.9 -0.2 -0.4 -0.1 -0.3 -0.1 -0.7 -0.4 -0.7 -0.3 17.5 -0.  -4.2 -0.8 10.3 -0.1 -0.  -0.3  0.9  5.5  9.8 -0.5 -0.3 -0.1 -0.6 -0.5 -0.5 -0.4 -0.3 -0.2 -0.1 -0.3 -0.2 -2.2 -0.3  0.7 -0.1  1.8 -0.3 -0.2  0.3 -0.2 -0.2 -0.6 -0.3 -0.2  0.1 -0.  -0.1 -0.2  0.5 -0.6 -0.4 -0.2 -0.2 -0.1 -0.2 -0.2 -0.2 -0.   3.2 -1.6 -0.3  6.5 -0.1  1.7 -0.3 -0.2 -1.1 -0.  -0.9 -0.1 -0.9 -0.3 -1.  -0.1 -0.3 -0.2 -1.  -0.5  1.9 -0.6  1.7 -0.   0.2  0.1 -0.1  0.3 -0.3 -0.2 -3.4  0.  -0.4 10.6 -0.1 -0.6  1.9 -0.4 -1.3 -0.6 -0.2  4.9 -1.  -0.5 -0.3 -0.  -0.3 -0.1 -1.1  0.9  4.3  2.9 -0.5  1.   0.1 -0.1  3.5 -0.2 -0.  -1.5 -1.4 -0.2 -0.7  1.8  3.6 -0.1 -0.1 -0.2 -0.2 15.5  4.2 -0.4 -0.6 -1.2  0.3 13.6  0.4 -3.7 -0.4 -1.1 -2.2]
vy_50sample [[2 6 7 8 3 4 1 9 5 5]
 [9 6 8 1 2 5 4 0 3 7]
 [0 6 9 8 5 3 1 7 2 4]
 [9 2 1 3 5 8 7 6 4 0]
 [2 2 0 0 6 4 5 5 7 3]
 [1 5 6 0 7 9 4 3 2 8]
 [8 1 0 6 2 7 4 9 5 3]
 [2 5 6 3 8 0 1 9 7 4]
 [3 2 7 4 8 0 9 6 1 5]
 [2 6 5 1 9 7 4 3 0 8]]
vt_50sample [[2 6 7 8 3 4 1 9 5 0]
 [9 6 8 1 2 5 4 0 3 7]
 [0 6 9 8 5 3 1 7 2 4]
 [9 2 1 3 5 8 7 6 4 0]
 [1 8 2 0 6 4 9 5 7 3]
 [1 6 5 0 7 9 4 3 2 8]
 [8 1 0 6 2 7 4 9 5 3]
 [2 5 6 3 8 0 1 9 7 4]
 [3 7 2 4 8 0 9 6 1 5]
 [2 6 5 1 9 7 4 3 0 8]]
Epoch 57410: Training cost= 0.2772, Training acc= 0.8686, Validation cost= 0.2990, Validation acc= 0.8685
Epoch 57420: Training cost= 0.2513, Training acc= 0.8686, Validation cost= 0.2192, Validation acc= 0.8685
Epoch 57430: Training cost= 0.1988, Training acc= 0.8686, Validation cost= 0.2124, Validation acc= 0.8685
Epoch 57440: Training cost= 0.2162, Training acc= 0.8686, Validation cost= 0.2495, Validation acc= 0.8685
Epoch 57450: Training cost= 0.2029, Training acc= 0.8687, Validation cost= 0.2283, Validation acc= 0.8685
Epoch 57460: Training cost= 0.2290, Training acc= 0.8687, Validation cost= 0.2169, Validation acc= 0.8685
Epoch 57470: Training cost= 0.1956, Training acc= 0.8687, Validation cost= 0.2453, Validation acc= 0.8685
Epoch 57480: Training cost= 0.2014, Training acc= 0.8687, Validation cost= 0.2259, Validation acc= 0.8685
Epoch 57490: Training cost= 0.2045, Training acc= 0.8687, Validation cost= 0.2598, Validation acc= 0.8685
Epoch 57500: Training cost= 0.1757, Training acc= 0.8687, Validation cost= 0.2887, Validation acc= 0.8685
tm  [-1.  -0.1 -3.5 13.4 -0.6 -0.1  0.4 -0.3 -1.4 -0.2  9.   0.4 -0.3 -0.4 -5.7 -0.3 -0.3  0.  -0.3 -0.6 -1.5 -0.1 -0.2  0.2 -0.6  1.  -0.5 -0.2 -1.2 -4.   1.1 -0.2 -0.7 -3.6 -0.1 -0.2  3.9  7.5 23.5 -0.1  1.2 -1.3 -0.4  1.6 -0.1 -0.2  7.3 -0.1 -2.7 -1.3 -0.2 -0.1 -0.1 -0.1 -0.3  6.8 -0.3 -0.3 -0.1 -0.7  2.3 -0.2 -0.3 -0.3 -0.3 -0.3  0.3 -0.5  0.  -0.1 -0.2  3.8 -0.3 -0.3  4.1 -0.  -0.2 -0.5 -0.1 -0.7 22.1 -0.2 -0.1 -0.5  1.8 -0.8 -1.8 -0.3 -0.  -0.3 -0.2 -0.2 -0.1  1.7 -0.5 -0.1 -0.3  1.3 -0.5 -0.2  1.5 -1.2  0.4 -0.3 -0.2 -0.2 -0.6 -0.1 -0.1 -2.2 -0.2 -0.3 -0.3 -0.2 -0.2 -1.6  2.8 -1.1  0.2  0.2 -0.2  8.8  0.3 -0.4 -0.  -7.3  0.1  1.5 -0.  -1.8 -0.3 -0.1 -0.   0.4  6.6 -1.4 -0.3  0.1 -0.1 -0.4 -0.2 -0.4 -0.2 -0.2 -0.1 -0.2 -0.2 -0.1  4.3 -0.3 -1.5 -0.2 -2.   1.  -0.  -0.1  0.4 -0.4  0.4 -0.5 -0.3 -1.3 -0.2 -0.1 -0.2  0.4 -0.1 -0.2 -0.1 -0.1 -0.2  0.1 -0.5 -0.2 -0.1 -0.9  2.1 -0.3 -2.  -0.1 -0.8  0.2  1.  -1.  -0.2  1.1 -0.6  0.8 -0.  11.8 -0.2 -0.4 -0.3 -1.1 -0.   0.6  0.6  0.4 -0.1 -0.  -0.1 -0.1  0.1 -0.1 -0.3  3.3 -0.1 -0.3 -0.6 -0.5 -0.3 -1.6 -0.3 10.2  1.4 -0.2 -1.  -1.1 -0.2  1.  -0.2 -0.2  0.8 -0.5 -0.9 -1.2  0.3 -0.3  0.1 -1.1 -1.  -0.8 -0.4 -0.2  1.   3.6 -0.3 -0.2  0.  18.4 -0.2  4.4 -0.3 -0.  -4.4 -1.8 -0.1 -0.1 -1.1  0.7 -5.6 -0.2 13.  -0.1 -0.1  7.6]
ty_50sample [[1 9 2 0 3 4 5 8 6 7]
 [2 6 4 9 3 0 7 5 1 8]
 [6 4 9 7 5 1 8 0 3 2]
 [8 1 4 5 2 6 0 3 3 7]
 [5 9 0 7 3 1 6 4 8 2]
 [9 2 3 6 1 4 7 0 0 5]
 [8 5 0 3 2 1 6 6 9 4]
 [0 5 9 4 7 2 3 6 1 8]
 [4 7 5 1 1 3 6 0 8 2]
 [3 1 8 8 6 7 9 4 0 2]]
tt_50sample [[1 9 2 0 3 4 5 8 6 7]
 [2 6 4 9 3 0 7 5 1 8]
 [6 4 9 7 5 1 8 0 3 2]
 [8 1 4 5 2 6 0 9 3 7]
 [5 9 0 7 3 1 6 4 8 2]
 [9 2 3 6 4 1 7 8 0 5]
 [8 5 0 3 2 1 6 7 9 4]
 [0 5 4 9 7 2 3 6 1 8]
 [4 7 5 1 9 3 6 0 8 2]
 [3 1 8 5 6 7 9 4 0 2]]
vm  [ 0.5 -0.3 -3.1 -1.4 -0.7 -0.4 -0.4 -0.6 -0.9  1.6 -3.  -0.3 -0.  -0.1 -1.3 -1.3 -0.2 -0.4  0.3 -0.6 -1.7 -0.2  1.  -0.5 -0.9  0.2  1.3 -0.2 -1.4 -2.4 -0.6 -0.4 -0.8 -7.7 -0.1 -0.1  0.8  2.9  1.7 -0.6  1.7 -2.9 -0.5  2.  -0.4  0.2  1.  -0.3  6.6  9.5 -0.3 -0.4 -1.1  4.8  1.7  2.2 -0.3 -3.5  3.8  4.9 -0.6  1.  -1.  -0.  -0.9 -0.1 -0.2 -0.  -0.2  0.6  0.4  8.9 -0.4  1.1 -3.  -0.5 -0.3 -0.5  0.7 -0.5 -5.2 -0.4 -0.3  0.2 -1.9 -2.4  8.6 -0.   0.3 -0.3 -0.5 -0.  -0.1 -0.4 -0.3 -0.6 -0.5 -3.4 -0.2 -0.2 -0.4 -0.3 -0.8 -0.4  0.6 -0.6 -1.4 -0.3 -0.5 -1.4 -0.1 -0.4 -0.3  0.   6.1 -4.3  1.5  0.1 -0.2  0.3  1.1  5.1 -0.1 -1.2 -0.1 -1.7 -0.3 -0.6  1.   5.  -0.  -0.2  0.4 -0.3  6.9 -5.3 -0.2  0.3 -0.5  0.9 -0.6 -0.6 -0.5 -0.5 -0.1 -0.4 -0.2 -0.1 -0.6 -0.5  1.4  0.3  3.4 -0.6  0.5 -0.2 -0.  -1.1 -0.3 -0.4  0.7 -0.8  0.3 -0.3 -0.2 -0.3 -0.3 -0.3 -0.4 -0.3 -0.2 -0.  -0.7 -0.4 -0.4  1.5 -0.4 -0.7 -0.1  0.   1.6 -0.5 -0.3 -1.  -0.1  3.2 -0.4 -0.1 -0.1  6.4 -0.5 -0.2 -0.2 -0.2  9.2 -0.4 -0.7 -1.8  0.  -0.1 -0.   0.3 -0.  -0.  -0.5 -2.  -0.2  0.2 17.  -0.4 -1.3 -3.  -0.8 -2.3 -0.6 -0.2 -1.  -0.9 -0.1 -0.1 -0.2 -0.4  0.4 -1.  -0.4 -1.8 -0.4 -0.2 -0.4  1.1 -0.6  0.1 -0.3 -0.3  0.8  2.6 -0.  -0.5  1.4 15.8 -0.1  4.1 -0.3 -0.2 15.4  1.   1.3  0.4 -0.9 -0.7 13.3 -0.3  1.1  0.2 -0.4 -0.5]
vy_50sample [[0 8 4 2 3 9 6 7 1 5]
 [5 2 4 9 7 3 6 6 1 0]
 [8 6 2 4 3 5 1 7 9 0]
 [3 2 5 4 6 7 9 9 1 1]
 [8 9 7 6 3 3 0 2 5 1]
 [0 1 1 9 8 2 7 3 5 4]
 [7 2 6 8 1 4 3 0 9 5]
 [4 6 0 8 1 2 3 7 9 5]
 [8 1 2 4 9 0 3 5 6 7]
 [0 2 3 9 1 6 7 8 4 5]]
vt_50sample [[0 8 4 2 3 9 6 7 1 5]
 [5 2 4 9 7 3 6 8 1 0]
 [8 6 2 4 5 3 1 7 9 0]
 [3 2 5 4 6 7 0 9 8 1]
 [8 9 7 6 4 3 0 2 5 1]
 [6 0 1 9 8 2 7 3 5 4]
 [7 2 6 8 1 4 3 0 9 5]
 [4 6 0 8 1 2 3 7 9 5]
 [8 1 2 4 9 0 3 5 6 7]
 [0 2 3 9 1 6 7 8 4 5]]
Epoch 57510: Training cost= 0.2449, Training acc= 0.8687, Validation cost= 0.2218, Validation acc= 0.8685
Epoch 57520: Training cost= 0.1607, Training acc= 0.8687, Validation cost= 0.2517, Validation acc= 0.8685
Epoch 57530: Training cost= 0.1993, Training acc= 0.8687, Validation cost= 0.2570, Validation acc= 0.8685
Epoch 57540: Training cost= 0.2418, Training acc= 0.8687, Validation cost= 0.2426, Validation acc= 0.8685
Epoch 57550: Training cost= 0.2516, Training acc= 0.8687, Validation cost= 0.2330, Validation acc= 0.8685
Epoch 57560: Training cost= 0.2603, Training acc= 0.8687, Validation cost= 0.2451, Validation acc= 0.8686
Epoch 57570: Training cost= 0.2721, Training acc= 0.8687, Validation cost= 0.2372, Validation acc= 0.8686
Epoch 57580: Training cost= 0.2177, Training acc= 0.8688, Validation cost= 0.1901, Validation acc= 0.8686
Epoch 57590: Training cost= 0.2243, Training acc= 0.8688, Validation cost= 0.2016, Validation acc= 0.8686
Epoch 57600: Training cost= 0.2304, Training acc= 0.8688, Validation cost= 0.2431, Validation acc= 0.8686
tm  [-0.1 -0.4 -4.7 -1.7 -0.8 -0.3 -0.1 -0.  -0.4 -0.3 -5.  -0.2 -0.2 -0.2 -2.1 -0.  -0.1 -0.4 -0.7 -0.1 -1.2  0.3 -0.1 -0.3 -1.3  0.3 -0.3 -0.2 -0.1 -1.  -0.2 -0.4 -0.8 -7.9 -0.1 -0.3 -0.4 -0.3  2.4 -0.8  0.4  1.9 -0.   1.7 -0.2 -0.1 -0.1 -0.2  8.2  8.4 -0.1 -0.2 -0.4 -0.7 -0.8  2.1 -0.5 -0.1  2.3  3.2 -0.9 -0.6 -0.2  0.4 -1.2 -0.1 -0.3 -0.5 -0.2 -0.1 -0.1 -0.6 -0.1  1.5 -2.5 -0.2 -0.2  1.  -0.2 -0.4 -3.9 -0.2 -0.1 -0.2 -1.8  3.   9.  -0.1 -0.1 -0.1 -0.3  0.  -0.4 -0.6 -0.9 -0.3  0.3 -2.9 -0.1 -0.1  1.1 -1.1 -0.3 -0.3 -0.3 -0.3 -1.4 -0.4 -1.2 -1.4 -0.5  0.7 -0.2 -0.3 -0.2  8.  -0.2 -0.1 -0.  -0.5 -0.3  4.6 -0.3 -1.2 -0.1 -2.7 -0.3  3.7  3.3  1.5  0.6 -0.4 -0.4 -0.6  9.6 -4.  -0.   0.1 -0.3  0.7  0.3 -0.1 -0.3 -0.2 -0.1 -0.2 -0.1 -0.1  7.5  0.2  1.   0.3  4.2  1.  -0.2 -0.1 -0.6 -1.2 -0.2 -0.2 -0.1 -0.4  0.1 -0.1  0.  -0.1 -0.2 -0.5 -0.2 -0.2 -0.1 -0.  -0.3 -0.  -0.2 -1.5 -0.8 -0.3 -0.4  0.  -1.7 -0.4 -0.7 -1.7  0.   0.1 -0.3  0.6 -0.3  2.9 -0.1 -0.1 -0.3 -0.8 10.8 -1.2 -0.2 -0.  -0.1  0.  -0.3 -0.2 -0.2 -0.4 -0.3 -1.1 -0.1  0.3  5.  -0.1 -0.7  0.6 -0.3 -1.9 -0.9 -0.4 -1.2 -1.3 -0.5 -0.4  0.4 -0.1  0.6 -1.3 -0.2  3.4 -1.5 -0.3 -0.8  2.7 -0.7 -0.5 -0.   0.7 -0.1  3.5 -0.6 -0.3  4.3 -1.1 -0.1 -0.9 -0.  -0.3 12.  -0.4 -0.3 -0.7 -1.3 -0.5  8.9 -0.1  1.4 -0.1  4.7  1.2]
ty_50sample [[8 4 5 9 3 6 0 2 7 1]
 [0 5 3 2 1 6 4 9 7 8]
 [9 3 5 1 8 2 2 0 4 6]
 [9 4 5 6 7 2 3 1 8 0]
 [4 7 3 2 8 9 6 1 0 5]
 [3 1 9 9 4 2 7 6 5 8]
 [5 3 9 7 0 1 2 4 8 6]
 [2 3 0 5 9 1 4 6 7 8]
 [9 4 1 5 5 2 6 3 7 0]
 [9 3 4 7 5 2 6 8 0 1]]
tt_50sample [[8 4 5 9 3 6 0 2 7 1]
 [0 3 5 2 1 6 4 9 7 8]
 [9 3 5 1 8 7 2 0 4 6]
 [9 4 5 6 2 7 3 1 8 0]
 [4 7 3 2 8 9 6 1 0 5]
 [3 1 9 0 4 2 7 6 5 8]
 [5 3 9 7 0 1 2 4 8 6]
 [2 3 0 5 9 1 4 6 7 8]
 [9 4 8 1 5 2 6 3 7 0]
 [9 3 4 7 5 2 6 8 0 1]]
vm  [-1.  -0.1 -0.4 -6.4 -2.2 -0.2 -0.3 -0.1 -0.3 -0.7 -4.3 -0.3 -0.2 -0.6 15.  -0.3 -0.1 -0.6 -0.3  2.6 -1.8 -0.1 -0.  -0.2 -1.3  1.4 -0.3 -0.6 -0.5  0.   1.6 -0.2 -0.3  7.4 -0.  -0.1  0.8 -0.4 -2.  -0.3  4.2 -0.6 -0.   4.7 -0.2 -0.3 -2.7 -0.1 -0.5  0.5 -0.4 -0.2 -0.1  0.9 -1.3 -2.  -1.3 -2.   4.9 -1.9  7.7 -0.3 -0.1 -0.1 -0.8 -0.3 -0.1 -0.1  1.   0.3 -0.4 -0.8 -0.2 -0.2 -4.9  0.4 -0.3 -0.  -0.   1.  -4.5  0.1  0.1  0.   0.3 -0.2  2.9 -0.1 -0.1 -0.4 -0.1 -0.1 -0.1 -0.7 -0.7 -0.2 -0.1 -4.2 -0.6 -0.1  2.5  4.6 -0.2 -0.2 -0.3 -0.2 -2.3  0.1 -1.2  1.5 -0.6 -0.2 -0.3 -0.7  1.2  8.1  0.7 -0.3 -0.1 -0.4  0.  -0.8  0.8  1.2 -0.1 18.5 -0.2  1.7  5.7 11.3 -0.3 -0.1 -0.2 -0.6 -3.7 -1.6  0.7  0.4 -0.7 -0.4  1.3 -0.1  0.1 -0.2 -0.1  0.3  0.5 -0.  -1.3 -0.2  6.6 -0.1 -0.4 -0.5  0.2 -0.2 -0.3 -0.4  2.9 -0.6  0.3 -0.7  0.8 -0.1 -0.3 -0.4 -0.4 -0.2 -0.  -0.1 -0.1  0.5 -0.2  0.1 -0.2  1.7 -0.1 -0.3  2.  -0.2 -0.6 -0.4 -0.5 -2.4 -0.  -0.1 -0.2 -0.1 -0.1  0.4 -0.1 -0.1 -0.2 -1.2 -3.7 -1.9 -0.4 -0.3  0.3 -0.  -0.1 -0.1 -0.2 -0.5 -0.1 -3.2  0.1 -0.3  3.6 -0.4 -0.5  1.3 -0.6  6.6 -0.9 -0.3 -2.4 -1.4  0.2 -0.2 -0.1 -0.1 -0.6 -1.1 -0.7  2.2 -1.4 -0.4  1.5 -0.1 -0.1 -0.3 -0.1  1.1 -0.3  1.3 -0.2 -0.3  3.8 -3.  -0.1 -1.5 -0.2 -0.1 13.9  3.6 -0.4  0.5 -1.3 -0.2 11.3 -0.3 -1.  -0.1  5.9 -2.5]
vy_50sample [[4 7 1 3 8 5 6 0 9 9]
 [8 2 3 0 7 6 9 1 4 5]
 [0 3 2 6 8 5 1 7 9 4]
 [9 9 4 8 3 2 6 1 0 5]
 [6 0 9 4 8 8 5 7 1 2]
 [6 7 4 2 1 9 0 5 8 3]
 [7 9 3 0 1 2 5 8 6 4]
 [5 8 2 0 0 7 3 4 1 6]
 [7 8 6 0 9 4 2 5 3 1]
 [4 2 9 0 8 5 7 3 1 6]]
vt_50sample [[4 7 1 3 8 5 0 6 2 9]
 [8 2 3 0 7 6 9 1 4 5]
 [0 3 2 6 8 5 1 7 9 4]
 [7 9 4 8 3 2 6 0 1 5]
 [6 0 9 4 3 8 5 7 1 2]
 [6 7 4 2 1 9 0 5 8 3]
 [7 3 9 0 1 2 5 8 6 4]
 [5 8 2 0 9 3 7 1 4 6]
 [7 8 6 0 9 4 2 5 3 1]
 [4 2 9 0 8 5 7 3 1 6]]
Epoch 57610: Training cost= 0.2270, Training acc= 0.8688, Validation cost= 0.2532, Validation acc= 0.8686
Epoch 57620: Training cost= 0.1765, Training acc= 0.8688, Validation cost= 0.2631, Validation acc= 0.8686
Epoch 57630: Training cost= 0.1896, Training acc= 0.8688, Validation cost= 0.2267, Validation acc= 0.8686
Epoch 57640: Training cost= 0.2251, Training acc= 0.8688, Validation cost= 0.2169, Validation acc= 0.8686
Epoch 57650: Training cost= 0.2295, Training acc= 0.8688, Validation cost= 0.1932, Validation acc= 0.8686
Epoch 57660: Training cost= 0.1917, Training acc= 0.8688, Validation cost= 0.2371, Validation acc= 0.8686
Epoch 57670: Training cost= 0.2249, Training acc= 0.8688, Validation cost= 0.2405, Validation acc= 0.8686
Epoch 57680: Training cost= 0.2303, Training acc= 0.8688, Validation cost= 0.2920, Validation acc= 0.8686
Epoch 57690: Training cost= 0.2764, Training acc= 0.8688, Validation cost= 0.2434, Validation acc= 0.8686
Epoch 57700: Training cost= 0.2914, Training acc= 0.8688, Validation cost= 0.2613, Validation acc= 0.8686
tm  [-0.4  0.   1.2 11.5 -1.4 -0.2  0.  -0.3 -1.5 -0.5 10.4  0.1 -0.1 -0.1 -2.1 -0.6 -0.4 -0.2 -0.  -1.2 -1.4 -0.3 -0.8 -0.2 -0.5  1.2 -0.4  0.1 -1.1 -2.2  1.  -0.4 -0.2 10.4 -0.  -0.1  3.6  7.6 25.9 -0.1  2.2 -3.9 -0.2  1.1 -0.1 -0.3  8.8 -0.2  1.  -4.9 -0.4 -0.1 -0.  -0.3 -0.   1.7 -0.1 -1.  -0.9 -2.3 -1.9 -0.8 -0.2 -0.3  0.1 -0.4 -0.1 -0.3 -0.1 -0.1 -0.1  4.9 -0.1 -0.6  3.1  0.1 -0.  -0.2 -0.1 -0.3 28.2  0.  -0.2 -0.5 -1.2 -3.6  2.9 -0.3 -0.2 -0.2 -0.3 -0.   0.6  2.5 -0.4  1.2 -0.4  0.8 -0.5 -0.   1.9 -1.2 -0.3 -0.2 -0.2  0.  -0.6 -0.  -0.3 -1.9 -0.1 -0.6 -0.4 -0.2 -0.3 -2.8  0.6 -0.9 -0.   0.3 -0.1  7.2 -0.3  1.6 -0.2 -2.6  0.3  2.6 -0.7  2.  -0.5  0.3  0.2  1.6 -3.9 -0.5 -0.2 -0.1  0.3 -0.5 -0.3 -0.2 -0.3 -0.2  0.4 -0.1 -0.1 -0.2 -1.1 -0.3 -1.4 -0.1 -0.1  0.3  0.  -0.  -0.1 -0.1  2.2 -0.6 -0.9 -1.5 -0.3 -0.1  0.7  1.1 -0.  -0.2 -0.3 -0.2 -0.2 -0.1 -0.3 -0.3 -0.2  2.   1.5 -0.4 -2.4 -0.1  0.1 -0.   0.6 -0.9 -0.1  0.  -0.2 -0.6  0.1  6.6 -0.3 -0.1 -0.2 -1.3 13.7  3.1 -0.1  1.   0.4 -0.  -0.1 -0.1 -0.1 -0.2  0.3  2.9  0.7 -0.2 -0.5 -0.4 -0.2 -2.  -0.5 -0.2  3.   0.1 -1.6 -1.3 -0.3 -0.  -0.1 -0.2 -0.3 -0.3 -3.  -1.4 -0.2 -0.2  0.1 -0.9 -0.2 -0.4 -0.1 -0.2  0.5  0.5 -0.   0.3 -0.3 23.7 -0.2  6.4 -0.1 -0.1 -5.8 -2.2 -0.2 -0.4 -0.5  0.6 -7.  -0.  14.3 -0.2  4.7 -0.2]
ty_50sample [[3 9 0 2 4 7 1 5 8 6]
 [1 4 2 8 6 9 3 7 5 0]
 [9 8 7 0 4 5 1 3 6 2]
 [4 9 1 6 3 5 7 0 8 2]
 [6 3 9 9 5 1 4 2 7 0]
 [2 8 3 4 1 5 7 0 6 9]
 [8 4 5 1 0 9 3 7 2 6]
 [1 9 6 5 4 2 3 8 0 7]
 [8 3 9 4 7 2 5 1 0 0]
 [0 5 3 4 6 1 8 9 7 2]]
tt_50sample [[3 9 0 2 7 4 1 5 8 6]
 [1 4 2 8 6 9 3 7 5 0]
 [9 8 7 0 4 5 1 3 6 2]
 [4 9 1 6 3 5 7 0 8 2]
 [6 3 8 9 5 1 4 2 7 0]
 [2 8 3 4 1 5 7 6 0 9]
 [4 8 5 1 0 9 3 7 2 6]
 [1 9 6 5 4 2 3 8 0 7]
 [8 3 9 4 7 2 5 1 6 0]
 [0 5 3 4 6 1 8 9 7 2]]
vm  [-0.9  0.2  6.4 22.1 -1.3 -0.   0.7 -0.  -1.2 -0.4  6.1  0.4 -0.2 -0.3 -1.9 -0.4  0.2 -0.  -0.2 -0.8 -1.1 -0.1 -0.7  0.1 -0.6  0.8 -0.2 -0.3 -0.9 -0.8  0.5 -0.1 -0.3 11.1 -0.1 -0.   1.7 -1.3  2.4  0.3  1.1 -0.5  0.9 -1.  -0.2  0.4  5.   0.  -2.3 -3.9 -0.2 -0.1 -0.3 -2.3 -0.2  1.2 -0.2  7.5 -1.  -0.3  3.6 -0.4 -0.2  0.1  0.2  0.6 -0.2 -0.4  2.2 -0.2 -0.1  0.7  1.2  0.8  0.2 -0.5 -0.1 -0.1 -0.1 -0.8 28.9 -0.3  0.1 -0.3  3.5 -0.2 -3.1 -0.3 -0.2 -0.4 -0.   0.2 -0.   0.6 -0.7 -0.6 -0.2 -1.  -0.1  0.6  1.9 -0.7  1.6 -0.3 -0.2 -0.6  0.2 -0.2  0.3 -1.6 -0.4 -0.2  0.2 -0.1 -0.3  1.1 -0.3 -0.7 -0.2 -0.3 -0.2  7.1 -0.3 -0.6 -0.2 -2.4 -0.2  8.2 -0.6 -0.6 -0.2 -0.   0.1 -0.2  9.4 20.5 -0.3 -0.3  0.9 -0.3  0.1 -0.1  0.7  0.4  0.4 -0.3 -0.2 -0.1  3.6 -0.2 -2.5 -0.4 -2.5  1.7 -0.1  0.2 -0.  -0.2 -0.6  0.4 -0.3  0.7 -0.4 -0.1 -0.5  1.3  0.7 -0.4  0.5 -0.2 -0.2 -0.4 -0.4 -0.2 -0.1 -0.1 -0.2 -0.4 -0.2 -0.  -1.4 -0.1 -0.3 -1.3 -0.2 -0.2 -0.6 -0.5 -0.3  2.5 -0.2 -0.1 -0.4 -0.9 -0.7  3.2  0.5  1.5 -0.  -0.1 -0.1  0.   0.2 -0.1 -0.2  1.6 -0.3 -0.2 -4.4 -0.1 -0.7 -1.2 -0.7 11.   0.  -0.3  6.9 -0.9 -0.2 -0.3 -0.2 -0.   0.7 -0.3  2.2 -1.  -1.6 -0.2 -0.6 -0.7  0.3 -0.9  0.3 -0.4 -0.1 -1.3 -0.6 -0.1  1.3  8.4 -0.2  1.4 -0.1 -0.1 -5.9 -0.9 -0.6  0.2 -1.  -0.  -7.2 -0.2  1.2 -0.4  6.4  3.3]
vy_50sample [[1 9 6 3 5 0 7 2 4 8]
 [9 0 4 3 5 2 8 1 7 6]
 [8 0 6 2 3 4 4 9 5 1]
 [6 8 5 9 4 0 3 7 2 1]
 [7 4 5 2 2 1 6 8 0 3]
 [0 7 9 2 4 8 5 6 3 1]
 [1 8 3 5 2 7 4 9 6 0]
 [3 1 9 0 7 8 5 2 6 4]
 [5 3 8 6 2 2 9 4 0 0]
 [7 3 2 8 4 6 0 5 1 9]]
vt_50sample [[1 9 6 3 5 0 7 2 4 8]
 [9 0 4 3 5 2 1 8 7 6]
 [0 8 6 2 3 4 7 9 5 1]
 [6 5 8 9 4 0 3 7 2 1]
 [7 4 5 9 2 1 8 6 0 3]
 [0 7 9 2 4 8 5 6 3 1]
 [1 8 3 5 2 7 4 9 6 0]
 [3 1 9 7 0 8 5 2 6 4]
 [5 3 8 7 6 2 9 1 4 0]
 [7 3 2 8 4 0 6 5 1 9]]
Epoch 57710: Training cost= 0.2518, Training acc= 0.8689, Validation cost= 0.2666, Validation acc= 0.8687
Epoch 57720: Training cost= 0.2210, Training acc= 0.8689, Validation cost= 0.2757, Validation acc= 0.8687
Epoch 57730: Training cost= 0.3091, Training acc= 0.8689, Validation cost= 0.2532, Validation acc= 0.8687
Epoch 57740: Training cost= 0.2277, Training acc= 0.8689, Validation cost= 0.2470, Validation acc= 0.8687
Epoch 57750: Training cost= 0.2227, Training acc= 0.8689, Validation cost= 0.2209, Validation acc= 0.8687
Epoch 57760: Training cost= 0.2052, Training acc= 0.8689, Validation cost= 0.2191, Validation acc= 0.8687
Epoch 57770: Training cost= 0.1858, Training acc= 0.8689, Validation cost= 0.2222, Validation acc= 0.8687
Epoch 57780: Training cost= 0.2845, Training acc= 0.8689, Validation cost= 0.2195, Validation acc= 0.8687
Epoch 57790: Training cost= 0.1954, Training acc= 0.8689, Validation cost= 0.2766, Validation acc= 0.8687
Epoch 57800: Training cost= 0.2064, Training acc= 0.8689, Validation cost= 0.2505, Validation acc= 0.8687
tm  [-0.8 -0.1 -1.2 -7.2 -1.6 -0.1 -0.2 -0.1 -1.2 -0.  12.8 -0.3 -0.1 -0.1 14.4  0.8 -0.4 -0.2 -0.4 -0.2 -1.8 -0.4 -0.2 -0.1 -1.  -0.3 -0.3 -0.  -1.  -0.5  0.2 -0.2 -0.7 18.2 -0.2 -0.1  1.8  8.6  3.1 -0.4  2.5  2.1 -0.1  5.9 -0.2 -0.1 -1.5 -0.2 -1.  -0.2 -0.4 -0.1 -0.5 18.2 -1.4 -2.1 -0.7 -2.8  3.5 -5.4  6.1 -0.6 -0.3 -0.4  0.7 -1.1 -0.1 -0.2 -0.1 -0.2  0.1  0.  -0.4 -0.3 -5.7 -0.7  0.   0.5 -0.1 -0.4  2.2 -0.4 -0.1 -0.2 -0.5  1.6  5.5 -0.3 -0.2 -0.5 -0.   0.   0.3 -0.2 -0.7 -0.2 -0.7 -3.5 -0.2 -0.6  0.6  5.9  0.3 -0.2 -0.2 -0.1 -3.6  1.  -0.4 -0.3 -0.3 -0.1 -0.4 -0.7  1.2  1.  -0.6 -0.4 -0.  -0.3  0.3 -0.2  0.7  0.6  0.1 18.9  0.5 -3.6  6.3  2.6 -0.3 -0.2 -0.5  0.1 -6.4 -0.1 -0.3 -0.1 -0.  -0.6 -0.2 -0.5 -0.2 -0.3 -0.1  0.8  0.4 -0.2 -0.8 -0.2  7.7 -0.1 -1.1 -0.   0.2  0.1 -0.5  0.3  1.9 -0.5 -0.8 -1.2  0.8 -0.1 -0.2  2.5  0.4 -0.1  0.7  0.1 -0.3 -0.  -0.3 -0.4  0.1  2.4  1.3 -0.2 -0.4 -0.  -1.3 -0.5 -0.3 -1.5 -0.  -0.2 -0.2 -0.9 -0.1  1.7 -0.3 -0.3 -0.  -1.2 -2.4 -1.9 -0.4 -0.4  0.1 -0.  -0.4 -0.2 -0.2 -0.1 -0.1 -3.7 -0.1 -0.3 -2.6 -0.6 -0.7 -0.6 -0.5  3.9  0.7 -0.8 -3.5 -1.6  0.2  0.2 -0.2 -0.  -0.9 -1.3 -0.5 -0.9  1.3  0.1 -1.1 -0.7 -0.6  1.8 -0.4 -0.3 -0.3  4.3 -0.3 -0.5  2.  -3.2 -0.  -1.8 -0.  -0.   0.7  3.7 -0.5 -0.1 -0.8  4.2 -0.8 -0.1  2.1 -0.4 -1.3 -0. ]
ty_50sample [[4 2 7 1 0 5 3 9 8 6]
 [7 8 0 3 9 1 5 2 4 6]
 [8 9 0 3 6 5 2 7 1 4]
 [4 6 2 9 8 8 3 7 1 5]
 [1 3 2 9 0 0 6 5 4 7]
 [1 4 6 0 9 3 7 8 2 5]
 [4 2 3 6 7 8 1 0 5 9]
 [7 5 2 4 3 6 9 8 0 1]
 [7 1 2 9 3 0 6 5 4 8]
 [3 3 0 2 2 7 9 5 6 8]]
tt_50sample [[4 2 7 1 0 5 3 9 8 6]
 [7 8 0 3 9 1 5 2 4 6]
 [8 9 0 3 6 5 2 7 1 4]
 [6 4 2 9 8 7 0 3 1 5]
 [1 3 2 9 0 8 6 5 4 7]
 [1 4 6 0 9 3 7 8 2 5]
 [4 2 3 6 7 8 1 0 5 9]
 [7 5 2 4 3 6 9 8 0 1]
 [7 1 2 9 3 0 6 5 4 8]
 [0 1 3 4 2 7 9 5 6 8]]
vm  [ 0.7 -0.6  5.5 25.1 -0.7 -0.4 -0.6  0.1  0.7 -0.4 -1.  -0.4 -0.3 -0.2 -3.2  3.5 -0.6 -0.2  1.3 -1.3 -1.1 -0.2 -0.  -0.3 -0.2 -0.4 -0.5 -0.5  0.3 -0.1 -1.1 -0.3  2.6 -3.6 -0.   0.1 -0.4 -0.5  3.3 -0.7  1.4 -2.9 -0.9 -1.7 -0.2 -0.5  9.  -0.3  7.2  7.8 -0.5 -0.2 -0.4 -2.2 -1.5  3.8 -0.6 -0.9 -0.7  7.9 -2.6 -0.5 -0.6  0.1 -0.9 -0.4 -0.2 -0.   0.8 -0.2 -0.3 -1.3  0.5 -0.3  4.6 -0.6 -0.3 -0.7 -0.2 -0.3  8.8 -0.2 -0.2 -0.3 -2.  -2.7  1.7 -0.4 -0.4 -0.5 -0.1 -0.2 -0.4 -0.6 -0.5 -0.2 -0.7 -0.3 -0.3 -0.7  2.1  1.7 -0.1 -0.2 -0.1 -0.1  3.8 -0.3 -0.2 -2.5 -0.8 -0.2 -0.1 -0.2 -0.5  7.6  1.  -0.3  0.7 -0.6 -0.3  8.1  0.1 -0.9 -0.1 -4.2 -0.3  6.9 -1.5 -3.7 -0.1 -0.2  0.7 -0.4 10.7  6.1 -0.2 -0.3 -0.2 -0.2 -0.4 -0.3 -0.5 -0.3 -0.2 -0.1 -0.3 -0.2 -2.2 -0.3 -3.  -0.1  2.3 -0.4 -0.4  0.   0.6 -0.2 -0.5  0.6 -0.3  0.1 -0.2 -0.1 -0.4  0.2  0.1  0.1 -0.5 -0.1 -0.2 -0.3 -0.2 -0.1 -0.1  3.4 -1.4 -0.2 -0.4 -0.1  3.2 -0.5  0.4 -0.5 -0.1 -0.1  0.2  0.4 -0.1 -0.2 -0.  -0.3 -0.4 -0.9 19.4  5.4  0.8  0.5 -0.2 -0.1 -0.3 -0.1  0.3 -0.3 -0.   6.3  0.  -0.3 13.3 -0.2  0.   0.7 -0.9 -2.   0.1 -0.8  8.6 -0.6 -0.5  0.9 -0.2 -0.2 -0.6 -0.7  1.2  3.2 -0.5  0.8 -0.6  1.2  0.1 -0.9 -0.2 -0.1 -0.9 -1.4 -0.4  0.9  1.  32.6 -0.1  9.7 -0.4  0.  -1.3 -2.9  0.4  0.1 -0.9  0.9 -2.3 -0.   1.4  0.2  0.1 12.7]
vy_50sample [[9 6 8 2 7 3 0 4 1 5]
 [7 1 6 3 2 0 9 8 5 4]
 [2 0 6 3 5 8 4 7 9 1]
 [9 3 1 2 0 8 7 4 6 5]
 [9 5 3 2 4 6 8 1 7 0]
 [6 0 1 4 3 5 7 2 9 8]
 [6 5 7 2 1 3 8 9 4 0]
 [8 8 4 0 1 6 3 7 5 2]
 [4 3 3 9 7 2 5 0 6 8]
 [2 3 5 9 7 8 1 6 4 0]]
vt_50sample [[9 6 8 2 7 3 0 4 1 5]
 [7 1 6 3 2 0 9 8 5 4]
 [2 0 6 3 5 8 4 7 9 1]
 [9 3 1 2 0 8 7 4 6 5]
 [9 5 3 2 4 6 8 1 7 0]
 [6 0 1 4 3 5 7 2 9 8]
 [6 5 7 2 1 3 8 9 4 0]
 [8 9 4 0 1 6 3 7 5 2]
 [4 3 1 9 7 2 5 0 6 8]
 [2 3 5 9 7 8 1 6 4 0]]
Epoch 57810: Training cost= 0.1981, Training acc= 0.8689, Validation cost= 0.2744, Validation acc= 0.8687
Epoch 57820: Training cost= 0.2119, Training acc= 0.8689, Validation cost= 0.2513, Validation acc= 0.8687
Epoch 57830: Training cost= 0.2210, Training acc= 0.8689, Validation cost= 0.2880, Validation acc= 0.8687
Epoch 57840: Training cost= 0.2684, Training acc= 0.8689, Validation cost= 0.2132, Validation acc= 0.8687
Epoch 57850: Training cost= 0.2496, Training acc= 0.8690, Validation cost= 0.2679, Validation acc= 0.8687
Epoch 57860: Training cost= 0.2668, Training acc= 0.8690, Validation cost= 0.2779, Validation acc= 0.8687
Epoch 57870: Training cost= 0.2404, Training acc= 0.8690, Validation cost= 0.2177, Validation acc= 0.8688
Epoch 57880: Training cost= 0.2241, Training acc= 0.8690, Validation cost= 0.2626, Validation acc= 0.8688
Epoch 57890: Training cost= 0.2165, Training acc= 0.8690, Validation cost= 0.2371, Validation acc= 0.8688
Epoch 57900: Training cost= 0.2261, Training acc= 0.8690, Validation cost= 0.2093, Validation acc= 0.8688
tm  [-0.7 -0.1 -2.1 -6.3 -1.9  0.8 -0.1 -0.2 -1.  -0.2  1.  -0.   0.  -0.1  8.5 -1.2 -0.  -0.2  0.1  0.9 -1.4 -0.2 -0.2 -0.2 -1.4  1.5 -0.3  0.2 -1.5 -2.4  1.7 -0.2 -0.3 -1.8 -0.2 -0.2  2.6  5.  -1.  -0.4  0.5  2.1 -0.4  2.8 -0.2 -0.4 -2.2 -0.5 -1.6 11.2 -0.1 -0.2 -0.5 13.7  2.1 -1.1 -0.8 -1.7  6.3 -0.5  9.6  0.8 -0.2 -0.1 -0.6 -0.1 -0.  -0.1  1.4 -0.2  0.   7.4 -0.2 -0.6 -5.3 -0.3 -0.1  0.5  0.1 -0.5 -6.  -0.2 -0.3 -0.2  1.9  4.7 -0.1 -0.2  0.3 -0.1 -0.5 -0.2  0.1 -0.4 -0.5 -0.3 -0.2 -4.1 -0.2 -0.2  0.4  5.2 -0.4 -0.2 -0.4 -0.5 -2.7 -0.   0.9  2.5 -0.2 -0.1 -0.2 -0.3  6.7 -4.3  0.1 -0.3 -0.1  1.   0.2 -1.1 -0.4 -0.1 -0.1 11.  -0.  -2.6  4.3  3.8 -0.4 -0.4 -0.1 -0.2 -2.  -4.   0.  -0.1 -0.4 -0.4 -0.1 -0.7 -0.3 -0.2  0.4  0.  -0.3  0.5 -0.1 -0.3  7.9 -0.2 -0.3  0.2 -0.1 -0.1 -0.1  1.7  0.5 -0.5  0.5 -1.2  0.8 -0.1 -0.3 -0.6  0.2 -0.4 -0.1 -0.2 -0.3 -0.2 -0.2  0.3 -0.1  0.1  0.8 -0.5  0.4 -0.1 -0.2 -0.2  0.1 -2.  -0.2  0.4 -0.3 -0.3  0.2  7.1 -0.4 -0.2 -0.1 -0.7 -4.6 -1.4 -0.6 -2.3  0.   0.6  0.1 -0.3 -0.1  0.1 -0.3 -3.7 -0.1 -0.1  6.9 -0.1 -0.2 -2.7 -0.3  7.3  0.3  0.6 -1.9 -1.  -0.2 -0.3 -0.1 -0.4 -0.  -1.   2.5 -1.2 -0.5 -0.  -0.2 -0.8 -0.4  1.4 -0.1  1.1  2.3  3.3  1.  -0.7  0.8 -2.5 -0.1 -1.2 -0.1  0.  17.6  4.6 -0.  -0.2 -1.2 -0.5 16.  -0.2 -0.4 -0.  -1.3 -0.4]
ty_50sample [[0 1 4 8 2 7 5 6 3 9]
 [4 8 0 7 2 1 5 3 9 6]
 [1 5 3 2 4 4 6 6 8 0]
 [0 1 5 7 9 4 2 6 8 3]
 [3 8 4 5 0 9 1 6 7 2]
 [9 1 4 0 3 7 6 5 8 2]
 [7 7 5 0 6 1 3 9 2 8]
 [6 4 8 2 1 0 9 9 3 5]
 [1 7 5 6 8 4 3 9 0 2]
 [2 7 1 6 0 5 4 8 9 3]]
tt_50sample [[0 1 4 8 2 7 5 6 3 9]
 [4 8 0 7 2 1 5 3 9 6]
 [1 5 3 2 4 9 7 6 8 0]
 [0 1 5 7 9 4 2 6 8 3]
 [3 8 4 5 0 1 9 6 7 2]
 [9 1 4 0 3 7 6 5 8 2]
 [7 4 5 0 1 6 3 9 2 8]
 [6 4 8 2 1 0 9 7 3 5]
 [1 7 5 6 8 4 3 9 2 0]
 [2 7 1 6 0 5 4 8 9 3]]
vm  [-0.5 -0.  -5.  -6.9 -1.2  0.3 -0.1 -0.  -1.  -0.4  7.  -0.2 -0.1 -0.1  2.  -0.5 -0.3 -0.3 -0.5  0.9 -1.1 -0.3 -0.  -0.2 -1.1 -0.1 -0.3 -0.  -1.1 -2.4  1.9 -0.2 -0.5 -1.9 -0.4 -0.2  0.9  4.3 -1.8 -0.5  0.9  5.9 -0.5  3.5 -0.2 -0.3 -1.8 -0.2  0.1  8.6 -0.3 -0.  -0.3 14.8 -0.2 -0.4 -0.9 -1.6  8.7 -3.3  4.5 -0.6 -0.1 -0.1 -0.1 -0.6  0.5 -0.2  0.3  0.1 -0.2  4.4 -0.5 -0.8 -5.  -0.9 -0.  -0.8 -0.1 -0.3 -2.5 -0.1 -0.2 -0.2 -0.4  6.2  5.7 -0.1 -0.  -0.2 -0.3 -0.2 -0.1 -0.6 -0.6 -0.1 -0.6 -4.   0.4 -0.6  0.9  3.  -0.2 -0.3 -0.2 -0.  -3.   0.9  0.6 -0.1 -0.4  0.1 -0.2 -0.4  4.8 -2.  -0.1  0.3 -0.1  0.9 -0.2 -0.4 -0.1  1.1 -0.1  2.1 -0.  -2.8 10.4 -0.1 -0.2 -0.4 -0.2 -0.3  5.1 -0.  -0.2 -0.2 -0.3 -0.7 -0.1 -0.5 -0.5  0.1  0.2 -0.1 -0.2 -0.1  5.8 -0.3  7.4 -0.   0.3 -0.1 -0.2 -0.1  0.5  1.3  0.1 -0.4 -0.4 -0.7  0.2 -0.1 -0.   0.1 -0.1 -0.1  0.  -0.2 -0.1 -0.  -0.2 -0.2 -0.1 -1.1 -0.2 -0.5  1.5 -0.1 -1.5  0.3 -0.2 -2.1 -0.1  0.  -0.2 -0.2  0.6  6.9 -0.2  0.  -0.1 -1.2 -1.9 -3.5 -0.6 -1.6 -0.1  0.4 -0.  -0.2 -0.2 -0.2 -0.4 -3.6  0.4  0.1 -2.4 -0.   0.3 -1.7 -0.6  0.7  0.3 -0.4 -2.2 -1.5 -0.4  0.8 -0.1 -0.3 -0.6 -1.6  2.9 -1.  -0.3 -0.2 -0.2 -0.3 -0.8  1.  -0.4 -0.3  1.3  5.7 -0.1 -0.6  2.3 -5.5  0.2 -2.5  0.1  0.4  8.4  4.1  0.4 -0.1 -1.3  0.   6.3 -0.1 -1.  -0.1 -1.5  2.8]
vy_50sample [[4 0 2 5 1 8 6 7 9 3]
 [1 6 9 0 4 8 5 2 7 3]
 [8 6 4 0 2 7 7 5 3 9]
 [5 3 2 4 9 7 6 0 1 8]
 [1 1 4 7 9 2 8 6 0 3]
 [5 8 9 3 2 7 6 4 0 1]
 [4 8 0 9 7 2 5 3 1 6]
 [1 7 6 6 8 4 0 3 9 2]
 [7 3 4 6 2 0 5 9 8 1]
 [0 8 4 9 7 3 1 5 2 6]]
vt_50sample [[4 0 2 5 1 8 6 7 9 3]
 [1 6 9 0 4 8 5 2 7 3]
 [8 6 4 0 2 7 1 5 3 9]
 [5 3 2 4 9 7 6 0 1 8]
 [1 5 4 7 9 2 8 6 0 3]
 [5 8 9 3 2 7 6 4 0 1]
 [4 8 0 9 7 2 5 3 1 6]
 [7 1 5 6 8 4 3 0 9 2]
 [7 3 4 6 2 0 5 9 8 1]
 [0 8 4 9 7 3 1 5 2 6]]
Epoch 57910: Training cost= 0.2293, Training acc= 0.8690, Validation cost= 0.2939, Validation acc= 0.8688
Epoch 57920: Training cost= 0.2324, Training acc= 0.8690, Validation cost= 0.2072, Validation acc= 0.8688
Epoch 57930: Training cost= 0.1895, Training acc= 0.8690, Validation cost= 0.2293, Validation acc= 0.8688
Epoch 57940: Training cost= 0.2578, Training acc= 0.8690, Validation cost= 0.2500, Validation acc= 0.8688
Epoch 57950: Training cost= 0.2187, Training acc= 0.8690, Validation cost= 0.2660, Validation acc= 0.8688
Epoch 57960: Training cost= 0.1888, Training acc= 0.8690, Validation cost= 0.2657, Validation acc= 0.8688
Epoch 57970: Training cost= 0.2303, Training acc= 0.8690, Validation cost= 0.2241, Validation acc= 0.8688
Epoch 57980: Training cost= 0.1977, Training acc= 0.8691, Validation cost= 0.2668, Validation acc= 0.8688
Epoch 57990: Training cost= 0.2489, Training acc= 0.8691, Validation cost= 0.2508, Validation acc= 0.8688
Epoch 58000: Training cost= 0.2539, Training acc= 0.8691, Validation cost= 0.2153, Validation acc= 0.8688
tm  [-0.2  0.4  4.1 -5.8 -1.7 -0.3 -0.2 -0.1 -0.6 -0.4 -1.7 -0.3 -0.2 -0.5 17.9  1.4 -0.2  0.7  0.8  0.6 -1.4  0.3  0.4 -0.1 -1.3 -0.2  0.5 -0.5 -0.7  5.9 -0.3 -0.  -0.5  2.4 -0.2 -0.1  0.7  5.1 -1.3 -0.6  2.1 -2.   2.3  3.9 -0.1  0.1 -2.2  0.5  1.8  8.8 -0.3 -0.2 -0.5 14.4 -1.  -2.2 -0.6 -3.9 -0.8  3.4  5.7  0.1 -0.7 -0.1 -0.9 -0.5  0.   0.1  1.2 -0.1 -0.1 -0.1 -0.1  0.4 -4.7  0.5  0.1 -0.3  0.2 -0.5 -8.2 -0.3 -0.   1.4 -1.  -2.   5.2 -0.2 -0.4 -0.2 -0.4 -0.2 -0.   0.2 -0.6 -0.7 -0.3 -3.8 -0.5 -0.3  1.6  5.5  0.4 -0.1 -0.1 -0.5 -2.6 -0.5 -0.3  0.3 -0.7 -0.1  0.1 -0.3 -0.6  1.7  1.3 -0.5 -0.2  0.2 -0.3 -0.7 -0.1 -0.8 -0.1 22.4 -0.5 -2.8 -1.4 10.1 -0.6 -0.1 -0.3 -0.4 -6.  -5.9 -0.3 -0.4 -0.6  0.4 -0.4 -0.3 -0.3  0.1 -0.2 -0.1  0.5 -0.3 -3.1  0.5  6.2 -0.2  2.7 -0.1 -0.3 -0.1  0.3 -0.2  1.9 -0.3  0.5 -0.5 -0.  -0.2 -0.4 -0.4 -0.3 -0.1 -0.2 -0.3 -0.  -0.  -0.2 -0.5 -0.1  3.5 -0.1 -0.3  1.   0.4  1.6 -0.5 -0.5 -1.6 -0.2 -0.6 -0.1 -0.4 -0.3 -1.5  0.2  0.2 -0.1 -0.6 -2.2  5.1 -0.5  1.1 -0.1 -0.2 -0.2 -0.1 -0.3  1.4 -0.2 -3.9  0.  -0.1 14.4 -0.4 -0.5 -0.8 -0.7 -0.1 -0.3  0.3 -2.4 -0.3  0.3 -0.3 -0.1 -0.1  1.  -0.8 -0.9  1.1 -0.1 -0.5  1.8 -0.4 -0.4  1.4 -0.1  0.1 -0.4 -0.3 -0.2 -0.3  0.8  1.5  0.1 -0.3  0.7 -0.2 23.   4.  -0.5 -0.1 -1.1 -0.4 21.4 -0.3 -0.7 -0.3 -0.3 -2.1]
ty_50sample [[7 8 4 2 0 3 1 6 5 9]
 [6 8 5 3 9 2 0 7 1 4]
 [3 1 5 7 2 8 4 9 6 0]
 [9 6 4 7 8 2 5 1 0 3]
 [9 5 8 3 2 6 7 0 1 4]
 [8 9 7 3 6 5 4 2 1 0]
 [6 0 2 7 5 8 1 9 4 3]
 [0 3 1 8 2 6 4 5 9 7]
 [5 0 8 2 6 4 1 3 7 9]
 [4 3 8 2 0 1 6 7 5 9]]
tt_50sample [[7 8 4 2 0 3 1 6 5 9]
 [6 8 5 3 9 2 0 7 1 4]
 [3 1 5 7 2 8 4 9 6 0]
 [9 6 4 7 8 2 5 1 3 0]
 [9 5 8 3 2 6 7 0 1 4]
 [8 9 7 3 6 5 4 2 1 0]
 [6 0 2 5 7 8 1 4 9 3]
 [0 3 1 8 2 6 4 5 9 7]
 [5 0 8 2 6 4 1 3 7 9]
 [4 3 8 2 0 1 6 7 5 9]]
vm  [-0.5 -0.1  5.9 -1.7 -1.3 -0.1 -0.3  0.3 -0.7  1.  11.5 -0.  -0.1 -0.2 12.7  0.9 -0.3 -0.  -0.3 -0.  -1.5 -0.3  1.  -0.2 -1.2  2.6 -0.2 -0.5 -1.  -1.2  0.7 -0.3 -0.2 11.8 -0.  -0.3  1.4  7.5 -1.2 -0.4  2.8  0.9 -0.7  0.7 -0.1 -0.1 -1.4 -0.3  0.9  8.1  0.1 -0.2 -0.2 18.4 -0.4 -1.7 -0.8 -1.7  5.9 -0.1  4.  -0.1 -0.1 -0.1 -0.  -0.4 -0.1  0.7 -0.4 -0.  -0.1  1.6 -0.3 -0.1 -4.7 -0.3 -0.2  0.9 -0.  -0.3 -1.3 -0.  -0.2 -0.2 -0.7  3.7  0.7 -0.3 -0.3 -0.4 -0.3 -0.1  0.4 -0.5 -0.4 -0.1 -0.4 -3.7 -0.3 -0.2 -0.6  7.6 -0.2  0.  -0.2  1.1 -2.6 -0.1 -0.2 -0.3 -0.2 -0.2 -0.1 -0.5  5.  -1.3 -0.3 -0.  -0.3  0.5 -0.3 -0.3 -0.2  1.6 -0.2 16.  -0.1 -3.6  3.5 -0.4 -0.4 -0.  -0.3  0.5 -3.4  2.6 -0.2 -0.2 -0.2 -0.5 -0.1 -0.4 -0.1 -0.1 -0.1 -0.1 -0.3 -0.1 -2.2 -0.2  1.  -0.1  0.1 -0.   0.4 -0.2 -0.3 -0.1  1.  -0.6  0.3 -1.   0.  -0.1 -0.3 -0.2 -0.4 -0.2 -0.2  0.  -0.1 -0.1 -0.2 -0.1 -0.2  2.6 -0.5 -0.2  0.9 -0.1  1.1 -0.4 -0.2 -1.7 -0.1 -0.4  0.  -0.5 -0.2  3.8 -0.2 -0.  -0.2 -0.7 -1.2 -1.2 -0.4 -1.8  0.  -0.1  0.1 -0.2 -0.1 -0.1  0.3 -2.3 -0.1 -0.1  5.3 -0.1  0.  -0.9 -0.6  2.  -0.8 -0.1 -0.6 -1.4 -0.1 -0.2  0.1 -0.2  0.1 -1.   3.8 -0.7  2.  -0.  -0.3 -0.6 -0.1  0.6 -0.1  0.8 -0.3 -1.   0.4 -0.4  3.4  3.3 -0.1 -0.1 -0.1 -0.2  5.5  0.9 -0.4 -0.1 -1.  -0.2  2.8 -0.2 -0.5 -0.1 -2.5  4. ]
vy_50sample [[2 7 0 1 4 6 8 9 5 3]
 [2 3 9 5 8 4 7 6 0 1]
 [5 4 2 7 8 3 9 6 1 0]
 [7 3 8 6 9 1 2 5 0 4]
 [3 6 8 5 2 4 9 0 7 1]
 [3 6 9 2 0 1 4 5 8 7]
 [6 5 2 0 1 8 3 4 9 7]
 [4 2 7 3 6 1 0 8 5 9]
 [7 1 0 8 4 3 6 2 5 5]
 [7 1 4 3 6 9 5 0 8 2]]
vt_50sample [[2 7 0 1 4 6 8 9 5 3]
 [3 2 9 8 5 4 7 6 0 1]
 [5 4 2 7 8 3 9 6 1 0]
 [7 3 8 6 9 1 2 5 0 4]
 [3 6 8 5 2 4 9 0 7 1]
 [3 6 9 2 0 1 4 5 8 7]
 [6 5 2 0 1 8 3 4 9 7]
 [4 2 7 3 6 1 0 8 5 9]
 [7 1 0 8 4 3 6 2 9 5]
 [7 1 4 3 6 9 5 0 8 2]]
Epoch 58010: Training cost= 0.1710, Training acc= 0.8691, Validation cost= 0.2054, Validation acc= 0.8688
Epoch 58020: Training cost= 0.2531, Training acc= 0.8691, Validation cost= 0.2174, Validation acc= 0.8689
Epoch 58030: Training cost= 0.2063, Training acc= 0.8691, Validation cost= 0.2914, Validation acc= 0.8689
Epoch 58040: Training cost= 0.2631, Training acc= 0.8691, Validation cost= 0.2596, Validation acc= 0.8689
Epoch 58050: Training cost= 0.1952, Training acc= 0.8691, Validation cost= 0.2365, Validation acc= 0.8689
Epoch 58060: Training cost= 0.2324, Training acc= 0.8691, Validation cost= 0.2715, Validation acc= 0.8689
Epoch 58070: Training cost= 0.2112, Training acc= 0.8691, Validation cost= 0.2255, Validation acc= 0.8689
Epoch 58080: Training cost= 0.2246, Training acc= 0.8691, Validation cost= 0.2824, Validation acc= 0.8689
Epoch 58090: Training cost= 0.2713, Training acc= 0.8691, Validation cost= 0.2424, Validation acc= 0.8689
Epoch 58100: Training cost= 0.2128, Training acc= 0.8691, Validation cost= 0.2317, Validation acc= 0.8689
tm  [ 2.6 -0.3  3.4  5.4 -2.1  0.1  0.4 -0.3 -0.5 -0.2 -2.5 -0.  -0.1 -0.5 -0.2 -3.1  0.9 -0.4  1.4  0.1 -1.2  0.   1.7 -0.3 -1.3  5.6  0.5  0.2 -0.8 -1.8 -0.2 -0.2 -0.3 -0.7  0.8  0.2 -0.1 -1.7 -1.8 -0.1  1.6  1.6  0.2 -0.8 -0.1  0.1 -0.2 -0.4 10.6  5.1 -0.2 -0.2 -0.2 -1.1  3.3  0.6 -0.7  3.9  3.2  3.8 -0.6 -0.3  1.  -0.3 -0.  -0.1  0.8 -0.   3.9 -0.1 -0.1  8.5 -0.2  0.6 -3.2 -0.1 -0.3  3.8 -0.1 -0.5  0.1  0.3 -0.1 -1.3 -2.5  3.4  5.4  0.6  0.1 -0.4 -0.8 -0.1 -0.1 -0.6 -1.2 -0.4 -0.1 -3.6 -0.8 -0.3 -0.2  2.5 -0.9 -0.1  0.1  0.6 -0.5 -0.3 -0.8  0.6 -0.5 -0.4 -0.3 -0.3  7.7 -4.7  1.3  0.3 -0.2  0.  -0.1  0.3 -0.4 -0.6 -0.2 -0.3 -0.6  4.9  1.5 -0.6  1.  -0.  -0.9  1.2  7.5  8.  -0.4 -0.  -0.4 -0.2 -0.3 -0.9  0.7 -0.4 -0.3 -0.2 -0.3 -0.2  2.8 -0.1 -0.6 -0.1  3.7  2.5 -0.3 -0.4 -0.5  2.3 -0.7  0.2 -0.5 -1.   0.1 -0.  -0.5 -1.2 -0.1 -0.9 -0.3 -0.1  0.4 -0.1 -0.5 -0.2 -0.2 -0.5 -1.2 -0.4  1.9 -0.  -0.8 -0.3 -0.4 -2.5 -0.  -0.1 -0.1 -0.1  0.3  4.6 -0.1 -0.2 -0.1 -0.6  8.7 -0.5 -0.5 -2.6 -0.3 -0.2  0.4 -0.  -0.4  2.2 -0.3 -0.  -0.3 -0.3  3.2 -0.4 -0.4 -2.2 -0.3 -2.9 -0.5 -0.1  3.6 -1.1 -0.2 -0.9  0.2  0.   0.5 -1.4  1.7 -1.7 -2.8 -1.  -0.4  0.2  1.3 -0.5 -0.2  1.5  0.2 -1.  -0.1 -0.4  2.5  4.7 -0.2 -0.1 -0.4  0.1  2.4 -1.5 -0.1 -0.6 -1.3  1.6 -0.6 -0.1 -0.9  0.4  5.7  4.2]
ty_50sample [[0 6 8 9 5 7 3 4 2 1]
 [2 8 4 1 9 7 3 0 5 6]
 [4 8 2 7 0 5 1 3 6 9]
 [1 6 9 2 0 8 5 7 4 3]
 [5 8 6 1 7 2 9 0 4 3]
 [7 0 8 4 6 6 9 3 2 1]
 [2 1 6 9 5 0 4 8 3 7]
 [9 2 4 7 1 0 6 5 8 3]
 [1 6 7 5 0 8 3 4 2 9]
 [8 8 2 6 6 7 5 5 9 4]]
tt_50sample [[0 6 8 9 7 5 3 4 2 1]
 [2 8 4 1 7 9 3 0 5 6]
 [4 8 2 7 0 5 1 3 6 9]
 [1 6 9 2 0 8 5 7 4 3]
 [5 8 6 1 7 2 9 4 0 3]
 [7 0 8 4 6 5 9 3 2 1]
 [2 1 6 9 5 0 4 8 3 7]
 [9 2 4 7 1 0 6 5 8 3]
 [1 6 7 5 0 8 3 4 2 9]
 [8 1 2 3 6 7 0 5 9 4]]
vm  [-0.8 -0.1 -1.5 -4.9 -1.8  0.1 -0.2 -0.  -0.7 -0.4  9.6  0.2 -0.1 -0.2  8.2  3.1  0.1 -0.2 -0.5  1.2 -1.3 -0.2  0.7  0.3 -1.8  1.7 -0.3 -0.2 -1.  -1.   0.6 -0.3 -0.5  3.3 -0.2 -0.   3.7  8.5 -0.6 -0.4  0.9  3.6 -0.1  2.8 -0.2 -0.3 -2.  -0.5 -1.7  6.2 -0.3 -0.  -0.4 17.7 -0.9 -1.2 -0.8 -1.1  1.2 -1.7  8.3 -0.5 -0.2  0.1 -0.4 -0.4  0.3 -0.1 -0.7 -0.   0.1  1.6 -0.3 -0.5 -4.1 -0.4  0.3 -0.5  0.3 -0.3 -2.7  0.4 -0.1 -0.1  1.9  5.5 -0.1 -0.1  0.  -0.3  0.1 -0.1 -0.1 -0.5 -0.4  0.  -0.3 -3.5 -0.1 -0.2  1.9  4.  -0.5 -0.2 -0.4 -0.3 -2.9  0.1 -0.1  0.6 -0.2  0.7 -0.1 -0.2  0.3 -0.2 -0.7 -1.1 -0.3 -0.1 -0.2 -0.6  0.8  0.8 -0.2 10.4  0.8 -3.6  1.6  2.7 -0.2 -0.1  0.  -0.4 -1.6 -1.5  0.2  0.2 -0.  -0.6 -0.1 -0.4 -0.7 -0.1 -0.1 -0.  -0.1 -0.1  2.4 -0.3  5.  -0.1 -0.8 -0.9  0.  -0.  -0.7 -0.3  0.4 -0.1  1.6 -0.6 -0.1 -0.1  0.1 -0.2 -0.4 -0.1 -0.1 -0.1 -0.2  0.4 -0.3 -0.4 -0.2 -0.1  0.  -0.   0.1 -0.1 -1.1 -0.2 -0.1 -2.2 -0.1 -0.4 -0.1 -0.5 -0.2  3.1 -0.3 -0.1 -0.1 -1.1 -3.5 -0.5 -0.3 -0.   0.  -0.  -0.  -0.2 -0.  -0.4 -0.3 -3.4  0.5 -0.1 -1.2 -0.1 -0.5 -0.8 -0.5  9.5 -0.7 -0.1 -1.7 -1.1 -0.1  0.5 -0.3 -0.1 -0.3 -1.7  2.8 -0.3  4.2  1.2  2.2 -0.5 -0.7  1.5 -0.2 -0.1 -0.   3.4  0.2 -0.4  1.8 -4.2  0.2 -1.7 -0.1  0.   8.7  3.4 -0.4  0.2 -1.  -0.4  7.1  0.  -0.3 -0.2 -2.4 -0.1]
vy_50sample [[2 1 4 0 5 7 8 6 3 9]
 [9 1 3 4 8 0 2 7 6 5]
 [0 4 3 6 2 7 1 8 5 9]
 [8 6 5 3 9 0 2 7 4 1]
 [8 9 6 2 3 1 5 0 7 4]
 [1 2 8 9 7 6 4 0 5 3]
 [2 0 1 9 8 3 7 5 4 6]
 [7 1 0 6 4 4 2 3 8 5]
 [3 7 9 5 6 4 1 2 0 8]
 [8 4 3 6 5 7 9 2 0 0]]
vt_50sample [[2 1 4 5 0 7 8 6 3 9]
 [9 1 3 4 8 0 2 7 6 5]
 [0 4 3 2 6 1 7 8 5 9]
 [8 6 3 5 9 0 2 7 4 1]
 [8 9 6 2 3 1 5 0 7 4]
 [1 2 8 9 7 4 6 0 5 3]
 [2 0 1 9 8 3 7 5 4 6]
 [7 1 0 6 9 4 2 3 8 5]
 [3 7 9 5 6 4 1 2 0 8]
 [8 4 3 6 5 7 9 2 1 0]]
Epoch 58110: Training cost= 0.2251, Training acc= 0.8692, Validation cost= 0.2486, Validation acc= 0.8689
Epoch 58120: Training cost= 0.2677, Training acc= 0.8692, Validation cost= 0.3308, Validation acc= 0.8689
Epoch 58130: Training cost= 0.2317, Training acc= 0.8692, Validation cost= 0.2420, Validation acc= 0.8689
Epoch 58140: Training cost= 0.2221, Training acc= 0.8692, Validation cost= 0.3430, Validation acc= 0.8689
Epoch 58150: Training cost= 0.2485, Training acc= 0.8692, Validation cost= 0.2280, Validation acc= 0.8689
Epoch 58160: Training cost= 0.2370, Training acc= 0.8692, Validation cost= 0.2215, Validation acc= 0.8689
Epoch 58170: Training cost= 0.2465, Training acc= 0.8692, Validation cost= 0.2917, Validation acc= 0.8689
Epoch 58180: Training cost= 0.2162, Training acc= 0.8692, Validation cost= 0.2063, Validation acc= 0.8690
Epoch 58190: Training cost= 0.2260, Training acc= 0.8692, Validation cost= 0.2888, Validation acc= 0.8690
Epoch 58200: Training cost= 0.2237, Training acc= 0.8692, Validation cost= 0.2585, Validation acc= 0.8690
tm  [-0.8 -0.2  5.1  1.4 -1.8 -0.  -0.1 -0.1 -0.1 -0.4 -2.6  0.2 -0.3 -0.4  5.7 -0.6  0.1 -0.6  0.6  1.4 -1.4  0.2 -0.3 -0.1 -1.1  2.4 -0.1  0.  -0.2 -2.6 -0.3 -0.6 -0.4  1.  -0.3 -0.  -0.2 -0.8 -2.2 -0.2 -0.1 -1.1 -0.4 -0.7 -0.2 -0.5 -2.  -0.1 -1.8 -2.4 -0.3 -0.1 -0.   0.9 -1.4 -0.9 -0.9  8.8  4.6  4.7 10.2 -0.4  1.1 -0.2  0.6 -0.2 -0.  -0.   1.4 -0.3 -0.3 -1.2 -0.2 -0.3 -5.6  2.7 -0.2  1.5 -0.1 -0.3 -2.3 -0.3 -0.  -0.4  0.1 -0.6 -3.  -0.2 -0.2 -0.4 -0.7 -0.3 -0.1 -0.1 -1.1 -0.2 -0.2 -3.7 -0.5 -0.5 -0.  -1.1 -0.3 -0.1 -0.5  1.4 -2.3 -0.1 -0.7  1.   0.9 -0.1 -0.2 -0.6  0.5  7.6  0.6  0.2 -0.3  0.4 -0.2 -0.9 -0.2 -0.2  0.2  7.4 -0.1  2.   6.5 17.1  0.4 -0.2 -0.5  0.8  3.   3.1 -0.2 -0.2 -0.1 -0.3 -0.  -0.   0.9 -0.2 -0.2 -0.1 -0.  -0.1  4.3 -0.3 -0.1 -0.2 -1.1  1.2 -0.2  0.1 -0.6  0.8 -0.2 -0.4 -0.2 -0.7  0.9 -0.2 -0.2 -0.3 -0.4 -0.4 -0.4 -0.2 -0.1 -0.3 -0.4 -0.3 -0.1 -0.6 -0.8 -0.2  2.3 -0.2 -1.5 -0.1 -0.  -2.8 -0.3 -0.1 -0.3 -0.3 -0.1  7.4 -0.2 -0.1 -0.2 -1.3 -4.6 -2.3 -0.3 -0.3 -0.2 -0.1 -0.2 -0.2 -0.2  0.4 -0.  -2.2  0.1 -0.2 -1.2 -0.4 -0.4  1.4 -0.4  9.4 -0.2  1.2  3.1 -1.  -0.3 -0.6 -0.2 -0.2  0.1 -1.2 -0.9  3.  -2.5 -0.5  0.6 -1.  -0.3  1.4 -0.2 -0.4 -0.9 -1.  -0.6 -0.5  1.1 -4.2 -0.1 -1.8 -0.2 -0.   8.   0.9 -0.2 -0.2 -1.1 -0.4  5.6 -0.2 -1.2  0.   9.6 -3.9]
ty_50sample [[1 3 5 6 8 7 0 4 9 2]
 [7 9 3 5 1 0 6 2 8 4]
 [1 9 3 2 6 5 7 4 0 8]
 [6 4 8 2 0 5 1 7 3 9]
 [6 9 4 2 3 7 1 5 8 0]
 [4 0 3 8 9 7 2 1 5 6]
 [7 1 5 5 8 9 0 6 3 2]
 [8 5 0 4 2 1 3 9 7 6]
 [2 0 3 4 5 9 1 6 8 7]
 [3 9 0 1 4 2 7 5 6 8]]
tt_50sample [[1 3 5 6 8 7 0 4 9 2]
 [7 9 3 5 1 0 6 2 8 4]
 [1 9 3 2 6 5 7 4 0 8]
 [6 4 8 2 0 5 1 7 3 9]
 [6 9 4 2 3 7 1 5 8 0]
 [4 0 3 8 7 9 2 1 5 6]
 [7 1 5 4 8 9 0 6 3 2]
 [8 5 0 4 2 1 3 9 7 6]
 [2 0 3 4 5 9 1 6 8 7]
 [9 3 0 1 4 2 7 5 6 8]]
vm  [-0.6 -0.4 10.4 -1.8 -1.7 -0.1 -0.1  0.6 -0.8 -0.5  5.7 -0.4 -0.1 -0.4 18.1 -1.3 -0.3 -0.2 -0.   1.6 -1.2 -0.5 -0.1 -0.  -1.4  3.  -0.3 -0.2 -1.4  2.2 -0.2 -0.3 -0.4 22.6 -0.  -0.1 -0.2 -1.7 -5.8 -0.2  0.1  2.4  1.4 -0.9 -0.   0.4 -2.4 -0.   0.9 -2.   0.1 -0.1 -0.6  6.7  0.5 -2.5 -0.8  5.9  1.6 -1.7  5.3  0.3 -0.1  0.2 -1.2 -0.1 -0.3 -0.1  1.6 -0.5 -0.3  2.2  0.1  0.8 -5.1  0.2  0.1  2.   0.4 -0.6  2.8 -0.2 -0.3 -0.2 -0.4  3.2 -0.7 -0.3 -0.1 -0.3 -0.6 -0.3 -0.1 -0.2 -0.5 -0.4  0.8 -4.3 -0.4 -0.5  1.8  6.7 -0.1  0.2 -0.4 -0.9 -2.1  0.4  1.5  2.6 -0.4  0.1 -0.  -0.6  3.7 -1.2 -0.4 -0.2 -0.3 -0.5 -0.2 -1.3  0.3  0.6 -0.2 23.1 -0.1 -0.6  2.8  7.8 -0.2 -0.2 -0.7 -0.2 -1.3 20.4 -0.4 -0.4 -0.3 -0.2  0.7 -0.6 -0.3 -0.3 -0.2 -0.4 -0.1 -0.3 -1.3 -0.2  1.8 -0.4 -0.7  3.  -0.4  0.3 -0.8 -0.5 -0.5  2.  -0.   0.1 -0.3 -0.2 -0.5 -0.4 -0.3 -0.3 -0.2 -0.1 -0.2 -0.2 -0.2 -0.2  0.   1.6 -0.5  0.2  5.  -0.  -1.  -0.3 -0.1 -1.3 -0.3 -0.2 -0.4 -0.4 -0.5 -0.5 -0.2 -0.  -0.2 -0.6 -1.8 -0.7 -0.4 -1.3  0.4 -0.  -0.1 -0.  -0.4 -0.  -0.2 -2.8 -0.1 -0.3 -3.9 -0.1 -0.6 -1.1 -0.3  3.4 -0.7 -0.3  5.9 -1.  -0.5 -0.6 -0.  -0.2 -0.1 -0.9  3.9 -1.1 -1.7 -0.2 -1.7 -0.3  1.1 -0.3 -0.3 -0.7  1.7 -1.9 -0.2 -0.2  2.5 -4.  -0.1 -1.7 -0.2 -0.1 -0.1  2.4 -0.5 -0.4 -1.6  0.8 -1.   0.2 -3.1 -0.5  5.1 -1.4]
vy_50sample [[7 6 0 5 1 3 4 2 9 8]
 [1 9 0 3 8 5 7 2 6 4]
 [2 6 7 5 1 3 8 4 0 9]
 [0 9 6 8 7 2 5 1 3 4]
 [5 0 8 6 7 3 9 1 4 2]
 [5 0 6 1 2 3 4 8 9 7]
 [7 8 5 0 3 2 1 6 9 4]
 [4 1 7 2 5 0 8 6 3 9]
 [6 4 8 2 9 5 3 0 1 7]
 [4 0 3 8 1 5 9 2 6 7]]
vt_50sample [[7 6 0 5 1 3 4 2 9 8]
 [1 9 0 3 8 5 7 2 6 4]
 [2 6 7 5 1 3 8 4 0 9]
 [0 9 6 8 7 2 5 1 3 4]
 [5 0 8 6 7 3 9 1 4 2]
 [5 6 0 1 2 3 4 8 9 7]
 [8 7 5 0 3 2 1 6 9 4]
 [4 1 7 2 5 0 8 6 9 3]
 [6 4 8 2 9 5 3 0 1 7]
 [4 0 3 8 1 9 5 2 6 7]]
Epoch 58210: Training cost= 0.1963, Training acc= 0.8692, Validation cost= 0.2169, Validation acc= 0.8690
Epoch 58220: Training cost= 0.2181, Training acc= 0.8692, Validation cost= 0.2416, Validation acc= 0.8690
Epoch 58230: Training cost= 0.1586, Training acc= 0.8692, Validation cost= 0.2464, Validation acc= 0.8690
Epoch 58240: Training cost= 0.1933, Training acc= 0.8692, Validation cost= 0.2346, Validation acc= 0.8690
Epoch 58250: Training cost= 0.2061, Training acc= 0.8692, Validation cost= 0.2801, Validation acc= 0.8690
Epoch 58260: Training cost= 0.2604, Training acc= 0.8693, Validation cost= 0.2529, Validation acc= 0.8690
Epoch 58270: Training cost= 0.2446, Training acc= 0.8693, Validation cost= 0.2320, Validation acc= 0.8690
Epoch 58280: Training cost= 0.2105, Training acc= 0.8693, Validation cost= 0.2074, Validation acc= 0.8690
Epoch 58290: Training cost= 0.2260, Training acc= 0.8693, Validation cost= 0.2418, Validation acc= 0.8690
Epoch 58300: Training cost= 0.2033, Training acc= 0.8693, Validation cost= 0.2147, Validation acc= 0.8690
tm  [ 0.8 -0.2 -1.1 -2.7 -1.7 -0.4 -0.2 -0.  -0.7 -0.6  3.6 -0.  -0.3 -0.2  4.   2.  -0.3  0.  -0.4 -0.9 -1.6 -0.2  0.5  0.1 -1.2  0.4 -0.  -0.6 -0.5 11.1  0.4 -0.  -0.   3.8 -0.2 -0.1  2.   0.4 -0.8 -0.4  2.  -0.7  2.4  1.6 -0.2 -0.1  3.5 -0.2  4.1  7.4 -0.3 -0.2 -0.   3.4 -0.9 -0.4 -0.7 -3.7 -3.2 -1.6 -0.9 -0.2 -0.6 -0.  -0.3  0.7 -0.4 -0.2  2.6 -0.1 -0.1 -0.5 -0.  -0.3 -1.4 -0.4 -0.1 -0.1 -0.2 -0.5 -0.4 -0.4 -0.1  0.  -1.4 -0.6 10.4 -0.1 -0.2 -0.2 -0.5 -0.1 -0.2  1.4 -0.6 -0.3 -0.3 -1.7 -0.5 -0.4  2.   5.4 -0.3 -0.1 -0.1  0.6 -1.6  0.2  2.  -1.2 -0.7 -0.3  0.5 -0.  -1.3  2.5  1.5 -1.  -0.1 -0.1 -0.1  4.  -0.4 -0.9 -0.2  5.  -0.5 -0.2 -3.9 -1.4 -0.1 -0.2 -0.3 -0.3 -0.5  4.2 -0.1 -0.3 -0.4 -0.7 -0.8 -0.3 -0.1 -0.1  0.  -0.3  0.6 -0.  -2.1  0.1  2.4 -0.1  2.9  0.3 -0.2  0.  -0.  -0.3 -0.5 -0.  -0.   0.9  0.3 -0.2 -0.4 -0.4  0.7 -0.3 -0.2  0.  -0.1 -0.3 -0.3 -0.2 -0.2  3.2 -1.1 -0.1  1.  -0.   0.9 -0.4 -0.3 -1.7 -0.3 -0.2 -0.2 -0.5 -0.3 -2.9 -0.  -0.1 -0.1 -1.2 11.5 14.4 -0.2  3.8 -0.  -0.1 -0.2 -0.1 -0.1 -0.   0.2 -1.3 -0.2 -0.3  8.8 -0.4 -0.4 -0.8 -0.5 -1.6  1.  -0.4 -1.2 -0.4 -0.1 -0.1 -0.1  0.  -0.6 -0.9  1.7  2.  -0.5 -0.7  2.   0.  -0.4 -0.   0.2  1.  -0.6  1.8  0.2 -0.3  0.5 15.5 -0.2  3.7 -0.1 -0.3  3.  -1.  -0.1  0.1 -1.2 -0.1  0.6 -0.1 -0.4  0.4 -0.6  6.7]
ty_50sample [[4 7 6 2 8 9 0 3 5 1]
 [9 2 3 5 4 6 8 8 1 7]
 [2 8 1 4 3 7 0 9 5 6]
 [1 5 2 0 9 7 6 8 4 3]
 [4 9 1 2 6 8 5 3 7 0]
 [3 8 2 9 0 5 7 1 6 4]
 [5 6 2 3 7 0 8 4 9 1]
 [4 5 6 6 8 3 2 9 7 1]
 [9 1 0 4 3 7 5 8 2 6]
 [8 2 2 0 7 9 1 3 6 4]]
tt_50sample [[4 7 2 6 8 9 0 3 5 1]
 [9 2 3 5 4 6 8 0 1 7]
 [2 8 1 4 3 7 0 9 5 6]
 [1 5 2 0 9 7 6 8 4 3]
 [4 9 1 2 6 8 5 3 7 0]
 [3 8 2 9 0 5 7 1 6 4]
 [5 6 2 3 7 8 0 4 1 9]
 [4 5 0 6 8 3 2 9 7 1]
 [9 1 0 4 3 7 5 8 2 6]
 [8 2 5 0 7 9 1 3 6 4]]
vm  [-0.1 -0.2 13.1  3.1 -1.5 -0.4  0.3 -0.2 -1.   0.2  4.9 -0.2 -0.3 -0.1 16.1 -1.  -0.4 -0.8 -1.4 -0.  -1.1 -0.4  1.5 -0.2 -1.   0.6 -0.2 -0.5 -1.5  1.3 -1.2 -0.1 -0.2  5.2 -0.4 -0.2  1.8 -0.1 -6.2 -0.3  5.8 -1.1  0.8 -0.6 -0.3 -0.3 -1.2 -0.5  2.9  4.2 -0.1 -0.1 -0.7 16.3  3.4 -2.2 -1.   3.3 -0.7  9.4  1.2  1.5 -0.8 -0.3 -0.7  1.3 -0.2 -0.2  3.9 -0.3 -0.2  6.7 -0.8 -1.3 -4.5 -0.6 -0.   2.9 -0.3 -0.4 -6.2  1.  -0.1  1.5 -1.1 -1.1  0.  -0.2 -0.1 -0.  -0.9  0.1 -0.1  1.  -0.4  0.8  0.9 -3.7 -0.3 -0.5 -0.3  4.4 -0.2 -0.2  0.1 -0.  -3.1 -0.1  2.3 -0.1 -0.6 -0.2  0.  -0.3  3.8 -5.   0.8 -0.2 -0.3 -0.3  0.2 -0.4 -0.7 -1.1 -0.2 20.9 -0.1 -3.3 -1.3 12.6 -0.4 -0.  -0.5 -0.3 -0.7  5.9  0.  -0.1 -0.6 -0.7 -0.5 -0.7  0.3 -0.1  0.3 -0.4 -0.3  0.9 -1.9 -0.4 -0.8  0.3  2.1  0.3 -0.3 -0.2 -0.1 -0.2 -0.6 -0.4  1.1  0.7 -0.1 -0.2 -0.1  0.5 -0.4 -0.5 -0.4  0.3 -0.   0.1 -0.1  0.1 -0.3  2.5 -1.3 -0.5  6.6 -0.2 -0.1 -0.2  0.6 -1.4 -0.4 -0.3 -0.4 -0.4 -0.1 -0.4 -0.1 -0.2 -0.3 -0.6  1.8  4.4 -0.9 -1.4 -0.2 -0.1  0.7 -0.1 -0.  -0.3 -0.1 -4.2 -0.1 -0.   8.3 -0.  -0.7 -3.3 -0.1 -1.7 -1.3 -0.1  6.6 -0.7 -0.2 -0.4 -0.3 -0.3 -0.5 -1.4  0.9 -1.6 -0.4 -1.   1.3 -0.2 -0.5  2.7 -0.2 -0.   1.4 -2.7  1.  -0.9  1.5 -1.  -0.1 -0.6 -0.2  0.  18.2  5.9 -0.3 -0.2 -1.2 -0.9 16.5 -0.1 -3.4 -0.2 -0.4 -2.8]
vy_50sample [[0 7 2 2 8 3 5 1 1 4]
 [1 9 5 8 7 6 2 3 0 4]
 [1 6 4 0 7 2 5 8 3 9]
 [4 8 5 9 6 3 7 2 1 0]
 [7 4 1 3 2 6 8 9 5 0]
 [8 3 2 7 5 9 6 1 0 4]
 [5 4 0 8 7 6 2 3 9 1]
 [3 5 7 0 6 2 4 8 9 1]
 [3 7 0 6 8 2 9 4 5 1]
 [1 4 3 0 2 5 8 6 7 7]]
vt_50sample [[0 7 6 2 8 3 5 9 1 4]
 [1 9 5 8 7 6 2 3 0 4]
 [1 6 4 0 7 5 2 3 8 9]
 [4 8 5 9 6 7 3 2 1 0]
 [7 4 1 3 2 6 8 9 5 0]
 [3 8 2 7 5 9 6 1 0 4]
 [5 4 0 8 7 6 2 3 9 1]
 [3 5 7 0 6 2 4 8 9 1]
 [7 3 0 6 8 2 9 4 5 1]
 [1 4 3 0 2 5 8 6 7 9]]
Epoch 58310: Training cost= 0.2350, Training acc= 0.8693, Validation cost= 0.2216, Validation acc= 0.8690
Epoch 58320: Training cost= 0.2664, Training acc= 0.8693, Validation cost= 0.2800, Validation acc= 0.8690
Epoch 58330: Training cost= 0.2850, Training acc= 0.8693, Validation cost= 0.2192, Validation acc= 0.8690
Epoch 58340: Training cost= 0.2339, Training acc= 0.8693, Validation cost= 0.2328, Validation acc= 0.8691
Epoch 58350: Training cost= 0.2393, Training acc= 0.8693, Validation cost= 0.2389, Validation acc= 0.8691
Epoch 58360: Training cost= 0.2236, Training acc= 0.8693, Validation cost= 0.2464, Validation acc= 0.8691
Epoch 58370: Training cost= 0.1845, Training acc= 0.8693, Validation cost= 0.2433, Validation acc= 0.8691
Epoch 58380: Training cost= 0.2912, Training acc= 0.8693, Validation cost= 0.2853, Validation acc= 0.8691
Epoch 58390: Training cost= 0.2462, Training acc= 0.8694, Validation cost= 0.2638, Validation acc= 0.8691
Epoch 58400: Training cost= 0.2178, Training acc= 0.8694, Validation cost= 0.2584, Validation acc= 0.8691
tm  [-0.2 -0.2 -1.1 -2.8 -1.7 -0.3 -0.1 -0.  -0.7 -0.6  7.2  0.5 -0.2 -0.3  4.8  2.3 -0.3 -0.2 -0.8  1.7 -1.8 -0.2 -0.7 -0.3 -1.1  2.4  0.1 -0.3 -0.7 -2.   1.  -0.3 -0.4  5.4 -0.1 -0.2  1.4  5.7  3.4 -0.2  3.9  2.1  1.3  3.3 -0.2 -0.1 -1.7 -0.4  4.9 -3.4 -0.2 -0.1 -0.1  7.7 -0.8 -0.7 -0.9  4.9  4.9 -2.1  2.3 -1.1  0.7  0.1 -0.1 -0.5 -0.3 -0.2 -0.2 -0.1 -0.1  0.1 -0.7 -0.1 -4.3 -0.6 -0.1 -0.2  0.2 -0.1  0.5  0.1 -0.2 -0.4 -1.2  1.7  5.5 -0.1 -0.  -0.4 -0.2 -0.   0.  -0.1 -0.8 -0.5  0.7 -3.6 -0.2 -0.3  1.9 -1.1 -0.4 -0.2 -0.2 -0.4 -2.3  0.7  1.1  0.2 -0.4 -0.3 -0.1 -0.5 -0.1  2.1  0.3 -0.8  0.2 -0.2 -0.2 -0.3  0.3  1.1 -0.4  6.2 -0.  -1.1  9.8 14.6 -0.3 -0.2  0.  -0.4 -2.1 -0.8  0.5  0.2 -0.  -0.7 -0.2 -0.2 -0.2 -0.2 -0.1 -0.4 -0.3 -0.1  7.5  0.1  2.1 -0.2 -0.2 -0.5  0.1 -0.2 -0.6 -0.4  2.9 -0.3  0.8 -1.2 -0.1  0.1 -0.2 -0.3 -0.2 -0.4 -0.  -0.  -0.2  0.4  0.2 -0.  -0.2 -1.6 -0.2 -0.4 -0.4 -0.1 -2.  -0.6 -0.1 -2.1 -0.  -0.4 -0.2 -0.5 -0.5  5.8 -0.   0.  -0.1 -1.4 -0.1 -3.4 -0.3  1.4  0.1 -0.1 -0.  -0.1  0.3 -0.4 -0.2 -2.8 -0.1 -0.4 -5.  -0.1 -0.8 -0.4 -0.8 -0.6 -1.2  0.3 -2.  -1.4 -0.3 -0.5 -0.1 -0.1 -0.4 -1.3 -2.3 -0.7 -0.8 -0.3  1.3  0.4 -0.2 -0.  -0.2 -0.6 -0.2  1.6  0.2 -0.1  3.2 -6.  -0.  -2.6 -0.1 -0.1  1.8  0.9 -0.4 -0.5 -1.1 -0.5 -0.3 -0.1  2.  -0.   3.9 -3.2]
ty_50sample [[5 3 4 2 0 7 1 8 9 6]
 [8 6 0 4 2 9 5 3 7 1]
 [1 1 6 5 7 9 3 2 4 0]
 [3 5 1 0 8 4 6 7 9 2]
 [1 0 3 9 8 7 4 2 5 6]
 [1 7 4 4 5 2 9 0 3 6]
 [1 2 0 9 4 5 3 6 7 8]
 [4 1 3 0 8 2 7 6 9 5]
 [6 8 5 1 7 2 9 4 0 3]
 [5 9 3 2 8 0 6 7 1 4]]
tt_50sample [[5 3 4 2 0 7 1 8 9 6]
 [8 6 0 4 2 9 5 3 7 1]
 [8 1 6 5 7 9 3 2 4 0]
 [3 5 1 0 8 4 6 7 9 2]
 [1 0 3 9 8 7 4 2 5 6]
 [1 7 8 4 5 2 9 0 3 6]
 [1 2 0 9 4 5 3 6 7 8]
 [4 1 3 0 8 2 7 6 9 5]
 [6 8 5 1 7 2 9 4 0 3]
 [5 9 3 2 8 0 6 7 1 4]]
vm  [-0.2 -0.1 -4.6 -4.1 -0.8  0.  -0.4 -0.3 -0.4 -0.4 11.9 -0.4 -0.1 -0.1 -0.9  1.  -0.5 -0.3 -0.3 -1.  -1.7 -0.1 -0.3 -0.4 -0.9  0.3 -0.3 -0.1 -0.9 -2.4  1.2 -0.7  0.   6.4 -0.2 -0.1  1.   4.  -0.9 -0.5  2.1 -1.  -0.9  2.9  0.2 -0.1  0.9  0.6  0.9 -0.4 -0.3 -0.1 -0.4  8.1 -0.9  1.2 -0.7 -4.4 11.4 -5.5  2.9 -0.6 -0.4 -0.2  1.8 -1.2 -0.2  0.3  0.3  0.   0.8  2.2  0.6 -0.  -3.2 -0.2 -0.3 -0.4 -0.2 -0.2 14.1 -0.7  0.5 -0.2 -0.9 -0.2  6.  -0.4 -0.  -0.3 -0.2 -0.2 -0.3 -0.7 -0.7  1.1 -0.5 -3.3 -0.2 -0.4  1.3  3.8 -0.1 -0.3 -0.  -0.4 -2.3  1.3 -0.3 -1.1 -0.7 -0.  -0.3 -0.5  7.3 -0.8  2.5  0.2 -0.  -0.1 -0.2  3.2  0.4  0.7 -0.4 -1.  -0.1 -1.2  9.5 -1.2 -0.3 -0.2 -0.  -0.5  6.7 14.3 -0.1 -0.2 -0.4 -0.5 -0.6 -0.3 -0.6 -0.4 -0.2 -0.2 -0.2 -0.2 -1.  -0.1  3.9 -0.2 -0.9 -0.8 -0.1 -0.  -0.1 -0.4  0.4 -0.5 -0.2 -0.6 -0.  -0.2 -0.2  0.3 -0.3  0.4 -0.2 -0.1 -0.2 -0.3 -0.1 -0.5 -0.2  2.1 -0.8  0.2  0.6 -0.1  0.8 -0.4 -0.4 -1.9 -0.   0.5  0.2 -0.6  0.2  6.8 -0.2 -0.2 -0.  -1.  -0.3 -3.5 -0.5 -2.3  0.8 -0.3 -0.3 -0.2 -0.5 -0.2 -0.7 -2.1 -0.2 -0.2  0.7 -0.6 -0.7 -1.  -0.4  0.1  0.2 -0.5 -1.8 -1.3 -0.2  0.4 -0.  -0.1 -1.1 -1.7  2.3 -0.9  0.4 -0.1  1.3 -0.1 -0.6  0.6 -0.2  0.2  0.3  6.4 -0.2 -0.3  1.2 13.4 -0.2  3.   0.1 -0.4 -2.7 -0.5  0.3  0.4 -1.5  0.9 -3.8  0.3 -0.6 -0.1 -1.7  6.9]
vy_50sample [[4 2 0 6 1 9 7 3 5 8]
 [0 2 1 8 4 9 3 6 5 7]
 [5 1 3 8 0 2 6 7 9 9]
 [7 9 3 0 8 1 6 2 4 5]
 [0 5 8 2 3 4 1 9 7 6]
 [6 6 4 5 3 7 8 9 2 1]
 [0 9 7 1 6 4 8 5 2 3]
 [0 1 7 9 6 3 4 5 2 8]
 [7 6 5 9 4 0 2 1 8 3]
 [7 0 5 2 3 3 4 6 9 1]]
vt_50sample [[4 2 0 6 1 9 7 3 5 8]
 [0 2 1 8 4 9 3 6 5 7]
 [5 1 3 8 0 2 6 7 9 4]
 [7 9 3 0 1 8 6 2 4 5]
 [0 5 8 2 3 4 1 9 7 6]
 [6 0 4 5 3 7 8 9 2 1]
 [0 9 7 1 6 4 8 5 2 3]
 [0 1 7 9 6 3 4 5 2 8]
 [7 6 5 9 0 4 2 1 8 3]
 [7 0 5 2 8 3 4 6 9 1]]
Epoch 58410: Training cost= 0.1900, Training acc= 0.8694, Validation cost= 0.2602, Validation acc= 0.8691
Epoch 58420: Training cost= 0.2623, Training acc= 0.8694, Validation cost= 0.2177, Validation acc= 0.8691
Epoch 58430: Training cost= 0.2412, Training acc= 0.8694, Validation cost= 0.2248, Validation acc= 0.8691
Epoch 58440: Training cost= 0.2376, Training acc= 0.8694, Validation cost= 0.1990, Validation acc= 0.8691
Epoch 58450: Training cost= 0.1832, Training acc= 0.8694, Validation cost= 0.2405, Validation acc= 0.8691
Epoch 58460: Training cost= 0.2173, Training acc= 0.8694, Validation cost= 0.2614, Validation acc= 0.8691
Epoch 58470: Training cost= 0.2192, Training acc= 0.8694, Validation cost= 0.2917, Validation acc= 0.8691
Epoch 58480: Training cost= 0.2446, Training acc= 0.8694, Validation cost= 0.2209, Validation acc= 0.8691
Epoch 58490: Training cost= 0.2200, Training acc= 0.8694, Validation cost= 0.2651, Validation acc= 0.8691
Epoch 58500: Training cost= 0.3180, Training acc= 0.8694, Validation cost= 0.2324, Validation acc= 0.8692
tm  [-1.  -0.1 10.7  9.7 -2.  -0.1  0.3 -0.2 -0.3 -1.  -3.1 -0.2 -0.1 -0.3  8.5 -0.6 -0.4 -0.2 -0.4  0.7 -1.4 -0.3  0.7 -0.4 -0.8  2.3 -0.4 -0.3 -0.5 -1.4 -0.2 -0.4 -0.2  9.9 -0.1 -0.1 -0.2  1.8 13.7 -0.3  3.8  1.8  0.9  1.3 -0.1 -0.2  0.3  0.1  2.9  0.8 -0.2 -0.1  0.1 -1.6 -0.5 -1.1 -0.9  7.   2.7  5.   0.8  0.2  0.5 -0.2 -1.2 -0.6 -0.1 -0.3  1.4  0.3  0.3 -0.5 -0.2  1.2 -2.3  0.6 -0.1  2.4 -0.1 -0.2  0.2 -0.3 -0.1 -0.2 -0.8  2.2 -1.   0.1 -0.1 -0.4 -0.8 -0.2  0.3 -0.8 -0.5  0.2  1.4 -2.9 -0.8 -0.3  3.3  4.9 -0.4 -0.4 -0.2 -0.3 -0.9 -0.1 -0.8 -1.2 -0.9 -0.2 -0.2 -0.8  1.2  5.9  0.6 -0.3  0.4 -0.7 -0.2  3.8 -0.1  0.5 -0.2 10.8 -0.2  6.4  4.5  2.4 -0.7 -0.3 -1.  -0.3 -7.7 -3.8 -0.1  0.2 -0.6 -0.3  0.9 -0.4 -0.3 -0.2 -0.2  0.9 -0.2 -0.1 -0.8 -0.2 -1.3  0.3  1.4  1.3 -0.  -0.2 -0.8 -0.5  4.6 -0.4 -0.4 -1.2 -0.  -0.2 -0.1 -0.3 -0.4 -0.3 -0.1  0.   0.   0.  -0.2 -0.3 -0.2 -0.1  1.  -0.  -1.2 -0.  -1.5 -0.1 -0.3 -1.6 -0.  -0.2 -0.2 -0.1 -0.1  3.9 -0.1 -0.1 -0.2 -0.3  1.8 -1.5 -0.1 -0.4 -0.1 -0.  -0.  -0.1 -0.2  0.1 -0.2 -0.8 -0.2 -0.1 -0.4 -0.4 -0.7  1.3 -0.   2.1 -0.7 -0.3 -0.9 -1.5 -0.2 -0.8 -0.  -0.2  0.1 -1.1 -2.1  2.  -1.7 -0.5 -0.1  0.2 -0.2 -0.6 -0.3 -0.3 -0.  -2.4 -0.5 -0.1  4.1 -0.2 -0.1 -0.5 -0.2 -0.3  2.5 -0.9 -0.4 -0.5 -1.2  0.7 -0.3 -0.   7.7 -0.   7.2  0.5]
ty_50sample [[7 5 5 8 1 0 0 4 2 6]
 [2 9 9 1 8 6 4 0 5 7]
 [9 9 3 4 5 2 7 0 6 8]
 [8 6 7 5 2 3 9 4 0 1]
 [2 5 3 9 8 6 7 7 4 1]
 [0 6 1 2 5 7 3 4 9 8]
 [3 8 5 6 2 4 7 1 9 0]
 [8 4 2 1 3 6 9 5 7 0]
 [0 8 5 1 6 9 2 4 7 3]
 [4 9 2 3 8 1 6 5 7 0]]
tt_50sample [[7 5 3 1 8 9 0 4 2 6]
 [2 3 9 1 8 6 4 0 5 7]
 [9 1 3 5 4 2 0 7 6 8]
 [6 8 7 5 2 3 9 4 0 1]
 [2 3 5 9 8 6 7 0 4 1]
 [0 6 1 2 7 5 3 4 9 8]
 [3 8 5 6 2 4 7 1 9 0]
 [4 8 2 1 3 6 9 5 7 0]
 [0 8 5 1 6 9 2 4 7 3]
 [4 9 2 3 8 1 6 5 7 0]]
vm  [-0.1 -0.1 13.3 17.3 -1.4  0.8  0.2 -0.1 -1.3 -0.4  5.1 -0.2 -0.2 -0.2  6.7 -0.9 -0.6  0.1 -0.5 -0.  -0.9 -0.4 -0.4 -0.3 -1.   3.3 -0.2  0.1 -1.6  1.7 -0.4 -0.2 -0.5 13.7 -0.  -0.1  4.6  0.6  3.6 -0.5 -0.4 -2.1  0.6 -1.1 -0.1 -0.2  2.2 -0.4  3.4 -1.7 -0.   0.   1.  -0.6  1.9 -1.  -0.3  3.9 -2.6  5.6 -0.2 -0.5  0.2 -0.1 -0.4 -0.2 -0.2 -0.2  2.3 -0.1 -0.1  6.6 -0.1 -0.1 -1.  -0.7 -0.2 -1.2 -0.1  0.1  8.8 -0.  -0.  -0.5 -1.  -1.8 -0.6 -0.1 -0.1 -0.4 -0.  -0.1 -0.1  0.3  0.2  0.2 -1.  -1.7 -0.4 -0.   1.8  4.5 -0.7 -0.2 -0.1  1.3 -0.7 -0.2  2.3 -0.5 -0.3 -0.5 -0.   0.1 -0.3 -3.8 -1.  -1.  -0.  -0.4  0.4  2.7 -0.3  2.1 -0.1  8.7 -0.3  3.4 -3.1  2.4  1.8  0.2 -0.1  0.4 -2.9  6.1 -0.2 -0.2  0.  -0.3 -0.5 -0.6 -0.7 -0.3 -0.1 -0.1 -0.4  0.  -2.5 -0.1 -2.  -0.1  0.4  0.3 -0.1 -0.1 -0.2 -0.6 -0.6 -0.2 -0.5 -0.4 -0.1 -0.2 -0.1 -0.3 -0.1 -0.1 -0.3 -0.1  0.1 -0.3  0.1 -0.1 -0.2  3.8  0.1 -0.1 -0.4 -0.2 -0.2 -0.3  0.1 -1.8  0.  -0.3 -0.  -0.2  0.1 -0.4 -0.  -0.1 -0.2 -1.4  4.8 12.8 -0.3 -0.   0.  -0.  -0.2 -0.1 -0.4 -0.2 -0.  -0.3 -0.1 -0.2  1.6 -0.3 -0.2 -2.4 -0.9  0.2  0.6  0.1  6.4 -0.9 -0.4  2.7 -0.1 -0.1 -0.  -0.7  0.1 -1.3 -0.6  1.4 -0.5 -0.5 -0.4 -0.6  0.4  0.9  2.1 -2.8  1.7 -0.2  0.8  9.3 -0.   1.7 -0.2 -0.1 -1.3 -1.3 -0.5  1.9 -1.1 -0.5 -2.5 -0.   1.9  0.4  3.1 -0.1]
vy_50sample [[7 0 3 9 6 2 1 8 5 4]
 [8 5 1 3 6 7 0 9 4 2]
 [4 3 2 1 5 0 9 7 7 6]
 [2 8 0 9 3 4 1 7 6 5]
 [6 5 7 1 9 2 8 0 3 4]
 [1 7 9 5 8 6 2 0 3 4]
 [4 5 2 9 7 3 0 8 6 1]
 [9 0 5 1 4 6 3 8 2 7]
 [3 7 5 1 2 6 4 0 9 8]
 [2 7 8 9 3 6 1 0 4 5]]
vt_50sample [[7 0 3 9 6 2 1 5 8 4]
 [8 5 1 3 6 7 0 9 2 4]
 [4 3 2 1 5 0 9 8 7 6]
 [2 8 0 9 3 4 1 7 6 5]
 [6 5 7 1 9 2 0 8 3 4]
 [1 7 9 5 8 6 2 0 3 4]
 [4 5 2 9 7 3 0 8 6 1]
 [9 0 5 1 4 3 6 8 2 7]
 [3 7 5 1 2 6 4 0 9 8]
 [2 7 8 9 3 6 1 0 4 5]]
Epoch 58510: Training cost= 0.2245, Training acc= 0.8694, Validation cost= 0.1982, Validation acc= 0.8692
Epoch 58520: Training cost= 0.2520, Training acc= 0.8694, Validation cost= 0.2732, Validation acc= 0.8692
Epoch 58530: Training cost= 0.2409, Training acc= 0.8695, Validation cost= 0.2331, Validation acc= 0.8692
Epoch 58540: Training cost= 0.1966, Training acc= 0.8695, Validation cost= 0.2365, Validation acc= 0.8692
Epoch 58550: Training cost= 0.1990, Training acc= 0.8695, Validation cost= 0.2420, Validation acc= 0.8692
Epoch 58560: Training cost= 0.2579, Training acc= 0.8695, Validation cost= 0.2161, Validation acc= 0.8692
Epoch 58570: Training cost= 0.1801, Training acc= 0.8695, Validation cost= 0.2136, Validation acc= 0.8692
Epoch 58580: Training cost= 0.2160, Training acc= 0.8695, Validation cost= 0.2104, Validation acc= 0.8692
Epoch 58590: Training cost= 0.2331, Training acc= 0.8695, Validation cost= 0.1958, Validation acc= 0.8692
Epoch 58600: Training cost= 0.2766, Training acc= 0.8695, Validation cost= 0.2551, Validation acc= 0.8692
tm  [-1.   0.  -2.1  5.2 -1.2 -0.2 -0.2 -0.1 -0.5 -0.5  9.4 -0.1 -0.2  0.3 -2.   4.6 -0.1 -0.4 -0.4 -0.3 -1.8 -0.2  1.8 -0.1 -1.5  3.  -0.2 -0.2 -0.5 -1.   1.1 -0.2 -0.4 -1.6 -0.1 -0.1  2.8  5.4  5.3 -0.4  1.1 -1.9 -0.3  0.  -0.2  0.3  1.7 -0.2 -0.7  4.2 -0.2 -0.3  1.   6.3 -1.1  2.5 -0.3 -2.2 -0.6 -0.4  0.8 -0.2 -0.2  0.  -0.2 -0.1 -0.2  0.  -0.6  0.4 -0.2 -0.8  0.9  1.3 -0.7 -0.5 -0.2 -0.5 -0.  -0.   9.3  0.3  0.3 -0.1  0.2 -1.2 -0.4  0.2 -0.1 -0.2  0.6 -0.1  0.2 -0.4 -0.3 -0.3 -0.4 -1.6 -0.2  0.1  1.6 -0.2  0.1  0.8 -0.2  2.3 -0.4  0.1  0.4 -1.  -0.3 -0.1 -0.1 -0.3 -0.3  7.  -0.6 -0.8 -0.2  0.2 -0.1  4.5 -0.   1.3  0.4 -2.7  0.1 -0.7 -1.2 -1.6  0.1 -0.3  0.2 -0.1  8.6  5.3 -0.1 -0.   1.1 -0.4 -0.  -0.1 -0.6 -0.2 -0.2 -0.2 -0.  -0.1 -0.6 -0.1 -0.6 -0.1 -0.3 -0.3  0.3 -0.2 -0.5  0.2 -0.1 -0.5  1.2 -0.   0.3 -0.1 -0.  -0.2 -0.2 -0.1  0.1  0.1 -0.2 -0.1 -0.1  0.6 -0.1  1.5 -0.3  0.3 -0.4 -0.1  2.7 -0.2 -0.4 -1.9 -0.1 -0.3 -0.2 -0.2 -0.1  3.4 -0.  -0.2 -0.1 -1.3  2.3  4.6  1.1  1.3 -0.2 -0.2 -0.2 -0.1 -0.4 -0.6  1.3  1.4 -0.1  0.   8.4 -0.1 -0.5 -0.  -0.9  9.5 -0.4 -0.4  0.5 -1.2 -0.4  0.9 -0.2 -0.  -0.1 -0.8  2.9  2.4  2.4  1.1 -0.3 -0.6 -0.3 -1.2 -0.2  0.8 -0.2  3.3 -0.2  0.7  2.9 21.6 -0.1  6.   0.2 -0.1 -1.4 -1.4 -0.5  1.2 -1.4 -0.1 -2.5 -0.3  2.8 -0.3 -1.1  7.1]
ty_50sample [[2 9 1 6 4 8 3 0 7 5]
 [2 0 6 9 5 3 8 7 4 1]
 [2 0 0 9 4 7 5 1 6 3]
 [9 5 1 4 6 0 3 7 8 2]
 [5 0 2 6 1 3 4 7 8 9]
 [2 6 6 4 3 5 8 7 9 0]
 [7 4 1 6 9 5 8 2 0 0]
 [6 1 5 2 8 3 7 0 4 9]
 [5 9 8 3 7 4 1 2 0 6]
 [6 3 4 1 2 7 7 0 9 5]]
tt_50sample [[2 9 1 4 6 8 3 0 7 5]
 [2 0 6 9 5 8 3 7 4 1]
 [2 0 8 9 4 7 5 1 6 3]
 [9 5 1 4 6 0 3 7 8 2]
 [5 0 2 6 1 3 4 7 8 9]
 [2 6 1 4 3 5 8 7 9 0]
 [7 4 1 6 9 5 8 2 3 0]
 [6 1 5 2 8 3 7 0 4 9]
 [5 9 8 3 7 4 1 2 0 6]
 [6 3 4 8 1 2 7 0 9 5]]
vm  [-0.6  0.3  5.5 19.1 -0.8  0.2 -0.1 -0.2 -1.1 -0.6 13.  -0.3 -0.2 -0.3 -1.6  1.2 -0.2 -0.2 -0.1 -1.2 -1.3 -0.2 -0.3 -0.1 -0.9 -0.1 -0.3 -0.5 -1.2 -1.7  0.1 -0.1  1.3 13.9 -0.3 -0.   4.4  6.1 11.4 -0.4  4.5 -2.8 -0.4 -0.2  0.1 -0.3  8.  -0.  -2.  -3.3 -0.2  0.2 -0.3  1.1  1.   1.1 -0.5 -0.5 -0.6 -1.7 -0.2 -0.4 -0.4 -0.2 -0.6 -0.4 -0.1 -0.1 -0.5 -0.2 -0.1  3.6 -0.  -0.8  5.9 -0.1 -0.2 -0.6 -0.3 -0.3 31.7 -0.2 -0.2 -0.   1.1 -1.8 -1.8 -0.2 -0.  -0.3 -0.2 -0.1 -0.2  2.1 -0.3  0.4 -0.1  0.8 -0.4  0.2  4.2  1.6  1.2 -0.2 -0.2 -0.2 -0.5 -0.4 -0.7 -1.8 -0.6 -0.   0.  -0.2  0.7 -1.9  2.  -1.1 -0.1 -0.3 -0.1  8.2 -0.4 -0.3 -0.  -2.1 -0.1 -0.  -1.2 -1.5 -0.6 -0.1 -0.1 -0.4 -0.6 14.7 -0.4 -0.2 -0.2 -0.1 -0.4 -0.  -0.6 -0.1 -0.1 -0.  -0.2 -0.  -1.6 -0.2 -2.4 -0.2 -1.8 -0.8 -0.2 -0.1  0.7 -0.5 -0.2 -0.4  0.5 -0.4 -0.2 -0.1  0.6  2.3 -0.1 -0.3 -0.2 -0.1 -0.2 -0.2 -0.2 -0.  -0.   3.5 -0.6 -0.1 -0.9 -0.2  0.7 -0.1 -0.1 -0.7 -0.4 -0.4 -0.5 -0.6 -0.1  4.9 -0.4 -0.  -0.  -0.8  3.8  4.1 -0.  -0.3 -0.3 -0.1 -0.3 -0.2 -0.2 -0.6 -0.1  0.9 -0.1 -0.1 -0.8 -0.1 -0.6 -2.2 -0.3  8.   0.3 -0.   2.4 -0.7 -0.3  1.5 -0.2  0.4 -0.2 -0.5 -0.3 -1.4  4.8 -0.1 -0.6 -0.6 -0.8 -0.7 -0.2 -0.1  1.1 -0.9  0.  -0.1 -0.2 26.8 -0.1  8.2 -0.2 -0.  -6.7 -1.2 -0.2  0.4 -1.1 -0.1 -8.  -0.2  5.7 -0.2 -0.7  5.6]
vy_50sample [[2 2 1 0 3 7 6 4 5 8]
 [9 5 3 7 6 8 1 2 4 4]
 [0 5 3 1 9 6 2 4 8 7]
 [9 7 5 0 8 2 1 6 4 3]
 [8 7 1 5 3 2 4 9 6 0]
 [3 2 7 4 9 0 5 6 1 8]
 [5 2 9 0 4 3 6 7 8 8]
 [4 6 3 0 1 7 5 9 2 8]
 [9 2 5 3 0 7 1 4 6 8]
 [4 7 5 2 6 1 8 9 0 3]]
vt_50sample [[2 9 1 0 3 7 6 4 5 8]
 [9 5 3 7 6 8 1 2 4 0]
 [0 5 3 1 9 6 2 8 4 7]
 [9 7 5 0 8 2 1 6 4 3]
 [8 7 1 5 3 2 4 9 6 0]
 [3 2 4 7 9 0 5 6 1 8]
 [5 2 9 0 4 3 6 7 8 1]
 [4 6 3 0 1 7 5 9 2 8]
 [9 2 5 3 0 7 1 4 6 8]
 [4 7 5 2 6 1 8 9 0 3]]
Epoch 58610: Training cost= 0.2551, Training acc= 0.8695, Validation cost= 0.2736, Validation acc= 0.8692
Epoch 58620: Training cost= 0.2259, Training acc= 0.8695, Validation cost= 0.2084, Validation acc= 0.8692
Epoch 58630: Training cost= 0.2068, Training acc= 0.8695, Validation cost= 0.2932, Validation acc= 0.8692
Epoch 58640: Training cost= 0.1954, Training acc= 0.8695, Validation cost= 0.2155, Validation acc= 0.8692
Epoch 58650: Training cost= 0.2628, Training acc= 0.8695, Validation cost= 0.2691, Validation acc= 0.8692
Epoch 58660: Training cost= 0.3131, Training acc= 0.8695, Validation cost= 0.2722, Validation acc= 0.8693
Epoch 58670: Training cost= 0.2389, Training acc= 0.8695, Validation cost= 0.2566, Validation acc= 0.8693
Epoch 58680: Training cost= 0.2355, Training acc= 0.8696, Validation cost= 0.2420, Validation acc= 0.8693
Epoch 58690: Training cost= 0.2010, Training acc= 0.8696, Validation cost= 0.2265, Validation acc= 0.8693
Epoch 58700: Training cost= 0.2387, Training acc= 0.8696, Validation cost= 0.2746, Validation acc= 0.8693
tm  [ 0.3 -0.1  8.1  1.5 -2.3 -0.1  0.2 -0.  -0.7  1.5 -2.9 -0.3 -0.2 -0.2 10.6 -2.6 -0.6 -0.2 -0.8 -0.1 -1.5  0.  -0.3 -0.2 -1.   2.6 -0.1 -0.1 -0.9 -2.5  0.1 -0.1 -0.3 10.9 -0.  -0.2 -0.5 -0.5  3.2 -0.2  4.8 -0.7 -0.3  2.  -0.1 -0.4 -0.  -0.3  6.6 -0.4 -0.   0.3 -0.  -0.8  2.1 -1.4 -0.7 -0.2  7.5  3.2 -0.1 -0.3  0.8 -0.4  0.6 -0.7  0.3 -0.3  3.5 -0.1 -0.   4.4 -0.6 -0.7 -3.6 -0.4 -0.1  3.1 -0.1 -0.4 -0.8  0.8 -0.  -0.6 -1.8 -0.7  5.  -0.3  0.  -0.1 -0.4 -0.1 -0.4 -1.  -0.8 -0.  -0.5 -3.7 -0.3 -0.3 -0.9  4.4 -0.7 -0.1  0.3 -0.2 -1.6 -0.5 -0.9  0.3 -0.2 -0.  -0.2 -0.7  8.2 -3.8  0.4  0.8 -0.3 -0.3 -0.1 -0.6 -0.4 -0.5 -0.1 13.7 -0.5  4.6  7.6  5.  -0.3 -0.1 -0.8  1.3 -4.9 -1.3  0.2  0.3 -0.6 -0.   1.1 -0.6 -0.  -0.2  0.2  0.3 -0.3 -0.2 -1.3 -0.1 -0.4 -0.2  3.5  3.6 -0.  -0.1 -0.5 -0.4  0.  -0.3 -0.6 -1.8  0.4  0.1  0.5 -0.1 -0.2 -0.6 -0.4  0.5 -0.2  0.1 -0.3 -0.1 -0.1  0.9 -1.  -0.2 -0.4 -0.1 -0.5 -0.3 -0.  -2.5 -0.1 -0.6 -0.1 -0.3  0.3  6.7 -0.  -0.4 -0.2 -0.8  5.7 -2.6 -0.5 -2.7 -0.2  0.2 -0.2 -0.2 -0.6 -0.  -0.3 -1.6 -0.2  0.1  4.2 -0.3 -0.3 -1.4 -0.3 -2.1 -1.4  0.2 -1.1 -1.8 -0.4 -0.2  0.2 -0.   1.5 -1.2 -1.3 -0.9 -2.7 -0.6 -0.5 -0.  -0.7 -0.1 -0.2  1.2 -0.2 -1.6  0.2 -0.4  6.3  2.2 -0.1 -0.5 -0.  -0.1  4.3 -0.8 -0.1 -0.9 -1.4  1.8  0.2 -0.   2.8 -0.   9.2 -0.7]
ty_50sample [[0 7 3 8 4 9 5 6 1 2]
 [8 1 2 6 3 5 5 4 4 7]
 [2 0 9 4 7 1 8 3 5 6]
 [0 8 5 4 2 1 9 7 3 6]
 [6 3 0 1 7 5 9 8 4 2]
 [6 1 5 3 0 8 4 9 2 7]
 [3 8 0 1 2 5 9 6 7 7]
 [1 9 8 0 7 4 3 5 6 2]
 [2 5 0 9 8 7 3 4 6 1]
 [3 6 1 7 2 5 9 4 8 0]]
tt_50sample [[0 7 3 8 4 9 5 6 1 2]
 [8 1 2 6 3 0 5 4 9 7]
 [2 0 9 4 7 1 8 3 5 6]
 [0 8 5 4 2 1 9 7 3 6]
 [6 3 0 1 5 7 9 8 4 2]
 [6 1 5 3 0 8 4 9 2 7]
 [3 8 0 1 2 5 9 6 7 4]
 [1 9 8 7 0 4 3 5 6 2]
 [2 5 0 8 9 7 3 4 6 1]
 [3 6 1 7 2 5 9 4 8 0]]
vm  [ 1.  -0.4 -0.4 -4.2 -1.5 -0.3 -0.6 -0.1 -0.2  0.1 -5.5 -0.  -0.2 -0.5  9.4  1.7 -0.6 -0.  -0.1  1.2 -1.5 -0.1 -0.1 -0.2 -1.1  0.3 -0.4 -0.5 -0.2 -1.1 -0.7 -0.2  0.5 -4.8 -0.2  0.4 -0.7  5.   0.5 -0.4  5.  -1.7  0.   5.2 -0.4  0.1 -2.   0.4  8.6  9.6 -0.4 -0.  -0.6  9.7 -1.2 -1.2 -0.7 -2.4  4.9  5.1  1.5 -0.7 -0.3 -0.  -0.7 -1.1 -0.  -0.2  2.7 -0.2 -0.1 -0.5  0.1  1.1 -4.8 -0.5 -0.2 -0.2 -0.  -0.3 -9.4 -0.2  0.2 -0.2 -2.3 -1.6  8.  -0.6 -0.1 -0.5 -0.1  0.  -0.2 -0.9 -0.8 -0.3 -0.3 -4.6 -0.4 -0.6  0.7  0.7  0.   0.7 -0.2 -1.  -1.4 -0.6 -1.   1.9 -0.5 -0.3 -0.  -0.2  1.   7.8  1.8  0.4 -0.4 -0.2 -0.2 -1.1  0.6 -1.3  0.  12.6 -0.1 -1.4  6.6 11.  -0.6 -0.2 -0.1 -0.4 -4.2 -8.8 -0.2 -0.3 -0.2  3.7 -0.4 -0.4 -0.  -0.  -0.2  0.3 -0.2 -0.1 -1.1 -0.   4.3 -0.   2.3  0.  -0.3 -0.3 -0.3 -0.3  4.6 -0.3 -0.1 -1.3 -0.1 -0.1 -0.4 -0.3  0.2 -0.2 -0.4 -0.  -0.  -0.1 -0.5 -0.2 -0.1  0.8 -0.6 -0.4 -0.2 -0.1 -0.2 -0.6 -0.1 -1.6 -0.5 -0.1 -0.4 -0.2 -0.3  2.4 -0.1 -0.3 -0.4 -0.4  1.4 -2.3 -0.3 -0.2 -0.5 -0.  -0.4  0.  -0.2 -0.4 -0.  -2.7  0.4  0.3 13.7 -0.1 -0.9  0.5 -1.  -2.1 -1.1 -0.2 -2.5 -0.9 -0.4 -0.  -0.  -0.1 -0.2 -1.3 -2.2  1.2 -1.1  0.1 -0.8  1.4  0.3 -0.4 -0.5 -0.4 -1.  -0.2 -0.1 -0.3  4.1 -1.5 -0.1 -1.1 -0.1 -0.2 25.8  1.9  0.3 -0.6 -1.   0.9 23.8 -0.4  1.1  0.1  3.3 -2.3]
vy_50sample [[8 4 3 7 2 0 5 1 6 9]
 [3 9 2 1 7 8 4 0 6 5]
 [5 5 4 4 2 8 3 7 6 1]
 [3 0 9 5 1 2 6 4 8 7]
 [7 2 0 6 9 3 8 1 5 4]
 [4 7 9 3 2 6 8 5 0 1]
 [3 1 6 5 4 0 9 2 8 7]
 [1 3 2 9 8 6 0 4 5 7]
 [8 7 6 5 0 1 2 9 4 3]
 [0 5 1 9 4 3 2 8 7 6]]
vt_50sample [[8 4 3 7 2 0 5 1 6 9]
 [3 9 2 1 7 8 4 0 6 5]
 [0 5 4 9 2 8 3 7 6 1]
 [3 0 9 5 1 2 6 8 4 7]
 [7 2 0 6 9 3 8 1 5 4]
 [7 4 3 9 2 6 8 5 0 1]
 [3 1 6 5 4 0 9 2 8 7]
 [1 3 2 9 8 6 0 4 5 7]
 [8 7 6 5 0 1 2 9 4 3]
 [0 5 9 1 4 3 2 8 7 6]]
Epoch 58710: Training cost= 0.2262, Training acc= 0.8696, Validation cost= 0.2862, Validation acc= 0.8693
Epoch 58720: Training cost= 0.2264, Training acc= 0.8696, Validation cost= 0.2589, Validation acc= 0.8693
Epoch 58730: Training cost= 0.2322, Training acc= 0.8696, Validation cost= 0.2359, Validation acc= 0.8693
Epoch 58740: Training cost= 0.2516, Training acc= 0.8696, Validation cost= 0.1982, Validation acc= 0.8693
Epoch 58750: Training cost= 0.3119, Training acc= 0.8696, Validation cost= 0.2555, Validation acc= 0.8693
Epoch 58760: Training cost= 0.2457, Training acc= 0.8696, Validation cost= 0.2703, Validation acc= 0.8693
Epoch 58770: Training cost= 0.2582, Training acc= 0.8696, Validation cost= 0.2178, Validation acc= 0.8693
Epoch 58780: Training cost= 0.2251, Training acc= 0.8696, Validation cost= 0.2306, Validation acc= 0.8693
Epoch 58790: Training cost= 0.2002, Training acc= 0.8696, Validation cost= 0.2351, Validation acc= 0.8693
Epoch 58800: Training cost= 0.2235, Training acc= 0.8696, Validation cost= 0.2920, Validation acc= 0.8693
tm  [-0.2 -0.2 11.3 24.5 -1.5 -0.4  0.3  0.3 -1.2 -0.  -2.1 -0.1 -0.2 -0.1  0.7 -0.9 -0.5 -0.1 -0.9 -1.4 -1.1 -0.1 -0.8  0.1  0.  -0.3 -0.2  0.1 -0.8  0.7 -0.2 -0.5  0.6 15.4 -0.2 -0.2  2.1 -0.7 14.6 -0.3  2.5 -0.8  0.2 -0.3 -0.1 -0.2  7.8 -0.   1.3 -4.4 -0.  -0.  -0.3 -5.3 -1.  -0.4 -0.5  9.1 -1.9  4.2 -1.  -0.8 -0.4 -0.3  0.7 -0.5 -0.1 -0.3  0.3 -0.1 -0.1  0.6 -0.2 -0.7 -0.3 -0.8 -0.2 -0.8 -0.1  0.7 22.8 -0.2 -0.1 -0.8 -0.9 -1.1 -0.6 -0.2 -0.2 -0.2 -0.3 -0.1  0.   1.7 -0.6 -0.6 -0.9 -0.6 -0.  -0.1  0.1 -0.6  0.1 -0.  -0.1  2.1 -0.8 -0.3 -0.6 -1.9 -0.1 -0.3 -0.1 -0.5 -1.  -0.4 -0.5 -0.6 -0.1 -0.4 -0.2  7.8 -0.2  2.4 -0.   0.9 -0.1 15.4 -0.9  4.3 -0.  -0.  -0.   0.9 -4.1  6.2 -0.1 -0.1  0.3 -0.7 -0.   0.4 -0.  -0.  -0.1 -0.1 -0.4 -0.1  0.3 -0.3 -3.  -0.1 -0.6 -0.3 -0.1 -0.1 -0.2 -0.6 -0.  -0.8 -0.3 -1.1 -0.1 -0.1 -0.   2.4 -0.4 -0.4 -0.1 -0.  -0.1 -0.1 -0.1 -0.1  0.2 -0.1 -0.5 -0.4 -1.3 -0.1 -2.1 -0.3  0.8 -1.5 -0.2  0.1 -0.1 -0.2 -0.1  0.1 -0.1 -0.2 -0.2 -1.1 10.2  4.2  0.3  3.1 -0.2 -0.1 -0.1 -0.2 -0.1 -0.7 -0.   2.3 -0.1 -0.1 -3.9 -0.1 -0.2 -0.6 -0.7 -0.2 -0.1  0.5  2.4 -1.4 -0.5  0.8 -0.1 -0.   1.7 -0.5 -1.9 -0.4 -2.  -0.4 -0.9 -0.5 -0.5 -0.3 -0.  -0.3 -0.5 -2.6 -0.2 -0.5  0.5  2.7 -0.  -0.2 -0.1 -0.2 -4.5 -1.7 -0.5 -0.3 -0.9 -0.4 -5.9  0.1  8.3 -0.2 11.  -0.4]
ty_50sample [[3 7 9 5 0 6 1 8 4 2]
 [5 2 0 4 9 7 8 6 1 3]
 [6 3 5 8 9 7 2 4 0 1]
 [6 2 7 4 3 0 9 1 5 8]
 [6 8 1 4 9 7 2 3 5 0]
 [8 4 0 9 3 2 6 5 1 7]
 [8 1 9 3 6 2 4 0 5 7]
 [5 9 1 3 8 0 2 6 7 4]
 [5 6 7 2 1 9 3 8 0 4]
 [2 9 3 6 0 7 8 5 1 4]]
tt_50sample [[3 7 9 5 0 6 1 8 4 2]
 [5 2 0 4 9 7 8 6 1 3]
 [6 3 5 8 9 7 2 4 0 1]
 [6 7 2 4 3 0 9 1 5 8]
 [6 8 1 4 9 7 2 3 5 0]
 [8 4 0 9 3 2 6 5 1 7]
 [8 1 9 3 6 2 4 0 5 7]
 [5 1 9 3 8 0 2 6 7 4]
 [5 6 7 2 1 9 3 8 0 4]
 [2 9 3 6 0 7 8 5 1 4]]
vm  [-0.5 -0.1 12.8 19.9 -0.6 -0.4 -0.4 -0.1 -0.3 -0.6  9.4 -0.2 -0.  -0.1  4.4  2.3  0.2 -0.  -0.3 -1.1 -1.1 -0.2 -0.4 -0.2 -0.4 -0.1 -0.2  0.3 -0.3 -1.5  0.6 -0.1 -0.5 22.2 -0.1 -0.1 -0.1  4.2 17.4  0.1  0.7  2.4 -0.5 -0.7 -0.4  0.8  5.8 -0.2 -1.5 -2.  -0.  -0.  -0.3 -0.8 -1.  -0.8 -0.5  9.1  2.2 -0.4  0.3 -0.1 -0.2 -0.   1.4 -0.6 -0.4 -0.2  0.7 -0.3 -0.1 -1.2  0.1 -0.1 -0.6  0.3 -0.1 -0.1 -0.2 -0.3 26.3 -0.7 -0.1 -0.2  1.3  3.  -2.9  0.4 -0.2 -0.6 -0.5 -0.  -0.  -0.7 -0.7 -0.6  0.5 -1.9 -0.5 -0.5  3.   5.9  0.2 -0.  -0.3  1.7 -0.7  0.7  0.5 -1.6  0.4 -0.2 -0.  -0.5 -0.1  9.1 -0.8 -0.4 -0.2 -0.5 -0.3  6.3  0.7  0.1  0.6  5.6 -0.1  4.   4.7 -2.2 -0.1 -0.4 -0.7 -0.5 -6.7  7.2 -0.1 -0.1 -0.  -0.3 -0.3  0.3 -0.1 -0.3 -0.1  0.7 -0.   0.2 -1.  -0.3 -2.2  0.4 -1.9  0.1 -0.  -0.1 -0.3 -0.6  0.4  0.6 -0.3 -1.1 -0.   0.4 -0.4  0.3 -0.1 -0.2 -0.2 -0.2 -0.2 -0.1 -0.  -0.2 -0.   0.2  0.2 -0.3 -1.8 -0.1 -1.3 -0.4 -0.3 -1.3 -0.2 -0.1 -0.3 -0.3 -0.1  4.3 -0.1 -0.1 -0.5 -0.5  2.3 -1.3  0.2  0.2 -0.3 -0.1 -0.3 -0.   0.2 -0.1  0.5  1.5 -0.1 -0.  -4.6  0.4 -0.4  2.3 -0.6  6.1 -0.  -0.6  1.5 -1.1 -0.3 -0.6 -0.2 -0.2 -0.  -0.2 -0.4  0.2 -0.6  0.6 -1.6 -0.6 -0.7 -0.5 -0.1 -0.7 -0.1 -2.6 -0.9 -0.   1.5  4.9 -0.1  0.2  0.1 -0.2 -5.3 -1.7 -0.3 -0.6 -1.2  0.3 -6.6 -0.1  9.9 -0.3  0.7  8.6]
vy_50sample [[7 9 9 5 2 3 6 0 4 8]
 [7 3 0 2 5 9 8 6 1 4]
 [6 5 4 0 8 3 7 2 9 1]
 [5 0 0 6 6 8 2 9 1 7]
 [1 9 2 8 0 4 7 3 6 5]
 [4 2 5 5 6 3 8 9 7 1]
 [0 9 8 7 5 1 3 2 4 6]
 [3 5 6 9 8 0 7 4 2 1]
 [8 2 1 7 5 4 3 6 0 9]
 [0 2 8 9 3 1 4 6 5 7]]
vt_50sample [[7 9 1 5 2 3 6 0 4 8]
 [7 3 0 2 9 5 8 6 1 4]
 [6 5 4 0 8 3 7 2 1 9]
 [5 0 3 4 6 8 2 9 1 7]
 [1 9 2 8 0 4 3 7 6 5]
 [4 2 5 0 6 3 8 9 1 7]
 [0 9 8 7 5 1 3 2 4 6]
 [3 5 6 9 8 0 7 4 2 1]
 [8 2 1 7 5 4 3 6 0 9]
 [0 8 2 3 9 1 4 6 5 7]]
Epoch 58810: Training cost= 0.2130, Training acc= 0.8696, Validation cost= 0.2369, Validation acc= 0.8693
Epoch 58820: Training cost= 0.2785, Training acc= 0.8697, Validation cost= 0.1964, Validation acc= 0.8693
Epoch 58830: Training cost= 0.2371, Training acc= 0.8697, Validation cost= 0.2173, Validation acc= 0.8694
Epoch 58840: Training cost= 0.1996, Training acc= 0.8697, Validation cost= 0.2065, Validation acc= 0.8694
Epoch 58850: Training cost= 0.2385, Training acc= 0.8697, Validation cost= 0.2228, Validation acc= 0.8694
Epoch 58860: Training cost= 0.2296, Training acc= 0.8697, Validation cost= 0.2412, Validation acc= 0.8694
Epoch 58870: Training cost= 0.2089, Training acc= 0.8697, Validation cost= 0.1867, Validation acc= 0.8694
Epoch 58880: Training cost= 0.2013, Training acc= 0.8697, Validation cost= 0.2274, Validation acc= 0.8694
Epoch 58890: Training cost= 0.2301, Training acc= 0.8697, Validation cost= 0.2476, Validation acc= 0.8694
Epoch 58900: Training cost= 0.2252, Training acc= 0.8697, Validation cost= 0.2529, Validation acc= 0.8694
tm  [-0.1 -0.1 -2.9  1.6 -1.2 -0.1  0.2 -0.3 -0.3 -0.6  4.9 -0.3 -0.3 -0.1 -2.3  0.6 -0.4 -0.2 -0.6 -0.2 -1.5 -0.5 -0.7 -0.2 -1.   1.6 -0.6 -0.2 -0.2 -0.7  0.4 -0.1 -0.  -2.1 -0.2 -0.4 -0.2 -1.6 -3.5 -0.4  0.3  2.3  0.2 -1.  -0.1 -0.3  1.1 -0.2  6.7 -1.6 -0.2  0.2 -0.2  0.2 -0.5  2.  -0.4  4.   1.6 -1.2 -1.1 -0.8  0.  -0.1 -0.3 -0.6 -0.2 -0.2 -0.3 -0.1 -0.1 -0.7 -0.6 -0.2 -2.7 -0.7 -0.3  0.2 -0.1 -0.5  8.5 -0.3  0.  -0.7 -1.5  2.   5.2  0.3 -0.1 -0.4 -0.1 -0.2 -0.  -0.3 -0.6  0.1 -0.2 -2.9 -0.3 -0.4  1.7 -1.4 -0.5 -0.3 -0.2 -0.7 -1.5  0.   1.3 -1.4 -0.5  0.2 -0.2 -0.6  0.3  6.4 -0.1 -0.6  0.4 -0.3 -0.2  4.2 -0.2 -0.1 -0.2 -2.9 -0.1  2.   4.8  2.3 -0.4 -0.2 -0.3 -0.3 19.5 19.   0.8  0.6 -0.1 -0.8 -0.1 -0.3 -0.3 -0.3 -0.2 -0.3 -0.1 -0.   8.3 -0.1 -0.3 -0.1  2.6 -0.1  0.5 -0.1 -0.7  0.3 -0.6 -0.7 -0.7  0.7 -0.1 -0.2  0.4 -0.2  0.4 -0.1 -0.2  0.3 -0.1  1.2 -0.2 -0.  -0.  -1.8 -1.4 -0.4  2.7 -0.1 -1.9 -0.3 -0.3 -1.5 -0.  -0.3 -0.2  0.1 -0.1  1.7 -0.2 -0.2 -0.4 -1.2 11.3 -1.5 -0.4 -0.  -0.1  0.2 -0.1 -0.2 -0.2 -0.1 -0.5 -1.2 -0.2 -0.1 -3.4  0.1 -0.9  1.1 -0.2 -1.4 -0.8 -0.1  4.1 -1.3 -0.3 -0.6  0.   0.  -0.2 -1.2  1.1 -0.2 -1.5  0.  -0.4  1.   1.5 -0.  -0.3 -0.6 -0.6  2.3 -0.5 -0.1  2.6 -1.7 -0.1 -1.1  0.1 -0.3 -1.2 -0.9 -0.3 -0.9 -1.3  0.3 -2.5 -0.3 -1.8 -0.   4.2  0.1]
ty_50sample [[6 5 3 3 4 2 0 8 1 7]
 [0 9 7 6 2 8 3 5 4 1]
 [4 7 8 2 5 1 9 0 3 6]
 [7 9 6 2 1 4 8 0 3 5]
 [4 1 2 0 8 3 6 5 9 9]
 [9 3 6 7 2 0 1 8 5 4]
 [8 7 3 6 2 5 4 0 9 9]
 [3 8 2 4 6 0 5 7 9 1]
 [8 5 0 7 2 3 4 6 1 9]
 [2 9 5 1 8 0 7 3 6 4]]
tt_50sample [[6 5 3 9 4 2 0 8 1 7]
 [0 9 7 6 2 8 3 5 4 1]
 [4 7 8 2 5 1 9 0 3 6]
 [7 9 6 2 1 4 8 0 3 5]
 [4 1 2 0 8 3 6 5 7 9]
 [9 3 6 7 2 0 1 8 5 4]
 [8 7 3 6 2 5 4 0 1 9]
 [3 8 2 4 6 0 5 7 9 1]
 [8 5 0 7 2 3 4 6 9 1]
 [2 5 9 1 8 0 7 3 6 4]]
vm  [-0.1 -0.3 -1.1 -6.  -1.3 -0.1 -0.  -0.2 -0.3  0.   7.2 -0.1 -0.2 -0.2 12.   1.4 -0.3 -0.4 -0.5 -0.6 -2.   0.2 -0.4 -0.2 -0.9 -0.1 -0.2  2.1 -0.1 -0.4  0.3 -0.5 -0.1 15.1 -0.2 -0.1 -0.1  2.6 -0.2 -0.4 -0.5 -4.4 -0.9  2.4 -0.1 -0.5 -0.5 -0.2  2.7 -3.7 -0.1 -0.1 -0.1  7.6 -1.7 -1.6 -0.5 -4.8  6.9 -4.2 -0.  -0.4  0.4 -0.2  1.8 -1.2 -0.1 -0.  -0.2 -0.5 -0.2 -1.4 -0.8 -0.8 -5.  -0.1  0.2  0.9 -0.3 -0.2  2.3 -0.  -0.4 -0.4 -1.7 -4.1  9.4 -0.2 -0.2 -0.  -0.1 -0.3 -0.3 -0.3 -0.8 -0.2 -1.1 -3.3 -0.1 -0.  -0.5 -0.3 -0.6 -0.1 -0.4  0.4 -3.5 -0.1  1.1 -0.7  1.8 -0.3 -0.3 -0.7  2.1  5.1 -0.8  1.1 -0.3 -0.1 -0.1 -0.3 -0.3  0.4 -0.1 15.3 -0.2 -1.1  6.5 16.   1.3 -0.2 -0.1  0.9 -3.8  4.7  0.2 -0.3  0.2 -0.5 -0.7 -0.1 -0.3 -0.1 -0.3  0.   0.2  0.3 -2.8 -0.3  7.6 -0.1  3.4 -0.1 -0.1  0.3 -0.3 -0.2 -0.7 -0.9 -0.3 -0.9  0.3 -0.2 -0.1  0.4 -0.5 -0.2 -0.5 -0.2 -0.1 -0.3 -0.2 -0.2  0.   4.1 -0.4 -0.2 -0.2 -0.3  2.7 -0.5  0.5 -1.9 -0.1 -0.8 -0.1 -0.4  0.1  0.4 -0.2 -0.5 -0.4 -1.2  4.3 -2.5 -0.6 -0.9 -0.3 -0.2 -0.3 -0.  -0.1 -0.7  1.1 -2.9 -0.1  0.4  6.3 -0.4 -0.6  1.1 -0.5 -1.5  0.9  2.7 -2.3 -1.  -0.4 -0.  -0.2 -0.1 -0.5 -1.6 -1.5  1.9 -1.1 -0.3 -1.1 -0.2 -0.9  4.1 -0.2  1.7 -1.4  2.4 -0.1 -0.8  1.3  9.7 -0.1  1.6 -0.2 -0.3 -0.1  0.2 -0.5 -0.5 -0.6 -0.9 -1.1 -0.1 -0.  -0.1  3.2 -3.8]
vy_50sample [[4 3 7 2 6 9 8 1 1 5]
 [0 7 6 3 9 1 4 5 8 2]
 [0 7 1 4 5 8 2 6 3 9]
 [3 6 9 1 0 8 5 2 4 4]
 [1 7 0 5 2 6 9 8 4 3]
 [2 3 8 0 7 4 6 9 1 5]
 [7 6 1 9 3 2 8 5 0 4]
 [5 6 0 1 7 3 9 2 8 4]
 [2 5 9 3 9 4 6 7 8 0]
 [3 2 8 0 4 5 6 7 9 1]]
vt_50sample [[4 3 7 2 6 9 0 8 1 5]
 [0 7 6 3 9 1 4 5 8 2]
 [7 0 4 1 5 8 2 6 3 9]
 [3 6 9 1 0 8 5 2 7 4]
 [1 7 0 5 2 6 9 8 4 3]
 [2 3 8 0 7 4 6 9 1 5]
 [7 6 9 1 3 2 8 5 0 4]
 [5 6 0 7 1 3 9 2 8 4]
 [2 5 9 1 3 4 6 7 8 0]
 [3 2 8 0 4 5 6 7 9 1]]
Epoch 58910: Training cost= 0.2179, Training acc= 0.8697, Validation cost= 0.2203, Validation acc= 0.8694
Epoch 58920: Training cost= 0.2231, Training acc= 0.8697, Validation cost= 0.2529, Validation acc= 0.8694
Epoch 58930: Training cost= 0.1926, Training acc= 0.8697, Validation cost= 0.2404, Validation acc= 0.8694
Epoch 58940: Training cost= 0.2424, Training acc= 0.8697, Validation cost= 0.2100, Validation acc= 0.8694
Epoch 58950: Training cost= 0.2366, Training acc= 0.8698, Validation cost= 0.1951, Validation acc= 0.8694
Epoch 58960: Training cost= 0.2233, Training acc= 0.8698, Validation cost= 0.2197, Validation acc= 0.8694
Epoch 58970: Training cost= 0.1891, Training acc= 0.8698, Validation cost= 0.2723, Validation acc= 0.8694
Epoch 58980: Training cost= 0.2173, Training acc= 0.8698, Validation cost= 0.2339, Validation acc= 0.8695
Epoch 58990: Training cost= 0.1795, Training acc= 0.8698, Validation cost= 0.2171, Validation acc= 0.8695
Epoch 59000: Training cost= 0.1959, Training acc= 0.8698, Validation cost= 0.2116, Validation acc= 0.8695
tm  [-0.7 -0.3 -0.  13.4 -1.5  0.  -0.4 -0.  -0.1 -0.3  7.8 -0.3 -0.1 -0.1 -2.   1.2 -0.5  0.4 -0.1 -0.3 -1.4 -0.3 -0.4 -0.  -1.   3.3 -0.4  0.  -1.  -3.3 -0.4 -0.2  1.  -1.  -0.1 -0.2  1.4 -0.3 -2.1 -0.5 -0.2  0.4 -1.2 -1.8  0.  -0.2  0.8 -0.3  1.4 -0.4  0.4 -0.1  0.2 -0.1 -0.1  2.  -0.4  3.8  7.6  3.5 -0.2 -0.4  2.1 -0.   0.3 -0.3 -0.2 -0.3 -0.8 -0.3 -0.1  1.3  0.4  0.4 -1.9 -0.5 -0.1 -0.6 -0.1  0.7 11.4 -0.7 -0.2 -0.6 -0.3  2.8 -1.4 -0.2 -0.2  0.7 -0.2 -0.2 -0.4 -1.  -0.3  0.1 -0.1 -3.1 -0.2 -0.2 -0.1 -0.8 -0.5  0.1 -0.3 -0.5 -0.9 -0.2  1.8 -0.9 -0.4  0.9 -0.1 -0.2  6.  -0.8 -0.6 -0.4 -0.1 -0.6 -0.2  2.1 -0.4  1.9 -0.5 -2.5 -0.2  2.5  7.3 -0.9 -0.3 -0.1 -0.  -0.6 17.1 17.3 -0.  -0.4  0.4 -0.3 -0.4 -0.5 -0.8 -0.3 -0.1  0.4 -0.2 -0.3  4.7 -0.  -1.6 -0.2 -0.1 -0.8 -0.1 -0.1 -0.9  1.6 -0.6 -0.3  1.9 -0.3 -0.1 -0.1 -0.1 -0.5 -0.5 -0.2 -0.5  0.1 -0.1 -0.2 -0.1 -0.4 -0.  -0.7 -0.8  1.2  1.3 -0.  -0.6 -0.  -0.  -1.9 -0.1 -0.7  0.7 -0.2 -0.1  9.  -0.1 -0.1 -0.2 -1.   4.1 -2.5 -0.3 -2.2 -0.1 -0.2 -0.3 -0.2 -0.3 -0.7 -0.4 -0.4 -0.2  0.4 -1.2 -0.2 -0.3 -0.  -0.5  3.1 -1.3 -0.   7.7 -0.9 -0.4  0.  -0.  -0.1  0.6 -1.4  4.2 -0.5 -0.5  3.4 -0.4 -0.3  1.7 -0.4 -0.1 -0.1 -0.1 -0.1  0.1 -0.2  3.3  5.1 -0.   0.7 -0.1 -0.4 -1.9 -1.6 -0.7 -0.2 -1.4 -0.2 -3.2  0.1 -1.2 -0.  -0.7  5.2]
ty_50sample [[6 9 0 2 1 5 3 8 4 7]
 [4 9 8 3 2 6 5 7 0 1]
 [6 9 0 1 7 2 5 4 3 8]
 [7 0 5 5 8 1 3 6 4 2]
 [8 4 7 5 2 6 3 1 9 0]
 [2 5 7 3 9 8 4 1 0 6]
 [4 1 3 8 2 7 9 5 0 6]
 [5 3 7 0 6 2 1 9 8 4]
 [6 8 3 2 9 4 0 5 1 7]
 [4 3 5 0 1 8 7 9 6 2]]
tt_50sample [[6 9 0 2 1 5 3 8 4 7]
 [9 4 8 3 2 6 5 7 0 1]
 [6 9 0 1 7 2 5 4 3 8]
 [7 0 9 5 8 1 3 6 2 4]
 [8 4 7 5 2 6 3 1 9 0]
 [2 5 7 3 9 8 4 1 0 6]
 [4 1 3 8 2 7 9 5 0 6]
 [5 3 7 0 6 2 9 1 8 4]
 [6 8 3 2 9 4 0 1 5 7]
 [4 3 5 0 1 8 7 9 6 2]]
vm  [-0.9 -0.2  4.3 20.6 -1.2  0.6 -0.2 -0.  -0.4 -0.7  5.5 -0.4  0.2 -0.1 -2.3 -0.7 -0.1 -0.4  0.4 -0.8 -1.4 -0.1  2.4  0.4 -0.8  1.6 -0.3  0.2 -1.1 -6.  -0.7  1.1 -0.2 -2.8 -0.1 -0.1  1.5  5.  12.8  0.2  1.3 -1.4 -1.3 -0.9 -0.2 -0.1  5.2 -0.3 -1.9  2.4 -0.  -0.1 -0.3  3.1  1.6  3.  -0.7  5.6 10.6  6.5  2.8  0.6 -0.2 -0.1  0.3 -0.1  0.4 -0.2 -0.3 -0.3 -0.2  2.8 -0.  -0.3 -0.6  0.1 -0.1  1.5  0.1 -0.2  6.3 -0.5 -0.2 -0.3  2.6 -0.7 -3.7 -0.  -0.   0.9 -0.4 -0.1 -0.3 -0.9 -0.8 -0.1  1.  -2.8 -0.2 -0.2  2.6 -1.  -0.   0.3 -0.2 -0.5 -1.2 -0.1  1.2 -1.4  0.4  0.1 -0.1 -0.3  7.7 -2.1 -0.  -0.2 -0.2 -0.2 -0.2  4.6  0.6 -0.2 -0.4 -2.9 -0.2 -0.1  9.8 -1.  -0.4 -0.2 -0.4 -0.6  2.5 -2.2 -0.  -0.2 -0.2 -0.1 -0.3 -0.4 -0.5 -0.1 -0.   0.1 -0.1 -0.   3.4  0.3 -2.5 -0.2 -0.8  1.  -0.2 -0.2 -0.3  0.5 -0.1  0.2 -0.5 -0.8 -0.3 -0.1 -0.1 -0.2  0.2 -0.2 -0.1 -0.1  0.3 -0.1  0.  -0.2 -0.2 -0.4 -0.2  0.1 -1.4 -0.  -0.5  0.6 -0.4 -1.9 -0.2 -0.5 -0.1 -0.6 -0.1 16.3 -0.2 -0.  -0.2 -0.6 -0.6 -3.4 -0.5 -2.5 -0.2 -0.1 -0.1 -0.2 -0.4 -0.1 -0.2 -0.8 -0.2  0.8  5.3 -0.  -0.4 -1.1 -0.   6.4 -0.7 -0.4  2.5 -1.4 -0.4 -0.6 -0.1 -0.1 -0.2 -1.1 -0.6 -0.7 -0.4  0.2 -0.4 -0.6 -0.9 -0.3 -0.2  0.6  2.2 -0.8 -0.3 -0.3  3.4 14.1 -0.1  3.6  0.1 -0.2 -0.7 -1.4 -0.1 -0.6 -1.3  1.5 -1.9 -0.   7.3 -0.3  1.2  5.4]
vy_50sample [[1 0 2 9 8 3 5 6 7 4]
 [7 3 6 9 2 5 4 8 1 0]
 [9 2 3 7 4 8 5 1 0 6]
 [8 3 4 0 9 5 6 2 1 7]
 [8 0 7 2 1 4 6 3 5 9]
 [9 3 6 1 8 0 2 4 7 5]
 [0 3 4 4 8 5 6 2 7 9]
 [7 3 5 0 8 6 2 1 9 4]
 [3 4 8 0 1 9 6 7 2 5]
 [3 7 6 5 0 2 1 8 4 9]]
vt_50sample [[1 0 2 9 8 3 5 6 7 4]
 [7 3 6 9 2 5 4 8 1 0]
 [9 2 3 7 4 8 5 1 0 6]
 [8 3 4 0 9 5 6 2 1 7]
 [8 0 7 2 1 4 6 3 5 9]
 [3 9 6 1 8 0 2 4 7 5]
 [0 3 1 4 8 5 6 2 7 9]
 [7 3 5 0 8 6 2 1 9 4]
 [3 4 8 0 1 9 6 7 2 5]
 [3 7 6 5 0 2 1 8 4 9]]
Epoch 59010: Training cost= 0.2152, Training acc= 0.8698, Validation cost= 0.2467, Validation acc= 0.8695
Epoch 59020: Training cost= 0.2321, Training acc= 0.8698, Validation cost= 0.1986, Validation acc= 0.8695
Epoch 59030: Training cost= 0.1917, Training acc= 0.8698, Validation cost= 0.2162, Validation acc= 0.8695
Epoch 59040: Training cost= 0.2566, Training acc= 0.8698, Validation cost= 0.2190, Validation acc= 0.8695
Epoch 59050: Training cost= 0.3078, Training acc= 0.8698, Validation cost= 0.2724, Validation acc= 0.8695
Epoch 59060: Training cost= 0.2109, Training acc= 0.8698, Validation cost= 0.1729, Validation acc= 0.8695
Epoch 59070: Training cost= 0.2116, Training acc= 0.8698, Validation cost= 0.2635, Validation acc= 0.8695
Epoch 59080: Training cost= 0.2160, Training acc= 0.8699, Validation cost= 0.2601, Validation acc= 0.8695
Epoch 59090: Training cost= 0.2631, Training acc= 0.8699, Validation cost= 0.2457, Validation acc= 0.8695
Epoch 59100: Training cost= 0.1874, Training acc= 0.8699, Validation cost= 0.2980, Validation acc= 0.8695
tm  [-0.5 -0.3  5.4  0.1 -1.9 -0.  -0.3  0.  -1.1 -0.3  6.6 -0.  -0.1 -0.2  7.1 -1.5 -0.1 -0.5 -0.   1.9 -1.4 -0.2 -0.3 -0.2 -1.4  4.2  0.   0.4 -1.4 -4.7 -0.4 -0.2 -0.2  4.1 -0.3 -0.   1.5  3.4 -1.2 -0.1  0.7  1.6 -0.2 -0.5 -0.2 -0.1 -2.  -0.4 -1.4 -1.9  0.3 -0.1 -0.4 12.3  4.  -0.9 -1.1  9.5  7.9  4.1  9.2 -0.3  0.4  0.1 -0.1 -0.1  0.5 -0.2  0.6 -0.3 -0.1  8.4 -0.3 -0.1 -5.2  0.2 -0.   1.4 -0.  -0.6 -1.8 -0.3 -0.1 -0.6  0.   1.8 -2.6 -0.  -0.2 -0.3 -0.8 -0.2  0.2 -0.  -0.6 -0.5 -0.1 -4.2 -0.4 -0.4  1.3 -0.4 -0.2 -0.2 -0.5 -0.2 -2.4  0.1  0.7  2.7 -0.3  0.9  0.2 -0.4  5.5 -4.3  1.4 -0.5 -0.2 -0.1 -0.1 -1.1 -0.2 -0.3 -0.   8.6 -0.2 -2.2  9.8 12.5 -0.5  0.1 -0.6 -0.  -1.   0.5 -0.3 -0.1 -0.3 -0.3 -0.1 -0.5 -0.2 -0.2  0.2 -0.1 -0.1 -0.1  4.9 -0.2 -0.1 -0.1 -1.3  1.5 -0.1 -0.1 -0.2 -0.3  1.  -0.  -0.1 -1.3  0.7  0.1 -0.1 -0.6 -0.2 -0.6  0.  -0.3 -0.  -0.1 -0.3 -0.3 -0.1 -1.2 -0.3 -0.3  1.3 -0.  -1.4 -0.2 -0.1 -2.  -0.1 -0.3 -0.5 -0.5 -0.  12.9 -0.2 -0.2 -0.1 -0.9 -4.3 -3.2 -0.7 -1.9 -0.2 -0.1 -0.1  0.1 -0.   0.6  0.1 -3.3 -0.1 -0.1 -3.2  0.  -0.2 -2.9 -0.4  7.  -0.4  0.   1.7 -1.2 -0.4 -0.8 -0.1 -0.   1.2 -0.8 -0.9 -2.  -1.1 -0.5  2.1 -0.9 -0.3  0.6 -0.1 -0.5  3.  -0.9  0.4 -0.4  1.5 -5.4 -0.3 -2.3 -0.1 -0.2  6.6  3.6 -0.  -0.3 -1.3 -0.1  4.2 -0.1 -0.5 -0.   2.7 -2.8]
ty_50sample [[0 1 5 3 2 7 8 6 4 9]
 [8 6 5 3 9 1 2 7 4 0]
 [6 2 0 9 8 1 4 3 5 7]
 [7 8 3 1 5 4 0 9 6 2]
 [7 8 2 3 1 4 4 6 0 0]
 [0 2 3 4 9 5 8 7 1 6]
 [9 7 8 6 4 2 0 5 1 3]
 [0 3 2 6 4 7 5 9 9 8]
 [8 1 9 7 3 4 2 5 0 6]
 [1 9 7 3 4 8 6 0 5 5]]
tt_50sample [[0 1 5 3 2 7 8 6 4 9]
 [8 6 5 3 9 1 2 7 4 0]
 [6 2 0 9 8 1 4 3 5 7]
 [7 8 3 1 5 4 0 9 6 2]
 [7 8 2 3 1 4 5 6 9 0]
 [0 2 3 4 9 5 7 8 6 1]
 [9 7 8 6 4 2 0 5 1 3]
 [0 3 2 6 4 7 5 1 9 8]
 [8 1 9 7 3 4 2 5 0 6]
 [1 9 7 3 4 8 6 0 5 2]]
vm  [ 0.8 -0.5 -2.1 -6.5 -1.6 -0.2 -0.3  0.5 -0.2 -0.1  2.6 -0.6 -0.2 -0.4  9.4  3.5 -0.4 -0.5 -0.3 -0.4 -1.3 -0.1  0.9 -0.2 -1.1 -0.7 -0.1 -0.1 -0.1  2.3  0.1 -0.2 -0.6 -1.8 -0.1 -0.5 -0.   7.   3.8 -0.8  0.1  5.3 -0.1  4.6 -0.2  0.  -1.  -0.2  3.6  7.1  0.2 -0.2 -0.7 15.  -1.3 -1.4 -1.1 -0.1 -0.5 -0.7  0.4 -0.6 -0.4 -0.  -0.5 -0.2 -0.3  0.1  0.6 -0.3 -0.2 -1.7 -0.6 -0.9 -4.8 -0.6 -0.2  0.6 -0.1 -0.2 -6.4 -0.1 -0.2  1.1 -1.2  4.3  9.5 -0.2 -0.4 -0.1 -0.7 -0.2 -0.2 -0.1 -0.9  1.6 -0.5 -3.4 -0.2 -0.5 -0.1  2.8  0.1  0.3 -0.3 -0.4 -3.4 -0.4  0.7 -0.2  0.7  0.4 -0.1 -0.6 -1.3  7.8  0.7 -0.3 -0.5 -0.1 -0.2 -0.3 -0.4 -1.1 -0.2 12.2 -0.  -2.8  1.4  8.1 -0.1 -0.5 -0.2 -0.4 -4.4 -5.9 -0.7 -0.4 -0.3 -0.7 -0.6 -0.2 -0.3  0.2 -0.2 -0.3 -0.3 -0.2  5.1 -0.3  7.3 -0.2  2.6  0.2 -0.2  0.4 -0.1  1.6  0.2 -0.5 -0.1 -0.7 -0.3 -0.1 -0.6  0.1 -0.1 -0.1 -0.4 -0.1  0.3 -0.4  0.2  0.2 -0.  -0.9  0.6 -0.5 -0.9 -0.3 -2.5 -0.7 -0.3 -1.8 -0.1 -0.2 -0.2 -0.3 -0.4 -0.7  0.2 -0.2 -0.3 -0.9  3.9 -0.5 -0.4  4.3 -0.2  0.3 -0.2 -0.1 -0.6 -0.5  1.1 -3.9 -0.1 -0.3 -1.1  0.9 -0.9 -0.3 -0.4 -2.1 -0.5  1.1 -3.1 -0.9 -0.4 -0.5  0.4 -0.3 -0.5 -1.6 -1.1  4.6 -0.  -0.5 -0.5  0.6 -1.2  3.6 -0.1 -0.2 -1.1  2.4 -0.5 -0.7  1.7 -7.4 -0.  -3.1 -0.4  0.1 18.5  4.3  0.4 -0.7 -0.7 -0.5 16.2  0.1  2.1 -0.5 -0.7 -1.6]
vy_50sample [[4 5 8 2 7 3 9 0 6 1]
 [8 6 5 1 3 0 7 4 2 9]
 [4 3 9 7 5 6 0 1 2 8]
 [7 2 3 4 6 0 8 9 9 5]
 [9 3 4 1 8 6 5 7 0 2]
 [2 3 7 1 0 8 6 4 9 5]
 [5 3 0 1 7 2 8 4 6 9]
 [3 0 7 2 1 4 9 8 6 5]
 [5 9 3 8 4 1 6 0 0 7]
 [7 6 9 3 2 1 0 8 4 5]]
vt_50sample [[4 5 2 8 7 3 9 0 1 6]
 [8 6 5 1 3 0 7 4 2 9]
 [4 3 9 7 5 6 0 1 2 8]
 [7 2 3 6 4 0 8 1 9 5]
 [9 3 1 4 8 6 5 0 7 2]
 [2 3 7 1 0 8 6 4 9 5]
 [5 3 1 0 7 2 8 4 6 9]
 [3 0 7 2 1 9 4 8 6 5]
 [5 9 3 8 4 1 6 2 0 7]
 [7 6 9 3 2 1 0 8 4 5]]
Epoch 59110: Training cost= 0.2606, Training acc= 0.8699, Validation cost= 0.2692, Validation acc= 0.8695
Epoch 59120: Training cost= 0.1807, Training acc= 0.8699, Validation cost= 0.2216, Validation acc= 0.8695
Epoch 59130: Training cost= 0.1913, Training acc= 0.8699, Validation cost= 0.2497, Validation acc= 0.8695
Epoch 59140: Training cost= 0.2403, Training acc= 0.8699, Validation cost= 0.2161, Validation acc= 0.8696
Epoch 59150: Training cost= 0.2329, Training acc= 0.8699, Validation cost= 0.2200, Validation acc= 0.8696
Epoch 59160: Training cost= 0.2063, Training acc= 0.8699, Validation cost= 0.2054, Validation acc= 0.8696
Epoch 59170: Training cost= 0.2256, Training acc= 0.8699, Validation cost= 0.2201, Validation acc= 0.8696
Epoch 59180: Training cost= 0.2759, Training acc= 0.8699, Validation cost= 0.2489, Validation acc= 0.8696
Epoch 59190: Training cost= 0.2197, Training acc= 0.8699, Validation cost= 0.2704, Validation acc= 0.8696
Epoch 59200: Training cost= 0.2416, Training acc= 0.8699, Validation cost= 0.2632, Validation acc= 0.8696
tm  [ 0.4 -0.4  9.3  3.  -1.1  0.2 -0.5  0.2 -0.   0.5 -1.1 -0.3 -0.1 -0.3 11.4  2.4 -0.8 -0.  -0.6 -0.5 -1.4  0.2 -0.2 -0.2 -0.8 -0.4 -0.2 -0.5  0.8  3.3 -0.5 -0.4  0.6  7.7 -0.1 -0.1 -0.2 -0.7 -4.  -0.6  1.3 -3.6 -0.6 -0.6 -0.  -0.2 -0.2 -0.3  6.5 -0.9 -0.2 -0.  -0.4  2.4 -1.3 -1.4 -0.8 -2.4  1.4  5.3 -0.3 -0.2 -0.5  0.4 -0.1 -0.6 -0.1  0.5  1.1 -0.1  0.1 -1.2 -0.4 -0.4 -3.6 -1.  -0.2 -0.7 -0.1 -0.3 -2.2 -0.1 -0.2  1.3 -1.7 -3.6  4.6 -0.1 -0.2 -0.5 -0.1 -0.2 -0.3 -0.6 -0.2 -0.3 -1.2 -3.1 -0.2 -0.3 -0.5  3.  -0.7 -0.1 -0.2  0.  -1.9 -0.4 -0.2 -0.7 -0.4 -0.2 -0.1 -0.5 -0.1  8.3 -0.6  0.  -0.  -0.1 -0.1  0.6 -0.6 -0.8 -0.2 14.4 -0.3 -0.1 -0.1 10.5  0.5 -0.3 -0.   0.4 -0.3  9.  -0.4 -0.3 -0.4 -0.4 -0.6 -0.4 -0.4 -0.2 -0.3 -0.2 -0.3 -0.2 -3.3 -0.4 -0.7 -0.1  3.  -0.8 -0.1  0.3  0.  -0.5 -1.1 -0.6  1.2  0.5 -0.1 -0.1 -0.3 -0.4 -0.3 -0.3 -0.3 -0.1 -0.2 -0.1 -0.2 -0.2 -0.1  5.4 -1.5 -0.4  3.9 -0.3  2.6 -0.4 -0.4 -1.5 -0.1 -0.4  0.7 -0.4 -0.  -0.7 -0.1 -0.1 -0.3 -1.1  6.4  0.1 -0.4 -0.1 -0.1 -0.1 -0.2 -0.1 -0.1 -0.6 -0.4 -2.   0.1 -0.3 10.3 -0.4 -0.8  0.7 -1.1 -2.3 -1.   0.5  4.8 -1.1 -0.4  1.5  0.  -0.   0.1 -1.4  1.   3.5 -0.5  0.  -0.1  1.7 -0.4  1.6 -0.1  0.7 -1.2 -2.   1.  -0.5  3.1 10.4  0.3  2.  -0.3  0.   7.8  0.1 -0.   0.2 -1.4 -0.8  5.2 -0.1 -2.2  0.2  2.8 -2.1]
ty_50sample [[7 6 3 8 2 9 4 0 1 5]
 [8 8 0 7 1 4 9 5 2 6]
 [1 6 8 7 3 4 0 2 9 5]
 [7 3 6 2 1 4 8 5 0 9]
 [1 0 6 5 8 2 9 7 4 3]
 [4 3 5 9 0 8 7 2 6 1]
 [4 9 1 8 2 3 6 0 7 5]
 [9 6 1 3 8 5 4 7 0 2]
 [0 5 4 6 7 1 2 9 3 8]
 [0 0 9 2 4 1 6 3 5 8]]
tt_50sample [[7 6 3 8 2 9 4 0 1 5]
 [3 8 0 7 1 4 9 5 2 6]
 [1 6 8 7 3 4 0 2 9 5]
 [7 3 6 2 1 4 8 5 0 9]
 [1 0 6 5 8 2 9 7 4 3]
 [4 3 5 9 0 8 7 2 6 1]
 [4 9 1 8 2 3 6 0 7 5]
 [9 6 1 3 8 5 4 7 0 2]
 [0 5 4 6 7 1 2 9 3 8]
 [0 7 9 2 4 1 6 3 5 8]]
vm  [-0.8 -0.3 -1.4 -4.7 -2.3 -0.3 -0.3 -0.2 -0.4 -0.4 -4.2 -0.3  0.3 -0.3  8.1 -0.1 -0.2 -0.1 -0.7 -0.8 -1.9  0.1 -0.2 -0.1 -1.2 -0.3 -0.3 -0.7 -0.2 -0.1  1.3 -0.1  0.2  3.9  0.3 -0.   0.7  2.7 13.2 -0.6  2.9 -1.8  0.8  6.  -0.3 -0.2  0.4  0.1  0.8 -0.9 -0.3 -0.3 -0.8 -1.  -1.5 -1.1 -1.2 -2.6  0.4 -2.   2.  -0.3 -0.4 -0.1 -0.6 -0.5 -0.2 -0.1  0.6 -0.2 -0.1 -1.5 -0.2 -0.1 -3.5  0.1 -0.2  1.7 -0.2 -0.1 -2.4 -0.4 -0.3 -0.  -0.7 -1.7  6.1 -0.1 -0.3 -0.2 -0.6 -0.1 -0.1 -0.2 -0.6 -0.3 -0.1 -2.8 -0.7 -0.5  0.9 -0.  -0.1  0.1 -0.  -0.7 -2.1 -0.2 -1.  -1.  -0.3 -0.1 -0.1 -0.5 -0.3  8.3  0.8 -0.5 -0.1 -0.3 -0.1  2.  -0.3 -0.2 -0.1 10.2 -0.1  4.6  2.2  9.6 -0.7 -0.3 -0.3 -0.2 -6.7 -5.9 -0.3 -0.3 -0.6 -0.4 -0.  -0.  -0.  -0.2 -0.2 -0.1 -0.2 -0.1 -0.9 -0.2  5.   0.2  1.1 -0.3 -0.1  0.1 -0.4 -0.3  3.4 -0.4 -0.1 -1.6  0.2 -0.3 -0.5  0.  -0.3 -0.3 -0.3  0.1 -0.3 -0.2 -0.  -0.   0.   0.6  1.5 -0.5 -1.5 -0.2 -0.3 -0.3 -0.2 -1.5  0.1 -0.3 -0.1 -0.2 -0.2  0.2  0.4 -0.3 -0.2 -1.  -0.  -0.5 -0.1  1.7 -0.2  0.2 -0.2 -0.2  0.5 -0.5 -0.2 -2.  -0.2 -0.1  5.9  0.  -0.9  1.  -0.3  0.4 -0.2 -0.4 -4.1 -1.2 -0.3 -0.8  0.1 -0.  -0.7 -0.9 -3.   3.2 -1.6 -0.6  2.1 -0.3 -0.4  1.7 -0.4  0.1 -0.9  2.6 -0.3 -0.4  1.7  3.9 -0.  -0.1 -0.2 -0.2  8.4 -0.3 -0.4 -0.6 -1.   0.3  5.8 -0.3  7.5  0.   7.9 -1.8]
vy_50sample [[4 3 7 8 1 9 5 0 2 6]
 [3 7 0 6 9 8 5 2 1 4]
 [6 1 8 3 0 7 2 5 4 9]
 [8 2 9 4 3 6 5 1 7 0]
 [7 4 9 0 5 8 2 6 3 1]
 [3 9 4 7 1 8 2 5 0 6]
 [3 7 1 0 6 8 4 5 2 9]
 [3 5 4 6 1 9 8 7 2 0]
 [3 9 6 1 8 4 2 7 0 5]
 [5 5 7 6 9 3 8 1 0 4]]
vt_50sample [[4 3 7 8 1 9 5 0 2 6]
 [3 7 0 6 9 8 5 2 1 4]
 [6 1 8 0 3 7 5 2 4 9]
 [8 2 9 4 3 6 5 1 7 0]
 [7 4 9 0 5 8 2 6 3 1]
 [3 9 4 7 1 8 2 5 0 6]
 [3 7 1 0 6 8 4 5 2 9]
 [3 5 4 6 1 9 8 7 2 0]
 [3 6 9 1 8 4 2 7 0 5]
 [5 2 7 6 9 3 8 1 0 4]]
Epoch 59210: Training cost= 0.2215, Training acc= 0.8699, Validation cost= 0.1971, Validation acc= 0.8696
Epoch 59220: Training cost= 0.1926, Training acc= 0.8700, Validation cost= 0.2336, Validation acc= 0.8696
Epoch 59230: Training cost= 0.2094, Training acc= 0.8700, Validation cost= 0.2144, Validation acc= 0.8696
Epoch 59240: Training cost= 0.2185, Training acc= 0.8700, Validation cost= 0.2401, Validation acc= 0.8696
Epoch 59250: Training cost= 0.1811, Training acc= 0.8700, Validation cost= 0.2224, Validation acc= 0.8696
Epoch 59260: Training cost= 0.2348, Training acc= 0.8700, Validation cost= 0.2313, Validation acc= 0.8696
Epoch 59270: Training cost= 0.1957, Training acc= 0.8700, Validation cost= 0.2046, Validation acc= 0.8696
Epoch 59280: Training cost= 0.2240, Training acc= 0.8700, Validation cost= 0.2138, Validation acc= 0.8696
Epoch 59290: Training cost= 0.2366, Training acc= 0.8700, Validation cost= 0.2218, Validation acc= 0.8697
Epoch 59300: Training cost= 0.2468, Training acc= 0.8700, Validation cost= 0.2497, Validation acc= 0.8697
tm  [-0.1 -0.  -2.2 -2.6 -1.5 -0.4  0.6 -0.5 -0.5 -0.5 -0.8 -0.1 -0.1 -0.4  2.  -0.4 -0.1  0.2 -0.9 -1.3 -1.9 -0.2 -0.4 -0.1 -1.  -0.3  0.5 -0.2 -0.6  1.8  0.  -0.2 -0.2  8.7 -0.1  0.9  1.2 -2.3 -3.8 -0.7 -0.5 -3.2 -0.2 -0.5 -0.4 -0.3  2.3 -0.1  1.  -2.9 -0.5 -0.1 -0.5 -2.3 -0.6 -0.5  0.1 -3.5  4.4 -3.8  3.6 -0.4 -0.  -0.6  0.2 -0.7 -0.1 -0.2 -0.5  0.4  0.3  1.7 -0.6  0.  -2.1 -0.1 -0.  -0.1 -0.1 -0.1 11.7  1.1 -0.2 -0.3 -0.1 -2.3  5.8  0.3 -0.2 -0.  -0.4 -0.1 -0.5 -0.3 -0.7 -0.3  0.3 -2.7 -0.2 -0.   2.3 -0.8 -0.1 -0.4  0.6 -0.8 -1.9 -0.5 -0.3 -1.6 -0.5 -0.4 -0.3 -0.3  3.8 -0.5 -1.2 -0.3 -0.5 -0.6 -0.2  5.2 -0.2 -0.1  0.1  2.2 -0.3  7.6  1.7  6.9  1.4 -0.  -0.  -0.7 12.2 21.  -0.4  0.7 -0.1 -0.5 -0.4 -0.7 -0.5  0.1 -0.1 -0.5 -0.1 -0.2 -0.9 -0.1  1.9  0.  -0.9 -0.9 -0.1 -0.4 -0.8 -0.4 -1.9 -0.6  0.7  2.  -0.2 -0.2  2.   2.3 -0.4 -0.3 -0.1  0.1 -0.1 -0.  -0.3 -0.4 -0.3  2.9 -0.7 -0.6  2.3 -0.2  0.3 -0.1 -0.4 -1.4  0.2 -0.4  0.  -0.8 -0.5 -0.5 -0.1 -0.3 -0.1 -1.2 -1.1 -0.7 -0.5 -1.4 -0.7 -0.2 -0.2 -0.1 -0.1 -0.5 -0.4 -2.8 -0.  -0.   4.6  0.3 -1.  -1.1 -0.6  0.1 -0.6  0.1  0.9 -1.1 -0.3 -0.6 -0.1  0.7 -0.3 -1.3  2.1 -0.8 -1.4  0.6 -0.4  1.5 -0.   0.6 -0.4  1.  -0.   3.8 -0.1 -0.6  3.  16.7 -0.2  4.7 -0.   0.  -2.   0.5 -0.3 -0.5 -1.1 -0.4 -3.3 -0.1 -1.9 -0.   5.9 -1.1]
ty_50sample [[6 4 3 0 1 7 9 8 2 5]
 [3 0 1 7 8 4 2 5 9 6]
 [4 3 8 0 9 2 7 6 5 1]
 [1 6 5 8 2 7 0 3 9 4]
 [6 4 0 2 7 9 8 5 1 3]
 [6 2 5 8 3 1 9 0 4 7]
 [5 2 1 0 4 6 9 7 3 8]
 [2 0 6 6 4 8 7 3 9 1]
 [3 2 1 4 0 7 5 8 6 9]
 [7 2 9 8 5 4 0 3 6 1]]
tt_50sample [[6 4 3 0 1 7 9 8 2 5]
 [3 0 1 7 8 4 2 5 9 6]
 [4 3 8 0 9 2 7 6 5 1]
 [1 6 5 8 2 7 0 9 3 4]
 [6 4 0 2 7 9 8 5 1 3]
 [6 2 5 8 3 1 9 0 4 7]
 [5 2 1 0 4 6 9 7 3 8]
 [2 0 5 6 4 8 3 7 9 1]
 [3 2 1 4 0 7 5 8 6 9]
 [7 2 9 8 5 4 0 3 6 1]]
vm  [-1.  -0.3 -1.6 -5.  -2.  -0.2 -0.1 -0.3 -0.1 -0.8 -2.4 -0.2 -0.  -0.4  6.9 -0.3  0.2 -0.4 -0.5 -0.6 -1.9  0.1 -0.2 -0.1 -1.3  0.5 -0.1 -0.2  0.9 -0.2  1.3 -0.4  1.1  5.9 -0.2  0.   1.5 -1.1 -2.  -0.5  2.7 -2.1 -0.1  2.8 -0.2 -0.6 -0.6 -0.3 -2.6 -1.7 -0.3 -0.3 -0.2 -0.6 -1.9 -0.9 -1.  -2.4  1.2 -2.5  8.6 -0.3 -0.2 -0.3  0.2 -0.4 -0.1 -0.1  0.9 -0.1 -0.1 -1.8 -0.2 -0.6 -4.1  1.3 -0.   2.3 -0.1 -0.4 -0.8 -0.1 -0.3 -0.4  2.2 -1.5 -0.6 -0.  -0.2 -0.  -0.8 -0.2 -0.1  0.2 -1.2 -0.2  0.  -3.  -0.5 -0.1  2.3 -0.2 -0.1  0.3 -0.3  0.6 -3.  -0.1 -0.6 -0.4 -0.3 -0.1 -0.1 -0.5 -0.1  9.9  1.6 -0.7 -0.4  0.1 -0.2  0.1 -0.4 -0.4 -0.1  9.  -0.1  3.6  0.6 11.  -0.1 -0.2 -0.4 -0.1 -0.5  5.9 -0.2 -0.1 -0.4 -0.4  0.1 -0.1  0.7 -0.2 -0.  -0.   0.  -0.  -0.8 -0.2  6.  -0.1 -1.4  0.6 -0.2  0.1 -0.6 -0.2 -0.3 -0.7  0.6 -0.7  0.9 -0.1  0.8 -0.4 -0.3 -0.4 -0.1 -0.1 -0.3 -0.2 -0.2 -0.2  0.1  1.3 -1.4 -0.1  2.2 -0.1 -0.   0.4 -0.  -2.5 -0.3 -0.4 -0.3 -0.6 -0.1  0.3 -0.1 -0.1 -0.1 -1.4 -3.8 -0.5 -0.5 -0.  -0.2 -0.1 -0.3 -0.3 -0.  -0.5  0.4 -2.6 -0.2  0.5  5.4 -0.1 -0.5  1.3  0.7 10.4 -0.2  0.2 -1.8 -1.  -0.2 -0.5 -0.2 -0.1 -0.4 -1.1 -0.8  3.7 -2.1 -0.9  0.4 -0.9 -0.7  3.4 -0.2  1.  -0.7  3.3 -0.3 -0.8  0.3  4.6 -0.1  0.5 -0.2 -0.2  4.1  0.2 -0.3 -0.5 -1.3 -0.1  1.2 -0.2 -1.   0.1  7.2 -2.3]
vy_50sample [[1 4 3 7 6 8 9 5 0 2]
 [1 7 9 8 3 2 5 4 0 6]
 [8 9 1 6 2 5 0 3 4 7]
 [1 8 5 4 6 3 7 7 2 9]
 [1 5 4 6 2 7 8 0 3 9]
 [5 7 4 4 2 3 8 1 6 9]
 [7 9 2 0 4 8 5 6 3 1]
 [3 5 2 0 4 1 9 8 6 7]
 [7 9 2 3 8 5 1 6 0 4]
 [2 8 1 5 4 3 9 7 7 6]]
vt_50sample [[1 4 3 7 6 8 9 5 0 2]
 [1 7 9 8 3 2 5 4 0 6]
 [8 9 1 2 6 5 0 3 4 7]
 [1 8 5 4 6 3 7 2 0 9]
 [1 5 4 6 2 7 8 0 9 3]
 [5 4 7 0 2 3 8 1 6 9]
 [7 9 2 0 4 8 5 6 3 1]
 [3 5 2 0 4 1 9 8 6 7]
 [7 9 2 3 8 5 1 6 0 4]
 [2 8 1 5 4 3 9 0 7 6]]
Epoch 59310: Training cost= 0.2312, Training acc= 0.8700, Validation cost= 0.2408, Validation acc= 0.8697
Epoch 59320: Training cost= 0.2413, Training acc= 0.8700, Validation cost= 0.2841, Validation acc= 0.8697
Epoch 59330: Training cost= 0.2201, Training acc= 0.8700, Validation cost= 0.2326, Validation acc= 0.8697
Epoch 59340: Training cost= 0.2323, Training acc= 0.8700, Validation cost= 0.2537, Validation acc= 0.8697
Epoch 59350: Training cost= 0.2689, Training acc= 0.8701, Validation cost= 0.3150, Validation acc= 0.8697
Epoch 59360: Training cost= 0.2507, Training acc= 0.8701, Validation cost= 0.2651, Validation acc= 0.8697
Epoch 59370: Training cost= 0.2248, Training acc= 0.8701, Validation cost= 0.2309, Validation acc= 0.8697
Epoch 59380: Training cost= 0.2552, Training acc= 0.8701, Validation cost= 0.2533, Validation acc= 0.8697
Epoch 59390: Training cost= 0.2381, Training acc= 0.8701, Validation cost= 0.2021, Validation acc= 0.8697
Epoch 59400: Training cost= 0.2451, Training acc= 0.8701, Validation cost= 0.2788, Validation acc= 0.8697
tm  [-0.6  0.1 -1.  -1.7 -2.  -0.3 -0.5 -0.2 -0.9  0.6 -8.3 -0.5  0.5 -0.1  3.5 -0.7  0.5  0.  -0.8 -2.  -1.6 -0.5  1.4 -0.  -0.9 -0.7 -0.5 -0.4 -0.9  3.2 -0.1  0.4  1.6 -1.7 -0.4 -0.   2.4  3.1 21.  -0.5  4.  -2.1  0.7  5.9 -0.3 -0.3  8.5 -0.3 -0.7  6.1 -0.1 -0.4 -1.2 -3.4 -1.2 -0.6 -0.8 -2.8 -2.7  3.2 -1.2 -0.5 -0.1 -0.3 -0.2 -0.2 -0.3 -0.6 -0.5 -0.1 -0.3 -0.3 -0.3 -0.6 -1.4  2.6 -0.3  2.  -0.1  1.2 -2.9 -0.4 -0.2 -0.3 -0.8 -2.   5.8  0.1 -0.2  0.8 -1.  -0.1 -0.3  4.1 -0.4 -0.2  1.1 -1.4 -0.6 -0.6  0.5  0.7  0.2 -0.  -0.3 -0.9 -1.7 -0.5 -2.2 -1.3  1.3 -0.1 -0.2 -0.3 -0.5 -1.2  0.7 -0.7 -0.1 -0.7 -0.6  4.2 -0.2 -1.2 -0.1  4.2  0.2 10.7 -2.9  3.2 -0.9  0.2 -0.3 -0.2 -6.7 -9.  -0.4 -0.1  0.1  0.6 -0.5 -0.2 -0.7 -0.1 -0.1 -0.3 -0.  -0.1 -0.9 -0.3  1.6 -0.1  1.  -0.6 -0.2 -0.3 -0.7  1.1  2.6 -0.7  1.8 -1.5 -0.2 -0.  -0.1  1.6 -0.3 -0.3 -0.4 -0.1 -0.2  0.7  0.  -0.5 -0.1  0.2  0.4 -0.1 -2.2 -0.2 -0.2 -0.6 -0.3 -0.8 -0.  -0.8 -0.4 -0.8 -0.4 -0.7  0.2 -0.5 -0.3 -0.4 10.4 12.1 -0.3  1.1 -0.4 -0.  -0.4 -0.1  0.4 -0.6 -0.  -0.8 -0.2 -0.1 13.6 -0.1 -1.3 -0.9 -0.1 -0.1 -0.1 -0.2 -3.8 -0.5 -0.3 -0.9 -0.3 -0.1  1.3 -0.8 -3.  -0.1 -1.3 -0.1 -0.3 -1.  -0.4  1.8 -0.5 -0.2 -1.   2.8 -0.2 -0.6 -0.4 18.6 -0.1  5.1 -0.  -0.3  9.6 -1.5 -0.7 -1.  -1.  -0.4  6.5 -0.5 12.  -0.3  6.6 -0.2]
ty_50sample [[8 4 3 7 0 9 1 5 2 6]
 [0 3 4 2 8 7 9 1 6 5]
 [1 0 5 7 2 3 4 6 9 8]
 [2 6 5 9 1 7 3 0 4 8]
 [3 9 5 8 2 7 6 4 0 1]
 [8 5 1 2 0 4 7 9 6 3]
 [5 9 2 0 6 1 7 3 4 8]
 [7 3 3 5 1 4 9 0 6 2]
 [9 6 7 0 1 2 8 8 4 5]
 [9 9 6 3 2 4 5 7 0 8]]
tt_50sample [[8 4 3 7 0 9 1 5 2 6]
 [0 3 4 2 8 7 9 6 1 5]
 [1 0 5 7 2 3 4 6 9 8]
 [2 6 5 1 9 7 3 0 4 8]
 [3 9 5 8 2 7 6 4 0 1]
 [8 5 2 1 0 4 7 9 6 3]
 [5 9 2 0 6 1 7 3 4 8]
 [7 3 5 8 1 4 9 0 6 2]
 [9 6 0 7 1 2 3 8 4 5]
 [9 1 6 3 2 4 5 7 0 8]]
vm  [-0.7 -0.2 -2.3  7.7 -1.6 -0.1 -0.3 -0.2  0.4 -0.4 -0.8  0.1 -0.1 -0.3 -3.4 -0.1 -0.3 -0.2 -0.1 -1.2 -1.5  0.1 -0.7 -0.2 -0.6 -0.  -0.1  0.6 -0.1 -2.3  1.3 -0.3 -0.   4.1 -0.2  0.2  0.2 -1.1 13.1  0.3  0.  -1.9 -0.7  0.8 -0.1 -0.2  8.4  0.2 -1.7 -3.3 -0.1 -0.2  0.1 -5.  -1.6  4.  -0.3 -0.9  4.1 -2.9  1.1 -0.9 -0.6 -0.2  2.4 -0.5  0.2 -0.2  2.2 -0.2 -0.  -1.5 -0.3 -0.4  1.   0.1 -0.1 -0.3 -0.  -0.4 25.9 -0.4  0.3 -0.2  1.1 -1.4 -1.   0.2 -0.2 -0.3 -0.  -0.2  0.2 -0.5 -1.2 -0.2 -0.5 -1.3 -0.3 -0.1  2.8 -1.4  0.7 -0.  -0.4  0.7 -0.5  0.1 -0.2 -1.7  0.6 -0.  -0.1 -0.5  0.3 10.3  0.5 -0.1 -0.1  0.3 -0.3  6.4 -0.  -0.1 -0.3 -4.3 -0.1 15.3  5.6 -0.7  0.5 -0.1  0.2 -0.5  6.7  9.7 -0.2 -0.1  0.7 -0.6 -0.   0.1  0.6 -0.3 -0.1  0.3 -0.  -0.1  2.7  0.2 -0.9 -0.1 -1.6  0.8 -0.2 -0.1  0.2 -0.1 -0.4  0.2 -0.2 -0.4 -0.2 -0.1 -0.  -0.1  0.2 -0.1 -0.2 -0.3  0.   0.1 -0.4 -0.4 -0.1 -0.1 -0.6 -0.3 -1.2 -0.1 -0.6 -0.3 -0.2 -2.1 -0.3 -0.4 -0.4 -0.4 -0.2  6.7 -0.2  0.9 -0.1 -1.5  1.9 -2.  -0.1 -0.1 -0.4 -0.2 -0.2 -0.   0.3 -0.1 -0.1  2.4 -0.1 -0.2 -1.9 -0.1 -0.6  1.8 -0.3  7.3  0.5  0.1 -0.8 -1.3 -0.   0.8 -0.2 -0.1 -0.5 -1.1 -0.8  1.8 -2.3 -0.1  2.5 -0.5 -0.8 -0.8 -0.2 -0.2 -0.7  3.2 -0.4 -0.1  2.5 16.1 -0.1  3.8  0.3 -0.3 -5.2 -2.2 -0.4 -0.2 -1.5 -0.1 -6.6 -0.2  7.  -0.3  9.1  3.7]
vy_50sample [[9 1 3 4 6 5 7 8 8 2]
 [4 3 7 1 2 5 8 8 0 9]
 [6 3 7 8 9 9 4 2 5 1]
 [3 2 4 1 9 5 0 6 7 8]
 [3 0 6 4 1 7 2 9 5 8]
 [3 1 9 2 5 8 4 7 6 0]
 [5 1 0 6 8 4 3 2 9 7]
 [0 8 2 5 6 3 4 7 9 1]
 [1 3 8 2 4 4 5 6 7 0]
 [5 1 8 6 7 3 4 0 2 9]]
vt_50sample [[9 1 3 4 6 5 7 0 8 2]
 [4 3 7 1 2 5 8 6 0 9]
 [6 3 7 8 0 9 4 2 5 1]
 [3 2 4 1 9 5 0 6 7 8]
 [0 3 6 4 1 7 9 2 5 8]
 [3 1 9 2 5 8 4 7 6 0]
 [5 1 0 6 4 8 3 2 9 7]
 [0 8 2 5 6 3 4 7 9 1]
 [1 3 8 2 4 9 5 6 7 0]
 [5 1 8 6 7 3 4 0 2 9]]
Epoch 59410: Training cost= 0.2567, Training acc= 0.8701, Validation cost= 0.2220, Validation acc= 0.8697
Epoch 59420: Training cost= 0.2071, Training acc= 0.8701, Validation cost= 0.2357, Validation acc= 0.8697
Epoch 59430: Training cost= 0.2322, Training acc= 0.8701, Validation cost= 0.2470, Validation acc= 0.8697
Epoch 59440: Training cost= 0.2432, Training acc= 0.8701, Validation cost= 0.2201, Validation acc= 0.8697
Epoch 59450: Training cost= 0.2239, Training acc= 0.8701, Validation cost= 0.1906, Validation acc= 0.8698
Epoch 59460: Training cost= 0.1858, Training acc= 0.8701, Validation cost= 0.1927, Validation acc= 0.8698
Epoch 59470: Training cost= 0.2368, Training acc= 0.8701, Validation cost= 0.2386, Validation acc= 0.8698
Epoch 59480: Training cost= 0.2839, Training acc= 0.8701, Validation cost= 0.2030, Validation acc= 0.8698
Epoch 59490: Training cost= 0.2146, Training acc= 0.8702, Validation cost= 0.2034, Validation acc= 0.8698
Epoch 59500: Training cost= 0.2257, Training acc= 0.8702, Validation cost= 0.2652, Validation acc= 0.8698
tm  [-0.5 -0.1 10.4  7.4 -1.5 -0.1  0.8 -0.2 -1.5  0.6 -2.4 -0.3 -0.1 -0.3 10.6 -1.7 -0.3 -0.7 -1.7  1.  -1.6 -0.   2.4 -0.5 -0.7  0.1  0.7 -0.2 -1.5 -0.8 -1.2 -0.1 -0.5 -2.   0.5 -0.2  1.2 -0.6 -5.1 -0.1  2.9 -2.8 -0.1 -0.6 -0.4 -0.5 -1.3 -0.6  1.9  4.7 -0.1 -0.3 -0.6 10.3  3.4 -1.5 -0.5  1.3  0.4 11.2  3.1  0.5 -0.5 -0.1 -0.8  0.5 -0.2 -0.3  2.8  0.3 -0.3  7.9 -0.8 -1.  -4.2 -0.7 -0.   1.9 -0.1  0.5 -7.   0.9 -0.4  1.7 -0.7 -3.1 -0.9 -0.2  0.3 -0.4  0.1 -0.  -0.3 -0.  -0.5 -0.5 -0.  -3.8  0.5 -0.3 -0.4 -0.1 -0.2 -0.5  0.2  0.4 -2.5 -0.3 -0.4 -0.6 -0.2 -0.2 -0.2 -0.6  5.  -5.1 -1.   1.  -0.2 -0.3  0.9  0.5 -0.2 -0.9 -0.3 13.7 -0.1 -1.8 -0.7 14.   0.5 -0.3 -0.4 -0.2  5.7 -0.4 -0.2  0.6 -0.3 -0.2 -0.4 -0.6 -0.  -0.1 -0.1 -0.4 -0.4  0.5 -1.5 -0.3 -1.4 -0.   2.6  1.3 -0.2 -0.4 -0.   2.  -1.2 -0.6 -0.3  1.   0.  -0.2 -0.3  1.2 -0.3 -0.7 -0.1 -0.1 -0.1 -0.1 -0.3 -0.1 -0.3  1.9 -0.2 -0.6  4.7 -0.   1.5 -0.2 -0.3 -1.6 -0.1 -0.5 -0.5 -0.4 -0.1  2.  -0.2 -0.2 -0.2 -0.6 -0.9  2.8 -1.1 -1.8  0.3  0.1  0.6 -0.1 -0.2 -0.1 -0.4 -3.6 -0.1 -0.4 13.7 -0.1 -0.9 -3.2 -0.7 -0.5 -0.9 -0.5  8.7 -1.3 -0.5 -0.6 -0.3 -0.2 -1.  -1.3  1.5 -1.5 -1.  -0.6 -0.3  0.6 -0.4  1.5 -0.3 -0.2  2.6 -1.9  0.9 -0.6  4.1  3.4 -0.2 -0.1 -0.2  0.9 20.1  5.1 -0.4 -0.2 -1.3 -0.3 18.5 -0.1 -2.6  0.2  3.6 -3. ]
ty_50sample [[0 8 6 3 7 2 1 9 5 4]
 [3 4 6 8 5 2 7 9 0 1]
 [7 0 5 9 6 4 1 2 8 3]
 [3 7 9 9 6 4 0 8 2 1]
 [2 1 7 9 8 3 6 5 4 0]
 [0 6 8 7 4 2 3 1 9 5]
 [7 2 3 6 9 0 1 8 5 4]
 [9 5 0 7 6 4 1 3 8 2]
 [0 0 8 6 3 7 1 5 9 2]
 [2 8 9 5 1 7 4 6 3 0]]
tt_50sample [[0 8 6 3 7 2 1 9 5 4]
 [3 4 8 6 5 7 2 9 0 1]
 [7 0 5 9 6 4 1 2 8 3]
 [3 7 9 5 6 4 0 8 2 1]
 [2 1 7 9 8 3 6 5 4 0]
 [0 6 8 7 4 2 3 1 5 9]
 [7 2 3 6 9 0 1 8 5 4]
 [9 5 0 7 6 4 1 3 8 2]
 [0 4 8 6 3 7 1 5 9 2]
 [2 8 9 5 1 7 4 6 3 0]]
vm  [-0.8  0.   3.9 -2.9 -1.9 -0.2 -0.1 -0.2  0.6 -1.1 -1.7 -0.3 -0.  -0.4 11.1  1.9 -0.1 -0.7  1.1  3.3 -1.5  0.2  0.3 -0.1 -1.7  3.4 -0.4  0.4  0.4 -0.1  1.1 -0.5 -0.7  2.7 -0.3 -0.1 -0.2 -0.9 -4.6 -0.1 -0.6  3.  -0.  -0.6 -0.1  0.  -2.4  0.3 -0.8  6.8 -0.3 -0.1  0.   6.7 -0.8 -1.3 -0.8  3.9  4.3  3.2  8.1 -0.2 -0.4 -0.1 -0.1  0.4  0.8 -0.1  2.4 -0.  -0.1 -1.2 -0.3 -0.2 -3.6  1.5 -0.   0.9  0.2 -0.1 -4.7 -0.2  0.2  2.   2.3  6.3 -1.5 -0.1  0.3  0.  -0.4 -0.1  0.2 -1.2 -1.   0.2  0.4 -4.3 -0.4  0.2  3.9  5.2 -0.3 -0.1 -0.3  0.8 -1.8 -0.4 -0.5  3.6 -0.3 -0.1 -0.1 -0.6  0.9 12.6 -0.4 -0.6 -0.2 -0.1 -0.2 -1.2  1.2  0.9 -0.1 14.1  0.3 -0.8  4.2  6.7  0.2 -0.2 -0.3 -1.   3.1  5.1  0.2  0.2 -0.1 -0.5  1.8 -0.2  0.9 -0.2 -0.2  0.8  0.6 -0.1 -0.2 -0.3  3.4 -0.1 -0.1  1.  -0.1  0.  -0.6 -0.3 -0.5 -0.4  0.8  2.7  0.4 -0.   0.9 -1.2 -0.3  0.1  0.1 -0.1 -0.1  0.3 -0.2 -0.1 -0.1  0.6 -0.3 -0.3  4.2 -0.1 -0.9 -0.4 -0.3 -3.1 -0.2  1.1 -0.4 -0.4  0.4  0.7 -0.1  0.2 -0.1 -1.  -3.7 -1.5 -0.3 -0.2  0.3 -0.   0.3 -0.1 -0.1 -0.3  0.7 -3.1  0.2  0.1  0.2 -0.1 -0.5  1.9 -0.5 10.5 -1.3  0.1  3.5 -1.2  0.2 -0.2 -0.2 -0.2  0.3 -1.2  5.5  3.4 -1.   0.6  2.2  0.5 -0.4 -0.7 -0.3 -0.2  0.3 -0.8 -0.1 -0.1  5.4 -4.7 -0.1 -2.  -0.  -0.1 14.2  2.8  0.3 -0.1 -1.6 -0.7 11.9 -0.2 -2.4 -0.3  1.  -1.1]
vy_50sample [[1 6 7 5 8 4 2 3 0 9]
 [1 4 8 6 0 7 5 3 9 2]
 [1 7 6 2 2 0 5 9 4 3]
 [0 6 1 8 4 5 7 2 9 3]
 [4 2 0 8 5 9 6 1 3 7]
 [3 8 2 6 5 9 4 0 1 7]
 [2 3 4 1 6 9 5 8 0 7]
 [2 1 8 7 6 4 0 3 5 9]
 [3 4 5 2 8 1 9 7 0 6]
 [0 6 1 4 8 7 9 3 5 2]]
vt_50sample [[1 6 7 5 8 4 2 3 0 9]
 [1 4 8 6 0 7 5 3 9 2]
 [1 7 6 2 8 0 5 9 4 3]
 [0 6 1 8 4 5 7 2 9 3]
 [4 2 8 0 5 9 6 1 3 7]
 [3 8 2 6 9 5 4 0 1 7]
 [2 3 4 1 6 9 5 8 0 7]
 [1 2 8 6 7 4 0 3 5 9]
 [3 4 5 2 8 1 9 7 0 6]
 [0 6 1 4 8 7 9 3 5 2]]
Epoch 59510: Training cost= 0.2313, Training acc= 0.8702, Validation cost= 0.2367, Validation acc= 0.8698
Epoch 59520: Training cost= 0.2418, Training acc= 0.8702, Validation cost= 0.2252, Validation acc= 0.8698
Epoch 59530: Training cost= 0.1992, Training acc= 0.8702, Validation cost= 0.2509, Validation acc= 0.8698
Epoch 59540: Training cost= 0.2372, Training acc= 0.8702, Validation cost= 0.1920, Validation acc= 0.8698
Epoch 59550: Training cost= 0.2261, Training acc= 0.8702, Validation cost= 0.2357, Validation acc= 0.8698
Epoch 59560: Training cost= 0.2126, Training acc= 0.8702, Validation cost= 0.2871, Validation acc= 0.8698
Epoch 59570: Training cost= 0.2087, Training acc= 0.8702, Validation cost= 0.2310, Validation acc= 0.8698
Epoch 59580: Training cost= 0.2642, Training acc= 0.8702, Validation cost= 0.2038, Validation acc= 0.8698
Epoch 59590: Training cost= 0.2010, Training acc= 0.8702, Validation cost= 0.2178, Validation acc= 0.8698
Epoch 59600: Training cost= 0.1822, Training acc= 0.8702, Validation cost= 0.2241, Validation acc= 0.8699
tm  [-0.4 -0.1 -4.3 -0.9 -1.3 -0.4 -0.3 -0.3 -0.8 -0.8 -0.1 -0.2 -0.4  0.3 -2.8  1.2 -0.5 -0.2 -0.3 -0.7 -1.4 -0.5 -0.2 -0.2 -1.  -0.2 -0.3 -0.5 -0.6 -1.9  0.8 -0.1 -0.6 -5.7 -0.2 -0.3  2.1  6.1 20.5 -0.9  0.6  1.6  0.9  2.9 -0.2 -0.   3.9 -0.2  2.1 -0.9 -0.3 -0.3 -0.4  0.5 -1.2  3.1 -0.9  4.8 -1.  -0.4 -1.2 -0.4 -0.4 -0.2 -1.1 -0.2 -0.5 -0.1  0.2 -0.2 -0.  -0.8 -0.1 -0.2 -1.5  0.6 -0.3  0.4 -0.3 -0.4 -0.3 -0.2 -0.3  0.4 -1.2  1.9  4.5  0.4 -0.2 -0.1 -0.8 -0.2 -0.1  1.4 -0.6  1.   1.3 -1.7 -0.5 -0.6  2.9 -1.6 -0.1 -0.2 -0.3 -0.6 -1.9 -0.3  0.1 -1.7 -0.3 -0.  -0.1 -0.5 -1.3  4.4  2.6 -0.8 -0.  -0.2 -0.3  5.4 -0.6 -1.2 -0.3 -3.5  1.1  1.5  0.6  6.3 -0.5 -0.4 -0.2 -0.6 -1.4 -6.1 -0.4 -0.1 -0.2 -0.3 -0.4  0.2 -0.7 -0.2 -0.2 -0.4 -0.6 -0.2  9.5 -0.3  0.8 -0.2  2.4 -0.2 -0.3 -0.1 -0.3 -0.7  1.7 -0.8  0.9 -1.2 -0.2 -0.2 -0.2  0.  -0.4 -0.4 -0.2 -0.   0.4 -0.3 -0.1  0.1 -0.  -1.9  2.3 -0.  -2.  -0.2 -2.2  0.  -0.3 -1.2 -0.2  0.5 -0.   0.2 -0.1  5.4 -0.3 -0.4 -0.3 -1.3 10.6 -0.1  0.2  4.8 -0.2 -0.2 -0.2 -0.  -0.5 -0.3 -0.2 -1.4 -0.3 -0.1 -1.8 -0.  -0.8 -0.3 -0.2 -0.4  0.3 -0.  -2.7 -1.1 -0.4 -0.4 -0.1 -0.2 -0.4 -1.  -2.7  3.7 -0.6 -0.4 -0.3 -0.2 -1.   0.5 -0.3 -0.6 -0.4  4.2 -0.2 -0.2  0.3 -2.  -0.2 -1.2 -0.3 -0.2  3.3 -0.9  0.6 -0.3 -1.3 -0.6 -0.1 -0.1 11.3 -0.4  3.2 -1. ]
ty_50sample [[5 3 4 8 2 9 0 1 7 6]
 [7 2 0 4 8 9 6 1 5 3]
 [1 4 3 2 6 9 0 8 5 7]
 [2 8 3 5 6 6 4 7 1 0]
 [4 1 7 8 0 3 9 2 6 5]
 [9 5 1 3 6 0 7 2 8 4]
 [6 4 8 3 9 0 2 2 7 5]
 [3 0 4 2 8 5 9 6 7 7]
 [8 0 5 1 2 7 9 6 4 3]
 [0 7 1 3 4 6 9 8 5 2]]
tt_50sample [[5 3 4 8 9 2 0 1 7 6]
 [7 2 0 4 8 9 6 1 5 3]
 [1 4 3 2 6 9 0 8 5 7]
 [2 3 8 5 6 9 4 7 1 0]
 [4 1 7 8 0 9 3 2 6 5]
 [9 5 1 3 6 0 7 2 8 4]
 [6 4 8 3 9 0 2 1 5 7]
 [3 0 4 2 8 5 9 6 1 7]
 [8 0 5 1 2 7 9 6 4 3]
 [0 7 1 3 4 6 9 8 5 2]]
vm  [-0.1 -0.1  3.3  0.6 -1.7 -0.  -0.2  0.4 -0.9 -0.8  4.9 -0.2 -0.2 -0.3  5.   3.4 -0.3  1.1 -0.2 -0.1 -1.8 -0.1  0.8 -0.  -1.3  1.8 -0.2 -0.4 -1.   2.2 -0.4 -0.1  0.1 -0.1 -0.2  0.1  3.3  8.1  7.1 -0.9  3.7 -1.7  2.1  3.  -0.1  0.1  0.3 -0.3  2.9  7.6 -0.3 -0.1 -0.1  8.5 -0.8 -0.7 -0.5 -2.5 -2.1  3.9 -0.  -0.3 -0.2 -0.1 -0.9 -0.6  0.2 -0.1 -0.2 -0.2 -0.1  2.4  1.9  0.4 -1.1 -0.5 -0.1 -1.  -0.  -0.1 -2.1 -0.2 -0.1  0.  -1.2 -1.3  3.8 -0.2 -0.1 -0.1 -0.  -0.2 -0.2 -0.1 -0.3 -0.3 -0.8 -2.1 -0.2 -0.1  3.   4.  -0.4 -0.1 -0.2 -0.5 -1.2 -0.4  1.3 -0.5 -0.9 -0.2 -0.1 -0.  -1.  -0.3 -0.  -1.5  0.3 -0.1 -0.1  1.5 -0.2 -0.8 -0.2  6.4  0.1 -1.3 -2.5 -0.1 -0.5 -0.1  0.1 -0.3 -3.5 -3.8 -0.3 -0.2 -0.2 -0.2 -0.5 -0.4 -0.7 -0.  -0.3  0.  -0.2 -0.3 -2.  -0.  -0.4 -0.   3.  -0.7 -0.2  0.3  0.   0.9  1.  -0.3  0.6 -0.7 -0.2 -0.  -0.3 -0.7 -0.3 -0.2 -0.  -0.  -0.  -0.3 -0.2 -0.1 -0.1  2.2 -0.3 -0.  -0.7  0.5  0.8 -0.6 -0.3 -1.9 -0.1 -0.6  1.  -0.2 -0.4 -0.6  0.2 -0.3 -0.3 -0.6  4.4 10.  -0.1  2.3  0.4 -0.2 -0.2  0.1 -0.5 -0.1  0.  -1.3 -0.1  0.3 10.5 -0.1 -0.3 -0.7 -0.9  0.1 -1.  -0.1 -1.5 -0.8 -0.3  1.5  0.1  0.1 -0.  -1.3 -0.7  1.   2.7  0.1  0.3 -0.3 -0.2 -0.4 -0.   1.2 -0.1 -0.5  0.5 -0.3  1.9 11.9 -0.   2.2 -0.1 -0.4  7.1 -1.  -0.5  0.9 -1.2 -0.2  4.   0.3  4.  -0.2 -1.1  2.7]
vy_50sample [[2 8 7 4 9 9 3 1 6 5]
 [1 4 6 8 9 5 0 3 2 7]
 [5 8 9 3 0 4 6 7 2 1]
 [2 3 1 4 5 6 9 8 0 7]
 [0 5 2 4 1 8 9 6 7 3]
 [3 8 1 4 9 0 6 7 2 5]
 [8 2 4 9 7 0 3 1 5 6]
 [3 6 8 9 1 0 4 5 2 7]
 [6 3 5 0 8 9 7 1 2 4]
 [6 7 8 1 9 5 2 4 3 0]]
vt_50sample [[2 8 7 0 4 9 3 1 6 5]
 [1 4 6 8 9 5 0 3 2 7]
 [5 8 9 3 0 4 6 7 2 1]
 [2 3 1 4 5 9 6 8 0 7]
 [0 5 2 4 1 8 9 6 7 3]
 [3 8 1 4 9 0 6 7 2 5]
 [8 2 4 9 7 0 3 1 5 6]
 [3 6 8 9 1 0 4 5 2 7]
 [6 3 5 0 8 9 7 1 2 4]
 [6 7 8 1 9 5 2 4 3 0]]
Epoch 59610: Training cost= 0.2942, Training acc= 0.8702, Validation cost= 0.2126, Validation acc= 0.8699
Epoch 59620: Training cost= 0.2452, Training acc= 0.8702, Validation cost= 0.3002, Validation acc= 0.8699
Epoch 59630: Training cost= 0.2758, Training acc= 0.8703, Validation cost= 0.3284, Validation acc= 0.8699
Epoch 59640: Training cost= 0.2631, Training acc= 0.8703, Validation cost= 0.2984, Validation acc= 0.8699
Epoch 59650: Training cost= 0.2157, Training acc= 0.8703, Validation cost= 0.2223, Validation acc= 0.8699
Epoch 59660: Training cost= 0.2271, Training acc= 0.8703, Validation cost= 0.2907, Validation acc= 0.8699
Epoch 59670: Training cost= 0.2459, Training acc= 0.8703, Validation cost= 0.2185, Validation acc= 0.8699
Epoch 59680: Training cost= 0.2356, Training acc= 0.8703, Validation cost= 0.2252, Validation acc= 0.8699
Epoch 59690: Training cost= 0.2374, Training acc= 0.8703, Validation cost= 0.2077, Validation acc= 0.8699
Epoch 59700: Training cost= 0.1776, Training acc= 0.8703, Validation cost= 0.2638, Validation acc= 0.8699
tm  [-0.1 -0.2  5.8 17.2 -1.3 -0.1  0.   0.3 -0.9  0.2  5.3  0.  -0.3 -0.3 -0.8 -0.3 -0.5 -0.3 -0.5 -0.8 -1.5 -0.2 -0.9 -0.  -0.4  0.5 -0.3 -0.5 -0.6  7.2  0.1 -0.3  1.4 16.3 -0.1 -0.1  2.1 -1.5  4.2 -0.   2.8 -1.5  1.3 -0.4 -0.2 -0.2  7.4 -0.3  3.  -5.  -0.1 -0.2 -0.  -4.3 -1.1  0.2 -0.4  3.5 -3.1 -1.6 -1.4 -1.1 -0.2 -0.1  1.  -0.3 -0.3 -0.2  1.2 -0.1 -0.4 -0.8  0.1 -0.8  2.2 -0.8 -0.2 -0.6 -0.  -0.5 30.   0.4 -0.2 -0.6 -0.9 -1.7  3.7 -0.2  0.5 -0.3  0.3  0.1 -0.1  1.7 -0.5 -0.5 -0.8  0.1 -0.2 -0.1  0.3 -0.7 -0.1 -0.  -0.1 -0.3 -0.4 -0.1  2.5 -1.4 -0.1 -0.5 -0.3 -0.3 -1.6  4.3 -0.6 -1.1  0.  -0.2 -0.2  5.1  0.4  1.9  0.  -0.9 -0.1 12.7 -2.2  1.8  0.7 -0.1  0.8  0.8  4.8 19.8  0.1 -0.1  0.7 -0.5  0.5  0.1  1.2  0.1 -0.3 -0.3 -0.2  0.1  0.6 -0.  -2.3 -0.1 -0.2  1.4 -0.1 -0.2 -0.3 -0.4 -0.9 -0.2 -0.6 -0.  -0.2  0.  -0.5  0.8  1.  -0.1 -0.2 -0.2 -0.2 -0.2 -0.2  0.2 -0.1  1.  -0.8 -0.7 -0.6  0.  -1.2 -0.4  0.6 -1.2 -0.1 -0.  -0.2 -0.4 -0.4 -1.6 -0.1  0.5 -0.1 -1.4 13.2  8.7  0.8  6.1 -0.1  0.1 -0.1 -0.2 -0.1 -0.5 -0.5  2.7 -0.3 -0.1 -4.2 -0.1  0.1 -0.1 -0.8 -0.7 -0.3 -0.1  3.2 -1.4 -0.1  1.5  0.1 -0.  -0.2 -0.7 -0.7 -0.3 -2.1 -0.3 -0.8 -0.2  0.4 -0.5 -0.1 -0.3 -0.8 -1.  -0.3 -0.1  1.9  8.6  0.1  1.4 -0.1  0.3 -6.1 -2.  -0.1 -0.2 -0.8 -0.2 -7.6 -0.2  2.   0.4 10.4  0.3]
ty_50sample [[3 9 6 7 5 4 0 1 2 8]
 [3 6 2 5 1 4 7 8 0 9]
 [6 6 7 5 3 0 4 2 8 1]
 [5 1 0 8 6 9 4 2 7 3]
 [0 7 9 3 2 1 6 4 5 8]
 [0 1 1 6 5 7 2 3 4 8]
 [4 8 1 9 2 6 5 0 3 7]
 [9 2 0 6 4 7 3 8 1 5]
 [7 9 3 5 4 1 8 6 2 0]
 [9 4 2 5 6 7 0 3 8 8]]
tt_50sample [[3 9 6 7 5 4 0 1 2 8]
 [3 6 2 5 1 4 7 8 0 9]
 [9 6 7 5 3 0 4 2 8 1]
 [5 1 0 8 6 9 4 2 7 3]
 [0 7 9 3 2 1 6 4 5 8]
 [9 0 1 6 5 7 2 3 4 8]
 [4 8 1 9 2 6 5 0 3 7]
 [9 2 0 6 4 7 3 8 1 5]
 [7 9 3 5 4 1 8 6 2 0]
 [9 4 2 5 6 7 0 3 1 8]]
vm  [-0.7  0.2 -4.7 -7.5 -1.5 -0.1 -0.5 -0.3 -0.  -0.4 -2.  -0.2 -0.2 -0.2  3.5 -0.2 -0.1 -0.3 -0.2  0.1 -1.2  0.1  0.1 -0.3 -1.   0.4 -0.4  0.8 -0.4 -2.1  1.5 -0.5  0.5 -2.4 -0.2 -0.1 -0.2 -1.  -5.  -0.6 -0.3  4.2 -1.   0.4 -0.1 -0.2 -1.8  0.3 -2.5  8.6 -0.2 -0.2 -0.3  4.  -1.9 -0.5 -0.8 -1.2 10.  -2.5 11.1 -0.3  0.4 -0.3  0.8 -0.9 -0.1 -0.1  1.5 -0.1  0.  -0.7 -0.4 -0.8 -5.8  0.9 -0.1 -0.2 -0.3 -0.1 -3.8 -0.5 -0.  -0.1  1.5  5.5 -0.9 -0.2 -0.3 -0.3 -0.6 -0.1 -0.2 -0.5 -1.1  0.2 -0.7 -4.  -0.4 -0.4  0.9  3.9  0.2 -0.2 -0.2  0.7 -3.1  0.3 -0.5  1.9 -0.3  0.2 -0.1 -0.8  4.3  3.7  1.8  1.  -0.2 -0.2 -0.3 -1.1 -0.6 -0.2 -0.   4.2 -0.1 -0.3 10.2  2.2 -0.1 -0.3 -0.1 -0.1 10.8  8.  -0.3 -0.2 -0.1 -0.7 -0.1 -0.3 -0.2 -0.3 -0.2  0.6 -0.1  0.   4.3 -0.2  8.8 -0.1 -1.6 -0.2 -0.2 -0.  -0.2  0.  -0.3 -0.7 -0.1 -0.6  0.4 -0.1 -0.2 -0.1 -0.5 -0.1 -0.5 -0.3  0.2 -0.3 -0.2 -0.3 -0.2 -0.7 -1.1 -0.1  4.8 -0.3 -0.9 -0.3 -0.1 -2.3 -0.2 -0.3 -0.3 -0.2 -0.   6.1 -0.1 -0.3 -0.2 -1.1 -5.5 -3.6 -0.3 -1.5 -0.2 -0.3 -0.3 -0.   0.  -0.4 -0.2 -3.3 -0.1 -0.3 -0.8 -0.5 -0.1  0.  -0.5  9.3  1.4 -0.  -1.  -1.  -0.3 -0.2 -0.2 -0.2 -0.6 -1.6  4.7  2.4 -1.8 -0.3 -0.1 -0.5 -0.7  1.9 -0.5 -0.1 -0.7  5.2 -0.1 -0.4  0.7 -5.1 -0.2 -2.4 -0.2 -0.2 11.7  2.7 -0.1 -0.2 -1.4 -0.1  9.6 -0.1 -2.7 -0.  -0.1  0.5]
vy_50sample [[1 4 6 5 8 0 7 2 3 9]
 [6 2 9 8 1 5 0 4 3 7]
 [2 9 8 1 4 6 0 7 5 3]
 [9 2 8 5 6 7 7 4 1 0]
 [2 0 9 4 6 1 5 3 7 8]
 [5 7 6 3 2 9 1 8 4 0]
 [4 9 5 8 2 6 0 3 7 7]
 [0 9 1 6 4 3 5 2 8 7]
 [9 7 4 1 3 0 8 2 5 6]
 [7 2 2 3 6 0 4 1 8 9]]
vt_50sample [[1 4 6 5 8 0 2 7 3 9]
 [6 2 9 8 1 5 0 4 3 7]
 [2 9 8 1 4 6 0 7 5 3]
 [9 2 8 6 5 3 7 4 1 0]
 [2 0 9 4 6 1 5 3 7 8]
 [5 7 6 3 2 9 1 8 4 0]
 [4 9 5 8 2 6 0 3 7 1]
 [0 9 1 6 4 3 5 2 8 7]
 [9 7 4 1 0 3 8 2 5 6]
 [7 5 2 3 6 0 4 1 8 9]]
Epoch 59710: Training cost= 0.2457, Training acc= 0.8703, Validation cost= 0.2721, Validation acc= 0.8699
Epoch 59720: Training cost= 0.2989, Training acc= 0.8703, Validation cost= 0.2056, Validation acc= 0.8699
Epoch 59730: Training cost= 0.2434, Training acc= 0.8703, Validation cost= 0.2311, Validation acc= 0.8699
Epoch 59740: Training cost= 0.2224, Training acc= 0.8703, Validation cost= 0.2599, Validation acc= 0.8699
Epoch 59750: Training cost= 0.2673, Training acc= 0.8703, Validation cost= 0.2891, Validation acc= 0.8699
Epoch 59760: Training cost= 0.2409, Training acc= 0.8703, Validation cost= 0.3253, Validation acc= 0.8699
Epoch 59770: Training cost= 0.3224, Training acc= 0.8703, Validation cost= 0.2700, Validation acc= 0.8699
Epoch 59780: Training cost= 0.2389, Training acc= 0.8704, Validation cost= 0.2792, Validation acc= 0.8699
Epoch 59790: Training cost= 0.2495, Training acc= 0.8704, Validation cost= 0.2866, Validation acc= 0.8700
Epoch 59800: Training cost= 0.2085, Training acc= 0.8704, Validation cost= 0.2227, Validation acc= 0.8700
tm  [-0.1 -0.  -1.7 -4.5 -1.8 -0.2 -0.3  0.  -1.  -0.4  4.2 -0.  -0.1 -0.3  7.3 -0.1  1.1 -0.1 -0.4  4.3 -1.4 -0.1  1.9  0.4 -1.7  3.3 -0.   0.4 -1.5 -0.5 -0.3 -0.1 -0.3 -3.8 -0.1 -0.1  2.9 -0.3 -7.8 -0.8 -0.7 -0.1  0.4 -1.2 -0.1 -0.1 -3.5 -0.5  5.3  3.8  0.2 -0.2 -0.1 16.1  1.9 -1.2 -0.7  2.3  0.3  4.   5.5 -0.2  1.8  0.3 -0.5  1.3 -0.1 -0.3 -0.9 -0.  -0.   7.  -0.1 -0.1 -5.2 -0.  -0.1 -0.  -0.2  0.3 -6.7  0.  -0.3 -0.3 -1.   1.7  2.6 -0.  -0.1 -0.1 -0.4  0.  -0.2 -0.4 -0.2 -0.4  0.1 -4.3 -0.2  1.1  1.5 -0.8 -0.9 -0.1 -0.1 -0.3 -2.5 -0.2  1.2  5.3 -0.8 -0.1  0.2 -0.3  1.6 -3.  -1.4 -1.  -0.4 -0.7 -0.1 -1.7 -0.4 -0.1 -0.1  8.7 -0.3 -3.1 -0.3 13.5  0.4 -0.1 -0.1 -0.4 16.4  9.9 -0.3 -0.2 -0.  -0.4 -0.6 -0.8 -1.1 -0.3  0.1 -0.2 -0.1 -0.1  5.2 -0.1  5.3 -0.2  2.6 -0.8 -0.1 -0.1 -0.5 -0.2 -1.2 -0.5 -0.   1.1 -0.2 -0.   0.2 -0.6 -0.3 -0.4 -0.1 -0.  -0.2 -0.2 -0.3  0.4 -0.2 -0.7 -0.7 -0.2  6.9 -0.1 -0.9 -0.3 -0.3 -2.1 -0.2 -0.5 -0.4 -0.1 -0.3  1.3  0.6 -0.3 -0.  -1.  -2.4  0.9 -0.4 -0.8 -0.1  0.2 -0.  -0.  -0.1 -0.4  0.4 -3.9 -0.3 -0.1  3.7  0.4 -0.5 -2.4 -0.8 -0.1 -0.7 -0.3  5.8 -1.  -0.9 -0.  -0.1 -0.1  0.5 -1.5  4.  -0.8  0.   1.8 -0.7  0.   0.9 -0.5  0.3  1.3  3.3  1.8  1.2 -0.2  3.3 -5.3 -0.1 -2.4  0.4 -0.1 19.4  5.1 -0.7  0.5 -1.5 -0.5 16.3 -0.  -4.1 -0.1 -0.4 -3.2]
ty_50sample [[6 0 2 8 5 5 1 1 7 9]
 [6 0 4 1 8 7 3 5 9 9]
 [9 3 4 1 5 6 7 0 8 8]
 [4 7 8 2 9 3 6 5 0 1]
 [2 1 6 3 8 7 5 0 4 9]
 [7 9 1 3 6 0 8 4 5 2]
 [3 0 0 2 1 1 9 5 4 7]
 [7 1 0 5 2 6 8 9 4 3]
 [8 1 6 0 5 4 2 7 3 9]
 [2 8 1 3 7 0 9 4 6 5]]
tt_50sample [[6 0 2 8 5 4 3 1 7 9]
 [6 0 4 1 8 7 3 5 2 9]
 [9 3 4 1 5 6 7 0 8 2]
 [4 7 8 2 9 3 6 5 0 1]
 [2 1 6 3 8 7 5 0 4 9]
 [7 9 1 3 6 0 8 4 5 2]
 [3 6 0 2 8 1 9 5 4 7]
 [7 1 0 5 2 6 8 9 4 3]
 [8 1 6 0 5 4 2 7 3 9]
 [2 8 1 3 7 0 4 9 6 5]]
vm  [-0.6 -0.2  0.3 -0.4 -1.8 -0.1  0.1 -0.1 -0.3 -0.7 -0.6 -0.3  0.1 -0.6  2.1 -0.5  0.  -0.4 -0.2 -0.4 -1.4 -0.2 -0.3 -0.2 -1.   2.8 -0.2 -0.1 -0.6  1.9  1.3 -0.5  0.1 13.2 -0.1 -0.1  2.5 -0.4  9.3  0.1  2.2  6.9  1.5  3.3 -0.2 -0.3  3.4 -0.1 -0.1 -0.4 -0.4 -0.2  0.1 -3.2 -1.  -0.4 -0.8  2.4 -0.7 -3.  -0.3 -0.3 -0.2 -0.1  0.3 -0.4  0.1 -0.1  1.7  0.2 -0.3 -0.4 -0.2 -0.4 -1.  -0.2 -0.1  0.5 -0.1 -0.  16.2 -0.2 -0.   0.2 -0.3  6.3  3.6 -0.2 -0.1 -0.2 -0.  -0.   0.2 -0.5 -0.7 -0.4  1.  -2.1 -0.5 -0.2  2.   5.  -0.1 -0.2 -0.2  0.7 -1.2  0.4 -0.1 -1.1 -0.3 -0.  -0.2 -0.3  0.6  3.3 -0.2 -0.8  0.8 -0.4 -0.1  4.4  1.2  1.7 -0.1  2.9 -0.1 10.6  1.2 -1.7 -0.5 -0.2 -0.3 -0.3 -3.1  5.7  0.7  0.1 -0.3 -0.5  1.4 -0.5  0.9 -0.3 -0.1  0.   0.1 -0.1  3.4 -0.  -0.1 -0.  -0.5 -0.2 -0.  -0.1 -0.7 -0.3  2.  -0.1  0.5 -0.4 -0.1 -0.1 -0.2 -0.6 -0.5  0.1 -0.2 -0.1 -0.   0.4 -0.2 -0.3  0.3 -0.2 -0.3 -0.2 -1.   0.  -1.6 -0.3 -0.1 -1.9 -0.1 -0.  -0.  -0.1 -0.2 -0.4 -0.1 -0.  -0.3 -0.9  5.4 -0.1 -0.2 -0.1 -0.1 -0.1 -0.1 -0.1 -0.  -0.4 -0.2 -0.3 -0.  -0.  -4.3 -0.2 -0.5  1.2 -0.3  4.3 -0.8 -0.4 -1.6 -1.4  1.  -0.8 -0.  -0.2 -0.7 -1.   1.4 -0.4 -1.8 -0.2 -0.3  0.2 -0.3 -0.2 -0.4 -0.6 -0.1  1.1  0.  -0.2  2.7 -0.9 -0.  -0.7 -0.2 -0.2 -3.  -1.6 -0.3 -0.5 -1.1 -0.1 -4.2 -0.3  5.4 -0.   3.5  7.5]
vy_50sample [[5 4 7 9 1 0 6 3 8 2]
 [7 8 4 3 5 0 9 2 6 1]
 [0 2 6 3 5 7 1 8 9 4]
 [9 1 7 0 4 8 6 5 3 3]
 [2 0 5 8 1 4 7 3 9 6]
 [2 3 7 0 5 1 8 4 9 6]
 [8 4 4 9 1 5 2 7 3 0]
 [4 5 6 0 0 2 1 9 3 7]
 [2 6 5 1 0 3 7 8 4 9]
 [5 2 1 0 4 7 6 3 9 8]]
vt_50sample [[5 4 7 9 1 0 6 3 8 2]
 [7 8 4 3 5 0 9 2 6 1]
 [0 2 6 3 5 7 1 8 9 4]
 [9 1 7 0 4 8 6 5 3 2]
 [2 0 5 8 1 4 7 3 9 6]
 [2 3 7 0 5 1 8 4 9 6]
 [8 6 4 9 1 5 2 7 3 0]
 [4 5 6 0 8 2 1 9 3 7]
 [2 6 5 1 0 3 7 8 4 9]
 [5 2 1 0 4 7 6 3 9 8]]
Epoch 59810: Training cost= 0.2628, Training acc= 0.8704, Validation cost= 0.1976, Validation acc= 0.8700
Epoch 59820: Training cost= 0.2200, Training acc= 0.8704, Validation cost= 0.2020, Validation acc= 0.8700
Epoch 59830: Training cost= 0.2202, Training acc= 0.8704, Validation cost= 0.2302, Validation acc= 0.8700
Epoch 59840: Training cost= 0.1452, Training acc= 0.8704, Validation cost= 0.2720, Validation acc= 0.8700
Epoch 59850: Training cost= 0.2315, Training acc= 0.8704, Validation cost= 0.2012, Validation acc= 0.8700
Epoch 59860: Training cost= 0.3205, Training acc= 0.8704, Validation cost= 0.2387, Validation acc= 0.8700
Epoch 59870: Training cost= 0.2221, Training acc= 0.8704, Validation cost= 0.2020, Validation acc= 0.8700
Epoch 59880: Training cost= 0.2083, Training acc= 0.8704, Validation cost= 0.2742, Validation acc= 0.8700
Epoch 59890: Training cost= 0.2097, Training acc= 0.8704, Validation cost= 0.2644, Validation acc= 0.8700
Epoch 59900: Training cost= 0.2338, Training acc= 0.8704, Validation cost= 0.2256, Validation acc= 0.8700
tm  [-0.7 -0.1 -1.5  0.2 -1.8 -0.1 -0.2 -0.  -0.5 -0.3 -3.  -0.1 -0.2 -0.4 -0.9 -1.1  0.4 -0.1 -0.2  0.1 -1.7 -0.2 -0.3 -0.  -1.3  2.8 -0.1 -0.3 -0.9 -0.3  1.1 -0.1 -0.2 -0.4 -0.  -0.3  2.6 -2.2 -3.1 -0.2 -0.1  4.9  0.6 -0.6 -0.2  0.  -0.4 -0.3  1.3 -0.4 -0.1 -0.  -0.  -2.7 -0.4  0.7 -0.8  4.8 -0.1 -0.8  2.3 -0.6 -0.1 -0.  -0.5 -0.5 -0.1  0.1  1.1 -0.1 -0.1  3.2 -0.3  1.1 -2.6 -0.2 -0.  -0.4 -0.1  0.6  5.7  0.1 -0.2 -0.4 -0.3  5.5  0.5 -0.2 -0.1 -0.4 -0.2 -0.1 -0.2 -0.4 -0.4 -0.4 -0.2 -2.9 -0.6 -0.3  0.3 -0.2 -0.2 -0.1 -0.4 -0.2 -1.2 -0.1 -0.9 -0.9 -0.5 -0.1 -0.  -0.2  2.7 -1.  -0.5 -0.6 -0.  -0.4  0.2  3.6 -0.1  1.5 -0.2 -1.2 -0.2  9.6  1.8  2.  -0.3 -0.1 -0.1 -0.2 14.4 15.8 -0.1 -0.1 -0.4 -0.2  0.6 -0.5 -0.1 -0.3 -0.  -0.1 -0.3 -0.2  6.2  0.1 -0.1 -0.1 -0.3 -0.4 -0.  -0.1 -0.6  1.4 -0.5 -0.6  1.4  0.6 -0.2 -0.  -0.2 -0.6 -0.6 -0.2 -0.2  0.2  0.   0.2 -0.3 -0.2 -0.3 -1.1 -0.8 -0.1  2.3 -0.1 -1.8 -0.1 -0.2 -1.7 -0.1 -0.  -0.  -0.  -0.2  1.2 -0.1 -0.2 -0.2 -1.  -0.1 -0.4 -0.3 -0.7 -0.1 -0.1  0.2 -0.1 -0.3 -0.3 -0.  -1.2 -0.3 -0.2 -3.4  0.4 -0.8 -0.8 -0.6  4.3 -1.  -0.2  4.1 -1.1 -0.1 -0.4  0.3 -0.1 -0.1 -1.   4.4 -0.6 -1.9  0.5  0.3  0.2  2.  -0.1 -0.2 -0.6  0.4  1.3  0.7 -0.2  3.4 -2.6 -0.2 -1.4 -0.  -0.1 -0.7 -0.5 -0.5 -0.2 -1.2 -0.5 -1.8 -0.  -1.6 -0.1  4.7  1. ]
ty_50sample [[6 5 0 1 4 3 3 8 7 2]
 [5 2 8 9 4 6 7 1 0 0]
 [1 8 0 5 6 3 7 4 9 2]
 [0 6 8 8 2 3 1 7 4 5]
 [9 4 3 2 6 7 5 0 8 1]
 [6 3 7 7 2 5 4 8 1 9]
 [9 4 0 8 2 5 6 7 3 1]
 [6 0 3 5 1 9 7 8 4 2]
 [1 8 3 4 5 2 0 0 6 7]
 [9 5 0 3 7 1 6 2 4 8]]
tt_50sample [[6 5 0 1 4 9 3 8 7 2]
 [5 2 8 9 4 6 1 7 0 3]
 [1 8 0 5 6 3 7 4 9 2]
 [0 6 8 9 2 3 1 7 4 5]
 [9 4 3 2 6 7 5 0 8 1]
 [6 3 7 0 2 5 4 8 1 9]
 [9 4 0 8 2 5 6 7 3 1]
 [6 0 3 5 1 9 7 8 4 2]
 [1 3 8 4 5 2 0 9 6 7]
 [9 5 0 3 7 1 6 2 4 8]]
vm  [-0.5  0.6 -2.5 13.9 -1.6 -0.2 -0.  -0.1 -0.  -0.5 -1.6 -0.1 -0.2 -0.2 -4.5 -0.7 -0.2 -0.5 -0.6 -0.9 -1.6 -0.1 -0.8 -0.1 -0.4  2.6 -0.2 -0.3 -0.1 -1.5  1.4 -0.2  1.3 -0.5 -0.2 -0.3 -0.2 -2.   6.8  0.2  4.4 -2.3 -0.3 -0.2  0.3 -0.3  9.2 -0.1  2.1 -3.1 -0.1  0.1  1.5 -5.5 -1.1  5.  -0.3 -0.7  1.8 -1.5 -1.6 -0.7 -0.1 -0.2  0.6 -0.3  0.1 -0.1  2.2  0.  -0.3 -1.4 -0.6 -0.6  2.7  0.3 -0.1  2.5 -0.1 -0.2 25.6  0.3  0.1 -0.2 -0.7 -1.8  1.8  0.1 -0.1 -0.   0.3 -0.2  0.7 -0.3 -0.9  0.4 -0.3 -0.6 -0.2 -0.4  1.5 -1.9 -0.  -0.1 -0.3 -0.3 -0.  -0.2 -0.4 -1.6  0.2  0.4 -0.  -0.6  1.5  8.2  1.7 -0.  -0.2 -0.1 -0.1  6.2 -0.   2.1 -0.1 -5.7 -0.1 16.4  3.  -0.5 -0.5 -0.1 -0.4 -0.2 13.6 15.5  0.7 -0.1 -0.  -0.6  1.3  0.3  1.1 -0.1 -0.1 -0.  -0.2 -0.1  4.2  0.2 -1.8  0.   1.4  2.1 -0.2 -0.1 -0.6  1.6 -0.2 -0.7 -0.3 -0.2 -0.1 -0.1  0.7 -0.1 -0.3 -0.  -0.1 -0.   0.3  0.1 -0.  -0.2 -0.2 -0.3 -1.4 -0.2 -0.7 -0.1 -0.1 -0.5 -0.1 -1.8 -0.3 -0.2 -0.2 -0.3 -0.1  4.8 -0.2 -0.  -0.3 -1.1 14.2 -1.1 -0.1 -0.6 -0.  -0.2  0.5 -0.1 -0.2 -0.1 -0.2  5.3 -0.  -0.  -0.2 -0.1 -0.5  2.3  0.3  0.7 -0.6  0.7  1.1 -1.5 -0.2 -0.3 -0.2 -0.1 -0.3 -0.6 -0.5  1.2 -2.8 -0.5  0.2 -0.2  0.7 -1.  -0.1 -0.2 -0.7  3.1 -0.3 -0.   3.7 22.9 -0.1  7.  -0.  -0.2 -5.1 -2.8 -0.2 -0.6 -1.2 -0.  -6.6 -0.2  3.6 -0.5 11.1  3.7]
vy_50sample [[9 3 6 4 1 5 0 8 7 2]
 [0 7 9 2 5 6 4 3 8 1]
 [4 7 2 5 8 6 0 0 1 3]
 [5 1 3 2 4 7 7 8 0 9]
 [6 4 5 3 3 7 8 2 1 0]
 [4 8 1 7 6 2 5 3 9 0]
 [0 6 8 5 9 1 2 4 3 7]
 [9 4 2 7 1 6 3 5 0 8]
 [1 9 9 6 8 5 2 3 7 4]
 [3 1 4 7 2 8 6 5 0 9]]
vt_50sample [[9 3 6 4 1 5 0 8 7 2]
 [0 7 9 2 5 6 4 3 8 1]
 [4 7 2 5 8 6 9 1 0 3]
 [5 1 3 2 4 6 7 0 8 9]
 [6 4 5 9 3 7 8 2 1 0]
 [4 1 8 7 6 2 5 3 9 0]
 [0 6 8 5 9 1 2 4 3 7]
 [9 4 2 7 1 6 3 5 0 8]
 [1 9 0 6 8 5 2 3 7 4]
 [3 1 4 7 2 8 6 5 0 9]]
Epoch 59910: Training cost= 0.2261, Training acc= 0.8704, Validation cost= 0.2235, Validation acc= 0.8700
Epoch 59920: Training cost= 0.2109, Training acc= 0.8705, Validation cost= 0.2580, Validation acc= 0.8700
Epoch 59930: Training cost= 0.2384, Training acc= 0.8705, Validation cost= 0.2747, Validation acc= 0.8700
Epoch 59940: Training cost= 0.2148, Training acc= 0.8705, Validation cost= 0.2302, Validation acc= 0.8700
Epoch 59950: Training cost= 0.2403, Training acc= 0.8705, Validation cost= 0.2060, Validation acc= 0.8700
Epoch 59960: Training cost= 0.2378, Training acc= 0.8705, Validation cost= 0.2670, Validation acc= 0.8701
Epoch 59970: Training cost= 0.2504, Training acc= 0.8705, Validation cost= 0.2570, Validation acc= 0.8701
Epoch 59980: Training cost= 0.2064, Training acc= 0.8705, Validation cost= 0.2811, Validation acc= 0.8701
Epoch 59990: Training cost= 0.2568, Training acc= 0.8705, Validation cost= 0.3089, Validation acc= 0.8701
Epoch 60000: Training cost= 0.2252, Training acc= 0.8705, Validation cost= 0.2096, Validation acc= 0.8701
tm  [-0.4 -0.1 -2.7 -0.5 -1.9 -0.4 -0.1 -0.1 -0.1  0.9 -4.7 -0.4 -0.4  0.8 -1.5 -1.7 -0.  -0.3  1.3 -0.7 -1.2 -0.1  0.8 -0.2 -1.2  3.3  0.3 -0.  -0.5 -1.5  1.2 -0.2 -1.9 -2.2 -0.1 -0.2 -1.3 -1.4  9.2 -0.4 -1.4  1.3 -0.7  1.2 -0.4  0.3  2.5 -0.3  5.5 10.7 -0.1 -0.2  0.4 -2.6 -1.   1.6 -0.2 -2.6  8.4 -0.8 -0.7 -0.  -0.6 -0.4 -0.5 -1.  -0.5 -0.1  4.7 -0.2 -0.1 -0.5  1.4  2.  -1.6 -0.  -0.1  1.1 -0.2 -0.6  2.3 -0.  -0.2 -0.3 -1.5  3.5  5.2  0.3 -0.2 -0.1  0.  -0.   0.1 -1.8 -1.3 -0.5 -0.8 -3.  -0.3 -0.5 -1.1  5.3 -0.2 -0.3 -0.2  0.  -0.3 -0.3 -1.1 -1.1 -0.1 -0.2 -0.3 -0.2  7.   2.  -0.6  2.1 -0.   0.8 -0.1  3.  -0.3 -0.9  0.2 -1.9 -0.2  9.6  6.5 -2.4  0.4 -0.  -0.5 -0.   4.4 -1.7 -0.3  0.  -0.3  0.6  0.3 -0.3  0.8  0.7 -0.  -0.3 -0.3  0.  -0.8 -0.  -0.1  0.1  2.7  5.1 -0.1 -0.2 -0.7  0.3 -0.9 -0.1  1.6 -0.2 -0.2  0.2 -0.1 -1.1 -0.8 -0.2  0.1 -0.1 -0.1 -0.3 -0.  -0.2 -0.4  1.5  0.2  0.6 -1.1 -0.1 -0.1 -0.8 -0.6 -3.3 -0.   0.4 -0.4 -0.4 -0.1  3.3  0.1 -0.2 -0.1 -0.7  9.9 -2.3  1.7 -2.6 -0.1 -0.2 -0.1  0.4 -0.7 -0.1  0.2  1.4 -0.1 -0.3  8.5 -0.4 -0.7  0.4 -1.  -0.  -0.8  0.2 -1.1 -0.8  0.3 -0.2  0.1  0.3 -0.3 -1.4  7.   3.  -3.3 -0.8 -0.6 -0.2 -0.8 -0.8 -0.   1.2 -0.6  2.9 -0.3 -0.1  4.7 15.7 -0.3  3.6  0.3 -0.   0.5 -2.  -0.  -0.3 -1.4 -1.2 -1.   0.2  4.7 -0.4  4.4  9.5]
ty_50sample [[4 9 8 0 6 7 1 5 3 2]
 [7 0 4 8 2 5 1 3 9 6]
 [6 8 0 2 3 7 4 5 9 1]
 [4 1 1 5 2 7 6 3 0 8]
 [6 3 7 5 2 9 0 8 4 1]
 [5 1 8 9 0 7 4 2 3 6]
 [3 5 6 9 2 0 4 7 1 8]
 [9 2 8 1 7 6 5 3 0 4]
 [5 3 4 8 0 7 6 9 2 1]
 [8 1 7 5 6 6 0 2 3 4]]
tt_50sample [[4 9 8 0 6 7 1 5 3 2]
 [7 0 4 8 2 5 1 3 9 6]
 [6 8 0 2 3 7 4 5 9 1]
 [4 1 9 5 2 7 6 3 0 8]
 [6 3 7 5 2 9 0 8 4 1]
 [5 1 8 9 0 7 4 2 3 6]
 [3 5 6 9 2 0 4 7 1 8]
 [9 2 8 1 7 6 5 3 0 4]
 [5 3 4 8 0 7 6 9 2 1]
 [1 8 7 5 6 9 0 2 3 4]]
vm  [-0.7  0.7 -2.7  8.  -0.2 -0.1 -0.3 -0.1 -0.7 -0.8  6.8 -0.2 -0.2 -0.1 -3.5  3.5 -0.4 -0.3 -0.4 -0.5 -1.  -0.2 -0.6 -0.2 -1.2  0.2 -0.2 -0.4 -0.7 -1.5 -0.9 -0.1 -0.7 -8.5 -0.2  0.5  3.3  5.9  1.8 -0.4  1.8  5.8  1.8 -0.5 -0.1  0.2  2.7 -0.  -1.2 12.4 -0.2 -0.2 -0.3  9.5 -1.   4.2 -0.6  6.9 -1.1  6.   3.1 -0.6 -0.5  0.  -0.6 -0.  -0.1 -0.2 -0.6  0.6  0.1  1.5 -0.3  0.1 -1.4 -0.1 -0.  -0.5 -0.   0.6 -1.9 -0.2  0.2  1.7  0.2  7.1 -1.4 -0.3  0.1 -0.1 -0.7 -0.1 -0.   0.6 -0.2  1.2 -0.1 -1.9 -0.5  0.9  3.9 -0.2  0.2 -0.3  0.  -0.1 -1.5 -0.4  1.6 -1.6 -0.6 -0.4 -0.1 -0.1 -0.9  1.3  1.4 -0.9 -0.1 -0.3 -0.2  6.5  0.1  0.5 -0.3 -4.3 -0.1 -1.4 -0.9 -2.4 -0.5 -0.2  0.2 -0.3 12.6 -2.  -0.1 -0.  -0.5 -0.6 -0.5  0.1 -0.7 -0.2 -0.1  0.1  0.3 -0.2  8.4 -0.  -1.   0.1  1.3 -0.7  0.1 -0.1  1.2 -1.2 -0.2 -0.8 -0.5 -0.2 -0.3 -0.3 -0.   0.1  1.3 -0.2 -0.2  0.1 -0.   0.2 -0.3 -0.5 -0.2 -2.  -0.6 -0.6 -0.2 -0.1 -2.1 -0.2 -0.3 -1.6 -0.   1.5 -0.2  1.8 -0.2  4.3 -0.2  0.2 -0.1 -0.7 -0.6  3.8 -0.4  3.2 -0.1 -0.1 -0.2 -0.  -0.2 -0.1 -0.3 -1.8 -0.2  0.3 -0.5 -0.4 -0.7 -1.3 -0.1  5.1 -0.1 -0.3  2.2 -0.9 -0.3 -0.2 -0.2  0.2 -0.3 -0.7  3.2  0.8  3.5 -0.2 -0.4 -0.4 -0.7  1.  -0.2 -0.3 -0.1  1.5 -0.6 -0.5 -0.1 -2.3 -0.1 -1.3  0.2 -0.1  7.2 -0.2 -0.1 -0.2 -1.1 -0.2  4.5 -0.1  0.6 -0.3 -2.   9.4]
vy_50sample [[2 5 8 1 0 6 9 4 3 7]
 [4 9 5 1 6 8 0 2 7 3]
 [9 4 6 8 8 7 2 1 0 5]
 [3 8 4 6 7 1 0 2 9 5]
 [8 9 1 3 5 0 6 2 4 7]
 [3 0 8 5 4 7 6 1 9 2]
 [1 8 7 5 5 4 2 3 9 6]
 [2 7 9 4 5 8 6 1 0 3]
 [9 2 1 6 3 4 7 5 0 8]
 [9 0 2 8 6 3 5 1 4 7]]
vt_50sample [[2 5 1 8 0 6 9 4 3 7]
 [4 9 5 1 6 8 0 2 7 3]
 [9 4 6 3 8 7 2 1 0 5]
 [3 8 4 6 7 1 0 2 9 5]
 [8 9 1 3 5 6 0 2 4 7]
 [3 0 8 5 4 7 6 1 9 2]
 [1 8 7 5 0 4 2 3 9 6]
 [2 7 9 5 4 8 6 1 0 3]
 [9 2 1 6 3 4 7 5 0 8]
 [9 0 2 8 6 3 5 1 4 7]]
Epoch 60010: Training cost= 0.2451, Training acc= 0.8705, Validation cost= 0.2412, Validation acc= 0.8701
Epoch 60020: Training cost= 0.2936, Training acc= 0.8705, Validation cost= 0.2494, Validation acc= 0.8701
Epoch 60030: Training cost= 0.1895, Training acc= 0.8705, Validation cost= 0.2024, Validation acc= 0.8701
Epoch 60040: Training cost= 0.1988, Training acc= 0.8705, Validation cost= 0.2592, Validation acc= 0.8701
Epoch 60050: Training cost= 0.2396, Training acc= 0.8705, Validation cost= 0.2287, Validation acc= 0.8701
Epoch 60060: Training cost= 0.2028, Training acc= 0.8706, Validation cost= 0.1865, Validation acc= 0.8701
Epoch 60070: Training cost= 0.2674, Training acc= 0.8706, Validation cost= 0.2833, Validation acc= 0.8701
Epoch 60080: Training cost= 0.2262, Training acc= 0.8706, Validation cost= 0.2806, Validation acc= 0.8701
Epoch 60090: Training cost= 0.2924, Training acc= 0.8706, Validation cost= 0.2554, Validation acc= 0.8701
Epoch 60100: Training cost= 0.2509, Training acc= 0.8706, Validation cost= 0.2435, Validation acc= 0.8701
tm  [-0.3 -0.1 -0.7 -1.2 -1.4 -0.  -0.3 -0.  -0.3 -0.5  9.1 -0.3 -0.1 -0.3  2.1  4.2  0.4 -0.1 -0.1 -1.1 -1.1 -0.4 -0.7 -0.2 -1.  -0.1 -0.1  0.  -0.2  0.2  0.3 -0.1 -0.9  2.7 -0.1 -0.1  0.8  8.7 13.1 -0.2 -0.5  6.5 -0.1  0.9  0.   0.8  2.2  0.2  1.2 10.5 -0.3 -0.2 -0.2 10.7 -1.2 -0.5 -0.7  2.6 -0.5 -1.  -0.1 -0.5 -0.7 -0.1 -0.5  0.2 -0.1 -0.1 -0.7  0.   0.  -1.  -0.4  0.6 -1.8  0.3 -0.  -0.2  0.2  0.4  0.7 -0.3 -0.2 -0.2 -0.5  8.1  2.7 -0.1 -0.3 -0.3 -0.5 -0.1  0.6 -0.4 -0.5  0.2  0.2 -2.3 -0.4  0.1  2.9  4.  -0.5 -0.1 -0.3 -0.2 -1.7 -0.  -0.  -1.5  0.8 -0.  -0.1 -0.4 -0.8  8.  -0.5 -0.6 -0.2 -0.2 -0.3  5.5  1.1  0.4 -0.1  2.5 -0.1 -1.7 -0.4 -3.2 -0.4 -0.3 -0.1 -0.5 -3.3 -3.5 -0.3 -0.1  0.3 -0.5 -0.2 -0.1 -0.3 -0.1 -0.3 -0.1 -0.4 -0.2  4.3  0.1  1.2 -0.1  1.3 -0.5 -0.2  0.1 -0.4  0.4  1.1 -0.1 -0.5 -0.5 -0.2 -0.2 -0.3  0.7 -0.2 -0.2  0.1 -0.1  0.1 -0.1 -0.2 -0.3  0.4 -0.7  2.5 -0.4 -1.4  0.3 -2.1 -0.1 -0.3 -1.5 -0.1 -0.3 -0.1 -0.5 -0.4  0.5 -0.1 -0.  -0.2 -0.9  3.7  1.6 -0.1  2.5 -0.1 -0.2 -0.  -0.1 -0.2 -0.2 -0.2 -1.6 -0.2 -0.2 -1.9  0.2 -0.2  0.4 -0.5  0.7 -0.3 -0.3 -1.7 -1.3 -0.5 -0.5 -0.1 -0.  -0.3 -1.   2.7  3.5  3.5  0.9  2.7 -0.  -0.9  0.1 -0.2 -0.5 -0.3  0.9 -0.5 -0.   2.  -1.9 -0.  -1.2 -0.2 -0.   1.5 -0.3 -0.4 -0.5 -0.8  0.1 -0.3 -0.1  6.9 -0.4 -2.6 11.7]
ty_50sample [[2 5 4 7 7 9 1 0 6 3]
 [9 3 5 1 8 0 0 2 7 4]
 [2 5 3 0 7 9 1 6 8 8]
 [9 6 4 2 0 7 3 1 5 8]
 [5 4 8 8 6 7 2 0 1 9]
 [7 7 5 1 2 9 6 0 4 8]
 [3 6 7 2 8 0 1 4 5 9]
 [7 0 2 3 9 8 5 4 1 6]
 [2 9 1 6 3 5 8 0 0 7]
 [8 0 3 1 7 6 4 9 5 2]]
tt_50sample [[2 5 4 7 8 9 1 0 6 3]
 [9 3 5 1 8 6 0 2 7 4]
 [2 5 3 0 7 9 1 6 8 4]
 [9 6 4 2 0 7 3 1 5 8]
 [5 4 8 6 3 7 2 0 1 9]
 [7 3 5 1 2 9 6 0 4 8]
 [3 6 7 2 8 0 1 4 5 9]
 [7 0 2 3 9 8 5 4 1 6]
 [2 9 6 1 3 5 8 4 0 7]
 [8 0 3 1 7 6 4 9 5 2]]
vm  [-0.9 -0.2 11.3  0.4 -2.  -0.1 -0.3 -0.2 -0.2 -1.3 -1.7 -0.2 -0.1 -0.5 14.2  1.9 -0.2  0.2 -0.2  0.4 -1.3 -0.1  1.5 -0.3 -1.5  3.2 -0.5 -0.2 -0.3 -0.7 -0.3 -0.2  1.6 11.1 -0.2 -0.1 -0.2  4.8  6.7 -0.4  4.   0.8  1.5  0.7 -0.4 -0.  -1.2  0.3 -1.   5.3 -0.4 -0.3  0.1  2.2 -1.1 -1.8 -0.8  5.9 -0.1  5.   7.4 -0.2  2.3 -0.5 -1.  -0.6 -0.4 -0.3 -0.3 -0.2 -0.2 -1.5 -0.5  2.  -3.9  1.9 -0.1  3.  -0.2 -0.1 -2.4 -0.4  0.4 -0.9 -0.2  1.7 -2.1 -0.1 -0.2 -0.2 -1.1 -0.2 -0.2 -0.1 -0.5 -0.5  3.3 -3.4 -1.   0.4  4.2  5.8 -0.4 -0.2  0.9 -0.5 -1.  -0.3 -0.5 -0.1 -0.6 -0.2 -0.3 -0.6 -0.2 10.8  0.  -0.7 -0.3 -0.5 -0.3 -0.2 -0.5  1.6  0.  18.1 -0.2  0.7 -0.2  2.3 -0.7 -0.4 -1.  -0.1 -8.2 -4.1 -0.2 -0.  -0.2 -0.3 -0.2 -0.5 -0.7 -0.2 -0.4 -0.4 -0.4 -0.1 -1.1 -0.2 -0.3  0.3 -0.2 -0.4 -0.2 -0.4 -0.8 -0.5  4.6 -0.3 -0.2 -1.9  0.2 -0.2 -0.4 -0.4 -0.  -0.3 -0.3 -0.2 -0.  -0.2 -0.2 -0.4  0.1 -0.4 -0.3 -0.2 -0.7 -0.2 -0.8  0.2 -0.2 -1.3 -0.1 -0.9 -0.3 -0.3 -0.2  0.9 -0.2 -0.1 -0.1 -0.7 -2.9  0.6  0.6 -0.1 -0.4 -0.1 -0.3 -0.   0.1  1.5 -0.5 -1.1 -0.2 -0.1  3.8 -0.2 -0.8  2.3  0.6  7.2 -0.1 -0.4 -1.2 -1.  -0.4 -1.4 -0.3 -0.   0.7 -0.4 -2.   3.8 -1.1 -0.2 -0.2 -0.8  0.2 -0.5 -0.4  0.5 -0.3 -2.  -0.9 -0.  -0.  -0.2 -0.1 -0.4 -0.1 -0.   8.5 -0.7 -0.7 -0.5 -1.3  3.6  5.5 -0.2  3.9  0.8  2.9 -0.1]
vy_50sample [[7 1 8 5 3 2 2 9 0 6]
 [8 6 3 0 5 4 9 9 7 2]
 [1 7 3 6 6 9 8 5 0 0]
 [2 6 3 7 1 0 9 5 8 4]
 [2 5 3 6 7 1 8 4 9 9]
 [3 2 2 4 8 1 5 0 6 7]
 [8 1 4 2 7 3 0 6 9 5]
 [2 5 1 0 9 7 3 4 8 6]
 [5 8 2 9 6 3 1 4 7 0]
 [2 1 4 7 9 0 6 3 5 8]]
vt_50sample [[7 1 8 5 3 2 4 9 0 6]
 [8 6 3 0 5 4 9 1 7 2]
 [7 1 3 6 4 9 8 5 0 2]
 [2 6 3 7 1 0 9 5 8 4]
 [2 5 3 6 7 1 8 4 9 0]
 [3 9 2 4 8 1 5 0 6 7]
 [8 1 4 2 7 3 0 6 9 5]
 [2 5 1 0 9 7 3 4 8 6]
 [5 8 2 9 6 3 1 4 7 0]
 [2 1 4 7 9 0 6 3 5 8]]
Epoch 60110: Training cost= 0.2610, Training acc= 0.8706, Validation cost= 0.2350, Validation acc= 0.8701
Epoch 60120: Training cost= 0.2026, Training acc= 0.8706, Validation cost= 0.2699, Validation acc= 0.8701
Epoch 60130: Training cost= 0.2494, Training acc= 0.8706, Validation cost= 0.2912, Validation acc= 0.8702
Epoch 60140: Training cost= 0.2480, Training acc= 0.8706, Validation cost= 0.2701, Validation acc= 0.8702
Epoch 60150: Training cost= 0.2239, Training acc= 0.8706, Validation cost= 0.2425, Validation acc= 0.8702
Epoch 60160: Training cost= 0.2588, Training acc= 0.8706, Validation cost= 0.2086, Validation acc= 0.8702
Epoch 60170: Training cost= 0.1693, Training acc= 0.8706, Validation cost= 0.2885, Validation acc= 0.8702
Epoch 60180: Training cost= 0.2080, Training acc= 0.8706, Validation cost= 0.2844, Validation acc= 0.8702
Epoch 60190: Training cost= 0.2277, Training acc= 0.8706, Validation cost= 0.2788, Validation acc= 0.8702
Epoch 60200: Training cost= 0.1713, Training acc= 0.8706, Validation cost= 0.2235, Validation acc= 0.8702
tm  [-0.8 -0.2 -3.7 -2.  -1.5  0.5 -0.3 -0.1 -1.5 -0.5 -1.7 -0.   0.  -0.3 -1.3 -1.4 -0.2 -0.2 -0.7  0.3 -1.9 -0.  -0.4 -0.2 -1.5  2.4  0.2 -0.4 -1.4 -3.7  1.2 -0.  -0.4 -4.5 -0.1 -0.2  4.7  2.5  3.9 -0.1  2.3 -2.   0.6  1.4 -0.2 -0.4 -0.7 -0.4 -0.7 -2.1 -0.2 -0.1 -0.3  0.7  0.7  0.6 -1.  -0.3  2.8 -0.1  5.9 -0.5  0.6 -0.1 -0.6 -0.2  0.1 -0.3  0.3 -0.  -0.2  5.8 -0.3 -0.  -3.1 -0.4 -0.2 -0.7 -0.1 -0.3 -1.8 -0.1 -0.3 -0.3 -0.2 -2.  -0.  -0.3  0.1 -0.2 -0.4 -0.1 -0.1 -0.  -0.2  0.7 -0.6 -3.1 -0.1 -0.1  1.2 -2.2 -0.2 -0.  -0.4 -0.1 -1.8 -0.2 -0.3 -0.5 -0.5 -0.4 -0.2 -0.1  1.8 -3.5 -0.2 -1.  -0.1 -0.4  0.2  1.  -0.1  0.8  0.3 -1.7 -0.3  1.3  5.  13.2 -0.2 -0.2 -0.1 -0.1  5.8 -2.5 -0.2  0.   1.  -0.1 -0.1 -0.5 -0.3 -0.2 -0.2 -0.1  0.  -0.   5.4 -0.2  1.6 -0.  -0.4 -0.1 -0.2 -0.1  0.  -0.4  1.  -0.4 -0.4 -1.2  0.2 -0.1 -0.4 -0.4 -0.  -0.4 -0.3 -0.   0.  -0.2 -0.1 -0.1 -0.2 -0.9  0.2 -0.6 -0.5 -0.2 -1.  -0.4 -0.2 -2.2 -0.3 -0.1 -0.3  0.1 -0.2 10.5 -0.2 -0.1 -0.3 -1.4 -2.3 -1.5 -0.6 -0.6 -0.2 -0.2 -0.2 -0.1 -0.2 -0.1 -0.1 -2.5  0.  -0.2  0.3 -0.2 -0.4 -2.3 -0.7  5.4 -0.6 -0.4 -1.6 -1.4 -0.4  0.8 -0.2 -0.2 -0.2 -1.4 -2.2 -0.8 -1.2  0.4 -0.  -0.4 -0.5  0.5 -0.4 -0.   2.2  2.9  0.2 -0.2  1.9 -1.6 -0.  -1.1 -0.3 -0.1  7.   0.8 -0.2  0.2 -1.4 -0.1  4.  -0.1  2.1  1.1  7.7 -2.9]
ty_50sample [[3 0 1 4 5 8 9 2 6 7]
 [2 3 1 4 7 8 6 0 9 5]
 [3 5 2 0 6 1 4 8 7 9]
 [7 9 8 3 0 6 1 5 4 2]
 [4 2 5 7 9 1 3 8 0 6]
 [7 2 6 1 3 8 5 4 9 0]
 [6 4 0 2 1 9 7 9 3 8]
 [9 8 3 2 5 6 1 7 4 0]
 [8 8 4 6 3 0 7 1 5 2]
 [2 6 9 1 0 8 4 7 5 3]]
tt_50sample [[3 0 1 4 5 8 9 2 6 7]
 [2 3 1 4 7 8 6 0 9 5]
 [3 5 2 0 6 1 4 8 7 9]
 [7 9 8 3 0 6 1 5 4 2]
 [4 2 5 7 9 1 3 8 0 6]
 [7 2 6 1 3 8 5 4 9 0]
 [6 4 0 2 1 7 9 5 3 8]
 [9 8 3 2 5 6 1 7 4 0]
 [9 8 4 6 3 7 0 1 5 2]
 [2 6 9 1 0 8 4 7 5 3]]
vm  [-0.2 -0.2  5.1 -2.1 -1.3 -0.4 -0.2 -0.1 -0.1 -0.1  8.5 -0.2 -0.3 -0.1 11.4  5.7 -0.2 -0.3 -0.1 -0.5 -0.9 -0.3 -0.4 -0.2 -1.3 -0.5 -0.4 -0.2  1.2  4.4 -0.5  0.3 -0.3  3.7 -0.1 -0.1 -0.2  5.1 -3.5 -0.5  1.2  7.3  0.3 -0.2 -0.1 -0.2 -1.2 -0.4  1.6 10.6 -0.2 -0.  -0.7 20.4 -1.5 -1.5 -1.1  5.  -1.   3.9  1.7 -0.7 -0.9 -0.  -0.6  0.5  0.3 -0.  -0.3 -0.1  0.5 -1.9 -0.4 -0.2 -4.8 -0.6 -0.2 -0.6 -0.1 -0.3 -4.3 -0.2 -0.3 -0.3 -1.   6.9  1.4 -0.1 -0.2 -0.3 -0.4 -0.1  0.5 -0.3 -0.4 -0.2 -0.6 -3.3 -0.5  0.1  1.7  4.9 -0.4 -0.  -0.4  0.5 -3.  -0.2 -0.1 -0.4  0.   0.3 -0.  -0.5 -1.8 14.7  1.3 -0.4 -0.2  0.1 -0.3 -0.  -0.4 -0.7 -0.  14.8  0.9 -3.9 -0.5 -0.4 -0.2 -0.2 -0.3 -0.2 -0.9  1.5 -0.4 -0.1 -0.6 -0.7 -0.1 -0.2 -0.4 -0.3 -0.   0.5 -0.3 -0.3  2.6 -0.3  2.6 -0.3  2.  -0.3 -0.2  0.8  0.5 -0.2 -0.4 -0.4 -0.6 -0.1 -0.3 -0.2 -0.1  0.1 -0.5 -0.3 -0.2 -0.1 -0.1 -0.  -0.3 -0.5 -0.  -0.4 -1.  -0.1  3.4 -0.1 -2.4  0.4 -0.4 -1.8 -0.2 -0.3 -0.3 -0.7 -0.4 -1.1 -0.2 -0.3 -0.2 -0.9 -0.2  1.7 -0.5  5.5 -0.1 -0.1 -0.3 -0.3 -0.2 -0.6 -0.2 -3.3 -0.1 -0.3 -2.3 -0.3  0.2  2.1 -0.6 -0.8 -0.6 -0.4  1.5 -1.  -0.5  0.7 -0.  -0.   1.6 -1.5  3.1  5.5  3.7 -0.3  1.6 -0.  -0.9  2.6 -0.2 -0.3 -0.9 -0.9 -0.3 -0.4  1.2 -7.2  0.1 -3.2 -0.  -0.2 12.7  4.6 -0.3 -0.3 -1.   0.  11.4  0.  -1.9 -0.6 -2.4  2.8]
vy_50sample [[2 5 7 8 6 4 1 9 3 0]
 [7 1 4 0 0 6 3 2 8 5]
 [0 4 9 5 2 8 3 3 1 7]
 [8 1 4 3 0 6 2 5 9 7]
 [5 2 9 9 1 1 4 6 3 7]
 [8 1 2 6 7 5 3 4 0 9]
 [4 3 0 2 8 6 5 9 7 1]
 [3 2 2 1 0 8 6 6 9 7]
 [3 1 2 6 4 8 5 7 9 0]
 [9 4 2 8 6 1 3 7 0 5]]
vt_50sample [[2 5 7 8 6 4 1 9 3 0]
 [7 1 4 9 0 6 3 2 8 5]
 [0 4 9 5 2 8 3 6 1 7]
 [8 1 4 3 0 6 2 5 9 7]
 [5 2 0 9 1 8 4 6 3 7]
 [8 1 2 6 7 5 3 4 0 9]
 [4 3 0 2 8 6 5 9 7 1]
 [3 5 2 0 1 8 6 4 9 7]
 [3 1 2 6 4 8 5 7 9 0]
 [9 4 2 8 6 1 7 3 0 5]]
Epoch 60210: Training cost= 0.2030, Training acc= 0.8707, Validation cost= 0.1945, Validation acc= 0.8702
Epoch 60220: Training cost= 0.1992, Training acc= 0.8707, Validation cost= 0.2637, Validation acc= 0.8702
Epoch 60230: Training cost= 0.2142, Training acc= 0.8707, Validation cost= 0.2147, Validation acc= 0.8702
Epoch 60240: Training cost= 0.2334, Training acc= 0.8707, Validation cost= 0.2988, Validation acc= 0.8702
Epoch 60250: Training cost= 0.2462, Training acc= 0.8707, Validation cost= 0.2074, Validation acc= 0.8702
Epoch 60260: Training cost= 0.1882, Training acc= 0.8707, Validation cost= 0.2868, Validation acc= 0.8702
Epoch 60270: Training cost= 0.2518, Training acc= 0.8707, Validation cost= 0.2619, Validation acc= 0.8702
Epoch 60280: Training cost= 0.2573, Training acc= 0.8707, Validation cost= 0.2491, Validation acc= 0.8702
Epoch 60290: Training cost= 0.2335, Training acc= 0.8707, Validation cost= 0.2269, Validation acc= 0.8703
Epoch 60300: Training cost= 0.2687, Training acc= 0.8707, Validation cost= 0.2412, Validation acc= 0.8703
tm  [-0.4  0.6 11.6 23.5 -1.3 -0.2 -0.2 -0.2 -0.3  0.9 -3.7 -0.2 -0.  -0.2  2.9 -0.8 -0.8 -0.3 -0.9 -1.7 -0.8 -0.4 -0.8 -0.4 -0.5 -0.6 -0.3  0.6 -1.   0.  -0.6 -0.5 -0.9  7.8 -0.1  0.4  1.1  1.  18.7 -0.2 -0.4  6.5 -0.5 -0.3 -0.  -0.2 10.1  0.9 -0.6 12.2 -0.5 -0.2 -0.4 -3.5 -0.3 -0.6 -0.5  8.8 -0.8  7.5 -0.8 -0.6 -0.8 -0.1 -0.4 -0.4  0.1 -0.  -0.1  0.6 -0.1  2.2 -0.6 -0.8  1.5 -0.1 -0.1 -0.6  0.4  1.4  6.1 -0.3 -0.2  1.2 -0.2  8.5 -1.6 -0.2 -0.1 -0.5  0.3 -0.2 -0.1 -0.8 -0.2  1.7 -0.1 -1.2 -0.2 -0.1 -0.   8.1 -0.2 -0.5  0.1 -0.1 -0.4 -0.2 -0.9 -2.3  0.6 -0.5 -0.  -0.2  1.6 -1.6 -1.  -0.1 -0.2 -0.6 -0.1  8.8  1.7  0.2 -0.2  3.1 -0.2 10.9 -1.2 -4.7 -0.2 -0.2  0.9 -0.6 -5.7 -3.7 -0.2  0.4 -0.2 -0.7 -0.2 -0.4 -0.3 -0.1 -0.  -0.3 -0.  -0.2 -0.7 -0.2 -3.  -0.   1.2 -0.4 -0.3 -0.1 -0.1 -0.6 -0.4 -0.5 -0.1 -0.6 -0.4 -0.1 -0.1  1.7  0.5  0.4  0.1 -0.3 -0.1  0.  -0.3 -0.2 -0.1  0.4  1.4 -0.5 -2.   0.  -2.5 -0.4 -0.3 -1.4 -0.1  0.4  0.3 -0.3 -0.  -0.  -0.4  0.7 -0.3 -1.   7.2  5.5 -0.4 -0.9  0.  -0.1 -0.1  0.2 -0.3 -0.2 -0.2 -0.2 -0.1 -0.2 -1.   0.1 -0.9 -1.6 -0.5  1.2 -0.5 -0.4  2.3 -1.1  0.3 -0.  -0.  -0.  -0.3 -0.7  3.9 -0.4 -0.2  1.3  2.6 -0.  -1.  -0.4 -0.  -0.6  0.  -2.6 -0.3 -0.4  2.1  1.6  0.  -0.4 -0.1  0.3 -0.8 -1.2 -0.3 -0.2 -0.6 -0.4 -1.6 -0.   9.9 -0.5 -0.5 16.5]
ty_50sample [[7 9 5 0 8 1 6 2 4 3]
 [5 0 3 9 2 1 4 6 7 8]
 [3 6 0 1 4 7 8 9 2 5]
 [4 7 6 3 1 9 5 2 8 8]
 [3 2 8 0 6 7 1 1 5 5]
 [4 7 6 2 5 1 9 3 8 0]
 [7 3 0 9 2 5 4 1 8 6]
 [4 2 8 9 0 0 1 5 3 6]
 [1 7 5 0 3 4 9 6 2 8]
 [8 6 0 5 2 1 4 9 7 3]]
tt_50sample [[7 9 5 0 8 1 6 2 4 3]
 [5 0 3 9 2 1 4 6 7 8]
 [3 6 0 1 4 7 8 9 2 5]
 [4 7 6 3 1 9 5 2 8 0]
 [3 2 8 0 6 7 1 4 9 5]
 [4 7 6 2 5 1 9 3 8 0]
 [7 3 0 9 2 5 4 1 8 6]
 [4 2 9 8 7 0 1 5 3 6]
 [1 7 5 0 3 4 9 6 2 8]
 [8 6 0 5 2 1 4 9 7 3]]
vm  [-0.5 -0.6 -2.1  5.7 -1.5 -0.  -0.3 -0.2 -1.2  2.   5.8 -0.1 -0.2 -0.4 -2.2 -1.6 -0.3 -0.3 -0.7 -0.7 -1.7  0.4 -0.7 -0.3 -1.1  2.1  0.5 -0.1 -1.2 -4.4 -0.1 -0.3 -0.8  3.4 -0.2 -0.3  2.1 -0.2  7.1 -0.4  1.9  1.8 -0.4  1.6 -0.1 -0.4  2.4 -0.6 -2.3 -3.5 -0.2 -0.2 -0.6 -1.9 -0.2  2.1 -0.3  4.1  7.1 -2.1  6.  -0.4 -0.2 -0.2  0.8 -0.7 -0.1 -0.2 -0.1 -0.2 -0.1  6.  -0.3 -0.4 -3.1 -0.5 -0.3 -0.5 -0.2 -0.6 18.2  0.  -0.4 -1.   0.5  1.9 -1.7  0.2  0.3 -0.6 -0.1 -0.1 -0.1  0.2 -0.9 -0.8 -0.2 -2.8 -0.3 -0.5 -1.  -1.1  0.3 -0.2 -0.2  1.1 -1.3 -0.   2.3 -1.2  0.4 -0.4 -0.1 -0.3  5.5 -3.3 -0.3 -0.3  0.2 -0.1  0.4  3.6 -0.3 -0.8  0.4 -2.8 -0.2  7.3 10.4  3.2 -0.2 -0.   0.2  0.7  7.9  9.6 -0.5 -0.1  0.  -0.6 -0.4 -0.5 -0.1 -0.7  0.  -0.3 -0.2  0.4  7.6 -0.5 -1.   0.4 -2.8 -0.1 -0.2  0.2 -0.1 -0.3 -0.3 -0.   0.4 -1.4  0.4  0.2 -0.1 -0.5 -0.3 -0.4 -0.3 -0.3 -0.1 -0.2 -0.4  0.5 -0.  -2.  -0.4 -0.6 -0.6 -0.1 -1.8 -0.3 -0.3 -1.7  0.  -0.5 -0.2 -0.2  0.  11.8 -0.  -0.3 -0.4 -1.1 -2.4 -3.2 -0.5 -1.8 -0.3  0.4 -0.3 -0.1  0.9  1.5 -0.1 -0.8 -0.1 -0.3 -5.4 -0.  -0.7 -2.2 -0.6  7.6 -0.8  0.  -1.  -1.2 -0.5 -0.4 -0.1 -0.3 -0.4 -0.8 -0.8 -2.1 -2.4 -0.1  2.3 -1.  -0.4  0.8 -0.  -0.6 -0.3  2.9  0.1 -0.8  0.7 -1.2 -0.1 -1.1 -0.2 -0.1 -3.5 -1.  -0.3 -0.7 -1.2 -0.5 -4.8 -0.2  3.4  0.9  5.2 -0.2]
vy_50sample [[1 0 5 3 9 4 6 2 7 8]
 [8 1 5 4 7 3 2 6 0 9]
 [7 2 2 4 5 9 8 0 3 6]
 [9 5 5 6 7 7 3 8 2 4]
 [9 8 5 7 2 4 6 3 0 1]
 [3 2 6 6 0 8 1 5 7 4]
 [0 8 3 7 2 9 1 6 4 5]
 [2 2 9 6 8 3 1 5 4 7]
 [9 4 2 5 1 8 7 3 6 0]
 [0 8 9 5 3 1 4 2 7 6]]
vt_50sample [[1 0 5 3 9 4 6 2 7 8]
 [8 1 5 4 7 3 2 6 0 9]
 [7 2 1 4 5 9 8 0 3 6]
 [9 5 1 6 0 7 3 8 2 4]
 [9 8 5 7 2 4 6 3 0 1]
 [3 2 0 9 6 8 1 5 7 4]
 [0 3 8 7 2 9 1 6 4 5]
 [0 2 9 6 8 3 1 5 4 7]
 [9 4 2 5 1 8 7 6 3 0]
 [0 8 9 5 3 4 1 2 7 6]]
Epoch 60310: Training cost= 0.2417, Training acc= 0.8707, Validation cost= 0.2256, Validation acc= 0.8703
Epoch 60320: Training cost= 0.2280, Training acc= 0.8707, Validation cost= 0.3475, Validation acc= 0.8703
Epoch 60330: Training cost= 0.2866, Training acc= 0.8707, Validation cost= 0.3036, Validation acc= 0.8703
Epoch 60340: Training cost= 0.2450, Training acc= 0.8707, Validation cost= 0.2583, Validation acc= 0.8703
Epoch 60350: Training cost= 0.2374, Training acc= 0.8707, Validation cost= 0.1975, Validation acc= 0.8703
Epoch 60360: Training cost= 0.2098, Training acc= 0.8708, Validation cost= 0.2629, Validation acc= 0.8703
Epoch 60370: Training cost= 0.2405, Training acc= 0.8708, Validation cost= 0.1889, Validation acc= 0.8703
Epoch 60380: Training cost= 0.2075, Training acc= 0.8708, Validation cost= 0.2358, Validation acc= 0.8703
Epoch 60390: Training cost= 0.2778, Training acc= 0.8708, Validation cost= 0.2860, Validation acc= 0.8703
Epoch 60400: Training cost= 0.1945, Training acc= 0.8708, Validation cost= 0.2759, Validation acc= 0.8703
tm  [-0.2 -0.4 -0.3 -2.4 -2.2 -0.8 -0.9 -0.1 -0.1  1.4 -5.4 -0.6  0.2  0.4  5.7  4.  -1.   0.8  1.3 -2.5 -0.8 -0.4  1.9 -0.5 -0.7 -1.9 -0.8 -0.  -0.1  8.4  0.9  0.8 -0.   3.1  0.1 -0.4  1.9  4.6 20.3 -0.8 -0.7 -0.7 -0.7  3.9 -0.2  0.3  9.9 -1.  -0.3  2.6  0.6  0.1 -1.4 -2.8 -2.2 -0.6 -0.9 -1.7 -2.9 -0.8 -1.7 -0.5 -0.8 -0.1  0.2 -0.  -0.5 -0.1 -0.4 -0.4  0.2 -2.6 -0.9 -0.9 -1.2 -0.4 -0.1 -1.1 -0.4  3.6 -1.9 -0.5 -0.3  1.6 -0.4 -0.9  8.1  0.2 -0.5 -0.1 -0.4 -0.2 -0.5  0.2 -0.3  3.3 -0.8 -1.5 -0.4 -0.5  0.1  1.7  0.2 -0.2 -0.1 -0.4 -2.  -0.1 -1.  -1.8  3.3 -0.6 -0.3 -0.1 -2.3 14.2  0.3 -0.5 -0.2 -0.8 -0.4  6.5 -0.7 -1.2 -0.3  6.7  1.5  9.4 -2.8  4.  -0.3  0.1 -0.1 -0.4 -7.2 -6.9 -0.4  0.1 -0.6 -0.3 -0.9  0.3 -1.2 -0.  -0.1 -0.2 -0.8 -0.1 -0.7 -0.5  2.2 -0.1  0.1 -1.6 -0.  -0.5  0.8 -0.1 -0.7 -0.8  3.2 -1.3 -0.6 -0.1 -0.3  2.8 -0.8  1.2 -1.   0.2  0.   0.5  0.9 -0.2 -0.   2.   2.  -0.4 -2.4 -0.4 -2.  -0.6  0.3 -1.5 -0.   0.4 -0.4 -0.2 -0.3 -2.1 -0.1 -0.8 -0.4 -1.6 16.6  9.5 -0.3  7.2 -0.6 -0.1  0.2 -0.3 -0.3 -1.2 -0.1 -1.5  0.1 -0.2  3.4  1.2 -1.2  0.8 -0.5 -1.5  0.5 -0.1 -3.4 -0.4 -0.3  3.5 -0.  -0.2 -0.5 -2.  -2.1  6.   0.8  3.5  4.2  0.  -1.6  4.2 -0.5  0.6 -2.1  0.9 -0.  -0.7 -0.4 -0.2 -0.3 -0.6 -0.4 -0.3  6.9 -0.5  0.2  0.8 -0.6 -1.   4.7 -0.  10.8 -0.4  1.8 -0.1]
ty_50sample [[4 7 8 3 5 9 2 1 6 0]
 [2 0 6 8 9 5 1 3 4 7]
 [6 9 0 5 8 2 7 3 4 1]
 [0 5 9 3 8 2 6 4 7 1]
 [5 2 1 3 0 4 9 6 7 8]
 [2 7 9 0 4 3 8 1 6 5]
 [9 2 7 5 4 3 1 8 6 0]
 [3 6 1 7 9 0 5 4 8 2]
 [3 8 9 0 2 4 7 6 5 1]
 [8 5 4 1 6 2 3 7 9 0]]
tt_50sample [[4 7 8 3 5 9 2 6 1 0]
 [2 0 6 8 9 5 1 3 4 7]
 [6 9 0 5 8 2 7 3 4 1]
 [0 5 9 3 8 2 4 6 7 1]
 [5 2 1 3 0 4 9 6 7 8]
 [2 7 9 0 4 3 8 1 6 5]
 [9 2 7 5 4 3 1 8 6 0]
 [3 1 6 7 9 0 5 4 8 2]
 [3 8 9 0 2 4 7 6 5 1]
 [8 5 4 1 6 2 3 7 9 0]]
vm  [-0.5 -0.   6.6  2.7 -1.2  0.3 -0.1 -0.2 -0.4 -0.4  8.  -0.2  0.  -0.2  7.9  1.2 -0.3 -0.2 -0.2  0.6 -1.7 -0.2 -0.5 -0.1 -1.  -0.1 -0.2 -0.1 -0.4 -2.5 -0.1 -0.4 -0.1  6.  -0.3  0.5 -0.  -1.  -7.4 -0.2  0.4 -1.9 -0.8 -1.4 -0.  -0.3 -1.8 -0.4 -1.5 -3.1 -0.4 -0.1 -0.2 14.5 -0.7 -1.1 -0.4  4.7  9.1  4.8  9.8 -0.6 -0.2 -0.3  1.2 -0.5 -0.2 -0.3 -0.  -0.2 -0.1 -0.4 -0.  -0.8 -5.1 -0.3  0.1  0.5  0.2 -0.9 -1.1 -0.3 -0.1 -0.2  1.1 -1.4 -2.9 -0.3 -0.   0.  -0.4 -0.  -0.2 -0.3 -1.1  0.  -0.4 -4.3  0.4 -0.3  1.7 -1.  -0.2 -0.3 -0.2 -0.6 -3.  -0.6 -0.3  1.7 -0.3 -0.1 -0.  -0.9  2.6  3.1 -0.  -0.2 -0.2 -0.4 -0.1 -1.1 -0.4 -0.6 -0.3  9.7 -0.1 -2.6  9.1 15.7 -0.3 -0.4 -0.2 -0.4 13.4 20.7 -0.3 -0.3 -0.  -0.5 -0.2 -0.1 -0.2 -0.   0.4  0.3 -0.1 -0.1  0.4 -0.1 -0.6 -0.3 -1.4  1.1 -0.1  0.4 -0.  -0.5 -1.3 -0.3 -0.5  1.1 -0.2 -0.2  0.   0.3 -0.2 -0.4  0.1 -0.3 -0.1 -0.2 -0.4 -0.4  0.5  0.8 -1.4 -0.4  6.8 -0.1 -0.6 -0.2 -0.2 -2.  -0.3  0.  -0.2 -0.9 -0.1  6.8 -0.4 -0.2 -0.4 -1.  -4.9 -3.1 -0.6 -0.8 -0.2 -0.1 -0.2  0.1 -0.2 -0.  -0.4 -4.  -0.  -0.  -1.1 -0.2 -0.7 -0.5 -0.7  5.9 -1.   1.6 10.1 -1.4  0.  -0.  -0.  -0.3  1.1 -1.   2.2 -0.3 -0.8 -0.3  0.9 -0.   0.2  1.3 -0.1 -0.3 -0.7 -1.4  0.1 -0.7  2.7 -3.1 -0.  -1.7  0.3 -0.1  4.8  3.9  0.4 -0.7 -1.2  0.1  1.9 -0.3 -3.9 -0.2  3.9 -3.7]
vy_50sample [[6 1 3 2 0 7 8 8 9 4]
 [7 3 2 6 8 0 5 1 9 4]
 [4 9 3 7 0 6 5 8 2 1]
 [7 1 9 5 3 0 6 8 2 4]
 [6 0 9 2 4 1 5 8 8 3]
 [1 4 6 2 5 7 8 3 9 0]
 [5 1 7 6 8 0 3 2 9 4]
 [9 0 5 1 8 4 7 3 6 2]
 [6 3 3 8 8 0 2 5 9 4]
 [5 5 1 9 3 0 4 7 6 2]]
vt_50sample [[6 1 3 2 0 5 7 8 9 4]
 [7 3 2 6 8 0 5 1 9 4]
 [4 9 3 7 0 6 5 8 2 1]
 [7 1 9 5 3 0 6 2 8 4]
 [6 0 9 2 4 1 5 7 8 3]
 [1 4 6 2 5 7 8 3 9 0]
 [5 1 7 6 8 0 3 2 9 4]
 [9 0 5 8 1 4 7 3 6 2]
 [6 1 3 8 0 7 2 5 9 4]
 [8 5 1 9 0 3 4 7 6 2]]
Epoch 60410: Training cost= 0.2145, Training acc= 0.8708, Validation cost= 0.2184, Validation acc= 0.8703
Epoch 60420: Training cost= 0.2233, Training acc= 0.8708, Validation cost= 0.2994, Validation acc= 0.8703
Epoch 60430: Training cost= 0.2070, Training acc= 0.8708, Validation cost= 0.2314, Validation acc= 0.8703
Epoch 60440: Training cost= 0.1738, Training acc= 0.8708, Validation cost= 0.2512, Validation acc= 0.8703
Epoch 60450: Training cost= 0.1852, Training acc= 0.8708, Validation cost= 0.2715, Validation acc= 0.8703
Epoch 60460: Training cost= 0.2451, Training acc= 0.8708, Validation cost= 0.2180, Validation acc= 0.8703
Epoch 60470: Training cost= 0.2992, Training acc= 0.8708, Validation cost= 0.2488, Validation acc= 0.8703
Epoch 60480: Training cost= 0.2491, Training acc= 0.8708, Validation cost= 0.3052, Validation acc= 0.8704
Epoch 60490: Training cost= 0.2092, Training acc= 0.8708, Validation cost= 0.2481, Validation acc= 0.8704
Epoch 60500: Training cost= 0.2496, Training acc= 0.8709, Validation cost= 0.2542, Validation acc= 0.8704
tm  [ 0.5 -0.  -1.3 19.7 -1.   0.2 -0.2  0.  -0.6 -0.1  7.1 -0.3 -0.   0.2 -4.  -0.3 -0.5 -0.3 -0.7 -1.  -1.5 -0.4  1.7 -0.1 -0.7  1.6 -0.2 -0.3 -0.8 -5.4 -0.4 -0.1 -0.3 -3.2 -0.1  0.3  0.1  6.4 19.1 -0.4  4.4  1.  -0.8 -0.2  0.1 -0.1  8.2 -0.   4.9  2.6 -0.2  0.1 -0.2 -0.3  1.1  4.6 -0.2  4.3  9.4  3.9 -1.8 -0.8  1.2 -0.1  0.9 -0.1 -0.1 -0.2 -1.  -0.2 -0.   3.8 -0.5 -0.2  1.  -0.7 -0.1 -0.1  0.3 -0.2 15.9  0.3 -0.2 -0.6 -1.3  2.9  1.8  0.1 -0.  -0.3  0.4 -0.1 -0.2 -1.1 -0.8  0.2  0.7 -2.2 -0.2 -0.1 -0.3 -1.2 -0.5 -0.2 -0.2 -0.4 -0.1 -0.2 -0.2 -1.6 -0.2  0.2 -0.2 -0.5  6.1 -2.3 -0.5 -0.2 -0.2 -0.4 -0.4  5.2  0.3 -0.3 -0.2 -5.1 -0.1  2.6 10.3 -3.  -0.2 -0.3 -0.3 -0.5  5.5 -1.7 -0.1  0.   1.4 -0.3 -0.3 -0.5 -0.7 -0.  -0.1 -0.2 -0.1 -0.2  7.7 -0.1 -2.5  0.3  2.8 -0.4  0.4 -0.  -0.7  0.4  1.1 -0.2 -0.6 -1.1 -0.2 -0.3  1.1 -0.1 -0.  -0.5 -0.1 -0.2 -0.  -0.1 -0.1 -0.1 -0.2 -1.5 -0.6 -0.3 -1.7 -0.2 -1.6 -0.1 -0.4 -1.9 -0.1 -0.5  0.2 -0.2 -0.1 15.  -0.  -0.   0.2 -0.8 15.2 -3.7 -0.2 -2.2 -0.1  0.2 -0.3 -0.2 -0.4 -0.4 -0.1  1.  -0.1 -0.1 -1.2 -0.  -0.2 -1.  -0.5 -1.9 -1.6 -0.8 -0.6 -1.9 -0.4 -0.4 -0.  -0.1  0.8 -1.6 -1.2 -0.9  0.   0.7 -0.7 -0.1 -0.5 -1.2 -0.2 -0.3  0.5  0.5 -0.2 -0.3  5.6 10.6 -0.1  2.4  0.5 -0.  -2.9 -2.3 -0.4 -0.4 -1.2  1.7 -4.4  0.  10.3 -0.2 -0.2 11.5]
ty_50sample [[9 0 2 5 8 3 4 1 6 7]
 [6 1 1 5 4 9 2 7 3 0]
 [7 4 5 0 8 2 6 3 9 1]
 [7 3 2 9 5 6 8 0 1 4]
 [4 0 8 6 3 7 2 9 5 1]
 [7 6 9 8 2 3 1 5 4 0]
 [4 5 9 2 3 6 0 8 1 7]
 [1 3 7 4 6 0 9 2 8 5]
 [5 7 1 6 8 3 0 9 4 2]
 [1 3 6 8 5 7 4 2 9 0]]
tt_50sample [[9 0 2 5 8 3 1 4 6 7]
 [6 1 8 5 4 9 2 7 3 0]
 [7 4 5 0 8 2 6 9 3 1]
 [7 3 2 9 5 6 8 0 1 4]
 [4 0 8 6 3 7 2 9 5 1]
 [7 6 9 8 2 3 1 5 4 0]
 [4 5 9 2 3 0 6 8 1 7]
 [1 3 7 4 6 0 9 2 8 5]
 [5 7 1 6 8 3 0 9 4 2]
 [1 3 6 8 5 7 4 2 9 0]]
vm  [-0.9 -0.1 -0.2 -0.4 -2.2 -0.1 -0.3 -0.1 -0.4 -0.6 -2.4 -0.1 -0.2 -0.1  2.  -0.9 -0.2 -0.3 -0.1 -0.1 -1.7 -0.  -0.3 -0.1 -1.6  3.3 -0.2 -0.2 -0.5 -2.4  1.1 -0.1 -0.7 -0.3  0.2 -0.1  0.9 -1.6 -2.6 -0.1 -0.6 -2.1 -0.6 -0.9 -0.2 -0.1 -0.8 -0.  -1.2 -0.4 -0.1 -0.  -0.1 -0.8 -0.7 -0.3 -0.3 -0.3  5.1  1.5  7.8 -0.3 -0.2 -0.1  0.9 -0.2 -0.2 -0.1  1.9 -0.1 -0.1  0.1  0.7  1.3 -3.  -0.6 -0.1 -0.1  0.2 -0.4 -0.8 -0.3  0.  -0.4  1.5 -1.9 -1.7 -0.1 -0.1 -0.2 -0.3 -0.2 -0.1 -0.9 -1.1 -0.2 -0.1 -3.8 -0.4 -0.2  2.  -0.9 -0.2 -0.1 -0.1  1.8 -1.2 -0.1 -0.6 -0.  -0.2  0.  -0.1 -0.4  4.4  2.5 -1.  -0.4 -0.2 -0.3 -0.3  0.5 -0.  -0.1 -0.2  2.8 -0.2  4.6  3.9  5.4  0.3 -0.3 -0.3 -0.4  8.8  8.3  0.3 -0.1  1.3 -0.1  0.9 -0.2  0.2 -0.1 -0.1 -0.1 -0.2 -0.  -0.4  0.2  0.2 -0.1 -0.9  1.6 -0.1 -0.  -0.7  1.9 -0.6 -0.4 -0.5 -0.1 -0.  -0.   0.2 -0.2  1.  -0.1  0.6 -0.  -0.1 -0.1 -0.1 -0.  -0.3  1.5 -0.7 -0.2  2.2 -0.1 -0.2  0.6 -0.1 -2.7 -0.1 -0.2 -0.4 -0.3 -0.1  6.9 -0.1  0.1 -0.2 -1.5 -2.9 -1.3 -0.  -1.3 -0.1 -0.1 -0.3 -0.3 -0.5 -0.2 -0.  -1.7 -0.3 -0.   6.5 -0.1 -0.4 -0.5 -0.5 10.2 -0.8 -0.4  3.6 -1.4 -0.2 -0.1 -0.1  0.3  0.1 -0.9  2.   0.2 -2.2  1.6 -0.1 -0.3 -0.1 -0.6 -0.2  0.5  0.1  0.3 -0.4 -0.   4.5  6.2 -0.1  0.6  0.3  0.   4.7 -0.2 -0.5 -0.3 -1.8  2.3  1.2 -0.3 -1.2 -0.2  8.5 -0.7]
vy_50sample [[1 6 3 0 8 4 7 9 5 2]
 [9 4 3 2 5 1 0 8 7 6]
 [6 6 2 8 3 1 9 4 5 7]
 [9 6 7 7 5 1 4 3 2 8]
 [8 6 0 3 7 2 1 9 4 5]
 [7 0 2 3 9 1 8 4 6 5]
 [4 1 0 6 3 9 8 5 7 2]
 [1 7 5 3 8 2 0 6 9 4]
 [3 8 4 6 9 5 0 1 2 7]
 [4 2 3 1 7 9 8 5 6 0]]
vt_50sample [[1 6 3 0 8 4 7 9 5 2]
 [9 4 3 2 5 0 1 8 7 6]
 [0 6 2 8 3 1 9 4 5 7]
 [9 6 0 7 5 1 4 3 2 8]
 [8 6 0 3 7 2 1 9 4 5]
 [7 0 2 3 9 1 8 4 6 5]
 [4 1 0 6 3 9 8 5 7 2]
 [1 7 5 3 8 2 0 6 9 4]
 [3 8 4 6 9 5 0 1 2 7]
 [4 2 3 1 7 9 8 5 6 0]]
Epoch 60510: Training cost= 0.1966, Training acc= 0.8709, Validation cost= 0.2385, Validation acc= 0.8704
Epoch 60520: Training cost= 0.2201, Training acc= 0.8709, Validation cost= 0.1911, Validation acc= 0.8704
Epoch 60530: Training cost= 0.2330, Training acc= 0.8709, Validation cost= 0.3003, Validation acc= 0.8704
Epoch 60540: Training cost= 0.1990, Training acc= 0.8709, Validation cost= 0.2223, Validation acc= 0.8704
Epoch 60550: Training cost= 0.2209, Training acc= 0.8709, Validation cost= 0.2837, Validation acc= 0.8704
Epoch 60560: Training cost= 0.2017, Training acc= 0.8709, Validation cost= 0.2475, Validation acc= 0.8704
Epoch 60570: Training cost= 0.1975, Training acc= 0.8709, Validation cost= 0.1748, Validation acc= 0.8704
Epoch 60580: Training cost= 0.2075, Training acc= 0.8709, Validation cost= 0.2314, Validation acc= 0.8704
Epoch 60590: Training cost= 0.2057, Training acc= 0.8709, Validation cost= 0.2026, Validation acc= 0.8704
Epoch 60600: Training cost= 0.2001, Training acc= 0.8709, Validation cost= 0.2363, Validation acc= 0.8704
tm  [ 0.3 -0.   6.3 -3.  -2.3 -0.2 -0.3 -0.2 -0.7  1.3 -7.2  0.1 -0.2 -0.3 15.6 -1.7 -0.5 -0.1 -0.6 -0.1 -1.1 -0.4 -0.6 -0.1 -1.4  0.4 -0.1 -0.2 -0.9  4.2 -0.3 -0.1 -0.4  3.  -0.3 -0.1  0.8 -1.2 -4.5 -0.3  0.7  7.7  0.9 -0.2 -0.1 -0.7 -1.7 -0.4  4.6  8.7 -0.3 -0.  -0.5  0.5 -0.5 -2.  -0.9  7.5 -1.1  4.5  3.3 -0.9 -0.5 -0.3 -0.7 -0.2  0.6 -0.3  0.7  0.  -0.1  5.4 -0.5 -0.9 -5.3 -0.1  0.  -0.5 -0.2  0.9 -7.1 -0.  -0.3 -0.3 -1.5  6.5  4.2 -0.4  1.2 -0.3 -0.3  0.2 -0.  -0.1 -0.7  0.3 -0.2 -3.8 -0.3 -0.2 -0.1  4.6 -0.7 -0.3 -0.   0.7 -2.6 -0.4 -2.   2.4  0.6 -0.3 -0.1 -0.1  1.5 -3.2 -0.2 -0.5 -0.1 -0.4 -0.2 -0.9 -0.3 -0.5 -0.4 19.9  0.1  2.1 -1.   6.2  0.8 -0.2 -0.2 -0.2 -1.4 -1.2 -0.1 -0.1 -0.3 -0.5  0.6 -0.3 -0.4 -0.2  0.3 -0.2 -0.4 -0.1  4.1 -0.4  2.4 -0.2  2.  -0.3 -0.   0.  -0.6 -0.2 -0.6 -0.3 -0.1 -0.5 -0.2 -0.2 -0.1  0.7 -0.1 -0.2 -0.4 -0.2 -0.1 -0.1 -0.4 -0.5 -0.1 -0.6 -1.  -0.   3.9 -0.1 -2.6 -0.5 -0.2 -2.2 -0.2 -0.1 -0.1 -0.4 -0.2 -1.  -0.5 -0.   0.7 -1.1 -0.8  4.  -0.7 -0.7  0.3 -0.   0.1 -0.2  0.2 -0.2 -0.6 -3.4 -0.  -0.3 -1.8 -0.4 -0.4 -1.9 -0.5 -1.5 -0.5 -0.4  2.1 -0.9 -0.4 -0.1  0.1 -0.3 -0.3 -1.6  2.8 -0.9 -1.4 -0.2  3.8 -0.2 -0.6  1.9 -0.3 -0.3 -0.5 -1.2  0.  -0.4  1.  -9.  -0.1 -3.8 -0.1 -0.1 19.8  3.2 -0.2 -0.3 -1.1 -0.1 18.8  0.3 -2.3 -0.2  4.3 -0.8]
ty_50sample [[5 0 7 8 6 4 3 1 9 2]
 [8 9 6 5 0 1 4 7 3 2]
 [3 5 6 0 9 4 7 2 1 8]
 [9 8 1 6 7 0 5 3 4 2]
 [1 7 2 8 0 9 6 3 5 4]
 [2 4 0 3 1 7 6 5 8 9]
 [7 8 2 0 9 4 5 1 6 3]
 [1 5 6 0 7 2 2 4 3 9]
 [4 7 0 8 1 2 5 9 6 3]
 [4 0 2 8 6 3 9 1 7 5]]
tt_50sample [[5 0 7 8 6 4 3 1 9 2]
 [8 9 6 5 0 1 4 7 3 2]
 [3 5 6 9 0 4 7 2 1 8]
 [9 8 1 6 7 0 5 3 4 2]
 [1 7 2 0 8 9 6 3 5 4]
 [2 4 0 3 1 7 6 5 8 9]
 [7 8 2 0 9 4 5 1 6 3]
 [1 5 6 0 7 8 2 4 3 9]
 [4 7 0 8 1 2 5 9 6 3]
 [4 0 2 8 6 3 9 1 7 5]]
vm  [-0.1 -0.4 12.3  0.8 -1.9 -0.1 -0.2  0.6 -0.3 -0.1 -3.7 -0.1 -0.2 -0.6 18.4 -0.7 -0.4  0.8 -1.2  1.8 -0.9 -0.5 -0.2 -0.1 -1.1  1.1 -0.1 -0.  -0.6  0.6 -0.8 -0.4 -0.7  5.  -0.1 -0.2 -0.5 -0.2 -3.7 -0.3 -0.4  5.6 -0.  -1.   0.3 -0.2 -2.9 -0.3  8.1  7.  -0.3 -0.1  0.   8.2 -1.1 -2.5 -0.7 12.6  1.5  8.6  4.1 -0.8  0.1 -0.4 -1.1 -0.3 -0.1  0.   1.3 -0.2 -0.2  1.3  0.3  0.1 -5.7 -0.3  0.6  0.4 -0.3 -0.3 -7.4 -0.1 -0.3 -0.4 -1.8  5.2 -0.3 -0.6  0.2 -0.3 -0.2  0.2 -0.3 -0.8 -1.  -0.2 -0.3 -4.2  0.  -0.2 -0.   4.1 -0.8 -0.3 -0.3  0.3 -2.2 -0.2 -1.   3.7  0.2 -0.3 -0.1 -0.4  1.4 -0.6 -1.2  0.2 -0.1 -0.5  0.3 -1.6 -0.5 -0.8 -0.4 23.5 -0.2 -1.2  1.9  8.6  1.  -0.1 -0.5 -0.2 -3.  -2.2 -0.5 -0.4  0.2 -0.1  0.2 -0.5 -0.3 -0.  -0.1  0.1 -0.6 -0.3  2.3 -0.3 -0.7 -0.5  2.3  1.  -0.1  0.6 -0.8 -0.4 -0.3  0.6 -0.2 -0.5 -0.4 -0.2 -0.7 -0.1 -0.5 -0.4 -0.5 -0.2 -0.2 -0.5 -0.5 -0.7  0.3 -0.3 -0.6  0.9  2.7  0.2 -2.2 -0.4 -0.2 -2.3 -0.3 -0.2  0.3 -0.4 -0.4 -0.1 -0.2 -0.2  0.6 -0.8 -1.5 -0.6 -0.  -0.6  1.3 -0.1 -0.1 -0.2 -0.3 -0.2 -0.3 -2.8 -0.1 -0.4 -1.4 -0.2 -0.4 -0.6 -0.8 -1.6 -0.4 -0.2  6.2 -1.  -0.4 -0.4  0.1 -0.2 -0.9 -1.3  2.5  1.4 -1.5 -0.3  1.2 -0.1 -0.7 -0.2 -0.2 -0.  -0.5 -2.9 -0.4  0.2  2.4 -8.8 -0.2 -3.8 -0.3 -0.1 20.4  2.1 -0.8 -0.2 -1.   0.6 18.8  0.9 -2.  -0.2  3.6 -1.8]
vy_50sample [[5 7 8 0 6 3 2 1 4 9]
 [2 5 8 7 6 4 3 9 0 1]
 [9 2 8 1 6 7 0 4 3 5]
 [7 9 5 2 8 6 1 0 4 3]
 [9 6 5 3 4 7 8 1 0 2]
 [1 5 2 9 9 7 6 0 8 3]
 [9 7 4 1 2 5 3 0 8 6]
 [8 0 4 2 7 1 9 6 5 3]
 [7 9 3 1 4 6 5 8 0 2]
 [9 6 1 3 5 7 8 0 2 4]]
vt_50sample [[5 7 8 0 6 3 2 1 4 9]
 [2 5 8 6 7 4 3 9 0 1]
 [9 2 8 1 6 7 0 4 3 5]
 [7 9 5 2 8 6 1 0 4 3]
 [9 6 5 3 4 7 8 1 0 2]
 [1 2 5 4 9 7 0 6 8 3]
 [9 7 4 1 2 5 3 0 8 6]
 [8 0 4 2 1 7 9 6 5 3]
 [7 9 3 1 4 6 5 8 0 2]
 [9 6 1 3 5 7 8 0 2 4]]
Epoch 60610: Training cost= 0.1897, Training acc= 0.8709, Validation cost= 0.2761, Validation acc= 0.8704
Epoch 60620: Training cost= 0.2015, Training acc= 0.8709, Validation cost= 0.2454, Validation acc= 0.8704
Epoch 60630: Training cost= 0.2035, Training acc= 0.8710, Validation cost= 0.2755, Validation acc= 0.8704
Epoch 60640: Training cost= 0.2159, Training acc= 0.8710, Validation cost= 0.2401, Validation acc= 0.8705
Epoch 60650: Training cost= 0.1710, Training acc= 0.8710, Validation cost= 0.2078, Validation acc= 0.8705
Epoch 60660: Training cost= 0.1824, Training acc= 0.8710, Validation cost= 0.1847, Validation acc= 0.8705
Epoch 60670: Training cost= 0.2673, Training acc= 0.8710, Validation cost= 0.2589, Validation acc= 0.8705
Epoch 60680: Training cost= 0.2164, Training acc= 0.8710, Validation cost= 0.2740, Validation acc= 0.8705
Epoch 60690: Training cost= 0.2703, Training acc= 0.8710, Validation cost= 0.2435, Validation acc= 0.8705
Epoch 60700: Training cost= 0.2238, Training acc= 0.8710, Validation cost= 0.2636, Validation acc= 0.8705
tm  [-0.5 -0.3 12.4 16.5 -1.4 -0.1 -0.3  0.  -0.5 -0.6 -4.  -0.1 -0.  -0.   7.8  0.6 -0.2 -0.2 -1.3 -0.4 -1.2  0.1  2.3 -0.3 -0.4 -0.2 -0.2 -0.7 -0.6  3.6 -1.2 -0.1  0.7 -0.4 -0.  -0.3  2.2  3.8  5.7 -0.8  4.1 -0.5  1.6 -0.  -0.3  0.3  0.3 -0.2  3.1  2.6 -0.2 -0.2 -0.3  0.3 -1.2 -1.  -0.8 10.3 -2.9 11.1 -0.1 -0.5 -0.3 -0.1 -1.  -0.5 -0.4 -0.1  1.3 -0.  -0.2  0.7  0.8  1.1 -2.3 -0.8 -0.2 -0.6 -0.1  1.7 -3.9 -0.3 -0.  -0.5 -1.4 -0.8 -0.8  0.1 -0.3 -0.2 -0.4 -0.  -0.2  0.9 -0.4  0.4 -0.3 -2.4 -0.3 -0.4  2.   0.8  0.9 -0.3 -0.  -0.2 -1.5 -0.  -0.8 -1.5 -1.  -0.2 -0.2 -0.  -1.6  1.8 -0.3 -0.8  0.4 -0.4  0.4  4.7 -0.1 -0.8 -0.  10.2 -0.3  1.2 -2.6  9.3 -0.2 -0.1  0.8  0.8 -4.8 -4.9 -0.2 -0.1 -0.4 -0.1 -0.4 -0.  -0.5 -0.1 -0.2 -0.2 -0.2 -0.1 -0.1 -0.1 -2.4  0.4  2.1 -0.6 -0.2 -0.3 -0.3  2.2  1.4 -0.7 -0.1 -0.7 -0.3  0.  -0.4  0.7 -0.3 -0.2 -0.3  0.1  0.2 -0.1  0.4  0.  -0.  -0.1 -0.4 -0.1 -0.7  0.1 -2.2 -0.4 -0.3 -1.3  0.1 -0.2 -0.2 -0.3 -0.2 -0.8  0.  -0.1 -0.2 -0.9  4.7 10.3 -0.2  4.7 -0.1 -0.1 -0.   0.  -0.4 -0.4 -0.3 -1.6 -0.3 -0.1  3.9 -0.2 -0.5 -0.7 -0.6 -0.8  0.1 -0.6  1.9 -1.  -0.2 -0.1 -0.  -0.2 -1.  -1.3 -2.3  1.7 -0.5 -0.4 -0.1 -0.1 -0.2  0.2 -0.1  1.  -0.3 -2.5 -0.3 -0.4  0.3 -2.3 -0.3 -1.4 -0.1 -0.1 11.6 -0.2 -0.7  2.2 -1.  -0.3  8.8 -0.2  3.1 -0.   5.5 -1.7]
ty_50sample [[8 3 5 5 0 9 2 1 6 4]
 [2 0 4 6 7 3 5 9 1 8]
 [2 3 6 9 7 4 1 8 0 5]
 [3 9 2 0 6 8 5 7 4 1]
 [4 5 8 7 2 9 9 3 1 0]
 [0 6 5 9 8 8 1 7 2 4]
 [1 2 7 9 3 4 8 0 5 6]
 [0 5 9 6 3 7 1 2 4 8]
 [6 9 0 4 1 2 7 8 3 5]
 [9 3 5 1 2 0 6 8 4 7]]
tt_50sample [[8 7 3 5 0 2 9 1 6 4]
 [2 0 4 6 7 3 5 9 1 8]
 [2 3 6 9 7 4 1 8 0 5]
 [3 9 2 0 6 8 5 7 4 1]
 [4 5 8 7 2 6 9 3 1 0]
 [0 6 5 9 8 3 1 7 2 4]
 [1 2 7 9 3 4 8 0 5 6]
 [0 5 9 6 3 7 1 2 4 8]
 [6 9 0 4 1 2 7 8 3 5]
 [9 3 5 1 2 0 6 8 4 7]]
vm  [-0.6 -0.2 -1.9 -1.1 -1.8 -0.1 -0.4 -0.1 -1.5 -0.8  5.3 -0.3 -0.  -0.1 -0.4 -1.  -0.1 -0.3 -0.7  0.7 -1.7 -0.4 -0.7 -0.1 -1.3  3.9 -0.1 -0.3 -1.3 -1.8  0.7  0.1 -0.4  0.4 -0.1 -0.3  4.3 -0.  -1.2 -0.3  2.   0.2  2.6  0.6 -0.1  0.1 -0.8 -0.3 -0.1 -3.7 -0.1  0.  -0.5  3.7  1.3 -0.2 -0.6  6.7 -0.7 -1.2  3.  -0.7 -0.3 -0.1 -0.3  0.5 -0.3 -0.2  0.3 -0.2 -0.2  5.2 -0.   0.6 -2.7 -0.8 -0.  -0.4  0.  -0.3  4.5 -0.2 -0.3 -0.6 -0.2 -0.4  0.5 -0.1 -0.1 -0.2 -0.3 -0.1 -0.1  1.3 -0.8 -0.5  0.5 -3.2  0.4 -0.5  3.3 -2.  -0.3 -0.  -0.   1.  -1.8 -0.   1.6 -0.1 -0.7 -0.2 -0.2  0.4 -0.3 -2.2 -0.3 -1.5 -0.2 -0.3 -0.4  1.   0.1  1.2  0.2 -0.4 -0.1 -0.1  1.9 12.7 -0.3 -0.2 -0.5 -0.1  8.1  8.2 -0.2 -0.1  1.  -0.3  0.1 -0.3 -0.3 -0.2 -0.2  0.1 -0.1  0.1  8.5 -0.2  0.6  0.  -0.5  1.7  0.3 -0.1 -0.2  1.9  0.1 -0.3 -0.5 -0.6 -0.2  0.  -0.1 -0.6  0.9 -0.3 -0.1  0.1 -0.  -0.   0.6 -0.1 -0.  -1.9 -0.4 -0.4  1.1 -0.1 -2.  -0.1 -0.2 -2.4 -0.1 -0.4 -0.3 -0.1 -0.   5.2  0.5 -0.  -0.1 -1.4 -0.7 -0.3 -0.5  0.9 -0.2 -0.1 -0.2  0.4 -0.3 -0.3  0.2 -2.6 -0.1 -0.1 -4.7  0.8  0.4 -2.1 -0.8  4.  -0.8 -0.5 -0.2 -1.1 -0.4 -0.3  0.1 -0.2 -0.  -1.1 -1.5 -1.2 -1.4  0.5  0.3 -0.3 -0.1 -0.  -0.2 -0.6  2.9  1.6 -0.3 -0.1  2.3 -4.5 -0.  -2.2 -0.  -0.1 -0.3  1.4 -0.4 -0.2 -1.5  0.1 -1.3 -0.2 -0.5 -0.2  8.4 -2.5]
vy_50sample [[3 5 0 1 6 4 2 9 8 7]
 [9 3 4 6 8 0 5 1 2 7]
 [1 2 8 3 7 6 9 4 5 0]
 [7 5 6 8 9 1 2 4 0 3]
 [4 1 7 0 3 5 8 2 6 9]
 [5 9 1 4 2 8 0 6 3 7]
 [8 2 4 1 3 6 9 7 0 5]
 [3 6 8 7 9 2 5 1 0 4]
 [8 0 5 9 6 3 7 4 1 2]
 [9 3 2 8 0 6 7 5 4 1]]
vt_50sample [[3 5 0 1 6 4 2 9 8 7]
 [9 3 4 6 0 8 5 1 2 7]
 [1 2 8 3 7 6 9 4 5 0]
 [7 5 6 8 9 1 2 4 0 3]
 [4 1 7 0 3 5 8 2 6 9]
 [5 9 1 4 2 8 0 6 3 7]
 [8 2 4 1 3 9 6 7 0 5]
 [3 6 8 7 9 2 5 1 0 4]
 [8 0 5 9 6 3 7 4 1 2]
 [9 3 2 8 0 6 7 5 4 1]]
Epoch 60710: Training cost= 0.3038, Training acc= 0.8710, Validation cost= 0.2273, Validation acc= 0.8705
Epoch 60720: Training cost= 0.3557, Training acc= 0.8710, Validation cost= 0.3256, Validation acc= 0.8705
Epoch 60730: Training cost= 0.4096, Training acc= 0.8710, Validation cost= 0.2609, Validation acc= 0.8705
Epoch 60740: Training cost= 2.3026, Training acc= 0.8710, Validation cost= 2.3026, Validation acc= 0.8705
Epoch 60750: Training cost= 2.3026, Training acc= 0.8709, Validation cost= 2.3026, Validation acc= 0.8703
Epoch 60760: Training cost= 2.3026, Training acc= 0.8707, Validation cost= 2.3026, Validation acc= 0.8702
Epoch 60770: Training cost= 2.3026, Training acc= 0.8706, Validation cost= 2.3026, Validation acc= 0.8701
Epoch 60780: Training cost= 2.3026, Training acc= 0.8705, Validation cost= 2.3026, Validation acc= 0.8700
Epoch 60790: Training cost= 2.3026, Training acc= 0.8703, Validation cost= 2.3026, Validation acc= 0.8698
Epoch 60800: Training cost= 2.3026, Training acc= 0.8702, Validation cost= 2.3026, Validation acc= 0.8697
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 9 3 7 2 1 8 5 4 0]
 [9 4 3 0 7 1 6 5 2 8]
 [9 1 0 2 6 4 5 8 3 7]
 [9 6 7 4 2 5 8 1 3 0]
 [4 1 8 2 3 6 9 5 0 7]
 [5 6 1 9 2 4 3 7 8 0]
 [6 3 9 7 1 4 2 8 0 5]
 [2 8 3 4 1 9 5 7 6 0]
 [5 7 8 9 4 0 2 6 3 1]
 [0 5 6 2 7 9 8 4 3 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 7 0 3 8 1 9 5 4 2]
 [3 6 9 4 1 5 8 0 2 7]
 [7 3 6 2 9 8 5 4 1 0]
 [4 2 0 6 1 8 9 3 5 7]
 [4 8 5 0 6 7 2 3 1 9]
 [9 2 8 1 7 3 0 4 5 6]
 [7 6 0 4 9 1 8 3 5 2]
 [3 4 6 5 9 2 7 0 8 1]
 [2 1 7 9 4 3 5 8 6 0]
 [0 4 5 6 8 9 3 1 7 2]]
Epoch 60810: Training cost= 2.3026, Training acc= 0.8701, Validation cost= 2.3026, Validation acc= 0.8696
Epoch 60820: Training cost= 2.3026, Training acc= 0.8700, Validation cost= 2.3026, Validation acc= 0.8694
Epoch 60830: Training cost= 2.3026, Training acc= 0.8698, Validation cost= 2.3026, Validation acc= 0.8693
Epoch 60840: Training cost= 2.3026, Training acc= 0.8697, Validation cost= 2.3026, Validation acc= 0.8692
Epoch 60850: Training cost= 2.3026, Training acc= 0.8696, Validation cost= 2.3026, Validation acc= 0.8691
Epoch 60860: Training cost= 2.3026, Training acc= 0.8695, Validation cost= 2.3026, Validation acc= 0.8689
Epoch 60870: Training cost= 2.3026, Training acc= 0.8693, Validation cost= 2.3026, Validation acc= 0.8688
Epoch 60880: Training cost= 2.3026, Training acc= 0.8692, Validation cost= 2.3026, Validation acc= 0.8687
Epoch 60890: Training cost= 2.3026, Training acc= 0.8691, Validation cost= 2.3026, Validation acc= 0.8686
Epoch 60900: Training cost= 2.3026, Training acc= 0.8690, Validation cost= 2.3026, Validation acc= 0.8684
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 7 1 8 6 2 9 4 0 5]
 [4 1 7 6 0 9 3 8 2 5]
 [4 1 3 8 9 0 2 6 7 5]
 [5 8 6 3 0 2 1 4 7 9]
 [4 6 7 2 1 0 5 3 9 8]
 [0 2 7 3 9 1 4 8 6 5]
 [0 5 7 2 4 8 3 1 9 6]
 [5 1 9 0 7 3 8 6 2 4]
 [2 0 4 7 1 9 8 3 6 5]
 [2 7 4 6 9 5 0 1 8 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 7 4 1 8 0 6 5 9 3]
 [9 7 4 3 2 0 8 5 1 6]
 [0 4 5 2 8 6 7 3 9 1]
 [5 7 2 1 9 0 3 8 6 4]
 [4 3 0 1 2 6 7 9 5 8]
 [9 2 6 7 1 3 5 8 4 0]
 [0 7 8 9 6 2 1 5 4 3]
 [6 9 1 2 7 0 3 5 8 4]
 [5 9 8 7 2 4 1 3 0 6]
 [1 6 8 2 9 4 7 0 3 5]]
Epoch 60910: Training cost= 2.3026, Training acc= 0.8688, Validation cost= 2.3026, Validation acc= 0.8683
Epoch 60920: Training cost= 2.3026, Training acc= 0.8687, Validation cost= 2.3026, Validation acc= 0.8682
Epoch 60930: Training cost= 2.3026, Training acc= 0.8686, Validation cost= 2.3026, Validation acc= 0.8681
Epoch 60940: Training cost= 2.3026, Training acc= 0.8685, Validation cost= 2.3026, Validation acc= 0.8679
Epoch 60950: Training cost= 2.3026, Training acc= 0.8683, Validation cost= 2.3026, Validation acc= 0.8678
Epoch 60960: Training cost= 2.3026, Training acc= 0.8682, Validation cost= 2.3026, Validation acc= 0.8677
Epoch 60970: Training cost= 2.3026, Training acc= 0.8681, Validation cost= 2.3026, Validation acc= 0.8676
Epoch 60980: Training cost= 2.3026, Training acc= 0.8679, Validation cost= 2.3026, Validation acc= 0.8674
Epoch 60990: Training cost= 2.3026, Training acc= 0.8678, Validation cost= 2.3026, Validation acc= 0.8673
Epoch 61000: Training cost= 2.3026, Training acc= 0.8677, Validation cost= 2.3026, Validation acc= 0.8672
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 1 2 5 6 3 8 9 4 7]
 [8 1 2 6 5 4 7 9 0 3]
 [8 0 7 2 1 5 4 9 3 6]
 [8 9 5 6 0 3 4 7 1 2]
 [8 4 3 7 6 0 1 9 5 2]
 [5 6 1 7 4 3 8 2 9 0]
 [6 5 1 3 7 0 8 9 2 4]
 [0 3 2 1 5 9 8 4 7 6]
 [2 1 5 0 7 3 8 6 4 9]
 [8 0 1 9 4 3 6 2 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 4 2 9 7 3 0 8 6 1]
 [5 3 8 4 2 1 0 7 6 9]
 [6 7 1 8 2 0 5 3 4 9]
 [0 4 2 7 6 1 8 5 3 9]
 [8 7 1 3 0 9 5 2 4 6]
 [5 0 8 3 2 6 4 1 7 9]
 [9 8 7 4 6 5 0 3 2 1]
 [6 4 2 7 3 0 5 1 9 8]
 [3 6 7 4 2 9 0 8 1 5]
 [0 1 7 5 4 2 8 3 6 9]]
Epoch 61010: Training cost= 2.3026, Training acc= 0.8676, Validation cost= 2.3026, Validation acc= 0.8670
Epoch 61020: Training cost= 2.3026, Training acc= 0.8674, Validation cost= 2.3026, Validation acc= 0.8669
Epoch 61030: Training cost= 2.3026, Training acc= 0.8673, Validation cost= 2.3026, Validation acc= 0.8668
Epoch 61040: Training cost= 2.3026, Training acc= 0.8672, Validation cost= 2.3026, Validation acc= 0.8667
Epoch 61050: Training cost= 2.3026, Training acc= 0.8671, Validation cost= 2.3026, Validation acc= 0.8665
Epoch 61060: Training cost= 2.3026, Training acc= 0.8669, Validation cost= 2.3026, Validation acc= 0.8664
Epoch 61070: Training cost= 2.3026, Training acc= 0.8668, Validation cost= 2.3026, Validation acc= 0.8663
Epoch 61080: Training cost= 2.3026, Training acc= 0.8667, Validation cost= 2.3026, Validation acc= 0.8662
Epoch 61090: Training cost= 2.3026, Training acc= 0.8666, Validation cost= 2.3026, Validation acc= 0.8660
Epoch 61100: Training cost= 2.3026, Training acc= 0.8664, Validation cost= 2.3026, Validation acc= 0.8659
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 2 5 4 8 7 3 9 1 6]
 [9 3 6 8 7 1 5 0 2 4]
 [2 1 8 5 6 3 7 0 4 9]
 [2 3 4 7 0 8 1 6 5 9]
 [4 0 3 5 7 2 8 1 9 6]
 [8 3 5 4 7 1 9 0 2 6]
 [3 9 5 0 2 6 7 1 4 8]
 [9 4 3 5 6 7 0 8 1 2]
 [3 7 0 2 4 9 5 1 6 8]
 [6 2 3 7 0 8 4 5 1 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 4 1 3 8 9 2 6 0 5]
 [1 8 2 0 5 3 4 7 9 6]
 [8 9 1 3 2 0 6 4 5 7]
 [9 8 7 3 0 6 5 4 1 2]
 [3 7 2 4 9 6 8 5 1 0]
 [9 7 5 1 2 6 8 3 0 4]
 [7 9 2 8 3 6 5 1 4 0]
 [5 1 3 8 6 9 0 2 4 7]
 [0 2 1 6 4 7 5 3 8 9]
 [7 3 9 8 6 2 4 5 0 1]]
Epoch 61110: Training cost= 2.3026, Training acc= 0.8663, Validation cost= 2.3026, Validation acc= 0.8658
Epoch 61120: Training cost= 2.3026, Training acc= 0.8662, Validation cost= 2.3026, Validation acc= 0.8657
Epoch 61130: Training cost= 2.3026, Training acc= 0.8661, Validation cost= 2.3026, Validation acc= 0.8655
Epoch 61140: Training cost= 2.3026, Training acc= 0.8659, Validation cost= 2.3026, Validation acc= 0.8654
Epoch 61150: Training cost= 2.3026, Training acc= 0.8658, Validation cost= 2.3026, Validation acc= 0.8653
Epoch 61160: Training cost= 2.3026, Training acc= 0.8657, Validation cost= 2.3026, Validation acc= 0.8652
Epoch 61170: Training cost= 2.3026, Training acc= 0.8656, Validation cost= 2.3026, Validation acc= 0.8650
Epoch 61180: Training cost= 2.3026, Training acc= 0.8654, Validation cost= 2.3026, Validation acc= 0.8649
Epoch 61190: Training cost= 2.3026, Training acc= 0.8653, Validation cost= 2.3026, Validation acc= 0.8648
Epoch 61200: Training cost= 2.3026, Training acc= 0.8652, Validation cost= 2.3026, Validation acc= 0.8647
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 6 0 3 9 7 8 2 1 5]
 [4 7 8 9 2 5 0 6 1 3]
 [6 2 7 1 4 9 8 5 0 3]
 [9 3 0 6 1 7 8 4 2 5]
 [6 1 7 3 0 2 8 9 5 4]
 [8 3 5 2 6 7 1 9 0 4]
 [2 6 0 1 9 7 8 3 4 5]
 [3 6 5 7 1 2 9 0 4 8]
 [2 0 5 9 3 7 4 1 8 6]
 [2 8 6 4 9 7 3 0 5 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 4 5 9 2 7 3 8 1 0]
 [9 6 3 0 7 1 8 4 5 2]
 [4 8 7 1 0 6 9 3 2 5]
 [6 9 1 7 0 3 8 4 5 2]
 [2 0 9 8 4 7 6 3 1 5]
 [1 6 0 9 4 5 7 8 3 2]
 [5 2 3 9 0 1 6 4 8 7]
 [8 3 5 2 7 6 9 1 0 4]
 [4 1 5 2 9 7 3 6 0 8]
 [6 8 3 0 7 9 5 2 1 4]]
Epoch 61210: Training cost= 2.3026, Training acc= 0.8651, Validation cost= 2.3026, Validation acc= 0.8645
Epoch 61220: Training cost= 2.3026, Training acc= 0.8649, Validation cost= 2.3026, Validation acc= 0.8644
Epoch 61230: Training cost= 2.3026, Training acc= 0.8648, Validation cost= 2.3026, Validation acc= 0.8643
Epoch 61240: Training cost= 2.3026, Training acc= 0.8647, Validation cost= 2.3026, Validation acc= 0.8642
Epoch 61250: Training cost= 2.3026, Training acc= 0.8646, Validation cost= 2.3026, Validation acc= 0.8640
Epoch 61260: Training cost= 2.3026, Training acc= 0.8644, Validation cost= 2.3026, Validation acc= 0.8639
Epoch 61270: Training cost= 2.3026, Training acc= 0.8643, Validation cost= 2.3026, Validation acc= 0.8638
Epoch 61280: Training cost= 2.3026, Training acc= 0.8642, Validation cost= 2.3026, Validation acc= 0.8637
Epoch 61290: Training cost= 2.3026, Training acc= 0.8641, Validation cost= 2.3026, Validation acc= 0.8635
Epoch 61300: Training cost= 2.3026, Training acc= 0.8639, Validation cost= 2.3026, Validation acc= 0.8634
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 8 3 1 7 0 5 6 2]
 [7 4 2 0 9 3 5 1 8 6]
 [0 2 8 1 3 6 5 4 7 9]
 [7 6 9 1 0 4 8 3 5 2]
 [3 1 0 7 9 6 2 4 5 8]
 [8 2 9 3 1 4 6 0 5 7]
 [5 7 4 6 2 9 1 0 8 3]
 [6 9 1 2 0 3 7 5 8 4]
 [5 8 7 4 6 1 2 0 3 9]
 [5 0 6 7 9 1 4 8 3 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 1 4 7 3 0 5 6 2 9]
 [3 2 0 6 1 5 7 4 9 8]
 [0 1 3 2 5 6 4 7 8 9]
 [5 6 3 7 4 0 2 9 8 1]
 [3 7 4 0 8 5 2 6 1 9]
 [6 0 9 1 5 7 4 3 8 2]
 [0 6 9 1 7 3 2 4 5 8]
 [8 3 1 0 7 9 5 6 4 2]
 [1 7 2 6 0 5 8 4 9 3]
 [1 4 5 0 9 3 2 8 6 7]]
Epoch 61310: Training cost= 2.3026, Training acc= 0.8638, Validation cost= 2.3026, Validation acc= 0.8633
Epoch 61320: Training cost= 2.3026, Training acc= 0.8637, Validation cost= 2.3026, Validation acc= 0.8632
Epoch 61330: Training cost= 2.3026, Training acc= 0.8636, Validation cost= 2.3026, Validation acc= 0.8630
Epoch 61340: Training cost= 2.3026, Training acc= 0.8634, Validation cost= 2.3026, Validation acc= 0.8629
Epoch 61350: Training cost= 2.3026, Training acc= 0.8633, Validation cost= 2.3026, Validation acc= 0.8628
Epoch 61360: Training cost= 2.3026, Training acc= 0.8632, Validation cost= 2.3026, Validation acc= 0.8627
Epoch 61370: Training cost= 2.3026, Training acc= 0.8631, Validation cost= 2.3026, Validation acc= 0.8625
Epoch 61380: Training cost= 2.3026, Training acc= 0.8629, Validation cost= 2.3026, Validation acc= 0.8624
Epoch 61390: Training cost= 2.3026, Training acc= 0.8628, Validation cost= 2.3026, Validation acc= 0.8623
Epoch 61400: Training cost= 2.3026, Training acc= 0.8627, Validation cost= 2.3026, Validation acc= 0.8622
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 2 6 1 3 9 0 7 4 5]
 [7 8 4 2 1 6 0 5 3 9]
 [4 8 0 2 6 9 3 7 5 1]
 [5 7 0 2 1 6 3 4 8 9]
 [8 4 2 0 7 1 9 3 6 5]
 [2 6 7 4 9 5 8 1 3 0]
 [8 9 5 6 0 4 2 3 1 7]
 [7 1 8 4 6 2 5 3 0 9]
 [3 2 9 7 8 0 1 5 6 4]
 [8 3 4 0 1 9 5 7 2 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 4 2 6 0 9 7 8 3 5]
 [8 9 2 3 0 5 7 4 6 1]
 [1 6 4 2 5 8 3 7 0 9]
 [3 9 6 8 7 2 0 4 1 5]
 [7 5 9 2 8 4 1 3 0 6]
 [6 4 0 3 9 2 7 8 5 1]
 [4 9 6 2 7 3 5 8 1 0]
 [3 6 2 5 8 7 9 0 1 4]
 [3 7 0 6 5 2 1 9 8 4]
 [6 3 5 0 8 7 4 9 2 1]]
Epoch 61410: Training cost= 2.3026, Training acc= 0.8626, Validation cost= 2.3026, Validation acc= 0.8621
Epoch 61420: Training cost= 2.3026, Training acc= 0.8624, Validation cost= 2.3026, Validation acc= 0.8619
Epoch 61430: Training cost= 2.3026, Training acc= 0.8623, Validation cost= 2.3026, Validation acc= 0.8618
Epoch 61440: Training cost= 2.3026, Training acc= 0.8622, Validation cost= 2.3026, Validation acc= 0.8617
Epoch 61450: Training cost= 2.3026, Training acc= 0.8621, Validation cost= 2.3026, Validation acc= 0.8616
Epoch 61460: Training cost= 2.3026, Training acc= 0.8620, Validation cost= 2.3026, Validation acc= 0.8614
Epoch 61470: Training cost= 2.3026, Training acc= 0.8618, Validation cost= 2.3026, Validation acc= 0.8613
Epoch 61480: Training cost= 2.3026, Training acc= 0.8617, Validation cost= 2.3026, Validation acc= 0.8612
Epoch 61490: Training cost= 2.3026, Training acc= 0.8616, Validation cost= 2.3026, Validation acc= 0.8611
Epoch 61500: Training cost= 2.3026, Training acc= 0.8615, Validation cost= 2.3026, Validation acc= 0.8609
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 1 6 4 0 9 7 3 8 2]
 [8 1 7 4 5 9 3 2 0 6]
 [4 7 8 5 2 3 9 1 6 0]
 [0 3 1 4 2 7 8 5 9 6]
 [0 8 1 5 3 4 7 2 6 9]
 [2 6 3 1 0 9 4 7 8 5]
 [2 5 4 8 6 1 9 7 3 0]
 [3 1 8 0 7 4 5 2 9 6]
 [1 6 3 0 8 4 7 2 9 5]
 [0 8 5 4 1 7 2 9 3 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 3 2 5 8 7 6 0 1 4]
 [4 3 6 7 8 2 1 0 5 9]
 [8 5 3 4 2 0 6 1 7 9]
 [8 7 9 3 1 0 4 2 5 6]
 [8 6 4 7 3 2 0 9 1 5]
 [9 3 4 1 5 8 7 6 2 0]
 [1 8 3 9 7 4 0 5 2 6]
 [8 1 4 9 7 0 2 6 5 3]
 [8 6 1 2 7 5 3 0 4 9]
 [6 5 4 2 9 7 0 8 3 1]]
Epoch 61510: Training cost= 2.3026, Training acc= 0.8613, Validation cost= 2.3026, Validation acc= 0.8608
Epoch 61520: Training cost= 2.3026, Training acc= 0.8612, Validation cost= 2.3026, Validation acc= 0.8607
Epoch 61530: Training cost= 2.3026, Training acc= 0.8611, Validation cost= 2.3026, Validation acc= 0.8606
Epoch 61540: Training cost= 2.3026, Training acc= 0.8610, Validation cost= 2.3026, Validation acc= 0.8604
Epoch 61550: Training cost= 2.3026, Training acc= 0.8608, Validation cost= 2.3026, Validation acc= 0.8603
Epoch 61560: Training cost= 2.3026, Training acc= 0.8607, Validation cost= 2.3026, Validation acc= 0.8602
Epoch 61570: Training cost= 2.3026, Training acc= 0.8606, Validation cost= 2.3026, Validation acc= 0.8601
Epoch 61580: Training cost= 2.3026, Training acc= 0.8605, Validation cost= 2.3026, Validation acc= 0.8599
Epoch 61590: Training cost= 2.3026, Training acc= 0.8603, Validation cost= 2.3026, Validation acc= 0.8598
Epoch 61600: Training cost= 2.3026, Training acc= 0.8602, Validation cost= 2.3026, Validation acc= 0.8597
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 7 5 9 8 2 6 1 0 4]
 [6 3 4 2 5 8 7 1 9 0]
 [7 3 0 1 4 6 5 2 9 8]
 [4 3 8 6 9 1 5 2 0 7]
 [7 1 9 4 5 2 3 8 6 0]
 [5 8 1 4 6 3 9 7 0 2]
 [6 0 8 3 1 7 9 4 2 5]
 [5 2 8 4 0 3 7 9 1 6]
 [2 4 0 5 9 8 6 1 3 7]
 [3 7 8 0 5 4 1 2 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 8 7 9 0 6 4 5 1]
 [7 9 6 2 1 8 0 5 3 4]
 [7 8 9 5 0 6 1 3 2 4]
 [4 1 9 6 8 2 7 3 0 5]
 [3 7 2 0 1 4 5 8 6 9]
 [8 2 4 3 9 6 0 1 7 5]
 [4 3 1 8 6 7 9 0 5 2]
 [2 8 9 1 4 6 3 5 7 0]
 [1 3 7 4 0 6 8 2 5 9]
 [6 9 1 4 0 5 3 2 7 8]]
Epoch 61610: Training cost= 2.3026, Training acc= 0.8601, Validation cost= 2.3026, Validation acc= 0.8596
Epoch 61620: Training cost= 2.3026, Training acc= 0.8600, Validation cost= 2.3026, Validation acc= 0.8595
Epoch 61630: Training cost= 2.3026, Training acc= 0.8598, Validation cost= 2.3026, Validation acc= 0.8593
Epoch 61640: Training cost= 2.3026, Training acc= 0.8597, Validation cost= 2.3026, Validation acc= 0.8592
Epoch 61650: Training cost= 2.3026, Training acc= 0.8596, Validation cost= 2.3026, Validation acc= 0.8591
Epoch 61660: Training cost= 2.3026, Training acc= 0.8595, Validation cost= 2.3026, Validation acc= 0.8590
Epoch 61670: Training cost= 2.3026, Training acc= 0.8594, Validation cost= 2.3026, Validation acc= 0.8588
Epoch 61680: Training cost= 2.3026, Training acc= 0.8592, Validation cost= 2.3026, Validation acc= 0.8587
Epoch 61690: Training cost= 2.3026, Training acc= 0.8591, Validation cost= 2.3026, Validation acc= 0.8586
Epoch 61700: Training cost= 2.3026, Training acc= 0.8590, Validation cost= 2.3026, Validation acc= 0.8585
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 2 7 5 3 6 9 4 0 1]
 [3 4 8 9 7 1 2 5 0 6]
 [5 1 7 6 4 0 9 8 3 2]
 [3 6 9 0 4 8 2 7 5 1]
 [6 3 4 9 8 5 2 1 0 7]
 [6 0 1 5 7 2 8 4 9 3]
 [7 6 5 3 1 8 0 9 2 4]
 [6 2 3 8 1 4 9 7 0 5]
 [6 9 2 4 3 0 5 8 1 7]
 [1 4 0 5 7 9 2 3 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 0 8 4 5 9 2 7 3 6]
 [9 0 7 1 8 4 2 5 6 3]
 [4 6 9 8 0 3 7 5 2 1]
 [9 0 1 6 8 2 4 7 3 5]
 [8 3 0 9 1 4 6 5 7 2]
 [6 3 5 7 1 8 2 9 0 4]
 [7 0 9 3 1 4 2 8 6 5]
 [2 3 7 1 6 8 9 4 5 0]
 [2 9 7 0 6 8 1 5 3 4]
 [3 6 4 1 0 9 7 2 5 8]]
Epoch 61710: Training cost= 2.3026, Training acc= 0.8589, Validation cost= 2.3026, Validation acc= 0.8583
Epoch 61720: Training cost= 2.3026, Training acc= 0.8587, Validation cost= 2.3026, Validation acc= 0.8582
Epoch 61730: Training cost= 2.3026, Training acc= 0.8586, Validation cost= 2.3026, Validation acc= 0.8581
Epoch 61740: Training cost= 2.3026, Training acc= 0.8585, Validation cost= 2.3026, Validation acc= 0.8580
Epoch 61750: Training cost= 2.3026, Training acc= 0.8584, Validation cost= 2.3026, Validation acc= 0.8579
Epoch 61760: Training cost= 2.3026, Training acc= 0.8583, Validation cost= 2.3026, Validation acc= 0.8577
Epoch 61770: Training cost= 2.3026, Training acc= 0.8581, Validation cost= 2.3026, Validation acc= 0.8576
Epoch 61780: Training cost= 2.3026, Training acc= 0.8580, Validation cost= 2.3026, Validation acc= 0.8575
Epoch 61790: Training cost= 2.3026, Training acc= 0.8579, Validation cost= 2.3026, Validation acc= 0.8574
Epoch 61800: Training cost= 2.3026, Training acc= 0.8578, Validation cost= 2.3026, Validation acc= 0.8572
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 8 3 2 6 9 4 7 1 5]
 [2 8 9 0 4 1 5 6 7 3]
 [4 6 5 1 3 9 0 2 8 7]
 [2 0 4 5 6 7 9 8 1 3]
 [0 3 4 7 1 2 8 9 6 5]
 [3 2 8 0 5 4 9 6 1 7]
 [7 6 4 3 9 0 2 1 8 5]
 [4 3 9 5 0 1 7 6 2 8]
 [2 0 5 3 7 4 9 6 1 8]
 [6 2 8 4 7 0 5 3 9 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 3 9 0 7 5 4 6 1 2]
 [7 3 4 5 1 2 9 6 0 8]
 [4 2 7 6 3 5 9 1 8 0]
 [0 9 5 8 7 6 4 1 3 2]
 [7 0 4 9 1 3 2 5 6 8]
 [7 8 1 9 4 6 2 0 5 3]
 [1 3 6 2 7 8 4 0 9 5]
 [7 3 6 2 5 8 9 1 0 4]
 [4 2 0 1 9 3 7 6 8 5]
 [3 8 1 7 0 9 2 4 6 5]]
Epoch 61810: Training cost= 2.3026, Training acc= 0.8576, Validation cost= 2.3026, Validation acc= 0.8571
Epoch 61820: Training cost= 2.3026, Training acc= 0.8575, Validation cost= 2.3026, Validation acc= 0.8570
Epoch 61830: Training cost= 2.3026, Training acc= 0.8574, Validation cost= 2.3026, Validation acc= 0.8569
Epoch 61840: Training cost= 2.3026, Training acc= 0.8573, Validation cost= 2.3026, Validation acc= 0.8568
Epoch 61850: Training cost= 2.3026, Training acc= 0.8571, Validation cost= 2.3026, Validation acc= 0.8566
Epoch 61860: Training cost= 2.3026, Training acc= 0.8570, Validation cost= 2.3026, Validation acc= 0.8565
Epoch 61870: Training cost= 2.3026, Training acc= 0.8569, Validation cost= 2.3026, Validation acc= 0.8564
Epoch 61880: Training cost= 2.3026, Training acc= 0.8568, Validation cost= 2.3026, Validation acc= 0.8563
Epoch 61890: Training cost= 2.3026, Training acc= 0.8567, Validation cost= 2.3026, Validation acc= 0.8561
Epoch 61900: Training cost= 2.3026, Training acc= 0.8565, Validation cost= 2.3026, Validation acc= 0.8560
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 0 5 1 7 6 3 9 8 4]
 [5 9 2 3 7 1 6 0 8 4]
 [2 5 3 0 9 1 4 6 7 8]
 [7 2 1 6 4 8 3 9 5 0]
 [7 0 5 3 2 1 6 8 4 9]
 [3 2 5 8 7 6 4 0 9 1]
 [3 1 8 4 7 0 2 6 5 9]
 [6 5 7 4 3 2 1 9 8 0]
 [5 4 9 8 6 2 1 3 7 0]
 [7 1 0 2 5 3 4 8 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 7 2 1 0 4 6 8 9]
 [2 8 3 7 4 9 6 0 1 5]
 [7 1 4 0 9 6 2 5 8 3]
 [6 5 0 9 4 8 3 1 7 2]
 [7 9 5 2 6 8 0 1 3 4]
 [0 6 2 5 4 7 1 9 8 3]
 [0 6 4 5 2 8 3 7 9 1]
 [7 4 9 3 6 5 1 8 2 0]
 [8 2 6 5 4 1 3 0 7 9]
 [1 9 3 4 5 0 7 6 8 2]]
Epoch 61910: Training cost= 2.3026, Training acc= 0.8564, Validation cost= 2.3026, Validation acc= 0.8559
Epoch 61920: Training cost= 2.3026, Training acc= 0.8563, Validation cost= 2.3026, Validation acc= 0.8558
Epoch 61930: Training cost= 2.3026, Training acc= 0.8562, Validation cost= 2.3026, Validation acc= 0.8557
Epoch 61940: Training cost= 2.3026, Training acc= 0.8560, Validation cost= 2.3026, Validation acc= 0.8555
Epoch 61950: Training cost= 2.3026, Training acc= 0.8559, Validation cost= 2.3026, Validation acc= 0.8554
Epoch 61960: Training cost= 2.3026, Training acc= 0.8558, Validation cost= 2.3026, Validation acc= 0.8553
Epoch 61970: Training cost= 2.3026, Training acc= 0.8557, Validation cost= 2.3026, Validation acc= 0.8552
Epoch 61980: Training cost= 2.3026, Training acc= 0.8556, Validation cost= 2.3026, Validation acc= 0.8550
Epoch 61990: Training cost= 2.3026, Training acc= 0.8554, Validation cost= 2.3026, Validation acc= 0.8549
Epoch 62000: Training cost= 2.3026, Training acc= 0.8553, Validation cost= 2.3026, Validation acc= 0.8548
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 2 5 0 8 3 9 4 6 1]
 [2 8 0 9 6 7 4 1 3 5]
 [1 6 4 9 3 0 8 7 5 2]
 [1 4 3 6 2 7 9 5 0 8]
 [2 5 0 4 3 7 1 8 9 6]
 [2 8 0 7 1 3 5 4 6 9]
 [9 2 3 6 0 5 8 1 7 4]
 [5 0 8 2 9 6 7 4 3 1]
 [5 8 1 0 6 3 7 2 9 4]
 [8 4 0 3 5 7 1 9 6 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 8 6 5 9 4 2 0 7 3]
 [3 8 1 5 2 9 7 0 4 6]
 [9 2 3 1 7 6 5 0 4 8]
 [9 2 3 1 0 4 5 8 7 6]
 [8 4 1 5 6 0 2 3 9 7]
 [5 2 8 1 4 7 9 0 3 6]
 [1 5 0 3 6 7 8 9 2 4]
 [1 8 9 6 0 4 3 7 5 2]
 [8 6 2 9 3 1 5 7 0 4]
 [6 2 0 3 1 7 8 9 5 4]]
Epoch 62010: Training cost= 2.3026, Training acc= 0.8552, Validation cost= 2.3026, Validation acc= 0.8547
Epoch 62020: Training cost= 2.3026, Training acc= 0.8551, Validation cost= 2.3026, Validation acc= 0.8546
Epoch 62030: Training cost= 2.3026, Training acc= 0.8549, Validation cost= 2.3026, Validation acc= 0.8544
Epoch 62040: Training cost= 2.3026, Training acc= 0.8548, Validation cost= 2.3026, Validation acc= 0.8543
Epoch 62050: Training cost= 2.3026, Training acc= 0.8547, Validation cost= 2.3026, Validation acc= 0.8542
Epoch 62060: Training cost= 2.3026, Training acc= 0.8546, Validation cost= 2.3026, Validation acc= 0.8541
Epoch 62070: Training cost= 2.3026, Training acc= 0.8545, Validation cost= 2.3026, Validation acc= 0.8539
Epoch 62080: Training cost= 2.3026, Training acc= 0.8543, Validation cost= 2.3026, Validation acc= 0.8538
Epoch 62090: Training cost= 2.3026, Training acc= 0.8542, Validation cost= 2.3026, Validation acc= 0.8537
Epoch 62100: Training cost= 2.3026, Training acc= 0.8541, Validation cost= 2.3026, Validation acc= 0.8536
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 3 8 5 9 7 6 0 2 4]
 [6 4 8 2 5 1 0 7 3 9]
 [0 3 5 8 4 6 9 2 1 7]
 [1 4 5 3 7 8 9 6 2 0]
 [5 2 0 4 7 6 9 3 1 8]
 [2 7 1 5 8 0 4 6 3 9]
 [4 0 2 5 9 3 1 8 6 7]
 [1 6 0 4 9 8 7 2 3 5]
 [7 9 5 8 4 2 6 1 3 0]
 [9 5 3 6 2 7 1 4 0 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 8 3 0 5 1 2 6 9 4]
 [8 4 6 0 1 5 2 9 7 3]
 [3 6 4 9 2 8 0 1 5 7]
 [7 6 5 2 1 0 3 4 8 9]
 [8 5 2 9 4 1 0 6 3 7]
 [0 1 7 9 6 8 3 2 4 5]
 [5 9 6 7 1 2 4 0 3 8]
 [7 9 2 5 6 8 4 3 1 0]
 [9 4 6 8 2 5 7 1 0 3]
 [2 4 6 9 5 1 0 8 3 7]]
Epoch 62110: Training cost= 2.3026, Training acc= 0.8540, Validation cost= 2.3026, Validation acc= 0.8535
Epoch 62120: Training cost= 2.3026, Training acc= 0.8539, Validation cost= 2.3026, Validation acc= 0.8533
Epoch 62130: Training cost= 2.3026, Training acc= 0.8537, Validation cost= 2.3026, Validation acc= 0.8532
Epoch 62140: Training cost= 2.3026, Training acc= 0.8536, Validation cost= 2.3026, Validation acc= 0.8531
Epoch 62150: Training cost= 2.3026, Training acc= 0.8535, Validation cost= 2.3026, Validation acc= 0.8530
Epoch 62160: Training cost= 2.3026, Training acc= 0.8534, Validation cost= 2.3026, Validation acc= 0.8529
Epoch 62170: Training cost= 2.3026, Training acc= 0.8532, Validation cost= 2.3026, Validation acc= 0.8527
Epoch 62180: Training cost= 2.3026, Training acc= 0.8531, Validation cost= 2.3026, Validation acc= 0.8526
Epoch 62190: Training cost= 2.3026, Training acc= 0.8530, Validation cost= 2.3026, Validation acc= 0.8525
Epoch 62200: Training cost= 2.3026, Training acc= 0.8529, Validation cost= 2.3026, Validation acc= 0.8524
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 5 0 3 7 6 4 2 8]
 [3 7 8 9 2 5 4 0 1 6]
 [4 5 2 9 8 3 1 6 0 7]
 [4 2 1 8 9 3 7 0 5 6]
 [5 9 3 6 2 4 0 1 7 8]
 [4 2 3 0 6 8 1 7 9 5]
 [4 3 5 6 1 2 8 7 9 0]
 [0 8 6 5 9 7 1 2 3 4]
 [1 3 6 7 2 0 5 9 8 4]
 [7 5 4 6 2 1 3 8 0 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 8 9 3 2 6 5 7 1 4]
 [8 7 5 1 2 0 3 4 9 6]
 [2 3 5 0 6 8 1 7 9 4]
 [6 2 8 5 1 7 0 3 4 9]
 [1 4 5 3 7 9 2 0 8 6]
 [2 3 6 5 4 7 1 0 8 9]
 [2 3 8 7 6 0 4 5 1 9]
 [6 1 0 9 3 2 8 7 4 5]
 [1 7 6 5 0 4 2 3 9 8]
 [5 0 9 7 3 8 6 1 2 4]]
Epoch 62210: Training cost= 2.3026, Training acc= 0.8528, Validation cost= 2.3026, Validation acc= 0.8523
Epoch 62220: Training cost= 2.3026, Training acc= 0.8526, Validation cost= 2.3026, Validation acc= 0.8521
Epoch 62230: Training cost= 2.3026, Training acc= 0.8525, Validation cost= 2.3026, Validation acc= 0.8520
Epoch 62240: Training cost= 2.3026, Training acc= 0.8524, Validation cost= 2.3026, Validation acc= 0.8519
Epoch 62250: Training cost= 2.3026, Training acc= 0.8523, Validation cost= 2.3026, Validation acc= 0.8518
Epoch 62260: Training cost= 2.3026, Training acc= 0.8522, Validation cost= 2.3026, Validation acc= 0.8516
Epoch 62270: Training cost= 2.3026, Training acc= 0.8520, Validation cost= 2.3026, Validation acc= 0.8515
Epoch 62280: Training cost= 2.3026, Training acc= 0.8519, Validation cost= 2.3026, Validation acc= 0.8514
Epoch 62290: Training cost= 2.3026, Training acc= 0.8518, Validation cost= 2.3026, Validation acc= 0.8513
Epoch 62300: Training cost= 2.3026, Training acc= 0.8517, Validation cost= 2.3026, Validation acc= 0.8512
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 5 2 4 0 3 9 8 6 7]
 [0 9 6 1 3 8 5 4 2 7]
 [7 8 0 6 1 3 9 4 5 2]
 [4 8 2 3 5 7 6 9 1 0]
 [0 7 5 8 6 9 2 4 1 3]
 [1 4 8 5 3 9 2 0 7 6]
 [2 1 4 6 0 8 7 9 3 5]
 [3 9 1 8 4 7 0 6 2 5]
 [0 4 8 2 6 9 5 7 3 1]
 [7 5 9 2 6 1 3 0 8 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 0 7 9 8 5 2 6 4 3]
 [1 9 8 3 6 0 2 7 4 5]
 [9 1 5 4 3 0 6 2 8 7]
 [7 1 8 5 2 4 6 3 0 9]
 [8 6 7 2 0 9 1 5 3 4]
 [4 5 2 0 9 7 6 8 1 3]
 [0 7 4 5 9 2 6 8 3 1]
 [2 1 7 4 0 9 3 6 5 8]
 [3 4 5 8 2 9 0 1 6 7]
 [1 6 2 4 3 5 7 0 8 9]]
Epoch 62310: Training cost= 2.3026, Training acc= 0.8516, Validation cost= 2.3026, Validation acc= 0.8510
Epoch 62320: Training cost= 2.3026, Training acc= 0.8514, Validation cost= 2.3026, Validation acc= 0.8509
Epoch 62330: Training cost= 2.3026, Training acc= 0.8513, Validation cost= 2.3026, Validation acc= 0.8508
Epoch 62340: Training cost= 2.3026, Training acc= 0.8512, Validation cost= 2.3026, Validation acc= 0.8507
Epoch 62350: Training cost= 2.3026, Training acc= 0.8511, Validation cost= 2.3026, Validation acc= 0.8506
Epoch 62360: Training cost= 2.3026, Training acc= 0.8510, Validation cost= 2.3026, Validation acc= 0.8504
Epoch 62370: Training cost= 2.3026, Training acc= 0.8508, Validation cost= 2.3026, Validation acc= 0.8503
Epoch 62380: Training cost= 2.3026, Training acc= 0.8507, Validation cost= 2.3026, Validation acc= 0.8502
Epoch 62390: Training cost= 2.3026, Training acc= 0.8506, Validation cost= 2.3026, Validation acc= 0.8501
Epoch 62400: Training cost= 2.3026, Training acc= 0.8505, Validation cost= 2.3026, Validation acc= 0.8500
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 4 1 6 0 2 5 7 3 8]
 [3 8 7 1 9 5 4 2 0 6]
 [9 6 0 8 2 4 7 5 3 1]
 [5 1 0 3 4 8 6 9 2 7]
 [8 5 4 7 3 1 6 2 9 0]
 [2 0 6 5 1 3 8 7 9 4]
 [3 7 5 2 1 0 9 4 6 8]
 [5 7 1 3 4 9 2 6 8 0]
 [0 4 5 6 8 2 3 7 1 9]
 [9 5 6 8 3 2 4 7 1 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 2 1 7 3 9 4 5 0 8]
 [5 6 9 1 2 3 4 7 8 0]
 [0 7 2 9 1 5 3 6 8 4]
 [5 7 0 8 6 4 1 2 9 3]
 [0 3 1 5 2 7 6 4 9 8]
 [1 4 9 0 6 5 7 2 3 8]
 [7 0 4 9 5 3 1 8 2 6]
 [1 6 0 9 3 5 8 7 4 2]
 [2 9 3 0 4 7 6 1 8 5]
 [3 8 1 5 7 2 6 4 0 9]]
Epoch 62410: Training cost= 2.3026, Training acc= 0.8504, Validation cost= 2.3026, Validation acc= 0.8498
Epoch 62420: Training cost= 2.3026, Training acc= 0.8502, Validation cost= 2.3026, Validation acc= 0.8497
Epoch 62430: Training cost= 2.3026, Training acc= 0.8501, Validation cost= 2.3026, Validation acc= 0.8496
Epoch 62440: Training cost= 2.3026, Training acc= 0.8500, Validation cost= 2.3026, Validation acc= 0.8495
Epoch 62450: Training cost= 2.3026, Training acc= 0.8499, Validation cost= 2.3026, Validation acc= 0.8494
Epoch 62460: Training cost= 2.3026, Training acc= 0.8498, Validation cost= 2.3026, Validation acc= 0.8492
Epoch 62470: Training cost= 2.3026, Training acc= 0.8496, Validation cost= 2.3026, Validation acc= 0.8491
Epoch 62480: Training cost= 2.3026, Training acc= 0.8495, Validation cost= 2.3026, Validation acc= 0.8490
Epoch 62490: Training cost= 2.3026, Training acc= 0.8494, Validation cost= 2.3026, Validation acc= 0.8489
Epoch 62500: Training cost= 2.3026, Training acc= 0.8493, Validation cost= 2.3026, Validation acc= 0.8488
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 9 8 4 1 6 7 2 0 3]
 [9 3 7 4 1 0 5 2 6 8]
 [9 8 6 1 2 0 5 3 7 4]
 [7 6 2 5 9 1 4 3 8 0]
 [8 7 3 9 5 6 2 0 1 4]
 [9 4 2 7 5 1 8 0 3 6]
 [6 9 7 0 2 4 3 5 8 1]
 [4 9 2 3 8 5 6 0 1 7]
 [8 5 2 6 0 7 9 3 4 1]
 [6 9 2 1 7 8 0 4 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 2 6 1 4 8 9 5 3 7]
 [1 3 7 9 8 5 0 2 6 4]
 [2 6 1 9 0 4 3 5 7 8]
 [5 0 7 2 3 1 6 4 8 9]
 [3 8 0 6 9 2 4 7 5 1]
 [7 1 9 8 3 5 2 6 4 0]
 [3 5 0 9 2 8 6 4 1 7]
 [7 8 4 1 5 6 2 0 3 9]
 [1 9 7 5 2 6 3 4 0 8]
 [0 4 6 3 5 8 9 2 7 1]]
Epoch 62510: Training cost= 2.3026, Training acc= 0.8492, Validation cost= 2.3026, Validation acc= 0.8486
Epoch 62520: Training cost= 2.3026, Training acc= 0.8490, Validation cost= 2.3026, Validation acc= 0.8485
Epoch 62530: Training cost= 2.3026, Training acc= 0.8489, Validation cost= 2.3026, Validation acc= 0.8484
Epoch 62540: Training cost= 2.3026, Training acc= 0.8488, Validation cost= 2.3026, Validation acc= 0.8483
Epoch 62550: Training cost= 2.3026, Training acc= 0.8487, Validation cost= 2.3026, Validation acc= 0.8482
Epoch 62560: Training cost= 2.3026, Training acc= 0.8486, Validation cost= 2.3026, Validation acc= 0.8480
Epoch 62570: Training cost= 2.3026, Training acc= 0.8484, Validation cost= 2.3026, Validation acc= 0.8479
Epoch 62580: Training cost= 2.3026, Training acc= 0.8483, Validation cost= 2.3026, Validation acc= 0.8478
Epoch 62590: Training cost= 2.3026, Training acc= 0.8482, Validation cost= 2.3026, Validation acc= 0.8477
Epoch 62600: Training cost= 2.3026, Training acc= 0.8481, Validation cost= 2.3026, Validation acc= 0.8476
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 4 2 0 1 9 7 3 8 5]
 [8 0 9 7 1 6 2 5 3 4]
 [2 0 7 8 5 1 3 4 6 9]
 [1 7 4 6 8 9 2 3 0 5]
 [5 0 6 1 7 9 3 4 8 2]
 [8 1 0 2 6 4 5 3 7 9]
 [7 2 9 0 1 8 5 4 3 6]
 [2 1 4 6 8 3 7 5 9 0]
 [5 6 4 2 3 9 8 7 1 0]
 [6 4 0 3 8 1 5 7 2 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 7 5 0 3 9 1 2 4 8]
 [2 8 9 6 5 3 1 7 4 0]
 [6 7 0 2 3 5 8 9 1 4]
 [2 6 1 0 8 4 3 7 5 9]
 [4 8 1 9 2 7 5 0 3 6]
 [2 9 6 8 0 7 4 1 5 3]
 [6 2 5 0 9 3 1 8 7 4]
 [3 0 6 7 8 5 1 9 2 4]
 [9 4 8 0 2 1 5 3 7 6]
 [0 9 1 2 3 8 7 4 5 6]]
Epoch 62610: Training cost= 2.3026, Training acc= 0.8480, Validation cost= 2.3026, Validation acc= 0.8474
Epoch 62620: Training cost= 2.3026, Training acc= 0.8478, Validation cost= 2.3026, Validation acc= 0.8473
Epoch 62630: Training cost= 2.3026, Training acc= 0.8477, Validation cost= 2.3026, Validation acc= 0.8472
Epoch 62640: Training cost= 2.3026, Training acc= 0.8476, Validation cost= 2.3026, Validation acc= 0.8471
Epoch 62650: Training cost= 2.3026, Training acc= 0.8475, Validation cost= 2.3026, Validation acc= 0.8470
Epoch 62660: Training cost= 2.3026, Training acc= 0.8474, Validation cost= 2.3026, Validation acc= 0.8469
Epoch 62670: Training cost= 2.3026, Training acc= 0.8472, Validation cost= 2.3026, Validation acc= 0.8467
Epoch 62680: Training cost= 2.3026, Training acc= 0.8471, Validation cost= 2.3026, Validation acc= 0.8466
Epoch 62690: Training cost= 2.3026, Training acc= 0.8470, Validation cost= 2.3026, Validation acc= 0.8465
Epoch 62700: Training cost= 2.3026, Training acc= 0.8469, Validation cost= 2.3026, Validation acc= 0.8464
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 4 0 6 5 1 2 9 8 7]
 [3 7 2 8 5 6 9 0 1 4]
 [1 6 2 0 7 9 5 4 8 3]
 [8 3 4 7 6 5 0 9 2 1]
 [7 5 6 2 8 9 0 3 1 4]
 [2 6 9 7 5 1 8 4 3 0]
 [5 3 7 1 0 2 8 6 9 4]
 [8 0 6 5 3 1 7 2 4 9]
 [9 6 8 5 7 0 2 1 3 4]
 [8 5 9 2 0 6 1 3 4 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 0 2 3 1 7 5 4 8 6]
 [0 4 7 1 6 9 3 2 5 8]
 [6 3 1 5 8 2 7 4 0 9]
 [0 1 6 9 3 2 7 8 4 5]
 [8 4 9 5 3 7 2 0 6 1]
 [7 1 6 9 4 8 2 5 0 3]
 [8 2 1 5 0 6 7 4 3 9]
 [8 7 2 1 9 0 3 4 6 5]
 [8 4 2 7 6 9 0 5 1 3]
 [3 4 7 5 2 8 0 6 1 9]]
Epoch 62710: Training cost= 2.3026, Training acc= 0.8468, Validation cost= 2.3026, Validation acc= 0.8463
Epoch 62720: Training cost= 2.3026, Training acc= 0.8466, Validation cost= 2.3026, Validation acc= 0.8461
Epoch 62730: Training cost= 2.3026, Training acc= 0.8465, Validation cost= 2.3026, Validation acc= 0.8460
Epoch 62740: Training cost= 2.3026, Training acc= 0.8464, Validation cost= 2.3026, Validation acc= 0.8459
Epoch 62750: Training cost= 2.3026, Training acc= 0.8463, Validation cost= 2.3026, Validation acc= 0.8458
Epoch 62760: Training cost= 2.3026, Training acc= 0.8462, Validation cost= 2.3026, Validation acc= 0.8457
Epoch 62770: Training cost= 2.3026, Training acc= 0.8460, Validation cost= 2.3026, Validation acc= 0.8455
Epoch 62780: Training cost= 2.3026, Training acc= 0.8459, Validation cost= 2.3026, Validation acc= 0.8454
Epoch 62790: Training cost= 2.3026, Training acc= 0.8458, Validation cost= 2.3026, Validation acc= 0.8453
Epoch 62800: Training cost= 2.3026, Training acc= 0.8457, Validation cost= 2.3026, Validation acc= 0.8452
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 8 3 1 5 2 0 9 6 4]
 [2 9 5 0 6 7 1 3 8 4]
 [4 2 7 8 9 1 3 0 5 6]
 [9 8 5 6 2 7 3 0 4 1]
 [0 6 8 5 7 1 2 4 3 9]
 [3 0 4 9 8 7 5 2 6 1]
 [2 0 4 5 7 8 3 1 9 6]
 [3 9 4 1 5 7 2 6 0 8]
 [4 2 6 3 7 9 8 0 5 1]
 [7 8 5 6 2 0 1 3 9 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 7 2 8 6 9 3 1 4 5]
 [6 5 2 4 8 0 1 7 9 3]
 [2 9 7 4 3 0 8 5 6 1]
 [3 2 0 6 7 4 8 9 1 5]
 [6 5 1 3 8 9 0 4 7 2]
 [5 4 7 0 8 6 9 2 3 1]
 [0 6 3 7 5 1 9 2 4 8]
 [8 0 5 1 2 6 9 7 4 3]
 [9 3 8 1 4 5 0 6 7 2]
 [6 0 5 8 4 2 3 9 7 1]]
Epoch 62810: Training cost= 2.3026, Training acc= 0.8456, Validation cost= 2.3026, Validation acc= 0.8451
Epoch 62820: Training cost= 2.3026, Training acc= 0.8455, Validation cost= 2.3026, Validation acc= 0.8449
Epoch 62830: Training cost= 2.3026, Training acc= 0.8453, Validation cost= 2.3026, Validation acc= 0.8448
Epoch 62840: Training cost= 2.3026, Training acc= 0.8452, Validation cost= 2.3026, Validation acc= 0.8447
Epoch 62850: Training cost= 2.3026, Training acc= 0.8451, Validation cost= 2.3026, Validation acc= 0.8446
Epoch 62860: Training cost= 2.3026, Training acc= 0.8450, Validation cost= 2.3026, Validation acc= 0.8445
Epoch 62870: Training cost= 2.3026, Training acc= 0.8449, Validation cost= 2.3026, Validation acc= 0.8444
Epoch 62880: Training cost= 2.3026, Training acc= 0.8447, Validation cost= 2.3026, Validation acc= 0.8442
Epoch 62890: Training cost= 2.3026, Training acc= 0.8446, Validation cost= 2.3026, Validation acc= 0.8441
Epoch 62900: Training cost= 2.3026, Training acc= 0.8445, Validation cost= 2.3026, Validation acc= 0.8440
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 6 0 1 5 3 9 2 4 8]
 [9 5 7 4 3 2 0 8 1 6]
 [1 0 8 5 6 2 9 4 3 7]
 [7 0 5 2 1 6 3 4 8 9]
 [2 4 7 5 9 6 1 8 0 3]
 [6 4 5 7 2 8 1 3 9 0]
 [4 5 1 8 9 7 3 0 2 6]
 [5 6 0 4 3 1 2 9 7 8]
 [4 7 3 8 9 1 0 2 5 6]
 [0 2 4 8 7 1 9 3 5 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 6 2 3 4 9 0 7 5 1]
 [5 2 8 7 6 1 0 4 9 3]
 [4 1 5 9 8 0 3 2 7 6]
 [5 9 3 6 7 1 2 0 4 8]
 [5 1 3 8 4 9 7 6 0 2]
 [6 0 7 5 9 8 2 4 1 3]
 [9 3 8 5 7 1 0 6 2 4]
 [5 1 4 7 3 9 6 0 2 8]
 [6 1 5 8 4 2 9 3 7 0]
 [5 9 1 3 4 7 6 2 0 8]]
Epoch 62910: Training cost= 2.3026, Training acc= 0.8444, Validation cost= 2.3026, Validation acc= 0.8439
Epoch 62920: Training cost= 2.3026, Training acc= 0.8443, Validation cost= 2.3026, Validation acc= 0.8438
Epoch 62930: Training cost= 2.3026, Training acc= 0.8442, Validation cost= 2.3026, Validation acc= 0.8436
Epoch 62940: Training cost= 2.3026, Training acc= 0.8440, Validation cost= 2.3026, Validation acc= 0.8435
Epoch 62950: Training cost= 2.3026, Training acc= 0.8439, Validation cost= 2.3026, Validation acc= 0.8434
Epoch 62960: Training cost= 2.3026, Training acc= 0.8438, Validation cost= 2.3026, Validation acc= 0.8433
Epoch 62970: Training cost= 2.3026, Training acc= 0.8437, Validation cost= 2.3026, Validation acc= 0.8432
Epoch 62980: Training cost= 2.3026, Training acc= 0.8436, Validation cost= 2.3026, Validation acc= 0.8431
Epoch 62990: Training cost= 2.3026, Training acc= 0.8434, Validation cost= 2.3026, Validation acc= 0.8429
Epoch 63000: Training cost= 2.3026, Training acc= 0.8433, Validation cost= 2.3026, Validation acc= 0.8428
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 2 3 9 6 5 7 4 1 8]
 [1 0 6 2 3 7 8 9 5 4]
 [2 3 1 8 7 4 9 6 5 0]
 [8 3 9 7 1 4 5 0 6 2]
 [3 8 5 7 2 9 1 6 4 0]
 [1 3 4 8 6 2 0 7 5 9]
 [4 7 1 5 3 2 0 9 6 8]
 [1 6 9 3 0 7 5 8 2 4]
 [7 4 9 0 1 8 2 5 3 6]
 [4 0 5 2 1 8 9 3 7 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 5 6 3 1 2 0 4 8 9]
 [6 1 2 0 3 5 7 4 8 9]
 [5 0 8 6 3 2 7 9 1 4]
 [5 2 4 7 9 1 6 3 0 8]
 [6 1 9 5 7 2 0 3 8 4]
 [4 3 2 6 7 8 9 5 1 0]
 [2 7 9 3 5 0 1 8 4 6]
 [2 5 7 8 4 0 1 9 6 3]
 [0 8 6 7 2 5 1 9 4 3]
 [9 5 8 4 1 7 6 0 2 3]]
Epoch 63010: Training cost= 2.3026, Training acc= 0.8432, Validation cost= 2.3026, Validation acc= 0.8427
Epoch 63020: Training cost= 2.3026, Training acc= 0.8431, Validation cost= 2.3026, Validation acc= 0.8426
Epoch 63030: Training cost= 2.3026, Training acc= 0.8430, Validation cost= 2.3026, Validation acc= 0.8425
Epoch 63040: Training cost= 2.3026, Training acc= 0.8429, Validation cost= 2.3026, Validation acc= 0.8423
Epoch 63050: Training cost= 2.3026, Training acc= 0.8427, Validation cost= 2.3026, Validation acc= 0.8422
Epoch 63060: Training cost= 2.3026, Training acc= 0.8426, Validation cost= 2.3026, Validation acc= 0.8421
Epoch 63070: Training cost= 2.3026, Training acc= 0.8425, Validation cost= 2.3026, Validation acc= 0.8420
Epoch 63080: Training cost= 2.3026, Training acc= 0.8424, Validation cost= 2.3026, Validation acc= 0.8419
Epoch 63090: Training cost= 2.3026, Training acc= 0.8423, Validation cost= 2.3026, Validation acc= 0.8418
Epoch 63100: Training cost= 2.3026, Training acc= 0.8421, Validation cost= 2.3026, Validation acc= 0.8416
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 8 3 0 2 4 7 5 1 9]
 [8 4 7 1 0 6 5 9 3 2]
 [3 4 0 5 2 9 1 6 7 8]
 [2 1 5 0 4 3 9 6 8 7]
 [9 2 0 6 1 5 3 4 8 7]
 [6 1 9 7 5 2 4 0 8 3]
 [7 1 6 2 4 5 8 3 9 0]
 [7 5 0 2 9 3 8 6 4 1]
 [3 9 2 4 6 7 8 5 1 0]
 [0 1 8 2 3 5 4 7 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 1 0 8 4 5 9 6 7]
 [5 8 1 2 9 3 6 0 7 4]
 [3 9 6 2 4 8 1 7 0 5]
 [1 7 2 9 3 4 5 0 6 8]
 [4 6 5 0 8 7 1 2 9 3]
 [1 0 4 6 8 7 9 2 5 3]
 [4 9 3 0 6 7 1 8 5 2]
 [4 6 0 1 7 2 8 9 3 5]
 [1 7 0 6 5 9 2 3 4 8]
 [8 3 0 6 2 4 1 7 5 9]]
Epoch 63110: Training cost= 2.3026, Training acc= 0.8420, Validation cost= 2.3026, Validation acc= 0.8415
Epoch 63120: Training cost= 2.3026, Training acc= 0.8419, Validation cost= 2.3026, Validation acc= 0.8414
Epoch 63130: Training cost= 2.3026, Training acc= 0.8418, Validation cost= 2.3026, Validation acc= 0.8413
Epoch 63140: Training cost= 2.3026, Training acc= 0.8417, Validation cost= 2.3026, Validation acc= 0.8412
Epoch 63150: Training cost= 2.3026, Training acc= 0.8416, Validation cost= 2.3026, Validation acc= 0.8411
Epoch 63160: Training cost= 2.3026, Training acc= 0.8414, Validation cost= 2.3026, Validation acc= 0.8409
Epoch 63170: Training cost= 2.3026, Training acc= 0.8413, Validation cost= 2.3026, Validation acc= 0.8408
Epoch 63180: Training cost= 2.3026, Training acc= 0.8412, Validation cost= 2.3026, Validation acc= 0.8407
Epoch 63190: Training cost= 2.3026, Training acc= 0.8411, Validation cost= 2.3026, Validation acc= 0.8406
Epoch 63200: Training cost= 2.3026, Training acc= 0.8410, Validation cost= 2.3026, Validation acc= 0.8405
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 9 8 3 2 6 0 4 5 7]
 [8 6 7 3 9 1 2 4 0 5]
 [4 8 5 3 2 9 7 0 1 6]
 [8 6 3 4 2 7 9 1 5 0]
 [7 2 0 5 3 9 1 4 6 8]
 [2 8 6 9 4 1 7 3 5 0]
 [6 7 4 1 5 0 2 9 3 8]
 [0 1 6 8 2 7 5 4 3 9]
 [6 3 1 0 8 2 9 5 4 7]
 [5 2 1 7 0 8 3 9 4 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 1 2 8 7 9 3 5 0 6]
 [6 0 9 8 4 5 7 2 3 1]
 [5 7 8 1 9 4 0 3 6 2]
 [4 3 6 7 0 8 1 5 2 9]
 [1 6 2 0 7 4 5 9 8 3]
 [0 7 1 4 5 2 8 9 6 3]
 [7 9 5 1 2 8 4 3 6 0]
 [0 5 2 7 4 8 1 6 3 9]
 [5 7 4 8 3 9 2 6 1 0]
 [5 1 4 3 9 0 6 7 2 8]]
Epoch 63210: Training cost= 2.3026, Training acc= 0.8409, Validation cost= 2.3026, Validation acc= 0.8404
Epoch 63220: Training cost= 2.3026, Training acc= 0.8407, Validation cost= 2.3026, Validation acc= 0.8402
Epoch 63230: Training cost= 2.3026, Training acc= 0.8406, Validation cost= 2.3026, Validation acc= 0.8401
Epoch 63240: Training cost= 2.3026, Training acc= 0.8405, Validation cost= 2.3026, Validation acc= 0.8400
Epoch 63250: Training cost= 2.3026, Training acc= 0.8404, Validation cost= 2.3026, Validation acc= 0.8399
Epoch 63260: Training cost= 2.3026, Training acc= 0.8403, Validation cost= 2.3026, Validation acc= 0.8398
Epoch 63270: Training cost= 2.3026, Training acc= 0.8402, Validation cost= 2.3026, Validation acc= 0.8397
Epoch 63280: Training cost= 2.3026, Training acc= 0.8400, Validation cost= 2.3026, Validation acc= 0.8395
Epoch 63290: Training cost= 2.3026, Training acc= 0.8399, Validation cost= 2.3026, Validation acc= 0.8394
Epoch 63300: Training cost= 2.3026, Training acc= 0.8398, Validation cost= 2.3026, Validation acc= 0.8393
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 9 5 3 4 0 7 8 1 6]
 [0 8 5 7 2 1 6 3 9 4]
 [8 4 1 9 5 3 6 2 0 7]
 [6 3 5 2 7 9 4 8 0 1]
 [1 2 7 4 5 6 8 0 9 3]
 [1 3 0 2 7 4 8 6 9 5]
 [4 7 2 6 9 5 1 0 3 8]
 [7 2 9 4 6 3 1 8 0 5]
 [6 8 0 3 7 2 9 5 1 4]
 [9 2 3 4 7 0 6 5 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 5 6 0 4 2 9 3 8 1]
 [2 9 0 4 5 3 8 7 1 6]
 [1 2 7 3 5 9 6 4 0 8]
 [1 0 7 2 6 8 5 3 4 9]
 [5 9 3 7 6 0 1 8 2 4]
 [4 0 2 3 6 9 1 5 7 8]
 [2 0 5 1 6 3 4 7 9 8]
 [2 3 4 6 7 1 9 8 0 5]
 [2 9 6 5 3 4 0 7 1 8]
 [8 3 5 4 9 2 1 7 6 0]]
Epoch 63310: Training cost= 2.3026, Training acc= 0.8397, Validation cost= 2.3026, Validation acc= 0.8392
Epoch 63320: Training cost= 2.3026, Training acc= 0.8396, Validation cost= 2.3026, Validation acc= 0.8391
Epoch 63330: Training cost= 2.3026, Training acc= 0.8395, Validation cost= 2.3026, Validation acc= 0.8389
Epoch 63340: Training cost= 2.3026, Training acc= 0.8393, Validation cost= 2.3026, Validation acc= 0.8388
Epoch 63350: Training cost= 2.3026, Training acc= 0.8392, Validation cost= 2.3026, Validation acc= 0.8387
Epoch 63360: Training cost= 2.3026, Training acc= 0.8391, Validation cost= 2.3026, Validation acc= 0.8386
Epoch 63370: Training cost= 2.3026, Training acc= 0.8390, Validation cost= 2.3026, Validation acc= 0.8385
Epoch 63380: Training cost= 2.3026, Training acc= 0.8389, Validation cost= 2.3026, Validation acc= 0.8384
Epoch 63390: Training cost= 2.3026, Training acc= 0.8388, Validation cost= 2.3026, Validation acc= 0.8383
Epoch 63400: Training cost= 2.3026, Training acc= 0.8386, Validation cost= 2.3026, Validation acc= 0.8381
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 5 8 6 9 0 7 1 3 4]
 [3 5 1 6 9 8 4 0 2 7]
 [5 2 9 4 3 7 1 0 8 6]
 [1 8 3 5 2 0 9 7 4 6]
 [8 4 3 2 9 7 0 1 6 5]
 [2 3 9 4 5 0 1 8 6 7]
 [7 2 6 1 0 4 5 3 8 9]
 [9 5 3 0 6 8 4 7 1 2]
 [3 4 7 8 2 5 6 0 1 9]
 [2 9 5 4 1 8 0 3 7 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 0 5 8 9 4 3 6 2 1]
 [6 8 5 4 1 2 0 9 3 7]
 [4 3 1 7 9 2 0 8 5 6]
 [1 2 0 3 6 4 5 7 8 9]
 [3 1 6 9 0 5 7 2 4 8]
 [8 5 9 7 6 1 4 3 2 0]
 [6 4 8 7 0 2 3 5 9 1]
 [7 1 3 4 2 5 9 6 8 0]
 [9 2 7 8 0 5 1 3 6 4]
 [1 3 6 7 9 4 2 5 0 8]]
Epoch 63410: Training cost= 2.3026, Training acc= 0.8385, Validation cost= 2.3026, Validation acc= 0.8380
Epoch 63420: Training cost= 2.3026, Training acc= 0.8384, Validation cost= 2.3026, Validation acc= 0.8379
Epoch 63430: Training cost= 2.3026, Training acc= 0.8383, Validation cost= 2.3026, Validation acc= 0.8378
Epoch 63440: Training cost= 2.3026, Training acc= 0.8382, Validation cost= 2.3026, Validation acc= 0.8377
Epoch 63450: Training cost= 2.3026, Training acc= 0.8381, Validation cost= 2.3026, Validation acc= 0.8376
Epoch 63460: Training cost= 2.3026, Training acc= 0.8379, Validation cost= 2.3026, Validation acc= 0.8374
Epoch 63470: Training cost= 2.3026, Training acc= 0.8378, Validation cost= 2.3026, Validation acc= 0.8373
Epoch 63480: Training cost= 2.3026, Training acc= 0.8377, Validation cost= 2.3026, Validation acc= 0.8372
Epoch 63490: Training cost= 2.3026, Training acc= 0.8376, Validation cost= 2.3026, Validation acc= 0.8371
Epoch 63500: Training cost= 2.3026, Training acc= 0.8375, Validation cost= 2.3026, Validation acc= 0.8370
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 3 0 6 7 5 4 1 9 2]
 [5 1 3 6 0 7 8 2 9 4]
 [2 7 9 5 1 0 3 6 4 8]
 [6 0 8 2 1 4 7 5 9 3]
 [0 3 1 4 5 6 2 9 7 8]
 [5 9 2 7 4 0 1 8 3 6]
 [4 9 3 5 0 8 2 6 1 7]
 [2 7 8 3 0 5 4 9 1 6]
 [2 6 1 3 8 5 0 4 7 9]
 [4 9 3 7 1 2 5 8 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 2 4 0 3 9 6 8 5 1]
 [1 0 3 9 7 5 8 2 4 6]
 [6 7 9 1 4 3 8 5 0 2]
 [6 4 8 9 3 2 7 0 1 5]
 [3 1 8 5 6 0 4 2 9 7]
 [2 9 6 8 0 1 3 5 4 7]
 [6 8 9 5 2 7 4 1 0 3]
 [2 3 4 6 8 1 7 0 5 9]
 [9 2 3 6 5 4 0 7 1 8]
 [5 1 3 0 7 9 6 4 8 2]]
Epoch 63510: Training cost= 2.3026, Training acc= 0.8374, Validation cost= 2.3026, Validation acc= 0.8369
Epoch 63520: Training cost= 2.3026, Training acc= 0.8372, Validation cost= 2.3026, Validation acc= 0.8367
Epoch 63530: Training cost= 2.3026, Training acc= 0.8371, Validation cost= 2.3026, Validation acc= 0.8366
Epoch 63540: Training cost= 2.3026, Training acc= 0.8370, Validation cost= 2.3026, Validation acc= 0.8365
Epoch 63550: Training cost= 2.3026, Training acc= 0.8369, Validation cost= 2.3026, Validation acc= 0.8364
Epoch 63560: Training cost= 2.3026, Training acc= 0.8368, Validation cost= 2.3026, Validation acc= 0.8363
Epoch 63570: Training cost= 2.3026, Training acc= 0.8367, Validation cost= 2.3026, Validation acc= 0.8362
Epoch 63580: Training cost= 2.3026, Training acc= 0.8365, Validation cost= 2.3026, Validation acc= 0.8360
Epoch 63590: Training cost= 2.3026, Training acc= 0.8364, Validation cost= 2.3026, Validation acc= 0.8359
Epoch 63600: Training cost= 2.3026, Training acc= 0.8363, Validation cost= 2.3026, Validation acc= 0.8358
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 1 9 4 5 0 2 8 6 7]
 [5 1 3 4 8 9 6 2 7 0]
 [2 4 0 7 3 9 5 6 1 8]
 [5 4 0 8 2 7 6 3 1 9]
 [5 3 9 7 8 1 4 2 6 0]
 [9 8 0 6 3 2 5 7 1 4]
 [7 5 6 0 9 2 8 1 4 3]
 [3 7 2 4 5 8 0 1 9 6]
 [3 1 0 9 2 5 4 6 7 8]
 [6 9 1 4 7 8 3 2 5 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 0 2 1 3 8 5 6 9 7]
 [7 5 1 8 9 0 6 4 3 2]
 [7 9 1 6 8 2 0 5 3 4]
 [9 3 0 5 1 8 4 7 2 6]
 [4 0 7 6 2 9 3 5 8 1]
 [0 4 6 2 3 1 7 9 8 5]
 [7 9 8 5 3 0 1 6 2 4]
 [6 9 0 8 2 3 5 4 1 7]
 [3 1 0 9 5 6 7 4 2 8]
 [7 0 6 5 4 2 9 8 1 3]]
Epoch 63610: Training cost= 2.3026, Training acc= 0.8362, Validation cost= 2.3026, Validation acc= 0.8357
Epoch 63620: Training cost= 2.3026, Training acc= 0.8361, Validation cost= 2.3026, Validation acc= 0.8356
Epoch 63630: Training cost= 2.3026, Training acc= 0.8360, Validation cost= 2.3026, Validation acc= 0.8355
Epoch 63640: Training cost= 2.3026, Training acc= 0.8359, Validation cost= 2.3026, Validation acc= 0.8353
Epoch 63650: Training cost= 2.3026, Training acc= 0.8357, Validation cost= 2.3026, Validation acc= 0.8352
Epoch 63660: Training cost= 2.3026, Training acc= 0.8356, Validation cost= 2.3026, Validation acc= 0.8351
Epoch 63670: Training cost= 2.3026, Training acc= 0.8355, Validation cost= 2.3026, Validation acc= 0.8350
Epoch 63680: Training cost= 2.3026, Training acc= 0.8354, Validation cost= 2.3026, Validation acc= 0.8349
Epoch 63690: Training cost= 2.3026, Training acc= 0.8353, Validation cost= 2.3026, Validation acc= 0.8348
Epoch 63700: Training cost= 2.3026, Training acc= 0.8352, Validation cost= 2.3026, Validation acc= 0.8347
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 2 6 3 5 0 8 9 1 4]
 [0 9 3 7 2 5 1 4 6 8]
 [7 4 1 9 0 8 2 3 6 5]
 [6 1 0 3 7 9 8 2 5 4]
 [5 2 1 0 9 4 6 3 8 7]
 [0 6 9 5 1 7 2 4 8 3]
 [8 0 1 4 5 2 6 9 3 7]
 [9 4 1 8 5 6 2 3 0 7]
 [1 3 8 5 7 6 0 4 2 9]
 [5 4 9 8 7 1 6 0 2 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 1 5 3 7 2 8 4 6 0]
 [7 3 1 4 8 5 6 9 2 0]
 [6 1 7 4 2 0 5 3 8 9]
 [8 4 5 0 3 2 9 7 6 1]
 [8 1 7 5 0 2 9 6 4 3]
 [2 3 5 9 1 4 6 8 0 7]
 [2 8 3 0 6 1 4 5 9 7]
 [2 3 0 7 6 9 8 1 5 4]
 [0 2 1 8 5 3 7 9 6 4]
 [0 2 7 1 3 9 4 5 8 6]]
Epoch 63710: Training cost= 2.3026, Training acc= 0.8350, Validation cost= 2.3026, Validation acc= 0.8345
Epoch 63720: Training cost= 2.3026, Training acc= 0.8349, Validation cost= 2.3026, Validation acc= 0.8344
Epoch 63730: Training cost= 2.3026, Training acc= 0.8348, Validation cost= 2.3026, Validation acc= 0.8343
Epoch 63740: Training cost= 2.3026, Training acc= 0.8347, Validation cost= 2.3026, Validation acc= 0.8342
Epoch 63750: Training cost= 2.3026, Training acc= 0.8346, Validation cost= 2.3026, Validation acc= 0.8341
Epoch 63760: Training cost= 2.3026, Training acc= 0.8345, Validation cost= 2.3026, Validation acc= 0.8340
Epoch 63770: Training cost= 2.3026, Training acc= 0.8344, Validation cost= 2.3026, Validation acc= 0.8339
Epoch 63780: Training cost= 2.3026, Training acc= 0.8342, Validation cost= 2.3026, Validation acc= 0.8337
Epoch 63790: Training cost= 2.3026, Training acc= 0.8341, Validation cost= 2.3026, Validation acc= 0.8336
Epoch 63800: Training cost= 2.3026, Training acc= 0.8340, Validation cost= 2.3026, Validation acc= 0.8335
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 0 2 8 4 3 1 9 5 6]
 [6 8 7 2 1 3 4 0 5 9]
 [1 2 0 9 8 5 4 6 7 3]
 [9 2 8 0 3 7 5 1 4 6]
 [8 7 4 9 5 1 3 2 6 0]
 [9 5 1 8 6 2 0 7 3 4]
 [0 7 9 3 4 6 8 5 2 1]
 [2 8 9 3 1 7 5 6 4 0]
 [8 2 7 1 5 4 6 0 9 3]
 [4 6 8 3 1 5 9 0 7 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 1 6 2 7 8 4 5 9 0]
 [9 2 8 3 5 1 0 6 7 4]
 [5 2 0 7 3 4 8 9 6 1]
 [8 4 5 3 9 7 1 6 0 2]
 [6 0 4 8 9 1 2 5 3 7]
 [5 8 2 0 6 1 7 9 4 3]
 [8 0 4 5 7 3 2 1 9 6]
 [7 0 4 1 2 6 9 5 8 3]
 [0 5 7 4 3 8 1 2 6 9]
 [0 5 2 6 8 4 9 7 1 3]]
Epoch 63810: Training cost= 2.3026, Training acc= 0.8339, Validation cost= 2.3026, Validation acc= 0.8334
Epoch 63820: Training cost= 2.3026, Training acc= 0.8338, Validation cost= 2.3026, Validation acc= 0.8333
Epoch 63830: Training cost= 2.3026, Training acc= 0.8337, Validation cost= 2.3026, Validation acc= 0.8332
Epoch 63840: Training cost= 2.3026, Training acc= 0.8335, Validation cost= 2.3026, Validation acc= 0.8330
Epoch 63850: Training cost= 2.3026, Training acc= 0.8334, Validation cost= 2.3026, Validation acc= 0.8329
Epoch 63860: Training cost= 2.3026, Training acc= 0.8333, Validation cost= 2.3026, Validation acc= 0.8328
Epoch 63870: Training cost= 2.3026, Training acc= 0.8332, Validation cost= 2.3026, Validation acc= 0.8327
Epoch 63880: Training cost= 2.3026, Training acc= 0.8331, Validation cost= 2.3026, Validation acc= 0.8326
Epoch 63890: Training cost= 2.3026, Training acc= 0.8330, Validation cost= 2.3026, Validation acc= 0.8325
Epoch 63900: Training cost= 2.3026, Training acc= 0.8329, Validation cost= 2.3026, Validation acc= 0.8324
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 4 9 0 1 6 5 3 8 2]
 [9 5 6 7 2 4 1 3 0 8]
 [6 2 7 4 1 0 8 9 5 3]
 [2 5 8 3 9 4 0 6 7 1]
 [6 5 9 2 4 7 3 8 0 1]
 [9 8 6 1 3 2 7 0 5 4]
 [4 0 9 7 3 6 5 8 1 2]
 [3 2 4 9 5 8 0 1 7 6]
 [7 5 2 4 3 0 9 8 1 6]
 [5 9 7 4 2 1 6 8 3 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 8 5 3 7 6 2 9 0 4]
 [6 5 8 1 7 3 0 9 4 2]
 [9 0 5 2 4 8 3 1 6 7]
 [8 6 9 3 0 4 2 5 7 1]
 [6 5 0 8 4 7 3 9 1 2]
 [4 7 6 2 9 3 0 1 5 8]
 [1 2 4 0 7 9 8 5 6 3]
 [1 0 7 5 4 2 6 8 9 3]
 [6 9 8 1 4 3 5 0 7 2]
 [8 6 0 1 2 9 4 7 3 5]]
Epoch 63910: Training cost= 2.3026, Training acc= 0.8327, Validation cost= 2.3026, Validation acc= 0.8322
Epoch 63920: Training cost= 2.3026, Training acc= 0.8326, Validation cost= 2.3026, Validation acc= 0.8321
Epoch 63930: Training cost= 2.3026, Training acc= 0.8325, Validation cost= 2.3026, Validation acc= 0.8320
Epoch 63940: Training cost= 2.3026, Training acc= 0.8324, Validation cost= 2.3026, Validation acc= 0.8319
Epoch 63950: Training cost= 2.3026, Training acc= 0.8323, Validation cost= 2.3026, Validation acc= 0.8318
Epoch 63960: Training cost= 2.3026, Training acc= 0.8322, Validation cost= 2.3026, Validation acc= 0.8317
Epoch 63970: Training cost= 2.3026, Training acc= 0.8321, Validation cost= 2.3026, Validation acc= 0.8316
Epoch 63980: Training cost= 2.3026, Training acc= 0.8319, Validation cost= 2.3026, Validation acc= 0.8314
Epoch 63990: Training cost= 2.3026, Training acc= 0.8318, Validation cost= 2.3026, Validation acc= 0.8313
Epoch 64000: Training cost= 2.3026, Training acc= 0.8317, Validation cost= 2.3026, Validation acc= 0.8312
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 3 2 7 8 6 0 5 4]
 [0 5 2 3 6 9 1 8 7 4]
 [9 2 4 5 8 7 6 0 3 1]
 [2 3 8 6 7 0 9 1 4 5]
 [5 8 6 7 2 0 4 1 9 3]
 [4 7 1 0 9 8 6 3 5 2]
 [2 4 8 7 3 0 5 6 9 1]
 [7 3 1 6 5 8 0 4 9 2]
 [4 5 1 9 3 8 6 7 0 2]
 [2 0 3 9 5 8 4 7 1 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 0 1 9 5 7 3 2 6 4]
 [7 5 8 3 2 0 6 4 9 1]
 [6 7 4 8 0 9 1 2 3 5]
 [1 2 3 5 0 7 4 6 8 9]
 [8 1 0 5 9 7 4 3 6 2]
 [8 2 9 4 7 3 0 1 6 5]
 [9 2 5 1 6 7 8 4 0 3]
 [1 5 3 9 6 8 0 2 7 4]
 [1 3 0 7 4 6 8 2 9 5]
 [3 6 4 0 2 1 9 5 7 8]]
Epoch 64010: Training cost= 2.3026, Training acc= 0.8316, Validation cost= 2.3026, Validation acc= 0.8311
Epoch 64020: Training cost= 2.3026, Training acc= 0.8315, Validation cost= 2.3026, Validation acc= 0.8310
Epoch 64030: Training cost= 2.3026, Training acc= 0.8314, Validation cost= 2.3026, Validation acc= 0.8309
Epoch 64040: Training cost= 2.3026, Training acc= 0.8313, Validation cost= 2.3026, Validation acc= 0.8308
Epoch 64050: Training cost= 2.3026, Training acc= 0.8311, Validation cost= 2.3026, Validation acc= 0.8306
Epoch 64060: Training cost= 2.3026, Training acc= 0.8310, Validation cost= 2.3026, Validation acc= 0.8305
Epoch 64070: Training cost= 2.3026, Training acc= 0.8309, Validation cost= 2.3026, Validation acc= 0.8304
Epoch 64080: Training cost= 2.3026, Training acc= 0.8308, Validation cost= 2.3026, Validation acc= 0.8303
Epoch 64090: Training cost= 2.3026, Training acc= 0.8307, Validation cost= 2.3026, Validation acc= 0.8302
Epoch 64100: Training cost= 2.3026, Training acc= 0.8306, Validation cost= 2.3026, Validation acc= 0.8301
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 0 3 2 9 7 4 6 1 8]
 [7 5 9 1 8 0 4 3 2 6]
 [2 5 7 0 9 4 3 6 8 1]
 [3 0 2 7 4 9 8 6 5 1]
 [6 2 0 4 7 1 9 3 8 5]
 [9 3 8 0 5 7 4 6 2 1]
 [9 8 5 3 1 0 2 6 4 7]
 [8 9 2 4 5 6 3 0 1 7]
 [4 7 9 0 6 2 5 8 3 1]
 [9 6 7 4 1 5 2 8 3 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 1 2 3 6 4 9 5 8 7]
 [3 6 8 2 5 9 0 4 1 7]
 [8 0 2 3 9 6 5 7 1 4]
 [4 3 6 5 7 8 0 9 1 2]
 [8 3 0 1 5 9 2 6 4 7]
 [8 0 6 4 9 5 3 2 1 7]
 [3 7 1 2 8 9 0 5 6 4]
 [9 8 7 4 0 6 3 1 5 2]
 [6 8 1 0 7 5 3 9 4 2]
 [8 1 3 6 2 7 9 4 0 5]]
Epoch 64110: Training cost= 2.3026, Training acc= 0.8305, Validation cost= 2.3026, Validation acc= 0.8300
Epoch 64120: Training cost= 2.3026, Training acc= 0.8303, Validation cost= 2.3026, Validation acc= 0.8298
Epoch 64130: Training cost= 2.3026, Training acc= 0.8302, Validation cost= 2.3026, Validation acc= 0.8297
Epoch 64140: Training cost= 2.3026, Training acc= 0.8301, Validation cost= 2.3026, Validation acc= 0.8296
Epoch 64150: Training cost= 2.3026, Training acc= 0.8300, Validation cost= 2.3026, Validation acc= 0.8295
Epoch 64160: Training cost= 2.3026, Training acc= 0.8299, Validation cost= 2.3026, Validation acc= 0.8294
Epoch 64170: Training cost= 2.3026, Training acc= 0.8298, Validation cost= 2.3026, Validation acc= 0.8293
Epoch 64180: Training cost= 2.3026, Training acc= 0.8297, Validation cost= 2.3026, Validation acc= 0.8292
Epoch 64190: Training cost= 2.3026, Training acc= 0.8295, Validation cost= 2.3026, Validation acc= 0.8290
Epoch 64200: Training cost= 2.3026, Training acc= 0.8294, Validation cost= 2.3026, Validation acc= 0.8289
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 5 4 8 3 0 6 2 7 1]
 [6 5 1 2 4 8 7 3 0 9]
 [6 1 8 0 4 3 2 5 9 7]
 [7 6 0 3 4 9 5 2 8 1]
 [0 8 6 2 5 1 4 3 9 7]
 [5 9 4 3 6 7 2 8 0 1]
 [8 5 1 2 6 0 7 4 3 9]
 [9 5 6 2 3 4 0 8 1 7]
 [5 6 1 0 7 3 2 9 4 8]
 [6 7 9 8 3 4 1 5 2 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 8 2 4 7 6 1 3 0 5]
 [0 9 1 8 6 4 7 5 3 2]
 [7 3 1 2 8 4 0 9 5 6]
 [3 7 9 1 6 5 2 0 4 8]
 [5 3 7 9 6 2 1 8 0 4]
 [9 1 5 7 3 6 4 0 8 2]
 [8 0 3 2 1 6 4 7 9 5]
 [5 1 8 9 4 7 2 6 0 3]
 [3 6 0 5 2 9 7 4 1 8]
 [5 1 4 9 7 2 8 3 6 0]]
Epoch 64210: Training cost= 2.3026, Training acc= 0.8293, Validation cost= 2.3026, Validation acc= 0.8288
Epoch 64220: Training cost= 2.3026, Training acc= 0.8292, Validation cost= 2.3026, Validation acc= 0.8287
Epoch 64230: Training cost= 2.3026, Training acc= 0.8291, Validation cost= 2.3026, Validation acc= 0.8286
Epoch 64240: Training cost= 2.3026, Training acc= 0.8290, Validation cost= 2.3026, Validation acc= 0.8285
Epoch 64250: Training cost= 2.3026, Training acc= 0.8289, Validation cost= 2.3026, Validation acc= 0.8284
Epoch 64260: Training cost= 2.3026, Training acc= 0.8288, Validation cost= 2.3026, Validation acc= 0.8283
Epoch 64270: Training cost= 2.3026, Training acc= 0.8286, Validation cost= 2.3026, Validation acc= 0.8281
Epoch 64280: Training cost= 2.3026, Training acc= 0.8285, Validation cost= 2.3026, Validation acc= 0.8280
Epoch 64290: Training cost= 2.3026, Training acc= 0.8284, Validation cost= 2.3026, Validation acc= 0.8279
Epoch 64300: Training cost= 2.3026, Training acc= 0.8283, Validation cost= 2.3026, Validation acc= 0.8278
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 5 3 0 7 6 4 8 2 9]
 [7 3 6 1 0 9 4 2 8 5]
 [9 7 8 4 2 5 3 1 6 0]
 [3 8 0 9 7 5 6 2 4 1]
 [3 9 5 1 4 0 2 8 6 7]
 [7 4 2 5 3 0 9 8 6 1]
 [2 3 9 4 0 7 8 5 1 6]
 [8 4 7 3 0 2 6 5 9 1]
 [9 2 3 0 5 8 6 7 1 4]
 [1 4 8 2 9 0 5 3 7 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 8 7 9 5 2 4 6 0 1]
 [1 2 5 6 3 4 0 8 9 7]
 [4 9 0 7 6 2 3 8 5 1]
 [2 6 3 9 4 0 5 8 1 7]
 [9 2 6 1 3 8 0 5 4 7]
 [8 9 5 3 4 6 0 1 2 7]
 [9 4 7 1 0 3 8 2 6 5]
 [6 3 0 8 7 2 4 5 1 9]
 [5 3 4 7 9 1 0 8 6 2]
 [9 5 8 2 7 6 0 4 1 3]]
Epoch 64310: Training cost= 2.3026, Training acc= 0.8282, Validation cost= 2.3026, Validation acc= 0.8277
Epoch 64320: Training cost= 2.3026, Training acc= 0.8281, Validation cost= 2.3026, Validation acc= 0.8276
Epoch 64330: Training cost= 2.3026, Training acc= 0.8280, Validation cost= 2.3026, Validation acc= 0.8275
Epoch 64340: Training cost= 2.3026, Training acc= 0.8278, Validation cost= 2.3026, Validation acc= 0.8273
Epoch 64350: Training cost= 2.3026, Training acc= 0.8277, Validation cost= 2.3026, Validation acc= 0.8272
Epoch 64360: Training cost= 2.3026, Training acc= 0.8276, Validation cost= 2.3026, Validation acc= 0.8271
Epoch 64370: Training cost= 2.3026, Training acc= 0.8275, Validation cost= 2.3026, Validation acc= 0.8270
Epoch 64380: Training cost= 2.3026, Training acc= 0.8274, Validation cost= 2.3026, Validation acc= 0.8269
Epoch 64390: Training cost= 2.3026, Training acc= 0.8273, Validation cost= 2.3026, Validation acc= 0.8268
Epoch 64400: Training cost= 2.3026, Training acc= 0.8272, Validation cost= 2.3026, Validation acc= 0.8267
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 8 0 6 5 9 2 4 1 7]
 [7 1 4 8 2 5 6 9 0 3]
 [1 8 5 2 4 7 6 9 0 3]
 [9 2 0 1 3 7 5 4 6 8]
 [6 4 3 2 8 7 1 0 5 9]
 [9 6 2 5 0 8 3 4 1 7]
 [4 6 1 3 9 2 8 7 5 0]
 [0 1 9 3 5 8 4 6 2 7]
 [9 8 5 6 1 0 3 7 4 2]
 [3 1 5 2 4 0 8 6 7 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 7 6 0 8 9 5 4 2 1]
 [9 3 4 2 6 8 1 7 5 0]
 [1 7 5 8 6 0 9 3 4 2]
 [4 3 9 5 6 0 2 1 8 7]
 [0 6 3 8 7 4 5 9 1 2]
 [2 3 7 8 4 1 9 0 6 5]
 [9 1 5 8 3 7 0 4 6 2]
 [7 5 2 3 8 9 4 6 0 1]
 [7 1 3 4 5 8 6 9 2 0]
 [6 5 7 0 9 4 1 2 8 3]]
Epoch 64410: Training cost= 2.3026, Training acc= 0.8271, Validation cost= 2.3026, Validation acc= 0.8266
Epoch 64420: Training cost= 2.3026, Training acc= 0.8269, Validation cost= 2.3026, Validation acc= 0.8264
Epoch 64430: Training cost= 2.3026, Training acc= 0.8268, Validation cost= 2.3026, Validation acc= 0.8263
Epoch 64440: Training cost= 2.3026, Training acc= 0.8267, Validation cost= 2.3026, Validation acc= 0.8262
Epoch 64450: Training cost= 2.3026, Training acc= 0.8266, Validation cost= 2.3026, Validation acc= 0.8261
Epoch 64460: Training cost= 2.3026, Training acc= 0.8265, Validation cost= 2.3026, Validation acc= 0.8260
Epoch 64470: Training cost= 2.3026, Training acc= 0.8264, Validation cost= 2.3026, Validation acc= 0.8259
Epoch 64480: Training cost= 2.3026, Training acc= 0.8263, Validation cost= 2.3026, Validation acc= 0.8258
Epoch 64490: Training cost= 2.3026, Training acc= 0.8262, Validation cost= 2.3026, Validation acc= 0.8257
Epoch 64500: Training cost= 2.3026, Training acc= 0.8260, Validation cost= 2.3026, Validation acc= 0.8255
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 0 3 4 2 5 9 1 8 6]
 [5 4 2 3 7 6 1 0 9 8]
 [2 8 5 6 3 0 7 1 4 9]
 [9 5 2 3 7 4 6 8 1 0]
 [1 6 8 3 0 5 4 2 7 9]
 [1 2 8 0 9 4 7 6 5 3]
 [0 1 6 4 2 3 5 8 9 7]
 [7 2 9 3 8 1 0 4 6 5]
 [3 7 1 5 2 6 9 0 8 4]
 [3 7 4 5 2 6 9 8 0 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 4 2 6 7 3 9 0 8 1]
 [8 2 7 6 1 0 9 4 3 5]
 [9 4 7 5 1 8 3 0 6 2]
 [3 1 2 5 0 4 7 8 9 6]
 [1 8 5 0 9 2 4 6 7 3]
 [9 2 4 3 8 0 6 7 1 5]
 [2 5 1 9 3 0 6 7 8 4]
 [5 4 1 0 6 8 2 9 3 7]
 [0 5 3 1 7 6 8 2 9 4]
 [6 0 9 5 4 1 2 8 3 7]]
Epoch 64510: Training cost= 2.3026, Training acc= 0.8259, Validation cost= 2.3026, Validation acc= 0.8254
Epoch 64520: Training cost= 2.3026, Training acc= 0.8258, Validation cost= 2.3026, Validation acc= 0.8253
Epoch 64530: Training cost= 2.3026, Training acc= 0.8257, Validation cost= 2.3026, Validation acc= 0.8252
Epoch 64540: Training cost= 2.3026, Training acc= 0.8256, Validation cost= 2.3026, Validation acc= 0.8251
Epoch 64550: Training cost= 2.3026, Training acc= 0.8255, Validation cost= 2.3026, Validation acc= 0.8250
Epoch 64560: Training cost= 2.3026, Training acc= 0.8254, Validation cost= 2.3026, Validation acc= 0.8249
Epoch 64570: Training cost= 2.3026, Training acc= 0.8253, Validation cost= 2.3026, Validation acc= 0.8248
Epoch 64580: Training cost= 2.3026, Training acc= 0.8251, Validation cost= 2.3026, Validation acc= 0.8246
Epoch 64590: Training cost= 2.3026, Training acc= 0.8250, Validation cost= 2.3026, Validation acc= 0.8245
Epoch 64600: Training cost= 2.3026, Training acc= 0.8249, Validation cost= 2.3026, Validation acc= 0.8244
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 3 6 5 8 0 2 9 4 1]
 [2 4 9 5 6 3 7 1 0 8]
 [3 9 7 5 8 0 6 2 4 1]
 [5 3 6 2 0 9 7 4 1 8]
 [6 7 5 0 9 3 4 8 1 2]
 [2 6 5 8 0 3 1 7 9 4]
 [7 9 6 8 2 5 0 4 3 1]
 [9 5 4 0 7 1 6 8 2 3]
 [6 2 1 9 0 5 8 3 4 7]
 [5 4 1 9 6 3 7 8 2 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 6 2 0 3 9 8 7 4 1]
 [4 0 3 8 7 5 1 2 9 6]
 [3 7 6 8 2 9 1 5 4 0]
 [4 6 2 0 9 3 7 5 8 1]
 [6 7 4 9 5 8 3 0 2 1]
 [6 4 8 1 5 2 9 7 3 0]
 [8 1 3 5 7 0 6 4 2 9]
 [4 5 9 1 6 0 2 3 8 7]
 [9 8 2 5 4 3 6 0 1 7]
 [3 2 4 8 5 6 0 1 7 9]]
Epoch 64610: Training cost= 2.3026, Training acc= 0.8248, Validation cost= 2.3026, Validation acc= 0.8243
Epoch 64620: Training cost= 2.3026, Training acc= 0.8247, Validation cost= 2.3026, Validation acc= 0.8242
Epoch 64630: Training cost= 2.3026, Training acc= 0.8246, Validation cost= 2.3026, Validation acc= 0.8241
Epoch 64640: Training cost= 2.3026, Training acc= 0.8245, Validation cost= 2.3026, Validation acc= 0.8240
Epoch 64650: Training cost= 2.3026, Training acc= 0.8244, Validation cost= 2.3026, Validation acc= 0.8239
Epoch 64660: Training cost= 2.3026, Training acc= 0.8242, Validation cost= 2.3026, Validation acc= 0.8237
Epoch 64670: Training cost= 2.3026, Training acc= 0.8241, Validation cost= 2.3026, Validation acc= 0.8236
Epoch 64680: Training cost= 2.3026, Training acc= 0.8240, Validation cost= 2.3026, Validation acc= 0.8235
Epoch 64690: Training cost= 2.3026, Training acc= 0.8239, Validation cost= 2.3026, Validation acc= 0.8234
Epoch 64700: Training cost= 2.3026, Training acc= 0.8238, Validation cost= 2.3026, Validation acc= 0.8233
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 5 8 3 2 6 1 4 7 9]
 [1 5 9 2 6 4 3 8 0 7]
 [2 0 7 1 3 9 6 8 5 4]
 [6 4 3 7 1 8 5 2 0 9]
 [2 8 7 0 4 5 1 3 9 6]
 [8 1 6 9 2 7 0 3 4 5]
 [8 7 9 0 4 1 2 3 5 6]
 [1 0 5 2 8 3 7 9 6 4]
 [9 8 6 2 0 5 7 3 1 4]
 [8 7 9 4 3 2 1 6 0 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 6 8 1 7 9 4 2 0 5]
 [4 0 2 7 3 5 6 9 8 1]
 [6 2 8 5 4 3 7 9 1 0]
 [7 3 1 4 8 6 0 9 2 5]
 [8 9 4 3 1 2 5 0 6 7]
 [7 6 4 9 5 0 1 3 8 2]
 [2 3 8 0 5 6 9 4 1 7]
 [2 0 3 5 8 4 7 9 1 6]
 [4 7 0 1 2 5 9 3 6 8]
 [3 5 9 4 8 6 1 2 0 7]]
Epoch 64710: Training cost= 2.3026, Training acc= 0.8237, Validation cost= 2.3026, Validation acc= 0.8232
Epoch 64720: Training cost= 2.3026, Training acc= 0.8236, Validation cost= 2.3026, Validation acc= 0.8231
Epoch 64730: Training cost= 2.3026, Training acc= 0.8235, Validation cost= 2.3026, Validation acc= 0.8230
Epoch 64740: Training cost= 2.3026, Training acc= 0.8233, Validation cost= 2.3026, Validation acc= 0.8229
Epoch 64750: Training cost= 2.3026, Training acc= 0.8232, Validation cost= 2.3026, Validation acc= 0.8227
Epoch 64760: Training cost= 2.3026, Training acc= 0.8231, Validation cost= 2.3026, Validation acc= 0.8226
Epoch 64770: Training cost= 2.3026, Training acc= 0.8230, Validation cost= 2.3026, Validation acc= 0.8225
Epoch 64780: Training cost= 2.3026, Training acc= 0.8229, Validation cost= 2.3026, Validation acc= 0.8224
Epoch 64790: Training cost= 2.3026, Training acc= 0.8228, Validation cost= 2.3026, Validation acc= 0.8223
Epoch 64800: Training cost= 2.3026, Training acc= 0.8227, Validation cost= 2.3026, Validation acc= 0.8222
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 5 4 0 1 3 9 2 8 6]
 [1 7 2 9 3 8 5 0 6 4]
 [7 1 2 5 6 3 9 4 0 8]
 [6 2 0 3 9 8 1 5 7 4]
 [9 2 7 4 8 0 1 5 6 3]
 [1 9 4 6 7 8 5 3 2 0]
 [6 9 2 7 8 4 3 5 1 0]
 [6 5 1 3 9 2 0 7 8 4]
 [7 0 1 5 3 8 2 9 6 4]
 [4 7 6 0 9 3 8 5 2 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 4 3 6 9 8 0 1 5 2]
 [8 3 6 4 5 1 7 2 9 0]
 [2 3 1 4 8 7 0 9 6 5]
 [7 2 1 9 5 8 3 6 0 4]
 [6 7 3 0 5 2 1 8 4 9]
 [8 0 5 3 2 1 4 9 7 6]
 [1 3 7 9 8 4 5 6 0 2]
 [3 4 8 1 7 0 9 6 2 5]
 [8 2 4 7 3 9 0 5 6 1]
 [5 0 7 6 9 1 4 2 8 3]]
Epoch 64810: Training cost= 2.3026, Training acc= 0.8226, Validation cost= 2.3026, Validation acc= 0.8221
Epoch 64820: Training cost= 2.3026, Training acc= 0.8225, Validation cost= 2.3026, Validation acc= 0.8220
Epoch 64830: Training cost= 2.3026, Training acc= 0.8223, Validation cost= 2.3026, Validation acc= 0.8219
Epoch 64840: Training cost= 2.3026, Training acc= 0.8222, Validation cost= 2.3026, Validation acc= 0.8217
Epoch 64850: Training cost= 2.3026, Training acc= 0.8221, Validation cost= 2.3026, Validation acc= 0.8216
Epoch 64860: Training cost= 2.3026, Training acc= 0.8220, Validation cost= 2.3026, Validation acc= 0.8215
Epoch 64870: Training cost= 2.3026, Training acc= 0.8219, Validation cost= 2.3026, Validation acc= 0.8214
Epoch 64880: Training cost= 2.3026, Training acc= 0.8218, Validation cost= 2.3026, Validation acc= 0.8213
Epoch 64890: Training cost= 2.3026, Training acc= 0.8217, Validation cost= 2.3026, Validation acc= 0.8212
Epoch 64900: Training cost= 2.3026, Training acc= 0.8216, Validation cost= 2.3026, Validation acc= 0.8211
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 1 0 4 2 7 3 9 6 5]
 [4 8 6 5 9 2 7 1 3 0]
 [0 9 3 2 6 8 5 7 4 1]
 [2 9 8 7 4 5 1 6 0 3]
 [2 1 8 9 0 6 3 4 5 7]
 [0 4 7 6 5 9 1 2 8 3]
 [3 5 4 7 2 1 9 8 6 0]
 [0 5 1 8 9 6 4 7 2 3]
 [1 4 6 7 0 9 8 5 2 3]
 [9 8 1 5 0 6 7 4 3 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 5 6 9 2 1 0 7 3 8]
 [2 1 9 0 8 3 6 5 4 7]
 [2 8 0 4 5 9 6 1 3 7]
 [9 5 7 2 3 6 8 1 4 0]
 [5 3 0 2 4 7 8 1 6 9]
 [9 1 0 5 2 3 4 8 7 6]
 [8 1 0 7 2 6 9 3 5 4]
 [7 8 4 3 0 2 6 5 9 1]
 [6 4 2 1 9 0 7 8 5 3]
 [5 6 1 8 0 3 4 2 7 9]]
Epoch 64910: Training cost= 2.3026, Training acc= 0.8215, Validation cost= 2.3026, Validation acc= 0.8210
Epoch 64920: Training cost= 2.3026, Training acc= 0.8213, Validation cost= 2.3026, Validation acc= 0.8209
Epoch 64930: Training cost= 2.3026, Training acc= 0.8212, Validation cost= 2.3026, Validation acc= 0.8207
Epoch 64940: Training cost= 2.3026, Training acc= 0.8211, Validation cost= 2.3026, Validation acc= 0.8206
Epoch 64950: Training cost= 2.3026, Training acc= 0.8210, Validation cost= 2.3026, Validation acc= 0.8205
Epoch 64960: Training cost= 2.3026, Training acc= 0.8209, Validation cost= 2.3026, Validation acc= 0.8204
Epoch 64970: Training cost= 2.3026, Training acc= 0.8208, Validation cost= 2.3026, Validation acc= 0.8203
Epoch 64980: Training cost= 2.3026, Training acc= 0.8207, Validation cost= 2.3026, Validation acc= 0.8202
Epoch 64990: Training cost= 2.3026, Training acc= 0.8206, Validation cost= 2.3026, Validation acc= 0.8201
Epoch 65000: Training cost= 2.3026, Training acc= 0.8205, Validation cost= 2.3026, Validation acc= 0.8200
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 4 0 3 2 5 7 1 9 6]
 [1 5 9 3 4 7 0 6 2 8]
 [1 6 2 5 4 0 9 7 3 8]
 [7 3 1 5 4 6 9 0 2 8]
 [5 3 0 1 2 8 4 7 9 6]
 [1 2 4 8 9 6 3 7 0 5]
 [2 8 0 4 6 5 9 1 3 7]
 [2 8 5 1 3 6 4 7 0 9]
 [2 0 5 7 6 1 9 4 3 8]
 [8 5 4 9 7 6 1 2 0 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 5 0 3 9 8 7 6 1 4]
 [4 8 7 1 5 2 6 0 9 3]
 [2 4 9 5 0 6 3 7 8 1]
 [2 6 5 1 4 8 0 7 3 9]
 [4 7 0 6 1 9 5 8 2 3]
 [0 6 7 4 9 5 8 2 3 1]
 [7 4 8 9 6 1 0 2 3 5]
 [6 3 7 2 5 8 0 1 9 4]
 [2 9 3 1 0 4 7 6 5 8]
 [3 5 4 2 6 0 1 8 7 9]]
Epoch 65010: Training cost= 2.3026, Training acc= 0.8203, Validation cost= 2.3026, Validation acc= 0.8199
Epoch 65020: Training cost= 2.3026, Training acc= 0.8202, Validation cost= 2.3026, Validation acc= 0.8197
Epoch 65030: Training cost= 2.3026, Training acc= 0.8201, Validation cost= 2.3026, Validation acc= 0.8196
Epoch 65040: Training cost= 2.3026, Training acc= 0.8200, Validation cost= 2.3026, Validation acc= 0.8195
Epoch 65050: Training cost= 2.3026, Training acc= 0.8199, Validation cost= 2.3026, Validation acc= 0.8194
Epoch 65060: Training cost= 2.3026, Training acc= 0.8198, Validation cost= 2.3026, Validation acc= 0.8193
Epoch 65070: Training cost= 2.3026, Training acc= 0.8197, Validation cost= 2.3026, Validation acc= 0.8192
Epoch 65080: Training cost= 2.3026, Training acc= 0.8196, Validation cost= 2.3026, Validation acc= 0.8191
Epoch 65090: Training cost= 2.3026, Training acc= 0.8195, Validation cost= 2.3026, Validation acc= 0.8190
Epoch 65100: Training cost= 2.3026, Training acc= 0.8193, Validation cost= 2.3026, Validation acc= 0.8189
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 5 6 2 3 8 9 4 7 1]
 [7 6 0 4 1 2 5 3 8 9]
 [9 7 2 4 8 3 0 5 6 1]
 [3 1 2 8 9 5 7 6 0 4]
 [2 5 9 0 6 3 8 1 4 7]
 [3 8 7 4 1 0 2 6 5 9]
 [8 1 2 4 6 0 7 3 9 5]
 [5 4 6 0 1 7 3 9 2 8]
 [5 2 8 6 9 0 1 7 3 4]
 [8 7 3 1 9 6 2 5 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 9 1 3 4 8 6 0 7 5]
 [7 8 1 9 4 0 3 6 5 2]
 [8 3 5 6 7 1 2 4 9 0]
 [3 4 7 0 9 8 6 1 5 2]
 [1 3 0 7 6 9 5 8 4 2]
 [1 6 0 8 3 7 2 5 9 4]
 [5 8 2 1 9 6 0 3 7 4]
 [6 0 8 3 9 4 7 5 2 1]
 [2 9 7 1 5 8 6 4 3 0]
 [7 5 9 6 8 3 1 0 4 2]]
Epoch 65110: Training cost= 2.3026, Training acc= 0.8192, Validation cost= 2.3026, Validation acc= 0.8187
Epoch 65120: Training cost= 2.3026, Training acc= 0.8191, Validation cost= 2.3026, Validation acc= 0.8186
Epoch 65130: Training cost= 2.3026, Training acc= 0.8190, Validation cost= 2.3026, Validation acc= 0.8185
Epoch 65140: Training cost= 2.3026, Training acc= 0.8189, Validation cost= 2.3026, Validation acc= 0.8184
Epoch 65150: Training cost= 2.3026, Training acc= 0.8188, Validation cost= 2.3026, Validation acc= 0.8183
Epoch 65160: Training cost= 2.3026, Training acc= 0.8187, Validation cost= 2.3026, Validation acc= 0.8182
Epoch 65170: Training cost= 2.3026, Training acc= 0.8186, Validation cost= 2.3026, Validation acc= 0.8181
Epoch 65180: Training cost= 2.3026, Training acc= 0.8185, Validation cost= 2.3026, Validation acc= 0.8180
Epoch 65190: Training cost= 2.3026, Training acc= 0.8184, Validation cost= 2.3026, Validation acc= 0.8179
Epoch 65200: Training cost= 2.3026, Training acc= 0.8182, Validation cost= 2.3026, Validation acc= 0.8178
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 2 7 1 6 5 9 8 4 0]
 [4 8 5 1 6 3 2 9 7 0]
 [4 7 6 2 1 9 8 5 3 0]
 [5 6 9 1 8 7 2 4 0 3]
 [2 3 5 7 0 1 8 9 6 4]
 [2 1 6 9 8 5 4 0 7 3]
 [5 4 0 1 2 7 8 3 9 6]
 [5 2 1 8 3 9 7 6 0 4]
 [5 8 6 0 1 4 2 9 7 3]
 [6 1 0 9 7 8 3 5 2 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 9 7 5 1 6 8 4 2 3]
 [8 2 5 4 9 7 6 1 3 0]
 [3 2 7 9 6 5 1 8 0 4]
 [8 7 9 5 1 6 2 3 4 0]
 [5 3 9 2 0 1 7 4 8 6]
 [0 8 6 7 4 2 9 3 1 5]
 [8 3 4 1 5 0 9 2 7 6]
 [3 4 8 0 7 5 6 1 2 9]
 [2 6 1 5 4 9 8 0 7 3]
 [9 8 1 3 4 2 0 7 5 6]]
Epoch 65210: Training cost= 2.3026, Training acc= 0.8181, Validation cost= 2.3026, Validation acc= 0.8176
Epoch 65220: Training cost= 2.3026, Training acc= 0.8180, Validation cost= 2.3026, Validation acc= 0.8175
Epoch 65230: Training cost= 2.3026, Training acc= 0.8179, Validation cost= 2.3026, Validation acc= 0.8174
Epoch 65240: Training cost= 2.3026, Training acc= 0.8178, Validation cost= 2.3026, Validation acc= 0.8173
Epoch 65250: Training cost= 2.3026, Training acc= 0.8177, Validation cost= 2.3026, Validation acc= 0.8172
Epoch 65260: Training cost= 2.3026, Training acc= 0.8176, Validation cost= 2.3026, Validation acc= 0.8171
Epoch 65270: Training cost= 2.3026, Training acc= 0.8175, Validation cost= 2.3026, Validation acc= 0.8170
Epoch 65280: Training cost= 2.3026, Training acc= 0.8174, Validation cost= 2.3026, Validation acc= 0.8169
Epoch 65290: Training cost= 2.3026, Training acc= 0.8173, Validation cost= 2.3026, Validation acc= 0.8168
Epoch 65300: Training cost= 2.3026, Training acc= 0.8171, Validation cost= 2.3026, Validation acc= 0.8167
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 7 5 8 9 6 1 4 0 3]
 [8 9 1 2 7 3 6 5 4 0]
 [0 3 1 2 4 6 5 9 8 7]
 [2 5 3 8 7 6 4 0 1 9]
 [1 9 7 3 4 0 8 2 6 5]
 [9 5 7 2 0 1 6 4 8 3]
 [8 1 2 0 7 4 3 5 6 9]
 [6 1 3 0 5 9 4 8 2 7]
 [6 0 8 5 3 4 1 9 7 2]
 [9 4 6 2 5 8 1 0 7 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 1 7 3 2 0 5 8 6 9]
 [6 3 0 4 8 7 9 2 5 1]
 [4 1 3 6 7 9 0 8 5 2]
 [1 3 0 2 5 9 7 4 8 6]
 [6 0 3 4 9 1 7 2 5 8]
 [9 4 7 8 3 6 1 2 5 0]
 [0 3 9 8 4 1 7 6 2 5]
 [5 3 4 9 6 1 2 0 8 7]
 [2 0 1 3 5 7 9 8 4 6]
 [6 2 5 4 0 7 8 1 9 3]]
Epoch 65310: Training cost= 2.3026, Training acc= 0.8170, Validation cost= 2.3026, Validation acc= 0.8165
Epoch 65320: Training cost= 2.3026, Training acc= 0.8169, Validation cost= 2.3026, Validation acc= 0.8164
Epoch 65330: Training cost= 2.3026, Training acc= 0.8168, Validation cost= 2.3026, Validation acc= 0.8163
Epoch 65340: Training cost= 2.3026, Training acc= 0.8167, Validation cost= 2.3026, Validation acc= 0.8162
Epoch 65350: Training cost= 2.3026, Training acc= 0.8166, Validation cost= 2.3026, Validation acc= 0.8161
Epoch 65360: Training cost= 2.3026, Training acc= 0.8165, Validation cost= 2.3026, Validation acc= 0.8160
Epoch 65370: Training cost= 2.3026, Training acc= 0.8164, Validation cost= 2.3026, Validation acc= 0.8159
Epoch 65380: Training cost= 2.3026, Training acc= 0.8163, Validation cost= 2.3026, Validation acc= 0.8158
Epoch 65390: Training cost= 2.3026, Training acc= 0.8162, Validation cost= 2.3026, Validation acc= 0.8157
Epoch 65400: Training cost= 2.3026, Training acc= 0.8160, Validation cost= 2.3026, Validation acc= 0.8156
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 7 8 0 1 3 2 5 6]
 [9 3 0 8 7 6 2 1 5 4]
 [9 7 0 2 1 3 5 4 8 6]
 [2 8 6 4 5 3 9 1 7 0]
 [5 9 4 6 3 0 2 7 8 1]
 [2 3 1 4 8 0 5 7 6 9]
 [9 7 6 8 3 1 4 2 5 0]
 [2 5 8 3 1 4 9 6 0 7]
 [9 6 2 8 7 1 0 4 3 5]
 [4 9 1 6 7 2 8 5 0 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 2 6 1 3 5 0 9 7 4]
 [3 0 4 8 1 7 9 5 2 6]
 [1 6 4 2 0 5 7 8 9 3]
 [6 8 0 5 2 7 3 4 9 1]
 [1 2 7 9 6 0 5 4 8 3]
 [2 1 3 9 8 0 7 4 6 5]
 [3 0 5 9 7 1 6 8 4 2]
 [8 4 1 6 2 9 3 7 0 5]
 [6 4 9 2 7 8 5 3 0 1]
 [7 1 0 5 2 9 3 6 8 4]]
Epoch 65410: Training cost= 2.3026, Training acc= 0.8159, Validation cost= 2.3026, Validation acc= 0.8155
Epoch 65420: Training cost= 2.3026, Training acc= 0.8158, Validation cost= 2.3026, Validation acc= 0.8153
Epoch 65430: Training cost= 2.3026, Training acc= 0.8157, Validation cost= 2.3026, Validation acc= 0.8152
Epoch 65440: Training cost= 2.3026, Training acc= 0.8156, Validation cost= 2.3026, Validation acc= 0.8151
Epoch 65450: Training cost= 2.3026, Training acc= 0.8155, Validation cost= 2.3026, Validation acc= 0.8150
Epoch 65460: Training cost= 2.3026, Training acc= 0.8154, Validation cost= 2.3026, Validation acc= 0.8149
Epoch 65470: Training cost= 2.3026, Training acc= 0.8153, Validation cost= 2.3026, Validation acc= 0.8148
Epoch 65480: Training cost= 2.3026, Training acc= 0.8152, Validation cost= 2.3026, Validation acc= 0.8147
Epoch 65490: Training cost= 2.3026, Training acc= 0.8151, Validation cost= 2.3026, Validation acc= 0.8146
Epoch 65500: Training cost= 2.3026, Training acc= 0.8150, Validation cost= 2.3026, Validation acc= 0.8145
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 7 1 2 3 8 9 0 5 4]
 [7 6 3 1 5 8 0 4 9 2]
 [0 2 7 9 6 5 4 8 3 1]
 [5 3 6 1 4 7 8 9 2 0]
 [6 2 3 7 5 1 0 4 9 8]
 [5 9 1 0 8 7 6 3 2 4]
 [2 3 4 7 8 0 1 9 6 5]
 [3 8 6 1 7 5 9 2 4 0]
 [6 3 0 9 4 5 8 1 2 7]
 [0 6 4 8 5 3 9 1 2 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 3 9 1 7 2 6 0 4 8]
 [8 3 6 4 7 1 2 5 9 0]
 [8 9 0 3 7 4 1 6 2 5]
 [9 6 5 0 4 1 3 2 7 8]
 [7 3 8 4 0 1 2 5 6 9]
 [3 9 2 4 5 6 7 8 1 0]
 [0 6 9 8 3 5 2 7 4 1]
 [5 1 4 0 8 7 6 9 2 3]
 [7 6 2 0 5 1 9 3 4 8]
 [6 2 1 5 9 3 7 8 0 4]]
Epoch 65510: Training cost= 2.3026, Training acc= 0.8148, Validation cost= 2.3026, Validation acc= 0.8144
Epoch 65520: Training cost= 2.3026, Training acc= 0.8147, Validation cost= 2.3026, Validation acc= 0.8143
Epoch 65530: Training cost= 2.3026, Training acc= 0.8146, Validation cost= 2.3026, Validation acc= 0.8141
Epoch 65540: Training cost= 2.3026, Training acc= 0.8145, Validation cost= 2.3026, Validation acc= 0.8140
Epoch 65550: Training cost= 2.3026, Training acc= 0.8144, Validation cost= 2.3026, Validation acc= 0.8139
Epoch 65560: Training cost= 2.3026, Training acc= 0.8143, Validation cost= 2.3026, Validation acc= 0.8138
Epoch 65570: Training cost= 2.3026, Training acc= 0.8142, Validation cost= 2.3026, Validation acc= 0.8137
Epoch 65580: Training cost= 2.3026, Training acc= 0.8141, Validation cost= 2.3026, Validation acc= 0.8136
Epoch 65590: Training cost= 2.3026, Training acc= 0.8140, Validation cost= 2.3026, Validation acc= 0.8135
Epoch 65600: Training cost= 2.3026, Training acc= 0.8139, Validation cost= 2.3026, Validation acc= 0.8134
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 2 9 7 1 3 6 0 4 5]
 [0 2 5 3 1 7 8 6 9 4]
 [3 5 0 6 7 1 8 9 2 4]
 [0 7 9 4 1 2 8 3 5 6]
 [9 3 0 5 7 8 6 4 2 1]
 [4 5 0 9 1 8 6 3 7 2]
 [2 7 5 9 6 4 1 3 8 0]
 [4 7 0 8 5 3 9 2 1 6]
 [8 4 7 0 5 9 3 6 1 2]
 [7 1 4 0 6 9 5 2 8 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 6 8 0 5 9 3 1 2 7]
 [7 6 1 3 2 5 8 0 9 4]
 [1 4 3 0 8 9 2 5 7 6]
 [1 6 3 7 2 4 0 9 5 8]
 [8 0 3 4 1 5 6 7 9 2]
 [1 0 9 8 7 3 6 5 4 2]
 [4 1 0 2 9 3 8 7 5 6]
 [8 1 0 3 6 7 2 9 5 4]
 [2 7 0 1 9 8 3 4 6 5]
 [0 8 5 3 4 9 7 6 2 1]]
Epoch 65610: Training cost= 2.3026, Training acc= 0.8138, Validation cost= 2.3026, Validation acc= 0.8133
Epoch 65620: Training cost= 2.3026, Training acc= 0.8136, Validation cost= 2.3026, Validation acc= 0.8132
Epoch 65630: Training cost= 2.3026, Training acc= 0.8135, Validation cost= 2.3026, Validation acc= 0.8131
Epoch 65640: Training cost= 2.3026, Training acc= 0.8134, Validation cost= 2.3026, Validation acc= 0.8129
Epoch 65650: Training cost= 2.3026, Training acc= 0.8133, Validation cost= 2.3026, Validation acc= 0.8128
Epoch 65660: Training cost= 2.3026, Training acc= 0.8132, Validation cost= 2.3026, Validation acc= 0.8127
Epoch 65670: Training cost= 2.3026, Training acc= 0.8131, Validation cost= 2.3026, Validation acc= 0.8126
Epoch 65680: Training cost= 2.3026, Training acc= 0.8130, Validation cost= 2.3026, Validation acc= 0.8125
Epoch 65690: Training cost= 2.3026, Training acc= 0.8129, Validation cost= 2.3026, Validation acc= 0.8124
Epoch 65700: Training cost= 2.3026, Training acc= 0.8128, Validation cost= 2.3026, Validation acc= 0.8123
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 5 8 1 0 7 3 2 9 4]
 [0 7 1 9 8 2 3 4 6 5]
 [5 2 4 7 1 8 3 0 6 9]
 [3 5 7 1 9 8 6 0 4 2]
 [3 1 4 6 0 9 7 2 8 5]
 [0 4 5 8 6 1 9 7 2 3]
 [4 9 8 2 6 5 7 0 3 1]
 [0 3 1 6 7 5 2 8 9 4]
 [7 8 9 6 1 2 5 3 4 0]
 [7 6 8 3 5 0 4 2 9 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 1 4 7 3 0 8 6 5 9]
 [9 8 5 1 0 2 4 7 6 3]
 [3 2 5 6 9 4 7 1 8 0]
 [2 1 9 8 7 3 4 5 6 0]
 [3 5 7 0 9 4 6 1 8 2]
 [8 4 6 1 5 0 3 7 9 2]
 [6 4 7 2 8 5 1 3 0 9]
 [6 1 7 9 0 5 3 8 4 2]
 [6 0 7 1 5 4 3 8 2 9]
 [5 3 8 4 6 1 0 9 2 7]]
Epoch 65710: Training cost= 2.3026, Training acc= 0.8127, Validation cost= 2.3026, Validation acc= 0.8122
Epoch 65720: Training cost= 2.3026, Training acc= 0.8126, Validation cost= 2.3026, Validation acc= 0.8121
Epoch 65730: Training cost= 2.3026, Training acc= 0.8125, Validation cost= 2.3026, Validation acc= 0.8120
Epoch 65740: Training cost= 2.3026, Training acc= 0.8123, Validation cost= 2.3026, Validation acc= 0.8119
Epoch 65750: Training cost= 2.3026, Training acc= 0.8122, Validation cost= 2.3026, Validation acc= 0.8118
Epoch 65760: Training cost= 2.3026, Training acc= 0.8121, Validation cost= 2.3026, Validation acc= 0.8116
Epoch 65770: Training cost= 2.3026, Training acc= 0.8120, Validation cost= 2.3026, Validation acc= 0.8115
Epoch 65780: Training cost= 2.3026, Training acc= 0.8119, Validation cost= 2.3026, Validation acc= 0.8114
Epoch 65790: Training cost= 2.3026, Training acc= 0.8118, Validation cost= 2.3026, Validation acc= 0.8113
Epoch 65800: Training cost= 2.3026, Training acc= 0.8117, Validation cost= 2.3026, Validation acc= 0.8112
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 8 7 5 3 9 1 0 4 2]
 [7 5 8 9 3 0 6 4 2 1]
 [3 2 9 4 1 7 6 5 8 0]
 [5 0 4 3 9 1 2 7 6 8]
 [5 6 1 8 7 0 2 4 3 9]
 [3 6 8 1 7 9 2 0 5 4]
 [4 2 8 1 5 0 6 9 7 3]
 [0 1 5 6 4 8 7 9 2 3]
 [3 9 2 0 8 7 1 6 4 5]
 [0 8 9 7 1 5 3 4 6 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 3 0 2 6 5 7 1 9 8]
 [2 1 5 4 0 7 8 9 3 6]
 [1 5 0 3 8 4 7 6 2 9]
 [9 7 3 1 4 0 6 2 8 5]
 [3 8 1 5 4 0 9 2 7 6]
 [5 8 6 2 3 9 0 4 7 1]
 [2 3 0 5 1 8 9 4 7 6]
 [4 2 6 1 8 5 9 7 0 3]
 [4 3 2 7 8 1 9 5 0 6]
 [6 7 5 2 0 1 8 9 3 4]]
Epoch 65810: Training cost= 2.3026, Training acc= 0.8116, Validation cost= 2.3026, Validation acc= 0.8111
Epoch 65820: Training cost= 2.3026, Training acc= 0.8115, Validation cost= 2.3026, Validation acc= 0.8110
Epoch 65830: Training cost= 2.3026, Training acc= 0.8114, Validation cost= 2.3026, Validation acc= 0.8109
Epoch 65840: Training cost= 2.3026, Training acc= 0.8113, Validation cost= 2.3026, Validation acc= 0.8108
Epoch 65850: Training cost= 2.3026, Training acc= 0.8112, Validation cost= 2.3026, Validation acc= 0.8107
Epoch 65860: Training cost= 2.3026, Training acc= 0.8110, Validation cost= 2.3026, Validation acc= 0.8106
Epoch 65870: Training cost= 2.3026, Training acc= 0.8109, Validation cost= 2.3026, Validation acc= 0.8105
Epoch 65880: Training cost= 2.3026, Training acc= 0.8108, Validation cost= 2.3026, Validation acc= 0.8103
Epoch 65890: Training cost= 2.3026, Training acc= 0.8107, Validation cost= 2.3026, Validation acc= 0.8102
Epoch 65900: Training cost= 2.3026, Training acc= 0.8106, Validation cost= 2.3026, Validation acc= 0.8101
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 4 2 8 6 7 9 3 0 1]
 [4 1 5 8 6 2 9 3 7 0]
 [3 9 2 6 8 1 0 7 4 5]
 [9 5 1 7 2 4 8 3 6 0]
 [5 7 6 0 2 9 8 3 1 4]
 [1 2 5 8 3 0 4 6 9 7]
 [1 0 9 5 4 3 6 7 8 2]
 [1 7 0 9 8 5 2 6 4 3]
 [6 1 9 0 2 3 7 4 8 5]
 [4 2 5 3 9 1 8 6 7 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 7 5 3 1 6 9 8 2 0]
 [1 0 2 8 3 9 5 4 6 7]
 [8 4 2 3 0 1 9 7 5 6]
 [0 7 1 9 3 5 4 2 6 8]
 [2 8 1 0 7 3 4 6 9 5]
 [7 9 6 8 1 4 2 0 3 5]
 [2 1 3 8 5 7 6 4 0 9]
 [5 2 8 6 0 3 4 1 9 7]
 [5 9 6 3 2 8 0 4 7 1]
 [7 6 0 3 4 5 9 2 8 1]]
Epoch 65910: Training cost= 2.3026, Training acc= 0.8105, Validation cost= 2.3026, Validation acc= 0.8100
Epoch 65920: Training cost= 2.3026, Training acc= 0.8104, Validation cost= 2.3026, Validation acc= 0.8099
Epoch 65930: Training cost= 2.3026, Training acc= 0.8103, Validation cost= 2.3026, Validation acc= 0.8098
Epoch 65940: Training cost= 2.3026, Training acc= 0.8102, Validation cost= 2.3026, Validation acc= 0.8097
Epoch 65950: Training cost= 2.3026, Training acc= 0.8101, Validation cost= 2.3026, Validation acc= 0.8096
Epoch 65960: Training cost= 2.3026, Training acc= 0.8100, Validation cost= 2.3026, Validation acc= 0.8095
Epoch 65970: Training cost= 2.3026, Training acc= 0.8099, Validation cost= 2.3026, Validation acc= 0.8094
Epoch 65980: Training cost= 2.3026, Training acc= 0.8098, Validation cost= 2.3026, Validation acc= 0.8093
Epoch 65990: Training cost= 2.3026, Training acc= 0.8096, Validation cost= 2.3026, Validation acc= 0.8092
Epoch 66000: Training cost= 2.3026, Training acc= 0.8095, Validation cost= 2.3026, Validation acc= 0.8091
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 7 0 1 6 5 2 3 8 9]
 [3 0 4 7 1 8 9 2 5 6]
 [3 2 0 6 8 9 5 7 4 1]
 [1 9 7 8 4 5 2 0 6 3]
 [4 6 7 3 1 2 5 8 9 0]
 [7 3 0 9 1 8 4 5 6 2]
 [1 3 4 2 5 7 8 6 9 0]
 [8 9 5 1 4 6 3 7 2 0]
 [8 9 3 0 2 5 7 6 4 1]
 [7 3 9 4 0 6 8 1 5 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 5 2 3 7 1 8 9 0 4]
 [4 1 0 9 6 3 2 7 5 8]
 [1 0 8 6 5 9 4 2 7 3]
 [4 8 1 7 2 6 0 9 3 5]
 [4 0 5 1 9 3 7 8 2 6]
 [6 2 8 5 9 3 1 0 4 7]
 [4 9 6 3 0 2 7 8 5 1]
 [3 5 0 6 7 8 4 2 9 1]
 [3 5 6 1 4 7 2 0 8 9]
 [2 7 3 5 9 0 8 4 6 1]]
Epoch 66010: Training cost= 2.3026, Training acc= 0.8094, Validation cost= 2.3026, Validation acc= 0.8089
Epoch 66020: Training cost= 2.3026, Training acc= 0.8093, Validation cost= 2.3026, Validation acc= 0.8088
Epoch 66030: Training cost= 2.3026, Training acc= 0.8092, Validation cost= 2.3026, Validation acc= 0.8087
Epoch 66040: Training cost= 2.3026, Training acc= 0.8091, Validation cost= 2.3026, Validation acc= 0.8086
Epoch 66050: Training cost= 2.3026, Training acc= 0.8090, Validation cost= 2.3026, Validation acc= 0.8085
Epoch 66060: Training cost= 2.3026, Training acc= 0.8089, Validation cost= 2.3026, Validation acc= 0.8084
Epoch 66070: Training cost= 2.3026, Training acc= 0.8088, Validation cost= 2.3026, Validation acc= 0.8083
Epoch 66080: Training cost= 2.3026, Training acc= 0.8087, Validation cost= 2.3026, Validation acc= 0.8082
Epoch 66090: Training cost= 2.3026, Training acc= 0.8086, Validation cost= 2.3026, Validation acc= 0.8081
Epoch 66100: Training cost= 2.3026, Training acc= 0.8085, Validation cost= 2.3026, Validation acc= 0.8080
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 2 7 4 3 1 6 9 0 5]
 [4 5 0 1 8 6 3 7 9 2]
 [8 7 6 2 4 0 1 3 5 9]
 [8 6 4 1 5 9 2 3 0 7]
 [0 6 5 4 1 8 3 7 9 2]
 [5 2 6 4 0 9 3 7 1 8]
 [0 2 3 1 5 6 9 4 7 8]
 [8 5 6 7 9 3 4 2 0 1]
 [0 3 5 8 4 6 2 7 9 1]
 [5 6 3 8 2 7 9 1 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 2 5 3 0 1 4 7 6 9]
 [9 8 2 1 5 3 6 0 4 7]
 [6 5 0 7 1 8 4 9 3 2]
 [0 8 9 4 5 1 7 2 6 3]
 [0 5 6 8 1 9 4 2 3 7]
 [2 8 9 1 0 7 4 5 6 3]
 [2 6 0 4 1 7 5 8 9 3]
 [1 3 0 9 8 7 5 6 4 2]
 [8 9 6 4 0 3 7 1 2 5]
 [1 5 3 9 0 6 4 2 8 7]]
Epoch 66110: Training cost= 2.3026, Training acc= 0.8084, Validation cost= 2.3026, Validation acc= 0.8079
Epoch 66120: Training cost= 2.3026, Training acc= 0.8083, Validation cost= 2.3026, Validation acc= 0.8078
Epoch 66130: Training cost= 2.3026, Training acc= 0.8081, Validation cost= 2.3026, Validation acc= 0.8077
Epoch 66140: Training cost= 2.3026, Training acc= 0.8080, Validation cost= 2.3026, Validation acc= 0.8076
Epoch 66150: Training cost= 2.3026, Training acc= 0.8079, Validation cost= 2.3026, Validation acc= 0.8074
Epoch 66160: Training cost= 2.3026, Training acc= 0.8078, Validation cost= 2.3026, Validation acc= 0.8073
Epoch 66170: Training cost= 2.3026, Training acc= 0.8077, Validation cost= 2.3026, Validation acc= 0.8072
Epoch 66180: Training cost= 2.3026, Training acc= 0.8076, Validation cost= 2.3026, Validation acc= 0.8071
Epoch 66190: Training cost= 2.3026, Training acc= 0.8075, Validation cost= 2.3026, Validation acc= 0.8070
Epoch 66200: Training cost= 2.3026, Training acc= 0.8074, Validation cost= 2.3026, Validation acc= 0.8069
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 0 9 5 1 3 6 7 8 4]
 [5 2 1 9 0 8 6 7 4 3]
 [5 8 0 2 7 1 3 6 9 4]
 [2 1 7 6 4 3 0 9 5 8]
 [1 0 8 7 4 5 9 6 2 3]
 [2 6 3 7 0 4 9 8 5 1]
 [0 9 8 4 3 5 2 7 1 6]
 [5 9 2 6 1 3 0 4 8 7]
 [5 1 7 6 9 2 4 8 0 3]
 [1 0 6 8 5 2 4 9 7 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 5 9 4 3 0 7 2 8 1]
 [3 5 2 4 7 6 0 8 9 1]
 [8 9 6 4 1 0 2 5 3 7]
 [5 3 8 6 9 1 2 4 0 7]
 [0 1 3 2 6 4 8 7 5 9]
 [5 7 1 8 9 4 6 0 3 2]
 [3 2 9 8 0 7 5 6 4 1]
 [9 4 5 1 2 7 6 3 8 0]
 [2 1 4 0 5 9 6 7 3 8]
 [6 0 9 2 4 3 1 7 5 8]]
Epoch 66210: Training cost= 2.3026, Training acc= 0.8073, Validation cost= 2.3026, Validation acc= 0.8068
Epoch 66220: Training cost= 2.3026, Training acc= 0.8072, Validation cost= 2.3026, Validation acc= 0.8067
Epoch 66230: Training cost= 2.3026, Training acc= 0.8071, Validation cost= 2.3026, Validation acc= 0.8066
Epoch 66240: Training cost= 2.3026, Training acc= 0.8070, Validation cost= 2.3026, Validation acc= 0.8065
Epoch 66250: Training cost= 2.3026, Training acc= 0.8069, Validation cost= 2.3026, Validation acc= 0.8064
Epoch 66260: Training cost= 2.3026, Training acc= 0.8068, Validation cost= 2.3026, Validation acc= 0.8063
Epoch 66270: Training cost= 2.3026, Training acc= 0.8066, Validation cost= 2.3026, Validation acc= 0.8062
Epoch 66280: Training cost= 2.3026, Training acc= 0.8065, Validation cost= 2.3026, Validation acc= 0.8061
Epoch 66290: Training cost= 2.3026, Training acc= 0.8064, Validation cost= 2.3026, Validation acc= 0.8060
Epoch 66300: Training cost= 2.3026, Training acc= 0.8063, Validation cost= 2.3026, Validation acc= 0.8058
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 8 2 3 6 7 4 0 9 5]
 [6 5 9 3 0 7 4 2 8 1]
 [3 7 9 8 1 2 4 5 6 0]
 [6 3 1 4 9 8 5 0 2 7]
 [5 0 1 4 8 2 9 7 6 3]
 [3 1 5 0 7 6 9 8 4 2]
 [2 7 4 9 3 5 6 8 1 0]
 [0 2 7 3 8 6 9 4 1 5]
 [5 4 9 8 0 3 6 1 7 2]
 [4 7 9 6 0 8 2 1 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 2 9 8 5 3 4 6 1 7]
 [7 3 5 1 0 6 8 4 2 9]
 [5 8 1 2 7 0 9 6 4 3]
 [6 9 5 2 0 3 7 1 4 8]
 [0 9 6 2 7 4 5 8 1 3]
 [4 9 8 1 2 6 7 3 5 0]
 [7 2 9 0 8 6 1 5 4 3]
 [6 1 2 4 9 5 0 8 3 7]
 [1 0 6 8 5 3 9 4 7 2]
 [6 3 7 0 5 9 4 8 1 2]]
Epoch 66310: Training cost= 2.3026, Training acc= 0.8062, Validation cost= 2.3026, Validation acc= 0.8057
Epoch 66320: Training cost= 2.3026, Training acc= 0.8061, Validation cost= 2.3026, Validation acc= 0.8056
Epoch 66330: Training cost= 2.3026, Training acc= 0.8060, Validation cost= 2.3026, Validation acc= 0.8055
Epoch 66340: Training cost= 2.3026, Training acc= 0.8059, Validation cost= 2.3026, Validation acc= 0.8054
Epoch 66350: Training cost= 2.3026, Training acc= 0.8058, Validation cost= 2.3026, Validation acc= 0.8053
Epoch 66360: Training cost= 2.3026, Training acc= 0.8057, Validation cost= 2.3026, Validation acc= 0.8052
Epoch 66370: Training cost= 2.3026, Training acc= 0.8056, Validation cost= 2.3026, Validation acc= 0.8051
Epoch 66380: Training cost= 2.3026, Training acc= 0.8055, Validation cost= 2.3026, Validation acc= 0.8050
Epoch 66390: Training cost= 2.3026, Training acc= 0.8054, Validation cost= 2.3026, Validation acc= 0.8049
Epoch 66400: Training cost= 2.3026, Training acc= 0.8053, Validation cost= 2.3026, Validation acc= 0.8048
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 7 0 2 5 1 8 3 4 9]
 [5 3 1 8 7 2 4 6 9 0]
 [3 2 5 0 8 4 7 1 6 9]
 [4 2 3 8 6 7 1 5 9 0]
 [7 1 0 5 9 6 8 3 2 4]
 [4 1 3 6 9 2 8 7 0 5]
 [7 3 4 5 9 2 6 8 1 0]
 [1 2 6 0 7 4 9 5 3 8]
 [9 7 1 4 2 3 8 5 0 6]
 [0 1 5 8 2 3 4 9 7 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 9 4 5 8 7 2 0 6 3]
 [1 0 4 8 9 3 5 2 6 7]
 [0 6 7 3 1 8 4 9 2 5]
 [3 4 0 6 9 2 7 5 1 8]
 [6 7 5 1 2 8 4 9 3 0]
 [4 6 0 9 5 8 3 1 7 2]
 [8 9 6 0 1 7 5 4 3 2]
 [2 7 8 1 0 6 5 4 9 3]
 [6 9 1 5 4 2 7 0 3 8]
 [2 0 9 6 1 5 4 8 7 3]]
Epoch 66410: Training cost= 2.3026, Training acc= 0.8052, Validation cost= 2.3026, Validation acc= 0.8047
Epoch 66420: Training cost= 2.3026, Training acc= 0.8051, Validation cost= 2.3026, Validation acc= 0.8046
Epoch 66430: Training cost= 2.3026, Training acc= 0.8049, Validation cost= 2.3026, Validation acc= 0.8045
Epoch 66440: Training cost= 2.3026, Training acc= 0.8048, Validation cost= 2.3026, Validation acc= 0.8044
Epoch 66450: Training cost= 2.3026, Training acc= 0.8047, Validation cost= 2.3026, Validation acc= 0.8043
Epoch 66460: Training cost= 2.3026, Training acc= 0.8046, Validation cost= 2.3026, Validation acc= 0.8041
Epoch 66470: Training cost= 2.3026, Training acc= 0.8045, Validation cost= 2.3026, Validation acc= 0.8040
Epoch 66480: Training cost= 2.3026, Training acc= 0.8044, Validation cost= 2.3026, Validation acc= 0.8039
Epoch 66490: Training cost= 2.3026, Training acc= 0.8043, Validation cost= 2.3026, Validation acc= 0.8038
Epoch 66500: Training cost= 2.3026, Training acc= 0.8042, Validation cost= 2.3026, Validation acc= 0.8037
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 9 6 2 1 7 4 3 0 8]
 [0 2 8 5 7 4 9 3 6 1]
 [6 0 9 1 3 7 5 4 8 2]
 [1 5 7 0 4 6 3 8 2 9]
 [8 2 4 0 9 6 3 7 1 5]
 [2 8 3 7 9 0 6 4 1 5]
 [8 2 7 1 5 6 9 3 4 0]
 [5 1 2 3 7 6 8 0 9 4]
 [8 1 9 4 0 2 6 3 5 7]
 [8 6 1 0 7 3 2 5 4 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 9 5 3 8 2 1 7 6 4]
 [3 1 6 5 8 0 4 9 2 7]
 [8 9 7 0 6 4 3 5 1 2]
 [7 8 6 9 3 4 0 2 5 1]
 [0 9 2 1 6 3 4 8 7 5]
 [2 7 4 9 5 6 3 1 0 8]
 [3 2 0 8 6 7 4 9 5 1]
 [4 0 8 3 9 5 6 2 7 1]
 [9 2 4 6 8 5 1 7 3 0]
 [6 4 9 8 0 3 5 1 7 2]]
Epoch 66510: Training cost= 2.3026, Training acc= 0.8041, Validation cost= 2.3026, Validation acc= 0.8036
Epoch 66520: Training cost= 2.3026, Training acc= 0.8040, Validation cost= 2.3026, Validation acc= 0.8035
Epoch 66530: Training cost= 2.3026, Training acc= 0.8039, Validation cost= 2.3026, Validation acc= 0.8034
Epoch 66540: Training cost= 2.3026, Training acc= 0.8038, Validation cost= 2.3026, Validation acc= 0.8033
Epoch 66550: Training cost= 2.3026, Training acc= 0.8037, Validation cost= 2.3026, Validation acc= 0.8032
Epoch 66560: Training cost= 2.3026, Training acc= 0.8036, Validation cost= 2.3026, Validation acc= 0.8031
Epoch 66570: Training cost= 2.3026, Training acc= 0.8035, Validation cost= 2.3026, Validation acc= 0.8030
Epoch 66580: Training cost= 2.3026, Training acc= 0.8034, Validation cost= 2.3026, Validation acc= 0.8029
Epoch 66590: Training cost= 2.3026, Training acc= 0.8033, Validation cost= 2.3026, Validation acc= 0.8028
Epoch 66600: Training cost= 2.3026, Training acc= 0.8031, Validation cost= 2.3026, Validation acc= 0.8027
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 5 4 1 9 3 6 2 0 8]
 [9 3 5 8 7 0 4 1 2 6]
 [3 4 9 7 2 1 6 0 5 8]
 [4 9 6 7 2 3 8 0 5 1]
 [6 8 7 4 1 0 5 2 3 9]
 [6 4 8 9 2 7 3 5 1 0]
 [1 0 7 8 5 2 3 9 6 4]
 [7 6 3 2 0 9 1 8 5 4]
 [2 9 0 3 6 5 4 7 8 1]
 [9 0 8 7 4 6 5 2 1 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 1 4 6 2 3 5 9 7 0]
 [7 8 1 9 0 6 5 3 4 2]
 [6 4 9 3 2 7 8 5 0 1]
 [9 7 8 4 2 1 5 6 0 3]
 [0 9 2 1 3 8 6 7 5 4]
 [1 3 7 8 2 0 5 9 6 4]
 [2 6 1 4 3 9 7 5 8 0]
 [0 9 7 3 8 6 5 4 1 2]
 [7 2 5 1 6 4 9 0 8 3]
 [0 4 7 5 6 2 8 9 1 3]]
Epoch 66610: Training cost= 2.3026, Training acc= 0.8030, Validation cost= 2.3026, Validation acc= 0.8026
Epoch 66620: Training cost= 2.3026, Training acc= 0.8029, Validation cost= 2.3026, Validation acc= 0.8025
Epoch 66630: Training cost= 2.3026, Training acc= 0.8028, Validation cost= 2.3026, Validation acc= 0.8024
Epoch 66640: Training cost= 2.3026, Training acc= 0.8027, Validation cost= 2.3026, Validation acc= 0.8022
Epoch 66650: Training cost= 2.3026, Training acc= 0.8026, Validation cost= 2.3026, Validation acc= 0.8021
Epoch 66660: Training cost= 2.3026, Training acc= 0.8025, Validation cost= 2.3026, Validation acc= 0.8020
Epoch 66670: Training cost= 2.3026, Training acc= 0.8024, Validation cost= 2.3026, Validation acc= 0.8019
Epoch 66680: Training cost= 2.3026, Training acc= 0.8023, Validation cost= 2.3026, Validation acc= 0.8018
Epoch 66690: Training cost= 2.3026, Training acc= 0.8022, Validation cost= 2.3026, Validation acc= 0.8017
Epoch 66700: Training cost= 2.3026, Training acc= 0.8021, Validation cost= 2.3026, Validation acc= 0.8016
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 2 4 7 0 3 6 9 1 8]
 [1 5 2 7 4 6 8 3 0 9]
 [4 3 9 5 2 0 7 6 1 8]
 [8 6 1 3 2 9 7 0 5 4]
 [1 8 4 6 3 7 0 2 5 9]
 [9 2 7 1 3 0 6 8 4 5]
 [7 9 1 2 6 8 4 3 5 0]
 [3 7 6 4 8 2 1 5 0 9]
 [8 5 7 3 0 2 6 1 9 4]
 [5 1 0 6 4 8 9 3 7 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 7 9 8 3 0 5 2 4 6]
 [9 2 3 0 4 8 5 7 6 1]
 [7 9 8 6 4 5 1 3 2 0]
 [7 9 3 6 2 1 0 4 5 8]
 [3 4 1 5 6 2 9 0 7 8]
 [4 9 1 7 2 8 6 3 0 5]
 [8 9 2 0 3 4 1 5 7 6]
 [8 3 9 5 0 6 1 7 2 4]
 [1 5 6 9 2 4 8 0 3 7]
 [1 8 9 5 3 6 0 7 4 2]]
Epoch 66710: Training cost= 2.3026, Training acc= 0.8020, Validation cost= 2.3026, Validation acc= 0.8015
Epoch 66720: Training cost= 2.3026, Training acc= 0.8019, Validation cost= 2.3026, Validation acc= 0.8014
Epoch 66730: Training cost= 2.3026, Training acc= 0.8018, Validation cost= 2.3026, Validation acc= 0.8013
Epoch 66740: Training cost= 2.3026, Training acc= 0.8017, Validation cost= 2.3026, Validation acc= 0.8012
Epoch 66750: Training cost= 2.3026, Training acc= 0.8016, Validation cost= 2.3026, Validation acc= 0.8011
Epoch 66760: Training cost= 2.3026, Training acc= 0.8015, Validation cost= 2.3026, Validation acc= 0.8010
Epoch 66770: Training cost= 2.3026, Training acc= 0.8014, Validation cost= 2.3026, Validation acc= 0.8009
Epoch 66780: Training cost= 2.3026, Training acc= 0.8013, Validation cost= 2.3026, Validation acc= 0.8008
Epoch 66790: Training cost= 2.3026, Training acc= 0.8011, Validation cost= 2.3026, Validation acc= 0.8007
Epoch 66800: Training cost= 2.3026, Training acc= 0.8010, Validation cost= 2.3026, Validation acc= 0.8006
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 3 5 4 1 9 7 6 8 0]
 [2 4 3 8 9 0 6 5 7 1]
 [8 9 2 3 1 0 4 5 6 7]
 [1 2 0 8 3 5 9 6 4 7]
 [0 1 3 4 8 9 6 7 2 5]
 [7 5 9 4 6 8 2 3 0 1]
 [8 5 6 4 3 9 1 2 7 0]
 [3 1 7 6 2 4 8 0 9 5]
 [9 8 1 5 7 0 3 2 6 4]
 [5 0 3 6 8 9 4 7 1 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 2 7 9 1 3 5 8 4 6]
 [3 7 5 8 1 2 4 0 9 6]
 [7 0 4 1 6 9 3 2 5 8]
 [1 9 8 2 3 0 4 5 7 6]
 [9 7 1 2 8 3 6 5 4 0]
 [0 6 1 8 2 7 9 4 3 5]
 [9 8 7 3 1 6 2 0 5 4]
 [3 1 2 0 9 6 8 7 5 4]
 [8 6 1 0 5 4 9 2 7 3]
 [3 0 2 9 6 4 1 5 8 7]]
Epoch 66810: Training cost= 2.3026, Training acc= 0.8009, Validation cost= 2.3026, Validation acc= 0.8005
Epoch 66820: Training cost= 2.3026, Training acc= 0.8008, Validation cost= 2.3026, Validation acc= 0.8004
Epoch 66830: Training cost= 2.3026, Training acc= 0.8007, Validation cost= 2.3026, Validation acc= 0.8002
Epoch 66840: Training cost= 2.3026, Training acc= 0.8006, Validation cost= 2.3026, Validation acc= 0.8001
Epoch 66850: Training cost= 2.3026, Training acc= 0.8005, Validation cost= 2.3026, Validation acc= 0.8000
Epoch 66860: Training cost= 2.3026, Training acc= 0.8004, Validation cost= 2.3026, Validation acc= 0.7999
Epoch 66870: Training cost= 2.3026, Training acc= 0.8003, Validation cost= 2.3026, Validation acc= 0.7998
Epoch 66880: Training cost= 2.3026, Training acc= 0.8002, Validation cost= 2.3026, Validation acc= 0.7997
Epoch 66890: Training cost= 2.3026, Training acc= 0.8001, Validation cost= 2.3026, Validation acc= 0.7996
Epoch 66900: Training cost= 2.3026, Training acc= 0.8000, Validation cost= 2.3026, Validation acc= 0.7995
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 6 2 1 7 9 3 0 8 4]
 [2 3 8 4 1 0 6 7 5 9]
 [9 3 7 5 6 4 2 1 8 0]
 [2 1 5 4 8 9 3 7 0 6]
 [2 8 7 9 0 6 5 1 4 3]
 [6 8 0 4 5 9 2 3 7 1]
 [2 3 7 1 0 9 8 4 6 5]
 [6 1 0 4 2 3 8 5 7 9]
 [3 2 5 0 7 6 8 4 1 9]
 [9 6 7 3 2 5 8 1 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 7 8 0 4 5 3 6 2 1]
 [3 8 9 4 7 2 5 1 0 6]
 [9 2 3 6 1 7 0 4 8 5]
 [8 0 3 1 9 6 2 4 5 7]
 [7 5 1 0 4 8 6 3 9 2]
 [6 3 5 4 1 0 8 2 7 9]
 [3 2 1 5 6 8 0 7 4 9]
 [4 8 5 6 3 2 1 0 7 9]
 [8 1 7 2 9 5 3 4 0 6]
 [7 5 9 1 0 4 6 2 3 8]]
Epoch 66910: Training cost= 2.3026, Training acc= 0.7999, Validation cost= 2.3026, Validation acc= 0.7994
Epoch 66920: Training cost= 2.3026, Training acc= 0.7998, Validation cost= 2.3026, Validation acc= 0.7993
Epoch 66930: Training cost= 2.3026, Training acc= 0.7997, Validation cost= 2.3026, Validation acc= 0.7992
Epoch 66940: Training cost= 2.3026, Training acc= 0.7996, Validation cost= 2.3026, Validation acc= 0.7991
Epoch 66950: Training cost= 2.3026, Training acc= 0.7995, Validation cost= 2.3026, Validation acc= 0.7990
Epoch 66960: Training cost= 2.3026, Training acc= 0.7994, Validation cost= 2.3026, Validation acc= 0.7989
Epoch 66970: Training cost= 2.3026, Training acc= 0.7993, Validation cost= 2.3026, Validation acc= 0.7988
Epoch 66980: Training cost= 2.3026, Training acc= 0.7992, Validation cost= 2.3026, Validation acc= 0.7987
Epoch 66990: Training cost= 2.3026, Training acc= 0.7991, Validation cost= 2.3026, Validation acc= 0.7986
Epoch 67000: Training cost= 2.3026, Training acc= 0.7989, Validation cost= 2.3026, Validation acc= 0.7985
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 8 9 1 5 7 4 6 3 0]
 [4 5 2 3 6 8 9 0 7 1]
 [8 4 3 2 1 0 9 6 5 7]
 [0 5 7 9 2 1 3 8 4 6]
 [6 7 0 9 8 1 2 5 4 3]
 [6 3 7 9 5 8 2 1 4 0]
 [8 1 5 3 4 0 9 6 2 7]
 [1 0 8 7 4 5 3 2 6 9]
 [5 6 7 9 8 1 0 3 4 2]
 [3 4 9 6 8 7 0 5 2 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 2 8 1 9 4 6 7 5 0]
 [9 2 0 5 3 6 8 1 7 4]
 [8 9 0 1 2 5 4 3 6 7]
 [7 4 9 1 3 5 8 0 2 6]
 [5 1 3 4 9 0 6 2 8 7]
 [5 3 4 8 7 2 6 0 1 9]
 [0 6 5 7 1 8 2 9 4 3]
 [0 8 7 3 4 1 2 5 9 6]
 [5 9 4 2 7 0 1 3 8 6]
 [2 0 6 5 3 1 9 7 4 8]]
Epoch 67010: Training cost= 2.3026, Training acc= 0.7988, Validation cost= 2.3026, Validation acc= 0.7984
Epoch 67020: Training cost= 2.3026, Training acc= 0.7987, Validation cost= 2.3026, Validation acc= 0.7983
Epoch 67030: Training cost= 2.3026, Training acc= 0.7986, Validation cost= 2.3026, Validation acc= 0.7982
Epoch 67040: Training cost= 2.3026, Training acc= 0.7985, Validation cost= 2.3026, Validation acc= 0.7981
Epoch 67050: Training cost= 2.3026, Training acc= 0.7984, Validation cost= 2.3026, Validation acc= 0.7980
Epoch 67060: Training cost= 2.3026, Training acc= 0.7983, Validation cost= 2.3026, Validation acc= 0.7978
Epoch 67070: Training cost= 2.3026, Training acc= 0.7982, Validation cost= 2.3026, Validation acc= 0.7977
Epoch 67080: Training cost= 2.3026, Training acc= 0.7981, Validation cost= 2.3026, Validation acc= 0.7976
Epoch 67090: Training cost= 2.3026, Training acc= 0.7980, Validation cost= 2.3026, Validation acc= 0.7975
Epoch 67100: Training cost= 2.3026, Training acc= 0.7979, Validation cost= 2.3026, Validation acc= 0.7974
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 5 2 4 8 6 1 0 7 3]
 [9 3 6 8 1 0 5 4 2 7]
 [9 4 8 6 7 2 3 0 1 5]
 [9 7 1 6 0 3 4 2 8 5]
 [4 9 0 5 1 2 6 3 7 8]
 [6 7 2 8 4 9 1 0 3 5]
 [7 5 4 9 8 3 2 6 0 1]
 [0 7 4 9 6 2 8 5 1 3]
 [5 4 8 1 7 9 3 2 6 0]
 [0 3 6 7 1 2 9 8 4 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 8 6 2 7 0 4 1 9 5]
 [1 8 9 0 2 4 7 6 3 5]
 [8 3 1 6 4 7 2 5 0 9]
 [6 7 5 8 3 0 4 9 2 1]
 [4 6 2 7 0 5 1 3 9 8]
 [5 1 8 4 7 6 0 9 3 2]
 [0 1 3 9 6 8 5 2 4 7]
 [4 1 7 3 2 0 8 5 6 9]
 [4 1 5 3 7 8 2 0 6 9]
 [2 7 4 6 9 3 8 5 0 1]]
Epoch 67110: Training cost= 2.3026, Training acc= 0.7978, Validation cost= 2.3026, Validation acc= 0.7973
Epoch 67120: Training cost= 2.3026, Training acc= 0.7977, Validation cost= 2.3026, Validation acc= 0.7972
Epoch 67130: Training cost= 2.3026, Training acc= 0.7976, Validation cost= 2.3026, Validation acc= 0.7971
Epoch 67140: Training cost= 2.3026, Training acc= 0.7975, Validation cost= 2.3026, Validation acc= 0.7970
Epoch 67150: Training cost= 2.3026, Training acc= 0.7974, Validation cost= 2.3026, Validation acc= 0.7969
Epoch 67160: Training cost= 2.3026, Training acc= 0.7973, Validation cost= 2.3026, Validation acc= 0.7968
Epoch 67170: Training cost= 2.3026, Training acc= 0.7972, Validation cost= 2.3026, Validation acc= 0.7967
Epoch 67180: Training cost= 2.3026, Training acc= 0.7971, Validation cost= 2.3026, Validation acc= 0.7966
Epoch 67190: Training cost= 2.3026, Training acc= 0.7970, Validation cost= 2.3026, Validation acc= 0.7965
Epoch 67200: Training cost= 2.3026, Training acc= 0.7969, Validation cost= 2.3026, Validation acc= 0.7964
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 3 2 5 4 0 9 7 1 8]
 [5 7 2 9 6 8 1 4 0 3]
 [9 8 0 7 4 2 5 3 6 1]
 [8 2 9 5 1 4 7 3 0 6]
 [4 9 8 0 5 7 1 2 6 3]
 [8 5 1 4 2 0 9 6 7 3]
 [4 3 8 0 6 2 1 7 9 5]
 [6 8 2 0 5 9 4 3 1 7]
 [6 7 3 5 0 2 9 8 1 4]
 [9 1 5 2 7 8 4 3 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 1 3 2 4 6 0 7 9 8]
 [8 3 2 7 4 9 0 6 1 5]
 [4 9 5 6 8 0 2 7 1 3]
 [5 0 9 6 7 2 4 8 1 3]
 [2 0 3 8 1 6 4 5 7 9]
 [8 3 0 1 6 2 7 9 5 4]
 [0 5 3 4 1 7 2 9 8 6]
 [0 5 1 8 7 6 2 4 3 9]
 [3 4 8 9 7 6 0 2 5 1]
 [5 1 6 7 8 2 4 3 0 9]]
Epoch 67210: Training cost= 2.3026, Training acc= 0.7968, Validation cost= 2.3026, Validation acc= 0.7963
Epoch 67220: Training cost= 2.3026, Training acc= 0.7967, Validation cost= 2.3026, Validation acc= 0.7962
Epoch 67230: Training cost= 2.3026, Training acc= 0.7966, Validation cost= 2.3026, Validation acc= 0.7961
Epoch 67240: Training cost= 2.3026, Training acc= 0.7965, Validation cost= 2.3026, Validation acc= 0.7960
Epoch 67250: Training cost= 2.3026, Training acc= 0.7963, Validation cost= 2.3026, Validation acc= 0.7959
Epoch 67260: Training cost= 2.3026, Training acc= 0.7962, Validation cost= 2.3026, Validation acc= 0.7958
Epoch 67270: Training cost= 2.3026, Training acc= 0.7961, Validation cost= 2.3026, Validation acc= 0.7957
Epoch 67280: Training cost= 2.3026, Training acc= 0.7960, Validation cost= 2.3026, Validation acc= 0.7956
Epoch 67290: Training cost= 2.3026, Training acc= 0.7959, Validation cost= 2.3026, Validation acc= 0.7955
Epoch 67300: Training cost= 2.3026, Training acc= 0.7958, Validation cost= 2.3026, Validation acc= 0.7954
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 1 5 2 3 0 9 6 8 7]
 [1 3 0 4 2 9 5 6 7 8]
 [3 8 5 7 1 2 4 9 6 0]
 [3 7 1 9 8 6 4 2 5 0]
 [0 8 1 9 7 6 2 3 5 4]
 [7 2 1 3 6 0 5 9 4 8]
 [4 7 5 1 2 9 6 0 3 8]
 [9 5 3 1 8 6 4 7 2 0]
 [4 5 7 2 3 6 1 9 8 0]
 [0 6 5 4 3 8 2 1 9 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 1 4 8 9 3 2 0 7 6]
 [6 2 0 1 5 4 9 8 3 7]
 [3 9 2 8 0 5 6 1 7 4]
 [3 0 5 4 9 7 6 1 2 8]
 [2 6 0 7 4 9 1 8 5 3]
 [9 2 6 7 1 4 0 8 3 5]
 [6 5 7 1 9 0 2 8 4 3]
 [5 1 3 9 4 7 6 8 0 2]
 [3 2 5 0 8 6 9 1 7 4]
 [4 3 8 7 2 1 5 9 6 0]]
Epoch 67310: Training cost= 2.3026, Training acc= 0.7957, Validation cost= 2.3026, Validation acc= 0.7953
Epoch 67320: Training cost= 2.3026, Training acc= 0.7956, Validation cost= 2.3026, Validation acc= 0.7952
Epoch 67330: Training cost= 2.3026, Training acc= 0.7955, Validation cost= 2.3026, Validation acc= 0.7950
Epoch 67340: Training cost= 2.3026, Training acc= 0.7954, Validation cost= 2.3026, Validation acc= 0.7949
Epoch 67350: Training cost= 2.3026, Training acc= 0.7953, Validation cost= 2.3026, Validation acc= 0.7948
Epoch 67360: Training cost= 2.3026, Training acc= 0.7952, Validation cost= 2.3026, Validation acc= 0.7947
Epoch 67370: Training cost= 2.3026, Training acc= 0.7951, Validation cost= 2.3026, Validation acc= 0.7946
Epoch 67380: Training cost= 2.3026, Training acc= 0.7950, Validation cost= 2.3026, Validation acc= 0.7945
Epoch 67390: Training cost= 2.3026, Training acc= 0.7949, Validation cost= 2.3026, Validation acc= 0.7944
Epoch 67400: Training cost= 2.3026, Training acc= 0.7948, Validation cost= 2.3026, Validation acc= 0.7943
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 8 9 1 2 0 7 6 5 3]
 [1 8 4 5 9 7 3 0 6 2]
 [4 6 3 2 1 8 9 5 7 0]
 [1 7 2 8 4 5 0 9 6 3]
 [1 7 4 0 6 8 9 5 3 2]
 [6 4 2 9 0 3 8 7 5 1]
 [3 4 9 2 8 0 1 5 6 7]
 [8 6 9 0 2 4 1 3 5 7]
 [6 1 7 5 3 0 9 8 4 2]
 [4 3 8 2 0 6 7 9 1 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 3 5 8 9 1 4 6 0 2]
 [0 8 6 1 3 2 4 9 7 5]
 [8 6 2 5 0 3 7 4 9 1]
 [9 5 3 2 7 8 0 6 1 4]
 [8 2 3 6 5 7 1 9 4 0]
 [4 1 7 2 9 0 8 3 6 5]
 [8 6 5 4 0 2 7 1 3 9]
 [8 5 3 2 6 0 1 9 4 7]
 [0 7 5 9 6 3 2 1 8 4]
 [1 9 6 5 4 0 7 3 2 8]]
Epoch 67410: Training cost= 2.3026, Training acc= 0.7947, Validation cost= 2.3026, Validation acc= 0.7942
Epoch 67420: Training cost= 2.3026, Training acc= 0.7946, Validation cost= 2.3026, Validation acc= 0.7941
Epoch 67430: Training cost= 2.3026, Training acc= 0.7945, Validation cost= 2.3026, Validation acc= 0.7940
Epoch 67440: Training cost= 2.3026, Training acc= 0.7944, Validation cost= 2.3026, Validation acc= 0.7939
Epoch 67450: Training cost= 2.3026, Training acc= 0.7943, Validation cost= 2.3026, Validation acc= 0.7938
Epoch 67460: Training cost= 2.3026, Training acc= 0.7942, Validation cost= 2.3026, Validation acc= 0.7937
Epoch 67470: Training cost= 2.3026, Training acc= 0.7941, Validation cost= 2.3026, Validation acc= 0.7936
Epoch 67480: Training cost= 2.3026, Training acc= 0.7940, Validation cost= 2.3026, Validation acc= 0.7935
Epoch 67490: Training cost= 2.3026, Training acc= 0.7939, Validation cost= 2.3026, Validation acc= 0.7934
Epoch 67500: Training cost= 2.3026, Training acc= 0.7938, Validation cost= 2.3026, Validation acc= 0.7933
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 3 0 4 6 5 8 2 7]
 [5 0 2 4 8 6 9 1 7 3]
 [2 7 8 1 5 9 6 0 4 3]
 [4 9 7 0 1 3 2 5 6 8]
 [6 5 9 1 2 0 7 8 3 4]
 [5 6 1 8 2 4 9 7 0 3]
 [5 8 7 0 3 2 4 1 9 6]
 [7 0 9 2 8 1 3 4 6 5]
 [7 9 4 0 5 8 3 1 2 6]
 [0 5 2 3 1 8 9 6 7 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 5 4 3 6 9 2 0 7 1]
 [6 4 2 3 7 5 0 8 1 9]
 [1 9 6 8 0 7 3 5 4 2]
 [0 2 5 8 1 9 4 3 7 6]
 [9 5 2 6 3 8 4 7 0 1]
 [1 0 2 7 8 5 6 4 9 3]
 [9 4 1 2 3 7 5 0 8 6]
 [7 0 2 1 4 5 6 9 8 3]
 [8 9 1 6 3 0 5 4 2 7]
 [5 8 0 1 7 2 9 4 6 3]]
Epoch 67510: Training cost= 2.3026, Training acc= 0.7937, Validation cost= 2.3026, Validation acc= 0.7932
Epoch 67520: Training cost= 2.3026, Training acc= 0.7936, Validation cost= 2.3026, Validation acc= 0.7931
Epoch 67530: Training cost= 2.3026, Training acc= 0.7935, Validation cost= 2.3026, Validation acc= 0.7930
Epoch 67540: Training cost= 2.3026, Training acc= 0.7934, Validation cost= 2.3026, Validation acc= 0.7929
Epoch 67550: Training cost= 2.3026, Training acc= 0.7933, Validation cost= 2.3026, Validation acc= 0.7928
Epoch 67560: Training cost= 2.3026, Training acc= 0.7932, Validation cost= 2.3026, Validation acc= 0.7927
Epoch 67570: Training cost= 2.3026, Training acc= 0.7931, Validation cost= 2.3026, Validation acc= 0.7926
Epoch 67580: Training cost= 2.3026, Training acc= 0.7929, Validation cost= 2.3026, Validation acc= 0.7925
Epoch 67590: Training cost= 2.3026, Training acc= 0.7928, Validation cost= 2.3026, Validation acc= 0.7924
Epoch 67600: Training cost= 2.3026, Training acc= 0.7927, Validation cost= 2.3026, Validation acc= 0.7923
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 4 9 3 6 5 1 7 8 2]
 [5 9 1 4 2 6 3 0 7 8]
 [9 2 3 8 0 4 1 6 7 5]
 [2 5 6 1 7 4 0 3 9 8]
 [4 3 8 9 5 7 0 6 2 1]
 [5 6 0 8 9 3 7 4 1 2]
 [7 5 8 2 4 6 1 9 3 0]
 [2 7 5 1 8 3 4 6 0 9]
 [5 4 6 3 7 2 9 8 0 1]
 [4 8 0 6 9 7 1 2 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 0 5 9 6 8 3 2 4 7]
 [9 5 8 7 0 4 3 6 1 2]
 [6 8 9 2 1 5 4 0 7 3]
 [5 0 2 3 8 4 7 1 9 6]
 [8 0 2 4 6 9 5 7 3 1]
 [3 4 6 7 5 8 1 9 0 2]
 [9 8 0 5 6 2 4 3 1 7]
 [0 4 8 7 3 1 5 2 9 6]
 [1 5 6 7 8 4 3 2 9 0]
 [6 0 8 4 5 1 9 2 7 3]]
Epoch 67610: Training cost= 2.3026, Training acc= 0.7926, Validation cost= 2.3026, Validation acc= 0.7922
Epoch 67620: Training cost= 2.3026, Training acc= 0.7925, Validation cost= 2.3026, Validation acc= 0.7921
Epoch 67630: Training cost= 2.3026, Training acc= 0.7924, Validation cost= 2.3026, Validation acc= 0.7920
Epoch 67640: Training cost= 2.3026, Training acc= 0.7923, Validation cost= 2.3026, Validation acc= 0.7919
Epoch 67650: Training cost= 2.3026, Training acc= 0.7922, Validation cost= 2.3026, Validation acc= 0.7918
Epoch 67660: Training cost= 2.3026, Training acc= 0.7921, Validation cost= 2.3026, Validation acc= 0.7917
Epoch 67670: Training cost= 2.3026, Training acc= 0.7920, Validation cost= 2.3026, Validation acc= 0.7916
Epoch 67680: Training cost= 2.3026, Training acc= 0.7919, Validation cost= 2.3026, Validation acc= 0.7915
Epoch 67690: Training cost= 2.3026, Training acc= 0.7918, Validation cost= 2.3026, Validation acc= 0.7914
Epoch 67700: Training cost= 2.3026, Training acc= 0.7917, Validation cost= 2.3026, Validation acc= 0.7913
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 4 8 7 9 3 2 6 5 1]
 [3 1 6 7 0 4 5 8 9 2]
 [3 7 6 5 4 8 2 1 9 0]
 [4 7 5 9 3 1 2 8 6 0]
 [2 5 9 0 6 7 1 3 4 8]
 [3 2 8 5 1 0 4 6 9 7]
 [2 7 1 6 9 0 5 8 3 4]
 [5 9 8 7 6 1 0 4 2 3]
 [3 1 2 9 5 7 4 6 0 8]
 [3 8 5 7 6 9 1 0 2 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 0 6 4 9 2 5 7 1 3]
 [7 3 4 9 1 6 8 2 0 5]
 [6 2 1 9 8 4 5 3 7 0]
 [3 9 2 5 4 7 6 8 0 1]
 [0 1 4 3 9 7 5 2 8 6]
 [4 5 3 1 7 6 0 2 9 8]
 [1 7 0 8 6 4 3 2 9 5]
 [6 7 0 9 8 3 4 5 2 1]
 [1 5 9 3 2 0 4 8 7 6]
 [2 8 5 1 9 3 6 7 4 0]]
Epoch 67710: Training cost= 2.3026, Training acc= 0.7916, Validation cost= 2.3026, Validation acc= 0.7911
Epoch 67720: Training cost= 2.3026, Training acc= 0.7915, Validation cost= 2.3026, Validation acc= 0.7910
Epoch 67730: Training cost= 2.3026, Training acc= 0.7914, Validation cost= 2.3026, Validation acc= 0.7909
Epoch 67740: Training cost= 2.3026, Training acc= 0.7913, Validation cost= 2.3026, Validation acc= 0.7908
Epoch 67750: Training cost= 2.3026, Training acc= 0.7912, Validation cost= 2.3026, Validation acc= 0.7907
Epoch 67760: Training cost= 2.3026, Training acc= 0.7911, Validation cost= 2.3026, Validation acc= 0.7906
Epoch 67770: Training cost= 2.3026, Training acc= 0.7910, Validation cost= 2.3026, Validation acc= 0.7905
Epoch 67780: Training cost= 2.3026, Training acc= 0.7909, Validation cost= 2.3026, Validation acc= 0.7904
Epoch 67790: Training cost= 2.3026, Training acc= 0.7908, Validation cost= 2.3026, Validation acc= 0.7903
Epoch 67800: Training cost= 2.3026, Training acc= 0.7907, Validation cost= 2.3026, Validation acc= 0.7902
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 0 7 2 1 3 4 9 8 5]
 [7 1 0 6 3 5 4 8 2 9]
 [9 5 6 1 7 3 2 0 4 8]
 [3 9 1 7 0 4 6 2 8 5]
 [4 0 5 6 8 7 2 1 9 3]
 [1 3 2 0 8 6 5 9 4 7]
 [2 1 4 3 9 5 8 7 6 0]
 [7 1 9 4 8 0 3 6 5 2]
 [3 8 2 4 6 1 9 5 0 7]
 [5 4 0 7 6 2 9 3 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 6 4 3 7 8 0 5 1 2]
 [6 2 7 4 9 0 5 3 1 8]
 [9 6 4 8 1 2 5 7 0 3]
 [5 1 9 8 2 3 7 4 6 0]
 [7 9 3 6 1 0 8 2 5 4]
 [9 7 6 1 5 8 2 4 0 3]
 [8 5 1 6 9 2 7 4 3 0]
 [0 8 4 2 3 6 7 5 9 1]
 [4 1 8 0 9 5 6 3 7 2]
 [2 7 5 6 0 1 3 9 8 4]]
Epoch 67810: Training cost= 2.3026, Training acc= 0.7906, Validation cost= 2.3026, Validation acc= 0.7901
Epoch 67820: Training cost= 2.3026, Training acc= 0.7905, Validation cost= 2.3026, Validation acc= 0.7900
Epoch 67830: Training cost= 2.3026, Training acc= 0.7904, Validation cost= 2.3026, Validation acc= 0.7899
Epoch 67840: Training cost= 2.3026, Training acc= 0.7903, Validation cost= 2.3026, Validation acc= 0.7898
Epoch 67850: Training cost= 2.3026, Training acc= 0.7902, Validation cost= 2.3026, Validation acc= 0.7897
Epoch 67860: Training cost= 2.3026, Training acc= 0.7901, Validation cost= 2.3026, Validation acc= 0.7896
Epoch 67870: Training cost= 2.3026, Training acc= 0.7900, Validation cost= 2.3026, Validation acc= 0.7895
Epoch 67880: Training cost= 2.3026, Training acc= 0.7899, Validation cost= 2.3026, Validation acc= 0.7894
Epoch 67890: Training cost= 2.3026, Training acc= 0.7898, Validation cost= 2.3026, Validation acc= 0.7893
Epoch 67900: Training cost= 2.3026, Training acc= 0.7897, Validation cost= 2.3026, Validation acc= 0.7892
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 0 5 9 4 1 8 3 2 6]
 [0 6 1 7 8 4 3 2 9 5]
 [0 4 5 2 1 6 3 8 7 9]
 [1 9 4 7 5 8 6 2 0 3]
 [1 6 3 5 7 9 4 2 0 8]
 [0 2 1 9 7 4 6 5 3 8]
 [4 3 0 9 7 2 6 1 5 8]
 [0 3 7 9 1 5 2 4 6 8]
 [9 5 2 0 6 1 8 7 3 4]
 [4 2 6 1 0 7 5 9 3 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 8 2 1 7 0 4 9 5 6]
 [5 1 6 4 7 9 3 2 0 8]
 [3 1 0 6 8 5 7 4 2 9]
 [2 6 0 9 3 7 5 8 4 1]
 [0 1 4 7 6 9 3 5 2 8]
 [4 5 1 7 9 3 6 2 0 8]
 [6 5 9 4 0 1 3 7 2 8]
 [0 9 3 6 7 2 1 8 5 4]
 [6 0 8 3 9 5 7 1 2 4]
 [8 9 4 3 6 1 7 5 0 2]]
Epoch 67910: Training cost= 2.3026, Training acc= 0.7896, Validation cost= 2.3026, Validation acc= 0.7891
Epoch 67920: Training cost= 2.3026, Training acc= 0.7895, Validation cost= 2.3026, Validation acc= 0.7890
Epoch 67930: Training cost= 2.3026, Training acc= 0.7894, Validation cost= 2.3026, Validation acc= 0.7889
Epoch 67940: Training cost= 2.3026, Training acc= 0.7893, Validation cost= 2.3026, Validation acc= 0.7888
Epoch 67950: Training cost= 2.3026, Training acc= 0.7892, Validation cost= 2.3026, Validation acc= 0.7887
Epoch 67960: Training cost= 2.3026, Training acc= 0.7891, Validation cost= 2.3026, Validation acc= 0.7886
Epoch 67970: Training cost= 2.3026, Training acc= 0.7890, Validation cost= 2.3026, Validation acc= 0.7885
Epoch 67980: Training cost= 2.3026, Training acc= 0.7889, Validation cost= 2.3026, Validation acc= 0.7884
Epoch 67990: Training cost= 2.3026, Training acc= 0.7888, Validation cost= 2.3026, Validation acc= 0.7883
Epoch 68000: Training cost= 2.3026, Training acc= 0.7887, Validation cost= 2.3026, Validation acc= 0.7882
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 7 8 2 5 1 9 0 6 4]
 [3 1 9 0 7 4 5 8 2 6]
 [3 7 5 2 8 6 0 1 4 9]
 [0 6 4 5 9 8 1 3 7 2]
 [3 8 1 6 5 2 9 0 7 4]
 [2 1 8 5 4 3 7 9 0 6]
 [3 4 8 6 5 7 2 1 9 0]
 [4 9 6 7 3 0 2 5 8 1]
 [4 1 5 8 0 7 6 3 9 2]
 [5 8 7 6 9 4 1 2 0 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 0 9 3 7 2 6 1 4 8]
 [1 3 9 8 6 2 0 4 7 5]
 [5 8 0 1 7 2 3 9 6 4]
 [4 8 1 2 6 5 9 0 3 7]
 [9 8 3 0 6 4 7 5 1 2]
 [9 0 7 5 8 2 3 6 4 1]
 [8 4 0 3 1 7 2 6 5 9]
 [5 0 7 6 8 3 4 9 2 1]
 [9 1 5 6 4 7 0 2 3 8]
 [5 1 9 2 3 0 8 7 4 6]]
Epoch 68010: Training cost= 2.3026, Training acc= 0.7886, Validation cost= 2.3026, Validation acc= 0.7881
Epoch 68020: Training cost= 2.3026, Training acc= 0.7885, Validation cost= 2.3026, Validation acc= 0.7880
Epoch 68030: Training cost= 2.3026, Training acc= 0.7884, Validation cost= 2.3026, Validation acc= 0.7879
Epoch 68040: Training cost= 2.3026, Training acc= 0.7883, Validation cost= 2.3026, Validation acc= 0.7878
Epoch 68050: Training cost= 2.3026, Training acc= 0.7882, Validation cost= 2.3026, Validation acc= 0.7877
Epoch 68060: Training cost= 2.3026, Training acc= 0.7881, Validation cost= 2.3026, Validation acc= 0.7876
Epoch 68070: Training cost= 2.3026, Training acc= 0.7880, Validation cost= 2.3026, Validation acc= 0.7875
Epoch 68080: Training cost= 2.3026, Training acc= 0.7879, Validation cost= 2.3026, Validation acc= 0.7874
Epoch 68090: Training cost= 2.3026, Training acc= 0.7878, Validation cost= 2.3026, Validation acc= 0.7873
Epoch 68100: Training cost= 2.3026, Training acc= 0.7877, Validation cost= 2.3026, Validation acc= 0.7872
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 7 6 8 2 1 3 0 5]
 [4 3 1 7 5 2 0 6 9 8]
 [7 2 9 8 3 4 1 5 6 0]
 [4 8 9 1 3 0 6 7 2 5]
 [1 3 2 9 4 5 8 6 0 7]
 [2 0 8 9 1 3 4 5 6 7]
 [3 4 1 9 7 6 0 5 2 8]
 [1 7 6 9 3 0 5 2 4 8]
 [0 4 3 9 5 8 1 7 6 2]
 [3 9 0 7 5 1 6 2 8 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 9 6 7 5 1 0 8 4 3]
 [3 7 5 8 4 2 6 1 9 0]
 [5 4 0 2 7 9 6 3 1 8]
 [5 4 3 0 9 7 2 8 1 6]
 [1 5 4 8 2 0 9 6 3 7]
 [8 4 9 5 0 3 7 2 6 1]
 [0 3 8 6 4 2 7 5 1 9]
 [2 1 6 5 4 3 7 8 9 0]
 [2 6 9 3 0 8 5 1 7 4]
 [0 8 9 6 5 3 2 7 1 4]]
Epoch 68110: Training cost= 2.3026, Training acc= 0.7876, Validation cost= 2.3026, Validation acc= 0.7871
Epoch 68120: Training cost= 2.3026, Training acc= 0.7875, Validation cost= 2.3026, Validation acc= 0.7870
Epoch 68130: Training cost= 2.3026, Training acc= 0.7874, Validation cost= 2.3026, Validation acc= 0.7869
Epoch 68140: Training cost= 2.3026, Training acc= 0.7873, Validation cost= 2.3026, Validation acc= 0.7868
Epoch 68150: Training cost= 2.3026, Training acc= 0.7872, Validation cost= 2.3026, Validation acc= 0.7867
Epoch 68160: Training cost= 2.3026, Training acc= 0.7871, Validation cost= 2.3026, Validation acc= 0.7866
Epoch 68170: Training cost= 2.3026, Training acc= 0.7870, Validation cost= 2.3026, Validation acc= 0.7865
Epoch 68180: Training cost= 2.3026, Training acc= 0.7869, Validation cost= 2.3026, Validation acc= 0.7864
Epoch 68190: Training cost= 2.3026, Training acc= 0.7868, Validation cost= 2.3026, Validation acc= 0.7863
Epoch 68200: Training cost= 2.3026, Training acc= 0.7866, Validation cost= 2.3026, Validation acc= 0.7862
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 0 5 9 6 8 2 1 3 4]
 [7 5 9 0 3 8 4 6 2 1]
 [6 1 3 2 4 0 9 7 8 5]
 [7 2 0 4 3 6 8 5 9 1]
 [6 7 3 0 2 8 9 1 5 4]
 [4 7 9 0 1 6 3 5 8 2]
 [3 5 8 6 4 7 2 9 1 0]
 [6 2 1 9 7 3 4 5 8 0]
 [1 5 2 4 8 3 7 9 0 6]
 [6 7 4 0 8 2 3 5 9 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 0 8 4 9 1 6 3 2 7]
 [4 0 1 5 3 7 2 8 6 9]
 [5 4 2 7 0 8 6 3 1 9]
 [5 0 6 7 8 9 3 1 4 2]
 [9 5 7 6 0 4 3 8 1 2]
 [4 8 1 2 5 6 9 3 0 7]
 [6 7 9 3 4 8 1 2 5 0]
 [4 5 2 9 6 0 1 7 3 8]
 [1 3 8 5 6 9 4 0 2 7]
 [1 4 6 0 3 8 2 7 9 5]]
Epoch 68210: Training cost= 2.3026, Training acc= 0.7865, Validation cost= 2.3026, Validation acc= 0.7861
Epoch 68220: Training cost= 2.3026, Training acc= 0.7864, Validation cost= 2.3026, Validation acc= 0.7860
Epoch 68230: Training cost= 2.3026, Training acc= 0.7863, Validation cost= 2.3026, Validation acc= 0.7859
Epoch 68240: Training cost= 2.3026, Training acc= 0.7862, Validation cost= 2.3026, Validation acc= 0.7858
Epoch 68250: Training cost= 2.3026, Training acc= 0.7861, Validation cost= 2.3026, Validation acc= 0.7857
Epoch 68260: Training cost= 2.3026, Training acc= 0.7860, Validation cost= 2.3026, Validation acc= 0.7856
Epoch 68270: Training cost= 2.3026, Training acc= 0.7859, Validation cost= 2.3026, Validation acc= 0.7855
Epoch 68280: Training cost= 2.3026, Training acc= 0.7858, Validation cost= 2.3026, Validation acc= 0.7854
Epoch 68290: Training cost= 2.3026, Training acc= 0.7857, Validation cost= 2.3026, Validation acc= 0.7853
Epoch 68300: Training cost= 2.3026, Training acc= 0.7856, Validation cost= 2.3026, Validation acc= 0.7852
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 1 2 9 8 7 4 3 0 6]
 [8 2 9 5 4 0 3 7 6 1]
 [5 3 1 2 0 9 4 7 6 8]
 [0 2 3 4 9 7 8 6 5 1]
 [6 5 7 3 4 8 1 0 9 2]
 [7 2 6 5 8 9 4 3 1 0]
 [5 8 2 0 1 6 7 9 4 3]
 [3 7 6 2 0 5 4 1 8 9]
 [2 1 5 4 0 3 9 8 7 6]
 [0 3 7 2 4 1 5 9 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 5 3 1 7 9 4 2 0 6]
 [7 6 4 0 8 3 2 1 9 5]
 [3 8 9 7 0 2 1 4 5 6]
 [5 3 7 1 8 9 6 0 4 2]
 [7 4 0 2 5 9 8 6 3 1]
 [5 0 3 2 1 6 7 4 9 8]
 [7 0 2 5 1 9 6 8 3 4]
 [0 3 2 4 7 8 5 6 9 1]
 [5 4 7 0 6 3 2 9 8 1]
 [7 5 9 0 8 2 3 4 6 1]]
Epoch 68310: Training cost= 2.3026, Training acc= 0.7855, Validation cost= 2.3026, Validation acc= 0.7851
Epoch 68320: Training cost= 2.3026, Training acc= 0.7854, Validation cost= 2.3026, Validation acc= 0.7850
Epoch 68330: Training cost= 2.3026, Training acc= 0.7853, Validation cost= 2.3026, Validation acc= 0.7849
Epoch 68340: Training cost= 2.3026, Training acc= 0.7852, Validation cost= 2.3026, Validation acc= 0.7848
Epoch 68350: Training cost= 2.3026, Training acc= 0.7851, Validation cost= 2.3026, Validation acc= 0.7847
Epoch 68360: Training cost= 2.3026, Training acc= 0.7850, Validation cost= 2.3026, Validation acc= 0.7846
Epoch 68370: Training cost= 2.3026, Training acc= 0.7849, Validation cost= 2.3026, Validation acc= 0.7845
Epoch 68380: Training cost= 2.3026, Training acc= 0.7848, Validation cost= 2.3026, Validation acc= 0.7844
Epoch 68390: Training cost= 2.3026, Training acc= 0.7847, Validation cost= 2.3026, Validation acc= 0.7843
Epoch 68400: Training cost= 2.3026, Training acc= 0.7846, Validation cost= 2.3026, Validation acc= 0.7842
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 2 6 1 9 4 0 3 5 7]
 [7 5 4 8 9 0 3 1 6 2]
 [7 6 0 3 9 8 1 2 4 5]
 [8 6 3 1 9 5 0 2 4 7]
 [3 4 1 9 8 5 0 7 6 2]
 [6 0 1 2 3 7 4 9 5 8]
 [4 8 0 2 3 1 9 5 7 6]
 [9 2 4 5 3 8 7 0 6 1]
 [4 3 9 5 7 0 1 6 2 8]
 [6 9 8 4 5 7 2 3 1 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 7 4 9 8 5 0 6 1]
 [1 3 5 6 7 2 8 0 9 4]
 [2 0 9 3 8 7 1 6 4 5]
 [5 8 2 3 4 9 1 0 6 7]
 [1 5 8 2 0 6 7 9 3 4]
 [6 7 3 0 2 4 8 5 9 1]
 [5 8 0 7 2 4 6 3 1 9]
 [6 3 8 0 4 2 9 7 1 5]
 [7 9 2 8 6 5 0 1 4 3]
 [7 2 0 1 6 9 5 4 8 3]]
Epoch 68410: Training cost= 2.3026, Training acc= 0.7845, Validation cost= 2.3026, Validation acc= 0.7841
Epoch 68420: Training cost= 2.3026, Training acc= 0.7844, Validation cost= 2.3026, Validation acc= 0.7840
Epoch 68430: Training cost= 2.3026, Training acc= 0.7843, Validation cost= 2.3026, Validation acc= 0.7839
Epoch 68440: Training cost= 2.3026, Training acc= 0.7842, Validation cost= 2.3026, Validation acc= 0.7838
Epoch 68450: Training cost= 2.3026, Training acc= 0.7841, Validation cost= 2.3026, Validation acc= 0.7837
Epoch 68460: Training cost= 2.3026, Training acc= 0.7840, Validation cost= 2.3026, Validation acc= 0.7836
Epoch 68470: Training cost= 2.3026, Training acc= 0.7839, Validation cost= 2.3026, Validation acc= 0.7835
Epoch 68480: Training cost= 2.3026, Training acc= 0.7838, Validation cost= 2.3026, Validation acc= 0.7834
Epoch 68490: Training cost= 2.3026, Training acc= 0.7837, Validation cost= 2.3026, Validation acc= 0.7833
Epoch 68500: Training cost= 2.3026, Training acc= 0.7836, Validation cost= 2.3026, Validation acc= 0.7832
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 0 3 5 4 2 6 7 8 1]
 [0 8 7 9 6 3 2 4 5 1]
 [1 5 8 9 6 7 0 2 3 4]
 [0 9 6 2 7 8 1 3 5 4]
 [8 1 7 2 0 5 4 6 3 9]
 [7 0 6 5 4 1 8 2 9 3]
 [0 1 2 9 4 3 5 7 6 8]
 [4 6 2 7 5 8 0 3 9 1]
 [8 1 3 5 7 4 9 0 2 6]
 [6 0 4 5 2 3 7 8 9 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 9 6 3 2 7 5 0 4 8]
 [4 1 9 5 2 0 6 7 8 3]
 [8 3 9 7 4 6 1 5 2 0]
 [1 0 7 8 3 6 4 9 5 2]
 [4 2 7 5 1 3 8 6 0 9]
 [1 7 9 4 0 5 8 3 6 2]
 [6 4 9 0 2 3 1 7 5 8]
 [2 6 1 4 0 8 7 3 5 9]
 [6 1 3 4 8 0 7 5 9 2]
 [4 3 0 1 5 6 2 7 8 9]]
Epoch 68510: Training cost= 2.3026, Training acc= 0.7835, Validation cost= 2.3026, Validation acc= 0.7831
Epoch 68520: Training cost= 2.3026, Training acc= 0.7834, Validation cost= 2.3026, Validation acc= 0.7830
Epoch 68530: Training cost= 2.3026, Training acc= 0.7833, Validation cost= 2.3026, Validation acc= 0.7829
Epoch 68540: Training cost= 2.3026, Training acc= 0.7832, Validation cost= 2.3026, Validation acc= 0.7828
Epoch 68550: Training cost= 2.3026, Training acc= 0.7831, Validation cost= 2.3026, Validation acc= 0.7827
Epoch 68560: Training cost= 2.3026, Training acc= 0.7830, Validation cost= 2.3026, Validation acc= 0.7826
Epoch 68570: Training cost= 2.3026, Training acc= 0.7829, Validation cost= 2.3026, Validation acc= 0.7825
Epoch 68580: Training cost= 2.3026, Training acc= 0.7828, Validation cost= 2.3026, Validation acc= 0.7824
Epoch 68590: Training cost= 2.3026, Training acc= 0.7827, Validation cost= 2.3026, Validation acc= 0.7823
Epoch 68600: Training cost= 2.3026, Training acc= 0.7826, Validation cost= 2.3026, Validation acc= 0.7822
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 1 7 8 6 9 0 4 2 3]
 [9 7 4 0 2 5 8 3 6 1]
 [9 5 2 8 6 3 7 1 0 4]
 [7 3 1 9 0 4 5 6 8 2]
 [4 7 9 6 0 1 8 5 2 3]
 [8 7 4 9 5 2 0 1 3 6]
 [0 8 6 2 4 1 9 3 7 5]
 [4 8 2 6 9 7 1 5 3 0]
 [6 0 7 9 4 3 8 2 5 1]
 [6 8 9 1 7 3 4 5 2 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 5 2 7 6 3 9 1 4 8]
 [8 5 2 0 7 3 9 4 1 6]
 [4 6 3 2 9 5 7 8 1 0]
 [8 7 1 3 9 2 6 4 5 0]
 [5 4 3 7 6 2 1 0 8 9]
 [9 1 7 8 0 6 4 3 5 2]
 [7 8 2 1 9 5 3 0 6 4]
 [5 4 2 8 9 1 7 3 0 6]
 [1 9 0 4 7 5 3 6 8 2]
 [5 1 4 3 2 0 6 7 8 9]]
Epoch 68610: Training cost= 2.3026, Training acc= 0.7825, Validation cost= 2.3026, Validation acc= 0.7821
Epoch 68620: Training cost= 2.3026, Training acc= 0.7824, Validation cost= 2.3026, Validation acc= 0.7820
Epoch 68630: Training cost= 2.3026, Training acc= 0.7823, Validation cost= 2.3026, Validation acc= 0.7819
Epoch 68640: Training cost= 2.3026, Training acc= 0.7822, Validation cost= 2.3026, Validation acc= 0.7818
Epoch 68650: Training cost= 2.3026, Training acc= 0.7821, Validation cost= 2.3026, Validation acc= 0.7817
Epoch 68660: Training cost= 2.3026, Training acc= 0.7820, Validation cost= 2.3026, Validation acc= 0.7816
Epoch 68670: Training cost= 2.3026, Training acc= 0.7820, Validation cost= 2.3026, Validation acc= 0.7815
Epoch 68680: Training cost= 2.3026, Training acc= 0.7819, Validation cost= 2.3026, Validation acc= 0.7814
Epoch 68690: Training cost= 2.3026, Training acc= 0.7818, Validation cost= 2.3026, Validation acc= 0.7813
Epoch 68700: Training cost= 2.3026, Training acc= 0.7817, Validation cost= 2.3026, Validation acc= 0.7812
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 3 9 1 7 4 0 2 6 5]
 [4 0 1 3 5 7 6 8 2 9]
 [4 0 7 1 3 9 5 8 2 6]
 [7 8 5 2 9 4 3 6 0 1]
 [5 7 9 8 1 3 6 4 2 0]
 [0 1 2 4 5 6 3 7 8 9]
 [7 1 3 9 2 8 5 0 4 6]
 [9 2 5 6 7 1 4 0 8 3]
 [7 9 8 4 0 5 6 3 2 1]
 [5 6 9 7 2 8 3 0 4 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 5 7 8 4 3 6 9 1 2]
 [5 0 8 1 7 4 3 6 2 9]
 [3 9 8 1 7 6 4 2 0 5]
 [8 4 6 2 0 7 5 1 9 3]
 [1 4 9 2 7 5 0 3 6 8]
 [1 7 9 0 3 6 5 4 8 2]
 [8 2 7 1 9 3 4 5 6 0]
 [7 3 8 0 6 5 4 2 1 9]
 [8 7 3 2 9 4 5 0 1 6]
 [2 3 8 1 6 9 0 4 7 5]]
Epoch 68710: Training cost= 2.3026, Training acc= 0.7816, Validation cost= 2.3026, Validation acc= 0.7811
Epoch 68720: Training cost= 2.3026, Training acc= 0.7815, Validation cost= 2.3026, Validation acc= 0.7810
Epoch 68730: Training cost= 2.3026, Training acc= 0.7814, Validation cost= 2.3026, Validation acc= 0.7809
Epoch 68740: Training cost= 2.3026, Training acc= 0.7813, Validation cost= 2.3026, Validation acc= 0.7808
Epoch 68750: Training cost= 2.3026, Training acc= 0.7812, Validation cost= 2.3026, Validation acc= 0.7807
Epoch 68760: Training cost= 2.3026, Training acc= 0.7811, Validation cost= 2.3026, Validation acc= 0.7806
Epoch 68770: Training cost= 2.3026, Training acc= 0.7810, Validation cost= 2.3026, Validation acc= 0.7805
Epoch 68780: Training cost= 2.3026, Training acc= 0.7809, Validation cost= 2.3026, Validation acc= 0.7804
Epoch 68790: Training cost= 2.3026, Training acc= 0.7808, Validation cost= 2.3026, Validation acc= 0.7803
Epoch 68800: Training cost= 2.3026, Training acc= 0.7807, Validation cost= 2.3026, Validation acc= 0.7802
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 1 7 9 4 5 0 8 3 6]
 [8 2 5 4 6 3 1 0 7 9]
 [7 3 1 8 4 0 9 6 2 5]
 [0 9 6 1 4 5 7 8 3 2]
 [8 9 1 3 7 4 0 2 6 5]
 [6 8 7 3 2 9 5 1 0 4]
 [4 7 9 2 3 1 0 6 5 8]
 [5 4 6 7 2 0 3 8 9 1]
 [4 2 3 8 1 7 0 5 9 6]
 [6 2 5 8 1 0 3 9 7 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 0 8 7 2 4 9 1 3 5]
 [7 4 2 6 5 1 9 8 3 0]
 [8 4 6 5 1 3 7 2 0 9]
 [2 6 0 7 1 5 8 3 4 9]
 [6 9 0 4 2 1 3 8 7 5]
 [1 6 2 8 7 0 5 4 9 3]
 [4 5 9 6 1 3 8 2 7 0]
 [4 0 1 6 5 3 9 7 2 8]
 [4 2 1 9 7 8 6 5 0 3]
 [3 6 2 7 1 8 4 9 5 0]]
Epoch 68810: Training cost= 2.3026, Training acc= 0.7806, Validation cost= 2.3026, Validation acc= 0.7801
Epoch 68820: Training cost= 2.3026, Training acc= 0.7805, Validation cost= 2.3026, Validation acc= 0.7800
Epoch 68830: Training cost= 2.3026, Training acc= 0.7804, Validation cost= 2.3026, Validation acc= 0.7799
Epoch 68840: Training cost= 2.3026, Training acc= 0.7803, Validation cost= 2.3026, Validation acc= 0.7798
Epoch 68850: Training cost= 2.3026, Training acc= 0.7802, Validation cost= 2.3026, Validation acc= 0.7797
Epoch 68860: Training cost= 2.3026, Training acc= 0.7801, Validation cost= 2.3026, Validation acc= 0.7796
Epoch 68870: Training cost= 2.3026, Training acc= 0.7800, Validation cost= 2.3026, Validation acc= 0.7795
Epoch 68880: Training cost= 2.3026, Training acc= 0.7799, Validation cost= 2.3026, Validation acc= 0.7794
Epoch 68890: Training cost= 2.3026, Training acc= 0.7798, Validation cost= 2.3026, Validation acc= 0.7793
Epoch 68900: Training cost= 2.3026, Training acc= 0.7797, Validation cost= 2.3026, Validation acc= 0.7792
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 1 5 6 3 2 8 0 7]
 [4 8 0 3 1 5 7 6 9 2]
 [2 5 9 6 4 8 0 1 7 3]
 [7 1 0 5 9 8 4 6 3 2]
 [9 5 8 6 7 1 3 2 4 0]
 [7 9 1 3 2 5 0 4 6 8]
 [4 9 7 8 3 2 6 5 1 0]
 [1 3 5 0 9 8 4 2 6 7]
 [7 9 6 1 4 3 5 2 0 8]
 [2 9 6 4 0 8 5 1 7 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 5 4 8 6 3 0 7 9 1]
 [1 8 7 4 5 0 2 9 3 6]
 [9 0 3 4 5 8 2 1 7 6]
 [2 3 5 9 0 8 7 1 4 6]
 [5 2 9 8 1 0 4 7 6 3]
 [6 8 2 0 7 3 5 4 1 9]
 [1 3 0 4 2 6 8 9 7 5]
 [3 1 4 6 7 2 8 9 5 0]
 [7 9 5 8 1 6 0 2 3 4]
 [1 0 4 3 8 2 7 9 6 5]]
Epoch 68910: Training cost= 2.3026, Training acc= 0.7796, Validation cost= 2.3026, Validation acc= 0.7791
Epoch 68920: Training cost= 2.3026, Training acc= 0.7795, Validation cost= 2.3026, Validation acc= 0.7790
Epoch 68930: Training cost= 2.3026, Training acc= 0.7794, Validation cost= 2.3026, Validation acc= 0.7789
Epoch 68940: Training cost= 2.3026, Training acc= 0.7793, Validation cost= 2.3026, Validation acc= 0.7788
Epoch 68950: Training cost= 2.3026, Training acc= 0.7792, Validation cost= 2.3026, Validation acc= 0.7787
Epoch 68960: Training cost= 2.3026, Training acc= 0.7791, Validation cost= 2.3026, Validation acc= 0.7786
Epoch 68970: Training cost= 2.3026, Training acc= 0.7790, Validation cost= 2.3026, Validation acc= 0.7785
Epoch 68980: Training cost= 2.3026, Training acc= 0.7789, Validation cost= 2.3026, Validation acc= 0.7784
Epoch 68990: Training cost= 2.3026, Training acc= 0.7788, Validation cost= 2.3026, Validation acc= 0.7783
Epoch 69000: Training cost= 2.3026, Training acc= 0.7787, Validation cost= 2.3026, Validation acc= 0.7782
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 4 3 9 8 2 0 5 1 6]
 [5 9 2 7 6 3 4 0 1 8]
 [1 9 3 4 0 5 8 7 2 6]
 [3 2 8 0 1 9 4 5 6 7]
 [2 5 8 6 9 1 4 7 3 0]
 [6 7 2 1 0 9 4 8 3 5]
 [6 2 0 5 1 4 3 9 8 7]
 [1 5 9 2 0 4 8 6 7 3]
 [2 5 4 8 6 3 1 0 7 9]
 [4 5 2 3 9 1 0 7 6 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 5 3 0 4 8 9 7 2 1]
 [1 5 3 9 0 4 6 7 2 8]
 [0 3 5 6 1 7 4 9 2 8]
 [4 1 6 5 2 7 3 8 0 9]
 [4 5 9 2 8 0 3 6 7 1]
 [3 2 5 4 0 8 7 9 6 1]
 [7 0 5 1 2 9 3 6 4 8]
 [4 7 1 6 9 0 8 5 2 3]
 [7 4 3 0 5 8 9 6 1 2]
 [9 1 8 4 2 7 0 3 5 6]]
Epoch 69010: Training cost= 2.3026, Training acc= 0.7786, Validation cost= 2.3026, Validation acc= 0.7781
Epoch 69020: Training cost= 2.3026, Training acc= 0.7785, Validation cost= 2.3026, Validation acc= 0.7780
Epoch 69030: Training cost= 2.3026, Training acc= 0.7784, Validation cost= 2.3026, Validation acc= 0.7779
Epoch 69040: Training cost= 2.3026, Training acc= 0.7783, Validation cost= 2.3026, Validation acc= 0.7778
Epoch 69050: Training cost= 2.3026, Training acc= 0.7782, Validation cost= 2.3026, Validation acc= 0.7777
Epoch 69060: Training cost= 2.3026, Training acc= 0.7781, Validation cost= 2.3026, Validation acc= 0.7776
Epoch 69070: Training cost= 2.3026, Training acc= 0.7780, Validation cost= 2.3026, Validation acc= 0.7775
Epoch 69080: Training cost= 2.3026, Training acc= 0.7779, Validation cost= 2.3026, Validation acc= 0.7774
Epoch 69090: Training cost= 2.3026, Training acc= 0.7778, Validation cost= 2.3026, Validation acc= 0.7773
Epoch 69100: Training cost= 2.3026, Training acc= 0.7777, Validation cost= 2.3026, Validation acc= 0.7772
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 8 7 9 4 0 1 5 6 3]
 [9 7 8 6 4 1 0 2 5 3]
 [3 9 8 5 6 1 2 0 7 4]
 [1 9 8 4 3 6 5 7 2 0]
 [6 7 0 1 2 4 8 5 3 9]
 [8 5 1 3 2 0 6 4 7 9]
 [5 4 3 1 7 8 2 9 0 6]
 [6 7 0 2 9 4 5 1 3 8]
 [6 9 5 3 0 4 1 2 8 7]
 [4 9 7 0 5 1 6 3 8 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 1 8 2 3 4 9 6 5 0]
 [7 5 0 9 4 6 2 3 8 1]
 [0 4 9 6 5 2 7 3 8 1]
 [9 2 7 5 1 8 6 3 0 4]
 [7 1 0 9 3 2 8 5 6 4]
 [3 8 4 6 2 1 5 0 7 9]
 [0 2 7 6 9 1 5 3 4 8]
 [1 2 3 8 0 5 4 6 9 7]
 [9 4 0 1 8 7 3 5 6 2]
 [1 5 7 9 0 4 2 6 3 8]]
Epoch 69110: Training cost= 2.3026, Training acc= 0.7776, Validation cost= 2.3026, Validation acc= 0.7771
Epoch 69120: Training cost= 2.3026, Training acc= 0.7775, Validation cost= 2.3026, Validation acc= 0.7770
Epoch 69130: Training cost= 2.3026, Training acc= 0.7774, Validation cost= 2.3026, Validation acc= 0.7770
Epoch 69140: Training cost= 2.3026, Training acc= 0.7773, Validation cost= 2.3026, Validation acc= 0.7769
Epoch 69150: Training cost= 2.3026, Training acc= 0.7772, Validation cost= 2.3026, Validation acc= 0.7768
Epoch 69160: Training cost= 2.3026, Training acc= 0.7771, Validation cost= 2.3026, Validation acc= 0.7767
Epoch 69170: Training cost= 2.3026, Training acc= 0.7770, Validation cost= 2.3026, Validation acc= 0.7766
Epoch 69180: Training cost= 2.3026, Training acc= 0.7769, Validation cost= 2.3026, Validation acc= 0.7765
Epoch 69190: Training cost= 2.3026, Training acc= 0.7768, Validation cost= 2.3026, Validation acc= 0.7764
Epoch 69200: Training cost= 2.3026, Training acc= 0.7767, Validation cost= 2.3026, Validation acc= 0.7763
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 0 1 4 8 9 7 6 2 5]
 [4 8 0 1 6 3 5 7 2 9]
 [7 6 3 0 4 9 2 1 5 8]
 [4 0 6 3 7 5 2 9 1 8]
 [2 9 4 6 0 5 7 8 1 3]
 [5 1 7 9 0 2 3 8 4 6]
 [9 2 7 5 1 3 4 8 0 6]
 [4 9 2 5 7 8 1 0 6 3]
 [8 7 2 3 9 1 6 4 0 5]
 [5 0 3 4 2 9 1 6 7 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 8 0 9 6 5 1 4 7]
 [5 2 4 9 1 3 0 8 7 6]
 [6 1 7 3 4 2 8 9 0 5]
 [1 6 8 2 5 7 9 0 3 4]
 [6 1 3 8 5 7 0 4 9 2]
 [2 4 5 8 6 1 3 7 9 0]
 [0 9 1 2 6 7 5 4 3 8]
 [3 8 5 4 7 2 0 1 9 6]
 [6 4 1 5 9 3 7 2 8 0]
 [7 9 4 6 5 1 0 2 8 3]]
Epoch 69210: Training cost= 2.3026, Training acc= 0.7766, Validation cost= 2.3026, Validation acc= 0.7762
Epoch 69220: Training cost= 2.3026, Training acc= 0.7765, Validation cost= 2.3026, Validation acc= 0.7761
Epoch 69230: Training cost= 2.3026, Training acc= 0.7764, Validation cost= 2.3026, Validation acc= 0.7760
Epoch 69240: Training cost= 2.3026, Training acc= 0.7763, Validation cost= 2.3026, Validation acc= 0.7759
Epoch 69250: Training cost= 2.3026, Training acc= 0.7762, Validation cost= 2.3026, Validation acc= 0.7758
Epoch 69260: Training cost= 2.3026, Training acc= 0.7761, Validation cost= 2.3026, Validation acc= 0.7757
Epoch 69270: Training cost= 2.3026, Training acc= 0.7760, Validation cost= 2.3026, Validation acc= 0.7756
Epoch 69280: Training cost= 2.3026, Training acc= 0.7759, Validation cost= 2.3026, Validation acc= 0.7755
Epoch 69290: Training cost= 2.3026, Training acc= 0.7758, Validation cost= 2.3026, Validation acc= 0.7754
Epoch 69300: Training cost= 2.3026, Training acc= 0.7758, Validation cost= 2.3026, Validation acc= 0.7753
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 0 3 2 9 5 4 7 6 1]
 [4 8 6 0 5 7 2 9 3 1]
 [7 1 5 2 9 4 3 0 8 6]
 [4 8 6 1 9 5 3 7 2 0]
 [2 3 7 8 4 1 5 0 9 6]
 [0 8 6 9 5 4 7 2 1 3]
 [4 0 8 3 1 7 5 6 2 9]
 [8 2 9 3 4 1 7 6 5 0]
 [3 2 0 8 1 5 4 7 9 6]
 [5 7 8 1 9 2 4 6 3 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 1 6 4 0 5 3 8 7 2]
 [2 1 6 4 7 5 9 8 0 3]
 [6 7 1 3 8 4 9 2 5 0]
 [5 8 9 0 1 3 7 6 4 2]
 [7 2 4 9 3 5 0 8 6 1]
 [2 0 6 7 3 9 1 4 5 8]
 [0 4 5 8 9 3 6 2 1 7]
 [7 0 8 3 5 9 6 4 1 2]
 [6 9 2 7 0 8 3 4 5 1]
 [6 9 0 5 3 7 8 2 4 1]]
Epoch 69310: Training cost= 2.3026, Training acc= 0.7757, Validation cost= 2.3026, Validation acc= 0.7752
Epoch 69320: Training cost= 2.3026, Training acc= 0.7756, Validation cost= 2.3026, Validation acc= 0.7751
Epoch 69330: Training cost= 2.3026, Training acc= 0.7755, Validation cost= 2.3026, Validation acc= 0.7750
Epoch 69340: Training cost= 2.3026, Training acc= 0.7754, Validation cost= 2.3026, Validation acc= 0.7749
Epoch 69350: Training cost= 2.3026, Training acc= 0.7753, Validation cost= 2.3026, Validation acc= 0.7748
Epoch 69360: Training cost= 2.3026, Training acc= 0.7752, Validation cost= 2.3026, Validation acc= 0.7747
Epoch 69370: Training cost= 2.3026, Training acc= 0.7751, Validation cost= 2.3026, Validation acc= 0.7746
Epoch 69380: Training cost= 2.3026, Training acc= 0.7750, Validation cost= 2.3026, Validation acc= 0.7745
Epoch 69390: Training cost= 2.3026, Training acc= 0.7749, Validation cost= 2.3026, Validation acc= 0.7744
Epoch 69400: Training cost= 2.3026, Training acc= 0.7748, Validation cost= 2.3026, Validation acc= 0.7743
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 5 4 2 1 3 7 8 6 9]
 [5 9 7 4 3 1 0 8 6 2]
 [8 1 6 9 5 4 0 3 2 7]
 [9 3 6 8 7 5 1 4 0 2]
 [5 2 1 4 3 0 9 7 6 8]
 [5 8 6 0 7 1 9 3 4 2]
 [5 4 1 7 8 9 6 2 3 0]
 [0 8 6 3 7 4 9 5 2 1]
 [7 2 4 5 0 6 9 8 1 3]
 [9 0 1 5 7 8 4 2 6 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 3 2 1 0 7 5 9 8 4]
 [2 5 6 8 1 9 0 3 7 4]
 [9 6 2 5 8 1 3 0 7 4]
 [7 3 6 9 5 2 8 0 4 1]
 [9 4 2 6 5 1 3 7 0 8]
 [9 6 0 5 2 7 8 4 1 3]
 [5 0 6 3 7 9 1 8 2 4]
 [9 1 0 5 8 4 2 7 3 6]
 [9 1 2 0 3 6 7 4 5 8]
 [1 0 7 3 4 5 9 6 8 2]]
Epoch 69410: Training cost= 2.3026, Training acc= 0.7747, Validation cost= 2.3026, Validation acc= 0.7742
Epoch 69420: Training cost= 2.3026, Training acc= 0.7746, Validation cost= 2.3026, Validation acc= 0.7741
Epoch 69430: Training cost= 2.3026, Training acc= 0.7745, Validation cost= 2.3026, Validation acc= 0.7740
Epoch 69440: Training cost= 2.3026, Training acc= 0.7744, Validation cost= 2.3026, Validation acc= 0.7739
Epoch 69450: Training cost= 2.3026, Training acc= 0.7743, Validation cost= 2.3026, Validation acc= 0.7738
Epoch 69460: Training cost= 2.3026, Training acc= 0.7742, Validation cost= 2.3026, Validation acc= 0.7737
Epoch 69470: Training cost= 2.3026, Training acc= 0.7741, Validation cost= 2.3026, Validation acc= 0.7736
Epoch 69480: Training cost= 2.3026, Training acc= 0.7740, Validation cost= 2.3026, Validation acc= 0.7735
Epoch 69490: Training cost= 2.3026, Training acc= 0.7739, Validation cost= 2.3026, Validation acc= 0.7734
Epoch 69500: Training cost= 2.3026, Training acc= 0.7738, Validation cost= 2.3026, Validation acc= 0.7733
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 3 4 1 2 5 0 8 6 7]
 [2 9 8 1 0 7 5 6 3 4]
 [5 3 8 9 4 2 7 0 1 6]
 [1 7 0 6 3 8 2 5 4 9]
 [5 4 7 9 8 6 3 0 2 1]
 [6 5 3 1 8 4 0 9 2 7]
 [5 3 8 2 7 1 9 6 4 0]
 [0 2 3 9 6 4 7 1 8 5]
 [7 3 4 6 9 5 1 8 0 2]
 [6 7 4 3 9 1 2 5 8 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 1 8 0 3 5 4 2 6 7]
 [7 4 2 9 5 1 8 0 3 6]
 [5 4 1 3 6 7 9 8 0 2]
 [7 0 9 8 1 4 6 2 3 5]
 [0 7 5 6 8 2 9 3 4 1]
 [9 1 6 5 2 8 7 0 4 3]
 [1 0 9 8 6 5 4 2 7 3]
 [7 3 2 9 0 6 8 5 1 4]
 [5 7 6 8 3 2 1 9 4 0]
 [6 5 7 4 1 0 3 9 8 2]]
Epoch 69510: Training cost= 2.3026, Training acc= 0.7737, Validation cost= 2.3026, Validation acc= 0.7733
Epoch 69520: Training cost= 2.3026, Training acc= 0.7736, Validation cost= 2.3026, Validation acc= 0.7732
Epoch 69530: Training cost= 2.3026, Training acc= 0.7735, Validation cost= 2.3026, Validation acc= 0.7731
Epoch 69540: Training cost= 2.3026, Training acc= 0.7734, Validation cost= 2.3026, Validation acc= 0.7730
Epoch 69550: Training cost= 2.3026, Training acc= 0.7733, Validation cost= 2.3026, Validation acc= 0.7729
Epoch 69560: Training cost= 2.3026, Training acc= 0.7732, Validation cost= 2.3026, Validation acc= 0.7728
Epoch 69570: Training cost= 2.3026, Training acc= 0.7731, Validation cost= 2.3026, Validation acc= 0.7727
Epoch 69580: Training cost= 2.3026, Training acc= 0.7730, Validation cost= 2.3026, Validation acc= 0.7726
Epoch 69590: Training cost= 2.3026, Training acc= 0.7729, Validation cost= 2.3026, Validation acc= 0.7725
Epoch 69600: Training cost= 2.3026, Training acc= 0.7728, Validation cost= 2.3026, Validation acc= 0.7724
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 3 5 6 4 9 0 1 7 2]
 [5 7 1 8 2 3 6 0 4 9]
 [4 9 5 7 3 2 8 0 6 1]
 [3 6 5 0 7 8 4 2 9 1]
 [6 2 9 5 4 7 3 8 0 1]
 [0 3 1 7 8 5 4 6 2 9]
 [0 1 3 4 9 7 5 6 8 2]
 [5 1 9 0 3 2 7 6 8 4]
 [9 1 6 0 2 5 3 8 4 7]
 [8 5 4 9 6 3 2 7 0 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 7 1 0 5 4 9 6 8]
 [7 3 9 2 6 0 5 1 8 4]
 [9 5 3 4 7 1 0 8 6 2]
 [3 2 7 4 5 6 9 0 1 8]
 [6 7 1 5 2 0 4 3 8 9]
 [6 5 2 0 9 1 7 3 8 4]
 [3 2 4 6 1 9 8 0 7 5]
 [8 6 1 5 9 7 2 0 3 4]
 [6 1 9 7 4 5 2 3 0 8]
 [9 2 8 4 3 1 6 5 0 7]]
Epoch 69610: Training cost= 2.3026, Training acc= 0.7727, Validation cost= 2.3026, Validation acc= 0.7723
Epoch 69620: Training cost= 2.3026, Training acc= 0.7726, Validation cost= 2.3026, Validation acc= 0.7722
Epoch 69630: Training cost= 2.3026, Training acc= 0.7725, Validation cost= 2.3026, Validation acc= 0.7721
Epoch 69640: Training cost= 2.3026, Training acc= 0.7725, Validation cost= 2.3026, Validation acc= 0.7720
Epoch 69650: Training cost= 2.3026, Training acc= 0.7724, Validation cost= 2.3026, Validation acc= 0.7719
Epoch 69660: Training cost= 2.3026, Training acc= 0.7723, Validation cost= 2.3026, Validation acc= 0.7718
Epoch 69670: Training cost= 2.3026, Training acc= 0.7722, Validation cost= 2.3026, Validation acc= 0.7717
Epoch 69680: Training cost= 2.3026, Training acc= 0.7721, Validation cost= 2.3026, Validation acc= 0.7716
Epoch 69690: Training cost= 2.3026, Training acc= 0.7720, Validation cost= 2.3026, Validation acc= 0.7715
Epoch 69700: Training cost= 2.3026, Training acc= 0.7719, Validation cost= 2.3026, Validation acc= 0.7714
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 7 2 4 5 1 6 8 3 9]
 [8 5 7 0 1 6 9 2 4 3]
 [8 0 1 7 3 4 9 2 5 6]
 [4 6 3 5 1 0 7 9 2 8]
 [5 9 6 7 8 2 3 1 4 0]
 [4 7 0 1 5 8 9 2 6 3]
 [6 5 3 7 8 4 9 1 0 2]
 [0 9 6 5 4 3 1 7 2 8]
 [5 6 1 9 2 0 4 3 7 8]
 [9 7 6 4 1 8 0 5 2 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 9 4 0 3 2 7 5 6 1]
 [2 4 3 9 8 1 0 7 6 5]
 [3 5 4 1 0 7 9 2 8 6]
 [6 0 5 9 1 7 2 4 8 3]
 [9 0 1 7 8 2 4 3 6 5]
 [0 9 6 2 4 7 5 1 8 3]
 [1 6 3 4 8 7 0 2 5 9]
 [4 1 0 7 6 3 5 2 8 9]
 [1 6 8 7 2 0 5 9 4 3]
 [5 2 8 3 9 0 7 6 1 4]]
Epoch 69710: Training cost= 2.3026, Training acc= 0.7718, Validation cost= 2.3026, Validation acc= 0.7713
Epoch 69720: Training cost= 2.3026, Training acc= 0.7717, Validation cost= 2.3026, Validation acc= 0.7712
Epoch 69730: Training cost= 2.3026, Training acc= 0.7716, Validation cost= 2.3026, Validation acc= 0.7711
Epoch 69740: Training cost= 2.3026, Training acc= 0.7715, Validation cost= 2.3026, Validation acc= 0.7710
Epoch 69750: Training cost= 2.3026, Training acc= 0.7714, Validation cost= 2.3026, Validation acc= 0.7709
Epoch 69760: Training cost= 2.3026, Training acc= 0.7713, Validation cost= 2.3026, Validation acc= 0.7708
Epoch 69770: Training cost= 2.3026, Training acc= 0.7712, Validation cost= 2.3026, Validation acc= 0.7707
Epoch 69780: Training cost= 2.3026, Training acc= 0.7711, Validation cost= 2.3026, Validation acc= 0.7706
Epoch 69790: Training cost= 2.3026, Training acc= 0.7710, Validation cost= 2.3026, Validation acc= 0.7705
Epoch 69800: Training cost= 2.3026, Training acc= 0.7709, Validation cost= 2.3026, Validation acc= 0.7705
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 6 8 7 0 2 9 3 5 4]
 [5 9 7 3 8 0 2 6 4 1]
 [3 6 5 7 4 8 2 9 0 1]
 [8 2 6 9 0 5 4 3 7 1]
 [1 0 8 5 9 4 7 6 2 3]
 [3 9 8 4 1 6 0 7 2 5]
 [4 5 3 9 8 0 1 7 2 6]
 [5 6 1 3 9 7 8 0 2 4]
 [3 0 6 7 5 4 2 8 9 1]
 [8 0 6 7 2 5 9 3 1 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 2 3 4 0 7 8 1 5 9]
 [2 6 5 4 7 8 3 9 0 1]
 [4 1 7 0 2 5 8 6 3 9]
 [0 2 9 7 6 5 8 3 1 4]
 [7 3 9 8 6 1 5 0 2 4]
 [0 5 2 8 4 7 3 1 6 9]
 [6 1 9 5 3 0 2 4 7 8]
 [4 3 8 6 2 7 5 9 1 0]
 [8 5 3 9 7 1 6 4 2 0]
 [7 1 0 2 3 8 4 6 9 5]]
Epoch 69810: Training cost= 2.3026, Training acc= 0.7708, Validation cost= 2.3026, Validation acc= 0.7704
Epoch 69820: Training cost= 2.3026, Training acc= 0.7707, Validation cost= 2.3026, Validation acc= 0.7703
Epoch 69830: Training cost= 2.3026, Training acc= 0.7706, Validation cost= 2.3026, Validation acc= 0.7702
Epoch 69840: Training cost= 2.3026, Training acc= 0.7705, Validation cost= 2.3026, Validation acc= 0.7701
Epoch 69850: Training cost= 2.3026, Training acc= 0.7704, Validation cost= 2.3026, Validation acc= 0.7700
Epoch 69860: Training cost= 2.3026, Training acc= 0.7703, Validation cost= 2.3026, Validation acc= 0.7699
Epoch 69870: Training cost= 2.3026, Training acc= 0.7702, Validation cost= 2.3026, Validation acc= 0.7698
Epoch 69880: Training cost= 2.3026, Training acc= 0.7701, Validation cost= 2.3026, Validation acc= 0.7697
Epoch 69890: Training cost= 2.3026, Training acc= 0.7700, Validation cost= 2.3026, Validation acc= 0.7696
Epoch 69900: Training cost= 2.3026, Training acc= 0.7700, Validation cost= 2.3026, Validation acc= 0.7695
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 8 4 9 7 0 2 6 1 3]
 [8 5 4 1 9 2 6 3 0 7]
 [3 7 2 1 8 0 5 4 9 6]
 [0 6 8 9 7 2 3 1 4 5]
 [7 1 3 0 4 2 6 5 9 8]
 [6 8 9 7 2 4 3 0 5 1]
 [6 1 2 5 0 8 7 9 4 3]
 [3 1 0 8 9 7 4 5 6 2]
 [4 1 3 7 8 5 9 6 2 0]
 [8 4 2 5 1 9 7 3 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 0 3 7 2 6 5 4 9 8]
 [9 3 5 4 6 7 1 0 8 2]
 [0 6 3 4 9 7 5 1 2 8]
 [1 7 4 2 3 0 5 8 6 9]
 [4 7 0 9 2 1 3 8 5 6]
 [5 7 8 0 4 6 9 2 1 3]
 [3 8 9 2 1 6 0 5 7 4]
 [6 3 1 5 8 9 0 4 2 7]
 [5 1 9 8 7 3 0 4 2 6]
 [9 8 2 6 4 5 7 3 0 1]]
Epoch 69910: Training cost= 2.3026, Training acc= 0.7699, Validation cost= 2.3026, Validation acc= 0.7694
Epoch 69920: Training cost= 2.3026, Training acc= 0.7698, Validation cost= 2.3026, Validation acc= 0.7693
Epoch 69930: Training cost= 2.3026, Training acc= 0.7697, Validation cost= 2.3026, Validation acc= 0.7692
Epoch 69940: Training cost= 2.3026, Training acc= 0.7696, Validation cost= 2.3026, Validation acc= 0.7691
Epoch 69950: Training cost= 2.3026, Training acc= 0.7695, Validation cost= 2.3026, Validation acc= 0.7690
Epoch 69960: Training cost= 2.3026, Training acc= 0.7694, Validation cost= 2.3026, Validation acc= 0.7689
Epoch 69970: Training cost= 2.3026, Training acc= 0.7693, Validation cost= 2.3026, Validation acc= 0.7688
Epoch 69980: Training cost= 2.3026, Training acc= 0.7692, Validation cost= 2.3026, Validation acc= 0.7687
Epoch 69990: Training cost= 2.3026, Training acc= 0.7691, Validation cost= 2.3026, Validation acc= 0.7686
Epoch 70000: Training cost= 2.3026, Training acc= 0.7690, Validation cost= 2.3026, Validation acc= 0.7685
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 3 8 9 1 2 6 0 4 5]
 [5 4 8 3 1 9 6 7 2 0]
 [5 0 9 8 6 3 1 2 4 7]
 [4 8 2 1 3 7 5 9 0 6]
 [2 6 5 8 7 3 4 9 0 1]
 [1 5 7 3 0 9 2 6 4 8]
 [6 9 5 7 2 1 8 3 4 0]
 [8 0 1 2 5 4 3 6 9 7]
 [0 6 9 8 4 1 7 5 3 2]
 [6 0 3 2 8 9 4 1 7 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 1 5 9 8 7 0 2 6]
 [1 9 3 2 7 0 8 4 6 5]
 [6 8 9 5 2 4 1 0 7 3]
 [3 4 7 2 5 1 9 0 6 8]
 [2 1 6 3 4 9 0 7 8 5]
 [0 9 8 1 7 3 2 6 5 4]
 [9 0 7 6 3 1 5 2 8 4]
 [6 1 5 0 9 3 4 7 8 2]
 [1 0 7 2 5 6 3 9 4 8]
 [2 6 8 9 3 1 5 0 4 7]]
Epoch 70010: Training cost= 2.3026, Training acc= 0.7689, Validation cost= 2.3026, Validation acc= 0.7684
Epoch 70020: Training cost= 2.3026, Training acc= 0.7688, Validation cost= 2.3026, Validation acc= 0.7683
Epoch 70030: Training cost= 2.3026, Training acc= 0.7687, Validation cost= 2.3026, Validation acc= 0.7683
Epoch 70040: Training cost= 2.3026, Training acc= 0.7686, Validation cost= 2.3026, Validation acc= 0.7682
Epoch 70050: Training cost= 2.3026, Training acc= 0.7685, Validation cost= 2.3026, Validation acc= 0.7681
Epoch 70060: Training cost= 2.3026, Training acc= 0.7684, Validation cost= 2.3026, Validation acc= 0.7680
Epoch 70070: Training cost= 2.3026, Training acc= 0.7683, Validation cost= 2.3026, Validation acc= 0.7679
Epoch 70080: Training cost= 2.3026, Training acc= 0.7682, Validation cost= 2.3026, Validation acc= 0.7678
Epoch 70090: Training cost= 2.3026, Training acc= 0.7681, Validation cost= 2.3026, Validation acc= 0.7677
Epoch 70100: Training cost= 2.3026, Training acc= 0.7680, Validation cost= 2.3026, Validation acc= 0.7676
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 3 5 8 2 6 4 0 9 1]
 [4 1 7 0 2 6 5 8 3 9]
 [4 5 9 0 7 8 2 6 1 3]
 [1 2 5 6 9 0 7 8 3 4]
 [2 5 3 7 9 1 8 0 6 4]
 [1 9 8 7 2 4 5 3 6 0]
 [2 0 4 8 6 7 3 5 1 9]
 [1 7 0 5 9 4 3 8 6 2]
 [6 1 9 8 5 3 0 2 4 7]
 [2 3 4 5 1 8 6 0 7 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 1 5 6 8 2 0 3 7 4]
 [4 6 2 5 9 3 0 8 1 7]
 [2 1 7 3 9 8 6 5 0 4]
 [4 8 9 5 3 2 1 6 0 7]
 [1 0 6 8 2 9 4 5 3 7]
 [0 2 7 5 6 1 4 9 8 3]
 [8 0 1 5 7 2 6 3 9 4]
 [3 8 9 4 7 6 0 5 2 1]
 [4 9 8 6 2 0 3 1 7 5]
 [3 9 1 5 6 4 0 2 7 8]]
Epoch 70110: Training cost= 2.3026, Training acc= 0.7679, Validation cost= 2.3026, Validation acc= 0.7675
Epoch 70120: Training cost= 2.3026, Training acc= 0.7678, Validation cost= 2.3026, Validation acc= 0.7674
Epoch 70130: Training cost= 2.3026, Training acc= 0.7678, Validation cost= 2.3026, Validation acc= 0.7673
Epoch 70140: Training cost= 2.3026, Training acc= 0.7677, Validation cost= 2.3026, Validation acc= 0.7672
Epoch 70150: Training cost= 2.3026, Training acc= 0.7676, Validation cost= 2.3026, Validation acc= 0.7671
Epoch 70160: Training cost= 2.3026, Training acc= 0.7675, Validation cost= 2.3026, Validation acc= 0.7670
Epoch 70170: Training cost= 2.3026, Training acc= 0.7674, Validation cost= 2.3026, Validation acc= 0.7669
Epoch 70180: Training cost= 2.3026, Training acc= 0.7673, Validation cost= 2.3026, Validation acc= 0.7668
Epoch 70190: Training cost= 2.3026, Training acc= 0.7672, Validation cost= 2.3026, Validation acc= 0.7667
Epoch 70200: Training cost= 2.3026, Training acc= 0.7671, Validation cost= 2.3026, Validation acc= 0.7666
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 0 6 4 9 8 7 3 2 5]
 [5 3 8 4 0 9 2 7 1 6]
 [3 6 7 9 4 2 1 0 5 8]
 [3 1 7 4 0 6 5 9 8 2]
 [4 8 7 5 2 3 1 0 9 6]
 [5 8 6 2 1 3 4 9 0 7]
 [2 8 5 4 9 0 6 1 3 7]
 [9 8 7 4 0 3 5 2 6 1]
 [4 7 5 1 3 0 2 8 6 9]
 [8 7 6 3 9 5 2 1 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 6 4 0 5 8 2 1 9 3]
 [3 4 1 5 9 7 0 8 6 2]
 [7 2 6 0 4 3 5 1 9 8]
 [2 7 9 0 4 6 3 5 8 1]
 [9 6 0 8 4 5 7 1 2 3]
 [9 0 2 7 1 4 5 3 8 6]
 [2 3 5 9 7 0 1 4 8 6]
 [7 8 6 4 1 0 2 9 5 3]
 [5 0 7 6 3 8 9 1 4 2]
 [1 8 4 9 2 7 6 0 3 5]]
Epoch 70210: Training cost= 2.3026, Training acc= 0.7670, Validation cost= 2.3026, Validation acc= 0.7665
Epoch 70220: Training cost= 2.3026, Training acc= 0.7669, Validation cost= 2.3026, Validation acc= 0.7664
Epoch 70230: Training cost= 2.3026, Training acc= 0.7668, Validation cost= 2.3026, Validation acc= 0.7663
Epoch 70240: Training cost= 2.3026, Training acc= 0.7667, Validation cost= 2.3026, Validation acc= 0.7663
Epoch 70250: Training cost= 2.3026, Training acc= 0.7666, Validation cost= 2.3026, Validation acc= 0.7662
Epoch 70260: Training cost= 2.3026, Training acc= 0.7665, Validation cost= 2.3026, Validation acc= 0.7661
Epoch 70270: Training cost= 2.3026, Training acc= 0.7664, Validation cost= 2.3026, Validation acc= 0.7660
Epoch 70280: Training cost= 2.3026, Training acc= 0.7663, Validation cost= 2.3026, Validation acc= 0.7659
Epoch 70290: Training cost= 2.3026, Training acc= 0.7662, Validation cost= 2.3026, Validation acc= 0.7658
Epoch 70300: Training cost= 2.3026, Training acc= 0.7661, Validation cost= 2.3026, Validation acc= 0.7657
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 5 1 7 2 3 6 0 4 8]
 [7 8 6 0 1 9 3 5 2 4]
 [3 2 8 5 4 0 7 9 1 6]
 [3 5 9 8 4 2 1 0 7 6]
 [5 9 3 0 8 1 4 6 7 2]
 [3 7 6 4 5 2 1 8 9 0]
 [2 3 9 8 4 1 7 6 5 0]
 [6 5 7 4 3 9 1 8 0 2]
 [2 3 5 8 0 4 6 9 1 7]
 [5 8 2 9 7 3 0 1 4 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 5 0 6 2 7 4 9 8 3]
 [6 2 4 3 8 1 7 9 5 0]
 [9 8 5 6 2 3 7 4 0 1]
 [7 3 1 8 2 6 5 4 9 0]
 [5 0 3 7 8 9 1 6 2 4]
 [3 0 4 9 8 6 5 1 2 7]
 [5 7 8 3 4 2 6 9 0 1]
 [9 3 7 0 4 2 6 8 5 1]
 [8 2 0 3 5 6 1 4 7 9]
 [8 9 7 3 4 1 5 0 6 2]]
Epoch 70310: Training cost= 2.3026, Training acc= 0.7660, Validation cost= 2.3026, Validation acc= 0.7656
Epoch 70320: Training cost= 2.3026, Training acc= 0.7659, Validation cost= 2.3026, Validation acc= 0.7655
Epoch 70330: Training cost= 2.3026, Training acc= 0.7659, Validation cost= 2.3026, Validation acc= 0.7654
Epoch 70340: Training cost= 2.3026, Training acc= 0.7658, Validation cost= 2.3026, Validation acc= 0.7653
Epoch 70350: Training cost= 2.3026, Training acc= 0.7657, Validation cost= 2.3026, Validation acc= 0.7652
Epoch 70360: Training cost= 2.3026, Training acc= 0.7656, Validation cost= 2.3026, Validation acc= 0.7651
Epoch 70370: Training cost= 2.3026, Training acc= 0.7655, Validation cost= 2.3026, Validation acc= 0.7650
Epoch 70380: Training cost= 2.3026, Training acc= 0.7654, Validation cost= 2.3026, Validation acc= 0.7649
Epoch 70390: Training cost= 2.3026, Training acc= 0.7653, Validation cost= 2.3026, Validation acc= 0.7648
Epoch 70400: Training cost= 2.3026, Training acc= 0.7652, Validation cost= 2.3026, Validation acc= 0.7647
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 4 0 1 2 9 3 5 8 7]
 [8 9 2 0 4 3 1 5 6 7]
 [8 4 5 2 9 6 7 3 0 1]
 [3 6 0 2 4 5 8 7 9 1]
 [2 4 3 1 8 0 7 5 6 9]
 [0 9 6 8 1 3 5 2 4 7]
 [6 8 1 7 3 9 2 0 5 4]
 [1 5 6 2 7 9 8 3 4 0]
 [1 9 5 7 6 3 4 2 0 8]
 [5 0 3 1 2 8 4 7 6 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 4 0 8 7 2 6 5 9 3]
 [2 3 4 6 9 5 8 0 1 7]
 [1 7 4 3 9 0 6 2 5 8]
 [1 0 8 2 3 7 5 9 4 6]
 [0 3 5 1 8 9 2 4 6 7]
 [3 9 6 0 7 8 5 4 2 1]
 [0 7 4 1 5 9 2 6 8 3]
 [7 6 0 9 1 3 4 2 5 8]
 [8 5 6 3 9 2 4 7 0 1]
 [5 1 6 0 2 4 9 7 8 3]]
Epoch 70410: Training cost= 2.3026, Training acc= 0.7651, Validation cost= 2.3026, Validation acc= 0.7646
Epoch 70420: Training cost= 2.3026, Training acc= 0.7650, Validation cost= 2.3026, Validation acc= 0.7646
Epoch 70430: Training cost= 2.3026, Training acc= 0.7649, Validation cost= 2.3026, Validation acc= 0.7645
Epoch 70440: Training cost= 2.3026, Training acc= 0.7648, Validation cost= 2.3026, Validation acc= 0.7644
Epoch 70450: Training cost= 2.3026, Training acc= 0.7647, Validation cost= 2.3026, Validation acc= 0.7643
Epoch 70460: Training cost= 2.3026, Training acc= 0.7646, Validation cost= 2.3026, Validation acc= 0.7642
Epoch 70470: Training cost= 2.3026, Training acc= 0.7645, Validation cost= 2.3026, Validation acc= 0.7641
Epoch 70480: Training cost= 2.3026, Training acc= 0.7644, Validation cost= 2.3026, Validation acc= 0.7640
Epoch 70490: Training cost= 2.3026, Training acc= 0.7643, Validation cost= 2.3026, Validation acc= 0.7639
Epoch 70500: Training cost= 2.3026, Training acc= 0.7642, Validation cost= 2.3026, Validation acc= 0.7638
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 5 9 2 1 8 7 6 3 0]
 [0 4 2 9 5 3 7 6 8 1]
 [8 2 7 1 5 0 4 3 6 9]
 [1 9 2 6 0 3 7 8 5 4]
 [0 1 2 5 3 7 9 8 4 6]
 [1 3 0 6 9 2 5 7 8 4]
 [3 5 1 4 6 0 2 9 7 8]
 [6 2 3 5 8 1 9 4 7 0]
 [6 4 9 1 3 5 7 2 0 8]
 [9 1 7 3 8 5 2 0 6 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 0 9 5 6 3 1 2 4 8]
 [6 0 1 9 7 8 3 5 4 2]
 [8 9 0 7 5 1 2 3 6 4]
 [3 1 8 5 7 6 0 2 4 9]
 [8 7 3 5 9 6 0 2 1 4]
 [8 1 7 0 3 4 6 2 5 9]
 [6 7 2 8 9 3 1 0 4 5]
 [4 6 7 8 2 3 9 1 5 0]
 [6 4 9 1 3 7 0 2 8 5]
 [0 8 2 4 1 3 6 7 9 5]]
Epoch 70510: Training cost= 2.3026, Training acc= 0.7642, Validation cost= 2.3026, Validation acc= 0.7637
Epoch 70520: Training cost= 2.3026, Training acc= 0.7641, Validation cost= 2.3026, Validation acc= 0.7636
Epoch 70530: Training cost= 2.3026, Training acc= 0.7640, Validation cost= 2.3026, Validation acc= 0.7635
Epoch 70540: Training cost= 2.3026, Training acc= 0.7639, Validation cost= 2.3026, Validation acc= 0.7634
Epoch 70550: Training cost= 2.3026, Training acc= 0.7638, Validation cost= 2.3026, Validation acc= 0.7633
Epoch 70560: Training cost= 2.3026, Training acc= 0.7637, Validation cost= 2.3026, Validation acc= 0.7632
Epoch 70570: Training cost= 2.3026, Training acc= 0.7636, Validation cost= 2.3026, Validation acc= 0.7631
Epoch 70580: Training cost= 2.3026, Training acc= 0.7635, Validation cost= 2.3026, Validation acc= 0.7630
Epoch 70590: Training cost= 2.3026, Training acc= 0.7634, Validation cost= 2.3026, Validation acc= 0.7630
Epoch 70600: Training cost= 2.3026, Training acc= 0.7633, Validation cost= 2.3026, Validation acc= 0.7629
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 1 2 3 7 9 6 5 4 8]
 [3 6 8 1 9 5 0 7 2 4]
 [8 3 1 4 9 5 2 6 7 0]
 [3 5 6 9 1 8 7 2 0 4]
 [8 9 7 1 6 3 5 2 0 4]
 [6 1 7 2 5 8 3 4 0 9]
 [0 1 4 3 8 2 5 9 7 6]
 [4 2 7 1 3 6 8 5 0 9]
 [0 8 2 4 3 1 5 6 7 9]
 [4 0 3 7 6 1 2 8 5 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 2 5 0 9 7 6 3 4 1]
 [3 5 0 4 2 7 8 1 9 6]
 [2 0 6 5 4 7 9 8 3 1]
 [6 9 5 0 1 4 3 8 2 7]
 [7 0 8 4 1 3 9 5 6 2]
 [1 8 5 6 7 0 3 9 4 2]
 [4 0 6 1 8 2 5 9 3 7]
 [2 1 3 7 8 6 4 0 5 9]
 [5 7 0 9 6 4 1 3 8 2]
 [6 8 4 2 9 3 0 1 5 7]]
Epoch 70610: Training cost= 2.3026, Training acc= 0.7632, Validation cost= 2.3026, Validation acc= 0.7628
Epoch 70620: Training cost= 2.3026, Training acc= 0.7631, Validation cost= 2.3026, Validation acc= 0.7627
Epoch 70630: Training cost= 2.3026, Training acc= 0.7630, Validation cost= 2.3026, Validation acc= 0.7626
Epoch 70640: Training cost= 2.3026, Training acc= 0.7629, Validation cost= 2.3026, Validation acc= 0.7625
Epoch 70650: Training cost= 2.3026, Training acc= 0.7628, Validation cost= 2.3026, Validation acc= 0.7624
Epoch 70660: Training cost= 2.3026, Training acc= 0.7627, Validation cost= 2.3026, Validation acc= 0.7623
Epoch 70670: Training cost= 2.3026, Training acc= 0.7627, Validation cost= 2.3026, Validation acc= 0.7622
Epoch 70680: Training cost= 2.3026, Training acc= 0.7626, Validation cost= 2.3026, Validation acc= 0.7621
Epoch 70690: Training cost= 2.3026, Training acc= 0.7625, Validation cost= 2.3026, Validation acc= 0.7620
Epoch 70700: Training cost= 2.3026, Training acc= 0.7624, Validation cost= 2.3026, Validation acc= 0.7619
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 6 2 9 3 0 8 4 1 7]
 [8 0 6 2 7 5 9 4 3 1]
 [0 3 6 1 2 9 8 5 4 7]
 [4 2 1 7 9 6 8 3 0 5]
 [1 7 5 6 2 3 4 0 8 9]
 [7 0 9 2 5 1 3 6 4 8]
 [4 9 2 7 6 8 5 0 1 3]
 [5 9 8 7 4 3 0 6 1 2]
 [1 7 4 6 2 0 9 5 8 3]
 [6 0 9 3 5 1 2 7 8 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 8 6 4 0 1 9 2 7]
 [2 6 9 0 1 8 3 7 4 5]
 [7 4 2 3 9 0 5 8 6 1]
 [4 5 6 8 1 9 2 3 7 0]
 [2 1 5 3 6 4 0 9 8 7]
 [0 6 1 3 2 9 5 4 7 8]
 [1 9 4 7 5 6 8 2 3 0]
 [2 6 5 9 3 0 1 7 8 4]
 [1 7 5 3 2 8 9 4 0 6]
 [5 8 2 6 0 9 1 3 4 7]]
Epoch 70710: Training cost= 2.3026, Training acc= 0.7623, Validation cost= 2.3026, Validation acc= 0.7618
Epoch 70720: Training cost= 2.3026, Training acc= 0.7622, Validation cost= 2.3026, Validation acc= 0.7617
Epoch 70730: Training cost= 2.3026, Training acc= 0.7621, Validation cost= 2.3026, Validation acc= 0.7616
Epoch 70740: Training cost= 2.3026, Training acc= 0.7620, Validation cost= 2.3026, Validation acc= 0.7615
Epoch 70750: Training cost= 2.3026, Training acc= 0.7619, Validation cost= 2.3026, Validation acc= 0.7615
Epoch 70760: Training cost= 2.3026, Training acc= 0.7618, Validation cost= 2.3026, Validation acc= 0.7614
Epoch 70770: Training cost= 2.3026, Training acc= 0.7617, Validation cost= 2.3026, Validation acc= 0.7613
Epoch 70780: Training cost= 2.3026, Training acc= 0.7616, Validation cost= 2.3026, Validation acc= 0.7612
Epoch 70790: Training cost= 2.3026, Training acc= 0.7615, Validation cost= 2.3026, Validation acc= 0.7611
Epoch 70800: Training cost= 2.3026, Training acc= 0.7614, Validation cost= 2.3026, Validation acc= 0.7610
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 7 4 6 5 3 1 8 2 9]
 [0 3 4 7 9 5 6 8 2 1]
 [1 5 2 6 8 4 0 7 9 3]
 [0 2 5 7 4 6 9 1 3 8]
 [8 7 4 2 9 1 5 6 3 0]
 [1 2 8 3 6 4 0 5 9 7]
 [4 0 3 5 9 6 7 8 1 2]
 [3 4 0 8 9 1 2 7 6 5]
 [6 7 4 5 8 2 9 1 3 0]
 [1 9 0 8 3 7 4 2 6 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 8 7 5 4 1 2 3 9 6]
 [0 5 3 7 4 8 9 2 6 1]
 [5 9 3 6 7 0 1 4 2 8]
 [3 2 1 0 4 7 5 8 6 9]
 [9 6 5 2 1 7 3 0 4 8]
 [1 0 4 2 8 3 9 7 6 5]
 [1 6 8 4 5 7 3 0 2 9]
 [0 8 5 2 4 3 9 7 1 6]
 [0 8 7 3 5 2 9 4 6 1]
 [3 7 8 5 4 0 2 9 1 6]]
Epoch 70810: Training cost= 2.3026, Training acc= 0.7613, Validation cost= 2.3026, Validation acc= 0.7609
Epoch 70820: Training cost= 2.3026, Training acc= 0.7612, Validation cost= 2.3026, Validation acc= 0.7608
Epoch 70830: Training cost= 2.3026, Training acc= 0.7612, Validation cost= 2.3026, Validation acc= 0.7607
Epoch 70840: Training cost= 2.3026, Training acc= 0.7611, Validation cost= 2.3026, Validation acc= 0.7606
Epoch 70850: Training cost= 2.3026, Training acc= 0.7610, Validation cost= 2.3026, Validation acc= 0.7605
Epoch 70860: Training cost= 2.3026, Training acc= 0.7609, Validation cost= 2.3026, Validation acc= 0.7604
Epoch 70870: Training cost= 2.3026, Training acc= 0.7608, Validation cost= 2.3026, Validation acc= 0.7603
Epoch 70880: Training cost= 2.3026, Training acc= 0.7607, Validation cost= 2.3026, Validation acc= 0.7602
Epoch 70890: Training cost= 2.3026, Training acc= 0.7606, Validation cost= 2.3026, Validation acc= 0.7601
Epoch 70900: Training cost= 2.3026, Training acc= 0.7605, Validation cost= 2.3026, Validation acc= 0.7601
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 9 8 3 1 7 5 4 0 2]
 [4 1 2 7 5 8 3 9 6 0]
 [3 0 6 9 4 1 2 5 8 7]
 [4 7 5 0 1 2 8 3 9 6]
 [7 1 8 0 6 9 4 5 2 3]
 [9 7 8 6 4 5 0 3 1 2]
 [1 3 6 8 2 7 4 0 9 5]
 [8 6 9 4 0 2 3 5 1 7]
 [2 9 4 6 5 3 7 8 1 0]
 [9 8 1 6 7 4 5 3 0 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 7 6 9 5 4 0 2 1 8]
 [9 0 8 5 3 1 4 2 7 6]
 [1 0 4 7 6 9 2 5 3 8]
 [6 3 4 2 5 8 1 0 7 9]
 [8 0 5 3 9 1 2 7 4 6]
 [0 7 5 8 2 1 4 3 6 9]
 [9 0 4 8 5 1 3 2 7 6]
 [7 2 3 8 0 5 6 1 4 9]
 [5 8 3 9 1 2 6 4 7 0]
 [9 5 8 6 2 7 0 3 4 1]]
Epoch 70910: Training cost= 2.3026, Training acc= 0.7604, Validation cost= 2.3026, Validation acc= 0.7600
Epoch 70920: Training cost= 2.3026, Training acc= 0.7603, Validation cost= 2.3026, Validation acc= 0.7599
Epoch 70930: Training cost= 2.3026, Training acc= 0.7602, Validation cost= 2.3026, Validation acc= 0.7598
Epoch 70940: Training cost= 2.3026, Training acc= 0.7601, Validation cost= 2.3026, Validation acc= 0.7597
Epoch 70950: Training cost= 2.3026, Training acc= 0.7600, Validation cost= 2.3026, Validation acc= 0.7596
Epoch 70960: Training cost= 2.3026, Training acc= 0.7599, Validation cost= 2.3026, Validation acc= 0.7595
Epoch 70970: Training cost= 2.3026, Training acc= 0.7598, Validation cost= 2.3026, Validation acc= 0.7594
Epoch 70980: Training cost= 2.3026, Training acc= 0.7598, Validation cost= 2.3026, Validation acc= 0.7593
Epoch 70990: Training cost= 2.3026, Training acc= 0.7597, Validation cost= 2.3026, Validation acc= 0.7592
Epoch 71000: Training cost= 2.3026, Training acc= 0.7596, Validation cost= 2.3026, Validation acc= 0.7591
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 2 6 0 3 8 7 5 4 1]
 [9 3 7 1 6 8 0 2 5 4]
 [8 4 7 6 9 1 0 3 2 5]
 [0 4 3 9 6 5 7 2 1 8]
 [5 3 1 0 2 6 9 8 4 7]
 [3 2 4 1 7 0 6 8 5 9]
 [9 3 1 2 5 0 8 4 7 6]
 [0 1 7 2 3 9 8 4 6 5]
 [6 8 4 5 2 0 1 9 3 7]
 [6 1 9 5 3 2 4 0 7 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 1 8 6 2 0 3 9 4 5]
 [1 0 3 7 6 9 4 5 2 8]
 [8 2 0 4 1 5 3 6 9 7]
 [6 5 2 4 8 9 1 7 3 0]
 [1 4 7 5 8 0 2 6 9 3]
 [2 4 8 1 7 0 5 6 3 9]
 [7 6 2 4 8 5 3 1 0 9]
 [7 0 4 3 6 2 9 1 5 8]
 [3 4 1 0 6 2 9 7 5 8]
 [9 8 2 7 1 6 0 4 5 3]]
Epoch 71010: Training cost= 2.3026, Training acc= 0.7595, Validation cost= 2.3026, Validation acc= 0.7590
Epoch 71020: Training cost= 2.3026, Training acc= 0.7594, Validation cost= 2.3026, Validation acc= 0.7589
Epoch 71030: Training cost= 2.3026, Training acc= 0.7593, Validation cost= 2.3026, Validation acc= 0.7588
Epoch 71040: Training cost= 2.3026, Training acc= 0.7592, Validation cost= 2.3026, Validation acc= 0.7588
Epoch 71050: Training cost= 2.3026, Training acc= 0.7591, Validation cost= 2.3026, Validation acc= 0.7587
Epoch 71060: Training cost= 2.3026, Training acc= 0.7590, Validation cost= 2.3026, Validation acc= 0.7586
Epoch 71070: Training cost= 2.3026, Training acc= 0.7589, Validation cost= 2.3026, Validation acc= 0.7585
Epoch 71080: Training cost= 2.3026, Training acc= 0.7588, Validation cost= 2.3026, Validation acc= 0.7584
Epoch 71090: Training cost= 2.3026, Training acc= 0.7587, Validation cost= 2.3026, Validation acc= 0.7583
Epoch 71100: Training cost= 2.3026, Training acc= 0.7586, Validation cost= 2.3026, Validation acc= 0.7582
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 7 0 1 9 2 4 5 6 8]
 [8 0 4 2 1 9 7 6 3 5]
 [6 5 7 4 0 8 2 9 1 3]
 [4 6 5 9 3 2 1 0 7 8]
 [4 1 3 9 0 5 7 6 2 8]
 [8 2 0 3 4 1 9 6 5 7]
 [6 8 4 1 7 2 3 0 5 9]
 [3 1 9 7 6 8 4 2 0 5]
 [8 3 0 4 6 1 9 5 7 2]
 [8 6 2 4 3 1 0 7 9 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 1 6 7 5 0 3 9 4 8]
 [5 1 7 2 4 9 6 8 0 3]
 [4 7 8 0 3 6 5 9 1 2]
 [2 1 3 4 6 8 9 5 0 7]
 [2 5 8 9 6 1 4 0 7 3]
 [9 5 6 7 0 4 8 3 2 1]
 [6 3 4 1 5 8 9 7 0 2]
 [4 6 5 1 9 2 7 8 3 0]
 [5 7 4 3 2 8 9 1 6 0]
 [8 6 5 2 1 9 0 7 4 3]]
Epoch 71110: Training cost= 2.3026, Training acc= 0.7586, Validation cost= 2.3026, Validation acc= 0.7581
Epoch 71120: Training cost= 2.3026, Training acc= 0.7585, Validation cost= 2.3026, Validation acc= 0.7580
Epoch 71130: Training cost= 2.3026, Training acc= 0.7584, Validation cost= 2.3026, Validation acc= 0.7579
Epoch 71140: Training cost= 2.3026, Training acc= 0.7583, Validation cost= 2.3026, Validation acc= 0.7578
Epoch 71150: Training cost= 2.3026, Training acc= 0.7582, Validation cost= 2.3026, Validation acc= 0.7577
Epoch 71160: Training cost= 2.3026, Training acc= 0.7581, Validation cost= 2.3026, Validation acc= 0.7576
Epoch 71170: Training cost= 2.3026, Training acc= 0.7580, Validation cost= 2.3026, Validation acc= 0.7575
Epoch 71180: Training cost= 2.3026, Training acc= 0.7579, Validation cost= 2.3026, Validation acc= 0.7575
Epoch 71190: Training cost= 2.3026, Training acc= 0.7578, Validation cost= 2.3026, Validation acc= 0.7574
Epoch 71200: Training cost= 2.3026, Training acc= 0.7577, Validation cost= 2.3026, Validation acc= 0.7573
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 3 8 4 9 1 2 0 5 6]
 [9 0 1 6 4 8 7 3 5 2]
 [1 3 2 8 7 9 0 4 6 5]
 [0 4 3 6 7 5 9 8 2 1]
 [3 1 4 0 2 8 6 5 9 7]
 [9 4 5 7 3 1 0 8 2 6]
 [6 1 8 5 4 0 7 9 2 3]
 [6 7 8 2 4 3 5 9 1 0]
 [9 8 2 5 4 3 6 0 1 7]
 [2 4 0 9 6 7 8 3 1 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 9 0 2 5 8 1 7 4 6]
 [1 6 5 3 8 0 7 4 9 2]
 [0 7 4 5 8 2 6 9 3 1]
 [8 5 0 4 6 9 7 1 3 2]
 [5 9 0 1 8 4 2 6 3 7]
 [3 2 4 9 6 7 5 0 8 1]
 [1 8 7 9 3 4 0 2 6 5]
 [9 7 0 5 4 3 1 8 6 2]
 [8 7 3 0 2 5 1 6 4 9]
 [9 2 1 0 4 6 3 8 5 7]]
Epoch 71210: Training cost= 2.3026, Training acc= 0.7576, Validation cost= 2.3026, Validation acc= 0.7572
Epoch 71220: Training cost= 2.3026, Training acc= 0.7575, Validation cost= 2.3026, Validation acc= 0.7571
Epoch 71230: Training cost= 2.3026, Training acc= 0.7574, Validation cost= 2.3026, Validation acc= 0.7570
Epoch 71240: Training cost= 2.3026, Training acc= 0.7573, Validation cost= 2.3026, Validation acc= 0.7569
Epoch 71250: Training cost= 2.3026, Training acc= 0.7573, Validation cost= 2.3026, Validation acc= 0.7568
Epoch 71260: Training cost= 2.3026, Training acc= 0.7572, Validation cost= 2.3026, Validation acc= 0.7567
Epoch 71270: Training cost= 2.3026, Training acc= 0.7571, Validation cost= 2.3026, Validation acc= 0.7566
Epoch 71280: Training cost= 2.3026, Training acc= 0.7570, Validation cost= 2.3026, Validation acc= 0.7565
Epoch 71290: Training cost= 2.3026, Training acc= 0.7569, Validation cost= 2.3026, Validation acc= 0.7564
Epoch 71300: Training cost= 2.3026, Training acc= 0.7568, Validation cost= 2.3026, Validation acc= 0.7563
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 0 6 8 3 5 2 1 9 7]
 [5 0 1 3 2 8 9 6 4 7]
 [2 7 0 5 9 4 1 6 3 8]
 [0 4 8 9 7 6 2 3 1 5]
 [4 2 5 1 7 3 9 0 6 8]
 [7 6 8 5 0 4 3 2 1 9]
 [8 6 0 7 4 1 2 9 3 5]
 [2 9 4 7 3 6 8 0 5 1]
 [9 6 5 0 1 3 4 8 2 7]
 [9 5 1 2 3 4 7 8 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 1 8 4 0 2 6 7 9]
 [4 3 8 0 9 5 2 7 6 1]
 [2 9 0 6 8 1 3 4 7 5]
 [3 9 6 0 7 2 1 8 5 4]
 [3 6 8 9 5 1 4 7 0 2]
 [3 0 9 1 7 4 8 6 5 2]
 [4 5 3 2 0 1 8 9 6 7]
 [6 7 2 9 5 4 1 0 3 8]
 [3 5 6 1 8 4 7 0 9 2]
 [7 3 5 9 8 4 2 1 6 0]]
Epoch 71310: Training cost= 2.3026, Training acc= 0.7567, Validation cost= 2.3026, Validation acc= 0.7563
Epoch 71320: Training cost= 2.3026, Training acc= 0.7566, Validation cost= 2.3026, Validation acc= 0.7562
Epoch 71330: Training cost= 2.3026, Training acc= 0.7565, Validation cost= 2.3026, Validation acc= 0.7561
Epoch 71340: Training cost= 2.3026, Training acc= 0.7564, Validation cost= 2.3026, Validation acc= 0.7560
Epoch 71350: Training cost= 2.3026, Training acc= 0.7563, Validation cost= 2.3026, Validation acc= 0.7559
Epoch 71360: Training cost= 2.3026, Training acc= 0.7562, Validation cost= 2.3026, Validation acc= 0.7558
Epoch 71370: Training cost= 2.3026, Training acc= 0.7562, Validation cost= 2.3026, Validation acc= 0.7557
Epoch 71380: Training cost= 2.3026, Training acc= 0.7561, Validation cost= 2.3026, Validation acc= 0.7556
Epoch 71390: Training cost= 2.3026, Training acc= 0.7560, Validation cost= 2.3026, Validation acc= 0.7555
Epoch 71400: Training cost= 2.3026, Training acc= 0.7559, Validation cost= 2.3026, Validation acc= 0.7554
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 0 4 6 5 8 3 1 2 9]
 [1 8 2 0 5 9 4 3 7 6]
 [4 0 6 8 3 9 5 7 1 2]
 [5 8 1 3 6 4 7 2 9 0]
 [3 4 2 1 9 5 8 7 0 6]
 [9 2 5 4 6 7 1 0 8 3]
 [1 3 9 4 2 7 8 5 6 0]
 [7 2 1 8 5 6 4 0 9 3]
 [1 9 5 2 0 6 7 3 8 4]
 [8 9 4 1 2 3 6 0 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 9 2 0 6 3 1 7 5 4]
 [0 3 6 2 8 1 7 4 9 5]
 [9 5 7 0 8 6 1 2 4 3]
 [1 3 6 8 9 2 7 4 5 0]
 [9 6 4 2 8 1 3 7 0 5]
 [8 0 3 5 6 7 4 1 9 2]
 [7 2 6 3 4 9 5 0 8 1]
 [2 3 8 0 7 4 9 1 5 6]
 [1 5 0 6 3 2 8 9 7 4]
 [2 0 3 9 7 4 5 6 8 1]]
Epoch 71410: Training cost= 2.3026, Training acc= 0.7558, Validation cost= 2.3026, Validation acc= 0.7553
Epoch 71420: Training cost= 2.3026, Training acc= 0.7557, Validation cost= 2.3026, Validation acc= 0.7552
Epoch 71430: Training cost= 2.3026, Training acc= 0.7556, Validation cost= 2.3026, Validation acc= 0.7552
Epoch 71440: Training cost= 2.3026, Training acc= 0.7555, Validation cost= 2.3026, Validation acc= 0.7551
Epoch 71450: Training cost= 2.3026, Training acc= 0.7554, Validation cost= 2.3026, Validation acc= 0.7550
Epoch 71460: Training cost= 2.3026, Training acc= 0.7553, Validation cost= 2.3026, Validation acc= 0.7549
Epoch 71470: Training cost= 2.3026, Training acc= 0.7552, Validation cost= 2.3026, Validation acc= 0.7548
Epoch 71480: Training cost= 2.3026, Training acc= 0.7551, Validation cost= 2.3026, Validation acc= 0.7547
Epoch 71490: Training cost= 2.3026, Training acc= 0.7551, Validation cost= 2.3026, Validation acc= 0.7546
Epoch 71500: Training cost= 2.3026, Training acc= 0.7550, Validation cost= 2.3026, Validation acc= 0.7545
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 9 4 2 7 8 5 1 0 6]
 [5 1 2 3 6 0 8 7 4 9]
 [5 7 0 8 4 1 2 3 6 9]
 [7 0 2 1 5 4 6 9 8 3]
 [4 1 8 3 7 5 6 9 2 0]
 [8 5 7 6 4 1 2 3 9 0]
 [8 6 3 7 4 1 9 2 0 5]
 [2 0 3 9 5 1 6 7 4 8]
 [3 1 6 0 4 8 9 2 5 7]
 [7 6 5 9 2 1 8 3 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 0 5 7 9 2 1 3 8 6]
 [2 7 3 5 0 6 9 1 4 8]
 [2 8 4 5 0 9 3 1 7 6]
 [2 1 3 8 7 9 5 6 4 0]
 [4 1 0 2 7 5 9 8 6 3]
 [1 0 4 8 5 7 9 6 2 3]
 [5 1 7 6 2 4 0 3 9 8]
 [6 0 1 4 3 7 2 8 9 5]
 [6 3 7 5 4 8 2 9 0 1]
 [1 9 3 2 8 0 5 6 7 4]]
Epoch 71510: Training cost= 2.3026, Training acc= 0.7549, Validation cost= 2.3026, Validation acc= 0.7544
Epoch 71520: Training cost= 2.3026, Training acc= 0.7548, Validation cost= 2.3026, Validation acc= 0.7543
Epoch 71530: Training cost= 2.3026, Training acc= 0.7547, Validation cost= 2.3026, Validation acc= 0.7542
Epoch 71540: Training cost= 2.3026, Training acc= 0.7546, Validation cost= 2.3026, Validation acc= 0.7541
Epoch 71550: Training cost= 2.3026, Training acc= 0.7545, Validation cost= 2.3026, Validation acc= 0.7541
Epoch 71560: Training cost= 2.3026, Training acc= 0.7544, Validation cost= 2.3026, Validation acc= 0.7540
Epoch 71570: Training cost= 2.3026, Training acc= 0.7543, Validation cost= 2.3026, Validation acc= 0.7539
Epoch 71580: Training cost= 2.3026, Training acc= 0.7542, Validation cost= 2.3026, Validation acc= 0.7538
Epoch 71590: Training cost= 2.3026, Training acc= 0.7541, Validation cost= 2.3026, Validation acc= 0.7537
Epoch 71600: Training cost= 2.3026, Training acc= 0.7540, Validation cost= 2.3026, Validation acc= 0.7536
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 4 6 2 7 8 3 1 0 5]
 [6 4 2 3 9 0 7 5 8 1]
 [9 2 1 4 3 7 6 8 5 0]
 [1 3 0 5 8 2 6 9 4 7]
 [3 6 5 2 1 0 9 7 4 8]
 [0 8 1 4 3 2 7 6 9 5]
 [9 4 5 2 7 3 0 1 8 6]
 [0 5 2 1 4 6 7 8 3 9]
 [5 0 4 1 3 7 6 9 2 8]
 [2 3 6 9 4 5 7 0 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 1 9 3 4 8 0 6 7 2]
 [4 8 1 7 5 3 6 2 0 9]
 [7 3 6 1 9 5 8 0 4 2]
 [3 7 0 9 2 4 1 5 6 8]
 [1 5 3 9 0 7 6 2 8 4]
 [1 4 5 3 0 2 6 8 9 7]
 [2 0 3 6 5 1 4 7 9 8]
 [4 1 3 0 2 6 7 9 5 8]
 [6 7 1 5 9 0 3 4 2 8]
 [0 2 4 5 9 7 8 1 6 3]]
Epoch 71610: Training cost= 2.3026, Training acc= 0.7540, Validation cost= 2.3026, Validation acc= 0.7535
Epoch 71620: Training cost= 2.3026, Training acc= 0.7539, Validation cost= 2.3026, Validation acc= 0.7534
Epoch 71630: Training cost= 2.3026, Training acc= 0.7538, Validation cost= 2.3026, Validation acc= 0.7533
Epoch 71640: Training cost= 2.3026, Training acc= 0.7537, Validation cost= 2.3026, Validation acc= 0.7532
Epoch 71650: Training cost= 2.3026, Training acc= 0.7536, Validation cost= 2.3026, Validation acc= 0.7531
Epoch 71660: Training cost= 2.3026, Training acc= 0.7535, Validation cost= 2.3026, Validation acc= 0.7531
Epoch 71670: Training cost= 2.3026, Training acc= 0.7534, Validation cost= 2.3026, Validation acc= 0.7530
Epoch 71680: Training cost= 2.3026, Training acc= 0.7533, Validation cost= 2.3026, Validation acc= 0.7529
Epoch 71690: Training cost= 2.3026, Training acc= 0.7532, Validation cost= 2.3026, Validation acc= 0.7528
Epoch 71700: Training cost= 2.3026, Training acc= 0.7531, Validation cost= 2.3026, Validation acc= 0.7527
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 3 4 0 1 8 5 2 6 7]
 [3 8 9 0 5 6 4 2 1 7]
 [2 6 1 0 3 4 8 7 9 5]
 [4 7 6 0 1 3 5 8 2 9]
 [8 9 5 3 7 2 6 1 0 4]
 [8 0 3 7 6 2 4 9 5 1]
 [0 5 3 2 7 4 1 8 6 9]
 [7 6 3 1 4 5 8 9 2 0]
 [5 4 0 1 7 3 8 6 2 9]
 [8 3 7 5 2 9 1 4 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 4 0 3 9 7 2 6 1 5]
 [0 9 4 1 8 7 3 5 2 6]
 [5 1 4 3 2 7 6 9 0 8]
 [2 1 3 7 5 4 8 0 6 9]
 [0 6 8 3 9 4 7 5 1 2]
 [9 7 0 3 4 5 8 1 2 6]
 [1 8 4 0 2 6 7 9 5 3]
 [6 0 1 2 9 7 3 4 8 5]
 [4 3 0 5 7 9 8 2 6 1]
 [5 4 6 8 0 2 9 3 7 1]]
Epoch 71710: Training cost= 2.3026, Training acc= 0.7530, Validation cost= 2.3026, Validation acc= 0.7526
Epoch 71720: Training cost= 2.3026, Training acc= 0.7529, Validation cost= 2.3026, Validation acc= 0.7525
Epoch 71730: Training cost= 2.3026, Training acc= 0.7529, Validation cost= 2.3026, Validation acc= 0.7524
Epoch 71740: Training cost= 2.3026, Training acc= 0.7528, Validation cost= 2.3026, Validation acc= 0.7523
Epoch 71750: Training cost= 2.3026, Training acc= 0.7527, Validation cost= 2.3026, Validation acc= 0.7522
Epoch 71760: Training cost= 2.3026, Training acc= 0.7526, Validation cost= 2.3026, Validation acc= 0.7521
Epoch 71770: Training cost= 2.3026, Training acc= 0.7525, Validation cost= 2.3026, Validation acc= 0.7521
Epoch 71780: Training cost= 2.3026, Training acc= 0.7524, Validation cost= 2.3026, Validation acc= 0.7520
Epoch 71790: Training cost= 2.3026, Training acc= 0.7523, Validation cost= 2.3026, Validation acc= 0.7519
Epoch 71800: Training cost= 2.3026, Training acc= 0.7522, Validation cost= 2.3026, Validation acc= 0.7518
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 0 5 1 3 6 4 9 2 7]
 [5 2 9 0 1 6 7 8 3 4]
 [4 0 2 8 9 5 7 1 3 6]
 [9 0 4 3 8 6 1 7 5 2]
 [4 0 1 7 3 6 5 8 2 9]
 [0 9 1 6 4 3 7 8 2 5]
 [1 4 6 8 9 7 2 0 5 3]
 [4 0 8 3 1 5 9 7 2 6]
 [3 7 4 2 1 9 5 8 0 6]
 [4 6 7 9 3 0 2 1 5 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 8 9 5 6 3 0 4 2 7]
 [9 3 2 6 1 8 5 0 4 7]
 [8 1 3 0 2 5 6 4 7 9]
 [3 4 1 8 6 9 0 5 2 7]
 [3 1 9 5 7 4 2 6 0 8]
 [4 2 3 6 7 8 5 0 9 1]
 [7 2 1 4 8 5 3 6 0 9]
 [7 1 8 6 3 4 2 9 5 0]
 [3 7 5 1 6 8 4 9 2 0]
 [4 9 3 8 5 0 6 2 7 1]]
Epoch 71810: Training cost= 2.3026, Training acc= 0.7521, Validation cost= 2.3026, Validation acc= 0.7517
Epoch 71820: Training cost= 2.3026, Training acc= 0.7520, Validation cost= 2.3026, Validation acc= 0.7516
Epoch 71830: Training cost= 2.3026, Training acc= 0.7519, Validation cost= 2.3026, Validation acc= 0.7515
Epoch 71840: Training cost= 2.3026, Training acc= 0.7519, Validation cost= 2.3026, Validation acc= 0.7514
Epoch 71850: Training cost= 2.3026, Training acc= 0.7518, Validation cost= 2.3026, Validation acc= 0.7513
Epoch 71860: Training cost= 2.3026, Training acc= 0.7517, Validation cost= 2.3026, Validation acc= 0.7512
Epoch 71870: Training cost= 2.3026, Training acc= 0.7516, Validation cost= 2.3026, Validation acc= 0.7511
Epoch 71880: Training cost= 2.3026, Training acc= 0.7515, Validation cost= 2.3026, Validation acc= 0.7511
Epoch 71890: Training cost= 2.3026, Training acc= 0.7514, Validation cost= 2.3026, Validation acc= 0.7510
Epoch 71900: Training cost= 2.3026, Training acc= 0.7513, Validation cost= 2.3026, Validation acc= 0.7509
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 9 6 3 2 8 4 1 5 7]
 [0 2 7 8 6 5 4 3 9 1]
 [9 7 3 6 4 2 0 1 8 5]
 [2 6 0 9 1 3 4 8 7 5]
 [7 0 5 8 4 3 2 1 6 9]
 [4 1 8 2 7 9 3 6 0 5]
 [6 9 8 3 7 0 4 2 5 1]
 [6 3 7 1 0 9 5 2 4 8]
 [7 9 8 4 5 6 1 3 0 2]
 [6 7 3 0 5 2 1 9 4 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 4 8 3 0 2 9 6 5 7]
 [6 4 7 1 9 8 0 2 5 3]
 [9 5 4 3 8 6 1 0 2 7]
 [0 8 1 9 3 5 2 4 7 6]
 [2 3 0 5 4 7 1 6 9 8]
 [9 4 5 7 0 1 6 8 3 2]
 [4 8 3 2 0 5 1 9 6 7]
 [2 1 9 0 4 5 3 6 8 7]
 [4 1 6 7 3 5 8 0 9 2]
 [1 2 4 8 9 3 5 6 7 0]]
Epoch 71910: Training cost= 2.3026, Training acc= 0.7512, Validation cost= 2.3026, Validation acc= 0.7508
Epoch 71920: Training cost= 2.3026, Training acc= 0.7511, Validation cost= 2.3026, Validation acc= 0.7507
Epoch 71930: Training cost= 2.3026, Training acc= 0.7510, Validation cost= 2.3026, Validation acc= 0.7506
Epoch 71940: Training cost= 2.3026, Training acc= 0.7510, Validation cost= 2.3026, Validation acc= 0.7505
Epoch 71950: Training cost= 2.3026, Training acc= 0.7509, Validation cost= 2.3026, Validation acc= 0.7504
Epoch 71960: Training cost= 2.3026, Training acc= 0.7508, Validation cost= 2.3026, Validation acc= 0.7503
Epoch 71970: Training cost= 2.3026, Training acc= 0.7507, Validation cost= 2.3026, Validation acc= 0.7502
Epoch 71980: Training cost= 2.3026, Training acc= 0.7506, Validation cost= 2.3026, Validation acc= 0.7501
Epoch 71990: Training cost= 2.3026, Training acc= 0.7505, Validation cost= 2.3026, Validation acc= 0.7501
Epoch 72000: Training cost= 2.3026, Training acc= 0.7504, Validation cost= 2.3026, Validation acc= 0.7500
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 0 9 6 7 3 8 5 4 2]
 [2 9 4 0 5 3 1 8 7 6]
 [4 3 6 2 8 7 5 1 0 9]
 [7 6 1 9 2 3 5 4 8 0]
 [9 7 0 4 6 5 3 8 2 1]
 [7 5 9 1 2 8 3 6 0 4]
 [5 1 4 8 0 9 7 3 6 2]
 [0 5 2 7 3 1 8 6 9 4]
 [0 6 7 2 1 9 8 4 5 3]
 [4 9 8 6 5 7 1 0 3 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 1 4 5 6 3 8 9 2 7]
 [2 1 9 8 3 7 0 6 4 5]
 [5 1 9 8 4 0 3 2 6 7]
 [6 7 5 9 2 1 3 0 4 8]
 [4 7 5 9 3 0 2 6 1 8]
 [6 0 8 2 1 4 3 5 9 7]
 [9 1 6 3 7 0 2 5 8 4]
 [7 0 9 4 1 2 6 3 8 5]
 [3 7 6 8 0 9 4 5 2 1]
 [5 1 2 0 3 7 6 4 8 9]]
Epoch 72010: Training cost= 2.3026, Training acc= 0.7503, Validation cost= 2.3026, Validation acc= 0.7499
Epoch 72020: Training cost= 2.3026, Training acc= 0.7502, Validation cost= 2.3026, Validation acc= 0.7498
Epoch 72030: Training cost= 2.3026, Training acc= 0.7501, Validation cost= 2.3026, Validation acc= 0.7497
Epoch 72040: Training cost= 2.3026, Training acc= 0.7500, Validation cost= 2.3026, Validation acc= 0.7496
Epoch 72050: Training cost= 2.3026, Training acc= 0.7500, Validation cost= 2.3026, Validation acc= 0.7495
Epoch 72060: Training cost= 2.3026, Training acc= 0.7499, Validation cost= 2.3026, Validation acc= 0.7494
Epoch 72070: Training cost= 2.3026, Training acc= 0.7498, Validation cost= 2.3026, Validation acc= 0.7493
Epoch 72080: Training cost= 2.3026, Training acc= 0.7497, Validation cost= 2.3026, Validation acc= 0.7492
Epoch 72090: Training cost= 2.3026, Training acc= 0.7496, Validation cost= 2.3026, Validation acc= 0.7492
Epoch 72100: Training cost= 2.3026, Training acc= 0.7495, Validation cost= 2.3026, Validation acc= 0.7491
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 1 9 0 6 4 5 2 3 8]
 [1 4 5 0 9 7 8 2 6 3]
 [3 1 4 9 6 5 2 0 8 7]
 [6 1 3 2 4 0 5 8 7 9]
 [6 9 1 2 7 8 4 5 3 0]
 [8 4 9 3 0 6 7 1 2 5]
 [6 5 0 7 9 4 1 2 8 3]
 [6 5 1 7 0 9 2 3 8 4]
 [9 5 6 0 2 3 4 7 8 1]
 [9 3 0 4 8 7 2 1 6 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 5 7 6 3 2 8 9 0 1]
 [5 7 1 2 8 3 4 6 0 9]
 [7 6 2 5 4 0 9 3 1 8]
 [6 5 1 8 3 2 0 7 4 9]
 [0 2 6 5 4 9 3 7 8 1]
 [8 3 9 7 1 4 6 2 0 5]
 [4 3 7 0 5 9 1 8 2 6]
 [5 8 1 2 3 7 4 0 6 9]
 [2 7 3 5 1 9 6 0 8 4]
 [2 1 5 0 6 7 4 8 9 3]]
Epoch 72110: Training cost= 2.3026, Training acc= 0.7494, Validation cost= 2.3026, Validation acc= 0.7490
Epoch 72120: Training cost= 2.3026, Training acc= 0.7493, Validation cost= 2.3026, Validation acc= 0.7489
Epoch 72130: Training cost= 2.3026, Training acc= 0.7492, Validation cost= 2.3026, Validation acc= 0.7488
Epoch 72140: Training cost= 2.3026, Training acc= 0.7491, Validation cost= 2.3026, Validation acc= 0.7487
Epoch 72150: Training cost= 2.3026, Training acc= 0.7491, Validation cost= 2.3026, Validation acc= 0.7486
Epoch 72160: Training cost= 2.3026, Training acc= 0.7490, Validation cost= 2.3026, Validation acc= 0.7485
Epoch 72170: Training cost= 2.3026, Training acc= 0.7489, Validation cost= 2.3026, Validation acc= 0.7484
Epoch 72180: Training cost= 2.3026, Training acc= 0.7488, Validation cost= 2.3026, Validation acc= 0.7483
Epoch 72190: Training cost= 2.3026, Training acc= 0.7487, Validation cost= 2.3026, Validation acc= 0.7483
Epoch 72200: Training cost= 2.3026, Training acc= 0.7486, Validation cost= 2.3026, Validation acc= 0.7482
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 7 5 0 2 6 3 9 4 8]
 [6 2 4 9 1 0 5 3 8 7]
 [1 7 6 8 3 5 4 0 9 2]
 [7 2 5 9 8 1 6 0 4 3]
 [0 4 5 7 2 1 3 8 6 9]
 [3 0 9 4 1 6 7 2 5 8]
 [1 4 3 5 7 2 9 8 0 6]
 [3 4 1 5 9 2 6 0 8 7]
 [8 4 1 7 0 6 5 3 9 2]
 [3 6 4 0 7 1 8 9 5 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 1 7 2 9 8 6 3 0 4]
 [8 7 4 0 5 6 9 2 1 3]
 [0 2 6 9 5 8 4 3 1 7]
 [4 8 0 9 3 6 2 1 7 5]
 [1 3 4 0 6 2 8 7 5 9]
 [2 8 6 7 0 1 9 4 3 5]
 [5 2 0 8 3 6 1 9 7 4]
 [9 1 3 8 4 0 2 5 6 7]
 [0 3 6 5 2 9 4 8 1 7]
 [8 4 1 9 7 6 0 2 5 3]]
Epoch 72210: Training cost= 2.3026, Training acc= 0.7485, Validation cost= 2.3026, Validation acc= 0.7481
Epoch 72220: Training cost= 2.3026, Training acc= 0.7484, Validation cost= 2.3026, Validation acc= 0.7480
Epoch 72230: Training cost= 2.3026, Training acc= 0.7483, Validation cost= 2.3026, Validation acc= 0.7479
Epoch 72240: Training cost= 2.3026, Training acc= 0.7482, Validation cost= 2.3026, Validation acc= 0.7478
Epoch 72250: Training cost= 2.3026, Training acc= 0.7482, Validation cost= 2.3026, Validation acc= 0.7477
Epoch 72260: Training cost= 2.3026, Training acc= 0.7481, Validation cost= 2.3026, Validation acc= 0.7476
Epoch 72270: Training cost= 2.3026, Training acc= 0.7480, Validation cost= 2.3026, Validation acc= 0.7475
Epoch 72280: Training cost= 2.3026, Training acc= 0.7479, Validation cost= 2.3026, Validation acc= 0.7474
Epoch 72290: Training cost= 2.3026, Training acc= 0.7478, Validation cost= 2.3026, Validation acc= 0.7474
Epoch 72300: Training cost= 2.3026, Training acc= 0.7477, Validation cost= 2.3026, Validation acc= 0.7473
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 0 2 9 5 1 4 3 8 6]
 [1 7 4 8 3 0 6 2 5 9]
 [2 6 8 5 0 1 9 4 7 3]
 [5 0 8 3 1 9 6 7 2 4]
 [8 1 2 5 0 9 6 7 3 4]
 [2 3 0 9 5 8 1 6 4 7]
 [9 2 6 1 8 5 3 4 7 0]
 [4 6 0 7 3 5 9 8 1 2]
 [1 0 8 2 6 4 7 5 3 9]
 [1 8 2 4 7 3 9 5 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 5 3 8 1 0 2 9 7 4]
 [1 8 6 4 7 0 3 5 2 9]
 [3 1 7 8 2 9 6 0 4 5]
 [0 1 8 6 4 7 2 3 9 5]
 [1 6 3 5 9 7 4 2 8 0]
 [5 6 2 8 1 7 0 4 3 9]
 [8 7 0 3 2 9 1 5 6 4]
 [6 3 4 5 0 7 9 8 1 2]
 [4 8 1 5 9 2 6 3 0 7]
 [5 0 3 7 9 4 1 8 6 2]]
Epoch 72310: Training cost= 2.3026, Training acc= 0.7476, Validation cost= 2.3026, Validation acc= 0.7472
Epoch 72320: Training cost= 2.3026, Training acc= 0.7475, Validation cost= 2.3026, Validation acc= 0.7471
Epoch 72330: Training cost= 2.3026, Training acc= 0.7474, Validation cost= 2.3026, Validation acc= 0.7470
Epoch 72340: Training cost= 2.3026, Training acc= 0.7474, Validation cost= 2.3026, Validation acc= 0.7469
Epoch 72350: Training cost= 2.3026, Training acc= 0.7473, Validation cost= 2.3026, Validation acc= 0.7468
Epoch 72360: Training cost= 2.3026, Training acc= 0.7472, Validation cost= 2.3026, Validation acc= 0.7467
Epoch 72370: Training cost= 2.3026, Training acc= 0.7471, Validation cost= 2.3026, Validation acc= 0.7466
Epoch 72380: Training cost= 2.3026, Training acc= 0.7470, Validation cost= 2.3026, Validation acc= 0.7466
Epoch 72390: Training cost= 2.3026, Training acc= 0.7469, Validation cost= 2.3026, Validation acc= 0.7465
Epoch 72400: Training cost= 2.3026, Training acc= 0.7468, Validation cost= 2.3026, Validation acc= 0.7464
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 2 9 3 6 7 8 0 5 1]
 [6 7 1 5 8 0 3 9 2 4]
 [6 2 7 5 8 3 1 0 4 9]
 [2 7 3 8 9 5 4 6 0 1]
 [9 6 3 2 8 5 4 7 0 1]
 [8 7 5 0 3 1 4 2 9 6]
 [7 8 1 5 3 0 6 2 9 4]
 [4 9 7 3 8 6 5 1 2 0]
 [4 9 6 5 7 0 3 1 2 8]
 [4 3 1 2 5 9 0 6 8 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 9 5 7 0 3 1 6 8 2]
 [9 2 3 0 4 8 5 7 6 1]
 [0 6 3 8 4 7 2 9 5 1]
 [1 4 9 2 5 8 3 0 6 7]
 [5 8 6 9 4 1 7 0 3 2]
 [3 4 2 1 7 8 6 5 9 0]
 [0 9 1 3 2 4 7 6 5 8]
 [4 5 7 1 0 3 2 8 9 6]
 [0 6 7 3 2 4 5 9 1 8]
 [5 2 4 0 1 3 9 7 8 6]]
Epoch 72410: Training cost= 2.3026, Training acc= 0.7467, Validation cost= 2.3026, Validation acc= 0.7463
Epoch 72420: Training cost= 2.3026, Training acc= 0.7466, Validation cost= 2.3026, Validation acc= 0.7462
Epoch 72430: Training cost= 2.3026, Training acc= 0.7465, Validation cost= 2.3026, Validation acc= 0.7461
Epoch 72440: Training cost= 2.3026, Training acc= 0.7465, Validation cost= 2.3026, Validation acc= 0.7460
Epoch 72450: Training cost= 2.3026, Training acc= 0.7464, Validation cost= 2.3026, Validation acc= 0.7459
Epoch 72460: Training cost= 2.3026, Training acc= 0.7463, Validation cost= 2.3026, Validation acc= 0.7458
Epoch 72470: Training cost= 2.3026, Training acc= 0.7462, Validation cost= 2.3026, Validation acc= 0.7458
Epoch 72480: Training cost= 2.3026, Training acc= 0.7461, Validation cost= 2.3026, Validation acc= 0.7457
Epoch 72490: Training cost= 2.3026, Training acc= 0.7460, Validation cost= 2.3026, Validation acc= 0.7456
Epoch 72500: Training cost= 2.3026, Training acc= 0.7459, Validation cost= 2.3026, Validation acc= 0.7455
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 3 1 0 9 2 8 4 5 6]
 [1 6 8 4 7 9 2 5 3 0]
 [8 7 3 4 1 2 6 9 0 5]
 [8 0 7 6 2 9 5 4 3 1]
 [0 6 4 9 1 8 2 5 3 7]
 [9 4 7 5 1 0 6 2 3 8]
 [1 4 7 2 5 0 8 3 9 6]
 [8 6 3 2 0 1 4 7 9 5]
 [9 5 2 0 7 4 6 8 1 3]
 [9 5 0 8 1 2 4 7 3 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 1 2 9 0 4 8 6 5 3]
 [3 1 6 9 2 7 0 8 5 4]
 [5 9 0 8 2 3 4 6 1 7]
 [2 3 7 9 5 6 0 1 8 4]
 [0 6 2 4 1 5 8 7 9 3]
 [5 0 2 6 7 3 9 1 4 8]
 [0 7 6 8 2 3 9 4 5 1]
 [8 1 4 3 5 9 0 2 6 7]
 [3 9 2 1 4 6 0 8 5 7]
 [2 3 1 0 9 4 7 5 6 8]]
Epoch 72510: Training cost= 2.3026, Training acc= 0.7458, Validation cost= 2.3026, Validation acc= 0.7454
Epoch 72520: Training cost= 2.3026, Training acc= 0.7457, Validation cost= 2.3026, Validation acc= 0.7453
Epoch 72530: Training cost= 2.3026, Training acc= 0.7457, Validation cost= 2.3026, Validation acc= 0.7452
Epoch 72540: Training cost= 2.3026, Training acc= 0.7456, Validation cost= 2.3026, Validation acc= 0.7451
Epoch 72550: Training cost= 2.3026, Training acc= 0.7455, Validation cost= 2.3026, Validation acc= 0.7450
Epoch 72560: Training cost= 2.3026, Training acc= 0.7454, Validation cost= 2.3026, Validation acc= 0.7450
Epoch 72570: Training cost= 2.3026, Training acc= 0.7453, Validation cost= 2.3026, Validation acc= 0.7449
Epoch 72580: Training cost= 2.3026, Training acc= 0.7452, Validation cost= 2.3026, Validation acc= 0.7448
Epoch 72590: Training cost= 2.3026, Training acc= 0.7451, Validation cost= 2.3026, Validation acc= 0.7447
Epoch 72600: Training cost= 2.3026, Training acc= 0.7450, Validation cost= 2.3026, Validation acc= 0.7446
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 9 8 2 6 1 0 4 5 3]
 [1 7 3 6 2 9 0 5 8 4]
 [4 1 9 3 7 5 8 0 6 2]
 [3 6 8 1 4 2 9 7 5 0]
 [9 4 0 1 8 6 7 3 5 2]
 [4 1 0 7 9 5 3 6 8 2]
 [9 5 6 4 7 0 1 2 3 8]
 [0 7 4 6 3 8 5 9 1 2]
 [1 9 3 4 2 0 6 7 8 5]
 [9 8 2 7 6 3 4 5 0 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 7 5 3 1 9 4 6 0 2]
 [4 9 8 1 6 5 2 0 7 3]
 [5 3 4 0 7 8 1 6 2 9]
 [4 7 3 8 1 9 0 6 5 2]
 [4 8 1 3 6 2 7 9 5 0]
 [7 8 2 9 4 0 3 1 5 6]
 [4 8 1 0 3 7 5 6 2 9]
 [8 6 4 2 3 1 0 5 9 7]
 [9 0 8 6 2 3 5 7 4 1]
 [7 2 4 9 5 6 8 3 1 0]]
Epoch 72610: Training cost= 2.3026, Training acc= 0.7449, Validation cost= 2.3026, Validation acc= 0.7445
Epoch 72620: Training cost= 2.3026, Training acc= 0.7449, Validation cost= 2.3026, Validation acc= 0.7444
Epoch 72630: Training cost= 2.3026, Training acc= 0.7448, Validation cost= 2.3026, Validation acc= 0.7443
Epoch 72640: Training cost= 2.3026, Training acc= 0.7447, Validation cost= 2.3026, Validation acc= 0.7442
Epoch 72650: Training cost= 2.3026, Training acc= 0.7446, Validation cost= 2.3026, Validation acc= 0.7442
Epoch 72660: Training cost= 2.3026, Training acc= 0.7445, Validation cost= 2.3026, Validation acc= 0.7441
Epoch 72670: Training cost= 2.3026, Training acc= 0.7444, Validation cost= 2.3026, Validation acc= 0.7440
Epoch 72680: Training cost= 2.3026, Training acc= 0.7443, Validation cost= 2.3026, Validation acc= 0.7439
Epoch 72690: Training cost= 2.3026, Training acc= 0.7442, Validation cost= 2.3026, Validation acc= 0.7438
Epoch 72700: Training cost= 2.3026, Training acc= 0.7441, Validation cost= 2.3026, Validation acc= 0.7437
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 6 5 2 8 9 4 0 1 7]
 [4 6 7 8 2 3 0 9 5 1]
 [0 4 6 1 5 3 7 8 9 2]
 [9 8 6 5 3 2 4 7 0 1]
 [1 9 3 8 6 0 4 2 7 5]
 [4 9 7 8 2 1 0 5 6 3]
 [3 7 4 9 1 0 6 5 2 8]
 [8 4 3 6 9 2 1 0 5 7]
 [2 1 5 3 9 6 0 8 4 7]
 [8 0 3 5 2 6 9 1 7 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 3 2 1 9 6 5 0 8 4]
 [6 9 3 0 1 2 5 7 8 4]
 [9 0 1 2 3 6 5 4 8 7]
 [8 5 1 4 6 7 9 3 2 0]
 [8 6 2 1 9 5 3 7 0 4]
 [1 8 4 6 7 2 9 3 5 0]
 [5 1 8 0 2 6 9 7 4 3]
 [9 0 1 8 2 7 4 3 5 6]
 [5 4 0 1 9 3 6 7 8 2]
 [7 8 3 2 1 9 6 4 0 5]]
Epoch 72710: Training cost= 2.3026, Training acc= 0.7441, Validation cost= 2.3026, Validation acc= 0.7436
Epoch 72720: Training cost= 2.3026, Training acc= 0.7440, Validation cost= 2.3026, Validation acc= 0.7435
Epoch 72730: Training cost= 2.3026, Training acc= 0.7439, Validation cost= 2.3026, Validation acc= 0.7434
Epoch 72740: Training cost= 2.3026, Training acc= 0.7438, Validation cost= 2.3026, Validation acc= 0.7434
Epoch 72750: Training cost= 2.3026, Training acc= 0.7437, Validation cost= 2.3026, Validation acc= 0.7433
Epoch 72760: Training cost= 2.3026, Training acc= 0.7436, Validation cost= 2.3026, Validation acc= 0.7432
Epoch 72770: Training cost= 2.3026, Training acc= 0.7435, Validation cost= 2.3026, Validation acc= 0.7431
Epoch 72780: Training cost= 2.3026, Training acc= 0.7434, Validation cost= 2.3026, Validation acc= 0.7430
Epoch 72790: Training cost= 2.3026, Training acc= 0.7434, Validation cost= 2.3026, Validation acc= 0.7429
Epoch 72800: Training cost= 2.3026, Training acc= 0.7433, Validation cost= 2.3026, Validation acc= 0.7428
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 8 0 3 9 1 6 2 4 7]
 [4 7 8 3 1 5 9 6 0 2]
 [5 4 7 3 2 6 1 0 9 8]
 [8 1 9 3 0 6 5 7 2 4]
 [8 7 4 6 5 0 3 1 2 9]
 [6 3 4 2 0 1 7 5 9 8]
 [0 8 7 3 5 6 9 1 4 2]
 [3 2 0 6 7 4 8 9 1 5]
 [4 9 5 2 0 3 7 6 1 8]
 [9 6 1 3 4 7 5 2 8 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 2 9 6 7 3 8 1 5 0]
 [0 9 2 8 5 7 3 1 6 4]
 [1 3 4 5 9 0 7 8 6 2]
 [2 7 5 6 0 4 9 3 8 1]
 [4 9 7 6 2 3 0 8 1 5]
 [8 6 1 0 5 4 2 7 9 3]
 [9 7 1 5 8 2 6 0 4 3]
 [8 3 5 2 4 0 7 9 1 6]
 [3 7 4 9 8 1 0 6 5 2]
 [6 8 4 3 5 1 7 9 0 2]]
Epoch 72810: Training cost= 2.3026, Training acc= 0.7432, Validation cost= 2.3026, Validation acc= 0.7427
Epoch 72820: Training cost= 2.3026, Training acc= 0.7431, Validation cost= 2.3026, Validation acc= 0.7426
Epoch 72830: Training cost= 2.3026, Training acc= 0.7430, Validation cost= 2.3026, Validation acc= 0.7426
Epoch 72840: Training cost= 2.3026, Training acc= 0.7429, Validation cost= 2.3026, Validation acc= 0.7425
Epoch 72850: Training cost= 2.3026, Training acc= 0.7428, Validation cost= 2.3026, Validation acc= 0.7424
Epoch 72860: Training cost= 2.3026, Training acc= 0.7427, Validation cost= 2.3026, Validation acc= 0.7423
Epoch 72870: Training cost= 2.3026, Training acc= 0.7426, Validation cost= 2.3026, Validation acc= 0.7422
Epoch 72880: Training cost= 2.3026, Training acc= 0.7426, Validation cost= 2.3026, Validation acc= 0.7421
Epoch 72890: Training cost= 2.3026, Training acc= 0.7425, Validation cost= 2.3026, Validation acc= 0.7420
Epoch 72900: Training cost= 2.3026, Training acc= 0.7424, Validation cost= 2.3026, Validation acc= 0.7419
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 9 6 7 5 3 8 2 0 4]
 [2 9 8 4 0 7 1 3 6 5]
 [6 2 3 7 4 5 9 8 0 1]
 [2 8 7 9 5 0 6 4 1 3]
 [8 1 2 9 7 0 3 6 5 4]
 [8 5 9 0 1 6 4 3 2 7]
 [2 3 1 5 0 9 6 7 8 4]
 [4 6 8 0 1 3 7 5 9 2]
 [2 3 4 8 1 0 6 5 7 9]
 [9 3 8 6 4 7 0 1 5 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 3 4 9 7 5 6 8 0 2]
 [9 5 8 2 7 1 4 6 0 3]
 [1 6 9 0 8 3 2 5 4 7]
 [7 5 2 3 9 0 1 4 6 8]
 [1 6 5 9 0 4 8 2 7 3]
 [7 2 3 9 8 5 1 4 0 6]
 [1 0 8 7 2 3 9 6 4 5]
 [8 4 0 9 2 7 1 3 6 5]
 [8 6 1 4 2 0 7 3 9 5]
 [2 0 4 1 6 7 5 3 9 8]]
Epoch 72910: Training cost= 2.3026, Training acc= 0.7423, Validation cost= 2.3026, Validation acc= 0.7419
Epoch 72920: Training cost= 2.3026, Training acc= 0.7422, Validation cost= 2.3026, Validation acc= 0.7418
Epoch 72930: Training cost= 2.3026, Training acc= 0.7421, Validation cost= 2.3026, Validation acc= 0.7417
Epoch 72940: Training cost= 2.3026, Training acc= 0.7420, Validation cost= 2.3026, Validation acc= 0.7416
Epoch 72950: Training cost= 2.3026, Training acc= 0.7419, Validation cost= 2.3026, Validation acc= 0.7415
Epoch 72960: Training cost= 2.3026, Training acc= 0.7419, Validation cost= 2.3026, Validation acc= 0.7414
Epoch 72970: Training cost= 2.3026, Training acc= 0.7418, Validation cost= 2.3026, Validation acc= 0.7413
Epoch 72980: Training cost= 2.3026, Training acc= 0.7417, Validation cost= 2.3026, Validation acc= 0.7412
Epoch 72990: Training cost= 2.3026, Training acc= 0.7416, Validation cost= 2.3026, Validation acc= 0.7412
Epoch 73000: Training cost= 2.3026, Training acc= 0.7415, Validation cost= 2.3026, Validation acc= 0.7411
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 0 9 1 3 7 8 6 4 5]
 [1 7 9 5 3 6 0 8 4 2]
 [3 8 6 7 9 4 1 5 0 2]
 [4 3 9 8 1 2 6 0 7 5]
 [8 6 3 1 2 9 4 7 0 5]
 [5 9 8 6 1 7 3 2 0 4]
 [4 3 1 5 0 6 2 7 9 8]
 [5 8 1 3 4 7 6 9 2 0]
 [3 1 6 2 9 4 8 7 0 5]
 [9 5 8 2 0 4 1 6 3 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 9 5 1 3 4 7 2 6 0]
 [5 2 3 1 4 8 6 9 7 0]
 [6 9 1 0 7 3 5 4 8 2]
 [9 4 7 3 6 1 8 2 5 0]
 [6 3 1 5 0 8 7 2 9 4]
 [1 0 5 6 3 2 4 7 8 9]
 [9 8 4 1 5 7 2 3 6 0]
 [9 6 2 5 1 8 4 3 0 7]
 [0 4 8 9 5 3 2 1 6 7]
 [1 0 8 5 4 9 2 7 3 6]]
Epoch 73010: Training cost= 2.3026, Training acc= 0.7414, Validation cost= 2.3026, Validation acc= 0.7410
Epoch 73020: Training cost= 2.3026, Training acc= 0.7413, Validation cost= 2.3026, Validation acc= 0.7409
Epoch 73030: Training cost= 2.3026, Training acc= 0.7412, Validation cost= 2.3026, Validation acc= 0.7408
Epoch 73040: Training cost= 2.3026, Training acc= 0.7411, Validation cost= 2.3026, Validation acc= 0.7407
Epoch 73050: Training cost= 2.3026, Training acc= 0.7411, Validation cost= 2.3026, Validation acc= 0.7406
Epoch 73060: Training cost= 2.3026, Training acc= 0.7410, Validation cost= 2.3026, Validation acc= 0.7405
Epoch 73070: Training cost= 2.3026, Training acc= 0.7409, Validation cost= 2.3026, Validation acc= 0.7404
Epoch 73080: Training cost= 2.3026, Training acc= 0.7408, Validation cost= 2.3026, Validation acc= 0.7404
Epoch 73090: Training cost= 2.3026, Training acc= 0.7407, Validation cost= 2.3026, Validation acc= 0.7403
Epoch 73100: Training cost= 2.3026, Training acc= 0.7406, Validation cost= 2.3026, Validation acc= 0.7402
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 0 1 2 7 8 4 3 5 9]
 [3 8 6 1 2 7 9 4 5 0]
 [6 5 3 1 0 9 7 8 4 2]
 [2 9 5 3 4 6 7 1 8 0]
 [8 7 9 5 6 4 2 1 3 0]
 [2 7 6 9 4 3 8 1 0 5]
 [7 3 8 0 6 4 1 5 9 2]
 [4 0 5 3 1 7 9 2 6 8]
 [7 2 0 1 6 9 3 5 4 8]
 [8 3 7 6 1 4 5 0 9 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 7 5 6 4 0 9 2 1 8]
 [3 1 9 0 5 8 4 2 6 7]
 [7 1 5 6 3 4 0 8 9 2]
 [2 6 5 8 4 3 0 9 7 1]
 [3 7 4 1 5 0 2 8 9 6]
 [0 4 6 1 7 3 5 9 8 2]
 [9 7 5 3 1 6 0 4 2 8]
 [4 7 3 2 6 5 1 9 0 8]
 [7 0 4 8 6 9 1 5 3 2]
 [8 7 4 1 2 9 5 6 3 0]]
Epoch 73110: Training cost= 2.3026, Training acc= 0.7405, Validation cost= 2.3026, Validation acc= 0.7401
Epoch 73120: Training cost= 2.3026, Training acc= 0.7404, Validation cost= 2.3026, Validation acc= 0.7400
Epoch 73130: Training cost= 2.3026, Training acc= 0.7404, Validation cost= 2.3026, Validation acc= 0.7399
Epoch 73140: Training cost= 2.3026, Training acc= 0.7403, Validation cost= 2.3026, Validation acc= 0.7398
Epoch 73150: Training cost= 2.3026, Training acc= 0.7402, Validation cost= 2.3026, Validation acc= 0.7397
Epoch 73160: Training cost= 2.3026, Training acc= 0.7401, Validation cost= 2.3026, Validation acc= 0.7397
Epoch 73170: Training cost= 2.3026, Training acc= 0.7400, Validation cost= 2.3026, Validation acc= 0.7396
Epoch 73180: Training cost= 2.3026, Training acc= 0.7399, Validation cost= 2.3026, Validation acc= 0.7395
Epoch 73190: Training cost= 2.3026, Training acc= 0.7398, Validation cost= 2.3026, Validation acc= 0.7394
Epoch 73200: Training cost= 2.3026, Training acc= 0.7397, Validation cost= 2.3026, Validation acc= 0.7393
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 6 2 5 8 4 3 0 9 7]
 [1 8 6 9 4 5 2 7 3 0]
 [0 9 2 1 7 5 4 3 8 6]
 [2 4 8 7 0 9 5 6 3 1]
 [3 7 5 9 2 0 4 1 6 8]
 [5 9 6 1 2 0 7 3 4 8]
 [9 1 3 8 5 7 2 0 6 4]
 [6 8 1 5 7 9 4 0 3 2]
 [8 2 4 3 1 7 9 5 0 6]
 [1 2 0 3 5 9 4 6 8 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 0 8 7 1 5 9 6 2 4]
 [9 5 0 2 1 3 4 8 7 6]
 [6 9 5 1 8 3 2 0 4 7]
 [7 5 1 4 6 8 2 3 0 9]
 [7 0 8 9 2 5 3 4 6 1]
 [8 1 2 9 6 3 7 5 0 4]
 [9 4 8 3 1 7 5 0 6 2]
 [9 4 1 6 8 0 7 5 3 2]
 [9 8 4 0 3 6 1 7 2 5]
 [6 3 8 9 5 2 0 7 4 1]]
Epoch 73210: Training cost= 2.3026, Training acc= 0.7397, Validation cost= 2.3026, Validation acc= 0.7392
Epoch 73220: Training cost= 2.3026, Training acc= 0.7396, Validation cost= 2.3026, Validation acc= 0.7391
Epoch 73230: Training cost= 2.3026, Training acc= 0.7395, Validation cost= 2.3026, Validation acc= 0.7391
Epoch 73240: Training cost= 2.3026, Training acc= 0.7394, Validation cost= 2.3026, Validation acc= 0.7390
Epoch 73250: Training cost= 2.3026, Training acc= 0.7393, Validation cost= 2.3026, Validation acc= 0.7389
Epoch 73260: Training cost= 2.3026, Training acc= 0.7392, Validation cost= 2.3026, Validation acc= 0.7388
Epoch 73270: Training cost= 2.3026, Training acc= 0.7391, Validation cost= 2.3026, Validation acc= 0.7387
Epoch 73280: Training cost= 2.3026, Training acc= 0.7390, Validation cost= 2.3026, Validation acc= 0.7386
Epoch 73290: Training cost= 2.3026, Training acc= 0.7390, Validation cost= 2.3026, Validation acc= 0.7385
Epoch 73300: Training cost= 2.3026, Training acc= 0.7389, Validation cost= 2.3026, Validation acc= 0.7384
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 6 9 7 8 5 2 0 4 3]
 [0 6 7 9 2 5 4 1 3 8]
 [8 9 3 0 6 1 2 5 7 4]
 [5 9 0 2 8 6 3 1 7 4]
 [8 4 3 6 2 5 0 7 9 1]
 [0 7 8 6 2 4 9 3 1 5]
 [4 3 7 8 9 0 5 2 6 1]
 [9 1 6 3 2 7 4 0 8 5]
 [0 2 7 4 1 3 9 6 8 5]
 [7 3 2 9 1 6 4 5 0 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 5 8 4 0 9 3 7 6 1]
 [3 9 2 6 8 4 0 7 5 1]
 [1 3 2 8 5 4 9 6 7 0]
 [4 2 3 6 7 9 5 1 8 0]
 [5 3 8 6 7 1 4 9 2 0]
 [6 9 7 8 1 5 3 0 4 2]
 [7 6 0 5 1 8 3 2 9 4]
 [6 2 1 3 7 9 5 8 0 4]
 [2 1 0 4 9 6 3 5 8 7]
 [1 2 6 4 0 7 5 9 3 8]]
Epoch 73310: Training cost= 2.3026, Training acc= 0.7388, Validation cost= 2.3026, Validation acc= 0.7384
Epoch 73320: Training cost= 2.3026, Training acc= 0.7387, Validation cost= 2.3026, Validation acc= 0.7383
Epoch 73330: Training cost= 2.3026, Training acc= 0.7386, Validation cost= 2.3026, Validation acc= 0.7382
Epoch 73340: Training cost= 2.3026, Training acc= 0.7385, Validation cost= 2.3026, Validation acc= 0.7381
Epoch 73350: Training cost= 2.3026, Training acc= 0.7384, Validation cost= 2.3026, Validation acc= 0.7380
Epoch 73360: Training cost= 2.3026, Training acc= 0.7384, Validation cost= 2.3026, Validation acc= 0.7379
Epoch 73370: Training cost= 2.3026, Training acc= 0.7383, Validation cost= 2.3026, Validation acc= 0.7378
Epoch 73380: Training cost= 2.3026, Training acc= 0.7382, Validation cost= 2.3026, Validation acc= 0.7377
Epoch 73390: Training cost= 2.3026, Training acc= 0.7381, Validation cost= 2.3026, Validation acc= 0.7377
Epoch 73400: Training cost= 2.3026, Training acc= 0.7380, Validation cost= 2.3026, Validation acc= 0.7376
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 2 6 3 7 9 8 4 5 0]
 [0 7 3 8 2 6 1 5 4 9]
 [9 1 6 5 0 8 2 4 3 7]
 [7 3 1 0 9 5 8 4 2 6]
 [1 8 9 7 6 4 2 3 0 5]
 [5 9 7 8 0 6 4 1 3 2]
 [3 7 0 8 1 2 5 6 4 9]
 [4 5 9 1 6 7 2 0 3 8]
 [0 2 5 1 9 8 6 3 7 4]
 [6 5 8 2 0 4 3 9 7 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 7 0 3 6 1 8 4 2 9]
 [5 3 8 2 9 6 0 7 4 1]
 [8 7 0 3 2 9 5 6 1 4]
 [3 5 1 4 9 8 6 0 2 7]
 [2 3 9 5 0 7 4 1 6 8]
 [4 8 7 1 2 9 0 6 3 5]
 [7 6 2 9 8 3 1 5 4 0]
 [0 6 5 2 9 3 7 8 4 1]
 [3 0 5 8 4 6 7 9 1 2]
 [7 5 9 4 3 6 0 1 8 2]]
Epoch 73410: Training cost= 2.3026, Training acc= 0.7379, Validation cost= 2.3026, Validation acc= 0.7375
Epoch 73420: Training cost= 2.3026, Training acc= 0.7378, Validation cost= 2.3026, Validation acc= 0.7374
Epoch 73430: Training cost= 2.3026, Training acc= 0.7377, Validation cost= 2.3026, Validation acc= 0.7373
Epoch 73440: Training cost= 2.3026, Training acc= 0.7377, Validation cost= 2.3026, Validation acc= 0.7372
Epoch 73450: Training cost= 2.3026, Training acc= 0.7376, Validation cost= 2.3026, Validation acc= 0.7371
Epoch 73460: Training cost= 2.3026, Training acc= 0.7375, Validation cost= 2.3026, Validation acc= 0.7370
Epoch 73470: Training cost= 2.3026, Training acc= 0.7374, Validation cost= 2.3026, Validation acc= 0.7370
Epoch 73480: Training cost= 2.3026, Training acc= 0.7373, Validation cost= 2.3026, Validation acc= 0.7369
Epoch 73490: Training cost= 2.3026, Training acc= 0.7372, Validation cost= 2.3026, Validation acc= 0.7368
Epoch 73500: Training cost= 2.3026, Training acc= 0.7371, Validation cost= 2.3026, Validation acc= 0.7367
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 3 9 4 2 0 6 1 5 7]
 [7 6 4 0 3 8 9 1 5 2]
 [7 4 8 3 2 6 1 0 5 9]
 [2 7 0 4 1 9 5 6 3 8]
 [2 7 5 8 4 1 6 3 0 9]
 [9 2 5 4 7 0 1 6 3 8]
 [0 3 7 8 6 2 5 1 9 4]
 [9 8 1 5 3 0 6 4 7 2]
 [6 1 2 0 3 7 8 5 9 4]
 [1 3 7 8 0 5 4 9 6 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 1 9 4 0 8 5 6 7]
 [8 5 7 3 9 6 1 0 4 2]
 [3 4 5 0 9 6 1 8 7 2]
 [3 8 4 6 9 5 0 2 7 1]
 [5 4 1 3 8 0 2 7 6 9]
 [5 0 6 1 2 3 8 7 9 4]
 [7 0 3 1 2 9 8 4 5 6]
 [5 7 8 0 3 4 1 2 9 6]
 [8 0 2 4 1 5 6 9 3 7]
 [5 1 8 9 6 0 2 7 3 4]]
Epoch 73510: Training cost= 2.3026, Training acc= 0.7370, Validation cost= 2.3026, Validation acc= 0.7366
Epoch 73520: Training cost= 2.3026, Training acc= 0.7370, Validation cost= 2.3026, Validation acc= 0.7365
Epoch 73530: Training cost= 2.3026, Training acc= 0.7369, Validation cost= 2.3026, Validation acc= 0.7364
Epoch 73540: Training cost= 2.3026, Training acc= 0.7368, Validation cost= 2.3026, Validation acc= 0.7364
Epoch 73550: Training cost= 2.3026, Training acc= 0.7367, Validation cost= 2.3026, Validation acc= 0.7363
Epoch 73560: Training cost= 2.3026, Training acc= 0.7366, Validation cost= 2.3026, Validation acc= 0.7362
Epoch 73570: Training cost= 2.3026, Training acc= 0.7365, Validation cost= 2.3026, Validation acc= 0.7361
Epoch 73580: Training cost= 2.3026, Training acc= 0.7364, Validation cost= 2.3026, Validation acc= 0.7360
Epoch 73590: Training cost= 2.3026, Training acc= 0.7364, Validation cost= 2.3026, Validation acc= 0.7359
Epoch 73600: Training cost= 2.3026, Training acc= 0.7363, Validation cost= 2.3026, Validation acc= 0.7358
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 1 8 4 3 0 6 5 7 9]
 [2 6 0 1 7 4 3 8 5 9]
 [4 2 3 9 6 8 0 1 5 7]
 [0 3 4 8 7 2 6 9 5 1]
 [8 2 1 9 0 6 4 7 5 3]
 [7 3 5 0 6 1 8 4 9 2]
 [3 0 1 5 6 8 2 9 4 7]
 [6 8 4 0 5 2 7 9 1 3]
 [3 6 7 9 5 2 4 1 8 0]
 [9 0 1 8 2 7 3 4 6 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 1 7 4 8 2 5 0 3 6]
 [8 3 6 1 7 2 4 9 0 5]
 [4 6 0 7 9 8 2 3 1 5]
 [4 1 3 0 8 7 9 2 6 5]
 [7 0 5 1 2 8 9 4 3 6]
 [8 9 3 6 4 2 1 0 7 5]
 [2 9 6 3 5 1 8 7 4 0]
 [6 2 4 9 5 3 0 7 8 1]
 [9 7 0 4 8 2 3 6 1 5]
 [9 3 6 2 0 5 8 4 7 1]]
Epoch 73610: Training cost= 2.3026, Training acc= 0.7362, Validation cost= 2.3026, Validation acc= 0.7358
Epoch 73620: Training cost= 2.3026, Training acc= 0.7361, Validation cost= 2.3026, Validation acc= 0.7357
Epoch 73630: Training cost= 2.3026, Training acc= 0.7360, Validation cost= 2.3026, Validation acc= 0.7356
Epoch 73640: Training cost= 2.3026, Training acc= 0.7359, Validation cost= 2.3026, Validation acc= 0.7355
Epoch 73650: Training cost= 2.3026, Training acc= 0.7358, Validation cost= 2.3026, Validation acc= 0.7354
Epoch 73660: Training cost= 2.3026, Training acc= 0.7358, Validation cost= 2.3026, Validation acc= 0.7353
Epoch 73670: Training cost= 2.3026, Training acc= 0.7357, Validation cost= 2.3026, Validation acc= 0.7352
Epoch 73680: Training cost= 2.3026, Training acc= 0.7356, Validation cost= 2.3026, Validation acc= 0.7351
Epoch 73690: Training cost= 2.3026, Training acc= 0.7355, Validation cost= 2.3026, Validation acc= 0.7351
Epoch 73700: Training cost= 2.3026, Training acc= 0.7354, Validation cost= 2.3026, Validation acc= 0.7350
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 3 2 4 6 8 0 9 7 5]
 [6 4 0 1 9 3 5 8 2 7]
 [6 4 8 1 7 3 9 0 5 2]
 [0 3 4 7 9 6 8 5 1 2]
 [6 8 4 2 1 3 9 5 0 7]
 [1 4 2 7 5 9 8 0 6 3]
 [1 2 7 9 8 6 5 3 4 0]
 [5 6 2 7 1 0 3 9 8 4]
 [7 2 1 9 5 8 0 6 3 4]
 [1 8 0 7 9 3 4 2 6 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 8 1 5 0 2 3 6 4 9]
 [8 1 5 7 4 0 9 2 3 6]
 [6 1 2 5 7 4 8 0 9 3]
 [0 3 7 1 2 9 5 4 6 8]
 [4 1 9 8 0 7 5 3 6 2]
 [2 1 3 4 5 6 8 0 7 9]
 [6 2 4 5 1 0 8 7 9 3]
 [3 5 1 9 0 7 2 8 6 4]
 [0 7 4 8 5 3 1 2 9 6]
 [9 5 4 0 2 7 3 8 1 6]]
Epoch 73710: Training cost= 2.3026, Training acc= 0.7353, Validation cost= 2.3026, Validation acc= 0.7349
Epoch 73720: Training cost= 2.3026, Training acc= 0.7352, Validation cost= 2.3026, Validation acc= 0.7348
Epoch 73730: Training cost= 2.3026, Training acc= 0.7351, Validation cost= 2.3026, Validation acc= 0.7347
Epoch 73740: Training cost= 2.3026, Training acc= 0.7351, Validation cost= 2.3026, Validation acc= 0.7346
Epoch 73750: Training cost= 2.3026, Training acc= 0.7350, Validation cost= 2.3026, Validation acc= 0.7345
Epoch 73760: Training cost= 2.3026, Training acc= 0.7349, Validation cost= 2.3026, Validation acc= 0.7345
Epoch 73770: Training cost= 2.3026, Training acc= 0.7348, Validation cost= 2.3026, Validation acc= 0.7344
Epoch 73780: Training cost= 2.3026, Training acc= 0.7347, Validation cost= 2.3026, Validation acc= 0.7343
Epoch 73790: Training cost= 2.3026, Training acc= 0.7346, Validation cost= 2.3026, Validation acc= 0.7342
Epoch 73800: Training cost= 2.3026, Training acc= 0.7345, Validation cost= 2.3026, Validation acc= 0.7341
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 9 0 8 7 5 6 4 3 1]
 [2 1 5 4 9 3 8 0 7 6]
 [3 8 4 2 1 9 0 6 7 5]
 [5 6 0 9 3 4 8 1 2 7]
 [4 6 7 1 0 9 3 5 8 2]
 [0 7 9 6 8 2 4 3 5 1]
 [2 9 0 8 3 5 4 6 7 1]
 [3 7 0 4 6 5 2 8 9 1]
 [0 8 3 7 4 5 1 9 6 2]
 [9 8 3 0 5 6 1 2 4 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 6 8 2 1 9 5 0 4 7]
 [9 3 0 5 6 2 8 7 1 4]
 [9 7 0 8 3 2 4 1 5 6]
 [6 8 2 4 0 3 7 5 9 1]
 [8 6 9 1 5 3 4 2 0 7]
 [2 5 8 7 6 3 1 4 9 0]
 [3 7 9 4 1 6 0 2 5 8]
 [6 4 5 9 2 0 3 1 7 8]
 [4 3 8 2 7 0 5 6 1 9]
 [7 0 3 5 6 4 1 9 2 8]]
Epoch 73810: Training cost= 2.3026, Training acc= 0.7345, Validation cost= 2.3026, Validation acc= 0.7340
Epoch 73820: Training cost= 2.3026, Training acc= 0.7344, Validation cost= 2.3026, Validation acc= 0.7339
Epoch 73830: Training cost= 2.3026, Training acc= 0.7343, Validation cost= 2.3026, Validation acc= 0.7339
Epoch 73840: Training cost= 2.3026, Training acc= 0.7342, Validation cost= 2.3026, Validation acc= 0.7338
Epoch 73850: Training cost= 2.3026, Training acc= 0.7341, Validation cost= 2.3026, Validation acc= 0.7337
Epoch 73860: Training cost= 2.3026, Training acc= 0.7340, Validation cost= 2.3026, Validation acc= 0.7336
Epoch 73870: Training cost= 2.3026, Training acc= 0.7339, Validation cost= 2.3026, Validation acc= 0.7335
Epoch 73880: Training cost= 2.3026, Training acc= 0.7339, Validation cost= 2.3026, Validation acc= 0.7334
Epoch 73890: Training cost= 2.3026, Training acc= 0.7338, Validation cost= 2.3026, Validation acc= 0.7333
Epoch 73900: Training cost= 2.3026, Training acc= 0.7337, Validation cost= 2.3026, Validation acc= 0.7333
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 6 4 3 5 8 0 1 9 7]
 [4 2 0 8 1 7 5 9 6 3]
 [2 1 7 0 9 5 8 6 3 4]
 [1 8 2 4 3 5 7 9 6 0]
 [9 6 0 5 8 1 3 2 4 7]
 [2 9 8 5 4 0 7 6 3 1]
 [7 8 9 4 0 1 2 3 6 5]
 [5 7 3 0 2 4 6 1 8 9]
 [0 7 3 2 1 6 5 8 9 4]
 [5 1 2 6 4 7 9 0 3 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 2 0 8 9 1 7 6 4]
 [2 6 8 7 5 0 4 3 9 1]
 [6 4 2 3 0 9 1 8 5 7]
 [9 5 8 1 0 7 6 4 2 3]
 [3 0 9 5 6 4 8 2 1 7]
 [1 0 6 8 2 7 5 9 3 4]
 [1 5 4 9 3 6 7 0 8 2]
 [0 4 6 5 3 2 7 1 8 9]
 [1 9 5 4 6 2 0 8 3 7]
 [3 9 8 2 0 7 4 1 6 5]]
Epoch 73910: Training cost= 2.3026, Training acc= 0.7336, Validation cost= 2.3026, Validation acc= 0.7332
Epoch 73920: Training cost= 2.3026, Training acc= 0.7335, Validation cost= 2.3026, Validation acc= 0.7331
Epoch 73930: Training cost= 2.3026, Training acc= 0.7334, Validation cost= 2.3026, Validation acc= 0.7330
Epoch 73940: Training cost= 2.3026, Training acc= 0.7333, Validation cost= 2.3026, Validation acc= 0.7329
Epoch 73950: Training cost= 2.3026, Training acc= 0.7333, Validation cost= 2.3026, Validation acc= 0.7328
Epoch 73960: Training cost= 2.3026, Training acc= 0.7332, Validation cost= 2.3026, Validation acc= 0.7327
Epoch 73970: Training cost= 2.3026, Training acc= 0.7331, Validation cost= 2.3026, Validation acc= 0.7327
Epoch 73980: Training cost= 2.3026, Training acc= 0.7330, Validation cost= 2.3026, Validation acc= 0.7326
Epoch 73990: Training cost= 2.3026, Training acc= 0.7329, Validation cost= 2.3026, Validation acc= 0.7325
Epoch 74000: Training cost= 2.3026, Training acc= 0.7328, Validation cost= 2.3026, Validation acc= 0.7324
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 0 3 4 8 1 7 9 2 5]
 [7 0 4 6 5 3 2 8 1 9]
 [6 1 4 7 9 3 8 2 5 0]
 [7 2 0 5 8 4 6 1 9 3]
 [3 7 6 0 4 1 5 8 2 9]
 [1 3 0 2 6 5 8 4 7 9]
 [8 7 1 2 5 4 9 3 6 0]
 [5 9 8 4 3 0 2 6 1 7]
 [6 2 7 9 8 5 4 3 1 0]
 [8 4 0 7 9 6 1 2 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 4 7 2 1 5 3 8 9 6]
 [6 1 4 5 3 7 2 8 0 9]
 [2 7 4 9 3 5 1 0 8 6]
 [9 5 7 6 1 8 3 4 0 2]
 [8 1 5 6 3 2 9 4 0 7]
 [6 5 1 0 2 3 4 7 9 8]
 [5 1 2 9 3 8 7 4 6 0]
 [9 3 2 0 7 5 8 6 1 4]
 [6 1 7 3 5 4 2 0 9 8]
 [4 5 7 1 6 8 0 9 3 2]]
Epoch 74010: Training cost= 2.3026, Training acc= 0.7327, Validation cost= 2.3026, Validation acc= 0.7323
Epoch 74020: Training cost= 2.3026, Training acc= 0.7327, Validation cost= 2.3026, Validation acc= 0.7322
Epoch 74030: Training cost= 2.3026, Training acc= 0.7326, Validation cost= 2.3026, Validation acc= 0.7321
Epoch 74040: Training cost= 2.3026, Training acc= 0.7325, Validation cost= 2.3026, Validation acc= 0.7321
Epoch 74050: Training cost= 2.3026, Training acc= 0.7324, Validation cost= 2.3026, Validation acc= 0.7320
Epoch 74060: Training cost= 2.3026, Training acc= 0.7323, Validation cost= 2.3026, Validation acc= 0.7319
Epoch 74070: Training cost= 2.3026, Training acc= 0.7322, Validation cost= 2.3026, Validation acc= 0.7318
Epoch 74080: Training cost= 2.3026, Training acc= 0.7321, Validation cost= 2.3026, Validation acc= 0.7317
Epoch 74090: Training cost= 2.3026, Training acc= 0.7321, Validation cost= 2.3026, Validation acc= 0.7316
Epoch 74100: Training cost= 2.3026, Training acc= 0.7320, Validation cost= 2.3026, Validation acc= 0.7315
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 2 3 6 1 4 0 9 5 8]
 [0 5 2 9 7 3 8 4 6 1]
 [2 0 6 1 3 9 5 7 8 4]
 [0 7 8 6 2 9 5 1 3 4]
 [1 0 9 8 7 4 5 6 3 2]
 [8 2 3 7 1 4 6 5 9 0]
 [1 9 3 4 6 0 2 5 7 8]
 [7 4 9 0 1 2 3 6 5 8]
 [1 8 5 3 7 6 9 0 4 2]
 [9 2 5 6 1 8 0 7 4 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 7 6 4 9 5 0 8 3 1]
 [8 2 7 0 6 4 5 1 3 9]
 [9 6 0 3 8 2 1 4 5 7]
 [1 3 5 9 4 6 2 8 0 7]
 [9 6 3 5 7 2 8 4 1 0]
 [3 9 2 1 8 0 5 6 7 4]
 [8 1 6 2 0 7 3 5 9 4]
 [9 5 8 0 3 7 2 4 1 6]
 [1 2 6 8 3 0 5 7 9 4]
 [5 6 2 7 8 4 9 0 3 1]]
Epoch 74110: Training cost= 2.3026, Training acc= 0.7319, Validation cost= 2.3026, Validation acc= 0.7315
Epoch 74120: Training cost= 2.3026, Training acc= 0.7318, Validation cost= 2.3026, Validation acc= 0.7314
Epoch 74130: Training cost= 2.3026, Training acc= 0.7317, Validation cost= 2.3026, Validation acc= 0.7313
Epoch 74140: Training cost= 2.3026, Training acc= 0.7316, Validation cost= 2.3026, Validation acc= 0.7312
Epoch 74150: Training cost= 2.3026, Training acc= 0.7316, Validation cost= 2.3026, Validation acc= 0.7311
Epoch 74160: Training cost= 2.3026, Training acc= 0.7315, Validation cost= 2.3026, Validation acc= 0.7310
Epoch 74170: Training cost= 2.3026, Training acc= 0.7314, Validation cost= 2.3026, Validation acc= 0.7310
Epoch 74180: Training cost= 2.3026, Training acc= 0.7313, Validation cost= 2.3026, Validation acc= 0.7309
Epoch 74190: Training cost= 2.3026, Training acc= 0.7312, Validation cost= 2.3026, Validation acc= 0.7308
Epoch 74200: Training cost= 2.3026, Training acc= 0.7311, Validation cost= 2.3026, Validation acc= 0.7307
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 5 6 0 2 9 8 4 7 1]
 [1 4 3 2 7 5 8 0 6 9]
 [2 8 1 4 0 9 7 3 6 5]
 [3 1 5 7 2 0 4 8 6 9]
 [0 3 9 2 6 1 8 7 5 4]
 [2 0 3 7 8 1 4 9 5 6]
 [0 2 3 4 6 8 5 9 1 7]
 [6 0 1 3 8 7 4 9 5 2]
 [0 2 9 3 6 7 4 8 5 1]
 [6 5 1 0 3 8 2 4 9 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 6 3 9 8 5 2 4 0 1]
 [2 3 9 1 8 0 4 7 5 6]
 [5 4 6 7 1 8 3 2 9 0]
 [1 7 8 0 6 4 5 9 3 2]
 [0 9 6 7 4 1 5 3 2 8]
 [6 2 1 3 4 7 8 5 0 9]
 [6 1 8 2 7 5 0 9 4 3]
 [0 9 8 3 5 7 4 2 6 1]
 [4 5 3 9 1 0 7 8 6 2]
 [4 1 6 9 0 5 3 7 2 8]]
Epoch 74210: Training cost= 2.3026, Training acc= 0.7310, Validation cost= 2.3026, Validation acc= 0.7306
Epoch 74220: Training cost= 2.3026, Training acc= 0.7310, Validation cost= 2.3026, Validation acc= 0.7305
Epoch 74230: Training cost= 2.3026, Training acc= 0.7309, Validation cost= 2.3026, Validation acc= 0.7304
Epoch 74240: Training cost= 2.3026, Training acc= 0.7308, Validation cost= 2.3026, Validation acc= 0.7304
Epoch 74250: Training cost= 2.3026, Training acc= 0.7307, Validation cost= 2.3026, Validation acc= 0.7303
Epoch 74260: Training cost= 2.3026, Training acc= 0.7306, Validation cost= 2.3026, Validation acc= 0.7302
Epoch 74270: Training cost= 2.3026, Training acc= 0.7305, Validation cost= 2.3026, Validation acc= 0.7301
Epoch 74280: Training cost= 2.3026, Training acc= 0.7304, Validation cost= 2.3026, Validation acc= 0.7300
Epoch 74290: Training cost= 2.3026, Training acc= 0.7304, Validation cost= 2.3026, Validation acc= 0.7299
Epoch 74300: Training cost= 2.3026, Training acc= 0.7303, Validation cost= 2.3026, Validation acc= 0.7298
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 5 3 4 9 0 1 6 2 8]
 [2 0 8 9 4 5 7 1 3 6]
 [4 1 7 6 2 9 3 0 5 8]
 [6 2 3 8 0 9 5 4 1 7]
 [2 0 9 1 6 7 5 3 4 8]
 [0 5 7 3 8 4 6 9 1 2]
 [6 9 5 2 3 0 7 8 4 1]
 [9 7 5 2 4 3 6 1 0 8]
 [1 2 6 3 4 7 9 0 5 8]
 [8 2 0 6 1 5 9 3 7 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 8 5 1 9 3 7 6 4 0]
 [5 8 2 6 1 9 3 0 7 4]
 [9 2 4 1 8 7 6 3 0 5]
 [9 0 7 6 8 3 5 2 1 4]
 [0 4 5 6 9 7 8 1 3 2]
 [2 6 9 4 0 3 7 1 5 8]
 [4 1 3 5 2 0 6 8 9 7]
 [5 1 3 8 9 0 4 7 6 2]
 [2 5 0 9 7 4 6 8 3 1]
 [5 4 3 9 2 6 8 7 1 0]]
Epoch 74310: Training cost= 2.3026, Training acc= 0.7302, Validation cost= 2.3026, Validation acc= 0.7298
Epoch 74320: Training cost= 2.3026, Training acc= 0.7301, Validation cost= 2.3026, Validation acc= 0.7297
Epoch 74330: Training cost= 2.3026, Training acc= 0.7300, Validation cost= 2.3026, Validation acc= 0.7296
Epoch 74340: Training cost= 2.3026, Training acc= 0.7299, Validation cost= 2.3026, Validation acc= 0.7295
Epoch 74350: Training cost= 2.3026, Training acc= 0.7299, Validation cost= 2.3026, Validation acc= 0.7294
Epoch 74360: Training cost= 2.3026, Training acc= 0.7298, Validation cost= 2.3026, Validation acc= 0.7293
Epoch 74370: Training cost= 2.3026, Training acc= 0.7297, Validation cost= 2.3026, Validation acc= 0.7293
Epoch 74380: Training cost= 2.3026, Training acc= 0.7296, Validation cost= 2.3026, Validation acc= 0.7292
Epoch 74390: Training cost= 2.3026, Training acc= 0.7295, Validation cost= 2.3026, Validation acc= 0.7291
Epoch 74400: Training cost= 2.3026, Training acc= 0.7294, Validation cost= 2.3026, Validation acc= 0.7290
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 3 5 0 4 2 6 9 7 8]
 [8 1 0 9 3 6 7 4 5 2]
 [3 5 6 7 9 8 0 4 1 2]
 [2 7 6 1 4 3 9 8 5 0]
 [6 4 7 8 5 1 9 3 2 0]
 [2 8 6 3 4 1 0 7 9 5]
 [1 9 8 3 7 5 6 2 0 4]
 [1 3 2 4 5 8 0 6 7 9]
 [6 8 4 5 2 0 9 3 7 1]
 [5 9 4 6 2 1 8 0 7 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 4 3 7 9 1 8 6 2 0]
 [5 3 8 7 6 0 1 9 2 4]
 [9 6 0 2 3 4 5 8 1 7]
 [2 8 7 0 1 5 6 4 3 9]
 [2 8 0 6 4 7 5 3 1 9]
 [9 0 2 4 7 8 6 1 5 3]
 [0 6 9 7 8 3 5 4 2 1]
 [0 2 5 6 9 1 8 3 7 4]
 [6 4 9 7 0 1 5 2 8 3]
 [2 9 0 1 8 4 7 3 6 5]]
Epoch 74410: Training cost= 2.3026, Training acc= 0.7293, Validation cost= 2.3026, Validation acc= 0.7289
Epoch 74420: Training cost= 2.3026, Training acc= 0.7293, Validation cost= 2.3026, Validation acc= 0.7288
Epoch 74430: Training cost= 2.3026, Training acc= 0.7292, Validation cost= 2.3026, Validation acc= 0.7287
Epoch 74440: Training cost= 2.3026, Training acc= 0.7291, Validation cost= 2.3026, Validation acc= 0.7287
Epoch 74450: Training cost= 2.3026, Training acc= 0.7290, Validation cost= 2.3026, Validation acc= 0.7286
Epoch 74460: Training cost= 2.3026, Training acc= 0.7289, Validation cost= 2.3026, Validation acc= 0.7285
Epoch 74470: Training cost= 2.3026, Training acc= 0.7288, Validation cost= 2.3026, Validation acc= 0.7284
Epoch 74480: Training cost= 2.3026, Training acc= 0.7288, Validation cost= 2.3026, Validation acc= 0.7283
Epoch 74490: Training cost= 2.3026, Training acc= 0.7287, Validation cost= 2.3026, Validation acc= 0.7282
Epoch 74500: Training cost= 2.3026, Training acc= 0.7286, Validation cost= 2.3026, Validation acc= 0.7282
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 4 7 5 6 0 3 9 8 1]
 [7 8 6 3 2 1 9 4 0 5]
 [0 8 6 1 2 5 7 4 9 3]
 [7 6 2 9 3 4 0 8 5 1]
 [0 3 7 1 6 9 5 4 2 8]
 [1 4 6 8 2 5 9 7 3 0]
 [5 2 9 4 1 3 6 0 8 7]
 [3 8 1 6 7 5 4 9 2 0]
 [6 7 4 0 8 2 3 5 9 1]
 [5 4 6 2 8 9 7 3 1 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 7 1 5 6 2 3 4 9 8]
 [4 8 5 1 2 3 9 0 6 7]
 [3 8 0 6 4 7 5 2 1 9]
 [8 6 1 7 4 0 9 2 3 5]
 [4 6 2 0 9 8 5 7 1 3]
 [4 2 6 7 8 5 9 0 1 3]
 [9 2 1 4 5 0 6 3 7 8]
 [7 1 0 9 3 6 5 2 8 4]
 [0 6 9 1 4 7 2 3 5 8]
 [4 8 5 1 3 2 7 6 9 0]]
Epoch 74510: Training cost= 2.3026, Training acc= 0.7285, Validation cost= 2.3026, Validation acc= 0.7281
Epoch 74520: Training cost= 2.3026, Training acc= 0.7284, Validation cost= 2.3026, Validation acc= 0.7280
Epoch 74530: Training cost= 2.3026, Training acc= 0.7283, Validation cost= 2.3026, Validation acc= 0.7279
Epoch 74540: Training cost= 2.3026, Training acc= 0.7282, Validation cost= 2.3026, Validation acc= 0.7278
Epoch 74550: Training cost= 2.3026, Training acc= 0.7282, Validation cost= 2.3026, Validation acc= 0.7277
Epoch 74560: Training cost= 2.3026, Training acc= 0.7281, Validation cost= 2.3026, Validation acc= 0.7277
Epoch 74570: Training cost= 2.3026, Training acc= 0.7280, Validation cost= 2.3026, Validation acc= 0.7276
Epoch 74580: Training cost= 2.3026, Training acc= 0.7279, Validation cost= 2.3026, Validation acc= 0.7275
Epoch 74590: Training cost= 2.3026, Training acc= 0.7278, Validation cost= 2.3026, Validation acc= 0.7274
Epoch 74600: Training cost= 2.3026, Training acc= 0.7277, Validation cost= 2.3026, Validation acc= 0.7273
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 6 8 3 0 2 4 5 7]
 [1 0 4 7 9 2 5 3 8 6]
 [9 4 1 8 6 0 3 7 5 2]
 [0 1 9 3 2 6 5 4 7 8]
 [0 4 3 8 7 6 9 2 1 5]
 [2 3 1 7 9 0 5 4 8 6]
 [0 2 3 1 6 4 7 9 5 8]
 [4 5 9 1 8 3 0 6 2 7]
 [6 1 5 9 7 4 0 3 2 8]
 [3 2 6 5 4 0 7 9 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 7 0 1 4 8 2 9 6 5]
 [2 6 0 1 3 8 5 4 9 7]
 [9 2 4 3 8 5 0 6 7 1]
 [6 8 7 4 2 9 5 1 3 0]
 [5 0 4 9 7 6 3 1 8 2]
 [7 6 5 3 4 2 9 0 8 1]
 [7 4 8 9 0 2 6 1 3 5]
 [2 8 9 5 3 7 6 1 4 0]
 [8 6 2 1 0 3 7 4 9 5]
 [6 3 0 4 7 2 9 5 1 8]]
Epoch 74610: Training cost= 2.3026, Training acc= 0.7277, Validation cost= 2.3026, Validation acc= 0.7272
Epoch 74620: Training cost= 2.3026, Training acc= 0.7276, Validation cost= 2.3026, Validation acc= 0.7271
Epoch 74630: Training cost= 2.3026, Training acc= 0.7275, Validation cost= 2.3026, Validation acc= 0.7271
Epoch 74640: Training cost= 2.3026, Training acc= 0.7274, Validation cost= 2.3026, Validation acc= 0.7270
Epoch 74650: Training cost= 2.3026, Training acc= 0.7273, Validation cost= 2.3026, Validation acc= 0.7269
Epoch 74660: Training cost= 2.3026, Training acc= 0.7272, Validation cost= 2.3026, Validation acc= 0.7268
Epoch 74670: Training cost= 2.3026, Training acc= 0.7272, Validation cost= 2.3026, Validation acc= 0.7267
Epoch 74680: Training cost= 2.3026, Training acc= 0.7271, Validation cost= 2.3026, Validation acc= 0.7266
Epoch 74690: Training cost= 2.3026, Training acc= 0.7270, Validation cost= 2.3026, Validation acc= 0.7266
Epoch 74700: Training cost= 2.3026, Training acc= 0.7269, Validation cost= 2.3026, Validation acc= 0.7265
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 5 2 4 6 7 3 8 9 0]
 [6 7 5 9 2 1 0 3 4 8]
 [9 3 2 7 1 0 5 4 8 6]
 [8 4 1 6 0 3 9 2 7 5]
 [0 8 6 5 1 9 4 2 3 7]
 [3 2 7 6 5 4 9 1 8 0]
 [7 8 0 5 9 3 2 6 1 4]
 [3 7 4 0 6 5 2 9 1 8]
 [4 9 0 5 6 1 7 8 3 2]
 [5 6 7 3 0 9 4 2 1 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 0 5 9 8 1 6 3 7 4]
 [9 8 4 0 1 3 7 5 2 6]
 [0 9 6 3 2 1 7 4 8 5]
 [3 5 8 7 2 4 6 0 9 1]
 [3 9 2 6 4 5 1 8 0 7]
 [7 9 4 0 5 8 2 3 6 1]
 [7 0 3 1 5 6 8 9 2 4]
 [4 7 0 1 5 3 2 8 6 9]
 [5 4 3 7 0 6 2 9 8 1]
 [5 4 3 7 6 1 2 0 9 8]]
Epoch 74710: Training cost= 2.3026, Training acc= 0.7268, Validation cost= 2.3026, Validation acc= 0.7264
Epoch 74720: Training cost= 2.3026, Training acc= 0.7267, Validation cost= 2.3026, Validation acc= 0.7263
Epoch 74730: Training cost= 2.3026, Training acc= 0.7266, Validation cost= 2.3026, Validation acc= 0.7262
Epoch 74740: Training cost= 2.3026, Training acc= 0.7266, Validation cost= 2.3026, Validation acc= 0.7261
Epoch 74750: Training cost= 2.3026, Training acc= 0.7265, Validation cost= 2.3026, Validation acc= 0.7261
Epoch 74760: Training cost= 2.3026, Training acc= 0.7264, Validation cost= 2.3026, Validation acc= 0.7260
Epoch 74770: Training cost= 2.3026, Training acc= 0.7263, Validation cost= 2.3026, Validation acc= 0.7259
Epoch 74780: Training cost= 2.3026, Training acc= 0.7262, Validation cost= 2.3026, Validation acc= 0.7258
Epoch 74790: Training cost= 2.3026, Training acc= 0.7261, Validation cost= 2.3026, Validation acc= 0.7257
Epoch 74800: Training cost= 2.3026, Training acc= 0.7261, Validation cost= 2.3026, Validation acc= 0.7256
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 1 6 0 3 2 5 8 4 9]
 [5 8 1 3 6 2 0 4 9 7]
 [0 8 4 7 5 2 9 3 6 1]
 [2 6 4 5 3 9 7 0 1 8]
 [7 0 4 3 6 9 1 8 2 5]
 [4 5 0 8 2 3 6 7 1 9]
 [0 1 4 5 9 2 3 6 7 8]
 [8 0 1 5 3 4 2 6 7 9]
 [3 6 4 5 9 8 0 7 2 1]
 [9 8 5 6 7 4 3 0 2 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 3 9 7 8 1 6 0 2 4]
 [9 4 8 5 1 0 3 7 2 6]
 [6 4 5 3 7 8 1 0 9 2]
 [9 3 7 6 8 1 5 4 0 2]
 [7 1 2 6 0 3 5 8 9 4]
 [5 0 1 7 4 6 8 3 2 9]
 [0 4 3 8 9 7 5 1 6 2]
 [4 0 9 7 5 6 2 3 8 1]
 [1 4 3 8 2 9 7 6 5 0]
 [2 6 4 3 7 1 9 0 5 8]]
Epoch 74810: Training cost= 2.3026, Training acc= 0.7260, Validation cost= 2.3026, Validation acc= 0.7256
Epoch 74820: Training cost= 2.3026, Training acc= 0.7259, Validation cost= 2.3026, Validation acc= 0.7255
Epoch 74830: Training cost= 2.3026, Training acc= 0.7258, Validation cost= 2.3026, Validation acc= 0.7254
Epoch 74840: Training cost= 2.3026, Training acc= 0.7257, Validation cost= 2.3026, Validation acc= 0.7253
Epoch 74850: Training cost= 2.3026, Training acc= 0.7256, Validation cost= 2.3026, Validation acc= 0.7252
Epoch 74860: Training cost= 2.3026, Training acc= 0.7256, Validation cost= 2.3026, Validation acc= 0.7251
Epoch 74870: Training cost= 2.3026, Training acc= 0.7255, Validation cost= 2.3026, Validation acc= 0.7251
Epoch 74880: Training cost= 2.3026, Training acc= 0.7254, Validation cost= 2.3026, Validation acc= 0.7250
Epoch 74890: Training cost= 2.3026, Training acc= 0.7253, Validation cost= 2.3026, Validation acc= 0.7249
Epoch 74900: Training cost= 2.3026, Training acc= 0.7252, Validation cost= 2.3026, Validation acc= 0.7248
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 3 7 6 8 5 1 2 9 0]
 [4 9 5 6 8 0 3 2 1 7]
 [7 0 6 9 8 5 1 3 4 2]
 [0 1 9 8 2 5 6 4 3 7]
 [1 4 3 8 7 2 0 9 5 6]
 [5 3 0 4 1 7 6 2 8 9]
 [6 5 7 1 8 0 9 3 4 2]
 [5 2 7 9 6 8 0 1 3 4]
 [8 3 2 7 4 1 9 6 0 5]
 [0 3 1 4 5 2 6 9 7 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 0 4 3 2 6 7 5 8 1]
 [7 3 6 9 5 8 0 2 4 1]
 [8 9 2 3 5 4 0 6 1 7]
 [0 5 7 1 3 4 6 2 8 9]
 [8 4 9 0 3 5 7 2 1 6]
 [4 1 5 0 7 2 9 3 8 6]
 [6 5 1 9 4 0 2 7 3 8]
 [1 4 2 9 8 5 7 0 3 6]
 [0 7 2 1 9 3 5 8 6 4]
 [3 2 4 5 7 8 6 9 1 0]]
Epoch 74910: Training cost= 2.3026, Training acc= 0.7251, Validation cost= 2.3026, Validation acc= 0.7247
Epoch 74920: Training cost= 2.3026, Training acc= 0.7251, Validation cost= 2.3026, Validation acc= 0.7246
Epoch 74930: Training cost= 2.3026, Training acc= 0.7250, Validation cost= 2.3026, Validation acc= 0.7246
Epoch 74940: Training cost= 2.3026, Training acc= 0.7249, Validation cost= 2.3026, Validation acc= 0.7245
Epoch 74950: Training cost= 2.3026, Training acc= 0.7248, Validation cost= 2.3026, Validation acc= 0.7244
Epoch 74960: Training cost= 2.3026, Training acc= 0.7247, Validation cost= 2.3026, Validation acc= 0.7243
Epoch 74970: Training cost= 2.3026, Training acc= 0.7246, Validation cost= 2.3026, Validation acc= 0.7242
Epoch 74980: Training cost= 2.3026, Training acc= 0.7246, Validation cost= 2.3026, Validation acc= 0.7241
Epoch 74990: Training cost= 2.3026, Training acc= 0.7245, Validation cost= 2.3026, Validation acc= 0.7241
Epoch 75000: Training cost= 2.3026, Training acc= 0.7244, Validation cost= 2.3026, Validation acc= 0.7240
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 7 5 8 3 9 2 4 6 1]
 [8 2 6 5 7 1 9 0 3 4]
 [0 5 1 6 8 7 2 9 4 3]
 [8 3 6 7 5 4 9 2 1 0]
 [9 7 2 3 8 4 6 0 5 1]
 [5 0 6 7 2 4 8 1 3 9]
 [5 1 2 6 7 4 9 8 3 0]
 [4 5 2 0 6 1 8 9 7 3]
 [9 5 6 3 2 8 7 1 4 0]
 [5 6 8 3 2 1 9 7 0 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 6 7 5 0 4 3 2 8 9]
 [2 1 3 0 8 4 5 9 6 7]
 [7 5 0 2 9 3 4 1 8 6]
 [8 1 9 6 7 4 3 5 0 2]
 [3 2 5 9 8 4 7 0 6 1]
 [1 5 9 7 3 8 2 6 4 0]
 [1 3 5 6 0 4 7 8 9 2]
 [0 6 3 5 2 7 8 9 1 4]
 [3 8 7 1 4 9 6 5 0 2]
 [4 0 2 9 3 1 6 5 7 8]]
Epoch 75010: Training cost= 2.3026, Training acc= 0.7243, Validation cost= 2.3026, Validation acc= 0.7239
Epoch 75020: Training cost= 2.3026, Training acc= 0.7242, Validation cost= 2.3026, Validation acc= 0.7238
Epoch 75030: Training cost= 2.3026, Training acc= 0.7241, Validation cost= 2.3026, Validation acc= 0.7237
Epoch 75040: Training cost= 2.3026, Training acc= 0.7241, Validation cost= 2.3026, Validation acc= 0.7236
Epoch 75050: Training cost= 2.3026, Training acc= 0.7240, Validation cost= 2.3026, Validation acc= 0.7236
Epoch 75060: Training cost= 2.3026, Training acc= 0.7239, Validation cost= 2.3026, Validation acc= 0.7235
Epoch 75070: Training cost= 2.3026, Training acc= 0.7238, Validation cost= 2.3026, Validation acc= 0.7234
Epoch 75080: Training cost= 2.3026, Training acc= 0.7237, Validation cost= 2.3026, Validation acc= 0.7233
Epoch 75090: Training cost= 2.3026, Training acc= 0.7236, Validation cost= 2.3026, Validation acc= 0.7232
Epoch 75100: Training cost= 2.3026, Training acc= 0.7236, Validation cost= 2.3026, Validation acc= 0.7231
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 5 2 1 8 7 6 0 4 3]
 [2 5 4 0 7 6 8 3 1 9]
 [7 3 5 0 9 6 1 2 4 8]
 [7 3 9 1 6 5 0 2 4 8]
 [8 7 5 0 6 9 3 1 2 4]
 [5 2 8 3 1 4 9 0 7 6]
 [3 9 6 1 0 8 2 5 4 7]
 [7 4 3 5 9 2 6 1 8 0]
 [6 9 7 1 2 5 8 4 0 3]
 [0 6 7 1 9 4 2 3 8 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 1 5 9 8 3 7 2 4 6]
 [1 9 6 4 7 8 2 3 5 0]
 [6 0 1 7 9 2 4 8 3 5]
 [9 0 1 6 8 3 2 7 4 5]
 [3 0 9 8 6 7 2 1 4 5]
 [3 4 2 1 6 9 5 0 8 7]
 [8 1 0 6 3 4 7 9 5 2]
 [7 6 4 1 0 3 2 9 5 8]
 [2 0 7 4 3 1 8 5 9 6]
 [5 2 8 1 0 4 7 6 9 3]]
Epoch 75110: Training cost= 2.3026, Training acc= 0.7235, Validation cost= 2.3026, Validation acc= 0.7231
Epoch 75120: Training cost= 2.3026, Training acc= 0.7234, Validation cost= 2.3026, Validation acc= 0.7230
Epoch 75130: Training cost= 2.3026, Training acc= 0.7233, Validation cost= 2.3026, Validation acc= 0.7229
Epoch 75140: Training cost= 2.3026, Training acc= 0.7232, Validation cost= 2.3026, Validation acc= 0.7228
Epoch 75150: Training cost= 2.3026, Training acc= 0.7231, Validation cost= 2.3026, Validation acc= 0.7227
Epoch 75160: Training cost= 2.3026, Training acc= 0.7231, Validation cost= 2.3026, Validation acc= 0.7226
Epoch 75170: Training cost= 2.3026, Training acc= 0.7230, Validation cost= 2.3026, Validation acc= 0.7226
Epoch 75180: Training cost= 2.3026, Training acc= 0.7229, Validation cost= 2.3026, Validation acc= 0.7225
Epoch 75190: Training cost= 2.3026, Training acc= 0.7228, Validation cost= 2.3026, Validation acc= 0.7224
Epoch 75200: Training cost= 2.3026, Training acc= 0.7227, Validation cost= 2.3026, Validation acc= 0.7223
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 3 6 1 4 7 8 0 2 9]
 [7 5 6 9 2 8 3 0 4 1]
 [5 3 6 1 9 0 7 4 2 8]
 [5 7 2 4 0 3 1 8 9 6]
 [5 6 9 7 0 3 4 1 8 2]
 [8 6 7 9 2 0 1 5 3 4]
 [1 9 4 5 8 3 0 6 2 7]
 [7 9 1 5 2 8 6 3 4 0]
 [5 9 0 3 6 1 2 4 7 8]
 [6 0 4 1 7 8 3 5 9 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 4 0 7 1 8 3 9 2 6]
 [7 3 8 2 5 4 9 0 1 6]
 [7 5 3 2 8 9 1 6 0 4]
 [3 8 2 6 4 0 9 7 5 1]
 [8 3 1 4 5 2 7 9 0 6]
 [0 5 4 3 8 6 2 7 1 9]
 [7 6 1 5 9 8 2 3 0 4]
 [6 9 5 1 3 4 0 2 8 7]
 [1 2 6 8 0 9 4 7 5 3]
 [5 7 8 6 4 9 0 2 3 1]]
Epoch 75210: Training cost= 2.3026, Training acc= 0.7227, Validation cost= 2.3026, Validation acc= 0.7222
Epoch 75220: Training cost= 2.3026, Training acc= 0.7226, Validation cost= 2.3026, Validation acc= 0.7221
Epoch 75230: Training cost= 2.3026, Training acc= 0.7225, Validation cost= 2.3026, Validation acc= 0.7221
Epoch 75240: Training cost= 2.3026, Training acc= 0.7224, Validation cost= 2.3026, Validation acc= 0.7220
Epoch 75250: Training cost= 2.3026, Training acc= 0.7223, Validation cost= 2.3026, Validation acc= 0.7219
Epoch 75260: Training cost= 2.3026, Training acc= 0.7222, Validation cost= 2.3026, Validation acc= 0.7218
Epoch 75270: Training cost= 2.3026, Training acc= 0.7222, Validation cost= 2.3026, Validation acc= 0.7217
Epoch 75280: Training cost= 2.3026, Training acc= 0.7221, Validation cost= 2.3026, Validation acc= 0.7216
Epoch 75290: Training cost= 2.3026, Training acc= 0.7220, Validation cost= 2.3026, Validation acc= 0.7216
Epoch 75300: Training cost= 2.3026, Training acc= 0.7219, Validation cost= 2.3026, Validation acc= 0.7215
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 8 1 0 7 5 6 2 3 4]
 [5 8 3 6 7 1 9 2 4 0]
 [7 6 2 4 0 3 9 5 8 1]
 [0 9 2 3 6 1 7 5 8 4]
 [5 6 7 3 2 4 9 8 0 1]
 [6 8 3 0 1 9 7 2 5 4]
 [3 4 7 8 5 6 0 1 2 9]
 [4 5 3 9 0 1 2 6 8 7]
 [1 5 0 6 7 4 8 2 9 3]
 [4 2 7 1 8 5 9 3 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 1 8 0 7 5 6 4 3 9]
 [1 8 3 4 0 7 6 5 9 2]
 [0 4 6 5 3 7 1 9 8 2]
 [0 3 8 2 1 4 6 7 9 5]
 [5 1 7 8 9 4 2 0 3 6]
 [9 2 1 0 6 5 8 4 3 7]
 [7 8 5 1 4 9 2 3 6 0]
 [7 2 1 0 4 6 9 5 8 3]
 [6 8 4 7 0 1 9 3 2 5]
 [0 3 5 6 8 2 9 7 1 4]]
Epoch 75310: Training cost= 2.3026, Training acc= 0.7218, Validation cost= 2.3026, Validation acc= 0.7214
Epoch 75320: Training cost= 2.3026, Training acc= 0.7217, Validation cost= 2.3026, Validation acc= 0.7213
Epoch 75330: Training cost= 2.3026, Training acc= 0.7217, Validation cost= 2.3026, Validation acc= 0.7212
Epoch 75340: Training cost= 2.3026, Training acc= 0.7216, Validation cost= 2.3026, Validation acc= 0.7212
Epoch 75350: Training cost= 2.3026, Training acc= 0.7215, Validation cost= 2.3026, Validation acc= 0.7211
Epoch 75360: Training cost= 2.3026, Training acc= 0.7214, Validation cost= 2.3026, Validation acc= 0.7210
Epoch 75370: Training cost= 2.3026, Training acc= 0.7213, Validation cost= 2.3026, Validation acc= 0.7209
Epoch 75380: Training cost= 2.3026, Training acc= 0.7212, Validation cost= 2.3026, Validation acc= 0.7208
Epoch 75390: Training cost= 2.3026, Training acc= 0.7212, Validation cost= 2.3026, Validation acc= 0.7207
Epoch 75400: Training cost= 2.3026, Training acc= 0.7211, Validation cost= 2.3026, Validation acc= 0.7207
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 8 5 0 9 2 6 1 4 3]
 [4 7 1 9 6 5 3 2 0 8]
 [2 0 6 3 4 9 7 1 5 8]
 [1 6 3 2 5 0 4 9 8 7]
 [8 2 7 0 5 9 4 1 6 3]
 [7 4 1 6 0 2 3 8 9 5]
 [8 4 9 2 0 5 3 6 7 1]
 [7 0 8 6 2 1 3 4 5 9]
 [6 4 8 0 2 5 9 1 7 3]
 [4 0 7 5 3 8 6 9 2 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 7 0 1 6 9 5 3 2 8]
 [0 7 9 1 8 3 6 5 2 4]
 [4 8 7 5 2 6 0 3 9 1]
 [2 7 5 1 6 8 4 3 9 0]
 [8 0 1 3 5 6 9 7 4 2]
 [1 5 2 8 3 7 0 4 6 9]
 [1 8 5 3 2 7 6 4 9 0]
 [7 5 8 2 3 0 9 4 1 6]
 [5 9 3 7 0 1 8 2 6 4]
 [3 6 5 9 8 2 4 1 0 7]]
Epoch 75410: Training cost= 2.3026, Training acc= 0.7210, Validation cost= 2.3026, Validation acc= 0.7206
Epoch 75420: Training cost= 2.3026, Training acc= 0.7209, Validation cost= 2.3026, Validation acc= 0.7205
Epoch 75430: Training cost= 2.3026, Training acc= 0.7208, Validation cost= 2.3026, Validation acc= 0.7204
Epoch 75440: Training cost= 2.3026, Training acc= 0.7208, Validation cost= 2.3026, Validation acc= 0.7203
Epoch 75450: Training cost= 2.3026, Training acc= 0.7207, Validation cost= 2.3026, Validation acc= 0.7202
Epoch 75460: Training cost= 2.3026, Training acc= 0.7206, Validation cost= 2.3026, Validation acc= 0.7202
Epoch 75470: Training cost= 2.3026, Training acc= 0.7205, Validation cost= 2.3026, Validation acc= 0.7201
Epoch 75480: Training cost= 2.3026, Training acc= 0.7204, Validation cost= 2.3026, Validation acc= 0.7200
Epoch 75490: Training cost= 2.3026, Training acc= 0.7203, Validation cost= 2.3026, Validation acc= 0.7199
Epoch 75500: Training cost= 2.3026, Training acc= 0.7203, Validation cost= 2.3026, Validation acc= 0.7198
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 6 1 9 2 7 5 3 8 4]
 [1 2 6 4 3 8 5 0 9 7]
 [4 9 6 8 7 0 1 3 2 5]
 [8 7 9 0 4 3 2 5 1 6]
 [3 2 9 1 5 7 4 0 8 6]
 [7 4 2 5 9 0 1 3 8 6]
 [2 4 7 8 0 3 5 6 1 9]
 [2 5 7 4 9 8 0 3 1 6]
 [9 6 4 1 3 0 7 2 5 8]
 [7 1 8 3 9 4 5 2 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 9 7 1 6 5 4 2 8 0]
 [9 0 8 1 5 4 2 6 7 3]
 [8 1 0 6 9 7 5 4 3 2]
 [5 4 7 2 0 8 9 1 6 3]
 [9 5 4 6 7 8 2 0 3 1]
 [5 6 2 7 4 9 0 1 3 8]
 [5 8 7 4 1 2 6 0 9 3]
 [3 2 6 8 1 7 4 0 5 9]
 [5 9 6 1 0 8 2 4 7 3]
 [1 3 6 4 2 0 5 7 9 8]]
Epoch 75510: Training cost= 2.3026, Training acc= 0.7202, Validation cost= 2.3026, Validation acc= 0.7198
Epoch 75520: Training cost= 2.3026, Training acc= 0.7201, Validation cost= 2.3026, Validation acc= 0.7197
Epoch 75530: Training cost= 2.3026, Training acc= 0.7200, Validation cost= 2.3026, Validation acc= 0.7196
Epoch 75540: Training cost= 2.3026, Training acc= 0.7199, Validation cost= 2.3026, Validation acc= 0.7195
Epoch 75550: Training cost= 2.3026, Training acc= 0.7198, Validation cost= 2.3026, Validation acc= 0.7194
Epoch 75560: Training cost= 2.3026, Training acc= 0.7198, Validation cost= 2.3026, Validation acc= 0.7193
Epoch 75570: Training cost= 2.3026, Training acc= 0.7197, Validation cost= 2.3026, Validation acc= 0.7193
Epoch 75580: Training cost= 2.3026, Training acc= 0.7196, Validation cost= 2.3026, Validation acc= 0.7192
Epoch 75590: Training cost= 2.3026, Training acc= 0.7195, Validation cost= 2.3026, Validation acc= 0.7191
Epoch 75600: Training cost= 2.3026, Training acc= 0.7194, Validation cost= 2.3026, Validation acc= 0.7190
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 8 6 9 7 1 3 4 2 0]
 [8 4 1 9 2 0 6 3 5 7]
 [1 0 3 4 6 7 2 8 9 5]
 [6 4 0 2 8 5 7 9 1 3]
 [4 1 3 6 2 8 9 5 7 0]
 [2 0 6 9 5 3 1 4 8 7]
 [8 4 3 7 1 5 2 9 6 0]
 [1 6 8 0 5 9 7 4 2 3]
 [2 9 1 4 7 6 0 8 5 3]
 [8 1 3 0 2 6 9 4 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 5 2 6 7 3 1 4 9 0]
 [6 3 8 2 0 7 9 4 1 5]
 [9 1 3 0 8 4 5 2 6 7]
 [4 2 6 1 0 5 9 8 3 7]
 [3 5 0 9 1 7 2 4 8 6]
 [8 0 5 2 1 9 7 4 3 6]
 [2 7 6 5 8 3 1 0 4 9]
 [5 9 3 2 1 4 0 6 7 8]
 [6 7 2 0 1 8 5 4 9 3]
 [0 9 5 2 6 8 4 3 1 7]]
Epoch 75610: Training cost= 2.3026, Training acc= 0.7194, Validation cost= 2.3026, Validation acc= 0.7189
Epoch 75620: Training cost= 2.3026, Training acc= 0.7193, Validation cost= 2.3026, Validation acc= 0.7189
Epoch 75630: Training cost= 2.3026, Training acc= 0.7192, Validation cost= 2.3026, Validation acc= 0.7188
Epoch 75640: Training cost= 2.3026, Training acc= 0.7191, Validation cost= 2.3026, Validation acc= 0.7187
Epoch 75650: Training cost= 2.3026, Training acc= 0.7190, Validation cost= 2.3026, Validation acc= 0.7186
Epoch 75660: Training cost= 2.3026, Training acc= 0.7189, Validation cost= 2.3026, Validation acc= 0.7185
Epoch 75670: Training cost= 2.3026, Training acc= 0.7189, Validation cost= 2.3026, Validation acc= 0.7184
Epoch 75680: Training cost= 2.3026, Training acc= 0.7188, Validation cost= 2.3026, Validation acc= 0.7184
Epoch 75690: Training cost= 2.3026, Training acc= 0.7187, Validation cost= 2.3026, Validation acc= 0.7183
Epoch 75700: Training cost= 2.3026, Training acc= 0.7186, Validation cost= 2.3026, Validation acc= 0.7182
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 6 2 7 4 1 9 5 0 3]
 [9 8 5 4 0 2 1 3 7 6]
 [2 7 6 8 9 3 1 4 0 5]
 [5 1 2 6 8 7 4 9 3 0]
 [5 1 4 0 3 9 8 2 7 6]
 [3 2 9 8 0 1 6 4 5 7]
 [7 5 2 6 0 3 4 8 9 1]
 [5 0 2 8 1 6 3 7 9 4]
 [5 6 7 0 3 8 4 2 1 9]
 [2 3 7 4 5 9 0 6 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 5 2 7 4 0 1 8 6 3]
 [3 0 4 2 1 7 6 8 5 9]
 [6 1 4 2 7 8 5 3 0 9]
 [4 0 8 5 6 1 3 2 7 9]
 [0 7 3 1 8 6 4 2 5 9]
 [4 5 1 8 2 9 3 0 6 7]
 [6 2 1 4 3 5 7 0 9 8]
 [8 1 7 3 2 4 9 5 6 0]
 [3 6 4 2 8 7 5 0 1 9]
 [1 3 4 2 0 5 9 7 6 8]]
Epoch 75710: Training cost= 2.3026, Training acc= 0.7185, Validation cost= 2.3026, Validation acc= 0.7181
Epoch 75720: Training cost= 2.3026, Training acc= 0.7185, Validation cost= 2.3026, Validation acc= 0.7180
Epoch 75730: Training cost= 2.3026, Training acc= 0.7184, Validation cost= 2.3026, Validation acc= 0.7180
Epoch 75740: Training cost= 2.3026, Training acc= 0.7183, Validation cost= 2.3026, Validation acc= 0.7179
Epoch 75750: Training cost= 2.3026, Training acc= 0.7182, Validation cost= 2.3026, Validation acc= 0.7178
Epoch 75760: Training cost= 2.3026, Training acc= 0.7181, Validation cost= 2.3026, Validation acc= 0.7177
Epoch 75770: Training cost= 2.3026, Training acc= 0.7180, Validation cost= 2.3026, Validation acc= 0.7176
Epoch 75780: Training cost= 2.3026, Training acc= 0.7180, Validation cost= 2.3026, Validation acc= 0.7175
Epoch 75790: Training cost= 2.3026, Training acc= 0.7179, Validation cost= 2.3026, Validation acc= 0.7175
Epoch 75800: Training cost= 2.3026, Training acc= 0.7178, Validation cost= 2.3026, Validation acc= 0.7174
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 4 5 9 3 7 2 8 6 1]
 [2 5 8 4 7 0 6 1 3 9]
 [4 5 6 3 1 2 7 9 8 0]
 [3 8 1 4 2 7 9 0 5 6]
 [2 3 0 6 8 9 1 7 4 5]
 [8 4 9 6 3 1 2 7 5 0]
 [6 5 7 9 8 3 4 2 1 0]
 [3 7 2 8 1 6 0 9 4 5]
 [1 6 8 2 0 9 7 4 3 5]
 [8 6 4 2 0 7 5 3 1 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 3 2 8 6 7 5 0 9 4]
 [0 2 9 6 7 3 8 1 4 5]
 [6 1 5 3 8 9 7 0 2 4]
 [5 3 4 0 7 2 9 1 8 6]
 [3 8 5 4 9 2 1 7 6 0]
 [8 4 3 1 0 2 9 6 5 7]
 [1 2 9 4 7 0 3 6 5 8]
 [8 4 1 9 7 0 5 2 6 3]
 [0 1 3 5 7 6 9 8 4 2]
 [1 2 7 5 9 4 0 6 3 8]]
Epoch 75810: Training cost= 2.3026, Training acc= 0.7177, Validation cost= 2.3026, Validation acc= 0.7173
Epoch 75820: Training cost= 2.3026, Training acc= 0.7176, Validation cost= 2.3026, Validation acc= 0.7172
Epoch 75830: Training cost= 2.3026, Training acc= 0.7176, Validation cost= 2.3026, Validation acc= 0.7171
Epoch 75840: Training cost= 2.3026, Training acc= 0.7175, Validation cost= 2.3026, Validation acc= 0.7171
Epoch 75850: Training cost= 2.3026, Training acc= 0.7174, Validation cost= 2.3026, Validation acc= 0.7170
Epoch 75860: Training cost= 2.3026, Training acc= 0.7173, Validation cost= 2.3026, Validation acc= 0.7169
Epoch 75870: Training cost= 2.3026, Training acc= 0.7172, Validation cost= 2.3026, Validation acc= 0.7168
Epoch 75880: Training cost= 2.3026, Training acc= 0.7172, Validation cost= 2.3026, Validation acc= 0.7167
Epoch 75890: Training cost= 2.3026, Training acc= 0.7171, Validation cost= 2.3026, Validation acc= 0.7167
Epoch 75900: Training cost= 2.3026, Training acc= 0.7170, Validation cost= 2.3026, Validation acc= 0.7166
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 8 2 9 3 5 6 0 7 4]
 [0 1 2 6 7 8 4 9 3 5]
 [8 5 4 0 3 6 9 7 2 1]
 [3 5 0 7 1 4 8 2 6 9]
 [4 3 9 1 5 0 2 7 6 8]
 [6 3 5 0 4 8 2 7 1 9]
 [4 2 7 8 3 9 0 6 5 1]
 [2 6 0 4 9 3 5 7 1 8]
 [4 6 7 9 1 8 0 5 2 3]
 [2 6 3 8 0 7 1 4 9 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 6 7 4 2 3 9 1 8 0]
 [1 0 7 5 4 8 2 9 3 6]
 [4 0 9 8 2 3 5 1 7 6]
 [4 7 5 1 0 9 6 3 2 8]
 [4 9 7 6 5 3 8 0 1 2]
 [5 4 2 7 1 6 3 8 9 0]
 [0 4 6 7 9 8 1 2 5 3]
 [7 1 8 0 5 2 9 4 6 3]
 [5 2 8 1 4 3 7 0 9 6]
 [4 5 8 9 3 7 6 0 2 1]]
Epoch 75910: Training cost= 2.3026, Training acc= 0.7169, Validation cost= 2.3026, Validation acc= 0.7165
Epoch 75920: Training cost= 2.3026, Training acc= 0.7168, Validation cost= 2.3026, Validation acc= 0.7164
Epoch 75930: Training cost= 2.3026, Training acc= 0.7167, Validation cost= 2.3026, Validation acc= 0.7163
Epoch 75940: Training cost= 2.3026, Training acc= 0.7167, Validation cost= 2.3026, Validation acc= 0.7162
Epoch 75950: Training cost= 2.3026, Training acc= 0.7166, Validation cost= 2.3026, Validation acc= 0.7162
Epoch 75960: Training cost= 2.3026, Training acc= 0.7165, Validation cost= 2.3026, Validation acc= 0.7161
Epoch 75970: Training cost= 2.3026, Training acc= 0.7164, Validation cost= 2.3026, Validation acc= 0.7160
Epoch 75980: Training cost= 2.3026, Training acc= 0.7163, Validation cost= 2.3026, Validation acc= 0.7159
Epoch 75990: Training cost= 2.3026, Training acc= 0.7163, Validation cost= 2.3026, Validation acc= 0.7158
Epoch 76000: Training cost= 2.3026, Training acc= 0.7162, Validation cost= 2.3026, Validation acc= 0.7158
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 8 6 9 4 3 2 7 5 1]
 [7 6 8 9 2 5 4 1 3 0]
 [1 9 7 0 8 6 3 4 5 2]
 [5 6 1 9 4 0 7 8 2 3]
 [5 0 8 3 9 2 6 7 4 1]
 [2 0 6 5 9 8 4 1 3 7]
 [3 9 2 4 7 0 1 5 8 6]
 [6 8 1 5 4 0 3 7 2 9]
 [4 9 1 0 6 7 3 2 8 5]
 [6 1 8 2 9 5 7 3 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 8 9 7 4 1 6 3 0 5]
 [9 5 0 6 7 4 2 3 1 8]
 [7 6 1 0 8 4 9 3 5 2]
 [8 0 3 2 6 1 7 5 9 4]
 [5 9 6 3 7 4 1 0 8 2]
 [3 0 8 5 6 7 1 9 2 4]
 [1 2 5 4 8 0 6 9 7 3]
 [0 5 7 6 9 8 1 4 3 2]
 [1 9 0 6 5 7 4 3 2 8]
 [9 1 6 8 2 5 0 3 7 4]]
Epoch 76010: Training cost= 2.3026, Training acc= 0.7161, Validation cost= 2.3026, Validation acc= 0.7157
Epoch 76020: Training cost= 2.3026, Training acc= 0.7160, Validation cost= 2.3026, Validation acc= 0.7156
Epoch 76030: Training cost= 2.3026, Training acc= 0.7159, Validation cost= 2.3026, Validation acc= 0.7155
Epoch 76040: Training cost= 2.3026, Training acc= 0.7159, Validation cost= 2.3026, Validation acc= 0.7154
Epoch 76050: Training cost= 2.3026, Training acc= 0.7158, Validation cost= 2.3026, Validation acc= 0.7154
Epoch 76060: Training cost= 2.3026, Training acc= 0.7157, Validation cost= 2.3026, Validation acc= 0.7153
Epoch 76070: Training cost= 2.3026, Training acc= 0.7156, Validation cost= 2.3026, Validation acc= 0.7152
Epoch 76080: Training cost= 2.3026, Training acc= 0.7155, Validation cost= 2.3026, Validation acc= 0.7151
Epoch 76090: Training cost= 2.3026, Training acc= 0.7154, Validation cost= 2.3026, Validation acc= 0.7150
Epoch 76100: Training cost= 2.3026, Training acc= 0.7154, Validation cost= 2.3026, Validation acc= 0.7149
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 4 7 8 6 5 0 9 2 3]
 [2 4 8 5 7 9 6 0 3 1]
 [5 6 9 4 0 7 8 2 1 3]
 [4 7 2 0 8 1 3 6 5 9]
 [9 2 4 1 3 8 0 5 7 6]
 [1 6 7 0 3 5 8 9 4 2]
 [2 5 3 7 4 1 9 8 0 6]
 [6 0 3 5 2 4 1 7 9 8]
 [9 7 6 3 1 4 8 2 0 5]
 [5 6 2 4 0 3 8 1 9 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 5 0 8 6 9 2 1 7]
 [2 3 6 7 0 4 9 1 5 8]
 [8 0 4 9 2 6 5 3 1 7]
 [4 7 3 8 2 1 9 0 6 5]
 [6 4 1 7 3 5 9 2 8 0]
 [7 0 1 4 5 6 8 9 2 3]
 [5 1 6 7 4 8 9 3 0 2]
 [1 8 6 3 9 7 4 5 0 2]
 [1 0 4 2 5 7 9 8 3 6]
 [7 9 8 4 5 2 0 3 6 1]]
Epoch 76110: Training cost= 2.3026, Training acc= 0.7153, Validation cost= 2.3026, Validation acc= 0.7149
Epoch 76120: Training cost= 2.3026, Training acc= 0.7152, Validation cost= 2.3026, Validation acc= 0.7148
Epoch 76130: Training cost= 2.3026, Training acc= 0.7151, Validation cost= 2.3026, Validation acc= 0.7147
Epoch 76140: Training cost= 2.3026, Training acc= 0.7150, Validation cost= 2.3026, Validation acc= 0.7146
Epoch 76150: Training cost= 2.3026, Training acc= 0.7150, Validation cost= 2.3026, Validation acc= 0.7145
Epoch 76160: Training cost= 2.3026, Training acc= 0.7149, Validation cost= 2.3026, Validation acc= 0.7145
Epoch 76170: Training cost= 2.3026, Training acc= 0.7148, Validation cost= 2.3026, Validation acc= 0.7144
Epoch 76180: Training cost= 2.3026, Training acc= 0.7147, Validation cost= 2.3026, Validation acc= 0.7143
Epoch 76190: Training cost= 2.3026, Training acc= 0.7146, Validation cost= 2.3026, Validation acc= 0.7142
Epoch 76200: Training cost= 2.3026, Training acc= 0.7146, Validation cost= 2.3026, Validation acc= 0.7141
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 7 4 3 1 6 8 9 2 0]
 [7 4 5 8 2 1 9 3 6 0]
 [4 5 1 8 6 7 0 9 2 3]
 [2 4 8 1 7 9 6 0 5 3]
 [5 7 8 3 4 6 9 0 1 2]
 [6 7 9 2 8 1 3 0 4 5]
 [1 2 8 0 5 9 3 6 4 7]
 [6 5 8 9 4 7 1 2 3 0]
 [5 2 8 0 9 3 7 4 6 1]
 [7 0 9 3 6 4 2 1 8 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 2 1 9 5 6 3 7 4 8]
 [1 0 8 2 5 9 6 3 4 7]
 [8 3 5 4 6 9 7 0 1 2]
 [2 4 8 1 9 7 3 5 6 0]
 [9 6 8 5 2 7 1 0 3 4]
 [1 0 8 2 6 5 7 9 4 3]
 [9 2 7 6 4 1 0 3 8 5]
 [4 2 6 7 8 9 0 1 5 3]
 [8 9 4 6 0 2 7 1 5 3]
 [8 5 3 0 4 2 7 6 9 1]]
Epoch 76210: Training cost= 2.3026, Training acc= 0.7145, Validation cost= 2.3026, Validation acc= 0.7141
Epoch 76220: Training cost= 2.3026, Training acc= 0.7144, Validation cost= 2.3026, Validation acc= 0.7140
Epoch 76230: Training cost= 2.3026, Training acc= 0.7143, Validation cost= 2.3026, Validation acc= 0.7139
Epoch 76240: Training cost= 2.3026, Training acc= 0.7142, Validation cost= 2.3026, Validation acc= 0.7138
Epoch 76250: Training cost= 2.3026, Training acc= 0.7142, Validation cost= 2.3026, Validation acc= 0.7137
Epoch 76260: Training cost= 2.3026, Training acc= 0.7141, Validation cost= 2.3026, Validation acc= 0.7137
Epoch 76270: Training cost= 2.3026, Training acc= 0.7140, Validation cost= 2.3026, Validation acc= 0.7136
Epoch 76280: Training cost= 2.3026, Training acc= 0.7139, Validation cost= 2.3026, Validation acc= 0.7135
Epoch 76290: Training cost= 2.3026, Training acc= 0.7138, Validation cost= 2.3026, Validation acc= 0.7134
Epoch 76300: Training cost= 2.3026, Training acc= 0.7138, Validation cost= 2.3026, Validation acc= 0.7133
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 7 0 4 1 9 8 6 5 3]
 [2 3 1 8 0 4 6 7 5 9]
 [4 8 2 1 0 7 3 5 6 9]
 [0 5 4 3 9 7 1 8 2 6]
 [9 6 2 8 4 0 5 1 3 7]
 [2 9 6 7 1 8 4 5 3 0]
 [4 7 2 1 3 5 6 0 9 8]
 [2 8 4 1 6 7 9 0 5 3]
 [9 5 4 8 3 1 2 0 7 6]
 [3 4 1 9 2 6 5 7 0 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 8 9 3 6 7 5 1 0 2]
 [7 3 4 8 5 9 1 6 2 0]
 [9 2 1 6 7 8 3 5 0 4]
 [4 9 0 1 7 5 6 8 2 3]
 [3 4 5 8 0 2 9 6 7 1]
 [8 4 6 0 2 3 5 1 7 9]
 [2 8 4 3 5 6 1 0 7 9]
 [6 7 1 5 9 3 8 0 2 4]
 [1 8 5 6 4 7 2 3 0 9]
 [3 2 5 4 1 9 8 0 7 6]]
Epoch 76310: Training cost= 2.3026, Training acc= 0.7137, Validation cost= 2.3026, Validation acc= 0.7133
Epoch 76320: Training cost= 2.3026, Training acc= 0.7136, Validation cost= 2.3026, Validation acc= 0.7132
Epoch 76330: Training cost= 2.3026, Training acc= 0.7135, Validation cost= 2.3026, Validation acc= 0.7131
Epoch 76340: Training cost= 2.3026, Training acc= 0.7134, Validation cost= 2.3026, Validation acc= 0.7130
Epoch 76350: Training cost= 2.3026, Training acc= 0.7134, Validation cost= 2.3026, Validation acc= 0.7129
Epoch 76360: Training cost= 2.3026, Training acc= 0.7133, Validation cost= 2.3026, Validation acc= 0.7129
Epoch 76370: Training cost= 2.3026, Training acc= 0.7132, Validation cost= 2.3026, Validation acc= 0.7128
Epoch 76380: Training cost= 2.3026, Training acc= 0.7131, Validation cost= 2.3026, Validation acc= 0.7127
Epoch 76390: Training cost= 2.3026, Training acc= 0.7130, Validation cost= 2.3026, Validation acc= 0.7126
Epoch 76400: Training cost= 2.3026, Training acc= 0.7130, Validation cost= 2.3026, Validation acc= 0.7125
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 9 1 0 2 8 3 4 6 7]
 [4 9 0 7 1 2 8 6 3 5]
 [7 5 8 0 6 4 2 3 1 9]
 [8 5 1 4 6 2 0 3 7 9]
 [4 5 6 0 7 2 9 1 3 8]
 [3 8 9 5 6 4 0 7 2 1]
 [4 3 2 5 8 0 9 1 7 6]
 [4 3 0 2 6 9 1 7 8 5]
 [8 6 1 2 7 3 4 9 5 0]
 [6 3 2 4 8 5 1 9 0 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 0 7 3 4 5 8 9 1 2]
 [3 8 9 0 6 5 2 4 7 1]
 [7 1 2 3 4 6 0 9 8 5]
 [2 0 3 6 9 7 8 1 5 4]
 [2 9 3 7 8 1 6 4 0 5]
 [0 3 9 6 2 5 4 7 8 1]
 [2 3 1 9 0 5 7 4 8 6]
 [8 6 1 4 5 7 3 2 9 0]
 [0 5 8 3 2 4 6 9 7 1]
 [9 6 7 0 2 4 5 8 1 3]]
Epoch 76410: Training cost= 2.3026, Training acc= 0.7129, Validation cost= 2.3026, Validation acc= 0.7125
Epoch 76420: Training cost= 2.3026, Training acc= 0.7128, Validation cost= 2.3026, Validation acc= 0.7124
Epoch 76430: Training cost= 2.3026, Training acc= 0.7127, Validation cost= 2.3026, Validation acc= 0.7123
Epoch 76440: Training cost= 2.3026, Training acc= 0.7126, Validation cost= 2.3026, Validation acc= 0.7122
Epoch 76450: Training cost= 2.3026, Training acc= 0.7126, Validation cost= 2.3026, Validation acc= 0.7121
Epoch 76460: Training cost= 2.3026, Training acc= 0.7125, Validation cost= 2.3026, Validation acc= 0.7121
Epoch 76470: Training cost= 2.3026, Training acc= 0.7124, Validation cost= 2.3026, Validation acc= 0.7120
Epoch 76480: Training cost= 2.3026, Training acc= 0.7123, Validation cost= 2.3026, Validation acc= 0.7119
Epoch 76490: Training cost= 2.3026, Training acc= 0.7122, Validation cost= 2.3026, Validation acc= 0.7118
Epoch 76500: Training cost= 2.3026, Training acc= 0.7122, Validation cost= 2.3026, Validation acc= 0.7117
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 1 5 9 3 7 8 0 6 2]
 [0 3 8 5 4 1 6 7 9 2]
 [5 2 8 1 4 0 3 7 9 6]
 [3 6 5 1 4 9 7 8 2 0]
 [7 2 9 1 4 5 6 0 3 8]
 [0 5 9 7 6 1 8 4 3 2]
 [0 3 6 5 7 9 4 8 1 2]
 [4 0 8 3 9 1 5 6 7 2]
 [9 5 1 0 2 7 8 6 3 4]
 [0 8 1 4 5 6 2 7 3 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 1 9 7 8 6 3 5 2 0]
 [2 9 5 3 4 6 0 7 8 1]
 [6 3 8 4 1 5 2 7 9 0]
 [1 7 4 3 8 0 2 9 6 5]
 [8 1 4 0 2 6 9 5 3 7]
 [6 1 4 8 3 9 5 0 2 7]
 [8 1 5 2 6 4 3 7 0 9]
 [3 9 0 8 2 4 1 7 6 5]
 [7 5 8 9 0 3 4 2 6 1]
 [0 3 7 9 5 1 6 4 2 8]]
Epoch 76510: Training cost= 2.3026, Training acc= 0.7121, Validation cost= 2.3026, Validation acc= 0.7117
Epoch 76520: Training cost= 2.3026, Training acc= 0.7120, Validation cost= 2.3026, Validation acc= 0.7116
Epoch 76530: Training cost= 2.3026, Training acc= 0.7119, Validation cost= 2.3026, Validation acc= 0.7115
Epoch 76540: Training cost= 2.3026, Training acc= 0.7118, Validation cost= 2.3026, Validation acc= 0.7114
Epoch 76550: Training cost= 2.3026, Training acc= 0.7118, Validation cost= 2.3026, Validation acc= 0.7113
Epoch 76560: Training cost= 2.3026, Training acc= 0.7117, Validation cost= 2.3026, Validation acc= 0.7113
Epoch 76570: Training cost= 2.3026, Training acc= 0.7116, Validation cost= 2.3026, Validation acc= 0.7112
Epoch 76580: Training cost= 2.3026, Training acc= 0.7115, Validation cost= 2.3026, Validation acc= 0.7111
Epoch 76590: Training cost= 2.3026, Training acc= 0.7114, Validation cost= 2.3026, Validation acc= 0.7110
Epoch 76600: Training cost= 2.3026, Training acc= 0.7114, Validation cost= 2.3026, Validation acc= 0.7109
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 2 8 4 7 1 0 9 5 3]
 [9 2 7 1 5 0 8 4 3 6]
 [5 6 3 1 2 8 0 4 9 7]
 [0 1 2 4 8 5 7 9 3 6]
 [2 4 7 1 9 0 8 5 3 6]
 [3 2 0 8 9 1 6 5 4 7]
 [2 7 4 8 3 9 5 0 6 1]
 [2 1 6 3 7 8 9 4 5 0]
 [0 9 5 8 2 4 6 7 3 1]
 [1 4 8 9 0 3 6 5 2 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 5 9 2 7 8 6 0 1]
 [5 4 3 9 8 2 1 7 0 6]
 [9 4 5 8 2 1 3 6 7 0]
 [9 8 1 7 0 5 3 2 4 6]
 [1 6 7 9 5 2 0 3 8 4]
 [8 3 7 1 6 4 9 2 5 0]
 [1 8 0 9 2 7 4 5 6 3]
 [6 7 9 2 0 3 1 8 5 4]
 [7 4 2 1 8 5 9 6 0 3]
 [9 3 2 4 1 8 6 7 0 5]]
Epoch 76610: Training cost= 2.3026, Training acc= 0.7113, Validation cost= 2.3026, Validation acc= 0.7109
Epoch 76620: Training cost= 2.3026, Training acc= 0.7112, Validation cost= 2.3026, Validation acc= 0.7108
Epoch 76630: Training cost= 2.3026, Training acc= 0.7111, Validation cost= 2.3026, Validation acc= 0.7107
Epoch 76640: Training cost= 2.3026, Training acc= 0.7110, Validation cost= 2.3026, Validation acc= 0.7106
Epoch 76650: Training cost= 2.3026, Training acc= 0.7110, Validation cost= 2.3026, Validation acc= 0.7105
Epoch 76660: Training cost= 2.3026, Training acc= 0.7109, Validation cost= 2.3026, Validation acc= 0.7105
Epoch 76670: Training cost= 2.3026, Training acc= 0.7108, Validation cost= 2.3026, Validation acc= 0.7104
Epoch 76680: Training cost= 2.3026, Training acc= 0.7107, Validation cost= 2.3026, Validation acc= 0.7103
Epoch 76690: Training cost= 2.3026, Training acc= 0.7106, Validation cost= 2.3026, Validation acc= 0.7102
Epoch 76700: Training cost= 2.3026, Training acc= 0.7106, Validation cost= 2.3026, Validation acc= 0.7101
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 4 1 7 8 9 5 0 2 3]
 [5 4 7 0 1 8 3 2 9 6]
 [2 1 5 6 3 8 4 9 0 7]
 [4 3 7 5 9 2 0 6 1 8]
 [8 9 6 1 0 3 7 2 4 5]
 [2 3 8 6 1 7 4 9 5 0]
 [1 6 4 3 5 2 0 8 7 9]
 [0 8 1 7 5 4 6 2 9 3]
 [9 0 5 6 7 3 4 8 2 1]
 [3 8 0 4 1 7 6 2 5 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 7 9 2 4 5 3 1 6 0]
 [8 4 7 3 5 9 6 1 0 2]
 [9 2 5 8 3 6 0 4 1 7]
 [8 6 5 3 1 4 2 9 0 7]
 [5 0 1 3 6 7 2 8 4 9]
 [2 4 1 8 7 0 5 9 6 3]
 [3 1 9 0 2 5 6 4 7 8]
 [5 8 2 9 0 4 3 7 1 6]
 [2 4 1 6 0 8 7 9 3 5]
 [0 6 1 8 9 5 7 3 2 4]]
Epoch 76710: Training cost= 2.3026, Training acc= 0.7105, Validation cost= 2.3026, Validation acc= 0.7101
Epoch 76720: Training cost= 2.3026, Training acc= 0.7104, Validation cost= 2.3026, Validation acc= 0.7100
Epoch 76730: Training cost= 2.3026, Training acc= 0.7103, Validation cost= 2.3026, Validation acc= 0.7099
Epoch 76740: Training cost= 2.3026, Training acc= 0.7102, Validation cost= 2.3026, Validation acc= 0.7098
Epoch 76750: Training cost= 2.3026, Training acc= 0.7102, Validation cost= 2.3026, Validation acc= 0.7097
Epoch 76760: Training cost= 2.3026, Training acc= 0.7101, Validation cost= 2.3026, Validation acc= 0.7097
Epoch 76770: Training cost= 2.3026, Training acc= 0.7100, Validation cost= 2.3026, Validation acc= 0.7096
Epoch 76780: Training cost= 2.3026, Training acc= 0.7099, Validation cost= 2.3026, Validation acc= 0.7095
Epoch 76790: Training cost= 2.3026, Training acc= 0.7098, Validation cost= 2.3026, Validation acc= 0.7094
Epoch 76800: Training cost= 2.3026, Training acc= 0.7098, Validation cost= 2.3026, Validation acc= 0.7093
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 1 3 2 9 8 0 6 5 7]
 [2 0 8 6 4 1 9 7 3 5]
 [7 1 8 9 6 3 4 5 2 0]
 [7 9 0 4 5 6 1 2 3 8]
 [1 6 9 4 0 2 8 3 7 5]
 [4 3 1 8 5 9 7 0 6 2]
 [6 4 2 1 7 9 8 3 5 0]
 [0 4 9 1 7 6 8 5 2 3]
 [9 0 2 6 3 5 7 4 8 1]
 [6 7 1 5 3 4 9 8 2 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 6 9 3 2 5 1 0 7 8]
 [5 4 9 6 2 0 7 1 8 3]
 [9 0 3 6 1 8 4 2 5 7]
 [2 1 3 6 8 0 9 5 7 4]
 [5 7 3 9 0 2 8 1 6 4]
 [6 7 3 9 8 2 5 0 4 1]
 [3 4 1 2 8 7 6 0 5 9]
 [5 9 0 2 3 7 6 8 4 1]
 [1 6 2 3 8 5 4 0 7 9]
 [2 1 5 7 8 0 4 6 3 9]]
Epoch 76810: Training cost= 2.3026, Training acc= 0.7097, Validation cost= 2.3026, Validation acc= 0.7093
Epoch 76820: Training cost= 2.3026, Training acc= 0.7096, Validation cost= 2.3026, Validation acc= 0.7092
Epoch 76830: Training cost= 2.3026, Training acc= 0.7095, Validation cost= 2.3026, Validation acc= 0.7091
Epoch 76840: Training cost= 2.3026, Training acc= 0.7094, Validation cost= 2.3026, Validation acc= 0.7090
Epoch 76850: Training cost= 2.3026, Training acc= 0.7094, Validation cost= 2.3026, Validation acc= 0.7089
Epoch 76860: Training cost= 2.3026, Training acc= 0.7093, Validation cost= 2.3026, Validation acc= 0.7089
Epoch 76870: Training cost= 2.3026, Training acc= 0.7092, Validation cost= 2.3026, Validation acc= 0.7088
Epoch 76880: Training cost= 2.3026, Training acc= 0.7091, Validation cost= 2.3026, Validation acc= 0.7087
Epoch 76890: Training cost= 2.3026, Training acc= 0.7090, Validation cost= 2.3026, Validation acc= 0.7086
Epoch 76900: Training cost= 2.3026, Training acc= 0.7090, Validation cost= 2.3026, Validation acc= 0.7086
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 2 8 9 7 3 1 4 0 6]
 [8 2 3 1 0 6 7 9 5 4]
 [2 9 7 8 5 6 1 0 4 3]
 [5 1 4 6 3 8 2 7 0 9]
 [2 7 0 5 9 8 1 4 6 3]
 [7 6 9 2 5 1 3 0 4 8]
 [7 8 3 1 9 5 2 0 6 4]
 [0 4 1 5 6 3 2 9 7 8]
 [0 7 8 4 2 3 6 9 5 1]
 [3 7 9 0 2 5 6 4 1 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 1 9 7 6 4 2 8 5 0]
 [3 8 2 1 6 9 5 0 4 7]
 [9 6 8 5 3 4 7 1 2 0]
 [7 3 6 1 8 9 2 0 4 5]
 [1 8 4 6 9 0 7 3 5 2]
 [7 1 5 6 8 4 0 9 2 3]
 [4 2 3 7 5 0 9 1 8 6]
 [0 8 4 7 6 9 2 1 3 5]
 [5 7 9 0 6 2 1 4 8 3]
 [2 9 1 4 3 0 7 5 6 8]]
Epoch 76910: Training cost= 2.3026, Training acc= 0.7089, Validation cost= 2.3026, Validation acc= 0.7085
Epoch 76920: Training cost= 2.3026, Training acc= 0.7088, Validation cost= 2.3026, Validation acc= 0.7084
Epoch 76930: Training cost= 2.3026, Training acc= 0.7087, Validation cost= 2.3026, Validation acc= 0.7083
Epoch 76940: Training cost= 2.3026, Training acc= 0.7086, Validation cost= 2.3026, Validation acc= 0.7082
Epoch 76950: Training cost= 2.3026, Training acc= 0.7086, Validation cost= 2.3026, Validation acc= 0.7082
Epoch 76960: Training cost= 2.3026, Training acc= 0.7085, Validation cost= 2.3026, Validation acc= 0.7081
Epoch 76970: Training cost= 2.3026, Training acc= 0.7084, Validation cost= 2.3026, Validation acc= 0.7080
Epoch 76980: Training cost= 2.3026, Training acc= 0.7083, Validation cost= 2.3026, Validation acc= 0.7079
Epoch 76990: Training cost= 2.3026, Training acc= 0.7083, Validation cost= 2.3026, Validation acc= 0.7078
Epoch 77000: Training cost= 2.3026, Training acc= 0.7082, Validation cost= 2.3026, Validation acc= 0.7078
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 6 7 5 3 1 8 0 9 2]
 [9 7 2 1 3 0 5 6 4 8]
 [9 6 1 2 5 7 8 0 4 3]
 [7 9 5 8 6 2 1 3 0 4]
 [5 9 6 7 8 1 4 0 2 3]
 [0 8 5 6 7 2 3 1 9 4]
 [6 3 8 0 2 5 9 7 1 4]
 [4 3 9 6 1 7 8 2 0 5]
 [8 4 1 0 3 2 6 7 9 5]
 [4 2 1 9 5 3 7 0 6 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 6 8 0 2 3 1 7 5 4]
 [4 1 0 3 2 8 5 7 9 6]
 [1 2 9 5 7 3 0 6 8 4]
 [8 0 3 6 9 2 1 5 4 7]
 [7 4 1 9 5 3 6 0 2 8]
 [8 7 6 2 1 0 3 9 5 4]
 [1 9 5 4 6 7 2 8 3 0]
 [1 7 5 9 0 2 6 8 4 3]
 [9 5 6 0 3 4 7 2 8 1]
 [1 6 3 5 4 9 7 2 0 8]]
Epoch 77010: Training cost= 2.3026, Training acc= 0.7081, Validation cost= 2.3026, Validation acc= 0.7077
Epoch 77020: Training cost= 2.3026, Training acc= 0.7080, Validation cost= 2.3026, Validation acc= 0.7076
Epoch 77030: Training cost= 2.3026, Training acc= 0.7079, Validation cost= 2.3026, Validation acc= 0.7075
Epoch 77040: Training cost= 2.3026, Training acc= 0.7079, Validation cost= 2.3026, Validation acc= 0.7074
Epoch 77050: Training cost= 2.3026, Training acc= 0.7078, Validation cost= 2.3026, Validation acc= 0.7074
Epoch 77060: Training cost= 2.3026, Training acc= 0.7077, Validation cost= 2.3026, Validation acc= 0.7073
Epoch 77070: Training cost= 2.3026, Training acc= 0.7076, Validation cost= 2.3026, Validation acc= 0.7072
Epoch 77080: Training cost= 2.3026, Training acc= 0.7075, Validation cost= 2.3026, Validation acc= 0.7071
Epoch 77090: Training cost= 2.3026, Training acc= 0.7075, Validation cost= 2.3026, Validation acc= 0.7071
Epoch 77100: Training cost= 2.3026, Training acc= 0.7074, Validation cost= 2.3026, Validation acc= 0.7070
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 7 4 5 8 1 3 2 9 6]
 [9 1 5 6 2 4 8 7 0 3]
 [1 8 6 5 0 3 2 4 7 9]
 [7 2 9 6 0 4 1 5 3 8]
 [3 8 9 2 1 7 4 0 6 5]
 [3 8 1 5 4 6 7 9 2 0]
 [3 5 9 4 1 7 2 0 6 8]
 [8 1 4 2 9 3 0 5 7 6]
 [0 6 7 2 9 8 5 3 4 1]
 [7 4 5 1 2 9 3 0 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 9 6 0 7 2 8 1 5]
 [6 8 2 7 1 3 9 4 5 0]
 [1 7 3 0 4 8 2 5 9 6]
 [4 1 5 2 8 9 3 0 7 6]
 [7 0 3 2 6 5 8 4 1 9]
 [4 8 2 5 3 9 0 7 6 1]
 [4 7 3 6 8 5 1 0 2 9]
 [9 4 2 0 6 8 7 5 3 1]
 [7 4 5 1 3 2 0 8 6 9]
 [8 1 3 7 0 9 2 4 6 5]]
Epoch 77110: Training cost= 2.3026, Training acc= 0.7073, Validation cost= 2.3026, Validation acc= 0.7069
Epoch 77120: Training cost= 2.3026, Training acc= 0.7072, Validation cost= 2.3026, Validation acc= 0.7068
Epoch 77130: Training cost= 2.3026, Training acc= 0.7072, Validation cost= 2.3026, Validation acc= 0.7067
Epoch 77140: Training cost= 2.3026, Training acc= 0.7071, Validation cost= 2.3026, Validation acc= 0.7067
Epoch 77150: Training cost= 2.3026, Training acc= 0.7070, Validation cost= 2.3026, Validation acc= 0.7066
Epoch 77160: Training cost= 2.3026, Training acc= 0.7069, Validation cost= 2.3026, Validation acc= 0.7065
Epoch 77170: Training cost= 2.3026, Training acc= 0.7068, Validation cost= 2.3026, Validation acc= 0.7064
Epoch 77180: Training cost= 2.3026, Training acc= 0.7068, Validation cost= 2.3026, Validation acc= 0.7063
Epoch 77190: Training cost= 2.3026, Training acc= 0.7067, Validation cost= 2.3026, Validation acc= 0.7063
Epoch 77200: Training cost= 2.3026, Training acc= 0.7066, Validation cost= 2.3026, Validation acc= 0.7062
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 4 9 8 1 6 7 2 3 0]
 [9 1 6 0 5 7 8 4 3 2]
 [2 0 1 7 4 5 9 6 3 8]
 [3 7 1 0 5 4 9 6 8 2]
 [1 7 2 8 5 6 9 3 0 4]
 [4 9 3 8 6 0 1 2 5 7]
 [7 4 1 3 9 5 6 8 2 0]
 [7 5 9 4 1 0 2 6 8 3]
 [1 3 5 0 2 4 9 7 6 8]
 [7 4 5 6 2 9 3 1 8 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 7 1 0 2 6 5 4 9 3]
 [2 6 9 7 0 3 5 8 1 4]
 [1 5 3 9 8 7 4 0 2 6]
 [5 0 2 3 1 6 8 9 7 4]
 [7 6 1 0 4 3 2 5 9 8]
 [4 7 2 5 6 9 1 3 8 0]
 [6 0 1 9 8 5 3 4 2 7]
 [5 6 1 2 0 9 4 3 8 7]
 [8 3 9 1 6 4 7 2 5 0]
 [3 0 7 9 1 2 5 4 6 8]]
Epoch 77210: Training cost= 2.3026, Training acc= 0.7065, Validation cost= 2.3026, Validation acc= 0.7061
Epoch 77220: Training cost= 2.3026, Training acc= 0.7064, Validation cost= 2.3026, Validation acc= 0.7060
Epoch 77230: Training cost= 2.3026, Training acc= 0.7064, Validation cost= 2.3026, Validation acc= 0.7060
Epoch 77240: Training cost= 2.3026, Training acc= 0.7063, Validation cost= 2.3026, Validation acc= 0.7059
Epoch 77250: Training cost= 2.3026, Training acc= 0.7062, Validation cost= 2.3026, Validation acc= 0.7058
Epoch 77260: Training cost= 2.3026, Training acc= 0.7061, Validation cost= 2.3026, Validation acc= 0.7057
Epoch 77270: Training cost= 2.3026, Training acc= 0.7061, Validation cost= 2.3026, Validation acc= 0.7056
Epoch 77280: Training cost= 2.3026, Training acc= 0.7060, Validation cost= 2.3026, Validation acc= 0.7056
Epoch 77290: Training cost= 2.3026, Training acc= 0.7059, Validation cost= 2.3026, Validation acc= 0.7055
Epoch 77300: Training cost= 2.3026, Training acc= 0.7058, Validation cost= 2.3026, Validation acc= 0.7054
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 7 2 0 5 4 3 8 1 9]
 [9 5 8 2 3 0 7 4 1 6]
 [3 4 9 5 6 2 0 1 7 8]
 [7 0 8 5 6 2 9 3 1 4]
 [7 4 5 6 8 1 9 2 3 0]
 [8 5 3 1 9 2 7 4 6 0]
 [0 9 6 1 8 2 7 5 3 4]
 [1 9 7 5 4 6 3 0 8 2]
 [9 7 2 6 5 1 8 0 4 3]
 [3 6 9 8 5 0 2 7 4 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 0 9 2 6 7 5 8 4 3]
 [7 6 0 9 5 1 4 8 2 3]
 [9 2 4 7 1 5 8 3 6 0]
 [9 8 2 5 4 3 6 7 0 1]
 [7 5 0 8 6 1 2 3 9 4]
 [6 5 9 1 3 2 8 4 0 7]
 [1 6 8 7 4 9 5 3 0 2]
 [9 2 5 6 0 3 4 1 8 7]
 [9 2 6 1 7 8 0 3 4 5]
 [6 4 3 1 2 8 0 5 7 9]]
Epoch 77310: Training cost= 2.3026, Training acc= 0.7057, Validation cost= 2.3026, Validation acc= 0.7053
Epoch 77320: Training cost= 2.3026, Training acc= 0.7057, Validation cost= 2.3026, Validation acc= 0.7052
Epoch 77330: Training cost= 2.3026, Training acc= 0.7056, Validation cost= 2.3026, Validation acc= 0.7052
Epoch 77340: Training cost= 2.3026, Training acc= 0.7055, Validation cost= 2.3026, Validation acc= 0.7051
Epoch 77350: Training cost= 2.3026, Training acc= 0.7054, Validation cost= 2.3026, Validation acc= 0.7050
Epoch 77360: Training cost= 2.3026, Training acc= 0.7053, Validation cost= 2.3026, Validation acc= 0.7049
Epoch 77370: Training cost= 2.3026, Training acc= 0.7053, Validation cost= 2.3026, Validation acc= 0.7049
Epoch 77380: Training cost= 2.3026, Training acc= 0.7052, Validation cost= 2.3026, Validation acc= 0.7048
Epoch 77390: Training cost= 2.3026, Training acc= 0.7051, Validation cost= 2.3026, Validation acc= 0.7047
Epoch 77400: Training cost= 2.3026, Training acc= 0.7050, Validation cost= 2.3026, Validation acc= 0.7046
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 5 3 2 4 9 6 1 7 8]
 [3 1 0 4 2 9 6 8 5 7]
 [7 9 5 0 8 2 1 4 6 3]
 [7 1 6 8 2 4 0 5 3 9]
 [0 6 3 5 1 8 2 9 4 7]
 [7 8 3 1 6 4 0 9 5 2]
 [8 2 0 1 9 3 4 7 6 5]
 [6 5 2 7 3 4 8 9 1 0]
 [6 3 4 1 7 2 5 0 8 9]
 [0 5 6 1 4 2 8 3 7 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 0 6 4 8 7 9 1 3 2]
 [7 2 4 9 6 0 5 8 1 3]
 [2 3 4 8 5 6 7 9 0 1]
 [0 3 7 4 5 6 2 9 8 1]
 [3 7 8 9 5 2 0 6 4 1]
 [0 9 5 3 2 6 4 1 8 7]
 [8 5 6 0 7 3 1 9 4 2]
 [1 4 9 6 3 2 5 8 0 7]
 [0 2 6 1 3 8 4 7 9 5]
 [1 6 9 4 5 0 3 8 2 7]]
Epoch 77410: Training cost= 2.3026, Training acc= 0.7050, Validation cost= 2.3026, Validation acc= 0.7045
Epoch 77420: Training cost= 2.3026, Training acc= 0.7049, Validation cost= 2.3026, Validation acc= 0.7045
Epoch 77430: Training cost= 2.3026, Training acc= 0.7048, Validation cost= 2.3026, Validation acc= 0.7044
Epoch 77440: Training cost= 2.3026, Training acc= 0.7047, Validation cost= 2.3026, Validation acc= 0.7043
Epoch 77450: Training cost= 2.3026, Training acc= 0.7046, Validation cost= 2.3026, Validation acc= 0.7042
Epoch 77460: Training cost= 2.3026, Training acc= 0.7046, Validation cost= 2.3026, Validation acc= 0.7042
Epoch 77470: Training cost= 2.3026, Training acc= 0.7045, Validation cost= 2.3026, Validation acc= 0.7041
Epoch 77480: Training cost= 2.3026, Training acc= 0.7044, Validation cost= 2.3026, Validation acc= 0.7040
Epoch 77490: Training cost= 2.3026, Training acc= 0.7043, Validation cost= 2.3026, Validation acc= 0.7039
Epoch 77500: Training cost= 2.3026, Training acc= 0.7043, Validation cost= 2.3026, Validation acc= 0.7038
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 8 0 3 5 7 9 6 1 2]
 [9 7 4 1 0 2 6 5 8 3]
 [0 5 2 7 8 4 1 3 9 6]
 [7 0 4 6 3 9 1 8 5 2]
 [6 9 5 4 2 7 8 0 3 1]
 [4 3 2 9 6 1 8 7 0 5]
 [7 8 1 0 6 9 4 3 5 2]
 [3 5 4 1 7 0 9 6 8 2]
 [5 0 8 1 7 2 6 9 4 3]
 [7 9 5 2 4 1 3 8 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 0 1 6 8 2 7 3 9 5]
 [9 2 6 7 1 3 0 8 4 5]
 [6 7 9 5 2 3 8 0 4 1]
 [2 0 3 5 9 8 7 6 4 1]
 [7 1 3 5 6 8 2 9 4 0]
 [8 2 5 9 4 3 0 7 6 1]
 [4 3 9 2 8 7 1 5 0 6]
 [4 6 7 3 5 0 1 8 2 9]
 [7 2 9 5 1 0 3 6 4 8]
 [9 3 8 4 0 5 1 2 6 7]]
Epoch 77510: Training cost= 2.3026, Training acc= 0.7042, Validation cost= 2.3026, Validation acc= 0.7038
Epoch 77520: Training cost= 2.3026, Training acc= 0.7041, Validation cost= 2.3026, Validation acc= 0.7037
Epoch 77530: Training cost= 2.3026, Training acc= 0.7040, Validation cost= 2.3026, Validation acc= 0.7036
Epoch 77540: Training cost= 2.3026, Training acc= 0.7039, Validation cost= 2.3026, Validation acc= 0.7035
Epoch 77550: Training cost= 2.3026, Training acc= 0.7039, Validation cost= 2.3026, Validation acc= 0.7035
Epoch 77560: Training cost= 2.3026, Training acc= 0.7038, Validation cost= 2.3026, Validation acc= 0.7034
Epoch 77570: Training cost= 2.3026, Training acc= 0.7037, Validation cost= 2.3026, Validation acc= 0.7033
Epoch 77580: Training cost= 2.3026, Training acc= 0.7036, Validation cost= 2.3026, Validation acc= 0.7032
Epoch 77590: Training cost= 2.3026, Training acc= 0.7036, Validation cost= 2.3026, Validation acc= 0.7031
Epoch 77600: Training cost= 2.3026, Training acc= 0.7035, Validation cost= 2.3026, Validation acc= 0.7031
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 9 6 1 8 3 4 5 7 2]
 [3 1 6 9 2 4 7 5 0 8]
 [8 3 0 5 7 9 6 1 4 2]
 [5 6 0 1 8 4 9 7 2 3]
 [3 9 1 4 2 6 0 8 7 5]
 [5 2 3 1 4 6 9 7 0 8]
 [7 1 8 3 5 0 9 6 2 4]
 [9 4 6 0 5 3 8 2 1 7]
 [3 7 2 1 5 6 8 4 9 0]
 [0 3 7 5 2 4 6 9 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 8 5 3 4 7 6 9 0 2]
 [5 7 3 6 0 4 2 8 1 9]
 [9 6 0 2 7 3 5 8 1 4]
 [0 1 3 5 8 9 4 7 2 6]
 [0 3 8 6 2 4 1 5 9 7]
 [9 4 7 5 6 1 0 2 3 8]
 [7 9 4 5 0 1 2 3 6 8]
 [4 9 7 5 3 2 8 6 0 1]
 [6 3 1 5 0 8 7 9 4 2]
 [8 9 4 5 3 1 2 6 7 0]]
Epoch 77610: Training cost= 2.3026, Training acc= 0.7034, Validation cost= 2.3026, Validation acc= 0.7030
Epoch 77620: Training cost= 2.3026, Training acc= 0.7033, Validation cost= 2.3026, Validation acc= 0.7029
Epoch 77630: Training cost= 2.3026, Training acc= 0.7032, Validation cost= 2.3026, Validation acc= 0.7028
Epoch 77640: Training cost= 2.3026, Training acc= 0.7032, Validation cost= 2.3026, Validation acc= 0.7028
Epoch 77650: Training cost= 2.3026, Training acc= 0.7031, Validation cost= 2.3026, Validation acc= 0.7027
Epoch 77660: Training cost= 2.3026, Training acc= 0.7030, Validation cost= 2.3026, Validation acc= 0.7026
Epoch 77670: Training cost= 2.3026, Training acc= 0.7029, Validation cost= 2.3026, Validation acc= 0.7025
Epoch 77680: Training cost= 2.3026, Training acc= 0.7029, Validation cost= 2.3026, Validation acc= 0.7024
Epoch 77690: Training cost= 2.3026, Training acc= 0.7028, Validation cost= 2.3026, Validation acc= 0.7024
Epoch 77700: Training cost= 2.3026, Training acc= 0.7027, Validation cost= 2.3026, Validation acc= 0.7023
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 7 5 4 9 1 2 6 3 8]
 [0 7 4 6 5 9 1 3 8 2]
 [1 4 7 9 2 8 5 6 0 3]
 [5 1 8 3 2 7 9 6 0 4]
 [0 8 1 4 3 7 6 9 2 5]
 [6 7 3 0 2 4 9 5 1 8]
 [4 1 2 7 0 3 6 5 8 9]
 [3 1 4 2 7 0 8 6 9 5]
 [6 1 7 3 4 0 2 9 8 5]
 [0 8 5 4 6 3 9 2 1 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 0 1 7 6 4 2 9 8]
 [0 7 1 5 6 2 4 9 8 3]
 [7 4 3 0 1 9 8 6 2 5]
 [8 7 6 9 4 2 3 0 1 5]
 [8 9 2 7 3 5 6 1 0 4]
 [5 1 4 7 3 6 2 8 0 9]
 [9 5 7 0 6 8 3 1 2 4]
 [6 4 5 3 2 7 8 9 0 1]
 [4 7 6 1 9 5 3 0 2 8]
 [7 9 4 6 3 1 0 5 2 8]]
Epoch 77710: Training cost= 2.3026, Training acc= 0.7026, Validation cost= 2.3026, Validation acc= 0.7022
Epoch 77720: Training cost= 2.3026, Training acc= 0.7025, Validation cost= 2.3026, Validation acc= 0.7021
Epoch 77730: Training cost= 2.3026, Training acc= 0.7025, Validation cost= 2.3026, Validation acc= 0.7021
Epoch 77740: Training cost= 2.3026, Training acc= 0.7024, Validation cost= 2.3026, Validation acc= 0.7020
Epoch 77750: Training cost= 2.3026, Training acc= 0.7023, Validation cost= 2.3026, Validation acc= 0.7019
Epoch 77760: Training cost= 2.3026, Training acc= 0.7022, Validation cost= 2.3026, Validation acc= 0.7018
Epoch 77770: Training cost= 2.3026, Training acc= 0.7022, Validation cost= 2.3026, Validation acc= 0.7017
Epoch 77780: Training cost= 2.3026, Training acc= 0.7021, Validation cost= 2.3026, Validation acc= 0.7017
Epoch 77790: Training cost= 2.3026, Training acc= 0.7020, Validation cost= 2.3026, Validation acc= 0.7016
Epoch 77800: Training cost= 2.3026, Training acc= 0.7019, Validation cost= 2.3026, Validation acc= 0.7015
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 3 1 9 8 0 7 4 5 6]
 [5 3 8 4 7 6 0 2 1 9]
 [2 6 3 9 0 4 7 1 5 8]
 [6 9 8 5 3 2 4 0 7 1]
 [0 8 7 6 2 1 3 9 4 5]
 [4 3 2 1 7 9 5 8 0 6]
 [0 5 8 1 7 2 6 9 3 4]
 [1 5 9 4 6 7 2 3 8 0]
 [8 9 7 3 6 4 0 2 5 1]
 [5 1 3 0 7 8 9 4 6 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 7 8 4 6 9 5 3 0 2]
 [3 9 5 0 7 8 2 4 6 1]
 [7 5 1 9 8 2 6 4 3 0]
 [4 8 9 0 6 2 3 1 7 5]
 [6 2 9 0 8 5 1 4 3 7]
 [3 5 0 4 7 8 2 9 6 1]
 [9 1 2 8 3 4 5 7 6 0]
 [3 6 0 1 4 2 9 5 7 8]
 [9 2 4 0 5 1 7 3 6 8]
 [8 2 5 4 9 0 1 6 3 7]]
Epoch 77810: Training cost= 2.3026, Training acc= 0.7018, Validation cost= 2.3026, Validation acc= 0.7014
Epoch 77820: Training cost= 2.3026, Training acc= 0.7018, Validation cost= 2.3026, Validation acc= 0.7014
Epoch 77830: Training cost= 2.3026, Training acc= 0.7017, Validation cost= 2.3026, Validation acc= 0.7013
Epoch 77840: Training cost= 2.3026, Training acc= 0.7016, Validation cost= 2.3026, Validation acc= 0.7012
Epoch 77850: Training cost= 2.3026, Training acc= 0.7015, Validation cost= 2.3026, Validation acc= 0.7011
Epoch 77860: Training cost= 2.3026, Training acc= 0.7015, Validation cost= 2.3026, Validation acc= 0.7010
Epoch 77870: Training cost= 2.3026, Training acc= 0.7014, Validation cost= 2.3026, Validation acc= 0.7010
Epoch 77880: Training cost= 2.3026, Training acc= 0.7013, Validation cost= 2.3026, Validation acc= 0.7009
Epoch 77890: Training cost= 2.3026, Training acc= 0.7012, Validation cost= 2.3026, Validation acc= 0.7008
Epoch 77900: Training cost= 2.3026, Training acc= 0.7011, Validation cost= 2.3026, Validation acc= 0.7007
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 6 4 8 0 3 1 9 7 5]
 [2 7 9 4 0 6 3 8 1 5]
 [1 9 2 6 4 7 3 0 8 5]
 [6 7 9 1 5 0 4 8 3 2]
 [5 6 8 4 2 3 0 1 9 7]
 [5 1 7 0 2 4 8 9 6 3]
 [8 0 3 5 9 7 2 4 1 6]
 [2 1 8 3 9 0 5 6 4 7]
 [5 2 1 9 8 4 0 6 7 3]
 [6 1 7 3 4 5 0 8 9 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 2 8 1 7 9 6 0 5 3]
 [2 6 7 1 3 8 0 4 5 9]
 [1 6 4 9 2 5 7 8 0 3]
 [9 1 0 5 4 3 2 7 8 6]
 [5 1 3 7 9 8 6 0 2 4]
 [4 0 8 3 6 1 5 7 2 9]
 [8 5 7 9 4 1 3 0 2 6]
 [9 5 7 1 4 2 3 6 8 0]
 [4 7 0 2 3 1 5 8 9 6]
 [0 6 1 2 9 5 8 4 3 7]]
Epoch 77910: Training cost= 2.3026, Training acc= 0.7011, Validation cost= 2.3026, Validation acc= 0.7007
Epoch 77920: Training cost= 2.3026, Training acc= 0.7010, Validation cost= 2.3026, Validation acc= 0.7006
Epoch 77930: Training cost= 2.3026, Training acc= 0.7009, Validation cost= 2.3026, Validation acc= 0.7005
Epoch 77940: Training cost= 2.3026, Training acc= 0.7008, Validation cost= 2.3026, Validation acc= 0.7004
Epoch 77950: Training cost= 2.3026, Training acc= 0.7008, Validation cost= 2.3026, Validation acc= 0.7004
Epoch 77960: Training cost= 2.3026, Training acc= 0.7007, Validation cost= 2.3026, Validation acc= 0.7003
Epoch 77970: Training cost= 2.3026, Training acc= 0.7006, Validation cost= 2.3026, Validation acc= 0.7002
Epoch 77980: Training cost= 2.3026, Training acc= 0.7005, Validation cost= 2.3026, Validation acc= 0.7001
Epoch 77990: Training cost= 2.3026, Training acc= 0.7005, Validation cost= 2.3026, Validation acc= 0.7000
Epoch 78000: Training cost= 2.3026, Training acc= 0.7004, Validation cost= 2.3026, Validation acc= 0.7000
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 0 6 1 4 7 8 9 3 2]
 [9 8 3 7 5 4 6 0 1 2]
 [2 4 9 5 3 0 8 1 6 7]
 [8 6 2 9 7 1 5 4 3 0]
 [3 8 5 6 9 0 7 4 2 1]
 [8 7 6 1 4 9 3 5 2 0]
 [0 8 6 9 4 1 3 5 2 7]
 [3 1 4 2 9 6 8 7 0 5]
 [7 0 3 2 8 6 4 9 1 5]
 [7 1 9 0 5 2 4 3 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 0 5 1 6 4 2 7 8 3]
 [5 6 1 7 0 3 2 4 8 9]
 [6 5 0 2 8 7 9 1 4 3]
 [5 4 9 7 3 2 8 0 6 1]
 [4 2 7 8 0 1 9 3 5 6]
 [9 0 5 8 1 7 2 4 3 6]
 [9 0 1 3 7 2 6 8 4 5]
 [4 5 7 8 1 0 2 9 3 6]
 [0 2 9 4 5 7 1 3 8 6]
 [7 6 9 2 0 1 5 3 8 4]]
Epoch 78010: Training cost= 2.3026, Training acc= 0.7003, Validation cost= 2.3026, Validation acc= 0.6999
Epoch 78020: Training cost= 2.3026, Training acc= 0.7002, Validation cost= 2.3026, Validation acc= 0.6998
Epoch 78030: Training cost= 2.3026, Training acc= 0.7001, Validation cost= 2.3026, Validation acc= 0.6997
Epoch 78040: Training cost= 2.3026, Training acc= 0.7001, Validation cost= 2.3026, Validation acc= 0.6997
Epoch 78050: Training cost= 2.3026, Training acc= 0.7000, Validation cost= 2.3026, Validation acc= 0.6996
Epoch 78060: Training cost= 2.3026, Training acc= 0.6999, Validation cost= 2.3026, Validation acc= 0.6995
Epoch 78070: Training cost= 2.3026, Training acc= 0.6998, Validation cost= 2.3026, Validation acc= 0.6994
Epoch 78080: Training cost= 2.3026, Training acc= 0.6998, Validation cost= 2.3026, Validation acc= 0.6994
Epoch 78090: Training cost= 2.3026, Training acc= 0.6997, Validation cost= 2.3026, Validation acc= 0.6993
Epoch 78100: Training cost= 2.3026, Training acc= 0.6996, Validation cost= 2.3026, Validation acc= 0.6992
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 1 3 4 9 5 6 7 0 2]
 [0 8 4 5 2 9 1 6 7 3]
 [8 5 4 2 3 0 7 6 1 9]
 [3 1 6 5 0 8 9 4 7 2]
 [7 3 2 9 8 4 6 1 5 0]
 [7 5 4 8 2 1 6 9 3 0]
 [8 1 0 5 9 7 2 6 3 4]
 [7 9 0 6 4 1 8 5 2 3]
 [8 6 7 9 5 0 3 1 4 2]
 [0 2 5 9 1 4 6 8 7 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 5 3 9 4 8 2 6 7 0]
 [2 7 9 3 0 4 5 8 6 1]
 [7 2 3 5 6 9 8 0 1 4]
 [2 6 3 1 8 0 7 9 5 4]
 [5 4 6 3 8 1 9 0 7 2]
 [2 7 3 4 5 0 6 8 9 1]
 [7 3 4 0 2 1 5 6 8 9]
 [6 1 9 5 0 8 4 2 3 7]
 [8 3 9 5 7 2 0 4 6 1]
 [8 1 0 7 9 3 2 5 6 4]]
Epoch 78110: Training cost= 2.3026, Training acc= 0.6995, Validation cost= 2.3026, Validation acc= 0.6991
Epoch 78120: Training cost= 2.3026, Training acc= 0.6995, Validation cost= 2.3026, Validation acc= 0.6990
Epoch 78130: Training cost= 2.3026, Training acc= 0.6994, Validation cost= 2.3026, Validation acc= 0.6990
Epoch 78140: Training cost= 2.3026, Training acc= 0.6993, Validation cost= 2.3026, Validation acc= 0.6989
Epoch 78150: Training cost= 2.3026, Training acc= 0.6992, Validation cost= 2.3026, Validation acc= 0.6988
Epoch 78160: Training cost= 2.3026, Training acc= 0.6991, Validation cost= 2.3026, Validation acc= 0.6987
Epoch 78170: Training cost= 2.3026, Training acc= 0.6991, Validation cost= 2.3026, Validation acc= 0.6987
Epoch 78180: Training cost= 2.3026, Training acc= 0.6990, Validation cost= 2.3026, Validation acc= 0.6986
Epoch 78190: Training cost= 2.3026, Training acc= 0.6989, Validation cost= 2.3026, Validation acc= 0.6985
Epoch 78200: Training cost= 2.3026, Training acc= 0.6988, Validation cost= 2.3026, Validation acc= 0.6984
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 0 5 4 7 1 3 2 6 9]
 [3 5 2 8 4 1 7 9 6 0]
 [8 5 7 6 1 3 4 2 0 9]
 [7 3 6 9 0 8 2 5 4 1]
 [6 2 8 5 3 9 4 1 7 0]
 [3 8 1 4 9 7 0 2 6 5]
 [7 4 2 3 5 0 8 6 1 9]
 [9 4 1 7 6 8 0 5 3 2]
 [8 7 1 9 4 6 0 2 5 3]
 [6 0 7 8 2 3 1 4 5 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 9 2 4 1 6 5 7 8 3]
 [6 1 0 7 2 5 4 3 8 9]
 [7 0 6 4 2 1 3 9 8 5]
 [5 7 4 1 6 2 0 9 8 3]
 [8 2 0 3 1 4 6 7 9 5]
 [3 4 9 6 1 2 7 8 5 0]
 [2 0 6 7 3 8 4 5 1 9]
 [5 6 0 3 7 9 2 1 4 8]
 [0 1 5 9 3 2 7 6 4 8]
 [1 5 6 3 8 0 2 4 9 7]]
Epoch 78210: Training cost= 2.3026, Training acc= 0.6988, Validation cost= 2.3026, Validation acc= 0.6984
Epoch 78220: Training cost= 2.3026, Training acc= 0.6987, Validation cost= 2.3026, Validation acc= 0.6983
Epoch 78230: Training cost= 2.3026, Training acc= 0.6986, Validation cost= 2.3026, Validation acc= 0.6982
Epoch 78240: Training cost= 2.3026, Training acc= 0.6985, Validation cost= 2.3026, Validation acc= 0.6981
Epoch 78250: Training cost= 2.3026, Training acc= 0.6985, Validation cost= 2.3026, Validation acc= 0.6981
Epoch 78260: Training cost= 2.3026, Training acc= 0.6984, Validation cost= 2.3026, Validation acc= 0.6980
Epoch 78270: Training cost= 2.3026, Training acc= 0.6983, Validation cost= 2.3026, Validation acc= 0.6979
Epoch 78280: Training cost= 2.3026, Training acc= 0.6982, Validation cost= 2.3026, Validation acc= 0.6978
Epoch 78290: Training cost= 2.3026, Training acc= 0.6982, Validation cost= 2.3026, Validation acc= 0.6977
Epoch 78300: Training cost= 2.3026, Training acc= 0.6981, Validation cost= 2.3026, Validation acc= 0.6977
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 4 5 3 0 2 8 6 9 7]
 [1 8 5 4 9 7 0 3 2 6]
 [8 7 4 0 3 9 5 6 2 1]
 [6 2 5 8 4 7 9 0 1 3]
 [6 7 3 1 9 4 0 8 5 2]
 [0 4 9 3 1 2 7 5 8 6]
 [7 3 1 9 6 0 5 8 2 4]
 [3 5 7 2 8 9 0 4 1 6]
 [3 2 6 8 5 7 1 4 0 9]
 [7 4 8 2 6 1 0 3 9 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 3 4 7 9 1 5 2 6 8]
 [6 4 1 3 2 7 5 8 9 0]
 [6 8 2 4 7 0 5 3 1 9]
 [7 4 2 8 6 3 0 1 5 9]
 [8 5 6 2 0 9 4 1 7 3]
 [6 2 4 3 9 5 1 8 7 0]
 [2 7 8 9 5 1 3 0 4 6]
 [9 8 2 5 1 6 3 0 7 4]
 [8 1 0 2 9 4 5 6 7 3]
 [7 5 2 1 6 0 8 9 3 4]]
Epoch 78310: Training cost= 2.3026, Training acc= 0.6980, Validation cost= 2.3026, Validation acc= 0.6976
Epoch 78320: Training cost= 2.3026, Training acc= 0.6979, Validation cost= 2.3026, Validation acc= 0.6975
Epoch 78330: Training cost= 2.3026, Training acc= 0.6978, Validation cost= 2.3026, Validation acc= 0.6974
Epoch 78340: Training cost= 2.3026, Training acc= 0.6978, Validation cost= 2.3026, Validation acc= 0.6974
Epoch 78350: Training cost= 2.3026, Training acc= 0.6977, Validation cost= 2.3026, Validation acc= 0.6973
Epoch 78360: Training cost= 2.3026, Training acc= 0.6976, Validation cost= 2.3026, Validation acc= 0.6972
Epoch 78370: Training cost= 2.3026, Training acc= 0.6975, Validation cost= 2.3026, Validation acc= 0.6971
Epoch 78380: Training cost= 2.3026, Training acc= 0.6975, Validation cost= 2.3026, Validation acc= 0.6971
Epoch 78390: Training cost= 2.3026, Training acc= 0.6974, Validation cost= 2.3026, Validation acc= 0.6970
Epoch 78400: Training cost= 2.3026, Training acc= 0.6973, Validation cost= 2.3026, Validation acc= 0.6969
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 5 7 3 8 4 9 0 2 6]
 [0 2 4 3 9 1 7 6 5 8]
 [6 8 9 2 7 0 1 3 5 4]
 [0 4 1 5 3 7 9 8 2 6]
 [4 6 9 0 2 1 7 8 3 5]
 [5 4 1 6 7 3 8 9 2 0]
 [1 6 9 2 8 3 4 0 5 7]
 [5 4 0 1 8 2 7 6 3 9]
 [6 1 3 7 5 0 9 8 4 2]
 [9 8 4 3 7 1 2 5 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 0 8 7 4 9 2 5 6 3]
 [5 3 7 9 6 2 8 4 1 0]
 [0 5 3 2 1 9 7 4 6 8]
 [9 4 0 1 3 2 6 8 7 5]
 [8 4 6 7 3 0 2 9 5 1]
 [4 7 2 1 5 3 0 6 8 9]
 [7 6 0 2 5 1 9 4 3 8]
 [5 6 2 8 1 4 7 3 0 9]
 [7 4 8 5 1 0 9 3 6 2]
 [8 3 4 9 6 0 2 5 7 1]]
Epoch 78410: Training cost= 2.3026, Training acc= 0.6972, Validation cost= 2.3026, Validation acc= 0.6968
Epoch 78420: Training cost= 2.3026, Training acc= 0.6972, Validation cost= 2.3026, Validation acc= 0.6968
Epoch 78430: Training cost= 2.3026, Training acc= 0.6971, Validation cost= 2.3026, Validation acc= 0.6967
Epoch 78440: Training cost= 2.3026, Training acc= 0.6970, Validation cost= 2.3026, Validation acc= 0.6966
Epoch 78450: Training cost= 2.3026, Training acc= 0.6969, Validation cost= 2.3026, Validation acc= 0.6965
Epoch 78460: Training cost= 2.3026, Training acc= 0.6969, Validation cost= 2.3026, Validation acc= 0.6965
Epoch 78470: Training cost= 2.3026, Training acc= 0.6968, Validation cost= 2.3026, Validation acc= 0.6964
Epoch 78480: Training cost= 2.3026, Training acc= 0.6967, Validation cost= 2.3026, Validation acc= 0.6963
Epoch 78490: Training cost= 2.3026, Training acc= 0.6966, Validation cost= 2.3026, Validation acc= 0.6962
Epoch 78500: Training cost= 2.3026, Training acc= 0.6966, Validation cost= 2.3026, Validation acc= 0.6961
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 6 8 4 9 5 1 2 7 0]
 [2 4 3 9 8 6 1 0 7 5]
 [3 9 1 2 4 5 0 6 7 8]
 [5 9 1 6 0 4 2 3 8 7]
 [2 9 4 0 3 5 1 6 8 7]
 [8 3 1 2 6 7 5 4 0 9]
 [7 3 6 5 2 4 1 0 8 9]
 [1 2 8 9 4 7 0 3 5 6]
 [0 3 5 4 6 7 2 8 9 1]
 [5 3 6 1 8 4 7 2 9 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 3 7 4 9 6 8 5 0 2]
 [4 7 9 6 0 1 2 3 8 5]
 [1 9 7 8 0 5 6 3 4 2]
 [4 5 0 7 2 1 8 3 9 6]
 [6 4 1 7 5 3 2 0 8 9]
 [2 9 4 8 1 6 0 7 3 5]
 [0 5 6 9 1 8 4 7 3 2]
 [6 9 8 3 1 5 0 4 2 7]
 [5 2 1 7 3 9 6 0 4 8]
 [3 5 6 1 7 8 2 9 0 4]]
Epoch 78510: Training cost= 2.3026, Training acc= 0.6965, Validation cost= 2.3026, Validation acc= 0.6961
Epoch 78520: Training cost= 2.3026, Training acc= 0.6964, Validation cost= 2.3026, Validation acc= 0.6960
Epoch 78530: Training cost= 2.3026, Training acc= 0.6963, Validation cost= 2.3026, Validation acc= 0.6959
Epoch 78540: Training cost= 2.3026, Training acc= 0.6963, Validation cost= 2.3026, Validation acc= 0.6958
Epoch 78550: Training cost= 2.3026, Training acc= 0.6962, Validation cost= 2.3026, Validation acc= 0.6958
Epoch 78560: Training cost= 2.3026, Training acc= 0.6961, Validation cost= 2.3026, Validation acc= 0.6957
Epoch 78570: Training cost= 2.3026, Training acc= 0.6960, Validation cost= 2.3026, Validation acc= 0.6956
Epoch 78580: Training cost= 2.3026, Training acc= 0.6959, Validation cost= 2.3026, Validation acc= 0.6955
Epoch 78590: Training cost= 2.3026, Training acc= 0.6959, Validation cost= 2.3026, Validation acc= 0.6955
Epoch 78600: Training cost= 2.3026, Training acc= 0.6958, Validation cost= 2.3026, Validation acc= 0.6954
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 2 5 9 7 6 4 8 1 3]
 [8 9 2 1 5 6 4 3 7 0]
 [6 5 7 8 1 9 4 3 2 0]
 [8 9 4 6 5 3 1 0 7 2]
 [2 5 1 9 3 4 0 8 7 6]
 [6 0 4 1 8 5 2 9 7 3]
 [0 6 3 5 1 7 8 2 4 9]
 [8 1 6 3 4 0 2 9 7 5]
 [6 5 2 4 8 0 1 9 7 3]
 [5 3 7 4 1 8 2 9 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 8 5 9 0 1 4 3 2 7]
 [0 1 5 2 8 4 3 9 6 7]
 [4 9 0 3 7 2 5 1 6 8]
 [6 1 4 2 7 9 3 5 0 8]
 [8 1 2 9 5 7 0 3 6 4]
 [6 9 8 4 0 2 3 7 1 5]
 [1 6 9 7 5 0 8 3 2 4]
 [4 5 8 0 2 1 7 3 6 9]
 [3 2 8 5 9 7 6 4 1 0]
 [1 9 0 4 3 8 2 6 5 7]]
Epoch 78610: Training cost= 2.3026, Training acc= 0.6957, Validation cost= 2.3026, Validation acc= 0.6953
Epoch 78620: Training cost= 2.3026, Training acc= 0.6956, Validation cost= 2.3026, Validation acc= 0.6952
Epoch 78630: Training cost= 2.3026, Training acc= 0.6956, Validation cost= 2.3026, Validation acc= 0.6952
Epoch 78640: Training cost= 2.3026, Training acc= 0.6955, Validation cost= 2.3026, Validation acc= 0.6951
Epoch 78650: Training cost= 2.3026, Training acc= 0.6954, Validation cost= 2.3026, Validation acc= 0.6950
Epoch 78660: Training cost= 2.3026, Training acc= 0.6953, Validation cost= 2.3026, Validation acc= 0.6949
Epoch 78670: Training cost= 2.3026, Training acc= 0.6953, Validation cost= 2.3026, Validation acc= 0.6949
Epoch 78680: Training cost= 2.3026, Training acc= 0.6952, Validation cost= 2.3026, Validation acc= 0.6948
Epoch 78690: Training cost= 2.3026, Training acc= 0.6951, Validation cost= 2.3026, Validation acc= 0.6947
Epoch 78700: Training cost= 2.3026, Training acc= 0.6950, Validation cost= 2.3026, Validation acc= 0.6946
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 4 1 5 9 3 2 7 6 0]
 [3 0 7 9 1 6 2 5 8 4]
 [9 2 8 5 0 1 4 3 7 6]
 [4 6 0 3 2 1 9 5 7 8]
 [9 1 0 6 8 4 7 5 3 2]
 [1 9 7 3 4 0 5 8 6 2]
 [2 7 8 9 1 6 5 4 0 3]
 [4 8 5 7 6 3 1 2 0 9]
 [5 7 8 4 2 1 3 0 6 9]
 [5 9 3 2 0 6 7 1 8 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 6 7 1 9 2 3 8 4 0]
 [5 4 6 9 8 3 7 2 1 0]
 [6 7 5 0 2 8 4 9 1 3]
 [6 2 0 4 5 8 9 3 7 1]
 [9 2 1 8 4 6 5 0 3 7]
 [5 9 4 2 3 0 7 8 1 6]
 [3 8 7 0 2 9 6 4 5 1]
 [7 4 5 1 3 0 8 9 6 2]
 [3 6 4 0 2 1 7 8 9 5]
 [6 7 9 1 0 8 2 4 5 3]]
Epoch 78710: Training cost= 2.3026, Training acc= 0.6950, Validation cost= 2.3026, Validation acc= 0.6946
Epoch 78720: Training cost= 2.3026, Training acc= 0.6949, Validation cost= 2.3026, Validation acc= 0.6945
Epoch 78730: Training cost= 2.3026, Training acc= 0.6948, Validation cost= 2.3026, Validation acc= 0.6944
Epoch 78740: Training cost= 2.3026, Training acc= 0.6947, Validation cost= 2.3026, Validation acc= 0.6943
Epoch 78750: Training cost= 2.3026, Training acc= 0.6947, Validation cost= 2.3026, Validation acc= 0.6943
Epoch 78760: Training cost= 2.3026, Training acc= 0.6946, Validation cost= 2.3026, Validation acc= 0.6942
Epoch 78770: Training cost= 2.3026, Training acc= 0.6945, Validation cost= 2.3026, Validation acc= 0.6941
Epoch 78780: Training cost= 2.3026, Training acc= 0.6944, Validation cost= 2.3026, Validation acc= 0.6940
Epoch 78790: Training cost= 2.3026, Training acc= 0.6944, Validation cost= 2.3026, Validation acc= 0.6940
Epoch 78800: Training cost= 2.3026, Training acc= 0.6943, Validation cost= 2.3026, Validation acc= 0.6939
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 7 2 6 1 5 9 3 8 0]
 [9 3 4 6 5 2 1 0 7 8]
 [1 4 2 5 9 6 3 0 7 8]
 [3 4 5 7 1 9 8 0 2 6]
 [8 4 5 1 7 6 0 3 2 9]
 [3 9 0 8 5 7 1 2 6 4]
 [9 5 3 4 2 1 6 0 7 8]
 [9 5 0 6 3 7 2 8 1 4]
 [2 3 6 1 5 4 8 7 9 0]
 [1 3 5 4 9 6 7 0 8 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 1 4 8 9 7 5 0 6 3]
 [5 0 1 9 7 4 2 3 8 6]
 [8 9 4 1 3 2 0 6 7 5]
 [3 7 2 1 6 8 5 4 0 9]
 [7 9 6 3 0 4 5 1 8 2]
 [6 9 3 7 8 5 2 1 0 4]
 [6 9 2 7 8 3 4 0 1 5]
 [0 4 5 8 1 6 3 9 7 2]
 [7 5 9 1 6 3 8 0 2 4]
 [9 8 4 6 5 1 7 0 2 3]]
Epoch 78810: Training cost= 2.3026, Training acc= 0.6942, Validation cost= 2.3026, Validation acc= 0.6938
Epoch 78820: Training cost= 2.3026, Training acc= 0.6941, Validation cost= 2.3026, Validation acc= 0.6937
Epoch 78830: Training cost= 2.3026, Training acc= 0.6941, Validation cost= 2.3026, Validation acc= 0.6937
Epoch 78840: Training cost= 2.3026, Training acc= 0.6940, Validation cost= 2.3026, Validation acc= 0.6936
Epoch 78850: Training cost= 2.3026, Training acc= 0.6939, Validation cost= 2.3026, Validation acc= 0.6935
Epoch 78860: Training cost= 2.3026, Training acc= 0.6938, Validation cost= 2.3026, Validation acc= 0.6934
Epoch 78870: Training cost= 2.3026, Training acc= 0.6938, Validation cost= 2.3026, Validation acc= 0.6934
Epoch 78880: Training cost= 2.3026, Training acc= 0.6937, Validation cost= 2.3026, Validation acc= 0.6933
Epoch 78890: Training cost= 2.3026, Training acc= 0.6936, Validation cost= 2.3026, Validation acc= 0.6932
Epoch 78900: Training cost= 2.3026, Training acc= 0.6935, Validation cost= 2.3026, Validation acc= 0.6931
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 1 3 4 2 9 6 0 7 8]
 [9 6 0 3 2 1 4 5 7 8]
 [1 4 5 0 3 2 6 9 8 7]
 [0 5 9 4 7 3 8 6 1 2]
 [3 4 7 2 5 1 6 9 8 0]
 [8 7 6 4 5 9 1 2 0 3]
 [2 4 1 0 6 9 7 3 8 5]
 [1 8 6 3 2 5 7 4 9 0]
 [7 5 0 6 2 1 4 3 9 8]
 [5 0 7 6 2 4 3 1 8 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 4 7 0 6 2 3 5 8 1]
 [1 2 0 7 4 6 5 8 9 3]
 [4 8 3 9 0 2 6 7 5 1]
 [1 9 0 2 6 7 4 5 8 3]
 [2 5 4 6 3 9 8 0 1 7]
 [6 7 1 0 5 9 3 8 2 4]
 [3 6 0 4 7 1 8 2 5 9]
 [4 0 9 6 2 3 5 8 1 7]
 [1 9 8 0 4 6 7 2 3 5]
 [0 2 6 9 3 4 7 5 8 1]]
Epoch 78910: Training cost= 2.3026, Training acc= 0.6935, Validation cost= 2.3026, Validation acc= 0.6931
Epoch 78920: Training cost= 2.3026, Training acc= 0.6934, Validation cost= 2.3026, Validation acc= 0.6930
Epoch 78930: Training cost= 2.3026, Training acc= 0.6933, Validation cost= 2.3026, Validation acc= 0.6929
Epoch 78940: Training cost= 2.3026, Training acc= 0.6932, Validation cost= 2.3026, Validation acc= 0.6928
Epoch 78950: Training cost= 2.3026, Training acc= 0.6932, Validation cost= 2.3026, Validation acc= 0.6928
Epoch 78960: Training cost= 2.3026, Training acc= 0.6931, Validation cost= 2.3026, Validation acc= 0.6927
Epoch 78970: Training cost= 2.3026, Training acc= 0.6930, Validation cost= 2.3026, Validation acc= 0.6926
Epoch 78980: Training cost= 2.3026, Training acc= 0.6929, Validation cost= 2.3026, Validation acc= 0.6925
Epoch 78990: Training cost= 2.3026, Training acc= 0.6929, Validation cost= 2.3026, Validation acc= 0.6925
Epoch 79000: Training cost= 2.3026, Training acc= 0.6928, Validation cost= 2.3026, Validation acc= 0.6924
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 8 7 6 1 4 5 3 2 0]
 [0 8 2 4 6 3 1 7 9 5]
 [0 4 8 6 3 2 9 5 7 1]
 [8 6 3 9 5 0 7 4 1 2]
 [5 2 1 0 6 9 4 7 8 3]
 [5 9 7 0 3 8 1 2 6 4]
 [3 4 1 9 6 2 0 7 8 5]
 [3 8 1 7 2 5 6 9 4 0]
 [8 6 7 5 2 1 9 3 0 4]
 [1 5 4 7 2 3 9 8 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 7 6 4 8 9 5 0 2 1]
 [6 2 0 4 9 1 3 8 5 7]
 [3 1 4 2 5 0 7 6 9 8]
 [5 7 6 0 9 8 2 3 4 1]
 [8 4 7 3 1 0 2 9 5 6]
 [6 5 2 9 7 8 3 4 1 0]
 [4 6 0 1 7 5 9 8 2 3]
 [5 6 8 1 9 2 0 3 4 7]
 [3 9 5 7 6 4 1 2 0 8]
 [7 8 4 0 5 1 3 6 9 2]]
Epoch 79010: Training cost= 2.3026, Training acc= 0.6927, Validation cost= 2.3026, Validation acc= 0.6923
Epoch 79020: Training cost= 2.3026, Training acc= 0.6926, Validation cost= 2.3026, Validation acc= 0.6922
Epoch 79030: Training cost= 2.3026, Training acc= 0.6926, Validation cost= 2.3026, Validation acc= 0.6922
Epoch 79040: Training cost= 2.3026, Training acc= 0.6925, Validation cost= 2.3026, Validation acc= 0.6921
Epoch 79050: Training cost= 2.3026, Training acc= 0.6924, Validation cost= 2.3026, Validation acc= 0.6920
Epoch 79060: Training cost= 2.3026, Training acc= 0.6923, Validation cost= 2.3026, Validation acc= 0.6919
Epoch 79070: Training cost= 2.3026, Training acc= 0.6923, Validation cost= 2.3026, Validation acc= 0.6919
Epoch 79080: Training cost= 2.3026, Training acc= 0.6922, Validation cost= 2.3026, Validation acc= 0.6918
Epoch 79090: Training cost= 2.3026, Training acc= 0.6921, Validation cost= 2.3026, Validation acc= 0.6917
Epoch 79100: Training cost= 2.3026, Training acc= 0.6920, Validation cost= 2.3026, Validation acc= 0.6916
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 4 6 7 8 5 1 0 3 9]
 [7 9 1 0 2 6 8 4 5 3]
 [2 8 9 5 3 0 6 1 7 4]
 [3 6 8 0 1 4 7 2 9 5]
 [3 4 9 8 5 1 2 6 0 7]
 [6 5 9 8 7 0 4 2 3 1]
 [7 8 5 0 9 1 6 2 3 4]
 [6 0 4 3 7 1 5 2 8 9]
 [9 7 8 0 1 6 3 5 2 4]
 [5 1 8 2 9 3 0 4 7 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 4 9 0 1 6 3 7 8 5]
 [8 3 9 0 5 7 4 1 2 6]
 [9 5 7 8 3 2 6 0 4 1]
 [6 7 0 1 4 9 3 8 5 2]
 [5 4 7 2 0 6 1 3 9 8]
 [6 3 4 1 7 2 0 9 5 8]
 [9 4 0 7 5 3 8 1 2 6]
 [3 6 8 5 9 4 2 1 7 0]
 [9 1 5 7 3 0 6 2 4 8]
 [4 2 1 8 9 3 5 7 6 0]]
Epoch 79110: Training cost= 2.3026, Training acc= 0.6920, Validation cost= 2.3026, Validation acc= 0.6916
Epoch 79120: Training cost= 2.3026, Training acc= 0.6919, Validation cost= 2.3026, Validation acc= 0.6915
Epoch 79130: Training cost= 2.3026, Training acc= 0.6918, Validation cost= 2.3026, Validation acc= 0.6914
Epoch 79140: Training cost= 2.3026, Training acc= 0.6917, Validation cost= 2.3026, Validation acc= 0.6913
Epoch 79150: Training cost= 2.3026, Training acc= 0.6917, Validation cost= 2.3026, Validation acc= 0.6913
Epoch 79160: Training cost= 2.3026, Training acc= 0.6916, Validation cost= 2.3026, Validation acc= 0.6912
Epoch 79170: Training cost= 2.3026, Training acc= 0.6915, Validation cost= 2.3026, Validation acc= 0.6911
Epoch 79180: Training cost= 2.3026, Training acc= 0.6914, Validation cost= 2.3026, Validation acc= 0.6910
Epoch 79190: Training cost= 2.3026, Training acc= 0.6914, Validation cost= 2.3026, Validation acc= 0.6910
Epoch 79200: Training cost= 2.3026, Training acc= 0.6913, Validation cost= 2.3026, Validation acc= 0.6909
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 1 2 9 5 8 4 6 0 3]
 [8 3 7 5 4 9 0 2 6 1]
 [2 1 6 4 8 7 9 3 0 5]
 [1 6 9 8 2 4 7 5 3 0]
 [2 4 9 0 6 3 8 5 7 1]
 [4 6 0 2 5 7 8 3 1 9]
 [3 4 8 5 0 1 7 9 6 2]
 [3 9 4 6 0 7 2 5 1 8]
 [8 6 9 4 5 0 7 3 2 1]
 [4 2 5 7 3 9 6 0 1 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 3 5 8 1 2 9 6 4 0]
 [8 4 7 3 6 2 0 9 1 5]
 [2 5 0 1 4 9 8 3 7 6]
 [1 8 0 4 2 6 3 9 7 5]
 [8 4 9 5 0 6 2 3 1 7]
 [3 9 5 0 8 6 4 2 7 1]
 [4 1 6 9 0 3 2 7 8 5]
 [0 3 2 6 1 7 4 9 5 8]
 [5 4 0 6 3 8 9 1 2 7]
 [3 9 1 6 5 2 0 8 4 7]]
Epoch 79210: Training cost= 2.3026, Training acc= 0.6912, Validation cost= 2.3026, Validation acc= 0.6908
Epoch 79220: Training cost= 2.3026, Training acc= 0.6911, Validation cost= 2.3026, Validation acc= 0.6907
Epoch 79230: Training cost= 2.3026, Training acc= 0.6911, Validation cost= 2.3026, Validation acc= 0.6907
Epoch 79240: Training cost= 2.3026, Training acc= 0.6910, Validation cost= 2.3026, Validation acc= 0.6906
Epoch 79250: Training cost= 2.3026, Training acc= 0.6909, Validation cost= 2.3026, Validation acc= 0.6905
Epoch 79260: Training cost= 2.3026, Training acc= 0.6908, Validation cost= 2.3026, Validation acc= 0.6904
Epoch 79270: Training cost= 2.3026, Training acc= 0.6908, Validation cost= 2.3026, Validation acc= 0.6904
Epoch 79280: Training cost= 2.3026, Training acc= 0.6907, Validation cost= 2.3026, Validation acc= 0.6903
Epoch 79290: Training cost= 2.3026, Training acc= 0.6906, Validation cost= 2.3026, Validation acc= 0.6902
Epoch 79300: Training cost= 2.3026, Training acc= 0.6905, Validation cost= 2.3026, Validation acc= 0.6901
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 2 4 7 8 5 1 3 6 9]
 [9 2 3 4 6 7 5 0 1 8]
 [2 8 7 0 5 1 9 4 6 3]
 [0 1 5 3 7 8 4 2 6 9]
 [6 8 7 0 4 1 5 3 9 2]
 [4 9 7 6 5 1 2 3 0 8]
 [5 8 2 4 9 0 1 7 6 3]
 [5 8 6 1 9 2 0 4 7 3]
 [3 9 4 2 1 0 6 5 7 8]
 [2 6 3 9 5 8 0 4 1 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 9 0 6 5 7 3 2 4 1]
 [3 6 7 5 1 4 2 8 0 9]
 [8 2 4 7 5 0 3 1 6 9]
 [2 9 6 1 8 5 0 7 3 4]
 [9 3 4 7 0 8 5 6 1 2]
 [4 6 9 3 1 7 0 5 8 2]
 [0 5 3 9 7 2 4 1 8 6]
 [2 1 9 6 8 4 7 0 3 5]
 [0 8 6 9 4 2 7 3 1 5]
 [7 4 9 2 0 1 6 3 5 8]]
Epoch 79310: Training cost= 2.3026, Training acc= 0.6905, Validation cost= 2.3026, Validation acc= 0.6901
Epoch 79320: Training cost= 2.3026, Training acc= 0.6904, Validation cost= 2.3026, Validation acc= 0.6900
Epoch 79330: Training cost= 2.3026, Training acc= 0.6903, Validation cost= 2.3026, Validation acc= 0.6899
Epoch 79340: Training cost= 2.3026, Training acc= 0.6902, Validation cost= 2.3026, Validation acc= 0.6898
Epoch 79350: Training cost= 2.3026, Training acc= 0.6902, Validation cost= 2.3026, Validation acc= 0.6898
Epoch 79360: Training cost= 2.3026, Training acc= 0.6901, Validation cost= 2.3026, Validation acc= 0.6897
Epoch 79370: Training cost= 2.3026, Training acc= 0.6900, Validation cost= 2.3026, Validation acc= 0.6896
Epoch 79380: Training cost= 2.3026, Training acc= 0.6899, Validation cost= 2.3026, Validation acc= 0.6895
Epoch 79390: Training cost= 2.3026, Training acc= 0.6899, Validation cost= 2.3026, Validation acc= 0.6895
Epoch 79400: Training cost= 2.3026, Training acc= 0.6898, Validation cost= 2.3026, Validation acc= 0.6894
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 3 7 1 9 5 4 2 0 6]
 [1 3 7 0 5 2 8 9 4 6]
 [3 1 6 7 0 4 5 2 9 8]
 [7 0 4 1 3 8 9 6 5 2]
 [5 8 7 3 2 4 0 1 9 6]
 [8 4 6 1 5 0 9 7 2 3]
 [4 8 9 2 0 6 5 1 3 7]
 [1 2 0 5 6 9 4 3 7 8]
 [2 3 8 6 0 1 9 4 7 5]
 [2 7 5 0 1 4 8 3 6 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 2 4 0 1 6 5 8 3 7]
 [4 9 3 7 8 2 5 1 0 6]
 [4 7 3 5 1 2 0 6 9 8]
 [4 5 3 2 6 9 0 1 8 7]
 [1 6 4 3 9 0 8 7 2 5]
 [6 8 5 1 4 2 3 9 7 0]
 [0 5 4 7 2 8 9 1 6 3]
 [3 7 2 9 6 0 5 8 4 1]
 [7 3 5 9 2 0 6 4 1 8]
 [1 3 2 9 4 8 6 5 7 0]]
Epoch 79410: Training cost= 2.3026, Training acc= 0.6897, Validation cost= 2.3026, Validation acc= 0.6893
Epoch 79420: Training cost= 2.3026, Training acc= 0.6896, Validation cost= 2.3026, Validation acc= 0.6892
Epoch 79430: Training cost= 2.3026, Training acc= 0.6896, Validation cost= 2.3026, Validation acc= 0.6892
Epoch 79440: Training cost= 2.3026, Training acc= 0.6895, Validation cost= 2.3026, Validation acc= 0.6891
Epoch 79450: Training cost= 2.3026, Training acc= 0.6894, Validation cost= 2.3026, Validation acc= 0.6890
Epoch 79460: Training cost= 2.3026, Training acc= 0.6893, Validation cost= 2.3026, Validation acc= 0.6889
Epoch 79470: Training cost= 2.3026, Training acc= 0.6893, Validation cost= 2.3026, Validation acc= 0.6889
Epoch 79480: Training cost= 2.3026, Training acc= 0.6892, Validation cost= 2.3026, Validation acc= 0.6888
Epoch 79490: Training cost= 2.3026, Training acc= 0.6891, Validation cost= 2.3026, Validation acc= 0.6887
Epoch 79500: Training cost= 2.3026, Training acc= 0.6891, Validation cost= 2.3026, Validation acc= 0.6886
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 5 7 3 6 8 2 9 0 1]
 [6 2 1 0 3 4 5 8 9 7]
 [0 3 1 7 8 4 9 6 5 2]
 [6 1 4 7 2 9 3 5 0 8]
 [9 4 0 7 5 8 2 3 6 1]
 [9 1 7 4 3 6 5 8 0 2]
 [4 6 0 9 7 2 5 8 1 3]
 [4 1 0 9 6 3 5 2 7 8]
 [6 3 7 4 8 1 5 9 2 0]
 [8 4 2 5 1 6 3 0 9 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 5 1 3 7 4 6 8 0 2]
 [7 0 4 8 9 5 2 3 1 6]
 [7 2 3 6 0 1 4 8 9 5]
 [5 2 4 1 6 9 8 0 7 3]
 [3 1 6 2 0 4 7 5 9 8]
 [7 8 9 1 3 5 4 0 6 2]
 [3 9 4 8 1 7 0 5 6 2]
 [8 2 0 7 5 3 4 6 9 1]
 [0 8 5 4 7 3 1 9 2 6]
 [9 6 8 7 3 2 4 5 1 0]]
Epoch 79510: Training cost= 2.3026, Training acc= 0.6890, Validation cost= 2.3026, Validation acc= 0.6886
Epoch 79520: Training cost= 2.3026, Training acc= 0.6889, Validation cost= 2.3026, Validation acc= 0.6885
Epoch 79530: Training cost= 2.3026, Training acc= 0.6888, Validation cost= 2.3026, Validation acc= 0.6884
Epoch 79540: Training cost= 2.3026, Training acc= 0.6888, Validation cost= 2.3026, Validation acc= 0.6884
Epoch 79550: Training cost= 2.3026, Training acc= 0.6887, Validation cost= 2.3026, Validation acc= 0.6883
Epoch 79560: Training cost= 2.3026, Training acc= 0.6886, Validation cost= 2.3026, Validation acc= 0.6882
Epoch 79570: Training cost= 2.3026, Training acc= 0.6885, Validation cost= 2.3026, Validation acc= 0.6881
Epoch 79580: Training cost= 2.3026, Training acc= 0.6885, Validation cost= 2.3026, Validation acc= 0.6881
Epoch 79590: Training cost= 2.3026, Training acc= 0.6884, Validation cost= 2.3026, Validation acc= 0.6880
Epoch 79600: Training cost= 2.3026, Training acc= 0.6883, Validation cost= 2.3026, Validation acc= 0.6879
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 3 2 6 7 4 5 9 0 8]
 [8 2 9 4 1 5 3 7 6 0]
 [2 5 0 3 9 8 4 7 6 1]
 [9 3 5 0 6 4 8 2 1 7]
 [7 4 2 3 9 0 1 8 5 6]
 [8 9 1 6 2 3 4 0 5 7]
 [9 2 8 5 0 7 1 4 6 3]
 [9 3 0 1 2 5 7 8 4 6]
 [6 2 8 4 3 7 0 1 9 5]
 [1 9 0 7 5 8 4 3 6 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 6 9 0 7 8 1 4 2]
 [6 0 3 5 4 9 2 7 8 1]
 [5 7 2 3 1 6 8 0 9 4]
 [9 8 3 6 5 0 1 4 2 7]
 [4 9 6 0 2 5 7 1 8 3]
 [1 8 4 0 7 6 3 2 5 9]
 [2 0 6 8 9 1 7 3 4 5]
 [9 3 4 8 1 6 2 7 0 5]
 [7 4 1 0 3 8 5 9 6 2]
 [3 6 5 9 8 2 4 0 1 7]]
Epoch 79610: Training cost= 2.3026, Training acc= 0.6882, Validation cost= 2.3026, Validation acc= 0.6878
Epoch 79620: Training cost= 2.3026, Training acc= 0.6882, Validation cost= 2.3026, Validation acc= 0.6878
Epoch 79630: Training cost= 2.3026, Training acc= 0.6881, Validation cost= 2.3026, Validation acc= 0.6877
Epoch 79640: Training cost= 2.3026, Training acc= 0.6880, Validation cost= 2.3026, Validation acc= 0.6876
Epoch 79650: Training cost= 2.3026, Training acc= 0.6879, Validation cost= 2.3026, Validation acc= 0.6875
Epoch 79660: Training cost= 2.3026, Training acc= 0.6879, Validation cost= 2.3026, Validation acc= 0.6875
Epoch 79670: Training cost= 2.3026, Training acc= 0.6878, Validation cost= 2.3026, Validation acc= 0.6874
Epoch 79680: Training cost= 2.3026, Training acc= 0.6877, Validation cost= 2.3026, Validation acc= 0.6873
Epoch 79690: Training cost= 2.3026, Training acc= 0.6876, Validation cost= 2.3026, Validation acc= 0.6872
Epoch 79700: Training cost= 2.3026, Training acc= 0.6876, Validation cost= 2.3026, Validation acc= 0.6872
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 3 1 8 0 7 4 2 5 6]
 [0 2 8 1 3 4 7 5 9 6]
 [8 5 1 6 2 9 3 7 0 4]
 [7 4 0 3 2 5 6 8 1 9]
 [3 9 5 2 0 8 1 4 7 6]
 [3 8 6 0 9 1 7 5 2 4]
 [0 1 5 7 8 4 2 6 9 3]
 [0 7 2 4 9 6 5 1 8 3]
 [2 8 5 9 6 4 3 7 1 0]
 [9 6 8 5 4 3 1 2 7 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 8 5 2 9 1 4 6 7 3]
 [8 4 3 2 5 6 1 9 7 0]
 [1 7 5 0 8 4 3 9 2 6]
 [9 4 8 1 2 3 0 5 7 6]
 [2 8 5 0 9 6 7 1 4 3]
 [7 5 0 2 3 9 8 6 1 4]
 [0 4 6 7 1 8 2 9 5 3]
 [3 6 1 0 9 8 7 4 5 2]
 [9 6 4 1 5 0 3 7 8 2]
 [4 6 3 9 2 0 5 7 1 8]]
Epoch 79710: Training cost= 2.3026, Training acc= 0.6875, Validation cost= 2.3026, Validation acc= 0.6871
Epoch 79720: Training cost= 2.3026, Training acc= 0.6874, Validation cost= 2.3026, Validation acc= 0.6870
Epoch 79730: Training cost= 2.3026, Training acc= 0.6874, Validation cost= 2.3026, Validation acc= 0.6870
Epoch 79740: Training cost= 2.3026, Training acc= 0.6873, Validation cost= 2.3026, Validation acc= 0.6869
Epoch 79750: Training cost= 2.3026, Training acc= 0.6872, Validation cost= 2.3026, Validation acc= 0.6868
Epoch 79760: Training cost= 2.3026, Training acc= 0.6871, Validation cost= 2.3026, Validation acc= 0.6867
Epoch 79770: Training cost= 2.3026, Training acc= 0.6871, Validation cost= 2.3026, Validation acc= 0.6867
Epoch 79780: Training cost= 2.3026, Training acc= 0.6870, Validation cost= 2.3026, Validation acc= 0.6866
Epoch 79790: Training cost= 2.3026, Training acc= 0.6869, Validation cost= 2.3026, Validation acc= 0.6865
Epoch 79800: Training cost= 2.3026, Training acc= 0.6868, Validation cost= 2.3026, Validation acc= 0.6864
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 0 9 4 5 7 3 8 6 2]
 [3 0 4 2 1 6 9 5 8 7]
 [4 8 5 9 3 2 7 6 1 0]
 [2 3 5 7 4 1 9 0 8 6]
 [7 0 1 3 8 6 9 4 2 5]
 [6 4 1 0 3 8 5 2 9 7]
 [8 5 2 1 0 7 4 6 3 9]
 [2 5 6 4 9 7 8 3 0 1]
 [0 5 3 9 8 7 2 1 4 6]
 [5 8 2 3 0 9 1 4 6 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 4 8 1 9 5 7 3 2 6]
 [0 7 6 4 8 1 9 5 3 2]
 [9 1 8 6 5 3 2 0 4 7]
 [9 4 8 7 1 6 0 2 3 5]
 [7 2 5 3 6 9 4 0 1 8]
 [5 9 2 1 7 4 0 6 3 8]
 [4 7 9 5 3 6 8 2 1 0]
 [4 0 6 2 1 9 3 8 5 7]
 [8 2 9 3 1 6 0 4 7 5]
 [8 1 7 2 9 5 3 4 6 0]]
Epoch 79810: Training cost= 2.3026, Training acc= 0.6868, Validation cost= 2.3026, Validation acc= 0.6864
Epoch 79820: Training cost= 2.3026, Training acc= 0.6867, Validation cost= 2.3026, Validation acc= 0.6863
Epoch 79830: Training cost= 2.3026, Training acc= 0.6866, Validation cost= 2.3026, Validation acc= 0.6862
Epoch 79840: Training cost= 2.3026, Training acc= 0.6865, Validation cost= 2.3026, Validation acc= 0.6861
Epoch 79850: Training cost= 2.3026, Training acc= 0.6865, Validation cost= 2.3026, Validation acc= 0.6861
Epoch 79860: Training cost= 2.3026, Training acc= 0.6864, Validation cost= 2.3026, Validation acc= 0.6860
Epoch 79870: Training cost= 2.3026, Training acc= 0.6863, Validation cost= 2.3026, Validation acc= 0.6859
Epoch 79880: Training cost= 2.3026, Training acc= 0.6862, Validation cost= 2.3026, Validation acc= 0.6858
Epoch 79890: Training cost= 2.3026, Training acc= 0.6862, Validation cost= 2.3026, Validation acc= 0.6858
Epoch 79900: Training cost= 2.3026, Training acc= 0.6861, Validation cost= 2.3026, Validation acc= 0.6857
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 7 3 8 0 5 2 9 1 4]
 [5 8 2 1 7 6 4 9 0 3]
 [1 5 3 9 2 0 8 6 7 4]
 [7 5 9 3 2 0 6 1 8 4]
 [6 3 2 0 9 5 8 4 7 1]
 [9 2 0 6 3 1 7 5 4 8]
 [9 2 5 7 1 0 8 3 6 4]
 [3 8 6 4 0 7 1 2 5 9]
 [2 8 3 6 0 4 5 7 1 9]
 [6 2 1 9 8 3 5 7 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 7 5 1 6 8 9 4 3 2]
 [4 3 1 8 6 0 7 9 5 2]
 [7 9 2 5 6 3 1 8 0 4]
 [0 8 6 3 4 5 1 2 9 7]
 [0 8 9 3 1 5 7 4 2 6]
 [1 8 6 4 7 0 9 3 5 2]
 [5 2 0 7 4 8 9 3 6 1]
 [7 6 9 4 8 5 3 1 0 2]
 [3 7 9 0 1 4 5 2 8 6]
 [4 5 2 0 8 1 3 7 9 6]]
Epoch 79910: Training cost= 2.3026, Training acc= 0.6860, Validation cost= 2.3026, Validation acc= 0.6856
Epoch 79920: Training cost= 2.3026, Training acc= 0.6860, Validation cost= 2.3026, Validation acc= 0.6856
Epoch 79930: Training cost= 2.3026, Training acc= 0.6859, Validation cost= 2.3026, Validation acc= 0.6855
Epoch 79940: Training cost= 2.3026, Training acc= 0.6858, Validation cost= 2.3026, Validation acc= 0.6854
Epoch 79950: Training cost= 2.3026, Training acc= 0.6857, Validation cost= 2.3026, Validation acc= 0.6853
Epoch 79960: Training cost= 2.3026, Training acc= 0.6857, Validation cost= 2.3026, Validation acc= 0.6853
Epoch 79970: Training cost= 2.3026, Training acc= 0.6856, Validation cost= 2.3026, Validation acc= 0.6852
Epoch 79980: Training cost= 2.3026, Training acc= 0.6855, Validation cost= 2.3026, Validation acc= 0.6851
Epoch 79990: Training cost= 2.3026, Training acc= 0.6854, Validation cost= 2.3026, Validation acc= 0.6850
Epoch 80000: Training cost= 2.3026, Training acc= 0.6854, Validation cost= 2.3026, Validation acc= 0.6850
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 4 9 0 3 2 7 8 5 6]
 [4 2 0 8 3 1 7 5 6 9]
 [1 7 9 2 4 3 5 8 6 0]
 [4 7 6 5 8 2 9 1 0 3]
 [8 2 4 3 5 7 6 1 9 0]
 [9 4 6 1 0 3 8 7 5 2]
 [7 9 2 4 0 8 5 1 3 6]
 [4 9 7 3 1 5 8 0 2 6]
 [3 7 8 5 0 1 2 6 9 4]
 [4 9 2 6 1 8 0 3 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 4 7 9 1 3 8 5 6 0]
 [4 6 1 2 8 9 5 0 7 3]
 [3 4 8 5 9 0 7 1 6 2]
 [5 1 9 8 6 4 7 2 0 3]
 [8 2 3 9 4 1 0 5 6 7]
 [4 2 0 3 7 1 6 8 5 9]
 [2 6 1 9 8 5 4 0 3 7]
 [6 9 8 3 5 1 7 0 2 4]
 [7 0 5 1 6 3 4 2 9 8]
 [7 1 4 6 5 2 0 9 3 8]]
Epoch 80010: Training cost= 2.3026, Training acc= 0.6853, Validation cost= 2.3026, Validation acc= 0.6849
Epoch 80020: Training cost= 2.3026, Training acc= 0.6852, Validation cost= 2.3026, Validation acc= 0.6848
Epoch 80030: Training cost= 2.3026, Training acc= 0.6851, Validation cost= 2.3026, Validation acc= 0.6848
Epoch 80040: Training cost= 2.3026, Training acc= 0.6851, Validation cost= 2.3026, Validation acc= 0.6847
Epoch 80050: Training cost= 2.3026, Training acc= 0.6850, Validation cost= 2.3026, Validation acc= 0.6846
Epoch 80060: Training cost= 2.3026, Training acc= 0.6849, Validation cost= 2.3026, Validation acc= 0.6845
Epoch 80070: Training cost= 2.3026, Training acc= 0.6849, Validation cost= 2.3026, Validation acc= 0.6845
Epoch 80080: Training cost= 2.3026, Training acc= 0.6848, Validation cost= 2.3026, Validation acc= 0.6844
Epoch 80090: Training cost= 2.3026, Training acc= 0.6847, Validation cost= 2.3026, Validation acc= 0.6843
Epoch 80100: Training cost= 2.3026, Training acc= 0.6846, Validation cost= 2.3026, Validation acc= 0.6842
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 6 0 1 3 2 9 5 8 7]
 [8 6 4 5 3 2 9 0 1 7]
 [8 9 2 3 7 0 5 4 6 1]
 [0 3 7 2 1 8 9 6 4 5]
 [3 1 9 6 0 8 4 5 7 2]
 [9 4 2 7 3 1 8 0 6 5]
 [3 9 5 1 0 6 7 4 8 2]
 [3 4 7 0 6 9 8 2 1 5]
 [1 8 9 5 0 6 7 3 4 2]
 [6 2 3 5 4 1 9 0 8 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 6 3 9 2 5 1 4 7 8]
 [9 8 7 1 5 0 6 2 3 4]
 [2 9 3 5 8 7 1 0 4 6]
 [6 7 4 3 9 2 1 0 8 5]
 [2 1 7 3 0 6 9 5 4 8]
 [7 9 3 2 5 0 8 6 1 4]
 [3 0 7 5 6 2 8 4 1 9]
 [1 7 6 3 4 2 0 8 9 5]
 [4 6 7 8 9 0 3 1 5 2]
 [7 5 1 3 2 0 6 9 8 4]]
Epoch 80110: Training cost= 2.3026, Training acc= 0.6846, Validation cost= 2.3026, Validation acc= 0.6842
Epoch 80120: Training cost= 2.3026, Training acc= 0.6845, Validation cost= 2.3026, Validation acc= 0.6841
Epoch 80130: Training cost= 2.3026, Training acc= 0.6844, Validation cost= 2.3026, Validation acc= 0.6840
Epoch 80140: Training cost= 2.3026, Training acc= 0.6843, Validation cost= 2.3026, Validation acc= 0.6839
Epoch 80150: Training cost= 2.3026, Training acc= 0.6843, Validation cost= 2.3026, Validation acc= 0.6839
Epoch 80160: Training cost= 2.3026, Training acc= 0.6842, Validation cost= 2.3026, Validation acc= 0.6838
Epoch 80170: Training cost= 2.3026, Training acc= 0.6841, Validation cost= 2.3026, Validation acc= 0.6837
Epoch 80180: Training cost= 2.3026, Training acc= 0.6841, Validation cost= 2.3026, Validation acc= 0.6837
Epoch 80190: Training cost= 2.3026, Training acc= 0.6840, Validation cost= 2.3026, Validation acc= 0.6836
Epoch 80200: Training cost= 2.3026, Training acc= 0.6839, Validation cost= 2.3026, Validation acc= 0.6835
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 5 9 6 3 2 0 8 1 7]
 [4 1 6 9 8 5 0 7 2 3]
 [0 5 8 7 4 2 6 1 3 9]
 [6 1 0 2 7 9 5 4 3 8]
 [4 0 1 3 8 9 5 7 2 6]
 [8 0 5 1 6 3 4 9 2 7]
 [6 2 3 4 5 9 0 1 7 8]
 [5 9 6 8 3 4 1 2 0 7]
 [7 0 9 1 5 6 4 8 3 2]
 [4 1 2 9 3 8 6 0 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 3 4 0 9 5 1 2 7 8]
 [5 3 1 8 2 0 7 9 4 6]
 [2 9 0 7 3 4 5 6 8 1]
 [8 0 7 3 1 2 9 6 4 5]
 [1 5 0 3 8 7 6 2 9 4]
 [1 4 9 7 6 2 8 3 0 5]
 [6 8 2 1 0 3 4 5 9 7]
 [1 9 8 2 4 7 6 5 0 3]
 [2 1 4 8 9 0 3 5 6 7]
 [3 1 9 0 6 5 8 4 7 2]]
Epoch 80210: Training cost= 2.3026, Training acc= 0.6838, Validation cost= 2.3026, Validation acc= 0.6834
Epoch 80220: Training cost= 2.3026, Training acc= 0.6838, Validation cost= 2.3026, Validation acc= 0.6834
Epoch 80230: Training cost= 2.3026, Training acc= 0.6837, Validation cost= 2.3026, Validation acc= 0.6833
Epoch 80240: Training cost= 2.3026, Training acc= 0.6836, Validation cost= 2.3026, Validation acc= 0.6832
Epoch 80250: Training cost= 2.3026, Training acc= 0.6835, Validation cost= 2.3026, Validation acc= 0.6831
Epoch 80260: Training cost= 2.3026, Training acc= 0.6835, Validation cost= 2.3026, Validation acc= 0.6831
Epoch 80270: Training cost= 2.3026, Training acc= 0.6834, Validation cost= 2.3026, Validation acc= 0.6830
Epoch 80280: Training cost= 2.3026, Training acc= 0.6833, Validation cost= 2.3026, Validation acc= 0.6829
Epoch 80290: Training cost= 2.3026, Training acc= 0.6833, Validation cost= 2.3026, Validation acc= 0.6829
Epoch 80300: Training cost= 2.3026, Training acc= 0.6832, Validation cost= 2.3026, Validation acc= 0.6828
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 2 8 0 3 7 5 4 9 1]
 [8 7 5 4 1 0 3 2 9 6]
 [7 5 6 1 2 3 0 4 8 9]
 [6 8 1 9 3 4 0 7 5 2]
 [9 4 3 5 6 0 7 1 2 8]
 [2 8 3 9 5 4 6 1 7 0]
 [3 6 7 8 0 5 1 4 9 2]
 [9 4 6 3 1 0 8 2 5 7]
 [4 6 2 8 9 1 7 3 0 5]
 [5 3 7 8 1 2 4 6 9 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 7 9 4 3 5 2 6 8 0]
 [7 2 0 5 6 8 1 4 9 3]
 [4 6 7 9 8 5 2 0 3 1]
 [7 6 9 4 5 2 8 1 3 0]
 [1 9 8 0 4 6 3 2 5 7]
 [9 6 2 7 8 0 3 4 1 5]
 [3 8 5 6 4 9 0 1 2 7]
 [3 4 5 7 8 2 0 1 9 6]
 [5 0 8 6 3 1 2 9 7 4]
 [1 6 8 0 4 7 5 9 2 3]]
Epoch 80310: Training cost= 2.3026, Training acc= 0.6831, Validation cost= 2.3026, Validation acc= 0.6827
Epoch 80320: Training cost= 2.3026, Training acc= 0.6830, Validation cost= 2.3026, Validation acc= 0.6826
Epoch 80330: Training cost= 2.3026, Training acc= 0.6830, Validation cost= 2.3026, Validation acc= 0.6826
Epoch 80340: Training cost= 2.3026, Training acc= 0.6829, Validation cost= 2.3026, Validation acc= 0.6825
Epoch 80350: Training cost= 2.3026, Training acc= 0.6828, Validation cost= 2.3026, Validation acc= 0.6824
Epoch 80360: Training cost= 2.3026, Training acc= 0.6827, Validation cost= 2.3026, Validation acc= 0.6824
Epoch 80370: Training cost= 2.3026, Training acc= 0.6827, Validation cost= 2.3026, Validation acc= 0.6823
Epoch 80380: Training cost= 2.3026, Training acc= 0.6826, Validation cost= 2.3026, Validation acc= 0.6822
Epoch 80390: Training cost= 2.3026, Training acc= 0.6825, Validation cost= 2.3026, Validation acc= 0.6821
Epoch 80400: Training cost= 2.3026, Training acc= 0.6825, Validation cost= 2.3026, Validation acc= 0.6821
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 5 3 9 0 8 7 1 4 6]
 [7 0 1 3 6 8 9 2 5 4]
 [8 9 0 7 5 6 2 1 3 4]
 [9 3 6 8 1 2 4 7 5 0]
 [5 9 8 6 3 2 7 1 4 0]
 [2 8 7 9 5 1 0 4 6 3]
 [0 6 9 2 8 7 4 3 1 5]
 [8 3 2 4 6 9 1 0 5 7]
 [1 9 7 6 8 3 2 0 4 5]
 [7 6 9 8 0 3 4 1 5 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 6 1 9 4 3 7 0 2 5]
 [2 1 3 7 5 9 8 6 0 4]
 [4 1 5 7 8 3 9 6 2 0]
 [4 3 9 1 0 6 2 7 8 5]
 [6 1 8 4 9 0 5 2 7 3]
 [1 0 9 2 7 6 3 4 5 8]
 [2 4 7 5 8 1 6 0 9 3]
 [4 8 9 6 3 2 0 5 1 7]
 [0 9 7 5 1 4 8 2 6 3]
 [5 7 3 1 4 0 9 2 8 6]]
Epoch 80410: Training cost= 2.3026, Training acc= 0.6824, Validation cost= 2.3026, Validation acc= 0.6820
Epoch 80420: Training cost= 2.3026, Training acc= 0.6823, Validation cost= 2.3026, Validation acc= 0.6819
Epoch 80430: Training cost= 2.3026, Training acc= 0.6822, Validation cost= 2.3026, Validation acc= 0.6818
Epoch 80440: Training cost= 2.3026, Training acc= 0.6822, Validation cost= 2.3026, Validation acc= 0.6818
Epoch 80450: Training cost= 2.3026, Training acc= 0.6821, Validation cost= 2.3026, Validation acc= 0.6817
Epoch 80460: Training cost= 2.3026, Training acc= 0.6820, Validation cost= 2.3026, Validation acc= 0.6816
Epoch 80470: Training cost= 2.3026, Training acc= 0.6820, Validation cost= 2.3026, Validation acc= 0.6816
Epoch 80480: Training cost= 2.3026, Training acc= 0.6819, Validation cost= 2.3026, Validation acc= 0.6815
Epoch 80490: Training cost= 2.3026, Training acc= 0.6818, Validation cost= 2.3026, Validation acc= 0.6814
Epoch 80500: Training cost= 2.3026, Training acc= 0.6817, Validation cost= 2.3026, Validation acc= 0.6813
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 5 1 4 3 6 7 2 8 9]
 [3 2 0 7 1 8 9 4 6 5]
 [2 0 4 5 8 1 6 7 3 9]
 [2 9 7 5 4 6 3 1 0 8]
 [5 4 8 3 1 0 2 7 6 9]
 [2 0 1 7 4 3 5 8 9 6]
 [2 6 3 7 1 4 9 5 0 8]
 [4 6 0 3 2 9 8 5 7 1]
 [0 6 2 5 7 9 3 8 1 4]
 [7 3 5 9 0 4 2 6 1 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 3 7 2 9 0 4 1 6 5]
 [0 4 5 1 8 7 3 9 2 6]
 [2 7 1 4 3 5 0 8 6 9]
 [8 7 6 1 9 5 0 3 4 2]
 [1 6 5 0 2 3 8 7 4 9]
 [2 8 5 9 6 3 4 7 0 1]
 [6 2 9 8 7 3 1 4 5 0]
 [8 1 9 2 7 6 5 0 4 3]
 [8 3 4 1 6 7 9 0 2 5]
 [7 3 5 2 8 6 1 4 9 0]]
Epoch 80510: Training cost= 2.3026, Training acc= 0.6817, Validation cost= 2.3026, Validation acc= 0.6813
Epoch 80520: Training cost= 2.3026, Training acc= 0.6816, Validation cost= 2.3026, Validation acc= 0.6812
Epoch 80530: Training cost= 2.3026, Training acc= 0.6815, Validation cost= 2.3026, Validation acc= 0.6811
Epoch 80540: Training cost= 2.3026, Training acc= 0.6814, Validation cost= 2.3026, Validation acc= 0.6810
Epoch 80550: Training cost= 2.3026, Training acc= 0.6814, Validation cost= 2.3026, Validation acc= 0.6810
Epoch 80560: Training cost= 2.3026, Training acc= 0.6813, Validation cost= 2.3026, Validation acc= 0.6809
Epoch 80570: Training cost= 2.3026, Training acc= 0.6812, Validation cost= 2.3026, Validation acc= 0.6808
Epoch 80580: Training cost= 2.3026, Training acc= 0.6812, Validation cost= 2.3026, Validation acc= 0.6808
Epoch 80590: Training cost= 2.3026, Training acc= 0.6811, Validation cost= 2.3026, Validation acc= 0.6807
Epoch 80600: Training cost= 2.3026, Training acc= 0.6810, Validation cost= 2.3026, Validation acc= 0.6806
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 9 1 7 0 6 5 2 4 8]
 [1 4 0 5 8 9 6 2 3 7]
 [3 2 8 6 4 7 5 1 9 0]
 [2 3 6 5 0 7 1 8 4 9]
 [3 5 6 2 9 8 7 0 1 4]
 [7 3 5 0 8 4 2 1 6 9]
 [6 8 0 3 4 7 9 2 5 1]
 [9 7 0 6 5 8 3 4 2 1]
 [8 3 4 5 7 9 0 1 6 2]
 [0 9 4 7 3 2 8 5 6 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 9 3 1 8 6 0 4 5 7]
 [1 7 6 3 8 5 2 4 0 9]
 [9 1 6 5 3 7 4 0 2 8]
 [0 1 3 6 7 4 2 8 5 9]
 [3 2 9 5 6 8 7 1 4 0]
 [9 3 0 4 8 7 6 5 1 2]
 [7 8 3 1 6 2 5 4 9 0]
 [8 1 2 9 0 4 7 3 5 6]
 [0 1 4 6 5 7 3 9 2 8]
 [5 8 2 4 3 1 9 6 0 7]]
Epoch 80610: Training cost= 2.3026, Training acc= 0.6809, Validation cost= 2.3026, Validation acc= 0.6805
Epoch 80620: Training cost= 2.3026, Training acc= 0.6809, Validation cost= 2.3026, Validation acc= 0.6805
Epoch 80630: Training cost= 2.3026, Training acc= 0.6808, Validation cost= 2.3026, Validation acc= 0.6804
Epoch 80640: Training cost= 2.3026, Training acc= 0.6807, Validation cost= 2.3026, Validation acc= 0.6803
Epoch 80650: Training cost= 2.3026, Training acc= 0.6807, Validation cost= 2.3026, Validation acc= 0.6803
Epoch 80660: Training cost= 2.3026, Training acc= 0.6806, Validation cost= 2.3026, Validation acc= 0.6802
Epoch 80670: Training cost= 2.3026, Training acc= 0.6805, Validation cost= 2.3026, Validation acc= 0.6801
Epoch 80680: Training cost= 2.3026, Training acc= 0.6804, Validation cost= 2.3026, Validation acc= 0.6800
Epoch 80690: Training cost= 2.3026, Training acc= 0.6804, Validation cost= 2.3026, Validation acc= 0.6800
Epoch 80700: Training cost= 2.3026, Training acc= 0.6803, Validation cost= 2.3026, Validation acc= 0.6799
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 9 1 3 4 5 8 0 6 2]
 [2 4 1 3 8 5 6 9 0 7]
 [7 8 5 4 2 3 1 0 9 6]
 [6 7 9 5 1 2 8 3 0 4]
 [1 2 5 7 0 4 3 8 9 6]
 [1 6 2 4 7 8 0 9 5 3]
 [8 0 1 9 7 5 2 3 4 6]
 [4 2 5 3 7 8 9 6 0 1]
 [4 5 1 0 2 6 8 7 3 9]
 [4 6 7 3 0 1 2 5 9 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 9 4 0 2 6 8 1 7]
 [9 1 7 0 8 5 3 2 6 4]
 [6 9 4 8 5 2 1 3 0 7]
 [8 4 9 3 2 7 1 0 6 5]
 [5 2 0 7 6 8 4 1 3 9]
 [0 6 9 8 4 1 2 5 3 7]
 [7 5 1 4 2 0 6 9 3 8]
 [8 1 0 2 9 7 3 4 5 6]
 [8 2 6 1 0 3 7 9 5 4]
 [8 1 4 9 6 7 0 5 3 2]]
Epoch 80710: Training cost= 2.3026, Training acc= 0.6802, Validation cost= 2.3026, Validation acc= 0.6798
Epoch 80720: Training cost= 2.3026, Training acc= 0.6801, Validation cost= 2.3026, Validation acc= 0.6798
Epoch 80730: Training cost= 2.3026, Training acc= 0.6801, Validation cost= 2.3026, Validation acc= 0.6797
Epoch 80740: Training cost= 2.3026, Training acc= 0.6800, Validation cost= 2.3026, Validation acc= 0.6796
Epoch 80750: Training cost= 2.3026, Training acc= 0.6799, Validation cost= 2.3026, Validation acc= 0.6795
Epoch 80760: Training cost= 2.3026, Training acc= 0.6799, Validation cost= 2.3026, Validation acc= 0.6795
Epoch 80770: Training cost= 2.3026, Training acc= 0.6798, Validation cost= 2.3026, Validation acc= 0.6794
Epoch 80780: Training cost= 2.3026, Training acc= 0.6797, Validation cost= 2.3026, Validation acc= 0.6793
Epoch 80790: Training cost= 2.3026, Training acc= 0.6796, Validation cost= 2.3026, Validation acc= 0.6793
Epoch 80800: Training cost= 2.3026, Training acc= 0.6796, Validation cost= 2.3026, Validation acc= 0.6792
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 6 3 0 9 7 1 4 8 5]
 [1 0 2 7 3 5 6 8 9 4]
 [7 9 1 8 2 3 4 6 5 0]
 [1 9 5 3 6 0 7 4 2 8]
 [2 6 1 9 3 5 7 4 0 8]
 [2 7 6 4 5 1 9 0 8 3]
 [6 5 2 9 8 7 1 4 0 3]
 [5 8 3 6 2 1 7 0 9 4]
 [7 4 0 1 8 9 5 2 3 6]
 [5 6 2 3 9 7 1 8 4 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 2 7 9 1 3 8 0 5 6]
 [7 2 3 0 9 4 6 8 1 5]
 [3 2 4 6 0 8 1 9 5 7]
 [1 2 4 5 9 6 8 3 0 7]
 [6 9 3 1 7 4 8 5 0 2]
 [5 3 9 2 0 7 6 4 8 1]
 [5 2 7 0 9 4 3 8 1 6]
 [5 2 7 0 3 1 8 4 9 6]
 [4 5 7 8 9 2 1 6 0 3]
 [6 4 3 2 5 7 0 9 1 8]]
Epoch 80810: Training cost= 2.3026, Training acc= 0.6795, Validation cost= 2.3026, Validation acc= 0.6791
Epoch 80820: Training cost= 2.3026, Training acc= 0.6794, Validation cost= 2.3026, Validation acc= 0.6790
Epoch 80830: Training cost= 2.3026, Training acc= 0.6794, Validation cost= 2.3026, Validation acc= 0.6790
Epoch 80840: Training cost= 2.3026, Training acc= 0.6793, Validation cost= 2.3026, Validation acc= 0.6789
Epoch 80850: Training cost= 2.3026, Training acc= 0.6792, Validation cost= 2.3026, Validation acc= 0.6788
Epoch 80860: Training cost= 2.3026, Training acc= 0.6791, Validation cost= 2.3026, Validation acc= 0.6787
Epoch 80870: Training cost= 2.3026, Training acc= 0.6791, Validation cost= 2.3026, Validation acc= 0.6787
Epoch 80880: Training cost= 2.3026, Training acc= 0.6790, Validation cost= 2.3026, Validation acc= 0.6786
Epoch 80890: Training cost= 2.3026, Training acc= 0.6789, Validation cost= 2.3026, Validation acc= 0.6785
Epoch 80900: Training cost= 2.3026, Training acc= 0.6789, Validation cost= 2.3026, Validation acc= 0.6785
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 7 2 4 3 6 0 5 8]
 [4 1 7 9 2 8 6 0 5 3]
 [0 6 2 3 9 5 8 7 1 4]
 [3 5 1 9 0 7 6 2 8 4]
 [4 6 1 0 9 5 8 3 7 2]
 [6 1 0 7 9 3 4 2 8 5]
 [2 6 5 1 3 9 7 8 0 4]
 [1 8 2 9 0 7 5 4 3 6]
 [5 6 9 4 3 2 8 0 7 1]
 [2 8 3 4 9 1 7 6 5 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 3 8 2 9 4 1 0 7 5]
 [6 3 7 1 0 4 2 9 8 5]
 [3 8 9 6 5 2 4 1 0 7]
 [5 1 6 9 4 0 2 7 3 8]
 [7 4 9 0 3 6 2 1 8 5]
 [3 8 7 6 5 9 2 0 1 4]
 [0 4 2 6 3 1 9 7 8 5]
 [5 1 0 9 7 3 4 8 6 2]
 [1 9 0 3 2 8 6 4 7 5]
 [2 7 3 1 4 0 9 5 6 8]]
Epoch 80910: Training cost= 2.3026, Training acc= 0.6788, Validation cost= 2.3026, Validation acc= 0.6784
Epoch 80920: Training cost= 2.3026, Training acc= 0.6787, Validation cost= 2.3026, Validation acc= 0.6783
Epoch 80930: Training cost= 2.3026, Training acc= 0.6786, Validation cost= 2.3026, Validation acc= 0.6782
Epoch 80940: Training cost= 2.3026, Training acc= 0.6786, Validation cost= 2.3026, Validation acc= 0.6782
Epoch 80950: Training cost= 2.3026, Training acc= 0.6785, Validation cost= 2.3026, Validation acc= 0.6781
Epoch 80960: Training cost= 2.3026, Training acc= 0.6784, Validation cost= 2.3026, Validation acc= 0.6780
Epoch 80970: Training cost= 2.3026, Training acc= 0.6784, Validation cost= 2.3026, Validation acc= 0.6780
Epoch 80980: Training cost= 2.3026, Training acc= 0.6783, Validation cost= 2.3026, Validation acc= 0.6779
Epoch 80990: Training cost= 2.3026, Training acc= 0.6782, Validation cost= 2.3026, Validation acc= 0.6778
Epoch 81000: Training cost= 2.3026, Training acc= 0.6781, Validation cost= 2.3026, Validation acc= 0.6777
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 8 0 4 2 5 9 3 6 1]
 [9 6 3 2 4 7 0 5 1 8]
 [7 5 2 6 4 0 8 9 1 3]
 [1 2 7 9 6 5 0 8 3 4]
 [4 6 2 3 8 1 0 9 7 5]
 [1 0 6 4 7 3 9 2 5 8]
 [6 1 9 2 3 4 8 7 5 0]
 [6 8 2 9 7 1 4 3 5 0]
 [2 5 0 4 3 7 6 1 8 9]
 [8 0 9 1 6 3 2 4 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 6 5 2 8 0 4 9 3 1]
 [9 8 5 1 4 6 3 7 2 0]
 [5 1 8 4 6 0 3 9 2 7]
 [5 2 3 1 8 7 6 4 9 0]
 [1 6 3 2 0 7 4 9 5 8]
 [0 9 1 4 5 6 2 3 8 7]
 [4 1 3 5 2 8 9 6 7 0]
 [6 9 7 8 4 5 3 1 0 2]
 [6 7 0 1 3 2 4 8 5 9]
 [9 7 8 4 5 0 1 2 3 6]]
Epoch 81010: Training cost= 2.3026, Training acc= 0.6781, Validation cost= 2.3026, Validation acc= 0.6777
Epoch 81020: Training cost= 2.3026, Training acc= 0.6780, Validation cost= 2.3026, Validation acc= 0.6776
Epoch 81030: Training cost= 2.3026, Training acc= 0.6779, Validation cost= 2.3026, Validation acc= 0.6775
Epoch 81040: Training cost= 2.3026, Training acc= 0.6779, Validation cost= 2.3026, Validation acc= 0.6775
Epoch 81050: Training cost= 2.3026, Training acc= 0.6778, Validation cost= 2.3026, Validation acc= 0.6774
Epoch 81060: Training cost= 2.3026, Training acc= 0.6777, Validation cost= 2.3026, Validation acc= 0.6773
Epoch 81070: Training cost= 2.3026, Training acc= 0.6776, Validation cost= 2.3026, Validation acc= 0.6773
Epoch 81080: Training cost= 2.3026, Training acc= 0.6776, Validation cost= 2.3026, Validation acc= 0.6772
Epoch 81090: Training cost= 2.3026, Training acc= 0.6775, Validation cost= 2.3026, Validation acc= 0.6771
Epoch 81100: Training cost= 2.3026, Training acc= 0.6774, Validation cost= 2.3026, Validation acc= 0.6770
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 7 3 0 5 4 8 6 2]
 [6 0 9 1 7 5 3 4 2 8]
 [9 1 7 5 3 6 0 2 8 4]
 [2 1 9 4 0 3 7 6 5 8]
 [3 2 0 8 9 6 1 4 5 7]
 [2 7 0 3 6 4 1 9 5 8]
 [6 0 2 7 3 8 5 9 4 1]
 [6 4 5 2 3 1 0 9 8 7]
 [0 1 8 5 4 2 3 9 7 6]
 [5 4 0 9 3 8 2 7 1 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 1 6 3 5 0 8 7 9 4]
 [9 6 3 7 0 2 5 8 1 4]
 [1 8 3 4 6 7 0 9 2 5]
 [1 4 9 2 0 6 5 3 8 7]
 [5 9 2 3 0 6 4 1 8 7]
 [7 5 8 9 6 4 3 2 1 0]
 [1 7 2 8 5 4 3 9 0 6]
 [5 1 3 2 6 8 0 7 4 9]
 [9 1 8 3 0 4 7 6 2 5]
 [0 5 8 3 1 4 7 6 2 9]]
Epoch 81110: Training cost= 2.3026, Training acc= 0.6774, Validation cost= 2.3026, Validation acc= 0.6770
Epoch 81120: Training cost= 2.3026, Training acc= 0.6773, Validation cost= 2.3026, Validation acc= 0.6769
Epoch 81130: Training cost= 2.3026, Training acc= 0.6772, Validation cost= 2.3026, Validation acc= 0.6768
Epoch 81140: Training cost= 2.3026, Training acc= 0.6771, Validation cost= 2.3026, Validation acc= 0.6768
Epoch 81150: Training cost= 2.3026, Training acc= 0.6771, Validation cost= 2.3026, Validation acc= 0.6767
Epoch 81160: Training cost= 2.3026, Training acc= 0.6770, Validation cost= 2.3026, Validation acc= 0.6766
Epoch 81170: Training cost= 2.3026, Training acc= 0.6769, Validation cost= 2.3026, Validation acc= 0.6765
Epoch 81180: Training cost= 2.3026, Training acc= 0.6769, Validation cost= 2.3026, Validation acc= 0.6765
Epoch 81190: Training cost= 2.3026, Training acc= 0.6768, Validation cost= 2.3026, Validation acc= 0.6764
Epoch 81200: Training cost= 2.3026, Training acc= 0.6767, Validation cost= 2.3026, Validation acc= 0.6763
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 9 4 2 8 7 3 6 0 1]
 [2 5 7 4 1 8 6 3 0 9]
 [3 9 7 8 5 2 6 0 4 1]
 [2 1 8 7 5 4 9 6 3 0]
 [9 3 1 5 2 0 4 8 6 7]
 [8 1 7 2 6 5 3 9 4 0]
 [9 1 5 2 0 8 4 7 3 6]
 [5 7 9 2 4 3 1 8 0 6]
 [9 3 6 8 4 5 7 1 0 2]
 [0 5 4 6 8 9 1 3 2 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 7 8 2 0 5 9 6 1]
 [2 9 3 8 5 4 7 1 6 0]
 [9 8 0 1 2 7 4 6 5 3]
 [1 0 4 7 8 2 9 5 3 6]
 [2 5 8 3 9 6 7 0 1 4]
 [6 7 0 2 8 4 1 5 9 3]
 [0 6 7 5 9 8 2 4 1 3]
 [6 4 5 3 2 1 0 9 8 7]
 [7 9 8 3 6 0 2 5 4 1]
 [7 0 1 6 4 5 2 3 9 8]]
Epoch 81210: Training cost= 2.3026, Training acc= 0.6766, Validation cost= 2.3026, Validation acc= 0.6763
Epoch 81220: Training cost= 2.3026, Training acc= 0.6766, Validation cost= 2.3026, Validation acc= 0.6762
Epoch 81230: Training cost= 2.3026, Training acc= 0.6765, Validation cost= 2.3026, Validation acc= 0.6761
Epoch 81240: Training cost= 2.3026, Training acc= 0.6764, Validation cost= 2.3026, Validation acc= 0.6760
Epoch 81250: Training cost= 2.3026, Training acc= 0.6764, Validation cost= 2.3026, Validation acc= 0.6760
Epoch 81260: Training cost= 2.3026, Training acc= 0.6763, Validation cost= 2.3026, Validation acc= 0.6759
Epoch 81270: Training cost= 2.3026, Training acc= 0.6762, Validation cost= 2.3026, Validation acc= 0.6758
Epoch 81280: Training cost= 2.3026, Training acc= 0.6762, Validation cost= 2.3026, Validation acc= 0.6758
Epoch 81290: Training cost= 2.3026, Training acc= 0.6761, Validation cost= 2.3026, Validation acc= 0.6757
Epoch 81300: Training cost= 2.3026, Training acc= 0.6760, Validation cost= 2.3026, Validation acc= 0.6756
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 1 4 0 3 7 8 6 5 2]
 [0 9 1 8 7 6 5 3 4 2]
 [7 6 5 3 8 4 2 9 0 1]
 [8 1 4 2 3 0 6 5 7 9]
 [8 3 6 7 2 0 5 1 9 4]
 [9 0 8 6 3 4 5 7 1 2]
 [4 0 5 9 2 3 7 1 6 8]
 [6 9 2 4 5 0 7 1 8 3]
 [9 6 2 3 5 4 0 7 1 8]
 [9 4 3 2 5 7 8 1 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 7 1 6 8 3 9 5 4 2]
 [7 8 1 9 4 2 0 5 6 3]
 [9 4 3 7 5 1 0 2 8 6]
 [7 3 4 9 8 1 0 5 6 2]
 [4 1 3 8 7 9 0 6 2 5]
 [4 6 2 1 5 9 3 7 0 8]
 [1 7 9 5 0 2 6 8 3 4]
 [0 3 4 5 7 2 1 9 8 6]
 [7 0 1 6 9 5 2 3 4 8]
 [2 0 9 6 8 5 1 3 7 4]]
Epoch 81310: Training cost= 2.3026, Training acc= 0.6759, Validation cost= 2.3026, Validation acc= 0.6755
Epoch 81320: Training cost= 2.3026, Training acc= 0.6759, Validation cost= 2.3026, Validation acc= 0.6755
Epoch 81330: Training cost= 2.3026, Training acc= 0.6758, Validation cost= 2.3026, Validation acc= 0.6754
Epoch 81340: Training cost= 2.3026, Training acc= 0.6757, Validation cost= 2.3026, Validation acc= 0.6753
Epoch 81350: Training cost= 2.3026, Training acc= 0.6757, Validation cost= 2.3026, Validation acc= 0.6753
Epoch 81360: Training cost= 2.3026, Training acc= 0.6756, Validation cost= 2.3026, Validation acc= 0.6752
Epoch 81370: Training cost= 2.3026, Training acc= 0.6755, Validation cost= 2.3026, Validation acc= 0.6751
Epoch 81380: Training cost= 2.3026, Training acc= 0.6754, Validation cost= 2.3026, Validation acc= 0.6751
Epoch 81390: Training cost= 2.3026, Training acc= 0.6754, Validation cost= 2.3026, Validation acc= 0.6750
Epoch 81400: Training cost= 2.3026, Training acc= 0.6753, Validation cost= 2.3026, Validation acc= 0.6749
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 9 7 6 2 4 3 1 8 0]
 [7 8 9 6 1 0 4 2 3 5]
 [9 6 7 1 4 3 2 5 0 8]
 [5 0 4 8 1 6 2 3 9 7]
 [4 3 8 9 6 0 1 7 2 5]
 [7 8 3 0 9 6 2 5 4 1]
 [3 5 7 9 0 8 6 1 4 2]
 [6 4 9 5 2 7 1 3 8 0]
 [2 5 4 6 3 1 7 8 0 9]
 [1 6 4 5 8 9 2 7 0 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 8 9 6 0 7 2 3 4 5]
 [1 2 8 5 3 0 4 9 6 7]
 [5 7 4 6 2 9 3 1 0 8]
 [5 3 0 6 4 8 1 7 2 9]
 [1 4 5 3 0 7 8 2 6 9]
 [3 0 7 8 1 5 4 6 9 2]
 [5 1 3 7 8 0 4 9 6 2]
 [1 5 4 7 9 0 3 6 2 8]
 [8 2 6 5 1 9 0 3 4 7]
 [5 2 1 8 3 0 9 4 6 7]]
Epoch 81410: Training cost= 2.3026, Training acc= 0.6752, Validation cost= 2.3026, Validation acc= 0.6748
Epoch 81420: Training cost= 2.3026, Training acc= 0.6752, Validation cost= 2.3026, Validation acc= 0.6748
Epoch 81430: Training cost= 2.3026, Training acc= 0.6751, Validation cost= 2.3026, Validation acc= 0.6747
Epoch 81440: Training cost= 2.3026, Training acc= 0.6750, Validation cost= 2.3026, Validation acc= 0.6746
Epoch 81450: Training cost= 2.3026, Training acc= 0.6749, Validation cost= 2.3026, Validation acc= 0.6746
Epoch 81460: Training cost= 2.3026, Training acc= 0.6749, Validation cost= 2.3026, Validation acc= 0.6745
Epoch 81470: Training cost= 2.3026, Training acc= 0.6748, Validation cost= 2.3026, Validation acc= 0.6744
Epoch 81480: Training cost= 2.3026, Training acc= 0.6747, Validation cost= 2.3026, Validation acc= 0.6743
Epoch 81490: Training cost= 2.3026, Training acc= 0.6747, Validation cost= 2.3026, Validation acc= 0.6743
Epoch 81500: Training cost= 2.3026, Training acc= 0.6746, Validation cost= 2.3026, Validation acc= 0.6742
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 5 8 1 6 9 2 0 4 3]
 [0 6 3 2 1 5 8 9 4 7]
 [7 9 2 6 5 3 1 0 4 8]
 [5 8 0 3 1 4 2 9 6 7]
 [7 5 0 4 3 6 9 1 2 8]
 [8 9 3 6 1 0 2 7 5 4]
 [1 3 8 2 9 6 4 0 7 5]
 [1 9 7 6 8 3 4 0 2 5]
 [5 8 7 1 3 4 2 9 6 0]
 [8 5 1 4 0 2 9 6 3 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 7 5 9 4 8 3 1 0 6]
 [0 8 3 6 2 4 7 9 5 1]
 [8 1 2 0 9 3 4 6 7 5]
 [7 0 1 4 2 8 9 5 6 3]
 [7 4 8 1 5 3 0 6 2 9]
 [5 3 1 2 0 7 9 8 6 4]
 [4 8 1 9 7 0 5 2 6 3]
 [3 7 1 5 4 0 6 2 8 9]
 [7 6 8 0 1 3 2 5 9 4]
 [9 8 1 0 2 5 7 6 4 3]]
Epoch 81510: Training cost= 2.3026, Training acc= 0.6745, Validation cost= 2.3026, Validation acc= 0.6741
Epoch 81520: Training cost= 2.3026, Training acc= 0.6745, Validation cost= 2.3026, Validation acc= 0.6741
Epoch 81530: Training cost= 2.3026, Training acc= 0.6744, Validation cost= 2.3026, Validation acc= 0.6740
Epoch 81540: Training cost= 2.3026, Training acc= 0.6743, Validation cost= 2.3026, Validation acc= 0.6739
Epoch 81550: Training cost= 2.3026, Training acc= 0.6742, Validation cost= 2.3026, Validation acc= 0.6739
Epoch 81560: Training cost= 2.3026, Training acc= 0.6742, Validation cost= 2.3026, Validation acc= 0.6738
Epoch 81570: Training cost= 2.3026, Training acc= 0.6741, Validation cost= 2.3026, Validation acc= 0.6737
Epoch 81580: Training cost= 2.3026, Training acc= 0.6740, Validation cost= 2.3026, Validation acc= 0.6736
Epoch 81590: Training cost= 2.3026, Training acc= 0.6740, Validation cost= 2.3026, Validation acc= 0.6736
Epoch 81600: Training cost= 2.3026, Training acc= 0.6739, Validation cost= 2.3026, Validation acc= 0.6735
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 4 1 5 3 7 8 6 9 0]
 [6 8 7 2 5 3 0 4 1 9]
 [4 9 1 3 6 0 5 8 2 7]
 [3 4 0 7 9 6 5 1 2 8]
 [6 2 4 1 9 7 5 0 3 8]
 [1 6 3 9 5 7 0 2 4 8]
 [8 6 1 4 3 2 7 9 5 0]
 [3 5 6 4 7 1 2 8 9 0]
 [0 7 5 3 6 9 1 8 4 2]
 [8 2 5 3 4 1 6 0 7 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 0 7 1 6 3 2 8 5 4]
 [9 3 6 0 4 1 8 7 5 2]
 [0 7 8 1 9 6 5 3 2 4]
 [9 2 3 6 7 8 1 5 0 4]
 [7 4 1 5 9 2 0 8 3 6]
 [8 2 5 3 7 4 0 9 1 6]
 [5 6 1 8 4 7 3 9 0 2]
 [4 8 9 0 2 7 5 1 6 3]
 [8 3 2 9 7 4 0 1 6 5]
 [6 9 3 1 8 0 7 2 5 4]]
Epoch 81610: Training cost= 2.3026, Training acc= 0.6738, Validation cost= 2.3026, Validation acc= 0.6734
Epoch 81620: Training cost= 2.3026, Training acc= 0.6738, Validation cost= 2.3026, Validation acc= 0.6734
Epoch 81630: Training cost= 2.3026, Training acc= 0.6737, Validation cost= 2.3026, Validation acc= 0.6733
Epoch 81640: Training cost= 2.3026, Training acc= 0.6736, Validation cost= 2.3026, Validation acc= 0.6732
Epoch 81650: Training cost= 2.3026, Training acc= 0.6735, Validation cost= 2.3026, Validation acc= 0.6731
Epoch 81660: Training cost= 2.3026, Training acc= 0.6735, Validation cost= 2.3026, Validation acc= 0.6731
Epoch 81670: Training cost= 2.3026, Training acc= 0.6734, Validation cost= 2.3026, Validation acc= 0.6730
Epoch 81680: Training cost= 2.3026, Training acc= 0.6733, Validation cost= 2.3026, Validation acc= 0.6729
Epoch 81690: Training cost= 2.3026, Training acc= 0.6733, Validation cost= 2.3026, Validation acc= 0.6729
Epoch 81700: Training cost= 2.3026, Training acc= 0.6732, Validation cost= 2.3026, Validation acc= 0.6728
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 2 8 3 0 7 4 5 6 1]
 [0 5 6 8 9 4 1 3 2 7]
 [7 2 9 4 1 6 3 0 8 5]
 [0 7 3 5 6 9 4 8 2 1]
 [9 0 8 5 2 6 4 7 1 3]
 [0 4 1 2 9 5 7 6 8 3]
 [1 7 3 9 8 2 5 0 4 6]
 [7 8 4 0 6 2 5 1 3 9]
 [2 9 1 8 0 5 3 7 4 6]
 [5 8 2 7 6 9 1 0 3 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 2 7 1 5 9 0 6 3 4]
 [7 9 3 8 6 5 0 1 2 4]
 [8 6 3 2 0 4 5 1 9 7]
 [4 6 0 5 1 2 8 3 9 7]
 [7 2 0 8 5 1 9 4 6 3]
 [0 3 9 8 4 5 6 2 7 1]
 [6 9 8 7 4 2 3 1 0 5]
 [6 1 3 9 8 4 0 5 2 7]
 [9 0 1 7 4 6 3 5 8 2]
 [3 8 5 7 4 1 2 9 6 0]]
Epoch 81710: Training cost= 2.3026, Training acc= 0.6731, Validation cost= 2.3026, Validation acc= 0.6727
Epoch 81720: Training cost= 2.3026, Training acc= 0.6730, Validation cost= 2.3026, Validation acc= 0.6727
Epoch 81730: Training cost= 2.3026, Training acc= 0.6730, Validation cost= 2.3026, Validation acc= 0.6726
Epoch 81740: Training cost= 2.3026, Training acc= 0.6729, Validation cost= 2.3026, Validation acc= 0.6725
Epoch 81750: Training cost= 2.3026, Training acc= 0.6728, Validation cost= 2.3026, Validation acc= 0.6724
Epoch 81760: Training cost= 2.3026, Training acc= 0.6728, Validation cost= 2.3026, Validation acc= 0.6724
Epoch 81770: Training cost= 2.3026, Training acc= 0.6727, Validation cost= 2.3026, Validation acc= 0.6723
Epoch 81780: Training cost= 2.3026, Training acc= 0.6726, Validation cost= 2.3026, Validation acc= 0.6722
Epoch 81790: Training cost= 2.3026, Training acc= 0.6726, Validation cost= 2.3026, Validation acc= 0.6722
Epoch 81800: Training cost= 2.3026, Training acc= 0.6725, Validation cost= 2.3026, Validation acc= 0.6721
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 7 9 8 5 4 1 6 3 0]
 [4 0 8 1 9 7 6 3 2 5]
 [5 7 8 4 3 6 1 0 9 2]
 [7 4 0 3 5 1 2 8 6 9]
 [0 7 9 6 1 4 8 2 3 5]
 [8 3 4 6 9 7 0 1 5 2]
 [2 7 6 8 4 3 0 9 5 1]
 [1 5 4 0 6 3 8 7 2 9]
 [3 8 2 6 5 7 1 0 9 4]
 [4 3 9 2 7 6 8 0 5 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 3 5 8 0 9 4 6 7 2]
 [1 0 7 8 3 4 9 5 6 2]
 [8 3 2 9 5 7 1 6 4 0]
 [8 5 3 9 7 4 2 0 1 6]
 [1 0 2 8 3 6 7 4 9 5]
 [5 2 0 9 4 6 1 7 3 8]
 [5 6 2 1 9 3 8 4 0 7]
 [2 5 9 4 1 7 3 6 8 0]
 [7 2 8 6 9 1 0 3 4 5]
 [7 5 8 0 3 4 9 6 1 2]]
Epoch 81810: Training cost= 2.3026, Training acc= 0.6724, Validation cost= 2.3026, Validation acc= 0.6720
Epoch 81820: Training cost= 2.3026, Training acc= 0.6723, Validation cost= 2.3026, Validation acc= 0.6720
Epoch 81830: Training cost= 2.3026, Training acc= 0.6723, Validation cost= 2.3026, Validation acc= 0.6719
Epoch 81840: Training cost= 2.3026, Training acc= 0.6722, Validation cost= 2.3026, Validation acc= 0.6718
Epoch 81850: Training cost= 2.3026, Training acc= 0.6721, Validation cost= 2.3026, Validation acc= 0.6717
Epoch 81860: Training cost= 2.3026, Training acc= 0.6721, Validation cost= 2.3026, Validation acc= 0.6717
Epoch 81870: Training cost= 2.3026, Training acc= 0.6720, Validation cost= 2.3026, Validation acc= 0.6716
Epoch 81880: Training cost= 2.3026, Training acc= 0.6719, Validation cost= 2.3026, Validation acc= 0.6715
Epoch 81890: Training cost= 2.3026, Training acc= 0.6719, Validation cost= 2.3026, Validation acc= 0.6715
Epoch 81900: Training cost= 2.3026, Training acc= 0.6718, Validation cost= 2.3026, Validation acc= 0.6714
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 2 6 1 4 8 5 0 7 9]
 [1 2 8 5 3 4 0 6 7 9]
 [5 8 1 6 7 4 0 3 9 2]
 [5 1 4 9 3 0 7 2 8 6]
 [8 0 2 4 3 7 5 9 1 6]
 [8 7 9 1 5 6 4 3 0 2]
 [7 1 2 3 6 8 0 4 9 5]
 [8 7 4 3 1 5 2 6 9 0]
 [9 1 6 8 5 7 3 0 4 2]
 [5 3 9 6 2 0 1 4 8 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 5 0 9 2 6 8 1 7 4]
 [0 7 2 4 9 3 8 1 6 5]
 [0 1 7 5 9 6 8 3 4 2]
 [5 6 3 7 8 0 2 1 9 4]
 [1 2 0 3 8 7 6 4 5 9]
 [1 0 5 3 8 2 7 4 9 6]
 [9 0 7 4 2 3 8 1 5 6]
 [1 5 3 9 0 6 2 7 8 4]
 [0 7 1 5 6 4 8 3 9 2]
 [9 0 2 8 1 7 3 4 6 5]]
Epoch 81910: Training cost= 2.3026, Training acc= 0.6717, Validation cost= 2.3026, Validation acc= 0.6713
Epoch 81920: Training cost= 2.3026, Training acc= 0.6716, Validation cost= 2.3026, Validation acc= 0.6713
Epoch 81930: Training cost= 2.3026, Training acc= 0.6716, Validation cost= 2.3026, Validation acc= 0.6712
Epoch 81940: Training cost= 2.3026, Training acc= 0.6715, Validation cost= 2.3026, Validation acc= 0.6711
Epoch 81950: Training cost= 2.3026, Training acc= 0.6714, Validation cost= 2.3026, Validation acc= 0.6711
Epoch 81960: Training cost= 2.3026, Training acc= 0.6714, Validation cost= 2.3026, Validation acc= 0.6710
Epoch 81970: Training cost= 2.3026, Training acc= 0.6713, Validation cost= 2.3026, Validation acc= 0.6709
Epoch 81980: Training cost= 2.3026, Training acc= 0.6712, Validation cost= 2.3026, Validation acc= 0.6708
Epoch 81990: Training cost= 2.3026, Training acc= 0.6712, Validation cost= 2.3026, Validation acc= 0.6708
Epoch 82000: Training cost= 2.3026, Training acc= 0.6711, Validation cost= 2.3026, Validation acc= 0.6707
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 4 1 3 9 7 6 5 8 2]
 [4 0 2 1 7 8 9 3 5 6]
 [4 9 7 6 0 1 5 3 2 8]
 [8 4 1 7 6 0 2 3 5 9]
 [2 6 1 4 3 0 5 9 8 7]
 [2 7 8 1 6 9 4 3 0 5]
 [6 9 5 7 8 0 2 1 3 4]
 [8 7 3 4 9 6 0 1 2 5]
 [1 8 2 6 0 4 5 7 9 3]
 [4 3 6 9 8 2 0 7 1 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 4 0 5 1 8 2 9 3 6]
 [3 6 9 1 2 0 7 8 5 4]
 [1 3 0 6 9 4 2 5 8 7]
 [2 1 3 4 9 6 7 8 0 5]
 [1 9 4 6 0 3 2 5 7 8]
 [2 9 4 7 8 0 5 6 1 3]
 [0 2 1 8 9 5 6 3 4 7]
 [6 8 4 5 2 9 7 1 0 3]
 [8 4 9 7 2 6 0 3 5 1]
 [0 6 9 1 3 5 8 7 4 2]]
Epoch 82010: Training cost= 2.3026, Training acc= 0.6710, Validation cost= 2.3026, Validation acc= 0.6706
Epoch 82020: Training cost= 2.3026, Training acc= 0.6710, Validation cost= 2.3026, Validation acc= 0.6706
Epoch 82030: Training cost= 2.3026, Training acc= 0.6709, Validation cost= 2.3026, Validation acc= 0.6705
Epoch 82040: Training cost= 2.3026, Training acc= 0.6708, Validation cost= 2.3026, Validation acc= 0.6704
Epoch 82050: Training cost= 2.3026, Training acc= 0.6707, Validation cost= 2.3026, Validation acc= 0.6704
Epoch 82060: Training cost= 2.3026, Training acc= 0.6707, Validation cost= 2.3026, Validation acc= 0.6703
Epoch 82070: Training cost= 2.3026, Training acc= 0.6706, Validation cost= 2.3026, Validation acc= 0.6702
Epoch 82080: Training cost= 2.3026, Training acc= 0.6705, Validation cost= 2.3026, Validation acc= 0.6701
Epoch 82090: Training cost= 2.3026, Training acc= 0.6705, Validation cost= 2.3026, Validation acc= 0.6701
Epoch 82100: Training cost= 2.3026, Training acc= 0.6704, Validation cost= 2.3026, Validation acc= 0.6700
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 8 4 1 7 6 5 2 9 3]
 [7 9 6 2 4 3 8 1 5 0]
 [9 6 5 4 8 7 1 0 3 2]
 [0 2 4 8 7 5 3 9 6 1]
 [9 2 7 5 1 6 8 4 0 3]
 [0 2 9 3 6 7 8 1 4 5]
 [8 9 4 3 0 7 6 2 1 5]
 [6 3 0 1 4 8 9 7 2 5]
 [1 8 5 6 3 4 7 9 0 2]
 [5 3 9 2 6 4 7 0 8 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 6 8 9 1 7 0 5 3 4]
 [8 5 3 0 4 2 6 7 9 1]
 [4 9 1 0 7 5 8 3 6 2]
 [6 7 1 5 9 8 0 4 3 2]
 [6 5 0 2 9 7 8 4 3 1]
 [3 0 7 8 4 5 6 1 2 9]
 [5 2 4 9 0 8 7 3 6 1]
 [3 2 4 6 7 9 8 0 5 1]
 [7 6 8 4 9 1 0 2 3 5]
 [2 5 8 3 9 7 4 1 6 0]]
Epoch 82110: Training cost= 2.3026, Training acc= 0.6703, Validation cost= 2.3026, Validation acc= 0.6699
Epoch 82120: Training cost= 2.3026, Training acc= 0.6703, Validation cost= 2.3026, Validation acc= 0.6699
Epoch 82130: Training cost= 2.3026, Training acc= 0.6702, Validation cost= 2.3026, Validation acc= 0.6698
Epoch 82140: Training cost= 2.3026, Training acc= 0.6701, Validation cost= 2.3026, Validation acc= 0.6697
Epoch 82150: Training cost= 2.3026, Training acc= 0.6700, Validation cost= 2.3026, Validation acc= 0.6697
Epoch 82160: Training cost= 2.3026, Training acc= 0.6700, Validation cost= 2.3026, Validation acc= 0.6696
Epoch 82170: Training cost= 2.3026, Training acc= 0.6699, Validation cost= 2.3026, Validation acc= 0.6695
Epoch 82180: Training cost= 2.3026, Training acc= 0.6698, Validation cost= 2.3026, Validation acc= 0.6695
Epoch 82190: Training cost= 2.3026, Training acc= 0.6698, Validation cost= 2.3026, Validation acc= 0.6694
Epoch 82200: Training cost= 2.3026, Training acc= 0.6697, Validation cost= 2.3026, Validation acc= 0.6693
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 3 8 4 2 6 0 5 1 9]
 [1 3 0 2 4 5 7 6 8 9]
 [7 6 9 3 4 1 0 2 5 8]
 [9 7 2 5 4 0 6 3 1 8]
 [6 3 8 5 1 0 7 4 9 2]
 [5 1 9 4 6 8 7 2 3 0]
 [1 6 5 0 7 2 3 4 8 9]
 [8 1 2 9 6 7 5 0 3 4]
 [9 0 8 5 1 2 7 6 3 4]
 [5 2 6 3 8 1 4 7 0 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 6 2 4 1 5 7 3 9 8]
 [0 4 7 9 1 2 6 8 3 5]
 [9 5 2 1 8 0 3 6 4 7]
 [7 1 9 2 3 0 6 4 5 8]
 [7 5 1 2 3 9 6 0 4 8]
 [6 0 2 8 4 9 7 3 1 5]
 [8 9 5 3 1 2 4 6 7 0]
 [3 8 7 9 1 0 6 2 4 5]
 [9 6 5 0 1 3 7 2 8 4]
 [5 1 8 6 0 7 4 9 3 2]]
Epoch 82210: Training cost= 2.3026, Training acc= 0.6696, Validation cost= 2.3026, Validation acc= 0.6692
Epoch 82220: Training cost= 2.3026, Training acc= 0.6696, Validation cost= 2.3026, Validation acc= 0.6692
Epoch 82230: Training cost= 2.3026, Training acc= 0.6695, Validation cost= 2.3026, Validation acc= 0.6691
Epoch 82240: Training cost= 2.3026, Training acc= 0.6694, Validation cost= 2.3026, Validation acc= 0.6690
Epoch 82250: Training cost= 2.3026, Training acc= 0.6694, Validation cost= 2.3026, Validation acc= 0.6690
Epoch 82260: Training cost= 2.3026, Training acc= 0.6693, Validation cost= 2.3026, Validation acc= 0.6689
Epoch 82270: Training cost= 2.3026, Training acc= 0.6692, Validation cost= 2.3026, Validation acc= 0.6688
Epoch 82280: Training cost= 2.3026, Training acc= 0.6691, Validation cost= 2.3026, Validation acc= 0.6688
Epoch 82290: Training cost= 2.3026, Training acc= 0.6691, Validation cost= 2.3026, Validation acc= 0.6687
Epoch 82300: Training cost= 2.3026, Training acc= 0.6690, Validation cost= 2.3026, Validation acc= 0.6686
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 3 2 5 6 4 0 7 1 8]
 [6 8 5 3 9 1 4 7 2 0]
 [0 9 6 2 1 3 8 5 4 7]
 [6 7 0 5 1 9 2 8 4 3]
 [8 7 2 3 6 9 4 5 1 0]
 [5 8 1 9 0 4 7 6 2 3]
 [0 6 5 9 8 4 2 1 7 3]
 [3 0 8 2 1 6 7 5 9 4]
 [1 3 6 2 5 7 9 0 4 8]
 [1 5 7 0 6 9 4 3 2 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 5 0 1 9 4 2 8 3 6]
 [7 3 2 8 4 1 6 5 0 9]
 [7 9 4 3 6 5 8 0 2 1]
 [7 1 6 2 9 4 3 8 0 5]
 [8 6 4 1 2 7 5 9 0 3]
 [5 1 6 0 9 8 4 3 7 2]
 [3 0 9 8 1 5 4 6 2 7]
 [0 6 7 2 1 4 3 5 9 8]
 [3 7 0 1 6 2 9 8 5 4]
 [7 4 2 3 8 0 6 1 5 9]]
Epoch 82310: Training cost= 2.3026, Training acc= 0.6689, Validation cost= 2.3026, Validation acc= 0.6686
Epoch 82320: Training cost= 2.3026, Training acc= 0.6689, Validation cost= 2.3026, Validation acc= 0.6685
Epoch 82330: Training cost= 2.3026, Training acc= 0.6688, Validation cost= 2.3026, Validation acc= 0.6684
Epoch 82340: Training cost= 2.3026, Training acc= 0.6687, Validation cost= 2.3026, Validation acc= 0.6683
Epoch 82350: Training cost= 2.3026, Training acc= 0.6687, Validation cost= 2.3026, Validation acc= 0.6683
Epoch 82360: Training cost= 2.3026, Training acc= 0.6686, Validation cost= 2.3026, Validation acc= 0.6682
Epoch 82370: Training cost= 2.3026, Training acc= 0.6685, Validation cost= 2.3026, Validation acc= 0.6681
Epoch 82380: Training cost= 2.3026, Training acc= 0.6685, Validation cost= 2.3026, Validation acc= 0.6681
Epoch 82390: Training cost= 2.3026, Training acc= 0.6684, Validation cost= 2.3026, Validation acc= 0.6680
Epoch 82400: Training cost= 2.3026, Training acc= 0.6683, Validation cost= 2.3026, Validation acc= 0.6679
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 9 6 3 2 0 4 1 7 5]
 [1 8 2 0 5 6 4 7 3 9]
 [7 3 2 1 0 4 6 9 8 5]
 [7 4 1 8 9 0 2 5 3 6]
 [5 4 8 2 9 1 3 6 7 0]
 [7 5 0 2 3 4 6 1 8 9]
 [8 4 2 6 9 3 5 1 7 0]
 [6 0 4 7 9 3 2 1 5 8]
 [8 0 5 3 9 6 1 2 7 4]
 [3 4 9 8 0 1 5 6 7 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 7 6 0 8 2 5 9 1]
 [3 2 5 7 0 4 1 9 6 8]
 [8 5 3 1 2 6 4 7 0 9]
 [6 1 9 5 8 3 4 7 2 0]
 [7 2 1 3 8 5 9 4 0 6]
 [8 9 0 6 4 7 5 3 2 1]
 [9 5 0 4 2 3 6 8 1 7]
 [7 3 4 8 5 0 2 6 1 9]
 [7 3 6 5 8 0 4 9 2 1]
 [5 6 2 9 3 4 0 1 7 8]]
Epoch 82410: Training cost= 2.3026, Training acc= 0.6683, Validation cost= 2.3026, Validation acc= 0.6679
Epoch 82420: Training cost= 2.3026, Training acc= 0.6682, Validation cost= 2.3026, Validation acc= 0.6678
Epoch 82430: Training cost= 2.3026, Training acc= 0.6681, Validation cost= 2.3026, Validation acc= 0.6677
Epoch 82440: Training cost= 2.3026, Training acc= 0.6680, Validation cost= 2.3026, Validation acc= 0.6677
Epoch 82450: Training cost= 2.3026, Training acc= 0.6680, Validation cost= 2.3026, Validation acc= 0.6676
Epoch 82460: Training cost= 2.3026, Training acc= 0.6679, Validation cost= 2.3026, Validation acc= 0.6675
Epoch 82470: Training cost= 2.3026, Training acc= 0.6678, Validation cost= 2.3026, Validation acc= 0.6675
Epoch 82480: Training cost= 2.3026, Training acc= 0.6678, Validation cost= 2.3026, Validation acc= 0.6674
Epoch 82490: Training cost= 2.3026, Training acc= 0.6677, Validation cost= 2.3026, Validation acc= 0.6673
Epoch 82500: Training cost= 2.3026, Training acc= 0.6676, Validation cost= 2.3026, Validation acc= 0.6672
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 0 9 1 5 6 3 7 8 2]
 [2 0 8 5 6 1 3 4 9 7]
 [4 1 7 5 2 3 0 6 8 9]
 [7 4 8 0 6 1 5 2 9 3]
 [1 8 0 9 7 4 3 2 6 5]
 [1 0 3 7 4 2 8 9 6 5]
 [0 7 8 4 6 2 9 3 1 5]
 [8 9 1 0 7 6 2 3 4 5]
 [7 8 1 6 3 0 5 4 2 9]
 [3 6 1 9 0 8 4 7 5 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 1 9 6 2 8 5 7 0 4]
 [4 3 5 7 8 0 6 2 1 9]
 [5 9 3 1 2 0 6 4 8 7]
 [6 8 5 7 0 2 3 4 9 1]
 [5 6 7 9 3 2 4 8 0 1]
 [6 0 5 3 7 1 9 4 2 8]
 [6 9 0 5 7 1 4 2 3 8]
 [1 8 4 3 0 6 7 2 9 5]
 [7 0 9 4 5 6 2 3 8 1]
 [8 6 2 0 5 1 3 7 9 4]]
Epoch 82510: Training cost= 2.3026, Training acc= 0.6676, Validation cost= 2.3026, Validation acc= 0.6672
Epoch 82520: Training cost= 2.3026, Training acc= 0.6675, Validation cost= 2.3026, Validation acc= 0.6671
Epoch 82530: Training cost= 2.3026, Training acc= 0.6674, Validation cost= 2.3026, Validation acc= 0.6670
Epoch 82540: Training cost= 2.3026, Training acc= 0.6674, Validation cost= 2.3026, Validation acc= 0.6670
Epoch 82550: Training cost= 2.3026, Training acc= 0.6673, Validation cost= 2.3026, Validation acc= 0.6669
Epoch 82560: Training cost= 2.3026, Training acc= 0.6672, Validation cost= 2.3026, Validation acc= 0.6668
Epoch 82570: Training cost= 2.3026, Training acc= 0.6671, Validation cost= 2.3026, Validation acc= 0.6668
Epoch 82580: Training cost= 2.3026, Training acc= 0.6671, Validation cost= 2.3026, Validation acc= 0.6667
Epoch 82590: Training cost= 2.3026, Training acc= 0.6670, Validation cost= 2.3026, Validation acc= 0.6666
Epoch 82600: Training cost= 2.3026, Training acc= 0.6669, Validation cost= 2.3026, Validation acc= 0.6666
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 1 2 4 5 6 7 0 9 3]
 [4 2 6 5 1 0 8 9 7 3]
 [8 9 1 0 4 7 3 6 2 5]
 [9 5 6 1 3 8 2 4 7 0]
 [3 0 2 1 9 6 4 7 5 8]
 [2 3 1 7 5 0 9 4 6 8]
 [7 5 6 2 4 1 9 0 8 3]
 [8 9 6 5 1 3 4 2 0 7]
 [4 1 2 0 5 7 3 6 9 8]
 [0 7 5 3 2 1 9 4 6 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 8 7 6 9 4 2 0 1 5]
 [7 6 8 1 2 3 9 0 4 5]
 [2 8 1 6 5 3 4 0 7 9]
 [8 6 3 0 4 2 7 9 1 5]
 [5 6 2 7 8 4 9 1 0 3]
 [2 0 6 4 3 1 5 7 8 9]
 [8 6 4 7 0 1 2 5 3 9]
 [0 4 3 7 2 6 8 9 1 5]
 [8 1 3 7 0 2 4 6 9 5]
 [7 4 5 8 9 2 1 6 3 0]]
Epoch 82610: Training cost= 2.3026, Training acc= 0.6669, Validation cost= 2.3026, Validation acc= 0.6665
Epoch 82620: Training cost= 2.3026, Training acc= 0.6668, Validation cost= 2.3026, Validation acc= 0.6664
Epoch 82630: Training cost= 2.3026, Training acc= 0.6667, Validation cost= 2.3026, Validation acc= 0.6664
Epoch 82640: Training cost= 2.3026, Training acc= 0.6667, Validation cost= 2.3026, Validation acc= 0.6663
Epoch 82650: Training cost= 2.3026, Training acc= 0.6666, Validation cost= 2.3026, Validation acc= 0.6662
Epoch 82660: Training cost= 2.3026, Training acc= 0.6665, Validation cost= 2.3026, Validation acc= 0.6661
Epoch 82670: Training cost= 2.3026, Training acc= 0.6665, Validation cost= 2.3026, Validation acc= 0.6661
Epoch 82680: Training cost= 2.3026, Training acc= 0.6664, Validation cost= 2.3026, Validation acc= 0.6660
Epoch 82690: Training cost= 2.3026, Training acc= 0.6663, Validation cost= 2.3026, Validation acc= 0.6659
Epoch 82700: Training cost= 2.3026, Training acc= 0.6663, Validation cost= 2.3026, Validation acc= 0.6659
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 4 5 9 3 2 6 1 7 0]
 [1 2 4 3 0 6 5 7 9 8]
 [2 4 6 9 5 1 7 0 3 8]
 [9 6 3 4 5 2 7 8 1 0]
 [1 8 4 3 7 5 0 2 6 9]
 [2 9 3 0 6 1 5 4 7 8]
 [9 4 7 0 1 5 3 6 8 2]
 [2 7 8 3 9 0 4 1 5 6]
 [4 1 6 0 2 7 3 5 9 8]
 [6 7 8 1 0 2 9 5 4 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 5 9 1 4 7 8 6 3 0]
 [8 0 4 6 5 3 9 2 1 7]
 [0 7 6 1 2 4 3 8 9 5]
 [8 9 4 1 5 3 7 6 0 2]
 [5 9 7 8 4 1 0 2 3 6]
 [1 7 9 3 8 2 4 5 6 0]
 [1 6 4 2 5 8 7 0 3 9]
 [8 1 5 3 4 9 7 2 6 0]
 [4 3 2 7 9 0 6 5 1 8]
 [7 6 5 2 8 4 1 0 3 9]]
Epoch 82710: Training cost= 2.3026, Training acc= 0.6662, Validation cost= 2.3026, Validation acc= 0.6658
Epoch 82720: Training cost= 2.3026, Training acc= 0.6661, Validation cost= 2.3026, Validation acc= 0.6657
Epoch 82730: Training cost= 2.3026, Training acc= 0.6661, Validation cost= 2.3026, Validation acc= 0.6657
Epoch 82740: Training cost= 2.3026, Training acc= 0.6660, Validation cost= 2.3026, Validation acc= 0.6656
Epoch 82750: Training cost= 2.3026, Training acc= 0.6659, Validation cost= 2.3026, Validation acc= 0.6655
Epoch 82760: Training cost= 2.3026, Training acc= 0.6658, Validation cost= 2.3026, Validation acc= 0.6655
Epoch 82770: Training cost= 2.3026, Training acc= 0.6658, Validation cost= 2.3026, Validation acc= 0.6654
Epoch 82780: Training cost= 2.3026, Training acc= 0.6657, Validation cost= 2.3026, Validation acc= 0.6653
Epoch 82790: Training cost= 2.3026, Training acc= 0.6656, Validation cost= 2.3026, Validation acc= 0.6653
Epoch 82800: Training cost= 2.3026, Training acc= 0.6656, Validation cost= 2.3026, Validation acc= 0.6652
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 6 0 4 8 1 9 7 2 5]
 [0 1 7 3 9 6 4 5 8 2]
 [7 9 6 3 8 2 5 0 1 4]
 [4 0 7 3 6 5 2 1 8 9]
 [3 9 0 1 6 2 4 7 5 8]
 [1 6 3 4 7 0 8 9 5 2]
 [3 0 4 1 6 5 9 2 8 7]
 [2 7 6 0 4 3 1 8 5 9]
 [1 9 4 6 7 8 5 0 3 2]
 [8 2 9 5 0 3 7 4 1 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 3 8 5 9 6 1 0 2 4]
 [5 0 8 2 6 7 9 3 4 1]
 [2 9 8 6 0 4 7 3 5 1]
 [9 3 6 5 4 1 7 2 0 8]
 [3 5 0 6 9 4 7 1 8 2]
 [3 0 4 1 9 8 2 5 6 7]
 [0 8 4 7 2 5 9 1 6 3]
 [0 3 8 4 1 9 7 5 6 2]
 [7 8 2 4 5 3 1 0 6 9]
 [8 1 5 3 0 6 2 7 4 9]]
Epoch 82810: Training cost= 2.3026, Training acc= 0.6655, Validation cost= 2.3026, Validation acc= 0.6651
Epoch 82820: Training cost= 2.3026, Training acc= 0.6654, Validation cost= 2.3026, Validation acc= 0.6651
Epoch 82830: Training cost= 2.3026, Training acc= 0.6654, Validation cost= 2.3026, Validation acc= 0.6650
Epoch 82840: Training cost= 2.3026, Training acc= 0.6653, Validation cost= 2.3026, Validation acc= 0.6649
Epoch 82850: Training cost= 2.3026, Training acc= 0.6652, Validation cost= 2.3026, Validation acc= 0.6648
Epoch 82860: Training cost= 2.3026, Training acc= 0.6652, Validation cost= 2.3026, Validation acc= 0.6648
Epoch 82870: Training cost= 2.3026, Training acc= 0.6651, Validation cost= 2.3026, Validation acc= 0.6647
Epoch 82880: Training cost= 2.3026, Training acc= 0.6650, Validation cost= 2.3026, Validation acc= 0.6646
Epoch 82890: Training cost= 2.3026, Training acc= 0.6650, Validation cost= 2.3026, Validation acc= 0.6646
Epoch 82900: Training cost= 2.3026, Training acc= 0.6649, Validation cost= 2.3026, Validation acc= 0.6645
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 8 1 3 2 4 5 6 0 7]
 [9 0 3 8 2 7 4 5 1 6]
 [0 6 3 2 1 9 4 8 7 5]
 [5 7 8 4 1 0 9 2 3 6]
 [6 5 3 9 8 1 7 2 4 0]
 [7 2 4 5 0 9 6 3 8 1]
 [8 5 1 3 6 4 9 7 0 2]
 [6 5 8 1 3 9 4 0 2 7]
 [6 9 5 7 8 1 2 3 4 0]
 [0 7 2 6 9 4 8 5 3 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 5 0 1 8 2 9 6 3 7]
 [3 5 4 1 9 2 7 8 6 0]
 [5 2 7 4 0 1 8 9 6 3]
 [6 7 2 8 9 5 0 1 4 3]
 [8 2 6 9 0 7 3 4 5 1]
 [2 3 0 1 5 4 8 7 6 9]
 [6 4 7 8 0 9 5 1 2 3]
 [1 2 8 7 6 9 5 3 4 0]
 [1 0 3 4 8 2 9 5 7 6]
 [8 9 0 1 5 7 3 2 6 4]]
Epoch 82910: Training cost= 2.3026, Training acc= 0.6648, Validation cost= 2.3026, Validation acc= 0.6644
Epoch 82920: Training cost= 2.3026, Training acc= 0.6648, Validation cost= 2.3026, Validation acc= 0.6644
Epoch 82930: Training cost= 2.3026, Training acc= 0.6647, Validation cost= 2.3026, Validation acc= 0.6643
Epoch 82940: Training cost= 2.3026, Training acc= 0.6646, Validation cost= 2.3026, Validation acc= 0.6642
Epoch 82950: Training cost= 2.3026, Training acc= 0.6646, Validation cost= 2.3026, Validation acc= 0.6642
Epoch 82960: Training cost= 2.3026, Training acc= 0.6645, Validation cost= 2.3026, Validation acc= 0.6641
Epoch 82970: Training cost= 2.3026, Training acc= 0.6644, Validation cost= 2.3026, Validation acc= 0.6640
Epoch 82980: Training cost= 2.3026, Training acc= 0.6643, Validation cost= 2.3026, Validation acc= 0.6640
Epoch 82990: Training cost= 2.3026, Training acc= 0.6643, Validation cost= 2.3026, Validation acc= 0.6639
Epoch 83000: Training cost= 2.3026, Training acc= 0.6642, Validation cost= 2.3026, Validation acc= 0.6638
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 2 3 5 4 6 9 7 0 1]
 [1 7 4 0 5 6 3 2 9 8]
 [0 8 6 1 2 3 5 9 7 4]
 [2 6 7 9 4 3 5 0 1 8]
 [7 5 6 0 4 3 9 1 2 8]
 [7 6 8 1 2 5 0 4 9 3]
 [1 5 2 4 8 7 0 9 3 6]
 [2 6 9 7 0 5 3 8 1 4]
 [3 4 6 9 2 5 7 1 8 0]
 [2 4 3 0 8 6 5 9 1 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 9 5 0 8 7 6 2 1 3]
 [5 8 3 9 2 6 4 0 1 7]
 [4 7 1 5 3 2 8 6 9 0]
 [5 0 2 3 8 1 6 9 4 7]
 [8 4 3 6 2 7 9 5 0 1]
 [2 4 8 7 3 1 0 9 6 5]
 [7 2 4 3 0 1 9 8 5 6]
 [2 8 6 9 3 0 5 4 1 7]
 [0 4 8 2 1 7 5 3 6 9]
 [4 2 0 1 7 8 6 9 5 3]]
Epoch 83010: Training cost= 2.3026, Training acc= 0.6641, Validation cost= 2.3026, Validation acc= 0.6638
Epoch 83020: Training cost= 2.3026, Training acc= 0.6641, Validation cost= 2.3026, Validation acc= 0.6637
Epoch 83030: Training cost= 2.3026, Training acc= 0.6640, Validation cost= 2.3026, Validation acc= 0.6636
Epoch 83040: Training cost= 2.3026, Training acc= 0.6639, Validation cost= 2.3026, Validation acc= 0.6636
Epoch 83050: Training cost= 2.3026, Training acc= 0.6639, Validation cost= 2.3026, Validation acc= 0.6635
Epoch 83060: Training cost= 2.3026, Training acc= 0.6638, Validation cost= 2.3026, Validation acc= 0.6634
Epoch 83070: Training cost= 2.3026, Training acc= 0.6637, Validation cost= 2.3026, Validation acc= 0.6634
Epoch 83080: Training cost= 2.3026, Training acc= 0.6637, Validation cost= 2.3026, Validation acc= 0.6633
Epoch 83090: Training cost= 2.3026, Training acc= 0.6636, Validation cost= 2.3026, Validation acc= 0.6632
Epoch 83100: Training cost= 2.3026, Training acc= 0.6635, Validation cost= 2.3026, Validation acc= 0.6631
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 5 3 7 6 1 8 9 0 2]
 [9 7 8 6 3 1 4 2 5 0]
 [0 7 5 1 3 8 6 2 9 4]
 [6 5 1 8 3 2 4 9 0 7]
 [7 9 5 4 6 2 1 8 0 3]
 [3 7 6 1 8 4 2 9 5 0]
 [8 7 0 5 3 4 9 1 6 2]
 [2 9 5 4 0 8 1 6 7 3]
 [0 5 1 9 3 4 6 7 2 8]
 [5 1 7 9 3 0 4 2 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 3 8 7 2 0 4 5 1 6]
 [0 2 1 8 7 3 5 4 9 6]
 [2 6 9 4 3 1 7 5 0 8]
 [7 1 0 4 8 9 5 3 6 2]
 [6 7 9 1 2 4 0 8 5 3]
 [5 7 2 3 6 4 0 1 9 8]
 [2 4 3 9 1 7 6 8 0 5]
 [3 4 5 2 8 6 1 9 0 7]
 [5 4 9 2 6 1 0 3 7 8]
 [4 2 8 6 1 9 3 7 0 5]]
Epoch 83110: Training cost= 2.3026, Training acc= 0.6635, Validation cost= 2.3026, Validation acc= 0.6631
Epoch 83120: Training cost= 2.3026, Training acc= 0.6634, Validation cost= 2.3026, Validation acc= 0.6630
Epoch 83130: Training cost= 2.3026, Training acc= 0.6633, Validation cost= 2.3026, Validation acc= 0.6629
Epoch 83140: Training cost= 2.3026, Training acc= 0.6633, Validation cost= 2.3026, Validation acc= 0.6629
Epoch 83150: Training cost= 2.3026, Training acc= 0.6632, Validation cost= 2.3026, Validation acc= 0.6628
Epoch 83160: Training cost= 2.3026, Training acc= 0.6631, Validation cost= 2.3026, Validation acc= 0.6627
Epoch 83170: Training cost= 2.3026, Training acc= 0.6631, Validation cost= 2.3026, Validation acc= 0.6627
Epoch 83180: Training cost= 2.3026, Training acc= 0.6630, Validation cost= 2.3026, Validation acc= 0.6626
Epoch 83190: Training cost= 2.3026, Training acc= 0.6629, Validation cost= 2.3026, Validation acc= 0.6625
Epoch 83200: Training cost= 2.3026, Training acc= 0.6629, Validation cost= 2.3026, Validation acc= 0.6625
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 2 1 0 5 9 8 4 6 7]
 [3 1 8 4 0 9 7 6 2 5]
 [3 0 7 9 1 5 2 8 4 6]
 [0 5 9 4 6 2 1 8 7 3]
 [7 5 4 0 9 2 6 3 8 1]
 [3 6 0 7 1 5 2 8 9 4]
 [1 0 5 9 2 6 7 8 3 4]
 [0 6 8 2 5 3 9 4 7 1]
 [1 6 2 4 0 9 7 3 5 8]
 [0 1 7 3 5 4 2 9 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 1 9 2 7 4 6 0 3 8]
 [6 8 7 9 1 2 5 0 4 3]
 [8 1 9 3 4 7 6 5 2 0]
 [9 8 0 6 1 7 2 5 4 3]
 [1 4 9 0 7 6 8 3 5 2]
 [4 6 0 3 9 8 5 2 1 7]
 [8 7 1 5 3 0 4 6 2 9]
 [8 3 0 9 4 5 7 6 1 2]
 [9 5 0 1 7 8 2 4 3 6]
 [9 4 0 6 1 7 3 2 5 8]]
Epoch 83210: Training cost= 2.3026, Training acc= 0.6628, Validation cost= 2.3026, Validation acc= 0.6624
Epoch 83220: Training cost= 2.3026, Training acc= 0.6627, Validation cost= 2.3026, Validation acc= 0.6623
Epoch 83230: Training cost= 2.3026, Training acc= 0.6627, Validation cost= 2.3026, Validation acc= 0.6623
Epoch 83240: Training cost= 2.3026, Training acc= 0.6626, Validation cost= 2.3026, Validation acc= 0.6622
Epoch 83250: Training cost= 2.3026, Training acc= 0.6625, Validation cost= 2.3026, Validation acc= 0.6621
Epoch 83260: Training cost= 2.3026, Training acc= 0.6624, Validation cost= 2.3026, Validation acc= 0.6621
Epoch 83270: Training cost= 2.3026, Training acc= 0.6624, Validation cost= 2.3026, Validation acc= 0.6620
Epoch 83280: Training cost= 2.3026, Training acc= 0.6623, Validation cost= 2.3026, Validation acc= 0.6619
Epoch 83290: Training cost= 2.3026, Training acc= 0.6622, Validation cost= 2.3026, Validation acc= 0.6619
Epoch 83300: Training cost= 2.3026, Training acc= 0.6622, Validation cost= 2.3026, Validation acc= 0.6618
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 6 4 7 1 9 5 8 0 2]
 [1 8 2 4 7 3 6 5 9 0]
 [5 4 8 9 2 1 0 7 3 6]
 [3 9 1 4 6 5 8 0 2 7]
 [4 5 6 3 0 1 9 2 8 7]
 [8 9 7 1 0 3 4 5 6 2]
 [2 7 3 9 4 1 8 6 0 5]
 [3 0 8 6 2 9 5 1 4 7]
 [6 7 0 8 9 5 2 3 1 4]
 [3 1 9 7 5 4 0 6 2 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 1 9 3 7 0 2 5 6 8]
 [8 7 6 3 0 9 5 4 2 1]
 [9 4 7 5 8 3 0 1 2 6]
 [2 1 5 7 4 3 0 8 6 9]
 [6 7 3 8 5 4 9 0 1 2]
 [7 1 8 5 3 9 4 6 2 0]
 [6 8 1 7 0 9 2 5 3 4]
 [2 7 3 8 9 4 1 0 5 6]
 [2 8 6 0 1 3 9 4 7 5]
 [7 3 1 6 8 4 5 2 9 0]]
Epoch 83310: Training cost= 2.3026, Training acc= 0.6621, Validation cost= 2.3026, Validation acc= 0.6617
Epoch 83320: Training cost= 2.3026, Training acc= 0.6620, Validation cost= 2.3026, Validation acc= 0.6617
Epoch 83330: Training cost= 2.3026, Training acc= 0.6620, Validation cost= 2.3026, Validation acc= 0.6616
Epoch 83340: Training cost= 2.3026, Training acc= 0.6619, Validation cost= 2.3026, Validation acc= 0.6615
Epoch 83350: Training cost= 2.3026, Training acc= 0.6618, Validation cost= 2.3026, Validation acc= 0.6615
Epoch 83360: Training cost= 2.3026, Training acc= 0.6618, Validation cost= 2.3026, Validation acc= 0.6614
Epoch 83370: Training cost= 2.3026, Training acc= 0.6617, Validation cost= 2.3026, Validation acc= 0.6613
Epoch 83380: Training cost= 2.3026, Training acc= 0.6616, Validation cost= 2.3026, Validation acc= 0.6613
Epoch 83390: Training cost= 2.3026, Training acc= 0.6616, Validation cost= 2.3026, Validation acc= 0.6612
Epoch 83400: Training cost= 2.3026, Training acc= 0.6615, Validation cost= 2.3026, Validation acc= 0.6611
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 1 4 9 6 5 2 7 0 3]
 [4 5 9 3 1 7 6 2 8 0]
 [2 5 0 3 1 9 4 6 8 7]
 [4 0 7 6 1 9 2 8 3 5]
 [5 0 3 6 2 1 7 9 8 4]
 [8 4 5 2 0 9 7 3 6 1]
 [1 9 6 5 2 0 8 7 4 3]
 [9 2 3 6 4 7 8 0 1 5]
 [1 5 6 7 4 8 0 3 9 2]
 [4 0 9 6 8 2 3 1 7 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 0 5 9 1 4 7 2 3 6]
 [4 5 6 1 3 8 0 2 7 9]
 [5 7 2 3 8 6 1 9 0 4]
 [3 4 0 7 6 5 2 9 8 1]
 [9 2 7 4 8 6 3 1 0 5]
 [5 1 6 4 7 2 3 9 8 0]
 [5 3 0 4 8 6 2 1 7 9]
 [8 5 3 2 7 1 6 9 0 4]
 [7 3 4 0 8 5 2 6 1 9]
 [4 0 7 9 6 2 1 8 3 5]]
Epoch 83410: Training cost= 2.3026, Training acc= 0.6614, Validation cost= 2.3026, Validation acc= 0.6611
Epoch 83420: Training cost= 2.3026, Training acc= 0.6614, Validation cost= 2.3026, Validation acc= 0.6610
Epoch 83430: Training cost= 2.3026, Training acc= 0.6613, Validation cost= 2.3026, Validation acc= 0.6609
Epoch 83440: Training cost= 2.3026, Training acc= 0.6612, Validation cost= 2.3026, Validation acc= 0.6609
Epoch 83450: Training cost= 2.3026, Training acc= 0.6612, Validation cost= 2.3026, Validation acc= 0.6608
Epoch 83460: Training cost= 2.3026, Training acc= 0.6611, Validation cost= 2.3026, Validation acc= 0.6607
Epoch 83470: Training cost= 2.3026, Training acc= 0.6610, Validation cost= 2.3026, Validation acc= 0.6607
Epoch 83480: Training cost= 2.3026, Training acc= 0.6610, Validation cost= 2.3026, Validation acc= 0.6606
Epoch 83490: Training cost= 2.3026, Training acc= 0.6609, Validation cost= 2.3026, Validation acc= 0.6605
Epoch 83500: Training cost= 2.3026, Training acc= 0.6608, Validation cost= 2.3026, Validation acc= 0.6605
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 5 4 3 2 0 6 7 1 8]
 [6 2 4 7 1 8 0 3 5 9]
 [4 8 7 1 5 9 3 0 2 6]
 [4 1 6 0 7 8 3 2 9 5]
 [6 2 9 3 7 8 4 5 1 0]
 [6 5 7 1 3 2 4 8 0 9]
 [7 1 9 5 2 6 4 0 8 3]
 [3 5 6 2 0 4 7 8 1 9]
 [6 7 9 4 0 1 5 8 2 3]
 [2 9 3 0 1 5 8 6 7 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 1 2 0 4 8 9 5 6 3]
 [4 0 6 3 1 9 8 2 7 5]
 [0 9 1 8 6 4 5 7 2 3]
 [3 8 7 9 0 5 1 4 6 2]
 [5 6 3 7 1 2 4 8 0 9]
 [4 8 2 6 5 3 9 1 0 7]
 [6 4 3 0 2 7 9 5 1 8]
 [0 6 3 4 8 5 2 7 1 9]
 [4 3 7 8 1 6 9 2 0 5]
 [9 6 1 0 4 3 8 2 7 5]]
Epoch 83510: Training cost= 2.3026, Training acc= 0.6608, Validation cost= 2.3026, Validation acc= 0.6604
Epoch 83520: Training cost= 2.3026, Training acc= 0.6607, Validation cost= 2.3026, Validation acc= 0.6603
Epoch 83530: Training cost= 2.3026, Training acc= 0.6606, Validation cost= 2.3026, Validation acc= 0.6602
Epoch 83540: Training cost= 2.3026, Training acc= 0.6606, Validation cost= 2.3026, Validation acc= 0.6602
Epoch 83550: Training cost= 2.3026, Training acc= 0.6605, Validation cost= 2.3026, Validation acc= 0.6601
Epoch 83560: Training cost= 2.3026, Training acc= 0.6604, Validation cost= 2.3026, Validation acc= 0.6600
Epoch 83570: Training cost= 2.3026, Training acc= 0.6604, Validation cost= 2.3026, Validation acc= 0.6600
Epoch 83580: Training cost= 2.3026, Training acc= 0.6603, Validation cost= 2.3026, Validation acc= 0.6599
Epoch 83590: Training cost= 2.3026, Training acc= 0.6602, Validation cost= 2.3026, Validation acc= 0.6598
Epoch 83600: Training cost= 2.3026, Training acc= 0.6602, Validation cost= 2.3026, Validation acc= 0.6598
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 5 4 3 2 0 6 9 1 7]
 [2 8 9 7 4 5 3 1 6 0]
 [8 1 0 7 9 4 3 2 5 6]
 [9 1 5 3 7 4 2 8 6 0]
 [1 4 2 8 6 3 0 7 5 9]
 [1 8 7 2 3 9 6 4 5 0]
 [7 5 0 4 3 6 1 8 9 2]
 [8 9 2 4 5 3 6 7 1 0]
 [6 3 0 9 7 2 1 5 4 8]
 [7 8 5 3 2 1 0 4 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 3 7 6 4 5 2 8 1 0]
 [4 5 8 6 3 7 0 1 9 2]
 [3 5 6 7 2 9 1 4 8 0]
 [8 1 6 0 9 4 5 2 7 3]
 [0 8 6 3 9 1 5 7 4 2]
 [8 1 2 6 9 4 5 3 7 0]
 [1 3 7 8 0 5 4 2 6 9]
 [4 5 9 7 1 2 0 3 6 8]
 [8 5 3 6 9 0 4 2 7 1]
 [6 9 4 8 3 2 5 1 7 0]]
Epoch 83610: Training cost= 2.3026, Training acc= 0.6601, Validation cost= 2.3026, Validation acc= 0.6597
Epoch 83620: Training cost= 2.3026, Training acc= 0.6600, Validation cost= 2.3026, Validation acc= 0.6596
Epoch 83630: Training cost= 2.3026, Training acc= 0.6600, Validation cost= 2.3026, Validation acc= 0.6596
Epoch 83640: Training cost= 2.3026, Training acc= 0.6599, Validation cost= 2.3026, Validation acc= 0.6595
Epoch 83650: Training cost= 2.3026, Training acc= 0.6598, Validation cost= 2.3026, Validation acc= 0.6594
Epoch 83660: Training cost= 2.3026, Training acc= 0.6598, Validation cost= 2.3026, Validation acc= 0.6594
Epoch 83670: Training cost= 2.3026, Training acc= 0.6597, Validation cost= 2.3026, Validation acc= 0.6593
Epoch 83680: Training cost= 2.3026, Training acc= 0.6596, Validation cost= 2.3026, Validation acc= 0.6592
Epoch 83690: Training cost= 2.3026, Training acc= 0.6596, Validation cost= 2.3026, Validation acc= 0.6592
Epoch 83700: Training cost= 2.3026, Training acc= 0.6595, Validation cost= 2.3026, Validation acc= 0.6591
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 2 6 1 8 0 5 9 7 4]
 [5 3 0 4 7 9 1 8 6 2]
 [8 2 6 1 9 7 3 5 4 0]
 [3 1 5 6 2 8 0 4 7 9]
 [7 9 1 5 4 3 2 6 8 0]
 [1 6 3 0 8 5 7 2 4 9]
 [4 9 8 3 2 0 6 7 1 5]
 [8 1 4 2 7 0 5 6 3 9]
 [2 9 5 7 1 8 6 3 0 4]
 [0 1 7 5 3 2 4 8 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 3 2 9 4 1 0 8 6 7]
 [8 4 1 5 3 7 0 9 2 6]
 [7 2 1 3 5 8 4 0 9 6]
 [8 1 4 6 9 2 3 5 7 0]
 [8 5 3 6 7 4 1 0 2 9]
 [0 6 2 3 5 8 4 9 1 7]
 [4 7 1 2 9 3 5 8 0 6]
 [4 6 9 5 2 3 0 8 1 7]
 [7 3 9 6 4 5 0 8 1 2]
 [9 7 2 0 6 3 8 1 5 4]]
Epoch 83710: Training cost= 2.3026, Training acc= 0.6594, Validation cost= 2.3026, Validation acc= 0.6590
Epoch 83720: Training cost= 2.3026, Training acc= 0.6594, Validation cost= 2.3026, Validation acc= 0.6590
Epoch 83730: Training cost= 2.3026, Training acc= 0.6593, Validation cost= 2.3026, Validation acc= 0.6589
Epoch 83740: Training cost= 2.3026, Training acc= 0.6592, Validation cost= 2.3026, Validation acc= 0.6588
Epoch 83750: Training cost= 2.3026, Training acc= 0.6592, Validation cost= 2.3026, Validation acc= 0.6588
Epoch 83760: Training cost= 2.3026, Training acc= 0.6591, Validation cost= 2.3026, Validation acc= 0.6587
Epoch 83770: Training cost= 2.3026, Training acc= 0.6590, Validation cost= 2.3026, Validation acc= 0.6586
Epoch 83780: Training cost= 2.3026, Training acc= 0.6590, Validation cost= 2.3026, Validation acc= 0.6586
Epoch 83790: Training cost= 2.3026, Training acc= 0.6589, Validation cost= 2.3026, Validation acc= 0.6585
Epoch 83800: Training cost= 2.3026, Training acc= 0.6588, Validation cost= 2.3026, Validation acc= 0.6584
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 6 9 1 0 4 8 3 5 2]
 [0 4 9 1 8 5 6 3 7 2]
 [3 2 1 0 4 8 7 9 6 5]
 [3 1 0 6 2 9 7 8 5 4]
 [7 2 3 8 1 6 9 5 4 0]
 [0 4 2 7 3 1 5 9 8 6]
 [5 2 6 9 1 7 4 8 0 3]
 [4 5 2 3 1 7 6 8 9 0]
 [7 6 1 9 2 4 8 5 0 3]
 [0 4 8 6 7 5 1 2 3 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 3 6 0 7 1 9 8 4 2]
 [4 8 6 1 5 3 2 9 7 0]
 [4 0 6 8 9 1 5 2 3 7]
 [2 1 7 0 6 4 8 3 9 5]
 [3 4 2 5 9 6 7 8 0 1]
 [9 7 8 2 1 5 4 3 6 0]
 [8 6 3 4 1 5 2 0 9 7]
 [8 4 9 7 5 3 2 0 6 1]
 [5 4 3 6 0 2 7 9 1 8]
 [3 6 1 5 2 9 8 0 4 7]]
Epoch 83810: Training cost= 2.3026, Training acc= 0.6588, Validation cost= 2.3026, Validation acc= 0.6584
Epoch 83820: Training cost= 2.3026, Training acc= 0.6587, Validation cost= 2.3026, Validation acc= 0.6583
Epoch 83830: Training cost= 2.3026, Training acc= 0.6586, Validation cost= 2.3026, Validation acc= 0.6582
Epoch 83840: Training cost= 2.3026, Training acc= 0.6586, Validation cost= 2.3026, Validation acc= 0.6582
Epoch 83850: Training cost= 2.3026, Training acc= 0.6585, Validation cost= 2.3026, Validation acc= 0.6581
Epoch 83860: Training cost= 2.3026, Training acc= 0.6584, Validation cost= 2.3026, Validation acc= 0.6580
Epoch 83870: Training cost= 2.3026, Training acc= 0.6584, Validation cost= 2.3026, Validation acc= 0.6580
Epoch 83880: Training cost= 2.3026, Training acc= 0.6583, Validation cost= 2.3026, Validation acc= 0.6579
Epoch 83890: Training cost= 2.3026, Training acc= 0.6582, Validation cost= 2.3026, Validation acc= 0.6578
Epoch 83900: Training cost= 2.3026, Training acc= 0.6582, Validation cost= 2.3026, Validation acc= 0.6578
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 1 7 5 3 4 9 8 0 2]
 [3 5 6 2 9 7 4 1 8 0]
 [9 5 3 2 1 8 4 7 6 0]
 [2 8 0 5 9 1 4 7 3 6]
 [4 7 9 8 6 3 1 0 2 5]
 [9 0 1 8 6 7 5 3 2 4]
 [3 8 0 9 2 5 6 4 7 1]
 [3 5 8 2 9 7 4 1 0 6]
 [2 1 9 8 6 4 3 5 0 7]
 [2 3 5 1 7 4 6 8 0 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 9 7 5 6 8 1 2 0 4]
 [8 2 0 5 3 1 7 9 4 6]
 [9 8 5 4 0 7 2 3 1 6]
 [3 6 9 4 5 1 0 7 2 8]
 [8 3 1 2 5 0 9 4 6 7]
 [6 7 1 5 4 0 2 8 3 9]
 [5 9 7 0 2 6 8 1 3 4]
 [5 1 9 0 4 8 6 7 2 3]
 [5 8 3 9 2 1 4 0 6 7]
 [9 8 5 6 1 7 2 3 0 4]]
Epoch 83910: Training cost= 2.3026, Training acc= 0.6581, Validation cost= 2.3026, Validation acc= 0.6577
Epoch 83920: Training cost= 2.3026, Training acc= 0.6580, Validation cost= 2.3026, Validation acc= 0.6576
Epoch 83930: Training cost= 2.3026, Training acc= 0.6580, Validation cost= 2.3026, Validation acc= 0.6576
Epoch 83940: Training cost= 2.3026, Training acc= 0.6579, Validation cost= 2.3026, Validation acc= 0.6575
Epoch 83950: Training cost= 2.3026, Training acc= 0.6578, Validation cost= 2.3026, Validation acc= 0.6574
Epoch 83960: Training cost= 2.3026, Training acc= 0.6578, Validation cost= 2.3026, Validation acc= 0.6574
Epoch 83970: Training cost= 2.3026, Training acc= 0.6577, Validation cost= 2.3026, Validation acc= 0.6573
Epoch 83980: Training cost= 2.3026, Training acc= 0.6576, Validation cost= 2.3026, Validation acc= 0.6572
Epoch 83990: Training cost= 2.3026, Training acc= 0.6576, Validation cost= 2.3026, Validation acc= 0.6572
Epoch 84000: Training cost= 2.3026, Training acc= 0.6575, Validation cost= 2.3026, Validation acc= 0.6571
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 7 3 1 8 2 4 0 5 6]
 [7 0 3 4 5 8 6 1 2 9]
 [9 3 2 1 0 7 6 5 8 4]
 [6 8 7 2 1 9 4 3 0 5]
 [3 0 7 6 8 9 2 5 4 1]
 [7 4 6 3 0 1 5 2 8 9]
 [6 7 8 5 2 9 0 4 1 3]
 [3 2 4 8 9 0 7 5 6 1]
 [7 0 4 3 5 1 2 8 6 9]
 [2 8 7 6 5 3 0 9 4 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 3 6 8 1 2 7 5 9 0]
 [6 7 5 8 9 4 3 2 1 0]
 [9 0 5 1 3 4 2 6 7 8]
 [1 3 7 5 9 4 0 6 2 8]
 [9 2 5 7 8 0 6 3 1 4]
 [2 0 9 5 3 6 4 1 7 8]
 [1 7 3 6 0 5 9 8 2 4]
 [5 7 6 9 3 1 2 8 0 4]
 [0 5 2 3 9 1 6 7 4 8]
 [1 5 8 6 4 9 3 0 2 7]]
Epoch 84010: Training cost= 2.3026, Training acc= 0.6574, Validation cost= 2.3026, Validation acc= 0.6570
Epoch 84020: Training cost= 2.3026, Training acc= 0.6574, Validation cost= 2.3026, Validation acc= 0.6570
Epoch 84030: Training cost= 2.3026, Training acc= 0.6573, Validation cost= 2.3026, Validation acc= 0.6569
Epoch 84040: Training cost= 2.3026, Training acc= 0.6572, Validation cost= 2.3026, Validation acc= 0.6568
Epoch 84050: Training cost= 2.3026, Training acc= 0.6572, Validation cost= 2.3026, Validation acc= 0.6568
Epoch 84060: Training cost= 2.3026, Training acc= 0.6571, Validation cost= 2.3026, Validation acc= 0.6567
Epoch 84070: Training cost= 2.3026, Training acc= 0.6570, Validation cost= 2.3026, Validation acc= 0.6567
Epoch 84080: Training cost= 2.3026, Training acc= 0.6570, Validation cost= 2.3026, Validation acc= 0.6566
Epoch 84090: Training cost= 2.3026, Training acc= 0.6569, Validation cost= 2.3026, Validation acc= 0.6565
Epoch 84100: Training cost= 2.3026, Training acc= 0.6568, Validation cost= 2.3026, Validation acc= 0.6565
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 4 7 5 8 2 9 0 6 1]
 [4 7 9 8 1 5 6 2 0 3]
 [0 5 8 3 2 6 9 4 1 7]
 [6 5 4 9 3 7 0 1 2 8]
 [5 9 4 1 8 7 2 0 6 3]
 [5 1 2 0 6 4 3 9 7 8]
 [9 2 0 4 8 1 6 3 5 7]
 [2 1 9 8 4 7 6 5 3 0]
 [1 3 6 9 4 7 2 8 5 0]
 [3 6 9 8 5 7 4 1 2 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 5 7 3 4 6 2 0 9 8]
 [0 4 3 2 1 7 9 8 6 5]
 [0 9 3 1 5 8 4 6 7 2]
 [2 1 4 5 8 6 3 0 9 7]
 [0 3 2 5 4 8 6 7 1 9]
 [8 6 5 1 4 0 7 3 2 9]
 [6 2 3 9 7 4 8 5 0 1]
 [9 1 2 0 8 5 3 7 4 6]
 [6 8 5 1 0 7 4 2 3 9]
 [6 1 8 3 0 5 7 4 9 2]]
Epoch 84110: Training cost= 2.3026, Training acc= 0.6568, Validation cost= 2.3026, Validation acc= 0.6564
Epoch 84120: Training cost= 2.3026, Training acc= 0.6567, Validation cost= 2.3026, Validation acc= 0.6563
Epoch 84130: Training cost= 2.3026, Training acc= 0.6566, Validation cost= 2.3026, Validation acc= 0.6563
Epoch 84140: Training cost= 2.3026, Training acc= 0.6566, Validation cost= 2.3026, Validation acc= 0.6562
Epoch 84150: Training cost= 2.3026, Training acc= 0.6565, Validation cost= 2.3026, Validation acc= 0.6561
Epoch 84160: Training cost= 2.3026, Training acc= 0.6564, Validation cost= 2.3026, Validation acc= 0.6561
Epoch 84170: Training cost= 2.3026, Training acc= 0.6564, Validation cost= 2.3026, Validation acc= 0.6560
Epoch 84180: Training cost= 2.3026, Training acc= 0.6563, Validation cost= 2.3026, Validation acc= 0.6559
Epoch 84190: Training cost= 2.3026, Training acc= 0.6562, Validation cost= 2.3026, Validation acc= 0.6559
Epoch 84200: Training cost= 2.3026, Training acc= 0.6562, Validation cost= 2.3026, Validation acc= 0.6558
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 9 1 7 5 0 4 3 2 8]
 [8 7 9 5 1 2 3 6 4 0]
 [7 5 1 0 4 2 3 8 6 9]
 [2 0 4 3 5 9 1 7 8 6]
 [3 4 1 2 0 9 8 6 5 7]
 [0 9 8 4 2 3 1 5 6 7]
 [4 6 2 8 7 1 0 9 5 3]
 [3 8 7 1 5 4 6 0 2 9]
 [9 7 0 8 5 6 4 2 3 1]
 [8 4 5 6 9 2 0 3 1 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 8 9 1 3 5 4 7 2 6]
 [9 1 5 6 0 4 7 3 2 8]
 [9 0 6 2 1 7 8 3 5 4]
 [2 6 8 1 4 3 0 5 7 9]
 [3 7 6 8 4 2 0 1 9 5]
 [3 8 1 5 6 0 9 2 7 4]
 [7 9 1 5 8 4 2 3 0 6]
 [5 3 6 9 7 4 1 2 8 0]
 [7 8 1 0 3 5 6 2 9 4]
 [0 4 3 8 1 7 9 6 2 5]]
Epoch 84210: Training cost= 2.3026, Training acc= 0.6561, Validation cost= 2.3026, Validation acc= 0.6557
Epoch 84220: Training cost= 2.3026, Training acc= 0.6560, Validation cost= 2.3026, Validation acc= 0.6557
Epoch 84230: Training cost= 2.3026, Training acc= 0.6560, Validation cost= 2.3026, Validation acc= 0.6556
Epoch 84240: Training cost= 2.3026, Training acc= 0.6559, Validation cost= 2.3026, Validation acc= 0.6555
Epoch 84250: Training cost= 2.3026, Training acc= 0.6558, Validation cost= 2.3026, Validation acc= 0.6555
Epoch 84260: Training cost= 2.3026, Training acc= 0.6558, Validation cost= 2.3026, Validation acc= 0.6554
Epoch 84270: Training cost= 2.3026, Training acc= 0.6557, Validation cost= 2.3026, Validation acc= 0.6553
Epoch 84280: Training cost= 2.3026, Training acc= 0.6556, Validation cost= 2.3026, Validation acc= 0.6553
Epoch 84290: Training cost= 2.3026, Training acc= 0.6556, Validation cost= 2.3026, Validation acc= 0.6552
Epoch 84300: Training cost= 2.3026, Training acc= 0.6555, Validation cost= 2.3026, Validation acc= 0.6551
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 1 0 3 5 9 7 2 4 8]
 [3 1 9 4 2 5 6 7 8 0]
 [8 4 3 2 9 6 0 5 7 1]
 [0 8 7 4 9 3 6 1 2 5]
 [4 5 6 3 0 8 1 2 7 9]
 [2 5 1 9 7 8 4 6 0 3]
 [2 7 9 5 4 3 8 0 6 1]
 [0 8 1 3 9 6 2 4 7 5]
 [9 3 4 0 2 5 8 6 7 1]
 [8 6 2 1 9 4 3 7 0 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 4 2 0 7 5 9 8 1 6]
 [9 1 7 3 4 5 0 6 8 2]
 [0 8 6 4 2 1 7 3 9 5]
 [6 1 0 3 8 5 4 9 7 2]
 [8 7 4 1 0 2 6 3 5 9]
 [7 9 4 3 2 6 0 8 5 1]
 [8 3 5 6 1 2 9 7 0 4]
 [2 6 4 0 7 5 8 9 1 3]
 [2 4 0 5 3 9 8 7 6 1]
 [5 6 3 0 4 1 7 2 9 8]]
Epoch 84310: Training cost= 2.3026, Training acc= 0.6554, Validation cost= 2.3026, Validation acc= 0.6551
Epoch 84320: Training cost= 2.3026, Training acc= 0.6554, Validation cost= 2.3026, Validation acc= 0.6550
Epoch 84330: Training cost= 2.3026, Training acc= 0.6553, Validation cost= 2.3026, Validation acc= 0.6549
Epoch 84340: Training cost= 2.3026, Training acc= 0.6552, Validation cost= 2.3026, Validation acc= 0.6549
Epoch 84350: Training cost= 2.3026, Training acc= 0.6552, Validation cost= 2.3026, Validation acc= 0.6548
Epoch 84360: Training cost= 2.3026, Training acc= 0.6551, Validation cost= 2.3026, Validation acc= 0.6547
Epoch 84370: Training cost= 2.3026, Training acc= 0.6550, Validation cost= 2.3026, Validation acc= 0.6547
Epoch 84380: Training cost= 2.3026, Training acc= 0.6550, Validation cost= 2.3026, Validation acc= 0.6546
Epoch 84390: Training cost= 2.3026, Training acc= 0.6549, Validation cost= 2.3026, Validation acc= 0.6545
Epoch 84400: Training cost= 2.3026, Training acc= 0.6549, Validation cost= 2.3026, Validation acc= 0.6545
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 9 4 2 0 5 3 6 8 7]
 [2 7 1 0 4 8 3 9 6 5]
 [2 8 4 1 7 3 9 5 0 6]
 [6 1 4 0 9 5 2 3 7 8]
 [5 8 3 6 0 7 4 1 9 2]
 [2 8 6 3 7 5 9 0 1 4]
 [6 2 9 8 0 4 7 1 3 5]
 [8 2 5 3 0 9 6 7 4 1]
 [6 3 4 0 9 8 5 1 2 7]
 [0 9 1 5 3 4 7 6 8 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 6 9 7 3 8 1 0 2 4]
 [6 7 0 3 4 9 2 8 1 5]
 [8 2 6 4 3 7 5 9 0 1]
 [0 1 8 9 2 3 5 6 7 4]
 [9 6 0 8 2 1 7 4 5 3]
 [6 3 1 7 4 0 5 8 2 9]
 [9 0 2 8 6 1 7 5 4 3]
 [7 6 4 0 2 5 9 1 3 8]
 [9 3 6 5 8 7 2 4 0 1]
 [6 8 7 5 2 3 9 0 1 4]]
Epoch 84410: Training cost= 2.3026, Training acc= 0.6548, Validation cost= 2.3026, Validation acc= 0.6544
Epoch 84420: Training cost= 2.3026, Training acc= 0.6547, Validation cost= 2.3026, Validation acc= 0.6543
Epoch 84430: Training cost= 2.3026, Training acc= 0.6547, Validation cost= 2.3026, Validation acc= 0.6543
Epoch 84440: Training cost= 2.3026, Training acc= 0.6546, Validation cost= 2.3026, Validation acc= 0.6542
Epoch 84450: Training cost= 2.3026, Training acc= 0.6545, Validation cost= 2.3026, Validation acc= 0.6541
Epoch 84460: Training cost= 2.3026, Training acc= 0.6545, Validation cost= 2.3026, Validation acc= 0.6541
Epoch 84470: Training cost= 2.3026, Training acc= 0.6544, Validation cost= 2.3026, Validation acc= 0.6540
Epoch 84480: Training cost= 2.3026, Training acc= 0.6543, Validation cost= 2.3026, Validation acc= 0.6539
Epoch 84490: Training cost= 2.3026, Training acc= 0.6543, Validation cost= 2.3026, Validation acc= 0.6539
Epoch 84500: Training cost= 2.3026, Training acc= 0.6542, Validation cost= 2.3026, Validation acc= 0.6538
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 1 0 4 3 6 8 7 9 2]
 [4 7 3 6 1 9 8 0 2 5]
 [1 3 2 0 5 4 6 8 9 7]
 [5 1 0 4 3 8 6 9 2 7]
 [6 2 3 9 5 8 1 4 7 0]
 [5 6 7 1 2 4 3 9 8 0]
 [6 1 2 7 3 5 4 8 9 0]
 [0 1 7 9 2 5 8 3 4 6]
 [0 5 6 8 3 2 9 1 4 7]
 [5 0 1 6 3 7 2 4 9 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 3 7 0 2 9 1 4 5 6]
 [2 3 7 6 4 9 8 0 1 5]
 [2 5 8 6 1 0 3 7 4 9]
 [2 1 7 0 5 3 4 8 6 9]
 [2 6 8 3 0 5 1 9 4 7]
 [3 4 1 5 6 2 9 7 0 8]
 [1 0 5 2 3 7 9 6 8 4]
 [8 1 6 7 0 4 3 2 9 5]
 [8 4 2 0 6 9 1 5 3 7]
 [0 8 9 5 7 1 3 2 4 6]]
Epoch 84510: Training cost= 2.3026, Training acc= 0.6541, Validation cost= 2.3026, Validation acc= 0.6538
Epoch 84520: Training cost= 2.3026, Training acc= 0.6541, Validation cost= 2.3026, Validation acc= 0.6537
Epoch 84530: Training cost= 2.3026, Training acc= 0.6540, Validation cost= 2.3026, Validation acc= 0.6536
Epoch 84540: Training cost= 2.3026, Training acc= 0.6539, Validation cost= 2.3026, Validation acc= 0.6536
Epoch 84550: Training cost= 2.3026, Training acc= 0.6539, Validation cost= 2.3026, Validation acc= 0.6535
Epoch 84560: Training cost= 2.3026, Training acc= 0.6538, Validation cost= 2.3026, Validation acc= 0.6534
Epoch 84570: Training cost= 2.3026, Training acc= 0.6537, Validation cost= 2.3026, Validation acc= 0.6534
Epoch 84580: Training cost= 2.3026, Training acc= 0.6537, Validation cost= 2.3026, Validation acc= 0.6533
Epoch 84590: Training cost= 2.3026, Training acc= 0.6536, Validation cost= 2.3026, Validation acc= 0.6532
Epoch 84600: Training cost= 2.3026, Training acc= 0.6535, Validation cost= 2.3026, Validation acc= 0.6532
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 8 9 6 5 4 1 2 7 0]
 [7 9 2 3 8 5 4 6 1 0]
 [2 6 9 5 3 7 0 8 4 1]
 [7 3 6 0 9 1 5 2 4 8]
 [2 0 9 5 4 3 1 7 6 8]
 [7 3 0 1 6 5 9 8 2 4]
 [4 2 7 8 3 5 0 9 6 1]
 [6 9 4 2 0 5 1 7 8 3]
 [2 1 3 4 9 8 0 5 7 6]
 [5 2 8 4 0 7 1 6 9 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 7 9 3 8 4 2 5 1 0]
 [6 2 5 8 3 1 9 0 4 7]
 [8 2 4 1 7 5 9 6 3 0]
 [5 0 9 2 6 7 3 4 1 8]
 [8 0 2 3 1 7 5 9 4 6]
 [2 8 4 7 9 3 5 0 6 1]
 [2 8 4 5 9 0 6 7 3 1]
 [8 3 9 6 4 0 2 1 5 7]
 [3 5 2 8 6 7 4 1 9 0]
 [1 5 9 2 7 3 8 0 6 4]]
Epoch 84610: Training cost= 2.3026, Training acc= 0.6535, Validation cost= 2.3026, Validation acc= 0.6531
Epoch 84620: Training cost= 2.3026, Training acc= 0.6534, Validation cost= 2.3026, Validation acc= 0.6530
Epoch 84630: Training cost= 2.3026, Training acc= 0.6533, Validation cost= 2.3026, Validation acc= 0.6530
Epoch 84640: Training cost= 2.3026, Training acc= 0.6533, Validation cost= 2.3026, Validation acc= 0.6529
Epoch 84650: Training cost= 2.3026, Training acc= 0.6532, Validation cost= 2.3026, Validation acc= 0.6528
Epoch 84660: Training cost= 2.3026, Training acc= 0.6531, Validation cost= 2.3026, Validation acc= 0.6528
Epoch 84670: Training cost= 2.3026, Training acc= 0.6531, Validation cost= 2.3026, Validation acc= 0.6527
Epoch 84680: Training cost= 2.3026, Training acc= 0.6530, Validation cost= 2.3026, Validation acc= 0.6526
Epoch 84690: Training cost= 2.3026, Training acc= 0.6530, Validation cost= 2.3026, Validation acc= 0.6526
Epoch 84700: Training cost= 2.3026, Training acc= 0.6529, Validation cost= 2.3026, Validation acc= 0.6525
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 8 0 5 9 1 4 7 3 2]
 [4 2 8 5 1 0 9 7 3 6]
 [7 9 5 4 2 0 1 6 8 3]
 [9 2 4 3 7 8 0 5 6 1]
 [5 1 4 9 3 7 2 0 8 6]
 [9 7 2 4 5 6 8 0 3 1]
 [7 9 1 6 4 5 0 2 8 3]
 [8 6 1 5 3 7 9 0 2 4]
 [4 0 3 6 8 9 1 7 5 2]
 [3 8 4 2 1 5 0 7 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 8 3 2 1 4 6 0 7 9]
 [3 6 0 9 8 2 5 1 4 7]
 [0 8 5 6 3 2 9 1 7 4]
 [6 4 9 2 8 3 1 0 7 5]
 [2 6 1 3 5 4 7 8 0 9]
 [8 5 2 3 6 7 1 0 9 4]
 [6 2 5 1 7 9 4 8 3 0]
 [7 3 9 1 5 8 0 6 2 4]
 [0 5 6 9 8 1 4 2 3 7]
 [0 3 9 2 4 5 7 1 8 6]]
Epoch 84710: Training cost= 2.3026, Training acc= 0.6528, Validation cost= 2.3026, Validation acc= 0.6524
Epoch 84720: Training cost= 2.3026, Training acc= 0.6528, Validation cost= 2.3026, Validation acc= 0.6524
Epoch 84730: Training cost= 2.3026, Training acc= 0.6527, Validation cost= 2.3026, Validation acc= 0.6523
Epoch 84740: Training cost= 2.3026, Training acc= 0.6526, Validation cost= 2.3026, Validation acc= 0.6523
Epoch 84750: Training cost= 2.3026, Training acc= 0.6526, Validation cost= 2.3026, Validation acc= 0.6522
Epoch 84760: Training cost= 2.3026, Training acc= 0.6525, Validation cost= 2.3026, Validation acc= 0.6521
Epoch 84770: Training cost= 2.3026, Training acc= 0.6524, Validation cost= 2.3026, Validation acc= 0.6521
Epoch 84780: Training cost= 2.3026, Training acc= 0.6524, Validation cost= 2.3026, Validation acc= 0.6520
Epoch 84790: Training cost= 2.3026, Training acc= 0.6523, Validation cost= 2.3026, Validation acc= 0.6519
Epoch 84800: Training cost= 2.3026, Training acc= 0.6522, Validation cost= 2.3026, Validation acc= 0.6519
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 6 7 8 1 4 9 0 5 2]
 [9 7 6 5 2 0 8 1 3 4]
 [1 6 8 2 9 3 0 4 7 5]
 [7 9 3 8 1 6 2 0 5 4]
 [5 3 6 2 7 4 9 0 8 1]
 [6 7 9 4 0 3 8 1 5 2]
 [7 8 5 4 3 1 2 6 0 9]
 [7 5 3 8 1 0 4 2 9 6]
 [3 5 1 6 0 4 9 8 2 7]
 [7 5 1 3 6 9 4 2 0 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 1 4 2 6 8 9 0 5 3]
 [6 7 4 0 2 3 9 1 5 8]
 [4 1 6 5 2 8 3 7 9 0]
 [4 0 3 6 7 8 2 5 9 1]
 [4 0 1 8 9 6 3 7 5 2]
 [0 5 1 3 9 6 8 7 4 2]
 [5 3 8 4 1 2 9 6 7 0]
 [7 5 1 2 8 4 6 0 3 9]
 [1 4 2 5 3 9 6 0 7 8]
 [9 0 8 2 3 6 4 5 1 7]]
Epoch 84810: Training cost= 2.3026, Training acc= 0.6522, Validation cost= 2.3026, Validation acc= 0.6518
Epoch 84820: Training cost= 2.3026, Training acc= 0.6521, Validation cost= 2.3026, Validation acc= 0.6517
Epoch 84830: Training cost= 2.3026, Training acc= 0.6520, Validation cost= 2.3026, Validation acc= 0.6517
Epoch 84840: Training cost= 2.3026, Training acc= 0.6520, Validation cost= 2.3026, Validation acc= 0.6516
Epoch 84850: Training cost= 2.3026, Training acc= 0.6519, Validation cost= 2.3026, Validation acc= 0.6515
Epoch 84860: Training cost= 2.3026, Training acc= 0.6518, Validation cost= 2.3026, Validation acc= 0.6515
Epoch 84870: Training cost= 2.3026, Training acc= 0.6518, Validation cost= 2.3026, Validation acc= 0.6514
Epoch 84880: Training cost= 2.3026, Training acc= 0.6517, Validation cost= 2.3026, Validation acc= 0.6513
Epoch 84890: Training cost= 2.3026, Training acc= 0.6516, Validation cost= 2.3026, Validation acc= 0.6513
Epoch 84900: Training cost= 2.3026, Training acc= 0.6516, Validation cost= 2.3026, Validation acc= 0.6512
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 2 1 9 0 5 3 7 6 8]
 [0 3 4 2 5 1 9 6 8 7]
 [1 0 2 4 3 8 9 5 6 7]
 [1 3 2 5 4 9 7 6 0 8]
 [5 0 2 1 3 9 7 4 6 8]
 [2 9 3 8 1 0 5 6 7 4]
 [4 3 9 2 7 0 8 6 5 1]
 [0 3 9 7 5 2 1 6 4 8]
 [6 1 3 9 7 0 8 2 5 4]
 [3 7 2 8 9 5 6 1 0 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 4 5 6 7 8 9 3 1 0]
 [8 6 5 0 7 4 1 2 9 3]
 [2 7 1 0 8 4 6 9 3 5]
 [3 6 2 5 8 4 1 9 7 0]
 [3 8 9 2 4 6 5 0 7 1]
 [7 4 6 0 8 1 9 2 3 5]
 [4 3 2 1 8 7 0 9 5 6]
 [3 4 9 0 2 8 6 7 5 1]
 [4 6 7 3 9 0 1 8 5 2]
 [8 7 9 5 4 3 1 6 2 0]]
Epoch 84910: Training cost= 2.3026, Training acc= 0.6515, Validation cost= 2.3026, Validation acc= 0.6511
Epoch 84920: Training cost= 2.3026, Training acc= 0.6515, Validation cost= 2.3026, Validation acc= 0.6511
Epoch 84930: Training cost= 2.3026, Training acc= 0.6514, Validation cost= 2.3026, Validation acc= 0.6510
Epoch 84940: Training cost= 2.3026, Training acc= 0.6513, Validation cost= 2.3026, Validation acc= 0.6509
Epoch 84950: Training cost= 2.3026, Training acc= 0.6513, Validation cost= 2.3026, Validation acc= 0.6509
Epoch 84960: Training cost= 2.3026, Training acc= 0.6512, Validation cost= 2.3026, Validation acc= 0.6508
Epoch 84970: Training cost= 2.3026, Training acc= 0.6511, Validation cost= 2.3026, Validation acc= 0.6508
Epoch 84980: Training cost= 2.3026, Training acc= 0.6511, Validation cost= 2.3026, Validation acc= 0.6507
Epoch 84990: Training cost= 2.3026, Training acc= 0.6510, Validation cost= 2.3026, Validation acc= 0.6506
Epoch 85000: Training cost= 2.3026, Training acc= 0.6509, Validation cost= 2.3026, Validation acc= 0.6506
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 8 6 0 2 9 4 5 7 3]
 [9 7 1 5 2 8 4 0 3 6]
 [3 9 6 7 2 1 4 8 0 5]
 [4 9 7 5 8 0 2 3 1 6]
 [3 5 2 0 8 4 1 6 9 7]
 [8 3 1 7 2 9 6 4 5 0]
 [7 9 4 2 8 0 1 5 6 3]
 [3 0 6 9 2 8 1 4 7 5]
 [9 5 3 6 7 8 2 1 0 4]
 [4 8 2 0 3 1 7 9 5 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[6 0 7 3 2 1 9 4 5 8]
 [6 4 0 3 2 1 7 8 9 5]
 [3 2 1 7 9 0 4 5 8 6]
 [7 3 4 0 6 2 5 9 8 1]
 [6 5 2 7 9 3 4 8 1 0]
 [8 0 3 4 2 1 6 9 5 7]
 [0 4 6 2 9 3 5 1 8 7]
 [1 7 2 8 5 4 3 9 0 6]
 [6 5 2 4 0 9 7 8 1 3]
 [5 0 1 3 9 8 4 6 7 2]]
Epoch 85010: Training cost= 2.3026, Training acc= 0.6509, Validation cost= 2.3026, Validation acc= 0.6505
Epoch 85020: Training cost= 2.3026, Training acc= 0.6508, Validation cost= 2.3026, Validation acc= 0.6504
Epoch 85030: Training cost= 2.3026, Training acc= 0.6507, Validation cost= 2.3026, Validation acc= 0.6504
Epoch 85040: Training cost= 2.3026, Training acc= 0.6507, Validation cost= 2.3026, Validation acc= 0.6503
Epoch 85050: Training cost= 2.3026, Training acc= 0.6506, Validation cost= 2.3026, Validation acc= 0.6502
Epoch 85060: Training cost= 2.3026, Training acc= 0.6505, Validation cost= 2.3026, Validation acc= 0.6502
Epoch 85070: Training cost= 2.3026, Training acc= 0.6505, Validation cost= 2.3026, Validation acc= 0.6501
Epoch 85080: Training cost= 2.3026, Training acc= 0.6504, Validation cost= 2.3026, Validation acc= 0.6500
Epoch 85090: Training cost= 2.3026, Training acc= 0.6504, Validation cost= 2.3026, Validation acc= 0.6500
Epoch 85100: Training cost= 2.3026, Training acc= 0.6503, Validation cost= 2.3026, Validation acc= 0.6499
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 3 8 7 5 0 2 6 4 1]
 [3 5 4 0 7 2 1 8 9 6]
 [0 7 9 6 1 5 2 8 4 3]
 [5 7 9 8 6 4 0 2 1 3]
 [6 4 3 7 9 0 8 2 5 1]
 [7 1 8 2 4 9 3 6 0 5]
 [1 8 9 2 7 5 3 6 4 0]
 [2 4 6 0 7 1 5 3 9 8]
 [6 0 2 1 8 5 7 3 9 4]
 [3 7 9 6 4 8 0 5 1 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 2 8 7 0 1 6 3 4 5]
 [7 5 8 6 3 1 2 0 4 9]
 [8 2 7 4 9 5 6 0 3 1]
 [9 6 3 5 2 0 8 4 1 7]
 [7 9 3 2 6 5 1 8 4 0]
 [1 8 9 7 0 3 5 4 2 6]
 [2 5 4 7 6 3 0 1 8 9]
 [2 4 7 8 1 3 9 5 0 6]
 [4 5 2 1 3 8 6 9 0 7]
 [0 6 3 5 9 7 8 4 2 1]]
Epoch 85110: Training cost= 2.3026, Training acc= 0.6502, Validation cost= 2.3026, Validation acc= 0.6498
Epoch 85120: Training cost= 2.3026, Training acc= 0.6502, Validation cost= 2.3026, Validation acc= 0.6498
Epoch 85130: Training cost= 2.3026, Training acc= 0.6501, Validation cost= 2.3026, Validation acc= 0.6497
Epoch 85140: Training cost= 2.3026, Training acc= 0.6500, Validation cost= 2.3026, Validation acc= 0.6497
Epoch 85150: Training cost= 2.3026, Training acc= 0.6500, Validation cost= 2.3026, Validation acc= 0.6496
Epoch 85160: Training cost= 2.3026, Training acc= 0.6499, Validation cost= 2.3026, Validation acc= 0.6495
Epoch 85170: Training cost= 2.3026, Training acc= 0.6498, Validation cost= 2.3026, Validation acc= 0.6495
Epoch 85180: Training cost= 2.3026, Training acc= 0.6498, Validation cost= 2.3026, Validation acc= 0.6494
Epoch 85190: Training cost= 2.3026, Training acc= 0.6497, Validation cost= 2.3026, Validation acc= 0.6493
Epoch 85200: Training cost= 2.3026, Training acc= 0.6496, Validation cost= 2.3026, Validation acc= 0.6493
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 4 7 3 9 0 8 6 1 5]
 [6 5 3 2 0 4 9 1 7 8]
 [2 4 0 3 8 1 9 6 7 5]
 [3 2 0 8 6 5 4 1 9 7]
 [6 8 0 7 4 3 1 2 9 5]
 [0 9 2 3 5 7 8 4 1 6]
 [2 5 4 6 3 8 7 1 0 9]
 [9 5 7 6 8 4 1 3 2 0]
 [7 1 6 8 5 4 0 9 2 3]
 [8 4 2 0 5 7 6 9 3 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 5 7 2 9 0 6 3 1 4]
 [2 5 0 3 6 7 8 1 9 4]
 [4 1 5 6 7 2 8 3 0 9]
 [8 1 4 7 0 3 9 6 5 2]
 [3 0 9 8 6 1 2 4 7 5]
 [9 4 8 3 5 1 2 6 0 7]
 [6 4 8 1 7 3 0 5 2 9]
 [9 1 3 4 2 0 7 6 5 8]
 [2 4 6 9 5 3 0 7 8 1]
 [3 5 7 0 2 4 9 8 6 1]]
Epoch 85210: Training cost= 2.3026, Training acc= 0.6496, Validation cost= 2.3026, Validation acc= 0.6492
Epoch 85220: Training cost= 2.3026, Training acc= 0.6495, Validation cost= 2.3026, Validation acc= 0.6491
Epoch 85230: Training cost= 2.3026, Training acc= 0.6494, Validation cost= 2.3026, Validation acc= 0.6491
Epoch 85240: Training cost= 2.3026, Training acc= 0.6494, Validation cost= 2.3026, Validation acc= 0.6490
Epoch 85250: Training cost= 2.3026, Training acc= 0.6493, Validation cost= 2.3026, Validation acc= 0.6489
Epoch 85260: Training cost= 2.3026, Training acc= 0.6493, Validation cost= 2.3026, Validation acc= 0.6489
Epoch 85270: Training cost= 2.3026, Training acc= 0.6492, Validation cost= 2.3026, Validation acc= 0.6488
Epoch 85280: Training cost= 2.3026, Training acc= 0.6491, Validation cost= 2.3026, Validation acc= 0.6488
Epoch 85290: Training cost= 2.3026, Training acc= 0.6491, Validation cost= 2.3026, Validation acc= 0.6487
Epoch 85300: Training cost= 2.3026, Training acc= 0.6490, Validation cost= 2.3026, Validation acc= 0.6486
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 9 8 1 6 3 2 0 4 7]
 [3 2 9 6 4 5 1 8 7 0]
 [8 6 2 9 0 7 5 1 3 4]
 [1 4 7 5 8 6 0 3 2 9]
 [5 1 7 3 0 2 8 4 6 9]
 [5 2 3 4 7 8 6 9 0 1]
 [6 1 5 2 3 9 4 0 7 8]
 [5 6 9 0 1 3 8 4 7 2]
 [8 6 9 1 7 5 2 3 4 0]
 [7 2 0 9 1 5 8 6 3 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 0 5 1 2 9 7 3 6 4]
 [5 2 6 0 1 3 8 9 4 7]
 [5 6 1 8 9 7 0 3 4 2]
 [5 6 4 1 3 2 7 9 0 8]
 [7 4 9 2 0 1 3 5 6 8]
 [3 4 0 6 1 5 9 7 2 8]
 [8 4 9 1 6 5 7 2 0 3]
 [3 6 8 1 2 7 9 5 0 4]
 [7 5 8 6 0 4 9 1 3 2]
 [1 6 7 5 2 4 9 8 0 3]]
Epoch 85310: Training cost= 2.3026, Training acc= 0.6489, Validation cost= 2.3026, Validation acc= 0.6486
Epoch 85320: Training cost= 2.3026, Training acc= 0.6489, Validation cost= 2.3026, Validation acc= 0.6485
Epoch 85330: Training cost= 2.3026, Training acc= 0.6488, Validation cost= 2.3026, Validation acc= 0.6484
Epoch 85340: Training cost= 2.3026, Training acc= 0.6487, Validation cost= 2.3026, Validation acc= 0.6484
Epoch 85350: Training cost= 2.3026, Training acc= 0.6487, Validation cost= 2.3026, Validation acc= 0.6483
Epoch 85360: Training cost= 2.3026, Training acc= 0.6486, Validation cost= 2.3026, Validation acc= 0.6482
Epoch 85370: Training cost= 2.3026, Training acc= 0.6485, Validation cost= 2.3026, Validation acc= 0.6482
Epoch 85380: Training cost= 2.3026, Training acc= 0.6485, Validation cost= 2.3026, Validation acc= 0.6481
Epoch 85390: Training cost= 2.3026, Training acc= 0.6484, Validation cost= 2.3026, Validation acc= 0.6480
Epoch 85400: Training cost= 2.3026, Training acc= 0.6484, Validation cost= 2.3026, Validation acc= 0.6480
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 6 3 4 7 0 5 8 2 9]
 [0 4 7 6 3 9 1 2 5 8]
 [4 7 5 3 0 2 1 9 8 6]
 [7 8 3 9 5 4 2 6 1 0]
 [9 4 2 6 8 0 5 7 1 3]
 [6 5 2 1 4 7 8 9 3 0]
 [5 9 3 4 7 6 8 2 0 1]
 [8 9 5 6 1 7 0 3 4 2]
 [2 8 4 1 9 5 6 7 0 3]
 [8 2 7 0 6 1 3 9 5 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 5 7 4 6 3 8 0 9 1]
 [5 7 8 4 2 6 1 9 3 0]
 [3 9 2 0 4 6 1 5 7 8]
 [6 7 0 2 3 9 1 5 4 8]
 [8 3 9 2 5 7 4 1 0 6]
 [4 7 9 3 5 1 6 2 8 0]
 [9 5 2 8 0 3 1 7 6 4]
 [8 1 4 0 6 2 5 7 9 3]
 [5 6 1 8 7 9 3 0 4 2]
 [8 3 7 2 5 6 4 1 0 9]]
Epoch 85410: Training cost= 2.3026, Training acc= 0.6483, Validation cost= 2.3026, Validation acc= 0.6479
Epoch 85420: Training cost= 2.3026, Training acc= 0.6482, Validation cost= 2.3026, Validation acc= 0.6479
Epoch 85430: Training cost= 2.3026, Training acc= 0.6482, Validation cost= 2.3026, Validation acc= 0.6478
Epoch 85440: Training cost= 2.3026, Training acc= 0.6481, Validation cost= 2.3026, Validation acc= 0.6477
Epoch 85450: Training cost= 2.3026, Training acc= 0.6480, Validation cost= 2.3026, Validation acc= 0.6477
Epoch 85460: Training cost= 2.3026, Training acc= 0.6480, Validation cost= 2.3026, Validation acc= 0.6476
Epoch 85470: Training cost= 2.3026, Training acc= 0.6479, Validation cost= 2.3026, Validation acc= 0.6475
Epoch 85480: Training cost= 2.3026, Training acc= 0.6478, Validation cost= 2.3026, Validation acc= 0.6475
Epoch 85490: Training cost= 2.3026, Training acc= 0.6478, Validation cost= 2.3026, Validation acc= 0.6474
Epoch 85500: Training cost= 2.3026, Training acc= 0.6477, Validation cost= 2.3026, Validation acc= 0.6473
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 0 9 4 5 7 3 2 1 8]
 [3 9 6 0 4 8 5 2 7 1]
 [1 3 7 5 8 0 2 6 4 9]
 [1 6 0 4 3 2 9 8 5 7]
 [7 5 8 9 0 4 2 3 6 1]
 [6 7 3 9 5 0 4 2 8 1]
 [7 0 3 6 2 4 8 9 1 5]
 [8 6 1 2 7 4 0 5 9 3]
 [7 5 1 9 8 2 3 0 6 4]
 [2 5 9 8 1 0 3 7 4 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 1 3 5 4 0 2 8 6 9]
 [8 6 0 1 3 5 7 2 4 9]
 [7 4 6 9 8 3 1 2 5 0]
 [9 2 0 6 4 1 7 5 3 8]
 [7 2 9 8 4 0 6 3 1 5]
 [9 8 2 1 6 5 0 3 4 7]
 [5 9 7 2 4 0 3 8 6 1]
 [4 5 0 3 1 9 7 2 6 8]
 [4 2 8 7 5 3 6 1 0 9]
 [3 7 9 6 0 5 4 8 1 2]]
Epoch 85510: Training cost= 2.3026, Training acc= 0.6476, Validation cost= 2.3026, Validation acc= 0.6473
Epoch 85520: Training cost= 2.3026, Training acc= 0.6476, Validation cost= 2.3026, Validation acc= 0.6472
Epoch 85530: Training cost= 2.3026, Training acc= 0.6475, Validation cost= 2.3026, Validation acc= 0.6471
Epoch 85540: Training cost= 2.3026, Training acc= 0.6475, Validation cost= 2.3026, Validation acc= 0.6471
Epoch 85550: Training cost= 2.3026, Training acc= 0.6474, Validation cost= 2.3026, Validation acc= 0.6470
Epoch 85560: Training cost= 2.3026, Training acc= 0.6473, Validation cost= 2.3026, Validation acc= 0.6470
Epoch 85570: Training cost= 2.3026, Training acc= 0.6473, Validation cost= 2.3026, Validation acc= 0.6469
Epoch 85580: Training cost= 2.3026, Training acc= 0.6472, Validation cost= 2.3026, Validation acc= 0.6468
Epoch 85590: Training cost= 2.3026, Training acc= 0.6471, Validation cost= 2.3026, Validation acc= 0.6468
Epoch 85600: Training cost= 2.3026, Training acc= 0.6471, Validation cost= 2.3026, Validation acc= 0.6467
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 4 9 3 7 6 8 1 5 2]
 [1 0 5 7 4 6 2 3 9 8]
 [5 2 3 4 7 6 8 0 9 1]
 [2 5 9 1 3 6 0 7 4 8]
 [6 0 1 7 8 3 5 9 4 2]
 [9 8 3 4 1 0 2 5 7 6]
 [8 5 0 3 6 4 2 7 9 1]
 [1 7 4 6 5 2 3 9 0 8]
 [3 2 6 8 9 7 4 1 0 5]
 [0 3 9 7 4 5 1 6 8 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 0 3 5 8 6 4 1 7 2]
 [6 2 1 4 0 5 9 8 7 3]
 [1 8 5 2 3 0 9 6 4 7]
 [2 7 1 9 6 8 3 5 0 4]
 [2 8 0 1 3 6 9 7 4 5]
 [6 0 4 8 2 9 7 5 1 3]
 [0 7 1 3 8 5 4 6 2 9]
 [1 7 3 4 8 0 5 6 2 9]
 [5 7 6 3 1 8 2 9 4 0]
 [5 6 8 9 2 0 7 4 3 1]]
Epoch 85610: Training cost= 2.3026, Training acc= 0.6470, Validation cost= 2.3026, Validation acc= 0.6466
Epoch 85620: Training cost= 2.3026, Training acc= 0.6469, Validation cost= 2.3026, Validation acc= 0.6466
Epoch 85630: Training cost= 2.3026, Training acc= 0.6469, Validation cost= 2.3026, Validation acc= 0.6465
Epoch 85640: Training cost= 2.3026, Training acc= 0.6468, Validation cost= 2.3026, Validation acc= 0.6464
Epoch 85650: Training cost= 2.3026, Training acc= 0.6468, Validation cost= 2.3026, Validation acc= 0.6464
Epoch 85660: Training cost= 2.3026, Training acc= 0.6467, Validation cost= 2.3026, Validation acc= 0.6463
Epoch 85670: Training cost= 2.3026, Training acc= 0.6466, Validation cost= 2.3026, Validation acc= 0.6463
Epoch 85680: Training cost= 2.3026, Training acc= 0.6466, Validation cost= 2.3026, Validation acc= 0.6462
Epoch 85690: Training cost= 2.3026, Training acc= 0.6465, Validation cost= 2.3026, Validation acc= 0.6461
Epoch 85700: Training cost= 2.3026, Training acc= 0.6464, Validation cost= 2.3026, Validation acc= 0.6461
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 9 0 4 6 5 7 2 1 3]
 [6 8 5 3 1 0 2 4 9 7]
 [1 6 0 5 9 7 3 8 4 2]
 [5 8 0 7 4 1 6 2 9 3]
 [6 4 1 2 8 9 0 7 5 3]
 [8 1 7 4 5 2 9 6 3 0]
 [9 5 3 1 8 4 7 0 2 6]
 [4 5 3 6 7 8 0 2 1 9]
 [1 3 4 0 6 9 2 8 7 5]
 [9 2 6 7 4 1 0 3 8 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 2 3 8 5 9 4 6 7 1]
 [8 0 7 5 3 6 2 9 1 4]
 [2 1 5 0 9 3 7 6 8 4]
 [7 5 4 1 9 0 2 6 8 3]
 [2 4 5 6 1 8 0 7 9 3]
 [4 2 6 0 3 1 8 5 7 9]
 [5 8 9 1 6 2 4 3 7 0]
 [6 5 1 9 7 4 0 8 2 3]
 [9 7 8 1 5 0 2 6 3 4]
 [2 5 6 3 1 7 9 0 4 8]]
Epoch 85710: Training cost= 2.3026, Training acc= 0.6464, Validation cost= 2.3026, Validation acc= 0.6460
Epoch 85720: Training cost= 2.3026, Training acc= 0.6463, Validation cost= 2.3026, Validation acc= 0.6459
Epoch 85730: Training cost= 2.3026, Training acc= 0.6462, Validation cost= 2.3026, Validation acc= 0.6459
Epoch 85740: Training cost= 2.3026, Training acc= 0.6462, Validation cost= 2.3026, Validation acc= 0.6458
Epoch 85750: Training cost= 2.3026, Training acc= 0.6461, Validation cost= 2.3026, Validation acc= 0.6457
Epoch 85760: Training cost= 2.3026, Training acc= 0.6461, Validation cost= 2.3026, Validation acc= 0.6457
Epoch 85770: Training cost= 2.3026, Training acc= 0.6460, Validation cost= 2.3026, Validation acc= 0.6456
Epoch 85780: Training cost= 2.3026, Training acc= 0.6459, Validation cost= 2.3026, Validation acc= 0.6456
Epoch 85790: Training cost= 2.3026, Training acc= 0.6459, Validation cost= 2.3026, Validation acc= 0.6455
Epoch 85800: Training cost= 2.3026, Training acc= 0.6458, Validation cost= 2.3026, Validation acc= 0.6454
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 2 8 7 1 4 6 0 5 3]
 [0 9 6 4 3 8 5 7 2 1]
 [8 3 2 7 0 5 9 4 6 1]
 [2 9 7 1 8 3 0 6 4 5]
 [4 2 3 0 8 6 7 9 1 5]
 [9 2 0 8 3 7 6 4 5 1]
 [5 2 3 8 9 0 6 7 1 4]
 [5 1 3 6 4 7 9 8 0 2]
 [9 3 5 7 8 1 6 2 4 0]
 [2 3 8 4 7 0 1 5 9 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 2 0 1 7 8 9 5 4 6]
 [9 7 5 1 2 8 6 0 3 4]
 [6 7 3 5 1 8 9 0 2 4]
 [3 7 8 6 9 4 5 1 0 2]
 [6 8 0 2 5 9 1 4 7 3]
 [9 3 7 1 4 5 8 0 6 2]
 [4 8 3 1 9 6 5 0 7 2]
 [9 3 5 1 2 4 8 6 7 0]
 [3 6 4 7 5 9 8 2 1 0]
 [4 5 2 1 9 7 8 6 3 0]]
Epoch 85810: Training cost= 2.3026, Training acc= 0.6457, Validation cost= 2.3026, Validation acc= 0.6454
Epoch 85820: Training cost= 2.3026, Training acc= 0.6457, Validation cost= 2.3026, Validation acc= 0.6453
Epoch 85830: Training cost= 2.3026, Training acc= 0.6456, Validation cost= 2.3026, Validation acc= 0.6452
Epoch 85840: Training cost= 2.3026, Training acc= 0.6455, Validation cost= 2.3026, Validation acc= 0.6452
Epoch 85850: Training cost= 2.3026, Training acc= 0.6455, Validation cost= 2.3026, Validation acc= 0.6451
Epoch 85860: Training cost= 2.3026, Training acc= 0.6454, Validation cost= 2.3026, Validation acc= 0.6450
Epoch 85870: Training cost= 2.3026, Training acc= 0.6454, Validation cost= 2.3026, Validation acc= 0.6450
Epoch 85880: Training cost= 2.3026, Training acc= 0.6453, Validation cost= 2.3026, Validation acc= 0.6449
Epoch 85890: Training cost= 2.3026, Training acc= 0.6452, Validation cost= 2.3026, Validation acc= 0.6449
Epoch 85900: Training cost= 2.3026, Training acc= 0.6452, Validation cost= 2.3026, Validation acc= 0.6448
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 0 3 8 6 1 5 9 7 2]
 [5 1 6 3 9 4 7 0 8 2]
 [0 1 6 7 3 9 2 4 5 8]
 [9 5 6 2 8 1 0 7 4 3]
 [4 0 8 6 9 2 3 7 5 1]
 [7 5 8 9 3 1 2 4 0 6]
 [8 4 3 2 9 0 1 7 5 6]
 [5 6 4 7 2 0 9 8 3 1]
 [5 8 6 7 2 3 1 0 4 9]
 [6 0 1 4 9 8 7 2 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 0 7 4 3 6 1 9 8 2]
 [1 6 8 0 4 7 9 5 2 3]
 [7 5 4 2 6 9 3 1 0 8]
 [5 9 7 1 0 2 3 6 8 4]
 [1 8 0 9 4 5 2 3 7 6]
 [2 9 0 6 5 8 1 7 3 4]
 [3 9 4 0 2 8 6 7 1 5]
 [6 9 3 4 0 8 7 1 2 5]
 [5 8 3 6 1 4 9 7 0 2]
 [3 7 2 0 8 9 5 6 1 4]]
Epoch 85910: Training cost= 2.3026, Training acc= 0.6451, Validation cost= 2.3026, Validation acc= 0.6447
Epoch 85920: Training cost= 2.3026, Training acc= 0.6450, Validation cost= 2.3026, Validation acc= 0.6447
Epoch 85930: Training cost= 2.3026, Training acc= 0.6450, Validation cost= 2.3026, Validation acc= 0.6446
Epoch 85940: Training cost= 2.3026, Training acc= 0.6449, Validation cost= 2.3026, Validation acc= 0.6445
Epoch 85950: Training cost= 2.3026, Training acc= 0.6448, Validation cost= 2.3026, Validation acc= 0.6445
Epoch 85960: Training cost= 2.3026, Training acc= 0.6448, Validation cost= 2.3026, Validation acc= 0.6444
Epoch 85970: Training cost= 2.3026, Training acc= 0.6447, Validation cost= 2.3026, Validation acc= 0.6443
Epoch 85980: Training cost= 2.3026, Training acc= 0.6447, Validation cost= 2.3026, Validation acc= 0.6443
Epoch 85990: Training cost= 2.3026, Training acc= 0.6446, Validation cost= 2.3026, Validation acc= 0.6442
Epoch 86000: Training cost= 2.3026, Training acc= 0.6445, Validation cost= 2.3026, Validation acc= 0.6442
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 4 7 9 1 8 6 5 0 3]
 [8 4 1 0 9 7 5 6 2 3]
 [6 0 9 8 1 3 2 5 7 4]
 [6 3 1 5 8 2 7 0 4 9]
 [3 9 7 6 4 5 0 1 2 8]
 [8 6 9 2 1 0 5 3 4 7]
 [7 3 1 9 8 4 2 0 5 6]
 [8 5 9 3 0 6 2 7 1 4]
 [7 4 2 9 6 1 0 5 8 3]
 [6 1 4 8 5 3 0 2 7 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 4 7 6 5 3 9 0 1 2]
 [1 5 9 0 4 8 7 6 3 2]
 [4 3 1 8 5 7 0 9 6 2]
 [8 9 0 1 4 2 3 5 7 6]
 [4 3 7 0 9 1 6 2 8 5]
 [4 6 8 7 5 1 9 3 2 0]
 [8 6 7 2 1 9 4 3 5 0]
 [5 3 7 8 0 2 4 9 1 6]
 [6 9 7 5 3 1 0 4 2 8]
 [7 3 2 6 8 4 5 1 0 9]]
Epoch 86010: Training cost= 2.3026, Training acc= 0.6445, Validation cost= 2.3026, Validation acc= 0.6441
Epoch 86020: Training cost= 2.3026, Training acc= 0.6444, Validation cost= 2.3026, Validation acc= 0.6440
Epoch 86030: Training cost= 2.3026, Training acc= 0.6443, Validation cost= 2.3026, Validation acc= 0.6440
Epoch 86040: Training cost= 2.3026, Training acc= 0.6443, Validation cost= 2.3026, Validation acc= 0.6439
Epoch 86050: Training cost= 2.3026, Training acc= 0.6442, Validation cost= 2.3026, Validation acc= 0.6438
Epoch 86060: Training cost= 2.3026, Training acc= 0.6441, Validation cost= 2.3026, Validation acc= 0.6438
Epoch 86070: Training cost= 2.3026, Training acc= 0.6441, Validation cost= 2.3026, Validation acc= 0.6437
Epoch 86080: Training cost= 2.3026, Training acc= 0.6440, Validation cost= 2.3026, Validation acc= 0.6437
Epoch 86090: Training cost= 2.3026, Training acc= 0.6440, Validation cost= 2.3026, Validation acc= 0.6436
Epoch 86100: Training cost= 2.3026, Training acc= 0.6439, Validation cost= 2.3026, Validation acc= 0.6435
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 3 0 7 9 6 4 5 8 1]
 [1 3 5 8 7 6 9 4 2 0]
 [2 7 6 9 1 4 8 3 0 5]
 [2 5 0 8 3 7 9 1 4 6]
 [4 8 7 6 1 0 2 3 5 9]
 [7 2 4 5 3 6 8 9 0 1]
 [4 8 2 5 0 3 6 7 1 9]
 [6 1 7 4 0 8 9 2 3 5]
 [9 7 0 4 6 1 3 5 8 2]
 [2 6 3 8 9 0 4 5 7 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 3 4 0 5 6 1 7 2 8]
 [5 0 8 2 1 7 3 9 6 4]
 [5 2 3 9 1 0 8 6 4 7]
 [2 4 9 6 7 8 1 3 5 0]
 [7 3 0 5 1 6 4 9 2 8]
 [3 2 5 4 6 0 8 9 1 7]
 [0 3 9 4 6 5 7 2 1 8]
 [6 8 1 9 5 4 0 3 7 2]
 [0 5 6 1 4 3 2 8 9 7]
 [5 8 6 1 0 3 4 2 7 9]]
Epoch 86110: Training cost= 2.3026, Training acc= 0.6438, Validation cost= 2.3026, Validation acc= 0.6435
Epoch 86120: Training cost= 2.3026, Training acc= 0.6438, Validation cost= 2.3026, Validation acc= 0.6434
Epoch 86130: Training cost= 2.3026, Training acc= 0.6437, Validation cost= 2.3026, Validation acc= 0.6433
Epoch 86140: Training cost= 2.3026, Training acc= 0.6436, Validation cost= 2.3026, Validation acc= 0.6433
Epoch 86150: Training cost= 2.3026, Training acc= 0.6436, Validation cost= 2.3026, Validation acc= 0.6432
Epoch 86160: Training cost= 2.3026, Training acc= 0.6435, Validation cost= 2.3026, Validation acc= 0.6431
Epoch 86170: Training cost= 2.3026, Training acc= 0.6435, Validation cost= 2.3026, Validation acc= 0.6431
Epoch 86180: Training cost= 2.3026, Training acc= 0.6434, Validation cost= 2.3026, Validation acc= 0.6430
Epoch 86190: Training cost= 2.3026, Training acc= 0.6433, Validation cost= 2.3026, Validation acc= 0.6430
Epoch 86200: Training cost= 2.3026, Training acc= 0.6433, Validation cost= 2.3026, Validation acc= 0.6429
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 0 9 8 3 5 2 1 6 7]
 [0 3 6 9 5 8 1 7 2 4]
 [2 4 9 3 5 7 6 8 0 1]
 [4 5 6 9 2 8 3 0 1 7]
 [5 1 9 7 8 2 4 6 3 0]
 [1 6 9 2 0 4 5 3 8 7]
 [5 8 2 7 3 0 4 1 9 6]
 [3 2 4 5 0 1 6 8 9 7]
 [5 7 9 1 3 6 8 4 2 0]
 [1 4 3 2 6 7 5 9 0 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 7 9 6 5 3 1 8 0 2]
 [3 6 1 2 7 8 0 5 9 4]
 [9 3 8 0 5 7 2 1 4 6]
 [8 2 0 5 9 1 3 6 4 7]
 [8 3 9 6 4 5 1 0 7 2]
 [2 1 4 8 7 0 5 9 3 6]
 [8 1 3 6 2 5 0 4 9 7]
 [8 9 4 0 1 2 7 6 3 5]
 [9 4 2 7 1 8 0 3 6 5]
 [0 7 6 2 4 5 8 9 1 3]]
Epoch 86210: Training cost= 2.3026, Training acc= 0.6432, Validation cost= 2.3026, Validation acc= 0.6428
Epoch 86220: Training cost= 2.3026, Training acc= 0.6431, Validation cost= 2.3026, Validation acc= 0.6428
Epoch 86230: Training cost= 2.3026, Training acc= 0.6431, Validation cost= 2.3026, Validation acc= 0.6427
Epoch 86240: Training cost= 2.3026, Training acc= 0.6430, Validation cost= 2.3026, Validation acc= 0.6426
Epoch 86250: Training cost= 2.3026, Training acc= 0.6430, Validation cost= 2.3026, Validation acc= 0.6426
Epoch 86260: Training cost= 2.3026, Training acc= 0.6429, Validation cost= 2.3026, Validation acc= 0.6425
Epoch 86270: Training cost= 2.3026, Training acc= 0.6428, Validation cost= 2.3026, Validation acc= 0.6425
Epoch 86280: Training cost= 2.3026, Training acc= 0.6428, Validation cost= 2.3026, Validation acc= 0.6424
Epoch 86290: Training cost= 2.3026, Training acc= 0.6427, Validation cost= 2.3026, Validation acc= 0.6423
Epoch 86300: Training cost= 2.3026, Training acc= 0.6426, Validation cost= 2.3026, Validation acc= 0.6423
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 2 7 6 5 8 1 4 9 3]
 [6 9 7 1 3 2 0 8 4 5]
 [8 5 3 2 4 6 0 7 9 1]
 [3 4 0 5 8 1 7 2 9 6]
 [9 8 1 5 4 0 3 6 2 7]
 [9 1 8 5 6 4 2 3 0 7]
 [8 5 7 1 2 4 0 3 9 6]
 [6 3 1 7 8 5 9 2 4 0]
 [4 2 7 9 8 6 3 1 0 5]
 [3 2 6 5 4 0 8 1 9 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 3 8 6 9 5 4 1 0 2]
 [4 6 9 5 8 2 0 1 3 7]
 [4 6 0 9 8 5 2 7 3 1]
 [5 2 8 0 1 6 4 3 9 7]
 [4 5 2 3 8 6 9 1 7 0]
 [0 7 4 5 3 8 6 2 1 9]
 [3 7 5 9 6 8 1 0 2 4]
 [9 5 7 1 8 2 6 3 4 0]
 [2 9 0 1 8 6 4 7 3 5]
 [9 0 5 6 1 3 4 2 7 8]]
Epoch 86310: Training cost= 2.3026, Training acc= 0.6426, Validation cost= 2.3026, Validation acc= 0.6422
Epoch 86320: Training cost= 2.3026, Training acc= 0.6425, Validation cost= 2.3026, Validation acc= 0.6421
Epoch 86330: Training cost= 2.3026, Training acc= 0.6424, Validation cost= 2.3026, Validation acc= 0.6421
Epoch 86340: Training cost= 2.3026, Training acc= 0.6424, Validation cost= 2.3026, Validation acc= 0.6420
Epoch 86350: Training cost= 2.3026, Training acc= 0.6423, Validation cost= 2.3026, Validation acc= 0.6420
Epoch 86360: Training cost= 2.3026, Training acc= 0.6423, Validation cost= 2.3026, Validation acc= 0.6419
Epoch 86370: Training cost= 2.3026, Training acc= 0.6422, Validation cost= 2.3026, Validation acc= 0.6418
Epoch 86380: Training cost= 2.3026, Training acc= 0.6421, Validation cost= 2.3026, Validation acc= 0.6418
Epoch 86390: Training cost= 2.3026, Training acc= 0.6421, Validation cost= 2.3026, Validation acc= 0.6417
Epoch 86400: Training cost= 2.3026, Training acc= 0.6420, Validation cost= 2.3026, Validation acc= 0.6416
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 6 1 9 7 3 8 2 0 5]
 [4 9 7 1 5 3 6 8 0 2]
 [5 6 4 7 8 2 1 0 3 9]
 [5 8 6 2 7 1 3 0 9 4]
 [5 9 0 3 8 6 4 2 7 1]
 [1 9 6 4 5 2 8 3 7 0]
 [1 8 2 7 3 4 9 5 0 6]
 [5 8 4 2 9 7 0 6 1 3]
 [6 9 3 7 8 4 0 5 2 1]
 [6 9 5 7 8 3 2 4 1 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 1 3 7 0 4 5 6 2 9]
 [7 3 2 0 8 1 4 5 9 6]
 [5 2 0 8 1 4 7 6 9 3]
 [0 5 9 8 7 3 2 6 4 1]
 [3 9 4 0 5 8 7 1 6 2]
 [1 8 7 9 5 2 0 4 6 3]
 [2 9 4 3 7 1 0 8 5 6]
 [0 9 4 8 1 2 7 6 3 5]
 [2 3 1 4 9 5 6 8 0 7]
 [9 3 7 6 0 5 4 2 8 1]]
Epoch 86410: Training cost= 2.3026, Training acc= 0.6419, Validation cost= 2.3026, Validation acc= 0.6416
Epoch 86420: Training cost= 2.3026, Training acc= 0.6419, Validation cost= 2.3026, Validation acc= 0.6415
Epoch 86430: Training cost= 2.3026, Training acc= 0.6418, Validation cost= 2.3026, Validation acc= 0.6415
Epoch 86440: Training cost= 2.3026, Training acc= 0.6418, Validation cost= 2.3026, Validation acc= 0.6414
Epoch 86450: Training cost= 2.3026, Training acc= 0.6417, Validation cost= 2.3026, Validation acc= 0.6413
Epoch 86460: Training cost= 2.3026, Training acc= 0.6416, Validation cost= 2.3026, Validation acc= 0.6413
Epoch 86470: Training cost= 2.3026, Training acc= 0.6416, Validation cost= 2.3026, Validation acc= 0.6412
Epoch 86480: Training cost= 2.3026, Training acc= 0.6415, Validation cost= 2.3026, Validation acc= 0.6411
Epoch 86490: Training cost= 2.3026, Training acc= 0.6414, Validation cost= 2.3026, Validation acc= 0.6411
Epoch 86500: Training cost= 2.3026, Training acc= 0.6414, Validation cost= 2.3026, Validation acc= 0.6410
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 5 9 3 6 2 1 8 4 7]
 [2 0 1 3 5 7 9 6 8 4]
 [1 6 7 0 2 4 3 8 5 9]
 [4 7 2 6 8 9 3 1 5 0]
 [2 5 3 7 0 1 9 8 6 4]
 [3 5 6 4 1 7 0 9 8 2]
 [2 0 1 8 3 9 5 7 4 6]
 [4 1 2 6 9 3 0 5 8 7]
 [0 4 5 6 1 7 9 3 8 2]
 [6 3 8 7 0 2 1 5 4 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 6 7 9 4 5 1 0 8 3]
 [0 3 8 7 2 1 4 9 5 6]
 [3 8 2 9 7 4 5 6 1 0]
 [6 8 7 9 1 2 0 3 4 5]
 [8 0 1 7 5 2 9 6 3 4]
 [0 2 1 4 9 6 8 5 3 7]
 [1 2 8 6 5 3 0 9 4 7]
 [1 3 5 6 0 7 4 2 8 9]
 [6 5 3 7 4 1 8 2 9 0]
 [9 8 5 0 4 6 2 1 7 3]]
Epoch 86510: Training cost= 2.3026, Training acc= 0.6413, Validation cost= 2.3026, Validation acc= 0.6410
Epoch 86520: Training cost= 2.3026, Training acc= 0.6413, Validation cost= 2.3026, Validation acc= 0.6409
Epoch 86530: Training cost= 2.3026, Training acc= 0.6412, Validation cost= 2.3026, Validation acc= 0.6408
Epoch 86540: Training cost= 2.3026, Training acc= 0.6411, Validation cost= 2.3026, Validation acc= 0.6408
Epoch 86550: Training cost= 2.3026, Training acc= 0.6411, Validation cost= 2.3026, Validation acc= 0.6407
Epoch 86560: Training cost= 2.3026, Training acc= 0.6410, Validation cost= 2.3026, Validation acc= 0.6406
Epoch 86570: Training cost= 2.3026, Training acc= 0.6409, Validation cost= 2.3026, Validation acc= 0.6406
Epoch 86580: Training cost= 2.3026, Training acc= 0.6409, Validation cost= 2.3026, Validation acc= 0.6405
Epoch 86590: Training cost= 2.3026, Training acc= 0.6408, Validation cost= 2.3026, Validation acc= 0.6405
Epoch 86600: Training cost= 2.3026, Training acc= 0.6408, Validation cost= 2.3026, Validation acc= 0.6404
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 6 1 8 0 2 5 7 3]
 [1 5 6 8 0 7 9 4 3 2]
 [4 3 9 7 5 1 2 0 6 8]
 [6 3 2 1 9 0 4 7 5 8]
 [9 4 3 8 1 5 0 7 2 6]
 [5 4 7 9 6 2 3 8 1 0]
 [2 1 9 6 8 3 4 5 7 0]
 [1 4 5 8 3 6 0 9 2 7]
 [2 9 5 7 8 6 3 0 1 4]
 [2 4 8 9 6 5 0 3 7 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 7 8 9 0 3 2 1 5 6]
 [2 6 4 8 5 7 3 1 0 9]
 [9 4 2 3 5 7 6 1 8 0]
 [0 5 4 1 6 7 8 2 3 9]
 [6 2 4 0 7 8 5 3 9 1]
 [1 2 5 7 3 0 8 4 6 9]
 [5 7 0 8 2 6 4 9 3 1]
 [3 7 4 6 0 5 2 1 8 9]
 [6 5 9 4 1 2 7 8 3 0]
 [4 3 6 8 7 0 1 5 2 9]]
Epoch 86610: Training cost= 2.3026, Training acc= 0.6407, Validation cost= 2.3026, Validation acc= 0.6403
Epoch 86620: Training cost= 2.3026, Training acc= 0.6406, Validation cost= 2.3026, Validation acc= 0.6403
Epoch 86630: Training cost= 2.3026, Training acc= 0.6406, Validation cost= 2.3026, Validation acc= 0.6402
Epoch 86640: Training cost= 2.3026, Training acc= 0.6405, Validation cost= 2.3026, Validation acc= 0.6401
Epoch 86650: Training cost= 2.3026, Training acc= 0.6404, Validation cost= 2.3026, Validation acc= 0.6401
Epoch 86660: Training cost= 2.3026, Training acc= 0.6404, Validation cost= 2.3026, Validation acc= 0.6400
Epoch 86670: Training cost= 2.3026, Training acc= 0.6403, Validation cost= 2.3026, Validation acc= 0.6400
Epoch 86680: Training cost= 2.3026, Training acc= 0.6403, Validation cost= 2.3026, Validation acc= 0.6399
Epoch 86690: Training cost= 2.3026, Training acc= 0.6402, Validation cost= 2.3026, Validation acc= 0.6398
Epoch 86700: Training cost= 2.3026, Training acc= 0.6401, Validation cost= 2.3026, Validation acc= 0.6398
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 5 8 2 1 3 6 7 9 0]
 [3 2 9 7 4 1 5 0 6 8]
 [8 2 7 4 3 9 5 0 1 6]
 [4 7 2 1 8 3 9 0 5 6]
 [3 4 7 1 8 5 9 6 0 2]
 [4 7 5 8 6 1 0 3 2 9]
 [3 4 0 9 5 8 2 6 1 7]
 [4 2 9 8 1 0 6 5 7 3]
 [0 6 2 5 7 3 9 8 1 4]
 [0 1 9 2 3 5 6 8 4 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 7 2 8 0 5 4 3 6 1]
 [3 5 4 1 9 2 6 0 8 7]
 [3 4 9 6 1 7 2 5 8 0]
 [5 1 4 0 8 9 2 6 3 7]
 [5 9 6 7 0 2 8 3 4 1]
 [0 5 4 6 8 9 3 7 2 1]
 [2 4 5 0 6 1 8 3 7 9]
 [4 3 0 6 5 2 9 7 1 8]
 [9 7 4 2 5 0 6 3 1 8]
 [0 3 9 1 5 4 7 2 6 8]]
Epoch 86710: Training cost= 2.3026, Training acc= 0.6401, Validation cost= 2.3026, Validation acc= 0.6397
Epoch 86720: Training cost= 2.3026, Training acc= 0.6400, Validation cost= 2.3026, Validation acc= 0.6396
Epoch 86730: Training cost= 2.3026, Training acc= 0.6399, Validation cost= 2.3026, Validation acc= 0.6396
Epoch 86740: Training cost= 2.3026, Training acc= 0.6399, Validation cost= 2.3026, Validation acc= 0.6395
Epoch 86750: Training cost= 2.3026, Training acc= 0.6398, Validation cost= 2.3026, Validation acc= 0.6395
Epoch 86760: Training cost= 2.3026, Training acc= 0.6398, Validation cost= 2.3026, Validation acc= 0.6394
Epoch 86770: Training cost= 2.3026, Training acc= 0.6397, Validation cost= 2.3026, Validation acc= 0.6393
Epoch 86780: Training cost= 2.3026, Training acc= 0.6396, Validation cost= 2.3026, Validation acc= 0.6393
Epoch 86790: Training cost= 2.3026, Training acc= 0.6396, Validation cost= 2.3026, Validation acc= 0.6392
Epoch 86800: Training cost= 2.3026, Training acc= 0.6395, Validation cost= 2.3026, Validation acc= 0.6391
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 2 7 0 8 5 9 1 4 3]
 [6 0 2 4 9 7 1 3 8 5]
 [7 1 8 5 4 0 9 6 2 3]
 [2 5 1 3 7 9 8 6 0 4]
 [4 3 2 7 9 8 6 5 1 0]
 [1 4 2 8 3 6 0 5 7 9]
 [9 3 0 5 7 4 6 1 2 8]
 [7 3 9 2 4 0 6 1 5 8]
 [2 0 4 5 8 7 9 1 3 6]
 [5 9 7 3 1 0 6 2 8 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 8 4 6 7 9 1 2 0 5]
 [6 9 3 5 7 4 8 2 0 1]
 [5 2 3 1 6 8 4 0 7 9]
 [7 1 0 3 4 5 9 8 6 2]
 [8 2 9 7 6 3 1 4 5 0]
 [4 9 5 2 7 0 6 8 1 3]
 [9 1 7 4 6 0 5 3 8 2]
 [6 5 2 0 4 8 1 7 3 9]
 [4 9 1 2 3 5 6 8 7 0]
 [8 4 5 9 1 2 0 7 6 3]]
Epoch 86810: Training cost= 2.3026, Training acc= 0.6394, Validation cost= 2.3026, Validation acc= 0.6391
Epoch 86820: Training cost= 2.3026, Training acc= 0.6394, Validation cost= 2.3026, Validation acc= 0.6390
Epoch 86830: Training cost= 2.3026, Training acc= 0.6393, Validation cost= 2.3026, Validation acc= 0.6390
Epoch 86840: Training cost= 2.3026, Training acc= 0.6393, Validation cost= 2.3026, Validation acc= 0.6389
Epoch 86850: Training cost= 2.3026, Training acc= 0.6392, Validation cost= 2.3026, Validation acc= 0.6388
Epoch 86860: Training cost= 2.3026, Training acc= 0.6391, Validation cost= 2.3026, Validation acc= 0.6388
Epoch 86870: Training cost= 2.3026, Training acc= 0.6391, Validation cost= 2.3026, Validation acc= 0.6387
Epoch 86880: Training cost= 2.3026, Training acc= 0.6390, Validation cost= 2.3026, Validation acc= 0.6386
Epoch 86890: Training cost= 2.3026, Training acc= 0.6390, Validation cost= 2.3026, Validation acc= 0.6386
Epoch 86900: Training cost= 2.3026, Training acc= 0.6389, Validation cost= 2.3026, Validation acc= 0.6385
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 5 7 1 8 0 4 6 2 9]
 [8 9 5 1 2 4 7 3 0 6]
 [0 9 1 3 5 4 7 8 6 2]
 [6 9 1 2 3 8 5 7 0 4]
 [0 4 9 3 7 8 2 6 5 1]
 [7 5 0 6 2 8 1 3 9 4]
 [3 9 6 8 1 2 0 7 5 4]
 [9 2 1 4 0 8 3 5 6 7]
 [4 7 9 3 1 8 6 0 5 2]
 [6 9 1 8 7 4 3 0 5 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 2 3 7 4 5 9 6 1 0]
 [0 9 5 8 7 6 1 4 2 3]
 [1 5 4 6 2 0 7 9 3 8]
 [6 4 2 1 8 7 3 9 0 5]
 [0 5 1 4 7 6 3 2 8 9]
 [2 7 6 1 8 3 0 5 9 4]
 [7 0 6 3 9 5 8 2 4 1]
 [0 3 7 2 4 5 1 9 8 6]
 [4 8 1 2 3 9 6 0 5 7]
 [2 9 8 4 7 5 1 0 6 3]]
Epoch 86910: Training cost= 2.3026, Training acc= 0.6388, Validation cost= 2.3026, Validation acc= 0.6385
Epoch 86920: Training cost= 2.3026, Training acc= 0.6388, Validation cost= 2.3026, Validation acc= 0.6384
Epoch 86930: Training cost= 2.3026, Training acc= 0.6387, Validation cost= 2.3026, Validation acc= 0.6383
Epoch 86940: Training cost= 2.3026, Training acc= 0.6386, Validation cost= 2.3026, Validation acc= 0.6383
Epoch 86950: Training cost= 2.3026, Training acc= 0.6386, Validation cost= 2.3026, Validation acc= 0.6382
Epoch 86960: Training cost= 2.3026, Training acc= 0.6385, Validation cost= 2.3026, Validation acc= 0.6382
Epoch 86970: Training cost= 2.3026, Training acc= 0.6385, Validation cost= 2.3026, Validation acc= 0.6381
Epoch 86980: Training cost= 2.3026, Training acc= 0.6384, Validation cost= 2.3026, Validation acc= 0.6380
Epoch 86990: Training cost= 2.3026, Training acc= 0.6383, Validation cost= 2.3026, Validation acc= 0.6380
Epoch 87000: Training cost= 2.3026, Training acc= 0.6383, Validation cost= 2.3026, Validation acc= 0.6379
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 6 0 4 7 5 9 2 8 3]
 [5 1 6 2 7 3 8 9 4 0]
 [3 9 5 6 8 1 0 4 7 2]
 [3 7 2 8 1 9 4 0 6 5]
 [5 7 4 2 8 3 9 6 1 0]
 [1 5 2 7 0 6 4 3 9 8]
 [8 5 0 4 9 1 6 3 2 7]
 [8 7 4 0 9 6 5 1 3 2]
 [2 8 7 3 1 0 9 4 5 6]
 [0 6 1 4 9 8 3 2 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 8 1 6 3 2 0 5 7 4]
 [5 9 6 4 3 0 1 7 8 2]
 [7 1 3 0 5 6 9 2 8 4]
 [1 6 2 0 7 4 8 5 3 9]
 [4 1 9 5 8 6 2 0 7 3]
 [9 2 6 4 5 0 1 7 3 8]
 [2 3 6 8 7 1 5 9 4 0]
 [4 9 0 7 1 5 2 8 6 3]
 [2 4 3 0 9 6 7 8 1 5]
 [1 5 2 0 8 4 7 6 9 3]]
Epoch 87010: Training cost= 2.3026, Training acc= 0.6382, Validation cost= 2.3026, Validation acc= 0.6378
Epoch 87020: Training cost= 2.3026, Training acc= 0.6381, Validation cost= 2.3026, Validation acc= 0.6378
Epoch 87030: Training cost= 2.3026, Training acc= 0.6381, Validation cost= 2.3026, Validation acc= 0.6377
Epoch 87040: Training cost= 2.3026, Training acc= 0.6380, Validation cost= 2.3026, Validation acc= 0.6377
Epoch 87050: Training cost= 2.3026, Training acc= 0.6380, Validation cost= 2.3026, Validation acc= 0.6376
Epoch 87060: Training cost= 2.3026, Training acc= 0.6379, Validation cost= 2.3026, Validation acc= 0.6375
Epoch 87070: Training cost= 2.3026, Training acc= 0.6378, Validation cost= 2.3026, Validation acc= 0.6375
Epoch 87080: Training cost= 2.3026, Training acc= 0.6378, Validation cost= 2.3026, Validation acc= 0.6374
Epoch 87090: Training cost= 2.3026, Training acc= 0.6377, Validation cost= 2.3026, Validation acc= 0.6373
Epoch 87100: Training cost= 2.3026, Training acc= 0.6377, Validation cost= 2.3026, Validation acc= 0.6373
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 4 7 2 1 3 5 8 0 9]
 [7 3 4 2 6 0 9 8 1 5]
 [9 3 5 4 1 0 2 6 7 8]
 [4 0 9 3 7 6 5 2 8 1]
 [0 3 7 1 5 9 6 4 2 8]
 [3 8 1 5 6 7 2 0 9 4]
 [7 5 9 1 3 8 6 4 2 0]
 [8 5 3 4 9 1 2 6 0 7]
 [4 0 5 3 2 7 6 9 8 1]
 [5 1 6 2 9 0 4 3 8 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 1 0 7 6 9 5 3 2 8]
 [0 9 8 6 5 1 7 4 2 3]
 [2 6 4 1 3 5 0 9 7 8]
 [7 2 9 5 0 6 1 8 3 4]
 [9 6 7 8 0 4 3 1 2 5]
 [4 9 8 2 0 7 3 5 6 1]
 [2 1 7 0 8 4 6 3 5 9]
 [1 9 8 5 6 2 4 3 7 0]
 [5 2 8 3 1 6 7 4 9 0]
 [1 3 6 0 5 2 7 9 4 8]]
Epoch 87110: Training cost= 2.3026, Training acc= 0.6376, Validation cost= 2.3026, Validation acc= 0.6372
Epoch 87120: Training cost= 2.3026, Training acc= 0.6375, Validation cost= 2.3026, Validation acc= 0.6372
Epoch 87130: Training cost= 2.3026, Training acc= 0.6375, Validation cost= 2.3026, Validation acc= 0.6371
Epoch 87140: Training cost= 2.3026, Training acc= 0.6374, Validation cost= 2.3026, Validation acc= 0.6370
Epoch 87150: Training cost= 2.3026, Training acc= 0.6373, Validation cost= 2.3026, Validation acc= 0.6370
Epoch 87160: Training cost= 2.3026, Training acc= 0.6373, Validation cost= 2.3026, Validation acc= 0.6369
Epoch 87170: Training cost= 2.3026, Training acc= 0.6372, Validation cost= 2.3026, Validation acc= 0.6369
Epoch 87180: Training cost= 2.3026, Training acc= 0.6372, Validation cost= 2.3026, Validation acc= 0.6368
Epoch 87190: Training cost= 2.3026, Training acc= 0.6371, Validation cost= 2.3026, Validation acc= 0.6367
Epoch 87200: Training cost= 2.3026, Training acc= 0.6370, Validation cost= 2.3026, Validation acc= 0.6367
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 3 2 6 4 7 9 0 8 5]
 [1 7 0 6 8 4 9 3 5 2]
 [0 5 8 7 4 1 6 2 3 9]
 [8 4 2 3 5 7 6 1 9 0]
 [5 3 2 9 4 8 0 1 6 7]
 [4 8 5 7 3 6 2 9 0 1]
 [6 3 1 8 4 2 5 9 0 7]
 [3 9 6 4 8 1 2 5 0 7]
 [6 0 2 1 7 9 3 5 8 4]
 [7 2 4 8 0 9 1 3 6 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 6 4 9 5 2 3 8 1 0]
 [6 9 3 0 2 4 7 5 8 1]
 [5 1 6 4 7 9 8 0 3 2]
 [0 1 2 7 3 6 4 5 8 9]
 [4 6 2 3 1 7 0 8 5 9]
 [4 7 1 9 5 2 8 6 0 3]
 [9 5 7 0 4 8 3 2 6 1]
 [2 3 9 1 4 7 5 6 8 0]
 [5 6 8 1 9 4 2 3 0 7]
 [6 9 1 3 2 4 5 8 0 7]]
Epoch 87210: Training cost= 2.3026, Training acc= 0.6370, Validation cost= 2.3026, Validation acc= 0.6366
Epoch 87220: Training cost= 2.3026, Training acc= 0.6369, Validation cost= 2.3026, Validation acc= 0.6365
Epoch 87230: Training cost= 2.3026, Training acc= 0.6369, Validation cost= 2.3026, Validation acc= 0.6365
Epoch 87240: Training cost= 2.3026, Training acc= 0.6368, Validation cost= 2.3026, Validation acc= 0.6364
Epoch 87250: Training cost= 2.3026, Training acc= 0.6367, Validation cost= 2.3026, Validation acc= 0.6364
Epoch 87260: Training cost= 2.3026, Training acc= 0.6367, Validation cost= 2.3026, Validation acc= 0.6363
Epoch 87270: Training cost= 2.3026, Training acc= 0.6366, Validation cost= 2.3026, Validation acc= 0.6362
Epoch 87280: Training cost= 2.3026, Training acc= 0.6365, Validation cost= 2.3026, Validation acc= 0.6362
Epoch 87290: Training cost= 2.3026, Training acc= 0.6365, Validation cost= 2.3026, Validation acc= 0.6361
Epoch 87300: Training cost= 2.3026, Training acc= 0.6364, Validation cost= 2.3026, Validation acc= 0.6361
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 1 8 7 6 5 3 2 0]
 [0 1 8 7 4 2 5 9 6 3]
 [6 8 0 3 7 5 4 2 1 9]
 [5 1 0 9 6 7 4 8 3 2]
 [8 4 3 9 6 5 7 2 0 1]
 [1 5 9 4 7 2 6 0 3 8]
 [7 3 9 5 4 8 6 1 0 2]
 [2 9 5 1 0 8 4 6 3 7]
 [0 1 4 7 5 3 6 9 2 8]
 [1 9 5 0 3 2 4 7 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 3 5 2 6 9 0 7 8 1]
 [1 7 6 3 0 2 5 8 9 4]
 [8 2 9 6 3 7 1 4 0 5]
 [3 7 1 0 6 8 9 5 2 4]
 [1 4 9 0 5 8 3 2 7 6]
 [5 2 4 9 7 6 8 3 1 0]
 [4 5 1 0 9 7 2 8 3 6]
 [4 8 7 1 0 2 3 9 6 5]
 [0 1 3 9 6 8 5 2 7 4]
 [9 8 0 1 4 3 7 5 6 2]]
Epoch 87310: Training cost= 2.3026, Training acc= 0.6364, Validation cost= 2.3026, Validation acc= 0.6360
Epoch 87320: Training cost= 2.3026, Training acc= 0.6363, Validation cost= 2.3026, Validation acc= 0.6359
Epoch 87330: Training cost= 2.3026, Training acc= 0.6362, Validation cost= 2.3026, Validation acc= 0.6359
Epoch 87340: Training cost= 2.3026, Training acc= 0.6362, Validation cost= 2.3026, Validation acc= 0.6358
Epoch 87350: Training cost= 2.3026, Training acc= 0.6361, Validation cost= 2.3026, Validation acc= 0.6357
Epoch 87360: Training cost= 2.3026, Training acc= 0.6361, Validation cost= 2.3026, Validation acc= 0.6357
Epoch 87370: Training cost= 2.3026, Training acc= 0.6360, Validation cost= 2.3026, Validation acc= 0.6356
Epoch 87380: Training cost= 2.3026, Training acc= 0.6359, Validation cost= 2.3026, Validation acc= 0.6356
Epoch 87390: Training cost= 2.3026, Training acc= 0.6359, Validation cost= 2.3026, Validation acc= 0.6355
Epoch 87400: Training cost= 2.3026, Training acc= 0.6358, Validation cost= 2.3026, Validation acc= 0.6354
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 1 8 0 6 7 3 4 2 9]
 [5 1 9 2 6 3 0 4 7 8]
 [7 1 4 2 8 0 6 5 9 3]
 [2 6 5 7 8 1 3 4 9 0]
 [4 0 2 1 5 7 9 6 8 3]
 [3 7 4 9 2 1 5 8 0 6]
 [1 9 6 4 8 0 2 3 7 5]
 [8 2 0 1 7 4 9 6 5 3]
 [1 6 5 7 8 4 2 0 9 3]
 [8 5 0 7 6 2 9 4 3 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 0 5 8 7 3 2 6 4 1]
 [2 4 5 1 9 7 0 3 8 6]
 [1 9 0 7 2 6 4 5 3 8]
 [4 6 3 8 1 2 0 9 5 7]
 [2 7 9 8 0 3 5 1 6 4]
 [6 3 0 8 9 1 4 7 2 5]
 [3 1 2 6 5 4 7 8 9 0]
 [9 7 6 2 1 4 5 0 3 8]
 [9 2 5 1 6 7 8 4 0 3]
 [9 0 1 4 6 8 2 3 5 7]]
Epoch 87410: Training cost= 2.3026, Training acc= 0.6357, Validation cost= 2.3026, Validation acc= 0.6354
Epoch 87420: Training cost= 2.3026, Training acc= 0.6357, Validation cost= 2.3026, Validation acc= 0.6353
Epoch 87430: Training cost= 2.3026, Training acc= 0.6356, Validation cost= 2.3026, Validation acc= 0.6353
Epoch 87440: Training cost= 2.3026, Training acc= 0.6356, Validation cost= 2.3026, Validation acc= 0.6352
Epoch 87450: Training cost= 2.3026, Training acc= 0.6355, Validation cost= 2.3026, Validation acc= 0.6351
Epoch 87460: Training cost= 2.3026, Training acc= 0.6354, Validation cost= 2.3026, Validation acc= 0.6351
Epoch 87470: Training cost= 2.3026, Training acc= 0.6354, Validation cost= 2.3026, Validation acc= 0.6350
Epoch 87480: Training cost= 2.3026, Training acc= 0.6353, Validation cost= 2.3026, Validation acc= 0.6350
Epoch 87490: Training cost= 2.3026, Training acc= 0.6353, Validation cost= 2.3026, Validation acc= 0.6349
Epoch 87500: Training cost= 2.3026, Training acc= 0.6352, Validation cost= 2.3026, Validation acc= 0.6348
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[3 5 7 8 2 9 1 0 6 4]
 [6 8 4 1 2 0 5 3 9 7]
 [2 9 8 6 5 4 1 0 7 3]
 [6 9 4 3 8 0 1 2 5 7]
 [8 4 7 2 3 0 5 9 6 1]
 [2 1 8 3 6 7 5 9 4 0]
 [3 0 4 7 9 1 5 6 8 2]
 [0 3 4 5 1 9 6 2 7 8]
 [7 3 9 5 0 2 4 1 6 8]
 [4 3 1 2 8 5 9 7 6 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 2 6 8 0 1 4 7 9 3]
 [6 1 3 8 0 7 9 5 2 4]
 [3 0 7 4 6 9 2 1 8 5]
 [0 3 5 9 2 4 8 6 7 1]
 [7 9 8 4 3 1 6 5 0 2]
 [4 2 0 6 5 8 7 9 3 1]
 [6 3 9 7 2 0 5 1 4 8]
 [2 6 9 0 7 8 5 3 1 4]
 [7 4 0 3 5 9 1 6 8 2]
 [9 5 7 8 1 4 0 6 3 2]]
Epoch 87510: Training cost= 2.3026, Training acc= 0.6351, Validation cost= 2.3026, Validation acc= 0.6348
Epoch 87520: Training cost= 2.3026, Training acc= 0.6351, Validation cost= 2.3026, Validation acc= 0.6347
Epoch 87530: Training cost= 2.3026, Training acc= 0.6350, Validation cost= 2.3026, Validation acc= 0.6346
Epoch 87540: Training cost= 2.3026, Training acc= 0.6350, Validation cost= 2.3026, Validation acc= 0.6346
Epoch 87550: Training cost= 2.3026, Training acc= 0.6349, Validation cost= 2.3026, Validation acc= 0.6345
Epoch 87560: Training cost= 2.3026, Training acc= 0.6348, Validation cost= 2.3026, Validation acc= 0.6345
Epoch 87570: Training cost= 2.3026, Training acc= 0.6348, Validation cost= 2.3026, Validation acc= 0.6344
Epoch 87580: Training cost= 2.3026, Training acc= 0.6347, Validation cost= 2.3026, Validation acc= 0.6343
Epoch 87590: Training cost= 2.3026, Training acc= 0.6346, Validation cost= 2.3026, Validation acc= 0.6343
Epoch 87600: Training cost= 2.3026, Training acc= 0.6346, Validation cost= 2.3026, Validation acc= 0.6342
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 0 4 1 6 2 7 8 5 3]
 [8 0 1 3 2 4 6 9 7 5]
 [1 5 6 4 0 9 3 2 7 8]
 [7 2 8 4 9 6 1 0 5 3]
 [1 8 7 9 6 0 3 4 2 5]
 [6 1 5 8 4 0 7 2 3 9]
 [2 7 5 8 0 1 9 4 6 3]
 [2 3 8 7 5 6 1 4 0 9]
 [1 4 7 3 5 0 8 9 2 6]
 [5 2 7 9 4 1 0 6 8 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 2 1 4 6 9 5 0 7 3]
 [1 5 7 2 9 0 3 6 4 8]
 [7 1 0 5 9 3 6 2 4 8]
 [1 9 7 3 6 0 8 2 4 5]
 [7 3 0 6 4 9 5 8 1 2]
 [4 0 1 5 3 2 6 8 9 7]
 [3 5 8 1 9 6 2 7 0 4]
 [9 0 3 8 5 4 6 7 2 1]
 [0 9 1 5 7 4 2 3 8 6]
 [3 6 5 7 8 4 9 0 1 2]]
Epoch 87610: Training cost= 2.3026, Training acc= 0.6345, Validation cost= 2.3026, Validation acc= 0.6342
Epoch 87620: Training cost= 2.3026, Training acc= 0.6345, Validation cost= 2.3026, Validation acc= 0.6341
Epoch 87630: Training cost= 2.3026, Training acc= 0.6344, Validation cost= 2.3026, Validation acc= 0.6340
Epoch 87640: Training cost= 2.3026, Training acc= 0.6343, Validation cost= 2.3026, Validation acc= 0.6340
Epoch 87650: Training cost= 2.3026, Training acc= 0.6343, Validation cost= 2.3026, Validation acc= 0.6339
Epoch 87660: Training cost= 2.3026, Training acc= 0.6342, Validation cost= 2.3026, Validation acc= 0.6339
Epoch 87670: Training cost= 2.3026, Training acc= 0.6342, Validation cost= 2.3026, Validation acc= 0.6338
Epoch 87680: Training cost= 2.3026, Training acc= 0.6341, Validation cost= 2.3026, Validation acc= 0.6337
Epoch 87690: Training cost= 2.3026, Training acc= 0.6340, Validation cost= 2.3026, Validation acc= 0.6337
Epoch 87700: Training cost= 2.3026, Training acc= 0.6340, Validation cost= 2.3026, Validation acc= 0.6336
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 8 5 7 3 6 9 0 4 1]
 [4 0 1 3 6 7 2 8 9 5]
 [8 2 3 7 4 9 1 0 5 6]
 [4 9 7 3 5 1 6 0 2 8]
 [0 4 5 9 1 2 8 3 6 7]
 [4 7 2 6 3 5 0 1 9 8]
 [2 9 4 1 8 6 7 3 5 0]
 [7 6 4 5 3 1 0 8 9 2]
 [6 0 2 7 9 1 3 5 4 8]
 [4 5 8 9 1 7 6 2 0 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 2 3 6 8 5 4 7 1 0]
 [1 6 4 3 7 0 8 5 9 2]
 [5 0 6 9 8 2 7 1 4 3]
 [6 2 8 5 7 1 3 0 9 4]
 [4 5 7 9 1 6 3 8 0 2]
 [5 1 4 7 3 2 0 8 6 9]
 [5 9 0 3 8 4 1 7 2 6]
 [2 3 0 5 8 9 4 1 6 7]
 [3 4 0 8 2 9 1 7 6 5]
 [0 3 2 1 5 7 9 8 4 6]]
Epoch 87710: Training cost= 2.3026, Training acc= 0.6339, Validation cost= 2.3026, Validation acc= 0.6335
Epoch 87720: Training cost= 2.3026, Training acc= 0.6339, Validation cost= 2.3026, Validation acc= 0.6335
Epoch 87730: Training cost= 2.3026, Training acc= 0.6338, Validation cost= 2.3026, Validation acc= 0.6334
Epoch 87740: Training cost= 2.3026, Training acc= 0.6337, Validation cost= 2.3026, Validation acc= 0.6334
Epoch 87750: Training cost= 2.3026, Training acc= 0.6337, Validation cost= 2.3026, Validation acc= 0.6333
Epoch 87760: Training cost= 2.3026, Training acc= 0.6336, Validation cost= 2.3026, Validation acc= 0.6332
Epoch 87770: Training cost= 2.3026, Training acc= 0.6335, Validation cost= 2.3026, Validation acc= 0.6332
Epoch 87780: Training cost= 2.3026, Training acc= 0.6335, Validation cost= 2.3026, Validation acc= 0.6331
Epoch 87790: Training cost= 2.3026, Training acc= 0.6334, Validation cost= 2.3026, Validation acc= 0.6331
Epoch 87800: Training cost= 2.3026, Training acc= 0.6334, Validation cost= 2.3026, Validation acc= 0.6330
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 0 5 4 1 6 3 8 9 7]
 [5 6 9 4 1 0 3 2 7 8]
 [2 6 9 0 7 3 1 4 5 8]
 [4 5 0 7 8 3 6 9 2 1]
 [0 4 1 7 9 5 6 2 3 8]
 [6 9 0 7 8 4 1 2 5 3]
 [0 9 5 8 7 4 1 3 6 2]
 [0 9 7 6 5 8 3 4 1 2]
 [1 9 6 3 2 0 8 5 7 4]
 [1 9 0 5 8 7 6 2 4 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 6 0 8 1 5 3 9 4 7]
 [2 0 5 9 6 1 8 3 7 4]
 [6 1 9 8 7 3 5 0 2 4]
 [1 8 3 9 4 2 6 5 7 0]
 [3 4 0 7 8 2 6 1 5 9]
 [2 5 6 4 9 0 8 3 1 7]
 [1 2 8 5 0 4 9 3 6 7]
 [9 3 5 6 7 2 8 1 4 0]
 [1 5 8 2 9 6 3 4 0 7]
 [8 5 6 3 1 9 7 0 2 4]]
Epoch 87810: Training cost= 2.3026, Training acc= 0.6333, Validation cost= 2.3026, Validation acc= 0.6329
Epoch 87820: Training cost= 2.3026, Training acc= 0.6332, Validation cost= 2.3026, Validation acc= 0.6329
Epoch 87830: Training cost= 2.3026, Training acc= 0.6332, Validation cost= 2.3026, Validation acc= 0.6328
Epoch 87840: Training cost= 2.3026, Training acc= 0.6331, Validation cost= 2.3026, Validation acc= 0.6328
Epoch 87850: Training cost= 2.3026, Training acc= 0.6331, Validation cost= 2.3026, Validation acc= 0.6327
Epoch 87860: Training cost= 2.3026, Training acc= 0.6330, Validation cost= 2.3026, Validation acc= 0.6326
Epoch 87870: Training cost= 2.3026, Training acc= 0.6329, Validation cost= 2.3026, Validation acc= 0.6326
Epoch 87880: Training cost= 2.3026, Training acc= 0.6329, Validation cost= 2.3026, Validation acc= 0.6325
Epoch 87890: Training cost= 2.3026, Training acc= 0.6328, Validation cost= 2.3026, Validation acc= 0.6325
Epoch 87900: Training cost= 2.3026, Training acc= 0.6328, Validation cost= 2.3026, Validation acc= 0.6324
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 1 2 3 8 4 6 5 9 0]
 [7 6 3 0 8 4 9 5 1 2]
 [0 5 1 9 3 2 8 4 6 7]
 [2 5 0 8 1 7 4 6 9 3]
 [7 3 6 2 0 4 1 5 8 9]
 [3 8 1 6 7 5 0 9 2 4]
 [7 4 8 1 0 3 6 5 2 9]
 [8 0 3 1 6 2 9 4 7 5]
 [0 8 6 2 7 3 1 4 9 5]
 [1 2 8 7 0 9 4 6 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 8 6 5 9 2 0 1 4 3]
 [9 3 4 2 5 8 0 6 1 7]
 [1 0 2 7 4 5 8 6 3 9]
 [7 6 1 2 8 3 5 9 0 4]
 [5 1 6 4 7 3 8 0 2 9]
 [3 9 0 7 8 6 2 1 5 4]
 [3 6 5 4 1 9 7 8 2 0]
 [2 3 8 5 0 9 6 1 7 4]
 [4 5 9 0 3 8 7 1 6 2]
 [2 6 5 4 0 3 8 7 9 1]]
Epoch 87910: Training cost= 2.3026, Training acc= 0.6327, Validation cost= 2.3026, Validation acc= 0.6323
Epoch 87920: Training cost= 2.3026, Training acc= 0.6326, Validation cost= 2.3026, Validation acc= 0.6323
Epoch 87930: Training cost= 2.3026, Training acc= 0.6326, Validation cost= 2.3026, Validation acc= 0.6322
Epoch 87940: Training cost= 2.3026, Training acc= 0.6325, Validation cost= 2.3026, Validation acc= 0.6322
Epoch 87950: Training cost= 2.3026, Training acc= 0.6325, Validation cost= 2.3026, Validation acc= 0.6321
Epoch 87960: Training cost= 2.3026, Training acc= 0.6324, Validation cost= 2.3026, Validation acc= 0.6320
Epoch 87970: Training cost= 2.3026, Training acc= 0.6323, Validation cost= 2.3026, Validation acc= 0.6320
Epoch 87980: Training cost= 2.3026, Training acc= 0.6323, Validation cost= 2.3026, Validation acc= 0.6319
Epoch 87990: Training cost= 2.3026, Training acc= 0.6322, Validation cost= 2.3026, Validation acc= 0.6319
Epoch 88000: Training cost= 2.3026, Training acc= 0.6322, Validation cost= 2.3026, Validation acc= 0.6318
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 4 3 0 2 6 9 1 8 7]
 [2 8 1 7 3 0 5 6 4 9]
 [2 9 4 6 3 1 7 0 8 5]
 [5 3 9 7 0 4 2 6 8 1]
 [8 2 3 6 7 0 5 1 4 9]
 [5 3 9 2 8 6 4 7 0 1]
 [3 2 6 0 7 1 4 5 8 9]
 [3 1 6 8 9 2 4 5 7 0]
 [7 8 3 6 4 1 2 0 9 5]
 [3 1 0 7 5 9 8 6 2 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 1 8 2 6 7 9 5 4 0]
 [7 3 5 8 0 2 1 9 4 6]
 [9 0 6 5 8 2 7 4 1 3]
 [5 3 9 6 7 2 1 0 4 8]
 [7 8 5 4 6 3 1 9 2 0]
 [9 7 5 4 3 8 0 6 2 1]
 [3 8 1 6 2 0 9 7 5 4]
 [9 4 3 0 1 2 5 7 8 6]
 [6 1 5 8 7 3 2 9 4 0]
 [4 3 7 8 6 1 2 0 9 5]]
Epoch 88010: Training cost= 2.3026, Training acc= 0.6321, Validation cost= 2.3026, Validation acc= 0.6317
Epoch 88020: Training cost= 2.3026, Training acc= 0.6320, Validation cost= 2.3026, Validation acc= 0.6317
Epoch 88030: Training cost= 2.3026, Training acc= 0.6320, Validation cost= 2.3026, Validation acc= 0.6316
Epoch 88040: Training cost= 2.3026, Training acc= 0.6319, Validation cost= 2.3026, Validation acc= 0.6316
Epoch 88050: Training cost= 2.3026, Training acc= 0.6319, Validation cost= 2.3026, Validation acc= 0.6315
Epoch 88060: Training cost= 2.3026, Training acc= 0.6318, Validation cost= 2.3026, Validation acc= 0.6314
Epoch 88070: Training cost= 2.3026, Training acc= 0.6317, Validation cost= 2.3026, Validation acc= 0.6314
Epoch 88080: Training cost= 2.3026, Training acc= 0.6317, Validation cost= 2.3026, Validation acc= 0.6313
Epoch 88090: Training cost= 2.3026, Training acc= 0.6316, Validation cost= 2.3026, Validation acc= 0.6312
Epoch 88100: Training cost= 2.3026, Training acc= 0.6315, Validation cost= 2.3026, Validation acc= 0.6312
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 5 1 4 2 3 7 9 6 0]
 [8 1 2 4 6 0 7 5 9 3]
 [5 9 3 6 2 4 1 7 0 8]
 [1 3 2 9 5 8 7 6 0 4]
 [2 6 1 8 5 0 7 9 4 3]
 [4 2 7 3 6 1 0 9 8 5]
 [5 8 6 7 4 3 2 9 0 1]
 [0 7 8 1 3 4 5 9 6 2]
 [7 9 3 8 4 0 6 1 5 2]
 [0 5 3 1 6 4 9 8 2 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 3 1 5 0 7 8 9 6 2]
 [0 6 2 8 1 9 4 3 5 7]
 [7 1 3 8 4 6 9 5 2 0]
 [6 5 2 9 8 1 0 4 3 7]
 [2 9 5 4 1 0 8 7 6 3]
 [9 0 3 8 2 6 4 1 5 7]
 [8 7 3 6 1 5 4 2 0 9]
 [3 0 8 7 1 2 5 6 4 9]
 [0 3 2 4 7 6 8 1 9 5]
 [1 6 3 0 5 2 9 4 8 7]]
Epoch 88110: Training cost= 2.3026, Training acc= 0.6315, Validation cost= 2.3026, Validation acc= 0.6311
Epoch 88120: Training cost= 2.3026, Training acc= 0.6314, Validation cost= 2.3026, Validation acc= 0.6311
Epoch 88130: Training cost= 2.3026, Training acc= 0.6314, Validation cost= 2.3026, Validation acc= 0.6310
Epoch 88140: Training cost= 2.3026, Training acc= 0.6313, Validation cost= 2.3026, Validation acc= 0.6309
Epoch 88150: Training cost= 2.3026, Training acc= 0.6312, Validation cost= 2.3026, Validation acc= 0.6309
Epoch 88160: Training cost= 2.3026, Training acc= 0.6312, Validation cost= 2.3026, Validation acc= 0.6308
Epoch 88170: Training cost= 2.3026, Training acc= 0.6311, Validation cost= 2.3026, Validation acc= 0.6308
Epoch 88180: Training cost= 2.3026, Training acc= 0.6311, Validation cost= 2.3026, Validation acc= 0.6307
Epoch 88190: Training cost= 2.3026, Training acc= 0.6310, Validation cost= 2.3026, Validation acc= 0.6306
Epoch 88200: Training cost= 2.3026, Training acc= 0.6309, Validation cost= 2.3026, Validation acc= 0.6306
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 6 4 2 7 1 0 5 8 3]
 [0 9 1 3 5 2 7 6 8 4]
 [6 1 8 0 9 2 4 7 5 3]
 [1 6 2 3 5 0 7 4 8 9]
 [8 0 7 4 1 3 2 5 6 9]
 [7 9 5 3 2 6 1 4 8 0]
 [0 6 8 5 1 4 9 7 2 3]
 [3 4 0 6 7 1 9 8 5 2]
 [2 8 0 7 1 5 9 3 6 4]
 [1 3 8 7 4 9 0 5 6 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 6 3 0 9 2 1 5 8 7]
 [5 6 3 0 4 9 2 1 8 7]
 [6 2 5 1 4 7 0 8 9 3]
 [8 1 3 7 4 5 6 2 0 9]
 [5 9 4 1 3 6 7 0 2 8]
 [3 8 0 6 9 1 5 4 2 7]
 [6 0 9 1 5 7 3 4 2 8]
 [9 3 7 5 1 4 6 0 2 8]
 [1 6 2 8 7 0 9 4 5 3]
 [7 1 0 8 3 4 6 5 2 9]]
Epoch 88210: Training cost= 2.3026, Training acc= 0.6309, Validation cost= 2.3026, Validation acc= 0.6305
Epoch 88220: Training cost= 2.3026, Training acc= 0.6308, Validation cost= 2.3026, Validation acc= 0.6305
Epoch 88230: Training cost= 2.3026, Training acc= 0.6308, Validation cost= 2.3026, Validation acc= 0.6304
Epoch 88240: Training cost= 2.3026, Training acc= 0.6307, Validation cost= 2.3026, Validation acc= 0.6303
Epoch 88250: Training cost= 2.3026, Training acc= 0.6306, Validation cost= 2.3026, Validation acc= 0.6303
Epoch 88260: Training cost= 2.3026, Training acc= 0.6306, Validation cost= 2.3026, Validation acc= 0.6302
Epoch 88270: Training cost= 2.3026, Training acc= 0.6305, Validation cost= 2.3026, Validation acc= 0.6302
Epoch 88280: Training cost= 2.3026, Training acc= 0.6305, Validation cost= 2.3026, Validation acc= 0.6301
Epoch 88290: Training cost= 2.3026, Training acc= 0.6304, Validation cost= 2.3026, Validation acc= 0.6300
Epoch 88300: Training cost= 2.3026, Training acc= 0.6303, Validation cost= 2.3026, Validation acc= 0.6300
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 5 6 8 0 9 1 7 4 3]
 [0 2 7 5 8 3 1 9 4 6]
 [0 9 4 5 2 7 3 1 6 8]
 [4 8 7 9 0 5 2 3 6 1]
 [8 1 2 3 5 6 0 9 4 7]
 [9 6 3 4 7 5 2 0 1 8]
 [0 1 6 5 9 7 2 8 4 3]
 [0 5 8 9 6 4 1 2 3 7]
 [8 9 1 5 0 4 3 7 6 2]
 [9 8 6 4 2 0 7 1 3 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 4 1 8 0 6 2 9 3 7]
 [3 4 9 7 5 1 2 8 6 0]
 [0 8 3 4 9 1 2 5 7 6]
 [9 3 6 5 2 7 8 4 0 1]
 [9 1 7 2 0 3 8 4 6 5]
 [2 0 5 6 4 7 3 9 8 1]
 [5 8 1 2 4 0 9 3 6 7]
 [3 1 4 0 2 7 8 5 9 6]
 [9 3 2 6 8 4 7 1 0 5]
 [7 1 6 4 8 9 5 2 3 0]]
Epoch 88310: Training cost= 2.3026, Training acc= 0.6303, Validation cost= 2.3026, Validation acc= 0.6299
Epoch 88320: Training cost= 2.3026, Training acc= 0.6302, Validation cost= 2.3026, Validation acc= 0.6299
Epoch 88330: Training cost= 2.3026, Training acc= 0.6302, Validation cost= 2.3026, Validation acc= 0.6298
Epoch 88340: Training cost= 2.3026, Training acc= 0.6301, Validation cost= 2.3026, Validation acc= 0.6297
Epoch 88350: Training cost= 2.3026, Training acc= 0.6300, Validation cost= 2.3026, Validation acc= 0.6297
Epoch 88360: Training cost= 2.3026, Training acc= 0.6300, Validation cost= 2.3026, Validation acc= 0.6296
Epoch 88370: Training cost= 2.3026, Training acc= 0.6299, Validation cost= 2.3026, Validation acc= 0.6296
Epoch 88380: Training cost= 2.3026, Training acc= 0.6299, Validation cost= 2.3026, Validation acc= 0.6295
Epoch 88390: Training cost= 2.3026, Training acc= 0.6298, Validation cost= 2.3026, Validation acc= 0.6294
Epoch 88400: Training cost= 2.3026, Training acc= 0.6297, Validation cost= 2.3026, Validation acc= 0.6294
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 7 2 5 6 3 0 1 4 8]
 [2 5 1 4 9 6 3 0 8 7]
 [3 4 7 6 0 1 8 5 2 9]
 [4 8 3 9 2 6 1 7 0 5]
 [8 2 7 6 0 3 5 1 9 4]
 [8 4 0 2 5 1 9 7 6 3]
 [5 2 9 0 7 8 3 6 4 1]
 [5 7 3 8 9 6 1 4 2 0]
 [5 4 8 6 1 7 3 2 9 0]
 [5 3 0 4 9 2 7 1 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 9 3 2 1 8 7 5 6 4]
 [4 9 2 8 6 1 3 0 7 5]
 [2 3 8 5 4 7 6 0 1 9]
 [6 5 0 9 3 1 4 2 7 8]
 [2 1 6 3 9 8 0 5 4 7]
 [0 3 6 7 5 8 4 1 9 2]
 [0 5 3 9 7 1 8 4 6 2]
 [7 4 8 5 6 3 2 0 1 9]
 [9 2 6 0 3 7 1 4 5 8]
 [3 2 6 4 1 9 7 8 0 5]]
Epoch 88410: Training cost= 2.3026, Training acc= 0.6297, Validation cost= 2.3026, Validation acc= 0.6293
Epoch 88420: Training cost= 2.3026, Training acc= 0.6296, Validation cost= 2.3026, Validation acc= 0.6293
Epoch 88430: Training cost= 2.3026, Training acc= 0.6296, Validation cost= 2.3026, Validation acc= 0.6292
Epoch 88440: Training cost= 2.3026, Training acc= 0.6295, Validation cost= 2.3026, Validation acc= 0.6291
Epoch 88450: Training cost= 2.3026, Training acc= 0.6294, Validation cost= 2.3026, Validation acc= 0.6291
Epoch 88460: Training cost= 2.3026, Training acc= 0.6294, Validation cost= 2.3026, Validation acc= 0.6290
Epoch 88470: Training cost= 2.3026, Training acc= 0.6293, Validation cost= 2.3026, Validation acc= 0.6290
Epoch 88480: Training cost= 2.3026, Training acc= 0.6293, Validation cost= 2.3026, Validation acc= 0.6289
Epoch 88490: Training cost= 2.3026, Training acc= 0.6292, Validation cost= 2.3026, Validation acc= 0.6288
Epoch 88500: Training cost= 2.3026, Training acc= 0.6291, Validation cost= 2.3026, Validation acc= 0.6288
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 8 6 4 9 3 5 1 2 0]
 [9 4 7 6 8 3 1 0 5 2]
 [6 5 2 7 9 0 1 4 3 8]
 [3 6 0 8 7 1 9 4 5 2]
 [0 5 9 8 2 1 3 4 6 7]
 [0 6 8 9 2 1 3 4 5 7]
 [3 4 2 8 7 9 6 0 5 1]
 [5 3 0 6 2 8 4 1 7 9]
 [0 7 9 3 8 1 4 6 5 2]
 [4 1 6 3 7 8 9 2 5 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[5 4 7 3 1 8 6 9 0 2]
 [2 0 1 9 4 5 7 6 8 3]
 [5 3 7 1 8 4 2 0 6 9]
 [8 9 7 5 6 0 2 1 3 4]
 [3 4 9 2 7 0 5 6 1 8]
 [1 5 8 6 0 3 7 4 9 2]
 [7 5 2 0 8 9 1 6 3 4]
 [7 2 9 6 8 0 1 4 3 5]
 [1 3 2 9 6 5 4 0 7 8]
 [8 2 4 1 5 9 0 6 3 7]]
Epoch 88510: Training cost= 2.3026, Training acc= 0.6291, Validation cost= 2.3026, Validation acc= 0.6287
Epoch 88520: Training cost= 2.3026, Training acc= 0.6290, Validation cost= 2.3026, Validation acc= 0.6287
Epoch 88530: Training cost= 2.3026, Training acc= 0.6290, Validation cost= 2.3026, Validation acc= 0.6286
Epoch 88540: Training cost= 2.3026, Training acc= 0.6289, Validation cost= 2.3026, Validation acc= 0.6285
Epoch 88550: Training cost= 2.3026, Training acc= 0.6288, Validation cost= 2.3026, Validation acc= 0.6285
Epoch 88560: Training cost= 2.3026, Training acc= 0.6288, Validation cost= 2.3026, Validation acc= 0.6284
Epoch 88570: Training cost= 2.3026, Training acc= 0.6287, Validation cost= 2.3026, Validation acc= 0.6284
Epoch 88580: Training cost= 2.3026, Training acc= 0.6287, Validation cost= 2.3026, Validation acc= 0.6283
Epoch 88590: Training cost= 2.3026, Training acc= 0.6286, Validation cost= 2.3026, Validation acc= 0.6283
Epoch 88600: Training cost= 2.3026, Training acc= 0.6285, Validation cost= 2.3026, Validation acc= 0.6282
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 6 3 8 4 2 0 9 1 5]
 [4 5 7 1 2 3 8 6 9 0]
 [4 0 3 7 2 9 6 1 5 8]
 [8 6 4 1 0 2 5 9 3 7]
 [7 1 6 5 2 4 3 8 0 9]
 [8 1 2 4 6 7 9 0 3 5]
 [9 1 7 8 4 2 6 3 5 0]
 [8 4 1 9 2 7 5 3 6 0]
 [2 1 9 3 6 4 5 7 8 0]
 [0 4 6 2 7 3 8 9 1 5]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 3 9 4 1 7 8 5 6 2]
 [2 8 0 7 4 1 6 5 3 9]
 [2 6 3 8 7 1 0 5 9 4]
 [0 3 9 8 6 4 2 5 7 1]
 [6 2 3 0 4 1 5 7 9 8]
 [0 1 2 7 3 8 5 9 6 4]
 [2 1 0 6 5 4 9 8 3 7]
 [2 9 8 4 1 7 6 3 5 0]
 [3 1 6 2 8 7 9 0 4 5]
 [4 7 1 5 3 9 8 0 2 6]]
Epoch 88610: Training cost= 2.3026, Training acc= 0.6285, Validation cost= 2.3026, Validation acc= 0.6281
Epoch 88620: Training cost= 2.3026, Training acc= 0.6284, Validation cost= 2.3026, Validation acc= 0.6281
Epoch 88630: Training cost= 2.3026, Training acc= 0.6284, Validation cost= 2.3026, Validation acc= 0.6280
Epoch 88640: Training cost= 2.3026, Training acc= 0.6283, Validation cost= 2.3026, Validation acc= 0.6280
Epoch 88650: Training cost= 2.3026, Training acc= 0.6283, Validation cost= 2.3026, Validation acc= 0.6279
Epoch 88660: Training cost= 2.3026, Training acc= 0.6282, Validation cost= 2.3026, Validation acc= 0.6278
Epoch 88670: Training cost= 2.3026, Training acc= 0.6281, Validation cost= 2.3026, Validation acc= 0.6278
Epoch 88680: Training cost= 2.3026, Training acc= 0.6281, Validation cost= 2.3026, Validation acc= 0.6277
Epoch 88690: Training cost= 2.3026, Training acc= 0.6280, Validation cost= 2.3026, Validation acc= 0.6277
Epoch 88700: Training cost= 2.3026, Training acc= 0.6280, Validation cost= 2.3026, Validation acc= 0.6276
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 1 9 4 7 6 5 0 3 8]
 [1 7 6 0 5 4 3 8 2 9]
 [7 8 9 0 2 5 4 3 6 1]
 [6 2 3 5 4 0 9 8 1 7]
 [5 7 9 0 3 2 1 6 4 8]
 [7 9 3 5 4 1 2 6 0 8]
 [3 1 7 8 0 4 2 5 9 6]
 [9 3 7 0 5 6 1 8 2 4]
 [6 9 4 3 8 1 2 0 7 5]
 [7 4 1 0 9 5 3 2 8 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 3 7 4 2 8 5 1 9 6]
 [9 8 0 3 7 2 1 4 5 6]
 [8 5 2 3 9 1 6 0 4 7]
 [8 7 2 3 4 1 5 0 6 9]
 [8 5 9 1 3 4 6 2 0 7]
 [7 5 2 9 4 8 6 3 1 0]
 [2 4 9 1 0 7 8 5 6 3]
 [4 0 8 1 3 6 9 7 5 2]
 [0 3 7 1 2 4 5 9 6 8]
 [2 9 3 6 5 8 7 1 0 4]]
Epoch 88710: Training cost= 2.3026, Training acc= 0.6279, Validation cost= 2.3026, Validation acc= 0.6275
Epoch 88720: Training cost= 2.3026, Training acc= 0.6278, Validation cost= 2.3026, Validation acc= 0.6275
Epoch 88730: Training cost= 2.3026, Training acc= 0.6278, Validation cost= 2.3026, Validation acc= 0.6274
Epoch 88740: Training cost= 2.3026, Training acc= 0.6277, Validation cost= 2.3026, Validation acc= 0.6274
Epoch 88750: Training cost= 2.3026, Training acc= 0.6277, Validation cost= 2.3026, Validation acc= 0.6273
Epoch 88760: Training cost= 2.3026, Training acc= 0.6276, Validation cost= 2.3026, Validation acc= 0.6272
Epoch 88770: Training cost= 2.3026, Training acc= 0.6275, Validation cost= 2.3026, Validation acc= 0.6272
Epoch 88780: Training cost= 2.3026, Training acc= 0.6275, Validation cost= 2.3026, Validation acc= 0.6271
Epoch 88790: Training cost= 2.3026, Training acc= 0.6274, Validation cost= 2.3026, Validation acc= 0.6271
Epoch 88800: Training cost= 2.3026, Training acc= 0.6274, Validation cost= 2.3026, Validation acc= 0.6270
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 0 3 5 4 8 9 6 7 1]
 [9 3 8 5 6 7 0 2 1 4]
 [9 8 4 7 5 6 2 3 1 0]
 [5 9 8 0 7 4 3 6 1 2]
 [1 2 3 7 9 6 0 4 8 5]
 [1 4 9 3 7 5 6 8 0 2]
 [7 0 4 6 1 8 5 9 3 2]
 [5 3 9 0 2 7 8 1 6 4]
 [0 9 3 5 6 2 4 7 1 8]
 [5 8 3 1 4 9 2 7 0 6]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 9 5 2 6 7 0 1 8 4]
 [9 7 6 1 0 3 8 2 4 5]
 [9 5 6 7 2 1 4 3 0 8]
 [3 7 5 1 4 6 8 0 9 2]
 [1 3 0 2 4 5 9 8 6 7]
 [8 2 6 1 7 0 4 3 5 9]
 [4 6 3 7 0 2 5 9 8 1]
 [5 7 8 6 1 2 9 4 0 3]
 [5 8 9 1 3 0 6 4 2 7]
 [4 2 5 3 1 8 7 9 6 0]]
Epoch 88810: Training cost= 2.3026, Training acc= 0.6273, Validation cost= 2.3026, Validation acc= 0.6269
Epoch 88820: Training cost= 2.3026, Training acc= 0.6272, Validation cost= 2.3026, Validation acc= 0.6269
Epoch 88830: Training cost= 2.3026, Training acc= 0.6272, Validation cost= 2.3026, Validation acc= 0.6268
Epoch 88840: Training cost= 2.3026, Training acc= 0.6271, Validation cost= 2.3026, Validation acc= 0.6268
Epoch 88850: Training cost= 2.3026, Training acc= 0.6271, Validation cost= 2.3026, Validation acc= 0.6267
Epoch 88860: Training cost= 2.3026, Training acc= 0.6270, Validation cost= 2.3026, Validation acc= 0.6266
Epoch 88870: Training cost= 2.3026, Training acc= 0.6269, Validation cost= 2.3026, Validation acc= 0.6266
Epoch 88880: Training cost= 2.3026, Training acc= 0.6269, Validation cost= 2.3026, Validation acc= 0.6265
Epoch 88890: Training cost= 2.3026, Training acc= 0.6268, Validation cost= 2.3026, Validation acc= 0.6265
Epoch 88900: Training cost= 2.3026, Training acc= 0.6268, Validation cost= 2.3026, Validation acc= 0.6264
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[5 6 1 3 8 7 4 9 0 2]
 [1 2 9 8 5 0 3 7 6 4]
 [4 7 6 8 2 3 9 5 0 1]
 [6 9 0 7 5 8 4 3 1 2]
 [6 9 2 7 3 8 1 4 0 5]
 [7 5 4 3 1 8 2 6 0 9]
 [2 9 8 4 3 5 1 6 7 0]
 [4 1 0 8 2 9 7 3 6 5]
 [8 7 1 9 6 5 3 4 0 2]
 [0 5 7 9 3 4 1 6 2 8]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 6 1 5 3 8 7 9 0 2]
 [6 5 2 7 1 8 4 3 9 0]
 [0 3 4 6 7 5 1 9 8 2]
 [6 7 3 9 0 8 4 1 5 2]
 [7 5 8 1 3 2 4 9 6 0]
 [1 9 7 5 6 0 8 4 2 3]
 [6 3 4 5 2 8 1 0 9 7]
 [4 8 1 5 7 9 3 0 6 2]
 [0 7 2 6 9 5 4 3 1 8]
 [1 3 0 9 8 7 6 5 4 2]]
Epoch 88910: Training cost= 2.3026, Training acc= 0.6267, Validation cost= 2.3026, Validation acc= 0.6263
Epoch 88920: Training cost= 2.3026, Training acc= 0.6266, Validation cost= 2.3026, Validation acc= 0.6263
Epoch 88930: Training cost= 2.3026, Training acc= 0.6266, Validation cost= 2.3026, Validation acc= 0.6262
Epoch 88940: Training cost= 2.3026, Training acc= 0.6265, Validation cost= 2.3026, Validation acc= 0.6262
Epoch 88950: Training cost= 2.3026, Training acc= 0.6265, Validation cost= 2.3026, Validation acc= 0.6261
Epoch 88960: Training cost= 2.3026, Training acc= 0.6264, Validation cost= 2.3026, Validation acc= 0.6261
Epoch 88970: Training cost= 2.3026, Training acc= 0.6264, Validation cost= 2.3026, Validation acc= 0.6260
Epoch 88980: Training cost= 2.3026, Training acc= 0.6263, Validation cost= 2.3026, Validation acc= 0.6259
Epoch 88990: Training cost= 2.3026, Training acc= 0.6262, Validation cost= 2.3026, Validation acc= 0.6259
Epoch 89000: Training cost= 2.3026, Training acc= 0.6262, Validation cost= 2.3026, Validation acc= 0.6258
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[6 4 1 0 2 3 8 7 5 9]
 [9 1 0 7 2 4 6 3 5 8]
 [6 5 8 0 7 9 4 1 2 3]
 [7 1 6 9 4 2 3 8 0 5]
 [9 2 5 1 4 0 3 8 7 6]
 [0 5 8 4 1 3 2 7 6 9]
 [1 7 9 5 6 8 3 4 0 2]
 [0 1 3 7 9 6 4 8 5 2]
 [1 0 4 9 7 8 5 6 2 3]
 [2 7 6 0 5 3 9 8 4 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 0 9 2 4 5 8 6 1 7]
 [8 9 4 2 5 0 1 3 7 6]
 [2 7 5 8 6 9 3 1 4 0]
 [2 1 6 4 7 0 5 8 3 9]
 [9 0 3 5 1 2 7 6 8 4]
 [8 1 4 7 6 5 2 9 3 0]
 [0 6 7 2 9 1 8 5 3 4]
 [4 6 9 5 8 2 0 7 3 1]
 [2 1 9 0 5 6 3 8 7 4]
 [4 0 6 5 3 9 7 1 8 2]]
Epoch 89010: Training cost= 2.3026, Training acc= 0.6261, Validation cost= 2.3026, Validation acc= 0.6258
Epoch 89020: Training cost= 2.3026, Training acc= 0.6261, Validation cost= 2.3026, Validation acc= 0.6257
Epoch 89030: Training cost= 2.3026, Training acc= 0.6260, Validation cost= 2.3026, Validation acc= 0.6256
Epoch 89040: Training cost= 2.3026, Training acc= 0.6259, Validation cost= 2.3026, Validation acc= 0.6256
Epoch 89050: Training cost= 2.3026, Training acc= 0.6259, Validation cost= 2.3026, Validation acc= 0.6255
Epoch 89060: Training cost= 2.3026, Training acc= 0.6258, Validation cost= 2.3026, Validation acc= 0.6255
Epoch 89070: Training cost= 2.3026, Training acc= 0.6258, Validation cost= 2.3026, Validation acc= 0.6254
Epoch 89080: Training cost= 2.3026, Training acc= 0.6257, Validation cost= 2.3026, Validation acc= 0.6253
Epoch 89090: Training cost= 2.3026, Training acc= 0.6256, Validation cost= 2.3026, Validation acc= 0.6253
Epoch 89100: Training cost= 2.3026, Training acc= 0.6256, Validation cost= 2.3026, Validation acc= 0.6252
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 0 1 6 8 4 3 9 5 7]
 [8 6 9 0 1 7 5 4 2 3]
 [8 7 1 9 3 4 6 5 2 0]
 [8 7 9 4 3 5 6 1 0 2]
 [1 9 5 4 0 3 8 2 7 6]
 [6 0 5 4 7 3 9 8 2 1]
 [2 8 7 3 1 5 4 9 0 6]
 [5 3 8 1 9 7 6 2 4 0]
 [2 5 6 3 0 8 7 9 1 4]
 [5 9 1 2 8 6 0 3 7 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 1 0 5 3 2 9 4 6 7]
 [6 3 0 5 2 4 7 8 9 1]
 [3 4 7 8 0 5 2 1 6 9]
 [1 0 9 8 7 3 6 2 5 4]
 [5 4 0 6 1 3 7 8 2 9]
 [8 0 2 7 9 3 1 4 6 5]
 [5 6 2 9 1 7 8 3 4 0]
 [2 4 7 0 5 1 6 9 8 3]
 [1 4 6 3 9 2 8 0 7 5]
 [8 1 2 9 6 5 7 4 3 0]]
Epoch 89110: Training cost= 2.3026, Training acc= 0.6255, Validation cost= 2.3026, Validation acc= 0.6252
Epoch 89120: Training cost= 2.3026, Training acc= 0.6255, Validation cost= 2.3026, Validation acc= 0.6251
Epoch 89130: Training cost= 2.3026, Training acc= 0.6254, Validation cost= 2.3026, Validation acc= 0.6250
Epoch 89140: Training cost= 2.3026, Training acc= 0.6253, Validation cost= 2.3026, Validation acc= 0.6250
Epoch 89150: Training cost= 2.3026, Training acc= 0.6253, Validation cost= 2.3026, Validation acc= 0.6249
Epoch 89160: Training cost= 2.3026, Training acc= 0.6252, Validation cost= 2.3026, Validation acc= 0.6249
Epoch 89170: Training cost= 2.3026, Training acc= 0.6252, Validation cost= 2.3026, Validation acc= 0.6248
Epoch 89180: Training cost= 2.3026, Training acc= 0.6251, Validation cost= 2.3026, Validation acc= 0.6248
Epoch 89190: Training cost= 2.3026, Training acc= 0.6251, Validation cost= 2.3026, Validation acc= 0.6247
Epoch 89200: Training cost= 2.3026, Training acc= 0.6250, Validation cost= 2.3026, Validation acc= 0.6246
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 8 7 5 6 1 9 4 2 3]
 [6 4 9 2 0 5 1 8 3 7]
 [6 4 2 3 8 9 1 7 0 5]
 [4 2 9 8 3 5 7 0 1 6]
 [4 5 2 6 8 1 9 0 3 7]
 [6 5 7 1 0 8 9 2 3 4]
 [9 4 1 5 0 8 6 2 7 3]
 [2 0 3 5 9 8 1 4 7 6]
 [8 1 0 4 3 9 6 5 2 7]
 [1 6 5 7 3 4 8 0 2 9]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[3 1 7 6 4 5 0 9 2 8]
 [5 6 3 0 8 9 1 2 4 7]
 [0 9 3 7 4 5 6 2 1 8]
 [8 9 2 3 0 5 7 4 6 1]
 [1 9 7 3 4 8 5 2 0 6]
 [5 0 6 9 1 3 7 8 2 4]
 [2 5 4 9 8 1 7 3 6 0]
 [4 1 5 6 3 7 0 8 2 9]
 [6 2 8 0 4 7 1 3 5 9]
 [8 1 4 5 3 2 9 6 0 7]]
Epoch 89210: Training cost= 2.3026, Training acc= 0.6249, Validation cost= 2.3026, Validation acc= 0.6246
Epoch 89220: Training cost= 2.3026, Training acc= 0.6249, Validation cost= 2.3026, Validation acc= 0.6245
Epoch 89230: Training cost= 2.3026, Training acc= 0.6248, Validation cost= 2.3026, Validation acc= 0.6245
Epoch 89240: Training cost= 2.3026, Training acc= 0.6248, Validation cost= 2.3026, Validation acc= 0.6244
Epoch 89250: Training cost= 2.3026, Training acc= 0.6247, Validation cost= 2.3026, Validation acc= 0.6243
Epoch 89260: Training cost= 2.3026, Training acc= 0.6246, Validation cost= 2.3026, Validation acc= 0.6243
Epoch 89270: Training cost= 2.3026, Training acc= 0.6246, Validation cost= 2.3026, Validation acc= 0.6242
Epoch 89280: Training cost= 2.3026, Training acc= 0.6245, Validation cost= 2.3026, Validation acc= 0.6242
Epoch 89290: Training cost= 2.3026, Training acc= 0.6245, Validation cost= 2.3026, Validation acc= 0.6241
Epoch 89300: Training cost= 2.3026, Training acc= 0.6244, Validation cost= 2.3026, Validation acc= 0.6241
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 4 1 5 0 8 6 7 3 9]
 [2 1 9 6 4 8 5 3 0 7]
 [9 6 4 1 5 2 0 8 3 7]
 [0 7 6 3 9 4 1 8 5 2]
 [9 0 3 1 5 4 7 6 8 2]
 [4 0 7 9 2 5 1 8 6 3]
 [5 7 1 0 3 4 2 8 6 9]
 [3 7 9 2 4 6 5 8 0 1]
 [3 1 6 8 0 4 9 5 7 2]
 [1 3 6 5 4 0 9 2 8 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 2 9 3 5 7 6 0 8 4]
 [9 5 7 2 8 0 3 1 4 6]
 [2 8 0 4 7 3 6 5 9 1]
 [1 6 8 0 4 5 3 7 2 9]
 [3 1 9 8 2 5 0 6 7 4]
 [8 6 9 0 7 2 3 1 5 4]
 [1 6 2 0 9 8 3 5 4 7]
 [1 3 5 7 6 0 9 4 8 2]
 [0 7 8 3 4 2 1 6 9 5]
 [4 5 6 0 8 7 3 9 1 2]]
Epoch 89310: Training cost= 2.3026, Training acc= 0.6243, Validation cost= 2.3026, Validation acc= 0.6240
Epoch 89320: Training cost= 2.3026, Training acc= 0.6243, Validation cost= 2.3026, Validation acc= 0.6239
Epoch 89330: Training cost= 2.3026, Training acc= 0.6242, Validation cost= 2.3026, Validation acc= 0.6239
Epoch 89340: Training cost= 2.3026, Training acc= 0.6242, Validation cost= 2.3026, Validation acc= 0.6238
Epoch 89350: Training cost= 2.3026, Training acc= 0.6241, Validation cost= 2.3026, Validation acc= 0.6238
Epoch 89360: Training cost= 2.3026, Training acc= 0.6241, Validation cost= 2.3026, Validation acc= 0.6237
Epoch 89370: Training cost= 2.3026, Training acc= 0.6240, Validation cost= 2.3026, Validation acc= 0.6236
Epoch 89380: Training cost= 2.3026, Training acc= 0.6239, Validation cost= 2.3026, Validation acc= 0.6236
Epoch 89390: Training cost= 2.3026, Training acc= 0.6239, Validation cost= 2.3026, Validation acc= 0.6235
Epoch 89400: Training cost= 2.3026, Training acc= 0.6238, Validation cost= 2.3026, Validation acc= 0.6235
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[0 4 5 8 6 2 1 7 3 9]
 [8 2 0 7 3 5 4 1 9 6]
 [4 5 9 3 2 1 0 8 7 6]
 [5 4 0 8 6 1 7 9 2 3]
 [9 6 4 7 3 8 2 0 1 5]
 [2 5 0 7 1 8 6 4 3 9]
 [9 2 4 7 0 6 1 5 3 8]
 [4 7 0 6 1 8 5 3 9 2]
 [2 5 1 4 0 7 3 9 8 6]
 [1 7 8 9 0 5 4 6 3 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 0 6 9 8 2 1 4 3 5]
 [3 0 1 6 2 8 5 4 7 9]
 [9 8 4 0 1 5 6 2 3 7]
 [0 7 5 3 2 6 4 8 9 1]
 [6 5 9 4 2 3 0 7 8 1]
 [9 2 6 7 3 8 5 4 0 1]
 [8 2 3 1 6 9 5 7 4 0]
 [2 6 0 5 3 4 9 1 8 7]
 [4 7 9 8 0 6 5 3 2 1]
 [4 1 5 6 2 3 9 0 8 7]]
Epoch 89410: Training cost= 2.3026, Training acc= 0.6238, Validation cost= 2.3026, Validation acc= 0.6234
Epoch 89420: Training cost= 2.3026, Training acc= 0.6237, Validation cost= 2.3026, Validation acc= 0.6233
Epoch 89430: Training cost= 2.3026, Training acc= 0.6236, Validation cost= 2.3026, Validation acc= 0.6233
Epoch 89440: Training cost= 2.3026, Training acc= 0.6236, Validation cost= 2.3026, Validation acc= 0.6232
Epoch 89450: Training cost= 2.3026, Training acc= 0.6235, Validation cost= 2.3026, Validation acc= 0.6232
Epoch 89460: Training cost= 2.3026, Training acc= 0.6235, Validation cost= 2.3026, Validation acc= 0.6231
Epoch 89470: Training cost= 2.3026, Training acc= 0.6234, Validation cost= 2.3026, Validation acc= 0.6231
Epoch 89480: Training cost= 2.3026, Training acc= 0.6234, Validation cost= 2.3026, Validation acc= 0.6230
Epoch 89490: Training cost= 2.3026, Training acc= 0.6233, Validation cost= 2.3026, Validation acc= 0.6229
Epoch 89500: Training cost= 2.3026, Training acc= 0.6232, Validation cost= 2.3026, Validation acc= 0.6229
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 4 8 5 7 9 0 6 3 2]
 [9 5 7 4 2 8 3 0 1 6]
 [5 3 9 2 7 8 0 4 6 1]
 [0 5 8 9 6 3 2 4 7 1]
 [6 0 3 5 7 2 1 4 9 8]
 [7 1 4 9 5 6 2 0 8 3]
 [6 7 2 8 9 5 4 3 0 1]
 [2 9 4 0 3 1 7 5 6 8]
 [9 3 6 0 1 5 4 7 2 8]
 [8 9 2 4 3 5 0 6 1 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[7 8 2 9 6 0 1 4 5 3]
 [1 3 0 8 4 2 6 5 9 7]
 [4 5 2 9 0 8 1 6 3 7]
 [8 2 4 1 9 7 3 6 5 0]
 [1 6 9 2 5 8 0 7 4 3]
 [0 4 8 2 5 3 9 1 6 7]
 [4 2 8 6 5 0 9 7 1 3]
 [3 1 7 5 0 4 2 6 8 9]
 [7 2 8 6 9 4 3 0 5 1]
 [9 2 5 3 8 0 6 4 7 1]]
Epoch 89510: Training cost= 2.3026, Training acc= 0.6232, Validation cost= 2.3026, Validation acc= 0.6228
Epoch 89520: Training cost= 2.3026, Training acc= 0.6231, Validation cost= 2.3026, Validation acc= 0.6228
Epoch 89530: Training cost= 2.3026, Training acc= 0.6231, Validation cost= 2.3026, Validation acc= 0.6227
Epoch 89540: Training cost= 2.3026, Training acc= 0.6230, Validation cost= 2.3026, Validation acc= 0.6226
Epoch 89550: Training cost= 2.3026, Training acc= 0.6229, Validation cost= 2.3026, Validation acc= 0.6226
Epoch 89560: Training cost= 2.3026, Training acc= 0.6229, Validation cost= 2.3026, Validation acc= 0.6225
Epoch 89570: Training cost= 2.3026, Training acc= 0.6228, Validation cost= 2.3026, Validation acc= 0.6225
Epoch 89580: Training cost= 2.3026, Training acc= 0.6228, Validation cost= 2.3026, Validation acc= 0.6224
Epoch 89590: Training cost= 2.3026, Training acc= 0.6227, Validation cost= 2.3026, Validation acc= 0.6224
Epoch 89600: Training cost= 2.3026, Training acc= 0.6227, Validation cost= 2.3026, Validation acc= 0.6223
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[9 0 4 5 2 6 1 3 8 7]
 [0 6 2 5 8 9 4 3 7 1]
 [4 9 0 2 8 1 5 3 6 7]
 [9 6 0 2 4 7 3 8 5 1]
 [1 9 3 2 8 6 0 7 4 5]
 [5 6 8 3 2 1 7 4 9 0]
 [7 3 5 2 4 9 6 0 8 1]
 [0 5 7 6 3 2 9 8 4 1]
 [2 7 8 6 3 9 0 5 1 4]
 [0 8 1 7 5 6 4 2 9 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 3 1 5 8 6 7 4 2 0]
 [6 1 3 0 5 9 4 2 8 7]
 [0 7 3 1 9 2 5 8 4 6]
 [1 8 6 5 4 3 9 2 0 7]
 [9 6 8 0 7 4 2 5 3 1]
 [5 4 2 7 3 9 1 8 6 0]
 [1 3 2 6 5 8 7 4 9 0]
 [8 0 5 1 6 3 4 2 7 9]
 [9 2 5 8 6 3 1 0 4 7]
 [4 6 5 8 3 1 0 7 9 2]]
Epoch 89610: Training cost= 2.3026, Training acc= 0.6226, Validation cost= 2.3026, Validation acc= 0.6222
Epoch 89620: Training cost= 2.3026, Training acc= 0.6225, Validation cost= 2.3026, Validation acc= 0.6222
Epoch 89630: Training cost= 2.3026, Training acc= 0.6225, Validation cost= 2.3026, Validation acc= 0.6221
Epoch 89640: Training cost= 2.3026, Training acc= 0.6224, Validation cost= 2.3026, Validation acc= 0.6221
Epoch 89650: Training cost= 2.3026, Training acc= 0.6224, Validation cost= 2.3026, Validation acc= 0.6220
Epoch 89660: Training cost= 2.3026, Training acc= 0.6223, Validation cost= 2.3026, Validation acc= 0.6219
Epoch 89670: Training cost= 2.3026, Training acc= 0.6222, Validation cost= 2.3026, Validation acc= 0.6219
Epoch 89680: Training cost= 2.3026, Training acc= 0.6222, Validation cost= 2.3026, Validation acc= 0.6218
Epoch 89690: Training cost= 2.3026, Training acc= 0.6221, Validation cost= 2.3026, Validation acc= 0.6218
Epoch 89700: Training cost= 2.3026, Training acc= 0.6221, Validation cost= 2.3026, Validation acc= 0.6217
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 0 5 7 8 4 3 6 2 9]
 [3 6 7 2 9 8 5 0 1 4]
 [1 8 6 9 5 3 7 0 4 2]
 [9 8 1 7 4 2 3 6 5 0]
 [0 4 9 1 3 5 8 2 7 6]
 [8 6 5 7 4 3 9 1 2 0]
 [8 0 7 9 4 5 2 6 1 3]
 [2 7 1 0 9 4 8 5 3 6]
 [6 7 0 8 2 3 9 4 1 5]
 [4 2 6 7 9 5 8 1 3 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 3 5 0 7 8 4 9 6 1]
 [4 6 1 3 2 9 8 5 0 7]
 [9 6 8 0 1 5 2 4 7 3]
 [9 4 8 5 0 6 3 7 2 1]
 [2 9 8 5 7 4 6 3 1 0]
 [3 2 1 6 9 5 0 8 7 4]
 [8 1 9 0 4 3 2 6 5 7]
 [3 4 2 7 0 6 5 9 1 8]
 [3 8 1 5 4 6 7 2 9 0]
 [4 6 2 1 5 8 3 9 7 0]]
Epoch 89710: Training cost= 2.3026, Training acc= 0.6220, Validation cost= 2.3026, Validation acc= 0.6217
Epoch 89720: Training cost= 2.3026, Training acc= 0.6220, Validation cost= 2.3026, Validation acc= 0.6216
Epoch 89730: Training cost= 2.3026, Training acc= 0.6219, Validation cost= 2.3026, Validation acc= 0.6215
Epoch 89740: Training cost= 2.3026, Training acc= 0.6218, Validation cost= 2.3026, Validation acc= 0.6215
Epoch 89750: Training cost= 2.3026, Training acc= 0.6218, Validation cost= 2.3026, Validation acc= 0.6214
Epoch 89760: Training cost= 2.3026, Training acc= 0.6217, Validation cost= 2.3026, Validation acc= 0.6214
Epoch 89770: Training cost= 2.3026, Training acc= 0.6217, Validation cost= 2.3026, Validation acc= 0.6213
Epoch 89780: Training cost= 2.3026, Training acc= 0.6216, Validation cost= 2.3026, Validation acc= 0.6212
Epoch 89790: Training cost= 2.3026, Training acc= 0.6215, Validation cost= 2.3026, Validation acc= 0.6212
Epoch 89800: Training cost= 2.3026, Training acc= 0.6215, Validation cost= 2.3026, Validation acc= 0.6211
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 4 3 0 5 2 6 7 8 9]
 [5 2 0 1 9 6 3 8 7 4]
 [0 4 8 3 5 7 1 2 9 6]
 [4 8 2 0 6 3 1 7 9 5]
 [9 8 5 0 6 1 4 7 3 2]
 [4 9 8 6 0 3 1 2 5 7]
 [4 1 7 0 2 6 8 9 3 5]
 [1 2 3 9 0 5 7 8 4 6]
 [2 7 0 6 3 4 9 5 1 8]
 [5 4 3 9 0 6 8 1 7 2]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 0 9 3 1 2 5 7 8 6]
 [2 8 5 3 7 4 9 1 6 0]
 [6 3 9 0 4 2 1 7 8 5]
 [1 6 9 0 4 5 2 7 3 8]
 [0 8 7 3 9 5 1 6 2 4]
 [2 7 0 5 3 1 6 9 8 4]
 [2 5 3 6 7 1 0 4 8 9]
 [5 1 2 8 4 3 9 7 6 0]
 [0 1 7 8 4 2 9 3 6 5]
 [4 8 1 9 6 0 2 3 5 7]]
Epoch 89810: Training cost= 2.3026, Training acc= 0.6214, Validation cost= 2.3026, Validation acc= 0.6211
Epoch 89820: Training cost= 2.3026, Training acc= 0.6214, Validation cost= 2.3026, Validation acc= 0.6210
Epoch 89830: Training cost= 2.3026, Training acc= 0.6213, Validation cost= 2.3026, Validation acc= 0.6210
Epoch 89840: Training cost= 2.3026, Training acc= 0.6213, Validation cost= 2.3026, Validation acc= 0.6209
Epoch 89850: Training cost= 2.3026, Training acc= 0.6212, Validation cost= 2.3026, Validation acc= 0.6208
Epoch 89860: Training cost= 2.3026, Training acc= 0.6211, Validation cost= 2.3026, Validation acc= 0.6208
Epoch 89870: Training cost= 2.3026, Training acc= 0.6211, Validation cost= 2.3026, Validation acc= 0.6207
Epoch 89880: Training cost= 2.3026, Training acc= 0.6210, Validation cost= 2.3026, Validation acc= 0.6207
Epoch 89890: Training cost= 2.3026, Training acc= 0.6210, Validation cost= 2.3026, Validation acc= 0.6206
Epoch 89900: Training cost= 2.3026, Training acc= 0.6209, Validation cost= 2.3026, Validation acc= 0.6206
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[7 4 1 3 9 8 0 6 5 2]
 [9 0 6 3 5 8 1 4 2 7]
 [0 9 6 7 2 3 8 4 5 1]
 [3 4 2 1 9 8 0 6 5 7]
 [0 1 2 3 6 7 5 8 4 9]
 [0 7 8 1 3 2 4 5 6 9]
 [3 2 9 7 6 0 5 4 8 1]
 [4 0 2 1 6 9 3 5 7 8]
 [2 9 4 8 7 3 0 1 6 5]
 [9 1 0 3 2 8 5 4 6 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 6 0 1 9 3 7 4 5 2]
 [1 8 2 6 3 0 9 7 4 5]
 [1 9 0 8 4 5 3 7 2 6]
 [9 0 3 7 1 8 5 4 6 2]
 [4 5 6 7 3 1 9 2 8 0]
 [0 4 3 5 2 8 1 6 7 9]
 [9 0 4 2 8 6 7 3 5 1]
 [8 9 6 7 0 1 4 3 2 5]
 [2 3 1 7 4 6 8 0 9 5]
 [8 5 0 7 4 2 6 9 1 3]]
Epoch 89910: Training cost= 2.3026, Training acc= 0.6208, Validation cost= 2.3026, Validation acc= 0.6205
Epoch 89920: Training cost= 2.3026, Training acc= 0.6208, Validation cost= 2.3026, Validation acc= 0.6204
Epoch 89930: Training cost= 2.3026, Training acc= 0.6207, Validation cost= 2.3026, Validation acc= 0.6204
Epoch 89940: Training cost= 2.3026, Training acc= 0.6207, Validation cost= 2.3026, Validation acc= 0.6203
Epoch 89950: Training cost= 2.3026, Training acc= 0.6206, Validation cost= 2.3026, Validation acc= 0.6203
Epoch 89960: Training cost= 2.3026, Training acc= 0.6206, Validation cost= 2.3026, Validation acc= 0.6202
Epoch 89970: Training cost= 2.3026, Training acc= 0.6205, Validation cost= 2.3026, Validation acc= 0.6201
Epoch 89980: Training cost= 2.3026, Training acc= 0.6204, Validation cost= 2.3026, Validation acc= 0.6201
Epoch 89990: Training cost= 2.3026, Training acc= 0.6204, Validation cost= 2.3026, Validation acc= 0.6200
Epoch 90000: Training cost= 2.3026, Training acc= 0.6203, Validation cost= 2.3026, Validation acc= 0.6200
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 9 5 8 0 7 1 3 6 2]
 [2 4 8 5 6 7 0 1 9 3]
 [5 9 3 2 1 6 0 7 8 4]
 [8 7 2 0 1 6 9 4 3 5]
 [9 8 6 3 1 2 5 7 4 0]
 [3 5 2 6 9 1 4 7 0 8]
 [8 6 7 3 2 1 0 9 4 5]
 [3 7 5 1 2 8 4 6 0 9]
 [4 7 9 8 0 2 6 3 5 1]
 [0 6 8 9 3 4 2 1 5 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[1 8 4 9 0 5 6 7 3 2]
 [2 7 6 1 0 4 5 3 9 8]
 [6 3 8 9 1 2 7 0 4 5]
 [8 4 0 1 9 3 2 7 6 5]
 [1 4 9 8 3 5 2 0 7 6]
 [8 9 7 4 3 5 6 0 1 2]
 [1 3 7 8 0 2 9 6 4 5]
 [5 0 1 3 9 7 8 6 4 2]
 [5 2 7 4 8 0 9 3 1 6]
 [8 5 2 9 7 6 1 4 0 3]]
Epoch 90010: Training cost= 2.3026, Training acc= 0.6203, Validation cost= 2.3026, Validation acc= 0.6199
Epoch 90020: Training cost= 2.3026, Training acc= 0.6202, Validation cost= 2.3026, Validation acc= 0.6199
Epoch 90030: Training cost= 2.3026, Training acc= 0.6202, Validation cost= 2.3026, Validation acc= 0.6198
Epoch 90040: Training cost= 2.3026, Training acc= 0.6201, Validation cost= 2.3026, Validation acc= 0.6197
Epoch 90050: Training cost= 2.3026, Training acc= 0.6200, Validation cost= 2.3026, Validation acc= 0.6197
Epoch 90060: Training cost= 2.3026, Training acc= 0.6200, Validation cost= 2.3026, Validation acc= 0.6196
Epoch 90070: Training cost= 2.3026, Training acc= 0.6199, Validation cost= 2.3026, Validation acc= 0.6196
Epoch 90080: Training cost= 2.3026, Training acc= 0.6199, Validation cost= 2.3026, Validation acc= 0.6195
Epoch 90090: Training cost= 2.3026, Training acc= 0.6198, Validation cost= 2.3026, Validation acc= 0.6195
Epoch 90100: Training cost= 2.3026, Training acc= 0.6198, Validation cost= 2.3026, Validation acc= 0.6194
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[2 3 8 6 9 1 7 0 5 4]
 [3 0 7 2 1 5 4 9 6 8]
 [2 6 7 0 8 1 9 3 5 4]
 [6 9 8 5 2 0 4 7 1 3]
 [3 1 6 9 8 7 2 4 0 5]
 [8 6 0 4 7 9 2 5 1 3]
 [2 7 1 8 5 3 6 9 4 0]
 [8 6 4 0 3 9 5 7 1 2]
 [0 9 4 3 8 5 2 6 7 1]
 [9 5 2 8 4 0 7 3 6 1]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[9 2 8 0 6 4 3 1 7 5]
 [3 1 8 7 2 4 9 0 5 6]
 [2 8 4 6 0 5 1 3 7 9]
 [1 3 8 4 9 2 7 5 6 0]
 [7 9 4 3 6 5 8 1 2 0]
 [0 6 5 8 9 3 4 7 2 1]
 [0 8 2 1 9 3 6 5 7 4]
 [1 3 5 6 0 7 2 8 4 9]
 [1 7 0 5 6 4 3 9 2 8]
 [3 4 1 6 7 2 5 9 8 0]]
Epoch 90110: Training cost= 2.3026, Training acc= 0.6197, Validation cost= 2.3026, Validation acc= 0.6193
Epoch 90120: Training cost= 2.3026, Training acc= 0.6196, Validation cost= 2.3026, Validation acc= 0.6193
Epoch 90130: Training cost= 2.3026, Training acc= 0.6196, Validation cost= 2.3026, Validation acc= 0.6192
Epoch 90140: Training cost= 2.3026, Training acc= 0.6195, Validation cost= 2.3026, Validation acc= 0.6192
Epoch 90150: Training cost= 2.3026, Training acc= 0.6195, Validation cost= 2.3026, Validation acc= 0.6191
Epoch 90160: Training cost= 2.3026, Training acc= 0.6194, Validation cost= 2.3026, Validation acc= 0.6191
Epoch 90170: Training cost= 2.3026, Training acc= 0.6193, Validation cost= 2.3026, Validation acc= 0.6190
Epoch 90180: Training cost= 2.3026, Training acc= 0.6193, Validation cost= 2.3026, Validation acc= 0.6189
Epoch 90190: Training cost= 2.3026, Training acc= 0.6192, Validation cost= 2.3026, Validation acc= 0.6189
Epoch 90200: Training cost= 2.3026, Training acc= 0.6192, Validation cost= 2.3026, Validation acc= 0.6188
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[1 8 7 3 0 5 4 9 2 6]
 [4 0 5 7 3 2 8 1 6 9]
 [5 8 3 7 6 0 9 2 1 4]
 [9 7 5 2 8 3 4 6 0 1]
 [2 1 0 9 7 8 5 4 3 6]
 [9 4 1 2 6 8 0 7 3 5]
 [9 7 8 3 6 4 0 2 5 1]
 [2 7 1 5 3 4 6 9 0 8]
 [4 3 7 2 0 1 5 6 9 8]
 [8 0 1 2 5 4 3 6 9 7]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[4 0 8 5 2 6 9 1 7 3]
 [9 3 0 1 2 5 6 4 8 7]
 [6 4 3 8 7 5 1 2 9 0]
 [3 2 9 1 6 8 7 4 0 5]
 [1 4 5 2 8 0 7 6 3 9]
 [8 1 6 7 0 3 4 9 5 2]
 [2 8 7 6 9 3 5 4 1 0]
 [2 7 4 0 1 9 3 5 8 6]
 [1 3 2 7 5 9 4 6 8 0]
 [5 4 0 7 3 6 9 1 2 8]]
Epoch 90210: Training cost= 2.3026, Training acc= 0.6191, Validation cost= 2.3026, Validation acc= 0.6188
Epoch 90220: Training cost= 2.3026, Training acc= 0.6191, Validation cost= 2.3026, Validation acc= 0.6187
Epoch 90230: Training cost= 2.3026, Training acc= 0.6190, Validation cost= 2.3026, Validation acc= 0.6186
Epoch 90240: Training cost= 2.3026, Training acc= 0.6189, Validation cost= 2.3026, Validation acc= 0.6186
Epoch 90250: Training cost= 2.3026, Training acc= 0.6189, Validation cost= 2.3026, Validation acc= 0.6185
Epoch 90260: Training cost= 2.3026, Training acc= 0.6188, Validation cost= 2.3026, Validation acc= 0.6185
Epoch 90270: Training cost= 2.3026, Training acc= 0.6188, Validation cost= 2.3026, Validation acc= 0.6184
Epoch 90280: Training cost= 2.3026, Training acc= 0.6187, Validation cost= 2.3026, Validation acc= 0.6184
Epoch 90290: Training cost= 2.3026, Training acc= 0.6187, Validation cost= 2.3026, Validation acc= 0.6183
Epoch 90300: Training cost= 2.3026, Training acc= 0.6186, Validation cost= 2.3026, Validation acc= 0.6182
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[4 0 6 3 5 9 8 7 1 2]
 [4 0 9 6 3 7 5 8 2 1]
 [3 9 0 2 6 7 4 1 8 5]
 [9 1 5 3 4 0 7 6 8 2]
 [5 8 6 4 2 0 3 9 7 1]
 [6 5 4 9 7 2 1 3 8 0]
 [6 4 8 2 5 9 1 0 7 3]
 [8 4 9 0 3 1 7 2 6 5]
 [4 6 8 1 2 3 0 7 9 5]
 [8 4 6 9 7 5 2 0 1 3]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[0 1 7 3 6 5 4 2 8 9]
 [1 5 7 2 9 4 0 6 8 3]
 [3 0 4 8 7 1 2 9 6 5]
 [9 7 1 3 5 2 4 0 6 8]
 [9 1 3 7 6 0 5 2 4 8]
 [3 7 6 8 2 5 9 0 4 1]
 [6 7 5 9 1 3 0 8 2 4]
 [4 9 0 5 2 1 6 3 8 7]
 [5 4 6 1 9 7 0 3 2 8]
 [0 4 1 3 7 8 9 5 2 6]]
Epoch 90310: Training cost= 2.3026, Training acc= 0.6185, Validation cost= 2.3026, Validation acc= 0.6182
Epoch 90320: Training cost= 2.3026, Training acc= 0.6185, Validation cost= 2.3026, Validation acc= 0.6181
Epoch 90330: Training cost= 2.3026, Training acc= 0.6184, Validation cost= 2.3026, Validation acc= 0.6181
Epoch 90340: Training cost= 2.3026, Training acc= 0.6184, Validation cost= 2.3026, Validation acc= 0.6180
Epoch 90350: Training cost= 2.3026, Training acc= 0.6183, Validation cost= 2.3026, Validation acc= 0.6180
Epoch 90360: Training cost= 2.3026, Training acc= 0.6183, Validation cost= 2.3026, Validation acc= 0.6179
Epoch 90370: Training cost= 2.3026, Training acc= 0.6182, Validation cost= 2.3026, Validation acc= 0.6178
Epoch 90380: Training cost= 2.3026, Training acc= 0.6181, Validation cost= 2.3026, Validation acc= 0.6178
Epoch 90390: Training cost= 2.3026, Training acc= 0.6181, Validation cost= 2.3026, Validation acc= 0.6177
Epoch 90400: Training cost= 2.3026, Training acc= 0.6180, Validation cost= 2.3026, Validation acc= 0.6177
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 9 2 1 7 0 6 5 3 4]
 [0 2 9 7 1 4 8 6 5 3]
 [7 1 3 8 6 0 9 4 5 2]
 [6 2 1 4 8 7 9 0 5 3]
 [9 4 5 1 6 7 8 2 0 3]
 [0 2 4 5 1 9 8 6 3 7]
 [5 3 8 4 0 1 2 9 6 7]
 [2 1 5 0 3 9 6 8 4 7]
 [1 5 3 4 8 9 6 0 7 2]
 [1 6 2 8 0 5 9 7 3 4]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[2 4 1 0 7 9 3 6 5 8]
 [7 5 9 4 2 1 3 8 6 0]
 [8 0 1 3 9 2 4 6 7 5]
 [5 1 6 7 8 4 3 2 0 9]
 [8 7 2 5 0 6 9 3 1 4]
 [6 2 8 5 0 4 1 7 9 3]
 [5 1 4 2 3 7 8 6 9 0]
 [7 1 5 2 4 3 8 6 9 0]
 [0 4 5 7 1 6 2 3 9 8]
 [5 1 0 6 8 2 9 7 3 4]]
Epoch 90410: Training cost= 2.3026, Training acc= 0.6180, Validation cost= 2.3026, Validation acc= 0.6176
Epoch 90420: Training cost= 2.3026, Training acc= 0.6179, Validation cost= 2.3026, Validation acc= 0.6176
Epoch 90430: Training cost= 2.3026, Training acc= 0.6179, Validation cost= 2.3026, Validation acc= 0.6175
Epoch 90440: Training cost= 2.3026, Training acc= 0.6178, Validation cost= 2.3026, Validation acc= 0.6174
Epoch 90450: Training cost= 2.3026, Training acc= 0.6177, Validation cost= 2.3026, Validation acc= 0.6174
Epoch 90460: Training cost= 2.3026, Training acc= 0.6177, Validation cost= 2.3026, Validation acc= 0.6173
Epoch 90470: Training cost= 2.3026, Training acc= 0.6176, Validation cost= 2.3026, Validation acc= 0.6173
Epoch 90480: Training cost= 2.3026, Training acc= 0.6176, Validation cost= 2.3026, Validation acc= 0.6172
Epoch 90490: Training cost= 2.3026, Training acc= 0.6175, Validation cost= 2.3026, Validation acc= 0.6172
Epoch 90500: Training cost= 2.3026, Training acc= 0.6175, Validation cost= 2.3026, Validation acc= 0.6171
tm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
ty_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
tt_50sample [[8 4 2 0 6 5 7 1 3 9]
 [7 0 8 3 1 5 9 4 6 2]
 [9 3 7 5 2 4 0 8 1 6]
 [1 8 6 4 0 7 9 3 5 2]
 [0 1 9 4 6 7 3 2 8 5]
 [5 2 9 4 7 0 8 6 3 1]
 [1 9 5 3 7 0 2 4 6 8]
 [4 7 1 2 9 8 3 0 6 5]
 [3 1 2 5 7 0 6 4 8 9]
 [9 6 1 4 3 7 8 2 5 0]]
vm  [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
vy_50sample [[0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]]
vt_50sample [[8 6 7 0 4 3 1 9 2 5]
 [2 7 9 3 4 8 6 0 5 1]
 [2 1 0 3 7 8 6 9 5 4]
 [8 3 2 0 5 1 4 9 7 6]
 [9 4 1 6 8 7 3 0 5 2]
 [2 0 3 9 1 7 5 6 4 8]
 [6 0 4 2 1 8 5 3 7 9]
 [3 4 6 2 9 1 7 5 8 0]
 [4 9 8 7 6 1 0 5 3 2]
 [7 2 6 4 9 3 8 1 5 0]]
Epoch 90510: Training cost= 2.3026, Training acc= 0.6174, Validation cost= 2.3026, Validation acc= 0.6170
Epoch 90520: Training cost= 2.3026, Training acc= 0.6173, Validation cost= 2.3026, Validation acc= 0.6170
Epoch 90530: Training cost= 2.3026, Training acc= 0.6173, Validation cost= 2.3026, Validation acc= 0.6169
Epoch 90540: Training cost= 2.3026, Training acc= 0.6172, Validation cost= 2.3026, Validation acc= 0.6169
Epoch 90550: Training cost= 2.3026, Training acc= 0.6172, Validation cost= 2.3026, Validation acc= 0.6168
Epoch 90560: Training cost= 2.3026, Training acc= 0.6171, Validation cost= 2.3026, Validation acc= 0.6168
Epoch 90570: Training cost= 2.3026, Training acc= 0.6171, Validation cost= 2.3026, Validation acc= 0.6167
Epoch 90580: Training cost= 2.3026, Training acc= 0.6170, Validation cost= 2.3026, Validation acc= 0.6166
Epoch 90590: Training cost= 2.3026, Training acc= 0.6169, Validation cost= 2.3026, Validation acc= 0.6166
